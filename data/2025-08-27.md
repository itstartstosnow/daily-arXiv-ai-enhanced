<div id=toc></div>

# Table of Contents

- [cs.CR](#cs.CR) [Total: 16]


<div id='cs.CR'></div>

# cs.CR [[Back]](#toc)

### [1] [A Systematic Approach to Predict the Impact of Cybersecurity Vulnerabilities Using LLMs](https://arxiv.org/abs/2508.18439)
*Anders Mølmen Høst,Pierre Lison,Leon Moonen*

Main category: cs.CR

TL;DR: TRIAGE是一个使用大语言模型自动将CVE漏洞映射到ATT&CK技术的混合方法，结合基于规则推理和数据驱动推理，提高了漏洞影响分析的效率和召回率。


<details>
  <summary>Details</summary>
Motivation: 现有的漏洞数据库（如NVD）缺乏关于漏洞实际影响的信息，特别是攻击者可能使用的战术、技术和程序（TTPs）。手动将CVE映射到ATT&CK技术既耗时又具有挑战性，需要自动化解决方案。

Method: 提出了TRIAGE双管齐下的自动化方法：1）基于MITRE CVE映射方法论的LLM提示生成初始技术列表；2）使用上下文学习的第二个LLM模块进行技术映射。这种混合方法结合了基于规则的推理和数据驱动的推断。

Result: 评估显示上下文学习方法优于单独的映射方法，混合方法提高了利用技术的召回率。GPT-4o-mini在此任务上表现优于Llama3.3-70B。

Conclusion: 大语言模型可用于自动预测网络安全漏洞的影响，TRIAGE使CVE到ATT&CK的映射过程更加高效，为漏洞影响分析提供了有效的自动化工具。

Abstract: Vulnerability databases, such as the National Vulnerability Database (NVD),
offer detailed descriptions of Common Vulnerabilities and Exposures (CVEs), but
often lack information on their real-world impact, such as the tactics,
techniques, and procedures (TTPs) that adversaries may use to exploit the
vulnerability. However, manually linking CVEs to their corresponding TTPs is a
challenging and time-consuming task, and the high volume of new vulnerabilities
published annually makes automated support desirable.
  This paper introduces TRIAGE, a two-pronged automated approach that uses
Large Language Models (LLMs) to map CVEs to relevant techniques from the ATT&CK
knowledge base. We first prompt an LLM with instructions based on MITRE's CVE
Mapping Methodology to predict an initial list of techniques. This list is then
combined with the results from a second LLM-based module that uses in-context
learning to map a CVE to relevant techniques. This hybrid approach
strategically combines rule-based reasoning with data-driven inference. Our
evaluation reveals that in-context learning outperforms the individual mapping
methods, and the hybrid approach improves recall of exploitation techniques. We
also find that GPT-4o-mini performs better than Llama3.3-70B on this task.
Overall, our results show that LLMs can be used to automatically predict the
impact of cybersecurity vulnerabilities and TRIAGE makes the process of mapping
CVEs to ATT&CK more efficient.
  Keywords: vulnerability impact, CVE, ATT&CK techniques, large language
models, automated mapping.

</details>


### [2] [Privacy-Preserving Federated Learning Framework for Risk-Based Adaptive Authentication](https://arxiv.org/abs/2508.18453)
*Yaser Baseri,Abdelhakim Senhaji Hafid,Dimitrios Makrakis,Hamidreza Fereidouni*

Main category: cs.CR

TL;DR: FL-RBA2是一个新颖的联邦学习框架，通过数学相似性变换解决非IID数据挑战，实现去中心化风险自适应认证，在保护隐私的同时提供强大的安全保证。


<details>
  <summary>Details</summary>
Motivation: 现有联邦学习方法在处理非独立同分布用户特征时存在偏差、不稳定和泛化能力差的问题，需要平衡安全性和隐私保护。

Method: 采用数学相似性变换将异构用户特征转换为IID相似向量，结合差分隐私保护敏感信息，使用消息认证码确保模型完整性，并通过聚类风险标注缓解冷启动问题。

Result: 在击键、鼠标和上下文数据集上的实验验证了FL-RBA2在高风险用户检测方面的有效性，以及对模型反转和推理攻击的韧性，即使在强差分隐私约束下也能保持良好性能。

Conclusion: FL-RBA2框架成功解决了非IID数据挑战，在保护用户隐私的同时实现了可扩展的自适应认证鲁棒性，为去中心化风险认证提供了可行的解决方案。

Abstract: Balancing robust security with strong privacy guarantees is critical for
Risk-Based Adaptive Authentication (RBA), particularly in decentralized
settings. Federated Learning (FL) offers a promising solution by enabling
collaborative risk assessment without centralizing user data. However, existing
FL approaches struggle with Non-Independent and Identically Distributed
(Non-IID) user features, resulting in biased, unstable, and poorly generalized
global models. This paper introduces FL-RBA2, a novel Federated Learning
framework for Risk-Based Adaptive Authentication that addresses Non-IID
challenges through a mathematically grounded similarity transformation. By
converting heterogeneous user features (including behavioral, biometric,
contextual, interaction-based, and knowledge-based modalities) into IID
similarity vectors, FL-RBA2 supports unbiased aggregation and personalized risk
modeling across distributed clients. The framework mitigates cold-start
limitations via clustering-based risk labeling, incorporates Differential
Privacy (DP) to safeguard sensitive information, and employs Message
Authentication Codes (MACs) to ensure model integrity and authenticity.
Federated updates are securely aggregated into a global model, achieving strong
balance between user privacy, scalability, and adaptive authentication
robustness. Rigorous game-based security proofs in the Random Oracle Model
formally establish privacy, correctness, and adaptive security guarantees.
Extensive experiments on keystroke, mouse, and contextual datasets validate
FL-RBA2's effectiveness in high-risk user detection and its resilience to model
inversion and inference attacks, even under strong DP constraints.

</details>


### [3] [An 8- and 12-bit block AES cipher](https://arxiv.org/abs/2508.18485)
*Peter T. Breuer*

Main category: cs.CR

TL;DR: 本文介绍了一个极小的8位或12位块AES（Rijndael）密码的实现，并提供了Java源代码


<details>
  <summary>Details</summary>
Motivation: 由于极小的块AES密码非常罕见、难以找到或缺乏详细说明，因此需要记录和实现这样的密码

Method: 开发了一个8位或12位块的AES（Rijndael）密码算法，并提供了完整的Java源代码实现

Result: 成功创建了一个真正微型的AES密码变体，适用于资源受限的环境

Conclusion: 该工作填补了极小块AES密码实现的空白，为需要微型加密解决方案的应用提供了实用工具

Abstract: Because it is so unusual, or hard to find, or expository, a truly tiny 8- or
12-bit block AES (Rijndael) cipher is documented here, along with Java source
code.

</details>


### [4] [Collaborative Intelligence: Topic Modelling of Large Language Model use in Live Cybersecurity Operations](https://arxiv.org/abs/2508.18488)
*Martin Lochner,Keegan Keplinger*

Main category: cs.CR

TL;DR: SOC专家主要使用LLM来理解复杂文本字符串，约40%的使用都围绕这一用例，表明LLM工具可以支持SOC工作流程


<details>
  <summary>Details</summary>
Motivation: 研究SOC专家如何自愿使用大型语言模型来支持实时安全运营，以了解人机协作的新模式

Method: 基于10个月的SOC操作员使用GPT-4的聊天数据，采用BERTopic模型和新型主题建模工作流进行主题分析

Result: SOC操作员主要使用LLM来促进对复杂文本字符串的理解，这种用例约占LLM使用量的40%

Conclusion: SOC操作员需要快速解释复杂命令，他们自然倾向于利用LLM支持这一活动，表明可以通过设计协作式LLM工具来增强SOC工作流程

Abstract: Objective: This work describes the topic modelling of Security Operations
Centre (SOC) use of a large language model (LLM), during live security
operations. The goal is to better understand how these specialists voluntarily
use this tool.
  Background: Human-automation teams have been extensively studied, but
transformer-based language models have sparked a new wave of collaboration. SOC
personnel at a major cybersecurity provider used an LLM to support live
security operations. This study examines how these specialists incorporated the
LLM into their work.
  Method: Our data set is the result of 10 months of SOC operators accessing
GPT-4 over an internally deployed HTTP-based chat application. We performed two
topic modelling exercises, first using the established BERTopic model
(Grootendorst, 2022), and second, using a novel topic modeling workflow.
  Results: Both the BERTopic analysis and novel modelling approach revealed
that SOC operators primarily used the LLM to facilitate their understanding of
complex text strings. Variations on this use-case accounted for ~40% of SOC LLM
usage.
  Conclusion: SOC operators are required to rapidly interpret complex commands
and similar information. Their natural tendency to leverage LLMs to support
this activity indicates that their workflow can be supported and augmented by
designing collaborative LLM tools for use in the SOC.
  Application: This work can aid in creating next-generation tools for Security
Operations Centres. By understanding common use-cases, we can develop workflows
supporting SOC task flow. One example is a right-click context menu for
executing a command line analysis LLM call directly in the SOC environment.

</details>


### [5] [PRISM: Robust VLM Alignment with Principled Reasoning for Integrated Safety in Multimodality](https://arxiv.org/abs/2508.18649)
*Nanxi Li,Zhengyue Zhao,Chaowei Xiao*

Main category: cs.CR

TL;DR: PRISM是一个保护视觉语言模型安全的新框架，通过安全感知的思维链推理和直接偏好优化，在保持模型效用的同时显著提升安全性


<details>
  <summary>Details</summary>
Motivation: 现有视觉语言模型安全方法存在过度防御损害效用或浅层对齐无法检测复杂威胁的问题，需要深度推理的安全保护方案

Method: 提出PRISM框架，包含PRISM-CoT数据集教授安全感知思维链推理，以及通过蒙特卡洛树搜索生成的PRISM-DPO进行直接偏好优化来精炼推理过程

Result: 在多个基准测试中取得显著成果：Qwen2-VL在JailbreakV-28K上攻击成功率仅0.15%，LLaVA-1.5在VLBreak上比之前最佳方法提升90%，在MIS基准上攻击成功率降至8.70%

Conclusion: PRISM框架在保持甚至增强模型效用的同时，提供了强大的安全防护，对自适应攻击具有强鲁棒性，并能有效泛化到分布外挑战

Abstract: Safeguarding vision-language models (VLMs) is a critical challenge, as
existing methods often suffer from over-defense, which harms utility, or rely
on shallow alignment, failing to detect complex threats that require deep
reasoning. To this end, we introduce PRISM (Principled Reasoning for Integrated
Safety in Multimodality), a system2-like framework that aligns VLMs by
embedding a structured, safety-aware reasoning process. Our framework consists
of two key components: PRISM-CoT, a dataset that teaches safety-aware
chain-of-thought reasoning, and PRISM-DPO, generated via Monte Carlo Tree
Search (MCTS) to further refine this reasoning through Direct Preference
Optimization to help obtain a delicate safety boundary. Comprehensive
evaluations demonstrate PRISM's effectiveness, achieving remarkably low attack
success rates including 0.15% on JailbreakV-28K for Qwen2-VL and 90%
improvement over the previous best method on VLBreak for LLaVA-1.5. PRISM also
exhibits strong robustness against adaptive attacks, significantly increasing
computational costs for adversaries, and generalizes effectively to
out-of-distribution challenges, reducing attack success rates to just 8.70% on
the challenging multi-image MIS benchmark. Remarkably, this robust defense is
achieved while preserving, and in some cases enhancing, model utility. To
promote reproducibility, we have made our code, data, and model weights
available at https://github.com/SaFoLab-WISC/PRISM.

</details>


### [6] [UniC-RAG: Universal Knowledge Corruption Attacks to Retrieval-Augmented Generation](https://arxiv.org/abs/2508.18652)
*Runpeng Geng,Yanting Wang,Ying Chen,Jinyuan Jia*

Main category: cs.CR

TL;DR: UniC-RAG是一种针对检索增强生成(RAG)系统的通用知识污染攻击方法，能够通过少量对抗性文本同时攻击大量不同主题的用户查询，攻击成功率超过90%。


<details>
  <summary>Details</summary>
Motivation: 现有的RAG系统容易受到知识污染攻击，但之前的研究主要针对特定查询或相似主题的查询，缺乏能够同时攻击大量多样化查询的通用攻击方法。

Method: 将UniC-RAG建模为优化问题，设计有效解决方案，包括基于平衡相似性的聚类方法来增强攻击效果，通过联合优化少量对抗性文本来同时攻击大量用户查询。

Result: UniC-RAG在包含数百万文本的知识库中注入100个对抗性文本，即可同时攻击2000个用户查询，攻击成功率超过90%，显著优于基线方法。

Conclusion: UniC-RAG展示了强大的攻击效果，现有防御机制无法有效防御，凸显了RAG系统需要新的防御机制来应对此类通用知识污染攻击。

Abstract: Retrieval-augmented generation (RAG) systems are widely deployed in
real-world applications in diverse domains such as finance, healthcare, and
cybersecurity. However, many studies showed that they are vulnerable to
knowledge corruption attacks, where an attacker can inject adversarial texts
into the knowledge database of a RAG system to induce the LLM to generate
attacker-desired outputs. Existing studies mainly focus on attacking specific
queries or queries with similar topics (or keywords). In this work, we propose
UniC-RAG, a universal knowledge corruption attack against RAG systems. Unlike
prior work, UniC-RAG jointly optimizes a small number of adversarial texts that
can simultaneously attack a large number of user queries with diverse topics
and domains, enabling an attacker to achieve various malicious objectives, such
as directing users to malicious websites, triggering harmful command execution,
or launching denial-of-service attacks. We formulate UniC-RAG as an
optimization problem and further design an effective solution to solve it,
including a balanced similarity-based clustering method to enhance the attack's
effectiveness. Our extensive evaluations demonstrate that UniC-RAG is highly
effective and significantly outperforms baselines. For instance, UniC-RAG could
achieve over 90% attack success rate by injecting 100 adversarial texts into a
knowledge database with millions of texts to simultaneously attack a large set
of user queries (e.g., 2,000). Additionally, we evaluate existing defenses and
show that they are insufficient to defend against UniC-RAG, highlighting the
need for new defense mechanisms in RAG systems.

</details>


### [7] [FALCON: Autonomous Cyber Threat Intelligence Mining with LLMs for IDS Rule Generation](https://arxiv.org/abs/2508.18684)
*Shaswata Mitra,Azim Bazarov,Martin Duclos,Sudip Mittal,Aritran Piplai,Md Rayhanur Rahman,Edward Zieglar,Shahram Rahimi*

Main category: cs.CR

TL;DR: FALCON是一个基于大语言模型的自主代理框架，能够从网络威胁情报数据实时生成可部署的入侵检测系统规则，并通过内置验证器进行评估，实现了95%的平均准确率。


<details>
  <summary>Details</summary>
Motivation: 传统的基于签名的入侵检测系统需要频繁更新规则来应对不断演变的网络威胁，但规则更新过程耗时且延迟部署，影响了整体安全准备状态。

Method: 提出了FALCON自主代理框架，利用大语言模型从CTI数据实时生成IDS规则，并采用内置多阶段验证器进行评估。框架针对网络型(Snort)和主机型(YARA)两种介质，构建了包含IDS规则和对应CTI的全面数据集。

Result: 评估显示FALCON在自动规则生成方面表现出色，平均准确率达到95%，多位网络安全分析师的定性评估显示在所有指标上达到84%的评分者间一致性。

Conclusion: 研究结果证明了基于大语言模型的数据挖掘在实时网络威胁缓解方面的可行性和有效性，为自主IDS规则生成提供了新的解决方案。

Abstract: Signature-based Intrusion Detection Systems (IDS) detect malicious activities
by matching network or host activity against predefined rules. These rules are
derived from extensive Cyber Threat Intelligence (CTI), which includes attack
signatures and behavioral patterns obtained through automated tools and manual
threat analysis, such as sandboxing. The CTI is then transformed into
actionable rules for the IDS engine, enabling real-time detection and
prevention. However, the constant evolution of cyber threats necessitates
frequent rule updates, which delay deployment time and weaken overall security
readiness. Recent advancements in agentic systems powered by Large Language
Models (LLMs) offer the potential for autonomous IDS rule generation with
internal evaluation. We introduce FALCON, an autonomous agentic framework that
generates deployable IDS rules from CTI data in real-time and evaluates them
using built-in multi-phased validators. To demonstrate versatility, we target
both network (Snort) and host-based (YARA) mediums and construct a
comprehensive dataset of IDS rules with their corresponding CTIs. Our
evaluations indicate FALCON excels in automatic rule generation, with an
average of 95% accuracy validated by qualitative evaluation with 84%
inter-rater agreement among multiple cybersecurity analysts across all metrics.
These results underscore the feasibility and effectiveness of LLM-driven data
mining for real-time cyber threat mitigation.

</details>


### [8] [Immutable Digital Recognition via Blockchain](https://arxiv.org/abs/2508.18750)
*Zeng Zhang,Xiaoqi Li*

Main category: cs.CR

TL;DR: 论文提出了一种整合去中心化管理与集中运营模式的区块链电子认证系统，符合国家政策导向，实现安全可靠的法律认证体系


<details>
  <summary>Details</summary>
Motivation: 为了解决传统电子认证系统的局限性，整合去中心化与集中化管理的优势，同时符合国家政策要求并促进社区参与

Method: 开发了一种整合去中心化管理和集中运营模型的解决方案，充分利用区块链技术优势

Result: 建立了一个安全、合法、可靠且动态的电子认证系统，实现了区块链技术优势的充分利用和社区参与的促进

Conclusion: 该集成方法成功创建了符合国家政策的安全电子认证框架，为区块链技术在认证领域的应用提供了有效解决方案

Abstract: The process integrates the decentralised management and centralised operation
models, aligning them with the national policy directives. The developed
solution enables the full utilisation of blockchain technology's advantages
while also fostering community participation. Consequently, it establishes a
secure, legal, reliable, and dynamic electronic certification system.

</details>


### [9] [Hidden Tail: Adversarial Image Causing Stealthy Resource Consumption in Vision-Language Models](https://arxiv.org/abs/2508.18805)
*Rui Zhang,Zihan Wang,Tianli Yang,Hongwei Li,Wenbo Jiang,Qingchuan Zhao,Yang Liu,Guowen Xu*

Main category: cs.CR

TL;DR: Hidden Tail是一种针对视觉语言模型的隐蔽资源消耗攻击，通过生成对抗图像诱导模型输出最大长度的隐藏特殊标记，在保持攻击隐蔽性的同时显著增加推理成本


<details>
  <summary>Details</summary>
Motivation: 现有视觉语言模型资源消耗攻击存在效果与隐蔽性之间的权衡问题，扩展的输出往往包含异常内容而容易被发现，需要开发更隐蔽的攻击方法

Method: 使用复合损失函数平衡语义保持、重复特殊标记诱导和抑制结束标记，通过动态权重策略优化生成提示无关的对抗图像

Result: 实验显示Hidden Tail将输出长度提升达19.2倍，达到最大标记限制，同时保持攻击隐蔽性，优于现有攻击方法

Conclusion: 该方法揭示了视觉语言模型在效率导向对抗威胁下的脆弱性，迫切需要提高模型对此类攻击的鲁棒性

Abstract: Vision-Language Models (VLMs) are increasingly deployed in real-world
applications, but their high inference cost makes them vulnerable to resource
consumption attacks. Prior attacks attempt to extend VLM output sequences by
optimizing adversarial images, thereby increasing inference costs. However,
these extended outputs often introduce irrelevant abnormal content,
compromising attack stealthiness. This trade-off between effectiveness and
stealthiness poses a major limitation for existing attacks. To address this
challenge, we propose \textit{Hidden Tail}, a stealthy resource consumption
attack that crafts prompt-agnostic adversarial images, inducing VLMs to
generate maximum-length outputs by appending special tokens invisible to users.
Our method employs a composite loss function that balances semantic
preservation, repetitive special token induction, and suppression of the
end-of-sequence (EOS) token, optimized via a dynamic weighting strategy.
Extensive experiments show that \textit{Hidden Tail} outperforms existing
attacks, increasing output length by up to 19.2$\times$ and reaching the
maximum token limit, while preserving attack stealthiness. These results
highlight the urgent need to improve the robustness of VLMs against
efficiency-oriented adversarial threats. Our code is available at
https://github.com/zhangrui4041/Hidden_Tail.

</details>


### [10] [A Tight Context-aware Privacy Bound for Histogram Publication](https://arxiv.org/abs/2508.18832)
*Sara Saeidian,Ata Yavuzyılmaz,Leonhard Grosse,Georg Schuppe,Tobias J. Oechtering*

Main category: cs.CR

TL;DR: 本文通过点wise最大泄漏(PML)分析拉普拉斯机制发布数据集直方图的隐私保证，证明当直方图各bin概率远离零时，固定噪声水平下可获得更强的隐私保护。


<details>
  <summary>Details</summary>
Motivation: 差分隐私是上下文无关的定义，不依赖数据分布。PML能够通过纳入数据分布假设进行更精细的隐私分析，探索如何利用数据分布知识改善隐私-效用权衡。

Method: 使用点wise最大泄漏(PML)作为隐私度量框架，分析拉普拉斯机制在发布直方图时的隐私保证，特别关注各直方图bin概率有下界的情况。

Result: 当每个直方图bin的概率有下界时，对于固定的噪声水平，可以获得比传统差分隐私更强的隐私保护。证明了上下文感知隐私度量的优势。

Conclusion: 纳入数据分布假设可以改善隐私-效用权衡，上下文感知的隐私度量比上下文无关的差分隐私提供更精细的隐私分析，为实际应用中的隐私保护提供了新的视角。

Abstract: We analyze the privacy guarantees of the Laplace mechanism releasing the
histogram of a dataset through the lens of pointwise maximal leakage (PML).
While differential privacy is commonly used to quantify the privacy loss, it is
a context-free definition that does not depend on the data distribution. In
contrast, PML enables a more refined analysis by incorporating assumptions
about the data distribution. We show that when the probability of each
histogram bin is bounded away from zero, stronger privacy protection can be
achieved for a fixed level of noise. Our results demonstrate the advantage of
context-aware privacy measures and show that incorporating assumptions about
the data can improve privacy-utility tradeoffs.

</details>


### [11] [EnerSwap: Large-Scale, Privacy-First Automated Market Maker for V2G Energy Trading](https://arxiv.org/abs/2508.18942)
*Ahmed Mounsf Rafik Bendada,Yacine Ghamri-Doudane*

Main category: cs.CR

TL;DR: 提出基于区块链的去中心化电动汽车V2G电力交易市场，使用隐私保护AMM模型防止市场操纵和隐私泄露，采用地理动态分片实现可扩展架构


<details>
  <summary>Details</summary>
Motivation: 传统集中式V2G电力市场存在中介垄断、市场操纵风险和用户隐私泄露问题，需要去中心化解决方案

Method: 基于区块链技术构建去中心化交易市场，采用隐私保护自动化做市商(AMM)模型，结合地理动态分片实现可扩展性

Result: 实现了开放公平的交易环境，有效缓解常见交易操纵攻击，保护用户隐私信息如能源提供商位置等

Conclusion: 该方案为V2G电力交易提供了安全、隐私保护且可扩展的去中心化市场框架，解决了集中式模式的弊端

Abstract: With the rapid growth of Electric Vehicle (EV) technology, EVs are destined
to shape the future of transportation. The large number of EVs facilitates the
development of the emerging vehicle-to-grid (V2G) technology, which realizes
bidirectional energy exchanges between EVs and the power grid. This has led to
the setting up of electricity markets that are usually confined to a small
geographical location, often with a small number of participants. Usually,
these markets are manipulated by intermediaries responsible for collecting bids
from prosumers, determining the market-clearing price, incorporating grid
constraints, and accounting for network losses. While centralized models can be
highly efficient, they grant excessive power to the intermediary by allowing
them to gain exclusive access to prosumers \textquotesingle price preferences.
This opens the door to potential market manipulation and raises significant
privacy concerns for users, such as the location of energy providers. This lack
of protection exposes users to potential risks, as untrustworthy servers and
malicious adversaries can exploit this information to infer trading activities
and real identities. This work proposes a secure, decentralized exchange market
built on blockchain technology, utilizing a privacy-preserving Automated Market
Maker (AMM) model to offer open and fair, and equal access to traders, and
mitigates the most common trading-manipulation attacks. Additionally, it
incorporates a scalable architecture based on geographical dynamic sharding,
allowing for efficient resource allocation and improved performance as the
market grows.

</details>


### [12] [LLMs in the SOC: An Empirical Study of Human-AI Collaboration in Security Operations Centres](https://arxiv.org/abs/2508.18947)
*Ronal Singh,Shahroz Tariq,Fatemeh Jalalvand,Mohan Baruwal Chhetri,Surya Nepal,Cecile Paris,Martin Lochner*

Main category: cs.CR

TL;DR: 大型语言模型在安全运营中心主要作为按需认知辅助工具，用于感知构建和技术沟通，而非高风险决策，分析师保留最终决策权。


<details>
  <summary>Details</summary>
Motivation: 探索LLMs在真实SOC环境中的实际应用情况，填补现有研究中缺乏对分析师与LLMs协作的实证研究空白。

Method: 对45名SOC分析师在10个月内的3,090个查询进行纵向研究分析，使用NICE框架评估查询相关性。

Result: 93%的查询与网络安全能力标准相符，分析师主要将LLMs用于解释低级遥测数据和精炼技术沟通，通过简短交互（1-3轮）完成。使用趋势显示从偶尔探索转向常规集成。

Conclusion: LLMs作为灵活的按需认知辅助工具增强而非替代SOC专业知识，研究为设计情境感知、以人为本的AI辅助提供了实用指导，强调需要更多真实环境中的研究。

Abstract: The integration of Large Language Models (LLMs) into Security Operations
Centres (SOCs) presents a transformative, yet still evolving, opportunity to
reduce analyst workload through human-AI collaboration. However, their
real-world application in SOCs remains underexplored. To address this gap, we
present a longitudinal study of 3,090 analyst queries from 45 SOC analysts over
10 months. Our analysis reveals that analysts use LLMs as on-demand aids for
sensemaking and context-building, rather than for making high-stakes
determinations, preserving analyst decision authority. The majority of queries
are related to interpreting low-level telemetry (e.g., commands) and refining
technical communication through short (1-3 turn) interactions. Notably, 93% of
queries align with established cybersecurity competencies (NICE Framework),
underscoring the relevance of LLM use for SOC-related tasks. Despite variations
in tasks and engagement, usage trends indicate a shift from occasional
exploration to routine integration, with growing adoption and sustained use
among a subset of analysts. We find that LLMs function as flexible, on-demand
cognitive aids that augment, rather than replace, SOC expertise. Our study
provides actionable guidance for designing context-aware, human-centred AI
assistance in security operations, highlighting the need for further
in-the-wild research on real-world analyst-LLM collaboration, challenges, and
impacts.

</details>


### [13] [The Double-edged Sword of LLM-based Data Reconstruction: Understanding and Mitigating Contextual Vulnerability in Word-level Differential Privacy Text Sanitization](https://arxiv.org/abs/2508.18976)
*Stephen Meisenbacher,Alexandra Klymenko,Andreea-Elena Bodea,Florian Matthes*

Main category: cs.CR

TL;DR: 本文研究LLM如何利用差分隐私文本脱敏中的上下文漏洞进行数据重建攻击，发现LLM既能推断原始语义降低隐私保护，也能用于提升脱敏文本质量和隐私保护


<details>
  <summary>Details</summary>
Motivation: 探索大型语言模型(LLM)在多大程度上可以利用差分隐私文本脱敏方法中的上下文漏洞，这些方法在词级别操作时容易因随机化而留下原始文本的上下文线索

Method: 使用先进的LLM测试更广泛的脱敏机制在不同隐私级别下的表现，进行数据重建攻击实验

Result: 发现LLM数据重建攻击具有双刃剑效应：既能推断原始语义降低实证隐私保护，也能用于改善DP脱敏文本的质量和隐私

Conclusion: 建议将LLM数据重建作为后处理步骤，通过对抗性思维来增强隐私保护

Abstract: Differentially private text sanitization refers to the process of privatizing
texts under the framework of Differential Privacy (DP), providing provable
privacy guarantees while also empirically defending against adversaries seeking
to harm privacy. Despite their simplicity, DP text sanitization methods
operating at the word level exhibit a number of shortcomings, among them the
tendency to leave contextual clues from the original texts due to randomization
during sanitization $\unicode{x2013}$ this we refer to as $\textit{contextual
vulnerability}$. Given the powerful contextual understanding and inference
capabilities of Large Language Models (LLMs), we explore to what extent LLMs
can be leveraged to exploit the contextual vulnerability of DP-sanitized texts.
We expand on previous work not only in the use of advanced LLMs, but also in
testing a broader range of sanitization mechanisms at various privacy levels.
Our experiments uncover a double-edged sword effect of LLM-based data
reconstruction attacks on privacy and utility: while LLMs can indeed infer
original semantics and sometimes degrade empirical privacy protections, they
can also be used for good, to improve the quality and privacy of DP-sanitized
texts. Based on our findings, we propose recommendations for using LLM data
reconstruction as a post-processing step, serving to increase privacy
protection by thinking adversarially.

</details>


### [14] [Attackers Strike Back? Not Anymore -- An Ensemble of RL Defenders Awakens for APT Detection](https://arxiv.org/abs/2508.19072)
*Sidahmed Benabderrahmane,Talal Rahwan*

Main category: cs.CR

TL;DR: 提出了一种结合深度学习、强化学习和主动学习的新型APT检测框架，通过多智能体集成和主动学习机制来应对高级持续性威胁的隐蔽性和适应性。


<details>
  <summary>Details</summary>
Motivation: 传统基于签名的检测系统无法有效应对APT攻击的隐蔽性、适应性和持久性特点，现有检测系统缺乏动态适应能力，需要开发能够持续学习和进化的防御机制。

Method: 使用自编码器进行潜在行为编码，构建多智能体强化学习防御系统（包括Q-Learning、PPO、DQN等算法），结合主动学习机制在不确定时模拟专家反馈，采用加权集成投票机制进行最终预测。

Result: 开发了一个统一的、自适应的防御系统框架，能够通过多智能体协作和主动学习来动态适应不断演变的攻击策略，提高检测准确性和鲁棒性。

Conclusion: 该框架为解决APT检测中的静态性和适应性不足问题提供了有效方案，通过深度学习和强化学习的结合，实现了对隐蔽威胁的持续学习和进化防御能力。

Abstract: Advanced Persistent Threats (APTs) represent a growing menace to modern
digital infrastructure. Unlike traditional cyberattacks, APTs are stealthy,
adaptive, and long-lasting, often bypassing signature-based detection systems.
This paper introduces a novel framework for APT detection that unites deep
learning, reinforcement learning (RL), and active learning into a cohesive,
adaptive defense system. Our system combines auto-encoders for latent
behavioral encoding with a multi-agent ensemble of RL-based defenders, each
trained to distinguish between benign and malicious process behaviors. We
identify a critical challenge in existing detection systems: their static
nature and inability to adapt to evolving attack strategies. To this end, our
architecture includes multiple RL agents (Q-Learning, PPO, DQN, adversarial
defenders), each analyzing latent vectors generated by an auto-encoder. When
any agent is uncertain about its decision, the system triggers an active
learning loop to simulate expert feedback, thus refining decision boundaries.
An ensemble voting mechanism, weighted by each agent's performance, ensures
robust final predictions.

</details>


### [15] [SecureV2X: An Efficient and Privacy-Preserving System for Vehicle-to-Everything (V2X) Applications](https://arxiv.org/abs/2508.19115)
*Joshua Lee,Ali Arastehfard,Weiran Liu,Xuegang Ban,Yuan Hong*

Main category: cs.CR

TL;DR: SecureV2X是一个可扩展的多代理系统，用于车辆与服务器之间的安全神经网络推理，解决了V2X系统中机器学习应用的隐私问题，在性能上显著优于现有安全系统。


<details>
  <summary>Details</summary>
Motivation: V2X系统中广泛使用机器学习技术会引发数据隐私问题，特别是智能交通和驾驶员安全应用可能泄露用户位置或医疗数据（如EEG信号），需要保护这些敏感信息。

Method: 提出SecureV2X系统，采用多代理架构在服务器和车辆之间部署安全神经网络推理，研究两种V2X应用：安全疲劳驾驶检测和安全闯红灯检测。

Result: 系统性能显著优于基线方法：疲劳驾驶检测速度快9.4倍，计算轮次减少143倍，通信量减少16.6倍；闯红灯检测运行时比最先进基准快近100倍。

Conclusion: SecureV2X系统有效解决了V2X系统中的隐私保护问题，具有出色的可扩展性和性能表现，能够同时支持大量安全计算交互。

Abstract: Autonomous driving and V2X technologies have developed rapidly in the past
decade, leading to improved safety and efficiency in modern transportation.
These systems interact with extensive networks of vehicles, roadside
infrastructure, and cloud resources to support their machine learning
capabilities. However, the widespread use of machine learning in V2X systems
raises issues over the privacy of the data involved. This is particularly
concerning for smart-transit and driver safety applications which can
implicitly reveal user locations or explicitly disclose medical data such as
EEG signals. To resolve these issues, we propose SecureV2X, a scalable,
multi-agent system for secure neural network inferences deployed between the
server and each vehicle. Under this setting, we study two multi-agent V2X
applications: secure drowsiness detection, and secure red-light violation
detection. Our system achieves strong performance relative to baselines, and
scales efficiently to support a large number of secure computation interactions
simultaneously. For instance, SecureV2X is $9.4 \times$ faster, requires
$143\times$ fewer computational rounds, and involves $16.6\times$ less
communication on drowsiness detection compared to other secure systems.
Moreover, it achieves a runtime nearly $100\times$ faster than state-of-the-art
benchmarks in object detection tasks for red light violation detection.

</details>


### [16] [An Efficient Lightweight Blockchain for Decentralized IoT](https://arxiv.org/abs/2508.19219)
*Faezeh Dehghan Tarzjani,Mostafa Salehi*

Main category: cs.CR

TL;DR: 这篇论文提出了一种基于权重选择方法的新型PoA共识机制，用于解决物联网中传统区块链共识算法资源消耗过大的问题。


<details>
  <summary>Details</summary>
Motivation: 物联网设备资源有限，传统PoW和PoS等共识算法计算成本过高，而现有PoA中的轮询选择方法在系统可靠性、能消耗、延迟和可扩展性方面存在不足。

Method: 提出使用虚拟化和聚类技术的轻量级区块链解决方案，并引入基于权重选择方法的新型PoA共识机制，用于选择验证节点验证交易。

Result: 通过模拟对比实验，新的WBS方法与传统TBS相比，能够降低能消耗、减少响应时间，同时提高了系统吞吐量。

Conclusion: 该研究为物联网提供了一种高效、轻量级的区块链解决方案，通过权重选择方法改善了PoA共识机制的性能表现。

Abstract: The Internet of Things (IoT) is applied in various fields, and the number of
physical devices connected to the IoT is increasingly growing. There are
significant challenges to the IoT's growth and development, mainly due to the
centralized nature and large-scale IoT networks. The emphasis on the
decentralization of IoT's architecture can overcome challenges to IoT's
capabilities. A promising decentralized platform for IoT is blockchain. Owing
to IoT devices' limited resources, traditional consensus algorithms such as PoW
and PoS in the blockchain are computationally expensive. Therefore, the PoA
consensus algorithm is proposed in the blockchain consensus network for IoT.
The PoA selects the validator as Turn-based selection (TBS) that needs
optimization and faces system reliability, energy consumption, latency, and low
scalability. We propose an efficient, lightweight blockchain for decentralizing
IoT architecture by using virtualization and clustering to increase
productivity and scalability to address these issues. We also introduce a novel
PoA based on the Weight-Based-Selection (WBS) method for validators to validate
transactions and add them to the blockchain. By simulation, we evaluated the
performance of our proposed WBS method as opposed to TBS. The results show
reduced energy consumption, and response time, and increased throughput.

</details>
