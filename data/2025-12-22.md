<div id=toc></div>

# Table of Contents

- [cs.CR](#cs.CR) [Total: 18]


<div id='cs.CR'></div>

# cs.CR [[Back]](#toc)

### [1] [CAPIO: Safe Kernel-Bypass of Commodity Devices using Capabilities](https://arxiv.org/abs/2512.16957)
*Friedrich Doku,Jonathan Laughton,Nick Wanninger,Peter Dinda*

Main category: cs.CR

TL;DR: CAPIO利用硬件能力架构实现细粒度内存映射I/O访问控制，解决内核旁路安全性与性能的权衡问题


<details>
  <summary>Details</summary>
Motivation: 传统系统在低延迟I/O上面临两难选择：要么使用高开销的内核接口，要么完全绕过内核但暴露敏感硬件资源。现有MMU基于页面的保护机制无法保护同一页面内的敏感控制寄存器。

Method: 基于CHERI硬件能力架构，在ARM Morello平台上实现CAPIO，利用不可伪造的能力创建精确的子页面"切片"来保护设备内存，实现字节级访问控制。

Result: 在未为内核旁路设计的商用网卡上实现了安全访问驱动程序，证明CAPIO既能获得内核旁路的延迟改进，又能对特权资源实施字节级访问控制。

Conclusion: CAPIO首次利用硬件能力架构实现了细粒度内存映射I/O访问控制，解决了内核旁路安全性与性能的根本权衡问题。

Abstract: Securing low-latency I/O in commodity systems forces a fundamental trade-off: rely on the kernel's high overhead mediated interface, or bypass it entirely, exposing sensitive hardware resources to userspace and creating new vulnerabilities. This dilemma stems from a hardware granularity mismatch: standard MMUs operate at page boundaries, making it impossible to selectively expose safe device registers without also exposing the sensitive control registers colocated on the same page. Existing solutions to driver isolation enforce an isolation model that cannot protect sub-page device resources.
  This paper presents CAPIO, the first architecture to leverage hardware capabilities to enforce fine-grained access control on memory-mapped I/O. Unlike prior page-based protections, CAPIO utilizes unforgeable capabilities to create precise, sub-page "slices" of device memory. This mechanism enables the kernel to delegate latency-critical hardware access to userspace applications while strictly preventing interaction with co-located privileged registers.
  We implement CAPIO based on CHERI on the ARM Morello platform and demonstrate a proof-of-concept safe-access driver for a commodity network card which was not originally designed for kernel bypass. We demonstrate that CAPIO achieves the latency improvements of kernel bypass while enforcing byte-level access control of privileged resources.

</details>


### [2] [MemoryGraft: Persistent Compromise of LLM Agents via Poisoned Experience Retrieval](https://arxiv.org/abs/2512.16962)
*Saksham Sahai Srivastava,Haoyu He*

Main category: cs.CR

TL;DR: 提出MemoryGraft攻击方法，通过向LLM智能体长期记忆中植入恶意成功经验，利用语义模仿启发式诱导智能体在后续任务中复制不安全模式，实现持久行为偏移


<details>
  <summary>Details</summary>
Motivation: LLM智能体依赖长期记忆和RAG来积累经验并改进未来表现，但这种经验学习能力引入了一个关键且未被探索的攻击面：智能体推理核心与其自身过去之间的信任边界。传统即时越狱攻击是瞬时的，标准RAG中毒针对事实知识，而智能体语义模仿启发式（倾向于复制检索到的成功任务模式）可能被利用

Method: 提出MemoryGraft间接注入攻击：攻击者提供良性摄入级工件，智能体在执行过程中读取这些工件，诱导其构建中毒的RAG存储，将少量恶意程序模板与良性经验一起持久化。当智能体后来遇到语义相似任务时，通过词法和嵌入相似性的联合检索可靠地浮现这些嫁接记忆，智能体采用嵌入的不安全模式

Result: 在MetaGPT的DataInterpreter智能体（使用GPT-4o）上验证MemoryGraft，发现少量中毒记录可以在良性工作负载中占据检索经验的大部分比例，将基于经验的自我改进转变为隐秘且持久的妥协向量

Conclusion: MemoryGraft揭示了LLM智能体经验学习机制中的新攻击面，通过利用语义模仿启发式实现持久行为中毒。这种攻击比传统方法更隐蔽和持久，需要重新思考智能体记忆系统的安全边界

Abstract: Large Language Model (LLM) agents increasingly rely on long-term memory and Retrieval-Augmented Generation (RAG) to persist experiences and refine future performance. While this experience learning capability enhances agentic autonomy, it introduces a critical, unexplored attack surface, i.e., the trust boundary between an agent's reasoning core and its own past. In this paper, we introduce MemoryGraft. It is a novel indirect injection attack that compromises agent behavior not through immediate jailbreaks, but by implanting malicious successful experiences into the agent's long-term memory. Unlike traditional prompt injections that are transient, or standard RAG poisoning that targets factual knowledge, MemoryGraft exploits the agent's semantic imitation heuristic which is the tendency to replicate patterns from retrieved successful tasks. We demonstrate that an attacker who can supply benign ingestion-level artifacts that the agent reads during execution can induce it to construct a poisoned RAG store where a small set of malicious procedure templates is persisted alongside benign experiences. When the agent later encounters semantically similar tasks, union retrieval over lexical and embedding similarity reliably surfaces these grafted memories, and the agent adopts the embedded unsafe patterns, leading to persistent behavioral drift across sessions. We validate MemoryGraft on MetaGPT's DataInterpreter agent with GPT-4o and find that a small number of poisoned records can account for a large fraction of retrieved experiences on benign workloads, turning experience-based self-improvement into a vector for stealthy and durable compromise. To facilitate reproducibility and future research, our code and evaluation data are available at https://github.com/Jacobhhy/Agent-Memory-Poisoning.

</details>


### [3] [AutoDFBench 1.0: A Benchmarking Framework for Digital Forensic Tool Testing and Generated Code Evaluation](https://arxiv.org/abs/2512.16965)
*Akila Wickramasekara,Tharusha Mihiranga,Aruna Withanage,Buddhima Weerasinghe,Frank Breitinger,John Sheppard,Mark Scanlon*

Main category: cs.CR

TL;DR: AutoDFBench 1.0：首个统一、自动化、可扩展的数字取证工具测试基准框架，支持传统工具、脚本及AI生成代码的评估，解决CFTT项目缺乏自动化基准测试的问题。


<details>
  <summary>Details</summary>
Motivation: NIST CFTT项目已成为数字取证工具测试的事实标准，但缺乏自动化基准测试框架，导致验证不一致、工具比较困难、验证可重复性有限。

Method: 开发模块化基准测试框架AutoDFBench 1.0，集成CFTT定义的五个领域：字符串搜索、已删除文件恢复、文件雕刻、Windows注册表恢复和SQLite数据恢复。包含63个测试用例和10,968个独特测试场景的真实数据，通过RESTful API执行评估，生成包含精确率、召回率和F1分数的结构化JSON输出。

Result: 框架使用CFTT数据集进行验证，提供标准化指标（精确率、召回率、F1分数），平均F1分数构成AutoDFBench分数。建立了首个统一、自动化、可扩展的数字取证工具测试基准框架。

Conclusion: AutoDFBench 1.0实现了公平、可重复的工具比较，支持工具供应商、研究人员、从业者和标准化机构，促进数字取证技术的透明、可重复和可比较评估。

Abstract: The National Institute of Standards and Technology (NIST) Computer Forensic Tool Testing (CFTT) programme has become the de facto standard for providing digital forensic tool testing and validation. However to date, no comprehensive framework exists to automate benchmarking across the diverse forensic tasks included in the programme. This gap results in inconsistent validation, challenges in comparing tools, and limited validation reproducibility. This paper introduces AutoDFBench 1.0, a modular benchmarking framework that supports the evaluation of both conventional DF tools and scripts, as well as AI-generated code and agentic approaches. The framework integrates five areas defined by the CFTT programme: string search, deleted file recovery, file carving, Windows registry recovery, and SQLite data recovery. AutoDFBench 1.0 includes ground truth data comprising of 63 test cases and 10,968 unique test scenarios, and execute evaluations through a RESTful API that produces structured JSON outputs with standardised metrics, including precision, recall, and F1~score for each test case, and the average of these F1~scores becomes the AutoDFBench Score. The benchmarking framework is validated against CFTT's datasets. The framework enables fair and reproducible comparison across tools and forensic scripts, establishing the first unified, automated, and extensible benchmarking framework for digital forensic tool testing and validation. AutoDFBench 1.0 supports tool vendors, researchers, practitioners, and standardisation bodies by facilitating transparent, reproducible, and comparable assessments of DF technologies.

</details>


### [4] [Adversarial VR: An Open-Source Testbed for Evaluating Adversarial Robustness of VR Cybersickness Detection and Mitigation](https://arxiv.org/abs/2512.17029)
*Istiak Ahmed,Ripan Kumar Kundu,Khaza Anuarul Hoque*

Main category: cs.CR

TL;DR: 该论文提出了Adversarial-VR测试平台，用于评估对抗攻击下基于深度学习的晕动症检测与缓解系统的鲁棒性。


<details>
  <summary>Details</summary>
Motivation: 现有基于深度学习的晕动症检测系统易受对抗攻击影响，缺乏专门的开放测试平台来评估这些系统在对抗条件下的鲁棒性，限制了其实际应用效果评估。

Method: 在Unity中开发Adversarial-VR实时VR测试平台，集成DeepTCN和Transformer两种SOTA深度学习模型进行晕动症严重程度检测，采用动态视觉隧道机制调整视野范围，并引入MI-FGSM、PGD和C&W三种对抗攻击来测试系统鲁棒性。

Result: 对抗攻击成功欺骗了晕动症检测系统，其中C&W攻击使基于Transformer的晕动症模型准确率相比无攻击时降低了5.94倍。

Conclusion: Adversarial-VR测试平台有效揭示了基于深度学习的晕动症检测系统在对抗攻击下的脆弱性，为VR开发者和研究人员提供了评估系统鲁棒性的工具，并开源实现以促进广泛采用。

Abstract: Deep learning (DL)-based automated cybersickness detection methods, along with adaptive mitigation techniques, can enhance user comfort and interaction. However, recent studies show that these DL-based systems are susceptible to adversarial attacks; small perturbations to sensor inputs can degrade model performance, trigger incorrect mitigation, and disrupt the user's immersive experience (UIX). Additionally, there is a lack of dedicated open-source testbeds that evaluate the robustness of these systems under adversarial conditions, limiting the ability to assess their real-world effectiveness. To address this gap, this paper introduces Adversarial-VR, a novel real-time VR testbed for evaluating DL-based cybersickness detection and mitigation strategies under adversarial conditions. Developed in Unity, the testbed integrates two state-of-the-art (SOTA) DL models: DeepTCN and Transformer, which are trained on the open-source MazeSick dataset, for real-time cybersickness severity detection and applies a dynamic visual tunneling mechanism that adjusts the field-of-view based on model outputs. To assess robustness, we incorporate three SOTA adversarial attacks: MI-FGSM, PGD, and C&W, which successfully prevent cybersickness mitigation by fooling DL-based cybersickness models' outcomes. We implement these attacks using a testbed with a custom-built VR Maze simulation and an HTC Vive Pro Eye headset, and we open-source our implementation for widespread adoption by VR developers and researchers. Results show that these adversarial attacks are capable of successfully fooling the system. For instance, the C&W attack results in a $5.94x decrease in accuracy for the Transformer-based cybersickness model compared to the accuracy without the attack.

</details>


### [5] [Sedna: Sharding transactions in multiple concurrent proposer blockchains](https://arxiv.org/abs/2512.17045)
*Alejandro Ranchal-Pedrosa,Benjamin Marsh,Lefteris Kokoris-Kogias,Alberto Sonnino*

Main category: cs.CR

TL;DR: Sedna是一个面向用户的协议，使用可验证的无速率编码替代简单的交易复制，在保证活性和隐私的同时，将带宽开销降低2-3倍，无需修改共识机制。


<details>
  <summary>Details</summary>
Motivation: 当前多提议者共识中，用户要么向多个提议者复制完整交易（牺牲吞吐量并暴露MEV风险），要么只向少数提议者发送（面临审查风险和延迟问题），形成了审查抵抗、低延迟和合理成本之间的三难困境。

Method: Sedna使用可验证的无速率编码技术，用户将编址的符号包私下发送给提议者子集，一旦收集到足够符号解码，交易按确定顺序执行。协议保证活性和"解码前隐私"，显著减少MEV暴露。

Result: 协议接近信息论下限的带宽开销，相比简单复制实现2-3倍的效率提升。Sedna无需修改共识机制，支持渐进部署。

Conclusion: Sedna通过编码技术解决了多提议者区块链中的交易传播三难困境，在保持审查抵抗和低延迟的同时，显著降低了带宽成本并增强了隐私保护。

Abstract: Modern blockchains increasingly adopt multi-proposer (MCP) consensus to remove single-leader bottlenecks and improve censorship resistance. However, MCP alone does not resolve how users should disseminate transactions to proposers. Today, users either naively replicate full transactions to many proposers, sacrificing goodput and exposing payloads to MEV, or target few proposers and accept weak censorship and latency guarantees. This yields a practical trilemma among censorship resistance, low latency, and reasonable cost (in fees or system goodput).
  We present Sedna, a user-facing protocol that replaces naive transaction replication with verifiable, rateless coding. Users privately deliver addressed symbol bundles to subsets of proposers; execution follows a deterministic order once enough symbols are finalized to decode. We prove Sedna guarantees liveness and \emph{until-decode privacy}, significantly reducing MEV exposure. Analytically, the protocol approaches the information-theoretic lower bound for bandwidth overhead, yielding a 2-3x efficiency improvement over naive replication. Sedna requires no consensus modifications, enabling incremental deployment.

</details>


### [6] [Biosecurity-Aware AI: Agentic Risk Auditing of Soft Prompt Attacks on ESM-Based Variant Predictors](https://arxiv.org/abs/2512.17146)
*Huixin Zhan*

Main category: cs.CR

TL;DR: SAGE框架用于审计基因组基础模型的对抗性漏洞，发现即使最先进的ESM2模型也对软提示攻击敏感，导致性能下降。


<details>
  <summary>Details</summary>
Motivation: 基因组基础模型（如ESM）在变异效应预测方面取得了显著成功，但其在对抗性操纵下的安全性和鲁棒性尚未得到充分探索。

Method: 提出SAGE（安全代理基因组评估器）框架，通过可解释的自动化风险审计循环：注入软提示扰动、监控模型行为、计算风险指标（AUROC、AUPR）、生成结构化报告和基于大语言模型的叙述性解释。

Result: 发现即使是ESM2这样的最先进基因组基础模型也对目标软提示攻击敏感，导致可测量的性能下降，揭示了基因组基础模型中先前隐藏的关键漏洞。

Conclusion: 基因组基础模型存在对抗性脆弱性，代理风险审计对于保护临床变异解释等生物医学应用的安全至关重要。

Abstract: Genomic Foundation Models (GFMs), such as Evolutionary Scale Modeling (ESM), have demonstrated remarkable success in variant effect prediction. However, their security and robustness under adversarial manipulation remain largely unexplored. To address this gap, we introduce the Secure Agentic Genomic Evaluator (SAGE), an agentic framework for auditing the adversarial vulnerabilities of GFMs. SAGE functions through an interpretable and automated risk auditing loop. It injects soft prompt perturbations, monitors model behavior across training checkpoints, computes risk metrics such as AUROC and AUPR, and generates structured reports with large language model-based narrative explanations. This agentic process enables continuous evaluation of embedding-space robustness without modifying the underlying model. Using SAGE, we find that even state-of-the-art GFMs like ESM2 are sensitive to targeted soft prompt attacks, resulting in measurable performance degradation. These findings reveal critical and previously hidden vulnerabilities in genomic foundation models, showing the importance of agentic risk auditing in securing biomedical applications such as clinical variant interpretation.

</details>


### [7] [AlignDP: Hybrid Differential Privacy with Rarity-Aware Protection for LLMs](https://arxiv.org/abs/2512.17251)
*Madhava Gaikwad*

Main category: cs.CR

TL;DR: AlignDP是一种混合隐私锁，通过分离稀有和非稀有字段，在数据接口处阻止知识转移。稀有字段使用PAC不可区分性保护，非稀有字段使用RAPPOR本地差分隐私，全局聚合器管理组合和预算。


<details>
  <summary>Details</summary>
Motivation: 大型语言模型面临提取、蒸馏和未经授权的微调风险。现有防御方法（如水印或监控）在泄露后起作用，需要一种在数据接口处阻止知识转移的主动防御机制。

Method: 设计两层级隐私保护：1) 稀有字段使用PAC不可区分性保护，实现有效的零epsilon本地差分隐私；2) 非稀有字段使用RAPPOR本地差分隐私，提供无偏频率估计；3) 全局聚合器管理组合和预算。

Result: 证明了PAC扩展到全局聚合的局限性，给出了RAPPOR估计的界限，分析了效用权衡。玩具模拟验证了可行性：稀有类别保持隐藏，频繁类别能以小误差恢复。

Conclusion: AlignDP提供了一种在数据接口处阻止知识转移的有效混合隐私保护方法，通过分离处理稀有和非稀有字段，在保护隐私的同时保持数据实用性。

Abstract: Large language models are exposed to risks of extraction, distillation, and unauthorized fine-tuning. Existing defenses use watermarking or monitoring, but these act after leakage. We design AlignDP, a hybrid privacy lock that blocks knowledge transfer at the data interface. The key idea is to separate rare and non-rare fields. Rare fields are shielded by PAC indistinguishability, giving effective zero-epsilon local DP. Non-rare fields are privatized with RAPPOR, giving unbiased frequency estimates under local DP. A global aggregator enforces composition and budget. This two-tier design hides rare events and adds controlled noise to frequent events. We prove limits of PAC extension to global aggregation, give bounds for RAPPOR estimates, and analyze utility trade-off. A toy simulation confirms feasibility: rare categories remain hidden, frequent categories are recovered with small error.

</details>


### [8] [Practical Framework for Privacy-Preserving and Byzantine-robust Federated Learning](https://arxiv.org/abs/2512.17254)
*Baolei Zhang,Minghong Fang,Zhuqing Liu,Biao Yi,Peizhao Zhou,Yuan Wang,Tong Li,Zheli Liu*

Main category: cs.CR

TL;DR: ABBR是一个实用的联邦学习框架，通过维度减少加速隐私计算，同时防御拜占庭攻击和隐私推理攻击，在保持安全性的同时显著降低计算和通信开销。


<details>
  <summary>Details</summary>
Motivation: 联邦学习面临拜占庭攻击和隐私推理攻击的双重威胁，现有防御方法计算和通信开销过大，理论与实践存在差距，需要更实用的解决方案。

Method: 提出ABBR框架：1）首次利用维度减少技术加速隐私计算中的复杂过滤规则；2）分析低维空间向量过滤的精度损失；3）引入自适应调优策略最小化绕过过滤的恶意模型对全局模型的影响。

Result: 在公开数据集上的评估显示：ABBR运行速度显著更快，通信开销最小，同时保持与基线方法几乎相同的拜占庭攻击防御能力。

Conclusion: ABBR是一个实用的联邦学习框架，有效解决了拜占庭攻击和隐私推理攻击的防御问题，在保持安全性的同时大幅降低了计算和通信开销，弥合了理论与实践的差距。

Abstract: Federated Learning (FL) allows multiple clients to collaboratively train a model without sharing their private data. However, FL is vulnerable to Byzantine attacks, where adversaries manipulate client models to compromise the federated model, and privacy inference attacks, where adversaries exploit client models to infer private data. Existing defenses against both backdoor and privacy inference attacks introduce significant computational and communication overhead, creating a gap between theory and practice. To address this, we propose ABBR, a practical framework for Byzantine-robust and privacy-preserving FL. We are the first to utilize dimensionality reduction to speed up the private computation of complex filtering rules in privacy-preserving FL. Additionally, we analyze the accuracy loss of vector-wise filtering in low-dimensional space and introduce an adaptive tuning strategy to minimize the impact of malicious models that bypass filtering on the global model. We implement ABBR with state-of-the-art Byzantine-robust aggregation rules and evaluate it on public datasets, showing that it runs significantly faster, has minimal communication overhead, and maintains nearly the same Byzantine-resilience as the baselines.

</details>


### [9] [An Iconic Heavy Hitter Algorithm Made Private](https://arxiv.org/abs/2512.17295)
*Rayne Holland*

Main category: cs.CR

TL;DR: 提出了首个满足差分隐私的SpaceSaving算法变体，以及从任意差分隐私频率预言机中提取频繁项的通⽤⽅法，在保持SpaceSaving实践优势的同时提供强隐私保证。


<details>
  <summary>Details</summary>
Motivation: 数据流中的频繁项识别是分析系统的基础问题，但数据流常来自敏感用户活动，需要更新级别的隐私保护。现有工作主要基于Misra-Gries算法，但实践中SpaceSaving算法具有更好的效用，缺乏其隐私化版本。

Method: 1) 对非隐私的SpaceSaving摘要进行后处理，注入渐近最优噪声并应用精心校准的选择规则抑制不稳定标签；2) 提出通用方法从任意差分隐私频率预言机中提取频繁项，仅需O(k)额外内存，提供安全释放项标识的机制。

Result: 在合成和真实数据集上的实验表明，在广泛的隐私参数和空间预算下，该方法比现有的差分隐私Misra-Gries算法具有更优的效用，SpaceSaving的经验优势在隐私化后得以保留。

Conclusion: SpaceSaving算法的经验优势在差分隐私下依然存在，能够在强差分隐私保证下实现高效、实用的频繁项识别，为隐私保护数据流分析提供了更好的解决方案。

Abstract: Identifying heavy hitters in data streams is a fundamental problem with widespread applications in modern analytics systems. These streams are often derived from sensitive user activity, making update-level privacy guarantees necessary. While recent work has adapted the classical heavy hitter algorithm Misra-Gries to satisfy differential privacy in the streaming model, the privatization of other heavy hitter algorithms with better empirical utility is absent.
  Under this observation, we present the first differentially private variant of the SpaceSaving algorithm, which, in the non-private setting, is regarded as the state-of-the-art in practice. Our construction post-processes a non-private SpaceSaving summary by injecting asymptotically optimal noise and applying a carefully calibrated selection rule that suppresses unstable labels. This yields strong privacy guarantees while preserving the empirical advantages of SpaceSaving.
  Second, we introduce a generic method for extracting heavy hitters from any differentially private frequency oracle in the data stream model. The method requires only O(k) additional memory, where k is the number of heavy items, and provides a mechanism for safely releasing item identities from noisy frequency estimates. This yields an efficient, plug-and-play approach for private heavy hitter recovery from linear sketches.
  Finally, we conduct an experimental evaluation on synthetic and real-world datasets. Across a wide range of privacy parameters and space budgets, our method provides superior utility to the existing differentially private Misra-Gries algorithm. Our results demonstrate that the empirical superiority of SpaceSaving survives privatization and that efficient, practical heavy hitter identification is achievable under strong differential privacy guarantees.

</details>


### [10] [Cryptanalysis of Pseudorandom Error-Correcting Codes](https://arxiv.org/abs/2512.17310)
*Tianrui Wang,Anyu Wang,Tianshuo Cong,Delong Ran,Jinyuan Liu,Xiaoyun Wang*

Main category: cs.CR

TL;DR: 本文首次对PRC（伪随机纠错码）进行密码分析，提出三种攻击方法破坏其不可检测性和鲁棒性假设，并在真实大模型上验证攻击有效性，同时提出防御建议。


<details>
  <summary>Details</summary>
Motivation: PRC作为CRYPTO 2024提出的新型密码原语，具有伪随机性和纠错双重能力，被认为是AI生成内容水印的有前景基础组件。然而其安全性尚未得到充分分析，特别是在具体参数和密码攻击面前存在安全空白。

Method: 提出三种攻击方法：两种针对PRC码字与普通向量的区分攻击，一种针对PRC解码过程的攻击。在DeepSeek和Stable Diffusion等真实大模型上验证攻击有效性。同时提出三种防御措施：参数建议、实现建议和修订密钥生成算法。

Result: 攻击成功破坏了所有参数配置下的PRC安全保证，能以2^22次操作的高概率检测水印存在。修订密钥生成函数能有效防止弱密钥出现，但当前基于PRC的水印方案仍无法在建议参数下达到128位安全级别。

Conclusion: 首次对PRC进行系统密码分析，揭示其安全缺陷，提出的攻击方法有效且实用。虽然防御建议能提升安全性，但受限于大模型固有配置（如最大输出长度），PRC水印方案仍需进一步改进才能达到高标准安全要求。

Abstract: Pseudorandom error-correcting codes (PRC) is a novel cryptographic primitive proposed at CRYPTO 2024. Due to the dual capability of pseudorandomness and error correction, PRC has been recognized as a promising foundational component for watermarking AI-generated content. However, the security of PRC has not been thoroughly analyzed, especially with concrete parameters or even in the face of cryptographic attacks. To fill this gap, we present the first cryptanalysis of PRC. We first propose three attacks to challenge the undetectability and robustness assumptions of PRC. Among them, two attacks aim to distinguish PRC-based codewords from plain vectors, and one attack aims to compromise the decoding process of PRC. Our attacks successfully undermine the claimed security guarantees across all parameter configurations. Notably, our attack can detect the presence of a watermark with overwhelming probability at a cost of $2^{22}$ operations. We also validate our approach by attacking real-world large generative models such as DeepSeek and Stable Diffusion. To mitigate our attacks, we further propose three defenses to enhance the security of PRC, including parameter suggestions, implementation suggestions, and constructing a revised key generation algorithm. Our proposed revised key generation function effectively prevents the occurrence of weak keys. However, we highlight that the current PRC-based watermarking scheme still cannot achieve a 128-bit security under our parameter suggestions due to the inherent configurations of large generative models, such as the maximum output length of large language models.

</details>


### [11] [Detection and Analysis of Sensitive and Illegal Content on the Ethereum Blockchain Using Machine Learning Techniques](https://arxiv.org/abs/2512.17411)
*Xingyu Feng*

Main category: cs.CR

TL;DR: 该研究针对以太坊区块链上的恶意/非法内容问题，开发了数据识别与恢复算法，成功恢复大量文件并进行情感分析，发现区块链上同时存在良性和有害内容，包括敏感信息针对中国政府官员。


<details>
  <summary>Details</summary>
Motivation: 区块链技术虽然具有透明和不可篡改的特性，但其去中心化结构可能导致恶意或非法内容被包含其中，引发隐私和安全担忧。研究旨在识别以太坊区块链上的敏感和非法内容。

Method: 1. 开发数据识别和恢复算法从以太坊区块链恢复文件；2. 使用FastText算法进行情感分析，参数调优后达到0.9准确率；3. 利用NSFWJS库检测不雅图像；4. 对恢复的内容进行分类和分析。

Result: 成功恢复175个常见文件、296张图像和91,206个文本。情感分析显示70,189个中性、5,208个积极和15,810个消极文本。检测到7张不雅图像，准确率100%。发现区块链上同时存在良性和有害内容，包括个人数据、露骨图像、分裂性语言和种族歧视，其中敏感信息针对中国政府官员。

Conclusion: 研究揭示了以太坊区块链上良性和有害内容共存的现象，提出了预防措施，为公众理解区块链技术和监管机构提供指导。所用算法为解决区块链数据隐私和安全问题提供了创新解决方案。

Abstract: Blockchain technology, lauded for its transparent and immutable nature, introduces a novel trust model. However, its decentralized structure raises concerns about potential inclusion of malicious or illegal content. This study focuses on Ethereum, presenting a data identification and restoration algorithm. Successfully recovering 175 common files, 296 images, and 91,206 texts, we employed the FastText algorithm for sentiment analysis, achieving a 0.9 accuracy after parameter tuning. Classification revealed 70,189 neutral, 5,208 positive, and 15,810 negative texts, aiding in identifying sensitive or illicit information. Leveraging the NSFWJS library, we detected seven indecent images with 100% accuracy. Our findings expose the coexistence of benign and harmful content on the Ethereum blockchain, including personal data, explicit images, divisive language, and racial discrimination. Notably, sensitive information targeted Chinese government officials. Proposing preventative measures, our study offers valuable insights for public comprehension of blockchain technology and regulatory agency guidance. The algorithms employed present innovative solutions to address blockchain data privacy and security concerns.

</details>


### [12] [Key-Conditioned Orthonormal Transform Gating (K-OTG): Multi-Key Access Control with Hidden-State Scrambling for LoRA-Tuned Models](https://arxiv.org/abs/2512.17519)
*Muhammad Haris Khan*

Main category: cs.CR

TL;DR: K-OTG是一种简单、兼容PEFT的机制，通过在指令调优语言模型中实施密钥访问控制来防止未经授权使用，同时保持授权用户的实用性。


<details>
  <summary>Details</summary>
Motivation: 当前语言模型缺乏有效的访问控制机制，无法防止未经授权使用。需要一种既能保护模型不被滥用，又不影响授权用户正常使用的解决方案。

Method: 使用双路径语料库训练：授权示例（带角色密钥前缀）学习任务输出，未授权示例学习可见块标记。推理时通过pre-lm_head钩子应用正交变换：正确密钥恢复模型原始基，否则使用会话临时扰乱器使logits无效并短路到BLOCK。

Result: 授权实用性接近基础模型（XSum ROUGE/BLEU、GSM8K准确率），未授权实用性崩溃（接近零的序列指标和爆炸的困惑度）。解锁矩阵对角线占主导，授权块发射为0，贪婪输出在nonce间完全匹配，运行时开销为40%令牌/秒。

Conclusion: K-OTG提供了一种实用、模型无关的方法，在防止未经授权使用的同时保持授权实用性，具有实际部署价值。

Abstract: We present a simple, PEFT-compatible mechanism that enforces secret-key access control in instruction-tuned language models. K-OTG trains on a dual-path corpus: authorized examples (prefixed with a role key) learn the task output, while unauthorized examples learn a visible block token. At inference, a pre-lm_head hook applies an orthonormal transform to the hidden state: with the correct key/role the inverse map restores the model's native basis; otherwise a session-ephemeral scrambler (permutation, sign flips, Householders) makes logits uninformative and the system short-circuits to BLOCK. Keys are not added as special tokens, and the method composes cleanly with LoRA on 4-bit bases. We evaluate an hour-scale protocol on 1-3B-class instruction models (Llama 3.2, Qwen2.5 1.5B) across utility (XSum ROUGE/BLEU, GSM8K accuracy, WikiText-2 perplexity), selectivity (3by3 role-key unlock matrices), nonce invariance, block suppression, and throughput. Authorized utility remains close to the base on summarization with the expected modest PPL increase from instruction tuning; unauthorized utility collapses (near-zero sequence metrics with exploding PPL), indicating practical unusability without the key. Unlock matrices are diagonally dominant (high on-target unlock, low cross-unlock), authorized block emission is 0 per N via robust bad-word lists, and greedy outputs match exactly across nonces, confirming correct inverse cancellation. The runtime overhead of the Python-level hook is 40% tokens per sec versus the base. K-OTG therefore provides a pragmatic, model-agnostic way to prevent unauthorized use while preserving authorized utility.

</details>


### [13] [MAD-OOD: A Deep Learning Cluster-Driven Framework for an Out-of-Distribution Malware Detection and Classification](https://arxiv.org/abs/2512.17594)
*Tosin Ige,Christopher Kiekintveld,Aritran Piplai,Asif Rahman,Olukunle Kolade,Sasidhar Kunapuli*

Main category: cs.CR

TL;DR: MADOOD是一个两阶段、聚类驱动的深度学习框架，用于鲁棒的OOD恶意软件检测和分类，通过高斯判别分析建模恶意软件家族嵌入，使用Z分数距离分析识别异常样本，在未见过的恶意软件家族上达到0.911的AUC。


<details>
  <summary>Details</summary>
Motivation: 恶意软件分类中的OOD检测面临重大挑战，因为多态和变形恶意软件变体引入了显著的家族内变异性。现有深度学习恶意软件检测器大多依赖封闭世界假设，未能充分建模这种类内变异，导致面对未见过的恶意软件家族时性能下降。

Method: 提出MADOOD两阶段框架：第一阶段使用高斯判别分析建模恶意软件家族嵌入，通过类条件球形决策边界分离分布内和OOD样本，利用Z分数距离分析识别异常样本；第二阶段通过深度神经网络集成聚类预测、精炼嵌入和监督分类器输出以提升分类精度。

Result: 在包含25个已知家族和多个新型OOD变体的基准恶意软件数据集上，MADOOD显著优于最先进的OOD检测方法，在未见过的恶意软件家族上达到高达0.911的AUC。

Conclusion: MADOOD为现实世界恶意软件检测和异常识别提供了一个可扩展、可解释且统计原理化的解决方案，适用于不断演变的网络安全环境。

Abstract: Out of distribution (OOD) detection remains a critical challenge in malware classification due to the substantial intra family variability introduced by polymorphic and metamorphic malware variants. Most existing deep learning based malware detectors rely on closed world assumptions and fail to adequately model this intra class variation, resulting in degraded performance when confronted with previously unseen malware families. This paper presents MADOOD, a novel two stage, cluster driven deep learning framework for robust OOD malware detection and classification. In the first stage, malware family embeddings are modeled using class conditional spherical decision boundaries derived from Gaussian Discriminant Analysis (GDA), enabling statistically grounded separation of indistribution and OOD samples without requiring OOD data during training. Z score based distance analysis across multiple class centroids is employed to reliably identify anomalous samples in the latent space. In the second stage, a deep neural network integrates cluster based predictions, refined embeddings, and supervised classifier outputs to enhance final classification accuracy. Extensive evaluations on benchmark malware datasets comprising 25 known families and multiple novel OOD variants demonstrate that MADOOD significantly outperforms state of the art OOD detection methods, achieving an AUC of up to 0.911 on unseen malware families. The proposed framework provides a scalable, interpretable, and statistically principled solution for real world malware detection and anomaly identification in evolving cybersecurity environments.

</details>


### [14] [Sandwiched and Silent: Behavioral Adaptation and Private Channel Exploitation in Ethereum MEV](https://arxiv.org/abs/2512.17602)
*Davide Mancino,Davide Rezzoli*

Main category: cs.CR

TL;DR: 论文实证量化了用户在遭受三明治攻击后的行为适应：约40%受害者60天内转向私有路由，重复暴露者达54%；流失率从首次攻击的7.5%降至1-2%。私有路由仍面临MEV提取风险，攻击高度集中在少数DEX池。


<details>
  <summary>Details</summary>
Motivation: 研究用户在遭受三明治攻击后的行为适应情况，量化用户转向私有路由的比例和流失率，揭示私有路由的实际保护效果和局限性。

Method: 使用2024年11月至2025年2月的交易级数据，结合内存池可见性和ZeroMEV标签，追踪用户在遭受第n次公开三明治攻击后的行为：60天内重新激活链上活动（反应激活）和首次采用私有路由。

Result: 约40%受害者在60天内转向私有路由，重复暴露者达54%；首次攻击后流失率7.5%，随后降至1-2%。2024年11-12月确认2,932次私有三明治攻击，涉及3,126笔私有受害者交易，造成409,236美元损失，攻击者获利293,786美元。单个机器人占私有前置攻击近三分之二，攻击高度集中在少数DEX池。

Conclusion: 私有路由不能完全保护用户免受MEV提取：虽然执行失败推动用户转向私有通道，但这些通道仍可被利用且高度集中，需要持续监控和协议级防御措施。

Abstract: How users adapt after being sandwiched remains unclear; this paper provides an empirical quantification. Using transaction level data from November 2024 to February 2025, enriched with mempool visibility and ZeroMEV labels, we track user outcomes after their n-th public sandwich: (i) reactivation, i.e., the resumption of on-chain activity within a 60-day window, and (ii) first-time adoption of private routing. We refer to users who do not reactivate within this window as churned, and to users experiencing multiple attacks (n>1) as undergoing repeated exposure. Our analysis reveals measurable behavioral adaptation: around 40% of victims migrate to private routing within 60 days, rising to 54% with repeated exposures. Churn peaks at 7.5% after the first sandwich but declines to 1-2%, consistent with survivor bias. In Nov-Dec 2024 we confirm 2,932 private sandwich attacks affecting 3,126 private victim transactions, producing \$409,236 in losses and \$293,786 in attacker profits. A single bot accounts for nearly two-thirds of private frontruns, and private sandwich activity is heavily concentrated on a small set of DEX pools. These results highlight that private routing does not guarantee protection from MEV extraction: while execution failures push users toward private channels, these remain exploitable and highly concentrated, demanding continuous monitoring and protocol-level defenses.

</details>


### [15] [A Post-Quantum Secure End-to-End Verifiable E-Voting Protocol Based on Multivariate Polynomials](https://arxiv.org/abs/2512.17613)
*Vikas Srivastava,Debasish Roy,Sihem Mesnager,Nibedita Kundu,Sumit Kumar Debnath,Sourav Mukhopadhyay*

Main category: cs.CR

TL;DR: 首个基于多元多项式的后量子安全端到端可验证电子投票协议设计


<details>
  <summary>Details</summary>
Motivation: 传统纸质投票存在公平性、有效性和可访问性问题，现有基于数论假设的电子投票方案在量子计算（如Shor算法）面前不再安全

Method: 基于多元多项式（MQ问题）构建后量子安全的电子投票协议，仅使用标准密码学原语作为构建模块

Result: 提出了首个基于MQ问题（NP-hard问题）的后量子安全端到端可验证电子投票协议设计

Conclusion: 该设计为量子计算时代提供了安全、有效的电子投票解决方案，基于数学上更安全的MQ问题而非易受量子攻击的数论假设

Abstract: Voting is a primary democratic activity through which voters select representatives or approve policies. Conventional paper ballot elections have several drawbacks that might compromise the fairness, effectiveness, and accessibility of the voting process. Therefore, there is an increasing need to design safer, effective, and easily accessible alternatives. E-Voting is one such solution that uses digital tools to simplify voting. Existing state-of-the-art designs for secure E-Voting are based on number-theoretic hardness assumptions. These designs are no longer secure due to quantum algorithms such as Shor's algorithm. We present the design and analysis of \textit{first} post-quantum secure end-to-end verifiable E-Voting protocol based on multivariate polynomials to address this issue. The security of our proposed design depends on the hardness of the MQ problem, which is an NP-hard problem. We present a simple yet efficient design involving only standard cryptographic primitives as building blocks.

</details>


### [16] [STAR: Semantic-Traffic Alignment and Retrieval for Zero-Shot HTTPS Website Fingerprinting](https://arxiv.org/abs/2512.17667)
*Yifei Cheng,Yujia Zhu,Baiyang Li,Xinhao Deng,Yitong Cai,Yaochen Ren,Qingyun Liu*

Main category: cs.CR

TL;DR: STAR将网站指纹识别重构为零样本跨模态检索问题，通过联合嵌入流量轨迹和逻辑配置文件，无需目标网站训练数据即可识别未知网站，显著提升隐私保护效果。


<details>
  <summary>Details</summary>
Motivation: 现代HTTPS机制（如ECH和加密DNS）虽然提高了隐私性，但仍容易受到网站指纹识别攻击。现有方法依赖监督学习和特定网站的标记轨迹，限制了可扩展性，无法处理未见过的网站。

Method: 将网站指纹识别重新定义为零样本跨模态检索问题，提出STAR框架。使用双编码器架构学习加密流量轨迹和爬取时逻辑配置文件的联合嵌入空间，通过对比学习和一致性目标训练，结合结构感知增强。

Result: 在1,600个未见网站上，STAR达到87.9%的top-1准确率和0.963的AUC，优于监督学习和少样本基线。每个网站仅用4个标记轨迹的适配器可将top-5准确率提升至98.8%。

Conclusion: STAR揭示了现代网络协议中固有的语义-流量对齐特性，识别出语义泄漏是加密HTTPS流量的主要隐私风险。该方法为可扩展的隐私保护提供了新方向，并开源了数据集和代码。

Abstract: Modern HTTPS mechanisms such as Encrypted Client Hello (ECH) and encrypted DNS improve privacy but remain vulnerable to website fingerprinting (WF) attacks, where adversaries infer visited sites from encrypted traffic patterns. Existing WF methods rely on supervised learning with site-specific labeled traces, which limits scalability and fails to handle previously unseen websites. We address these limitations by reformulating WF as a zero-shot cross-modal retrieval problem and introducing STAR. STAR learns a joint embedding space for encrypted traffic traces and crawl-time logic profiles using a dual-encoder architecture. Trained on 150K automatically collected traffic-logic pairs with contrastive and consistency objectives and structure-aware augmentation, STAR retrieves the most semantically aligned profile for a trace without requiring target-side traffic during training. Experiments on 1,600 unseen websites show that STAR achieves 87.9 percent top-1 accuracy and 0.963 AUC in open-world detection, outperforming supervised and few-shot baselines. Adding an adapter with only four labeled traces per site further boosts top-5 accuracy to 98.8 percent. Our analysis reveals intrinsic semantic-traffic alignment in modern web protocols, identifying semantic leakage as the dominant privacy risk in encrypted HTTPS traffic. We release STAR's datasets and code to support reproducibility and future research.

</details>


### [17] [Digital and Web Forensics Model Cards, V1](https://arxiv.org/abs/2512.17722)
*Paola Di Maio*

Main category: cs.CR

TL;DR: 本文提出了一个专门为数字和网络取证设计的标准化模型卡框架，包括分类、推理类型、偏见识别和错误分类的受控词汇表，以及一个基于网络的生成工具。


<details>
  <summary>Details</summary>
Motivation: 数字和网络取证领域缺乏标准化的模型表示方法，需要建立统一的框架来系统化地描述取证模型的知识、能力和局限性，以促进该领域的透明度和可重复性。

Method: 基于现有的模型卡方法和数字取证分析的抽象模型，开发了一个基于网络的框架，包含分类、推理类型、偏见识别和错误分类的受控词汇表，并创建了一个生成工具来促进采用。

Result: 提出了模型卡的具体结构，展示了受控词汇表，并发布了生成工具的测试版本，邀请社区反馈以完善这一新兴标准。

Conclusion: 该框架旨在标准化数字和网络取证模型的表示，最终目标是防止反欺诈和数字取证过程被不良行为者控制，确保过程的透明性和可靠性。

Abstract: This paper introduces a standardized model card framework specifically designed for digital and web forensics. Building upon established model card methodologies and recent work on abstract models for digital forensic analysis, this paper presents a web based framework that generates model cards specifically designed to represent knowledge in the forensic domain. The framework includes controlled vocabularies for classification, reasoning types, bias identification, and error categorization, along with a web-based generator tool to facilitate adoption. The paper describes the model card structure, presents the controlled vocabularies, and introduces the beta version of the generator tool, inviting community feedback to refine this emerging standard. Ultimately, the systemic risk is that that the anti fraud and digital and web forensics processes are controlled by the mobs.

</details>


### [18] [Methods and Tools for Secure Quantum Clouds with a specific Case Study on Homomorphic Encryption](https://arxiv.org/abs/2512.17748)
*Aurelia Kusumastuti,Nikolay Tcholtchev,Philipp Lämmel,Sebastian Bock,Manfred Hauswirth*

Main category: cs.CR

TL;DR: 该研究探索了在量子云计算中集成同态加密（HE）以增强安全性的可行性，成功在Eclipse Qrisp框架中实现了三种后量子密码算法，并提出了量子云安全建议。


<details>
  <summary>Details</summary>
Motivation: 量子计算技术的发展给云计算带来了新的安全挑战，需要量子抗性加密策略来保护提供量子计算服务的量子云基础设施。

Method: 将同态加密集成到Eclipse Qrisp量子计算框架中，实现并测试了三种后量子密码算法（QOTP、Chen、GSW），评估技术可行性和性能权衡。

Result: 成功在Qrisp中集成了三种PQC算法，证明HE与量子计算框架集成的可行性。QOTP简单且开销低，而Chen和GSW算法在运行时间和内存消耗方面存在性能权衡。

Conclusion: 提出了量子云安全建议：在数据存储和处理层面实施HE、开发量子密钥分发（QKD）、加强访问控制和认证机制，并参与PQC标准化工作。

Abstract: The rise of quantum computing/technology potentially introduces significant security challenges to cloud computing, necessitating quantum-resistant encryption strategies as well as protection schemes and methods for cloud infrastructures offering quantum computing time and services (i.e. quantum clouds). This research explores various options for securing quantum clouds and ensuring privacy, especially focussing on the integration of homomorphic encryption (HE) into Eclipse Qrisp, a high-level quantum computing framework, to enhance the security of quantum cloud platforms. The study addresses the technical feasibility of integrating HE with Qrisp, evaluates performance trade-offs, and assesses the potential impact on future quantum cloud architectures.The successful implementation and Qrisp integration of three post-quantum cryptographic (PQC) algorithms demonstrates the feasibility of integrating HE with quantum computing frameworks. The findings indicate that while the Quantum One-Time Pad (QOTP) offers simplicity and low overhead, other algorithms like Chen and Gentry-Sahai-Waters (GSW) present performance trade-offs in terms of runtime and memory consumption. The study results in an overall set of recommendations for securing quantum clouds, e.g. implementing HE at data storage and processing levels, developing Quantum Key Distribution (QKD), and enforcing stringent access control and authentication mechanisms as well as participating in PQC standardization efforts.

</details>
