<div id=toc></div>

# Table of Contents

- [cs.CR](#cs.CR) [Total: 58]


<div id='cs.CR'></div>

# cs.CR [[Back]](#toc)

### [1] [AegisShield: Democratizing Cyber Threat Modeling with Generative AI](https://arxiv.org/abs/2509.10482)
*Matthew Grofsky*

Main category: cs.CR

TL;DR: AegisShield是一个基于生成式AI的威胁建模工具，通过整合STRIDE和MITRE ATT&CK框架，自动化生成威胁并提供系统评估，显著降低了威胁建模的复杂性。


<details>
  <summary>Details</summary>
Motivation: 传统威胁建模方法难以扩展，特别是对于资源有限的小型组织。技术系统日益复杂使得手动威胁建模变得困难且耗时。

Method: 开发AegisShield工具，集成STRIDE和MITRE ATT&CK框架，利用国家漏洞数据库和AlienVault开放威胁交换的实时威胁情报，自动化生成威胁描述和评估。

Result: 评估243个威胁和8000多个AI生成威胁显示：显著降低复杂性(p<0.001)，输出与专家开发威胁语义对齐(p<0.05)，85.4%的成功率映射到MITRE ATT&CK技术(p<0.001)。

Conclusion: AegisShield通过自动化和标准化威胁建模，帮助资源有限的组织更早地应对风险，支持安全设计实践的更广泛采用。

Abstract: The increasing sophistication of technology systems makes traditional threat
modeling hard to scale, especially for small organizations with limited
resources. This paper develops and evaluates AegisShield, a generative AI
enhanced threat modeling tool that implements STRIDE and MITRE ATT&CK to
automate threat generation and provide systematic assessments. By integrating
real time threat intelligence from the National Vulnerability Database and
AlienVault Open Threat Exchange, AegisShield produces streamlined and
accessible threat descriptions. Our assessment of 243 threats from 15 case
studies and over 8000 AI generated threats shows that AegisShield reduces
complexity (p less than 0.001), yields outputs semantically aligned with expert
developed threats (p less than 0.05), and achieves an 85.4 percent success rate
in mapping threats to MITRE ATT&CK techniques (p less than 0.001). Automating
and standardizing threat modeling helps under resourced organizations address
risk earlier and supports wider adoption of secure by design practices.

</details>


### [2] [Turning CVEs into Educational Labs:Insights and Challenges](https://arxiv.org/abs/2509.10488)
*Trueye Tafese*

Main category: cs.CR

TL;DR: 将CVE漏洞转化为容器化实践教育实验室，通过Docker模拟SQL注入、任意代码执行等真实漏洞，提供结构化教程和评估体系，提升学生的网络安全理解和实践能力。


<details>
  <summary>Details</summary>
Motivation: 将理论性的CVE漏洞信息转化为可实践的网络安全教育内容，弥合理论概念与动手实践之间的差距，为网络安全教育提供可扩展和可复制的教学模型。

Method: 开发基于Docker的容器化实验室环境，模拟真实漏洞场景（SQL注入、任意代码执行、SSL证书验证不当等），包含结构化教程、前后测调查和学习成果评估体系。

Result: 学生显著提升了网络安全原理理解、威胁缓解技术和安全编码实践能力，证明了漏洞分析在教育中的价值。

Conclusion: 该方法成功创建了一个可扩展、可复制的网络安全教育模型，在受控安全环境中有效培养对现实世界安全挑战的深入理解，为网络安全教育提供了创新解决方案。

Abstract: This research focuses on transforming CVEs to hands-on educational lab for
cybersecurity training. The study shows the practical application of CVEs by
developing containerized lab environments- Docker to simulate real-world
vulnerabilities like SQL Injection, arbitrary code execution, and improper SSL
certificate validation. These labs has structured tutorials, pre- and
post-surveys to evaluate learning outcomes, and remediation steps.Key
challenges included interpreting limited CVE data, resolving technical
complexities in lab design, and ensuring accessibility for diverse learners.
Despite these difficulties, the findings highlight the use of educational
benefits of vulnerability analysis, bridging theoretical concepts with hands-on
experience. The results indicate that students improved comprehension of
cybersecurity principles, threat mitigation techniques, and secure coding
practices. This innovative approach provides a scalable and reproducible model
for integrating CVEs into cybersecurity education, fostering a deeper
understanding of real-world security challenges in a controlled and safe
environment.

</details>


### [3] [Investigation Of The Distinguishability Of Giraud-Verneuil Atomic Blocks](https://arxiv.org/abs/2509.10492)
*Philip Laryea Doku*

Main category: cs.CR

TL;DR: 该论文研究了椭圆曲线密码系统(ECC)实现中Giraud和Verneuil原子模式对侧信道分析(SCA)的安全性，发现在存在额外时钟周期进程时原子块可被电磁辐射区分，移除后安全性提升，表明原子性单独不足以完全防护SCA攻击。


<details>
  <summary>Details</summary>
Motivation: ECC虽然效率高且安全性强，但在标量乘法(kP)过程中容易受到侧信道分析攻击。现有防护措施如规则性和原子性，本研究专注于原子性模式的安全性评估。

Method: 在NIST EC P-256曲线上使用右到左kP算法实现Giraud和Verneuil原子模式，采用FLECC库和恒定时间操作，在Texas Instruments LAUNCHXLF28379D MCU上执行，使用Lecroy示波器和Langer探头测量电磁辐射。

Result: 当存在额外时钟周期进程时，原子块在电磁轨迹中可被视觉区分；移除这些进程后，原子块更加同步且难以区分，降低了SCA攻击成功的风险。

Conclusion: 虽然原子模式正确实现了虚拟操作，但硬件或软件层面插入的额外进程仍会影响SCA抵抗能力。原子性单独不能完全保护ECC免受SCA攻击，需要进一步研究额外时钟周期进程的成因和内存寄存器中中间操作的处理方式。

Abstract: In this work, we investigate the security of Elliptic Curve Cryptosystem
(ECC) implementations against Side-Channel Analysis (SCA). ECC is well known
for its efficiency and strong security, yet vulnerable to SCA which exploits
physical information leaked during scalar multiplication (kP). Countermeasures
such as regularity and atomicity exist; this thesis focuses on atomicity. In
this work, we study the Giraud and Verneuil atomic pattern for kP, implementing
it using the right-to-left kP algorithm on the NIST EC P-256 curve. We use the
FLECC library with constant-time operations and execute on the Texas
Instruments LAUNCHXLF28379D MCU. We measure Electromagnetic (EM) emissions
during kP using a Lecroy WavePro 604HD Oscilloscope, a Langer ICS 105
Integrated Circuit Scanner, and a Langer MFA-R 0.2-75 Near Field Probe. We
investigate whether the Giraud and Verneuil atomic blocks are distinguishable
in EM traces. Our findings show that, when additional clock cycle processes are
present, the atomic blocks can be visually distinguished; after removing these
processes, they become more synchronised and harder to distinguish, reducing
the risk of a successful SCA attack. These results show that, although the
atomic pattern is correctly implemented with dummy operations, resistance to
SCA can still be affected by additional processes inserted at hardware or
software level.This means atomicity alone may not fully protect ECC from SCA.
More research is needed to investigate the causes of the additional clock cycle
processes and how intermediate operations are addressed in memory registers.
This will help to understand the processes that lead to the insertion of these
additional clock cycles. This thesis is the first to experimentally implement
and investigate Giraud and Verneuil's atomic pattern on hardware, and it offers
useful results to improve countermeasures against SCA.

</details>


### [4] [EchoLeak: The First Real-World Zero-Click Prompt Injection Exploit in a Production LLM System](https://arxiv.org/abs/2509.10540)
*Pavan Reddy,Aditya Sanjay Gujral*

Main category: cs.CR

TL;DR: EchoLeak漏洞利用微软365 Copilot的零点击提示注入，通过精心构造的邮件实现远程未认证数据泄露，揭示了AI助手在生产环境中的严重安全风险。


<details>
  <summary>Details</summary>
Motivation: 随着大语言模型助手在企业工作流程中的集成度提高，连接内外数据源带来了新的安全担忧，需要研究实际生产系统中的提示注入漏洞及其防御措施。

Method: 通过多级绕过技术：规避微软XPIA分类器、使用引用式Markdown绕过链接审查、利用自动获取图像、滥用Teams代理权限，实现无用户交互的权限提升和数据泄露。

Result: 成功演示了零点击远程数据泄露攻击，证明了提示注入作为实际高危漏洞类别的存在，现有防御机制在此类攻击面前失效。

Conclusion: 提出了包括提示分区、增强输入输出过滤、基于来源的访问控制和严格内容安全策略等工程缓解措施，强调最小权限原则、深度防御架构和持续对抗测试的重要性，为构建安全AI助手提供了蓝图。

Abstract: Large language model (LLM) assistants are increasingly integrated into
enterprise workflows, raising new security concerns as they bridge internal and
external data sources. This paper presents an in-depth case study of EchoLeak
(CVE-2025-32711), a zero-click prompt injection vulnerability in Microsoft 365
Copilot that enabled remote, unauthenticated data exfiltration via a single
crafted email. By chaining multiple bypasses-evading Microsofts XPIA (Cross
Prompt Injection Attempt) classifier, circumventing link redaction with
reference-style Markdown, exploiting auto-fetched images, and abusing a
Microsoft Teams proxy allowed by the content security policy-EchoLeak achieved
full privilege escalation across LLM trust boundaries without user interaction.
We analyze why existing defenses failed, and outline a set of engineering
mitigations including prompt partitioning, enhanced input/output filtering,
provenance-based access control, and strict content security policies. Beyond
the specific exploit, we derive generalizable lessons for building secure AI
copilots, emphasizing the principle of least privilege, defense-in-depth
architectures, and continuous adversarial testing. Our findings establish
prompt injection as a practical, high-severity vulnerability class in
production AI systems and provide a blueprint for defending against future
AI-native threats.

</details>


### [5] [Robust DDoS-Attack Classification with 3D CNNs Against Adversarial Methods](https://arxiv.org/abs/2509.10543)
*Landon Bragg,Nathan Dorsey,Josh Prior,John Ajit,Ben Kim,Nate Willis,Pablo Rivas*

Main category: cs.CR

TL;DR: 提出了一种基于蜂巢图序列和3D CNN的DDoS攻击检测方法，通过对抗训练将对抗样本准确率从50-55%提升至93%以上，并在早期帧（3-4帧）就能实现有效分类。


<details>
  <summary>Details</summary>
Motivation: DDoS攻击通过微妙改变流量模式来绕过检测，对在线基础设施构成严重威胁，需要开发更强大的检测方法。

Method: 使用时空蜂巢图编码建立模式识别基线，应用FGSM和PGD对抗训练结合空间噪声和图像位移，分析逐帧预测寻找早期信号。

Result: 在基准数据集上，该方法将对抗准确率从50-55%提升至93%以上，同时保持干净样本性能，第3-4帧显示出强预测信号。

Conclusion: 基于蜂巢图序列和3D CNN的方法能有效检测DDoS攻击，支持早期分类，对抗训练显著提升了模型鲁棒性。

Abstract: Distributed Denial-of-Service (DDoS) attacks remain a serious threat to
online infrastructure, often bypassing detection by altering traffic in subtle
ways. We present a method using hive-plot sequences of network data and a 3D
convolutional neural network (3D CNN) to classify DDoS traffic with high
accuracy. Our system relies on three main ideas: (1) using spatio-temporal
hive-plot encodings to set a pattern-recognition baseline, (2) applying
adversarial training with FGSM and PGD alongside spatial noise and image
shifts, and (3) analyzing frame-wise predictions to find early signals. On a
benchmark dataset, our method lifts adversarial accuracy from 50-55% to over
93% while maintaining clean-sample performance. Frames 3-4 offer strong
predictive signals, showing early-stage classification is possible.

</details>


### [6] [Decentralized Identity Management on Ripple: A Conceptual Framework for High-Speed, Low-Cost Identity Transactions in Attestation-Based Attribute-Based Identity](https://arxiv.org/abs/2509.10545)
*Ruwanga Konara,Kasun De Zoysa,Asanka Sayakkara*

Main category: cs.CR

TL;DR: 本文分析了去中心化身份管理系统(DIDMS)的研究现状，特别关注基于证明的属性基去中心化身份管理(ABABDIDM)在Ripple区块链上的应用潜力，指出该领域在Ripple平台上的研究空白。


<details>
  <summary>Details</summary>
Motivation: 现有研究主要集中在Hyperledger、Ethereum和Bitcoin等主流区块链上的DIDMS实现，而Ripple区块链虽然具有适合属性基身份管理的特性，但相关研究严重缺乏。作者旨在填补这一研究空白。

Method: 通过文献综述分析现有DIDMS研究现状，识别Ripple区块链在ABABDIDM应用中的潜力，并尝试在Ripple上概念化设计一个基于证明的属性基去中心化身份管理系统。

Result: 发现ABABDIDM相比一般的属性基DIDMS(ABDIDM)研究关注度显著不足，特别是Ripple区块链作为DIDMS平台的研究几乎空白，为后续研究指明了方向。

Conclusion: Ripple区块链具有开发属性基去中心化身份管理系统的良好特性，但相关研究严重缺乏，需要更多工作来探索其在这一领域的应用潜力。

Abstract: Recent years have seen many industrial implementations and much scholastic
research, i.e., prototypes and theoretical frameworks, in Decentralized
Identity Management Systems (DIDMS). It is safe to say that Attestation-Based
Attribute-Based Decentralized IDM (ABABDIDM) has not received anywhere near the
same level of attention in the literature as general Attribute-Based DIDMs
(ABDIDM), i.e, decentralized Attribute-Based Access Control (ABAC). The use of
decentralization, i.e., DIDM, is to improve upon the security and
privacy-related issues of centralized Identity Management Systems (IDM) and
Attribute-Based IDMs (ABIDM). And blockchain is the framework used for
decentralization in all these schemes. Many DIDMs - even ABDIDMs - have been
defined on popular blockchains such as Hyperledger, Ethereum, and Bitcoin.
However, despite the characteristics of Ripple that makes it appealing for an
ABIDM, there is a lack of research to develop an Identity Management System
(IDMS) on Ripple in literature. We have attempted to conceptualize an ABABDIDM
on Ripple.

</details>


### [7] [Auditable Early Stopping for Agentic Routing: Ledger-Verified Run-Wise Certificates under Local DP](https://arxiv.org/abs/2509.10550)
*Shivam Akhauri*

Main category: cs.CR

TL;DR: 提出了基于扰动和MAP（PaM）最佳优先搜索的运行早期停止证书，用于工具使用代理中的路由决策，支持精确和代理两种模式，确保局部差分隐私和可审计性。


<details>
  <summary>Details</summary>
Motivation: 在生产工具使用代理（如检索→摘要→计算器）中，路由器需要在保持局部差分隐私和留下可审计痕迹的同时，知道何时停止探索。

Method: 使用上下文索引前缀DAG，通过偏移传播实现懒加载的指数竞赛耦合路径分数和剪枝键。提供精确模式（使用精确叶计数）和代理模式（使用上界计数），包含编译器、局部有限性检查、SuffixCountDP例程等组件。

Result: 实现了可重现的结果，包括小型真实工具使用管道和验证器检查的审计轨迹，提供了代码和账本。

Conclusion: 该方法为工具使用代理提供了可靠的早期停止机制，确保隐私保护和可审计性，支持多LLM控制器和运行时选择的DP训练LoRA适配器。

Abstract: In production tool-use agents (e.g., retrieval $\to$ summarization $\to$
calculator), routers must know when to stop exploring while preserving local DP
and leaving an auditable trail. We present run-wise early-stopping certificates
for perturb-and-MAP (PaM) best-first search on context-indexed prefix DAGs
whose children partition the leaves. We couple realized path scores and pruning
keys to a single exponential race realized lazily via offset propagation. With
exact leaf counts $N(v)$, lazy reuse at winners and independent residuals yield
an Exact mode with a sound halting rule based on Key$(v) = M_tau(v) - \log
t(v)$, where $t(v)$ is the minimum arrival time among leaves under $v$. With
only upper bounds $N_{ub} \ge N$, a Surrogate mode uses a parent-anchored
surrogate race without winner reuse; because $-\log \hat t \ge -\log t$, the
frontier invariant holds and stopping remains sound. We add a compiler from
shared-node DAGs to prefix DAGs, local finiteness checks, a SuffixCountDP
routine for exact counts with safe downgrades, a validator-side tightening term
$\kappa = \log(N/N_{ub})$, and an auditable ledger/validator that replays runs
deterministically. We also give an absolute LogSumExp tail bound, an acyclicity
certificate, and a fallback PRF-per-leaf scheme (NoCert) whose work matches a
realized-score best-first baseline up to a small per-node overhead. Finally, we
integrate a price/latency/$(\epsilon, \delta)$-aware multi-LLM controller and
DP-trained LoRA adapters chosen at runtime; these choices do not affect the
two-mode frontier invariants. We report Mac/commodity-hardware reproducible
results, a small real tool-use pipeline, and validator-checked audit trails,
with code and ledgers provided.

</details>


### [8] [A Hybrid Encryption Framework Combining Classical, Post-Quantum, and QKD Methods](https://arxiv.org/abs/2509.10551)
*Amal Raj,Vivek Balachandran*

Main category: cs.CR

TL;DR: 提出混合加密框架，结合经典密码学、后量子密码学和量子密钥分发技术，以应对量子计算威胁，并通过原型实现验证性能


<details>
  <summary>Details</summary>
Motivation: 应对量子计算对现有密码体系的威胁，提供从经典密码向后量子密码的平稳过渡方案，同时利用量子密钥分发增强密钥安全性

Method: 构建混合加密框架，集成EdDSA、ECDH（经典密码学）、ML-DSA-6x5、ML-KEM-768（后量子密码学）和Guardian QKD技术，使用密钥派生函数生成对称密钥和HMAC密钥

Result: 开发了原型系统并评估了执行时间和网络性能指标，验证了框架的可行性

Conclusion: 该框架有效结合了经典密码学的高效性、后量子密码学的量子抗性和量子密钥分发的密钥安全性，为密码系统的量子安全过渡提供了实用路径，为未来后量子密码技术的应用奠定了基础

Abstract: This paper introduces a hybrid encryption framework combining classical
cryptography (EdDSA, ECDH), post-quantum cryptography (ML-DSA-6x5, ML-KEM-768),
and Quantum Key Distribution (QKD) via Guardian to counter quantum computing
threats. Our prototype implements this integration, using a key derivation
function to generate secure symmetric and HMAC keys, and evaluates its
performance across execution time and network metrics. The approach improves
data protection by merging classical efficiency with PQC's quantum resilience
and QKD's key security, offering a practical transition path for cryptographic
systems. This research lays the foundation for future adoption of PQC in
securing digital communication.

</details>


### [9] [AVEC: Bootstrapping Privacy for Local LLMs](https://arxiv.org/abs/2509.10561)
*Madhava Gaikwad*

Main category: cs.CR

TL;DR: AVEC是一个为本地语言模型提供隐私保护的框架，通过在边缘实施具有可验证性的隐私保护机制，使用自适应差分隐私预算分配和可验证转换技术。


<details>
  <summary>Details</summary>
Motivation: 为了解决本地语言模型在委托查询中的隐私保护问题，需要建立一个既能保护隐私又能验证查询完整性的框架，避免隐私泄露和未授权访问。

Method: 采用自适应预算算法分配每查询的差分隐私参数，基于敏感性、本地置信度和历史使用情况；使用可验证转换和设备完整性检查；基于Rényi差分隐私和里程表式记账形式化保证。

Result: 建立了效用上限、委托泄露边界，并证明了确定性门控和仅哈希认证的不可能性；通过模拟评估验证了机制行为和记账效果。

Conclusion: AVEC提供了一个概念架构和理论基础，为本地语言模型的隐私引导提供了可行的技术路径，为后续实证研究奠定了基础。

Abstract: This position paper presents AVEC (Adaptive Verifiable Edge Control), a
framework for bootstrapping privacy for local language models by enforcing
privacy at the edge with explicit verifiability for delegated queries. AVEC
introduces an adaptive budgeting algorithm that allocates per-query
differential privacy parameters based on sensitivity, local confidence, and
historical usage, and uses verifiable transformation with on-device integrity
checks. We formalize guarantees using R\'enyi differential privacy with
odometer-based accounting, and establish utility ceilings, delegation-leakage
bounds, and impossibility results for deterministic gating and hash-only
certification. Our evaluation is simulation-based by design to study mechanism
behavior and accounting; we do not claim deployment readiness or task-level
utility with live LLMs. The contribution is a conceptual architecture and
theoretical foundation that chart a pathway for empirical follow-up on
privately bootstrapping local LLMs.

</details>


### [10] [Enhancing IoMT Security with Explainable Machine Learning: A Case Study on the CICIOMT2024 Dataset](https://arxiv.org/abs/2509.10563)
*Mohammed Yacoubi,Omar Moussaoui,C. Drocourt*

Main category: cs.CR

TL;DR: 本研究比较了bagging和boosting两种集成学习技术在IoMT网络安全威胁检测中的应用，使用Random Forest和CatBoost模型，并通过XAI技术(SHAP和LIME)提升模型的可解释性。


<details>
  <summary>Details</summary>
Motivation: IoMT环境中AI驱动的威胁检测模型存在黑盒问题，网络安全专业人员需要理解AI决策背后的逻辑以确保信任和问责制，医疗设备面临的网络攻击威胁日益严重。

Method: 采用集成学习方法：bagging使用Random Forest减少方差，boosting使用CatBoost改善偏差。应用XAI技术(SHAP和LIME)生成局部和全局解释，突出特征重要性。

Result: 研究展示了集成学习技术在检测复杂网络攻击方面的有效性，同时通过XAI技术提供了模型决策的可解释性洞察。

Conclusion: XAI技术能够有效解决AI模型在网络安全领域的透明度问题，帮助利益相关者理解网络威胁检测的关键驱动因素，增强对AI决策的信任。

Abstract: Explainable Artificial Intelligence (XAI) enhances the transparency and
interpretability of AI models, addressing their inherent opacity. In
cybersecurity, particularly within the Internet of Medical Things (IoMT), the
black-box nature of AI-driven threat detection poses a significant challenge.
Cybersecurity professionals must not only detect attacks but also understand
the reasoning behind AI decisions to ensure trust and accountability. The rapid
increase in cyberattacks targeting connected medical devices threatens patient
safety and data privacy, necessitating advanced AI-driven solutions. This study
compares two ensemble learning techniques, bagging and boosting, for
cyber-attack classification in IoMT environments. We selected Random Forest for
bagging and CatBoost for boosting. Random Forest helps reduce variance, while
CatBoost improves bias by combining weak classifiers into a strong ensemble
model, making them effective for detecting sophisticated attacks. However,
their complexity often reduces transparency, making it difficult for
cybersecurity professionals to interpret and trust their decisions. To address
this issue, we apply XAI models to generate local and global explanations,
providing insights into AI decision-making. Using techniques like SHAP (Shapley
Additive Explanations) and LIME (Local Interpretable Model-agnostic
Explanations), we highlight feature importance to help stakeholders understand
the key factors driving cyber threat detection.

</details>


### [11] [SG-ML: Smart Grid Cyber Range Modelling Language](https://arxiv.org/abs/2509.10568)
*Muhammad M. Roomi,Suhail S. M. Hussain,Daisuke Mashima*

Main category: cs.CR

TL;DR: SG-ML是一种基于XML的智能电网建模语言，用于自动化生成智能电网网络靶场，整合了电力系统和网络拓扑表示，支持定制化配置和自动化部署。


<details>
  <summary>Details</summary>
Motivation: 现有的网络靶场设计方法多为临时性方案，缺乏统一的方法论来整合电力系统和网络拓扑表示，难以实现可重复、可扩展的自动化部署。

Method: SG-ML定义为一组XML模式，利用IEC 61850 SCL和IEC 61131 PLCopen XML等标准定义电力系统拓扑、网络拓扑和设备配置，并引入专有模式补充标准未覆盖的部分如攻击注入参数等。

Result: SG-ML提供了统一的建模方法，支持用户定制化配置，能够自动化实例化网络靶场环境，实现现有资产的复用，降低了建模工作量。

Conclusion: SG-ML实现了可重复、可扩展、自动化的智能电网网络靶场生成，适用于研究、培训和安全性评估。

Abstract: This work provides a detailed specification of the Smart Grid Modelling
Language (SG-ML), which is designed for the automated generation of smart grid
cyber ranges. SG-ML is defined as a set of XML schemas that describe a smart
grid's configuration in both machine-readable and human-friendly ways, thereby
bridging the gap between system modelling and automated deployment. Unlike
prior ad-hoc approaches to cyber range design, SG-ML provides a unified
methodology that integrates both power system and cyber network
representations. The SG-ML model can be customized by users to meet specific
requirements, such as emulating physical or cyber topologies and configuring
network devices. An SG-ML Processor then parses this configured model to
instantiate the cyber range environment. The modelling language leverages
established standards like the IEC 61850 Substation Configuration Language
(SCL) and IEC 61131 PLCopen XML to define power system topology, cyber network
topology, and device configurations. This approach allows for the reuse of
existing assets, reducing the effort needed to create the SG-ML model. To
address gaps not covered by these standards such as attack injection
parameters, scenario-specific metadata, and additional network constraints,
SG-ML introduces proprietary schemas that complement standard models. Overall,
SG-ML enables reproducible, scalable, and automated generation of realistic
smart grid cyber ranges for research, training, and security assessment.

</details>


### [12] [MarkDiffusion: An Open-Source Toolkit for Generative Watermarking of Latent Diffusion Models](https://arxiv.org/abs/2509.10569)
*Leyi Pan,Sheng Guan,Zheyu Fu,Luyang Si,Zian Wang,Xuming Hu,Irwin King,Philip S. Yu,Aiwei Liu,Lijie Wen*

Main category: cs.CR

TL;DR: MarkDiffusion是一个开源Python工具包，用于潜在扩散模型的生成式水印，包含统一实现框架、可视化套件和综合评估模块三大组件


<details>
  <summary>Details</summary>
Motivation: 帮助研究人员、增强公众对生成式水印的认识和参与度，促进共识并推动研究和应用发展

Method: 开发包含三个核心组件的工具包：1）统一实现框架用于算法集成和用户友好接口；2）可视化套件直观展示水印模式；3）评估模块提供24种工具和8个自动化评估流水线

Result: 成功构建了一个全面的生成式水印工具包，覆盖可检测性、鲁棒性和输出质量三个关键方面的评估

Conclusion: MarkDiffusion通过提供标准化工具和可视化功能，有效促进了生成式水印技术的研究、应用和公众理解

Abstract: We introduce MarkDiffusion, an open-source Python toolkit for generative
watermarking of latent diffusion models. It comprises three key components: a
unified implementation framework for streamlined watermarking algorithm
integrations and user-friendly interfaces; a mechanism visualization suite that
intuitively showcases added and extracted watermark patterns to aid public
understanding; and a comprehensive evaluation module offering standard
implementations of 24 tools across three essential aspects - detectability,
robustness, and output quality - plus 8 automated evaluation pipelines. Through
MarkDiffusion, we seek to assist researchers, enhance public awareness and
engagement in generative watermarking, and promote consensus while advancing
research and applications.

</details>


### [13] [Directionality of the Voynich Script](https://arxiv.org/abs/2509.10573)
*Christophe Parisel*

Main category: cs.CR

TL;DR: 提出了一种基于n-gram困惑度不对称性的统计方法，用于确定字符序列的方向性偏好


<details>
  <summary>Details</summary>
Motivation: 虽然Voynich手稿几乎确定是从左到右书写的，但底层文字或密码的阅读方向（左到右还是右到左）缺乏定量研究

Method: 利用n-gram困惑度不对称性来检测字符序列中的方向性偏差

Result: 该方法能够有效识别文本的方向性偏好

Conclusion: 统计方法可以为Voynich手稿等历史文献的阅读方向问题提供定量分析工具

Abstract: While the Voynich Manuscript was almost certainly written left-to-right
(LTR), the question whether the underlying script or cipher reads LTR or
right-to-left (RTL) has received little quantitative attention. We introduce a
statistical method that leverages n-gram perplexity asymmetry to determine
directional bias in character sequences.

</details>


### [14] [The Coding Limits of Robust Watermarking for Generative Models](https://arxiv.org/abs/2509.10577)
*Danilo Francati,Yevin Nikhel Goonatilake,Shubham Pawar,Daniele Venturi,Giuseppe Ateniese*

Main category: cs.CR

TL;DR: 本文证明了生成模型密码水印鲁棒性的尖锐阈值：对于二进制输出，修改超过一半编码位时任何方案都无法存活；对于q进制字母表，阈值为(1-1/q)的符号。同时给出了达到该界限的显式构造，并通过实验验证了该阈值在实践中已经达到。


<details>
  <summary>Details</summary>
Motivation: 研究密码水印的鲁棒性极限，为生成模型的水印技术提供理论基础和实践指导，明确水印能够承受的最大篡改程度。

Method: 引入无消息密钥码的编码抽象框架，形式化鲁棒水印的充分必要条件（可靠性、篡改检测和伪随机性），给出理论证明和显式构造，并通过实验验证理论结果。

Result: 建立了鲁棒性的精确界限：二进制情况下容忍不超过50%错误，q进制情况下容忍不超过(1-1/q)错误。构造了接近该界限的线性时间码，实验证明简单裁剪操作就能破坏现有水印方案。

Conclusion: 完整刻画了鲁棒水印的理论极限，提供了达到该极限的构造方法，并证明这一极限在实践中已经显现，为水印技术的设计和评估提供了重要参考。

Abstract: We prove a sharp threshold for the robustness of cryptographic watermarking
for generative models. This is achieved by introducing a coding abstraction,
which we call messageless secret-key codes, that formalizes sufficient and
necessary requirements of robust watermarking: soundness, tamper detection, and
pseudorandomness. Thus, we establish that robustness has a precise limit: For
binary outputs no scheme can survive if more than half of the encoded bits are
modified, and for an alphabet of size q the corresponding threshold is
$(1-1/q)$ of the symbols.
  Complementing this impossibility, we give explicit constructions that meet
the bound up to a constant slack. For every ${\delta} > 0$, assuming
pseudorandom functions and access to a public counter, we build linear-time
codes that tolerate up to $(1/2)(1-{\delta})$ errors in the binary case and
$(1-1/q)(1-{\delta})$ errors in the $q$-ary case. Together with the lower
bound, these yield the maximum robustness achievable under standard
cryptographic assumptions.
  We then test experimentally whether this limit appears in practice by looking
at the recent watermarking for images of Gunn, Zhao, and Song (ICLR 2025). We
show that a simple crop and resize operation reliably flipped about half of the
latent signs and consistently prevented belief-propagation decoding from
recovering the codeword, erasing the watermark while leaving the image visually
intact.
  These results provide a complete characterization of robust watermarking,
identifying the threshold at which robustness fails, constructions that achieve
it, and an experimental confirmation that the threshold is already reached in
practice.

</details>


### [15] [Multi-channel secure communication framework for wireless IoT (MCSC-WoT): enhancing security in Internet of Things](https://arxiv.org/abs/2509.10581)
*Prokash Barman,Ratul Chowdhury,Banani Saha*

Main category: cs.CR

TL;DR: 提出了MCSC框架，整合加密协议和动态信道跳频策略，提升IoT/WoT网络安全并减少同步开销


<details>
  <summary>Details</summary>
Motivation: 传统加密方法和跳频技术不足以防御中间人、干扰和重放攻击，多信道通信系统的同步问题导致延迟和能耗增加，不适合资源受限的IoT/WoT设备

Method: 多信道安全通信(MCSC)框架，集成先进加密协议和动态信道跳频策略

Result: 与FHSS、单信道AES、ECC等方案相比，MCSC具有更低错误率，对更广泛的网络攻击更具弹性，在多种干扰条件下验证了其效率

Conclusion: MCSC框架能有效保护IoT和WoT网络安全，同时不损害操作性能，满足资源受限设备的特定需求

Abstract: In modern smart systems, the convergence of the Internet of Things (IoT) and
Wireless of Things (WoT) have been revolutionized by offering a broad level of
wireless connectivity and communication among various devices. Hitherto, this
greater interconnectivity poses important security problems, including the
question of how to securely interconnect different networks, preserve secure
communication channels, and maintain data integrity. However, the traditional
cryptographic method and frequency hopping technique, although they provide
some protection, are not sufficient to defend against Man-In-The-Middle,
jamming, and replay attacks. In addition, synchronization issues in
multi-channel communication systems result in increased latency and energy
consumption, which make them unsuitable for resource-constrained IoT and WoT
devices. This work presents the Multi-Channel Secure Communication (MCSC)
framework, which integrates advanced cryptographic protocols with dynamic
channel-hopping strategies to enhance security with reduced synchronization
overhead. The MCSC framework maximizes the critical performance metrics, such
as packet delivery ratio, latency, throughput, and energy efficiency, and
fulfills the specific requirements of the IoT and WoT networks. A comprehensive
comparison of MCSC with well-established methods, including Frequency Hop
Spread Spectrum, single channel Advanced Encryption Standard, and various
Elliptic Curve Cryptography-based schemes, indicates that MCSC has lower error
rates and is more resilient to a wider range of cyber attacks. The efficiency
of the proposed solution to secure IoT and WoT networks without compromising
the operational performance is validated under various interference conditions.

</details>


### [16] [Safety and Security Analysis of Large Language Models: Risk Profile and Harm Potential](https://arxiv.org/abs/2509.10655)
*Charankumar Akiri,Harrison Simpson,Kshitiz Aryal,Aarav Khanna,Maanak Gupta*

Main category: cs.CR

TL;DR: 该研究对9个主流大语言模型进行安全漏洞实证分析，发现普遍存在对抗性提示攻击风险，提出风险严重性指数(RSI)来量化评估模型安全态势。


<details>
  <summary>Details</summary>
Motivation: 随着大语言模型广泛部署，其对抗性操纵和利用漏洞可能带来严重的安全、安保和道德风险，需要评估模型在面对不断演变的对抗性提示技术时的安全状况。

Method: 对9个主流LLM(包括Claude Opus 4、DeepSeek V3、GPT-4o等)进行实证分析，使用24个不同安全和安保类别的对抗性提示数据集，评估模型产生有害响应的能力。

Result: 研究发现测试的LLM安全过滤器存在广泛漏洞，模型在暴力犯罪、非暴力犯罪活动、社会危害、非法性内容、危险代码生成等多个安全类别中表现出脆弱性。

Conclusion: 研究强调需要更强的对齐机制、负责任的部署实践和模型治理，特别是对于开放访问和快速迭代的模型，RSI指标可作为比较LLM风险的有价值度量标准。

Abstract: While the widespread deployment of Large Language Models (LLMs) holds great
potential for society, their vulnerabilities to adversarial manipulation and
exploitation can pose serious safety, security, and ethical risks. As new
threats continue to emerge, it becomes critically necessary to assess the
landscape of LLMs' safety and security against evolving adversarial prompt
techniques. To understand the behavior of LLMs, this research provides an
empirical analysis and risk profile of nine prominent LLMs, Claude Opus 4,
DeepSeek V3 (both open-source and online), Gemini 2.5 Flash, GPT-4o, Grok 3,
Llama 4 Scout, Mistral 7B, and Qwen 3 1.7B, against 24 different security and
safety categories. These LLMs are evaluated on their ability to produce harmful
responses for adversarially crafted prompts (dataset has been made public) for
a broad range of safety and security topics, such as promotion of violent
criminal behavior, promotion of non-violent criminal activity, societal harms
related to safety, illegal sexual content, dangerous code generation, and
cybersecurity threats beyond code. Our study introduces the Risk Severity Index
(RSI), an agile and scalable evaluation score, to quantify and compare the
security posture and creating a risk profile of LLMs. As the LLM development
landscape progresses, the RSI is intended to be a valuable metric for comparing
the risks of LLMs across evolving threats. This research finds widespread
vulnerabilities in the safety filters of the LLMs tested and highlights the
urgent need for stronger alignment, responsible deployment practices, and model
governance, particularly for open-access and rapidly iterated models.

</details>


### [17] [LLM in the Middle: A Systematic Review of Threats and Mitigations to Real-World LLM-based Systems](https://arxiv.org/abs/2509.10682)
*Vitor Hugo Galhardo Moia,Igor Jochem Sanz,Gabriel Antonio Fontes Rebello,Rodrigo Duarte de Meneses,Briland Hitaj,Ulf Lindqvist*

Main category: cs.CR

TL;DR: 本文对基于大语言模型(LLM)系统的安全隐私威胁进行了系统性综述，从整个软件和LLM生命周期角度对威胁和防御策略进行了全面分类和分析。


<details>
  <summary>Details</summary>
Motivation: 生成式AI特别是LLM的成功应用吸引了网络犯罪分子的关注，他们试图滥用模型、窃取敏感数据或破坏服务。为LLM系统提供安全保障面临巨大挑战，需要同时缓解传统软件应用威胁和针对LLM及其集成的威胁。

Method: 采用系统性文献综述方法，基于整个软件和LLM生命周期对威胁和防御策略进行综合分类。分析从开发到运营的不同LLM使用场景的真实案例，按严重程度和适用场景对威胁进行分类。

Result: 建立了全面的威胁分类框架，将防御策略系统性地分类并映射到对应的生命周期阶段和可能缓解的攻击策略。识别了最相关的威胁并提供了相应的防御建议。

Conclusion: 该研究为消费者和供应商在集成LLM时理解和有效缓解风险提供了途径，同时也为研究社区讨论阻碍LLM系统安全隐私采用的开放挑战和边缘案例奠定了基础。

Abstract: The success and wide adoption of generative AI (GenAI), particularly large
language models (LLMs), has attracted the attention of cybercriminals seeking
to abuse models, steal sensitive data, or disrupt services. Moreover, providing
security to LLM-based systems is a great challenge, as both traditional threats
to software applications and threats targeting LLMs and their integration must
be mitigated. In this survey, we shed light on security and privacy concerns of
such LLM-based systems by performing a systematic review and comprehensive
categorization of threats and defensive strategies considering the entire
software and LLM life cycles. We analyze real-world scenarios with distinct
characteristics of LLM usage, spanning from development to operation. In
addition, threats are classified according to their severity level and to which
scenarios they pertain, facilitating the identification of the most relevant
threats. Recommended defense strategies are systematically categorized and
mapped to the corresponding life cycle phase and possible attack strategies
they attenuate. This work paves the way for consumers and vendors to understand
and efficiently mitigate risks during integration of LLMs in their respective
solutions or organizations. It also enables the research community to benefit
from the discussion of open challenges and edge cases that may hinder the
secure and privacy-preserving adoption of LLM-based systems.

</details>


### [18] [Privacy-Preserving Decentralized Federated Learning via Explainable Adaptive Differential Privacy](https://arxiv.org/abs/2509.10691)
*Fardin Jalil Piran,Zhiling Chen,Yang Zhang,Qianyu Zhou,Jiong Tang,Farhad Imani*

Main category: cs.CR

TL;DR: PrivateDFL是一个可解释的去中心化联邦学习框架，结合超维计算和差分隐私，通过审计累积噪声来减少重复噪声添加，在保护隐私的同时提高准确性和效率。


<details>
  <summary>Details</summary>
Motivation: 去中心化联邦学习中模型更新存在隐私泄露风险，差分隐私虽然提供保护但缺乏透明度，导致重复添加噪声而降低准确性。

Method: 提出PrivateDFL框架，将超维计算与差分隐私结合，维护可审计的累积噪声记录，使每个客户端只需添加所需噪声与已累积噪声之间的差值。

Result: 在MNIST、ISOLET和UCI-HAR数据集上，PrivateDFL在IID和非IID分区下均实现更高准确性、更低延迟和能耗，同时保持正式(ε,δ)隐私保证。

Conclusion: 该框架在无中央服务器的情况下有效平衡隐私保护和模型性能，未来工作将扩展到对抗性客户端和异构隐私预算的自适应拓扑。

Abstract: Decentralized federated learning faces privacy risks because model updates
can leak data through inference attacks and membership inference, a concern
that grows over many client exchanges. Differential privacy offers principled
protection by injecting calibrated noise so confidential information remains
secure on resource-limited IoT devices. Yet without transparency, black-box
training cannot track noise already injected by previous clients and rounds,
which forces worst-case additions and harms accuracy. We propose PrivateDFL, an
explainable framework that joins hyperdimensional computing with differential
privacy and keeps an auditable account of cumulative noise so each client adds
only the difference between the required noise and what has already been
accumulated. We evaluate on MNIST, ISOLET, and UCI-HAR to span image, signal,
and tabular modalities, and we benchmark against transformer-based and deep
learning-based baselines trained centrally with Differentially Private
Stochastic Gradient Descent (DP-SGD) and Renyi Differential Privacy (RDP).
PrivateDFL delivers higher accuracy, lower latency, and lower energy across IID
and non-IID partitions while preserving formal (epsilon, delta) guarantees and
operating without a central server. For example, under non-IID partitions,
PrivateDFL achieves 24.42% higher accuracy than the Vision Transformer on MNIST
while using about 10x less training time, 76x lower inference latency, and 11x
less energy, and on ISOLET it exceeds Transformer accuracy by more than 80%
with roughly 10x less training time, 40x lower inference latency, and 36x less
training energy. Future work will extend the explainable accounting to
adversarial clients and adaptive topologies with heterogeneous privacy budgets.

</details>


### [19] [Side-channel Inference of User Activities in AR/VR Using GPU Profiling](https://arxiv.org/abs/2509.10703)
*Seonghun Son,Chandrika Mukherjee,Reham Mohamed Aburas,Berk Gulmezoglu,Z. Berkay Celik*

Main category: cs.CR

TL;DR: OVRWatcher是一种新型侧信道攻击方法，通过监控AR/VR设备的低分辨率GPU使用情况来推断用户活动，无需并发应用执行或特殊权限，准确率超过99%


<details>
  <summary>Details</summary>
Motivation: 现有AR/VR设备恶意应用监控方法在部分设备上不可行，需要开发新的侧信道攻击技术来跟踪用户活动

Method: 通过后台脚本监控1Hz的低分辨率GPU使用情况，捕捉GPU指标与3D对象交互之间的相关性，支持不同速度、距离和渲染场景

Result: 在应用指纹识别方面达到99%以上准确率，在对象级推断方面达到98%以上准确率，能够识别虚拟购物应用中的产品选择和虚拟会议参与者数量

Conclusion: OVRWatcher证明了通过低分辨率GPU监控可以有效推断AR/VR用户活动，揭示了新的隐私风险，需要更强的安全防护措施

Abstract: Over the past decade, AR/VR devices have drastically changed how we interact
with the digital world. Users often share sensitive information, such as their
location, browsing history, and even financial data, within third-party apps
installed on these devices, assuming a secure environment protected from
malicious actors. Recent research has revealed that malicious apps can exploit
such capabilities and monitor benign apps to track user activities, leveraging
fine-grained profiling tools, such as performance counter APIs. However,
app-to-app monitoring is not feasible on all AR/VR devices (e.g., Meta Quest),
as a concurrent standalone app execution is disabled. In this paper, we present
OVRWatcher, a novel side-channel primitive for AR/VR devices that infers user
activities by monitoring low-resolution (1Hz) GPU usage via a background
script, unlike prior work that relies on high-resolution profiling. OVRWatcher
captures correlations between GPU metrics and 3D object interactions under
varying speeds, distances, and rendering scenarios, without requiring
concurrent app execution, access to application data, or additional SDK
installations. We demonstrate the efficacy of OVRWatcher in fingerprinting both
standalone AR/VR and WebXR applications. OVRWatcher also distinguishes virtual
objects, such as products in immersive shopping apps selected by real users and
the number of participants in virtual meetings, thereby revealing users'
product preferences and potentially exposing confidential information from
those meetings. OVRWatcher achieves over 99% accuracy in app fingerprinting and
over 98% accuracy in object-level inference.

</details>


### [20] [Feature-Centric Approaches to Android Malware Analysis: A Survey](https://arxiv.org/abs/2509.10709)
*Shama Maganur,Yili Jiang,Jiaqi Huang,Fangtian Zhong*

Main category: cs.CR

TL;DR: 本文对Android恶意软件分析方法进行了系统性文献综述，重点分析了静态、动态、混合和图基方法的特征提取技术及其在IoT安全中的应用，比较了各种方法的优缺点并提出了未来研究方向。


<details>
  <summary>Details</summary>
Motivation: Android平台的开放性使其成为恶意软件攻击IoT网络的主要入口，导致大规模破坏、数据泄露和拒绝服务攻击，因此需要系统研究Android恶意软件分析方法来保护IoT基础设施安全。

Method: 采用系统性文献综述方法，分析比较了四种主要的Android恶意软件分析技术：静态分析、动态分析、混合分析和图基分析，评估了它们在特征提取、计算成本、抗规避能力等方面的性能表现。

Result: 研究发现静态分析效率高但易被混淆技术规避；动态分析抗规避能力强但计算成本高，不适合轻量级IoT设备；混合方法在准确性和资源消耗间取得平衡；图基方法在语义建模和对抗鲁棒性方面表现优异。

Conclusion: 该研究为Android恶意软件检测提供了结构化比较，揭示了研究空白，并提出了增强IoT环境中恶意软件检测的可扩展性、适应性和长期安全性的未来发展路线图。

Abstract: Sophisticated malware families exploit the openness of the Android platform
to infiltrate IoT networks, enabling large-scale disruption, data exfiltration,
and denial-of-service attacks. This systematic literature review (SLR) examines
cutting-edge approaches to Android malware analysis with direct implications
for securing IoT infrastructures. We analyze feature extraction techniques
across static, dynamic, hybrid, and graph-based methods, highlighting their
trade-offs: static analysis offers efficiency but is easily evaded through
obfuscation; dynamic analysis provides stronger resistance to evasive behaviors
but incurs high computational costs, often unsuitable for lightweight IoT
devices; hybrid approaches balance accuracy with resource considerations; and
graph-based methods deliver superior semantic modeling and adversarial
robustness. This survey contributes a structured comparison of existing
methods, exposes research gaps, and outlines a roadmap for future directions to
enhance scalability, adaptability, and long-term security in IoT-driven Android
malware detection.

</details>


### [21] [Security theory for data flow and access control: From partial orders to lattices and back, a half-century trip](https://arxiv.org/abs/2509.10727)
*Luigi Logrippo*

Main category: cs.CR

TL;DR: 本文认为基于偏序理论的多级Bell La Padula模型比基于格理论的模型更适合安全数据访问控制，并通过示例展示如何使用基于属性的访问控制(ABAC)实现非格数据流网络。


<details>
  <summary>Details</summary>
Motivation: 重新评估1970年代提出的基于偏序理论的多级Bell La Padula模型，论证其相对于后来盛行的基于格理论的模型具有更合适的理论基础。

Method: 通过理论分析和示例演示，说明基于偏序的模型如何通过属性基访问控制(ABAC)实现非格结构的数据流网络。

Result: 证明了偏序模型在安全数据访问控制中的适用性，并展示了ABAC在实现复杂数据流控制方面的灵活性。

Conclusion: 基于偏序理论的多级Bell La Padula模型比格理论模型更适合现代安全数据访问控制需求，ABAC为实现非格数据流网络提供了有效解决方案。

Abstract: The multi level Bell La Padula model for secure data access and data flow
control, formulated in the 1970s, was based on the theory of partial orders.
Since then, another model, based on lattice theory, has prevailed. We present
reasons why the partial order model is more appropriate. We also show, by
example, how non lattice data flow networks can be easily implemented by using
Attribute-based access control (ABAC).

</details>


### [22] [Five Minutes of DDoS Brings down Tor: DDoS Attacks on the Tor Directory Protocol and Mitigations](https://arxiv.org/abs/2509.10755)
*Zhongtang Luo,Jianting Zhang,Akshat Neerati,Aniket Kate*

Main category: cs.CR

TL;DR: 本文发现Tor目录协议存在同步性假设漏洞，可通过DDoS攻击以每月53.28美元的成本瘫痪整个Tor网络，并提出了基于部分同步假设的新协议来增强安全性。


<details>
  <summary>Details</summary>
Motivation: 当前Tor目录协议采用严格的同步假设，使其容易受到自然和对抗性非同步通信场景的影响，特别是DDoS攻击威胁整个Tor网络的可用性。

Method: 通过控制环境演示DDoS攻击的有效性，设计基于部分同步共识协议的新Tor目录协议，使用Rust实现原型并证明其安全性。

Result: 攻击实验显示仅需5分钟针对多数权威节点的DDoS攻击就能破坏协议，防御方案在保持性能的同时有效抵抗类似攻击。

Conclusion: Tor目录协议需要从严格同步假设转向部分同步模型，新设计的协议在保持性能的同时显著提升了网络抗攻击能力。

Abstract: The Tor network offers network anonymity to its users by routing their
traffic through a sequence of relays. A group of nine directory authorities
maintains information about all available relay nodes using a distributed
directory protocol. We observe that the current protocol makes a steep
synchrony assumption, which makes it vulnerable to natural as well as
adversarial non-synchronous communication scenarios over the Internet. In this
paper, we show that it is possible to cause a failure in the Tor directory
protocol by targeting a majority of the authorities for only five minutes using
a well-executed distributed denial-of-service (DDoS) attack. We demonstrate
this attack in a controlled environment and show that it is cost-effective for
as little as \$53.28 per month to disrupt the protocol and to effectively bring
down the entire Tor network. To mitigate this problem, we consider the popular
partial synchrony assumption for the Tor directory protocol that ensures that
the protocol security is hampered even when the network delays are large and
unknown. We design a new Tor directory protocol that leverages any standard
partial-synchronous consensus protocol to solve this problem, while also
proving its security. We have implemented a prototype in Rust, demonstrating
comparable performance to the current protocol while resisting similar attacks.

</details>


### [23] [A Content-dependent Watermark for Safeguarding Image Attribution](https://arxiv.org/abs/2509.10766)
*Tong Zhou,Ruyi Ding,Gaowen Liu,Charles Fleming,Ramana Rao Kompella,Yunsi Fei,Xiaolin Xu,Shaolei Ren*

Main category: cs.CR

TL;DR: MetaSeal是一个具有密码学安全保证的内容依赖水印框架，用于保护图像归属，防止伪造并提供篡改证据


<details>
  <summary>Details</summary>
Motivation: 数字和AI生成图像的快速增长需要安全可验证的图像归属方法。现有水印技术易受伪造攻击，存在错误归属风险，可能损害AI模型开发者的声誉和数字艺术家的权利

Method: 提出MetaSeal框架，采用内容依赖水印技术，提供密码学安全保证。设计具有防伪造能力、鲁棒的自包含保护以及篡改证据检测功能

Result: 实验证明MetaSeal能有效减轻伪造尝试，适用于自然图像和AI生成图像，为安全图像归属设立了新标准

Conclusion: MetaSeal通过内容依赖水印和密码学安全机制，解决了当前水印技术的脆弱性问题，为图像归属保护提供了更可靠的解决方案

Abstract: The rapid growth of digital and AI-generated images has amplified the need
for secure and verifiable methods of image attribution. While digital
watermarking offers more robust protection than metadata-based
approaches--which can be easily stripped--current watermarking techniques
remain vulnerable to forgery, creating risks of misattribution that can damage
the reputations of AI model developers and the rights of digital artists. These
vulnerabilities arise from two key issues: (1) content-agnostic watermarks,
which, once learned or leaked, can be transferred across images to fake
attribution, and (2) reliance on detector-based verification, which is
unreliable since detectors can be tricked. We present MetaSeal, a novel
framework for content-dependent watermarking with cryptographic security
guarantees to safeguard image attribution. Our design provides (1) forgery
resistance, preventing unauthorized replication and enforcing cryptographic
verification; (2) robust, self-contained protection, embedding attribution
directly into images while maintaining resilience against benign
transformations; and (3) evidence of tampering, making malicious alterations
visually detectable. Experiments demonstrate that MetaSeal effectively
mitigates forgery attempts and applies to both natural and AI-generated images,
establishing a new standard for secure image attribution.

</details>


### [24] [ORQ: Complex Analytics on Private Data with Strong Security Guarantees](https://arxiv.org/abs/2509.10793)
*Eli Baum,Sam Buxbaum,Nitin Mathai,Muhammad Faisal,Vasiliki Kalavri,Mayank Varia,John Liagouris*

Main category: cs.CR

TL;DR: ORQ是一个基于多方安全计算(MPC)的协作数据分析系统，能够高效处理包含多表连接和聚合的关系查询，显著降低了MPC执行时间并支持更大规模数据集的处理。


<details>
  <summary>Details</summary>
Motivation: 现有的MPC技术在处理关系查询时存在二次成本问题，特别是在多表连接和聚合操作上效率低下，无法满足大规模私有数据集的安全协作分析需求。

Method: ORQ通过创新的"即时连接和聚合"方法消除安全连接的二次成本，包含通用无感知操作符、数据并行向量化查询引擎、通信层优化MPC网络成本，以及数据流API等技术组件。

Result: 在LAN和WAN部署中，ORQ相比现有技术显著减少MPC执行时间，能够处理规模大一个数量级的数据集，成功在TPC-H基准测试Scale Factor 10下实现完全MPC处理。

Conclusion: ORQ系统证明了MPC技术可以高效处理复杂的关系查询，为大规模私有数据的安全协作分析提供了可行的解决方案，突破了此前只能通过信息泄露或可信第三方实现的性能限制。

Abstract: We present ORQ, a system that enables collaborative analysis of large private
datasets using cryptographically secure multi-party computation (MPC). ORQ
protects data against semi-honest or malicious parties and can efficiently
evaluate relational queries with multi-way joins and aggregations that have
been considered notoriously expensive under MPC. To do so, ORQ eliminates the
quadratic cost of secure joins by leveraging the fact that, in practice, the
structure of many real queries allows us to join records and apply the
aggregations "on the fly" while keeping the result size bounded. On the system
side, ORQ contributes generic oblivious operators, a data-parallel vectorized
query engine, a communication layer that amortizes MPC network costs, and a
dataflow API for expressing relational analytics -- all built from the ground
up.
  We evaluate ORQ in LAN and WAN deployments on a diverse set of workloads,
including complex queries with multiple joins and custom aggregations. When
compared to state-of-the-art solutions, ORQ significantly reduces MPC execution
times and can process one order of magnitude larger datasets. For our most
challenging workload, the full TPC-H benchmark, we report results entirely
under MPC with Scale Factor 10 -- a scale that had previously been achieved
only with information leakage or the use of trusted third parties.

</details>


### [25] [Automatic Generation of a Cryptography Misuse Taxonomy Using Large Language Models](https://arxiv.org/abs/2509.10814)
*Yang Zhang,Wenyi Ouyang,Yi Zhang,Liang Cheng,Chen Wu,Wenxin Hu*

Main category: cs.CR

TL;DR: 利用大型语言模型自动检测和分类密码学API误用，构建了包含279个基础类别的分类体系，其中36个是现有分类未涵盖的新类型，有效提升了检测工具的覆盖能力。


<details>
  <summary>Details</summary>
Motivation: 密码学API误用严重威胁系统安全，现有检测工具依赖有限的人工规则，难以适应不断演变的误用模式，需要更智能的检测方法。

Method: 开发LLM无关的提示工程方法，指导GPT、Llama、Gemini和Claude等主流大语言模型从C/C++、Java、Python和Go代码中检测密码学API误用实例，并进行层次化分类。

Result: 在3,492个真实软件程序数据集上验证了方法的有效性，构建了包含279个基础类别的分类体系（其中36个是新类型），将11个新类型编码为检测规则后成功集成到现有工具中，扩展了检测能力。

Conclusion: 基于大语言模型的方法能够自动发现和分类密码学API误用模式，构建动态可扩展的分类体系，为开发者和检测工具提供持续跟踪和理解新兴误用模式的能力。

Abstract: The prevalence of cryptographic API misuse (CAM) is compromising the
effectiveness of cryptography and in turn the security of modern systems and
applications. Despite extensive efforts to develop CAM detection tools, these
tools typically rely on a limited set of predefined rules from human-curated
knowledge. This rigid, rule-based approach hinders adaptation to evolving CAM
patterns in real practices.
  We propose leveraging large language models (LLMs), trained on publicly
available cryptography-related data, to automatically detect and classify CAMs
in real-world code to address this limitation. Our method enables the
development and continuous expansion of a CAM taxonomy, supporting developers
and detection tools in tracking and understanding emerging CAM patterns.
Specifically, we develop an LLM-agnostic prompt engineering method to guide
LLMs in detecting CAM instances from C/C++, Java, Python, and Go code, and then
classifying them into a hierarchical taxonomy.
  Using a data set of 3,492 real-world software programs, we demonstrate the
effectiveness of our approach with mainstream LLMs, including GPT, Llama,
Gemini, and Claude. It also allows us to quantitatively measure and compare the
performance of these LLMs in analyzing CAM in realistic code. Our evaluation
produced a taxonomy with 279 base CAM categories, 36 of which are not addressed
by existing taxonomies. To validate its practical value, we encode 11 newly
identified CAM types into detection rules and integrate them into existing
tools. Experiments show that such integration expands the tools' detection
capabilities.

</details>


### [26] [From Paradigm Shift to Audit Rift: Exploring Vulnerabilities and Audit Tips for TON Smart Contracts](https://arxiv.org/abs/2509.10823)
*Yury Yanovich,Sergey Sobolev,Yash Madhwal,Kirill Ziborov,Vladimir Gorgadze,Victoria Kovalevskay,Elizaveta Smirnova,Matvey Mishuris,Subodh Sharma*

Main category: cs.CR

TL;DR: 本文基于对34份专业审计报告的分析，提出了TON智能合约的全面审计清单，包含233个真实漏洞案例，旨在提升TON生态系统的安全性。


<details>
  <summary>Details</summary>
Motivation: TON区块链平台虽然具有高性能优势，但其异步执行模型和多层架构为智能合约开发带来了独特的安全挑战，需要专门的审计方法来应对这些挑战。

Method: 通过分析34份专业审计报告中的233个真实漏洞，开发了一个针对TON智能合约的全面审计清单，包括异步消息处理等TON特有问题的检查项。

Result: 创建了一个实用的审计清单，帮助开发者和审计人员系统性地识别和缓解漏洞，并通过详细案例研究展示了漏洞的影响和应对经验。

Conclusion: 该审计清单填补了以太坊成熟审计方法与TON生态系统新兴需求之间的空白，有助于构建更安全可靠的区块链环境。

Abstract: The Open Network (TON) is a high-performance blockchain platform designed for
scalability and efficiency, leveraging an asynchronous execution model and a
multi-layered architecture. While TON's design offers significant advantages,
it also introduces unique challenges for smart contract development and
security. This paper introduces a comprehensive audit checklist for TON smart
contracts, based on an analysis of 34 professional audit reports containing 233
real-world vulnerabilities. The checklist addresses TON-specific challenges,
such as asynchronous message handling, and provides actionable insights for
developers and auditors. We also present detailed case studies of
vulnerabilities in TON smart contracts, highlighting their implications and
offering lessons learned. By adopting this checklist, developers and auditors
can systematically identify and mitigate vulnerabilities, enhancing the
security and reliability of TON-based projects. Our work bridges the gap
between Ethereum's mature audit methodologies and the emerging needs of the TON
ecosystem, fostering a more secure and robust blockchain environment.

</details>


### [27] [A Comparison of Selected Image Transformation Techniques for Malware Classification](https://arxiv.org/abs/2509.10838)
*Rishit Agrawal,Kunal Bhatnagar,Andrew Do,Ronnit Rana,Mark Stamp*

Main category: cs.CR

TL;DR: 本文研究了8种不同的恶意软件转图像技术，发现尽管转换过程差异很大，但多种技术在多种学习模型下表现相似，表明基于图像的恶意软件分类效果更多取决于图像分析技术本身而非具体的转换策略细节。


<details>
  <summary>Details</summary>
Motivation: 当前恶意软件研究中广泛使用基于图像的机器学习技术，但缺乏标准化的恶意软件转图像方法，现有方法往往显得随意且未充分考虑可执行文件特性。

Method: 实验了8种不同的恶意软件转图像转换技术，并对每种技术测试了多种学习模型。

Result: 发现多种图像转换技术在不同学习模型下表现相似，尽管图像转换过程差异很大。

Conclusion: 基于图像的恶意软件分类技术的有效性更多取决于图像分析技术的内在优势，而不是图像转换策略的具体细节。

Abstract: Recently, a considerable amount of malware research has focused on the use of
powerful image-based machine learning techniques, which generally yield
impressive results. However, before image-based techniques can be applied to
malware, the samples must be converted to images, and there is no
generally-accepted approach for doing so. The malware-to-image conversion
strategies found in the literature often appear to be ad hoc, with little or no
effort made to take into account properties of executable files. In this paper,
we experiment with eight distinct malware-to-image conversion techniques, and
for each, we test a variety of learning models. We find that several of these
image conversion techniques perform similarly across a range of learning
models, in spite of the image conversion processes being quite different. These
results suggest that the effectiveness of image-based malware classification
techniques may depend more on the inherent strengths of image analysis
techniques, as opposed to the precise details of the image conversion strategy.

</details>


### [28] [Large Language Models for Security Operations Centers: A Comprehensive Survey](https://arxiv.org/abs/2509.10858)
*Ali Habibzadeh,Farid Feyzi,Reza Ebrahimi Atani*

Main category: cs.CR

TL;DR: 本调查系统探讨了将生成式AI特别是大语言模型集成到安全运营中心工作流中的能力、挑战和未来方向，这是首个详细研究LLM在SOC中应用的全面研究。


<details>
  <summary>Details</summary>
Motivation: 安全运营中心面临高警报量、资源有限、专家需求大、响应延迟和威胁情报利用困难等挑战，LLM有潜力通过自动化日志分析、简化分类、提高检测准确性和快速提供知识来解决这些问题。

Method: 采用系统性调查方法，对生成式AI特别是LLM在SOC工作流中的集成进行结构化分析，包括能力评估、挑战识别和未来方向探讨。

Result: 研究提供了LLM在SOC中应用的全面概述，展示了其在自动化日志分析、事件分类、检测准确性提升和知识支持方面的潜力。

Conclusion: LLM为SOC运营提供了有前景的解决方案，这项调查为研究人员和SOC管理者提供了当前LLM集成状态的广泛概述，是首个详细研究LLM在SOC中应用的全面工作。

Abstract: Large Language Models (LLMs) have emerged as powerful tools capable of
understanding and generating human-like text, offering transformative potential
across diverse domains. The Security Operations Center (SOC), responsible for
safeguarding digital infrastructure, represents one of these domains. SOCs
serve as the frontline of defense in cybersecurity, tasked with continuous
monitoring, detection, and response to incidents. However, SOCs face persistent
challenges such as high alert volumes, limited resources, high demand for
experts with advanced knowledge, delayed response times, and difficulties in
leveraging threat intelligence effectively. In this context, LLMs can offer
promising solutions by automating log analysis, streamlining triage, improving
detection accuracy, and providing the required knowledge in less time. This
survey systematically explores the integration of generative AI and more
specifically LLMs into SOC workflow, providing a structured perspective on its
capabilities, challenges, and future directions. We believe that this survey
offers researchers and SOC managers a broad overview of the current state of
LLM integration within academic study. To the best of our knowledge, this is
the first comprehensive study to examine LLM applications in SOCs in details.

</details>


### [29] [Finding SSH Strict Key Exchange Violations by State Learning](https://arxiv.org/abs/2509.10895)
*Fabian Bäumer,Marcel Maehren,Marcus Brinkmann,Jörg Schwenk*

Main category: cs.CR

TL;DR: 分析SSH严格密钥交换(strict KEX)实现的安全性，发现多个实现违反规范并存在严重安全漏洞


<details>
  <summary>Details</summary>
Motivation: SSH协议在USENIX 2024年遭受Terrapin攻击后，厂商采用strict KEX作为防御措施，但该扩展的实际实现安全性尚未得到充分验证

Method: 使用黑盒状态学习技术分析10个支持strict KEX的SSH实现，学习33个状态机，检查是否符合规范

Result: 发现7个实现违反strict KEX规范，识别出2个关键安全漏洞：Tectia SSH的恶意会话攻击和Erlang SSH的未认证远程代码执行

Conclusion: 虽然strict KEX设计上能防御Terrapin攻击，但实际实现存在严重安全问题，需要更严格的验证和测试

Abstract: SSH is an important protocol for secure remote shell access to servers on the
Internet. At USENIX 2024, B\"aumer et al. presented the Terrapin attack on SSH,
which relies on the attacker injecting optional messages during the key
exchange. To mitigate this attack, SSH vendors adopted an extension developed
by OpenSSH called strict key exchange ("strict KEX"). With strict KEX, optional
messages are forbidden during the handshake, preventing the attack. In
practice, this should simplify the state machine of an SSH handshake to a
linear message flow similar to that of TLS.
  In this work, we analyze the design, implementation, and security of strict
KEX in popular SSH servers, using black-box state learning, which can uncover
the hidden state machine of an implementation. In practice, it is limited by
the number of learned messages and the complexity of the state machine. Thus,
learning the complete state machine of SSH is infeasible. Previous research on
SSH, therefore, excluded optional messages, learning only a partial state
machine. However, these messages are a critical part of the Terrapin attack. We
propose to instead learn the complete state machine of the handshake phase of
an SSH server, but with strict KEX enabled.
  We investigate the security of ten SSH implementations supporting strict KEX
for up to five key exchange algorithms. In total, we learn 33 state machines,
revealing significant differences in the implementations. We show that seven
implementations violate the strict KEX specification and find two critical
security vulnerabilities. One results in a rogue session attack in the
proprietary Tectia SSH implementation. Another affects the official SSH
implementation of the Erlang Open Telecom Platform, and enables unauthenticated
remote code execution in the security context of the SSH server.

</details>


### [30] [A Range-Based Sharding (RBS) Protocol for Scalable Enterprise Blockchain](https://arxiv.org/abs/2509.11006)
*M. Z. Haider,M. Dias de Assuncao,Kaiwen Zhang*

Main category: cs.CR

TL;DR: 提出了针对企业区块链的Range-Based Sharding协议，通过提交-揭示方案实现公平分片分配，显著提升吞吐量和降低延迟


<details>
  <summary>Details</summary>
Motivation: 区块链技术在企业环境中面临可扩展性挑战，现有分片方案存在协调困难、容错性差和共识开销大的问题

Method: 基于Quorum实现Range-Based Sharding协议，采用提交-揭示方案进行安全无偏的分片分配，平衡计算负载并减少跨分片交易延迟

Result: 实验评估显示RBS相比现有企业分片框架实现了显著更高的吞吐量和更低的延迟

Conclusion: RBS是企业大规模区块链部署的高效可行解决方案，通过优化分片机制有效解决了可扩展性问题

Abstract: Blockchain technology offers decentralization and security but struggles with
scalability, particularly in enterprise settings where efficiency and
controlled access are paramount. Sharding is a promising solution for private
blockchains, yet existing approaches face challenges in coordinating shards,
ensuring fault tolerance with limited nodes, and minimizing the high overhead
of consensus mechanisms like PBFT. This paper proposes the Range-Based Sharding
(RBS) Protocol, a novel sharding mechanism tailored for enterprise blockchains,
implemented on Quorum. Unlike traditional sharding models such as OmniLedger
and non-sharding Corda framework, RBS employs a commit-reveal scheme for secure
and unbiased shard allocation, ensuring fair validator distribution while
reducing cross-shard transaction delays. Our approach enhances scalability by
balancing computational loads across shards, reducing consensus overhead, and
improving parallel transaction execution. Experimental evaluations demonstrate
that RBS achieves significantly higher throughput and lower latency compared to
existing enterprise sharding frameworks, making it a viable and efficient
solution for largescale blockchain deployments.

</details>


### [31] [SoK: How Sensor Attacks Disrupt Autonomous Vehicles: An End-to-end Analysis, Challenges, and Missed Threats](https://arxiv.org/abs/2509.11120)
*Qingzhao Zhang,Shaocheng Luo,Z. Morley Mao,Miroslav Pajic,Michael K. Reiter*

Main category: cs.CR

TL;DR: 本文提出了系统错误传播图（SEPG）来分析自动驾驶车辆传感器攻击在系统级传播的可行性，发现了11个新的攻击向量，并展示了LLM在自动化安全评估中的应用。


<details>
  <summary>Details</summary>
Motivation: 自动驾驶车辆依赖复杂的传感器系统，但现有研究缺乏对传感器攻击在真实端到端系统中可行性的系统性理解，特别是攻击如何通过系统模块传播。

Method: 使用系统错误传播图（SEPG）结构化分析传感器攻击在不同平台、传感器模态和攻击方法中的传播路径，并通过概念验证实验验证发现。

Result: 提炼出7个关键发现，揭示了11个先前被忽视的攻击向量，展示了LLM在自动化SEPG构建和专家分析交叉验证方面的潜力。

Conclusion: SEPG为理解传感器攻击在自动驾驶系统中的传播提供了系统性框架，揭示了新的攻击向量，并证明了AI辅助安全评估的可行性。

Abstract: Autonomous vehicles, including self-driving cars, robotic ground vehicles,
and drones, rely on complex sensor pipelines to ensure safe and reliable
operation. However, these safety-critical systems remain vulnerable to
adversarial sensor attacks that can compromise their performance and mission
success. While extensive research has demonstrated various sensor attack
techniques, critical gaps remain in understanding their feasibility in
real-world, end-to-end systems. This gap largely stems from the lack of a
systematic perspective on how sensor errors propagate through interconnected
modules in autonomous systems when autonomous vehicles interact with the
physical world.
  To bridge this gap, we present a comprehensive survey of autonomous vehicle
sensor attacks across platforms, sensor modalities, and attack methods. Central
to our analysis is the System Error Propagation Graph (SEPG), a structured
demonstration tool that illustrates how sensor attacks propagate through system
pipelines, exposing the conditions and dependencies that determine attack
feasibility. With the aid of SEPG, our study distills seven key findings that
highlight the feasibility challenges of sensor attacks and uncovers eleven
previously overlooked attack vectors exploiting inter-module interactions,
several of which we validate through proof-of-concept experiments.
Additionally, we demonstrate how large language models (LLMs) can automate
aspects of SEPG construction and cross-validate expert analysis, showcasing the
promise of AI-assisted security evaluation.

</details>


### [32] [ODoQ: Oblivious DNS-over-QUIC](https://arxiv.org/abs/2509.11123)
*Aditya Kulkarni,Tamal Das,Vivek Balachandran*

Main category: cs.CR

TL;DR: 提出ODoQ协议，结合QUIC协议和代理服务器，在保护用户隐私的同时降低DNS解析延迟


<details>
  <summary>Details</summary>
Motivation: 现有DNS隐私协议要么侧重用户隐私保护（如Oblivious DNS），要么侧重降低解析延迟（如DNS-over-QUIC），缺乏能同时实现两者的单一协议

Method: 设计Oblivious DNS-over-QUIC（ODoQ）协议，利用QUIC协议的优势并引入中间代理服务器来保护客户端身份不被递归解析器暴露

Result: 成功开发出ODoQ协议，能够同时提供用户隐私保护和低延迟DNS解析

Conclusion: ODoQ协议有效解决了DNS隐私保护与性能优化的双重需求，为DNS安全提供了新的解决方案

Abstract: The Domain Name System (DNS), which converts domain names to their respective
IP addresses, has advanced enhancements aimed at safeguarding DNS data and
users' identity from attackers. The recent privacy-focused advancements have
enabled the IETF to standardize several protocols. Nevertheless, these
protocols tend to focus on either strengthening user privacy (like Oblivious
DNS and Oblivious DNS-over-HTTPS) or reducing resolution latency (as
demonstrated by DNS-over-QUIC). Achieving both within a single protocol remains
a key challenge, which we address in this paper. Our proposed protocol --
'Oblivious DNS-over-QUIC' (ODoQ) -- leverages the benefits of the QUIC protocol
and incorporates an intermediary proxy server to protect the client's identity
from exposure to the recursive resolver.

</details>


### [33] [Cryptanalysis and design for a family of plaintext non-delayed chaotic ciphers](https://arxiv.org/abs/2509.11158)
*Qianxue Wang,Simin Yu*

Main category: cs.CR

TL;DR: 本文分析了无延迟明文混沌密码(PNDCC)的安全漏洞，提出了四种攻击方法并证明统计测试不足以保证其安全性，最后提出了改进的明文延迟混沌密码(PDCC)方案。


<details>
  <summary>Details</summary>
Motivation: 重新审视PNDCC的设计原理和实证安全性，因为现有混沌密码设计通常仅通过统计测试来声称安全性，缺乏严格的密码学证明。

Method: 提出了一个典型的三阶段置换-扩散-置换PNDCC实例，展示了四种攻击方法：基于同构操作的差分攻击、S-PTC攻击、新型脉冲步进差分攻击(ISBDA)和新型链式攻击。

Result: 成功破解了多阶段PNDCC类密码，证明统计指标良好并不足以保证安全性，并提出了可抵抗各种密码分析的PDCC改进方案。

Conclusion: PNDCC存在严重安全漏洞，统计测试不是安全性的充分条件，提出的PDCC方案能够有效抵抗各种密码分析攻击。

Abstract: Plaintext non-delayed chaotic cipher (PNDCC) means that in the diffusion
equation, plaintext has no delay terms while ciphertext has a feedback term. In
existing literature, chaotic cipher diffusions invariably take this form. Since
its introduction, PNDCC has attracted attention but also doubts. Designers of
chaotic ciphers usually claim PNDCC security by statistical tests, while
rigorous cryptographic proofs are absent. Thus, it is necessary to re-examine
its design rationale and empirical security. To address this issue, we present
a typical example of a three-stage permutation-diffusion-permutation PNDCC,
which contains multiple security vulnerabilities. Although all of its
statistical indicators show good performance, we are able to break it using
four different attacks. The first is a differential attack based on homogeneous
operations; the second is an S-PTC attack; the third is a novel
impulse-step-based differential attack (ISBDA), proposed in this paper, and the
fourth is a novel chain attack, also introduced here. These results demonstrate
that the fulfilment of statistical criteria is not a sufficient condition for
the security of PNDCC. Then, based on a mathematical model of multi-stage
PNDCC, we show that the proposed chain attack can successfully break a class of
multi-stage PNDCCs. The key technique of the chain attack depends on how to
reveal all permutations. To address this key problem, we summarize the chaining
rules and show that, from the attacker's perspective, if the same decryption
chain can be reconstructed then all permutations can be deciphered. To that
end, the entire diffusion process can be broken by solving a system of
simultaneous equations. Finally, as a secure improvement, we propose a new
scheme termed plaintext-delayed chaotic cipher (PDCC) that can resist various
cryptanalytic attacks.

</details>


### [34] [Your Compiler is Backdooring Your Model: Understanding and Exploiting Compilation Inconsistency Vulnerabilities in Deep Learning Compilers](https://arxiv.org/abs/2509.11173)
*Simin Chen,Jinjun Peng,Yixin He,Junfeng Yang,Baishakhi Ray*

Main category: cs.CR

TL;DR: 深度学习编译器存在根本性安全漏洞，未经修改的官方编译器可在编译过程中改变模型语义并植入隐藏后门，在对抗和自然场景下均存在风险


<details>
  <summary>Details</summary>
Motivation: 揭示深度学习编译器设计中的固有安全风险，研究官方未修改编译器是否能在编译过程中改变模型语义并引入隐藏后门

Method: 研究对抗性和自然性两种场景：对抗场景下制作良性模型，使触发器在编译前无效但在编译后成为有效后门；自然场景下分析HuggingFace前100个模型

Result: 在6个模型、3个商业编译器和2个硬件平台上测试，攻击对触发输入成功率100%，保持正常精度且不被最先进检测器发现；31个模型中发现自然触发器

Conclusion: 深度学习编译器可能在不经对抗操作的情况下引入风险，揭示了编译器设计中被忽视的安全威胁，为安全可信机器学习开辟了新研究方向

Abstract: Deep learning (DL) compilers are core infrastructure in modern DL systems,
offering flexibility and scalability beyond vendor-specific libraries. This
work uncovers a fundamental vulnerability in their design: can an official,
unmodified compiler alter a model's semantics during compilation and introduce
hidden backdoors? We study both adversarial and natural settings. In the
adversarial case, we craft benign models where triggers have no effect
pre-compilation but become effective backdoors after compilation. Tested on six
models, three commercial compilers, and two hardware platforms, our attack
yields 100% success on triggered inputs while preserving normal accuracy and
remaining undetected by state-of-the-art detectors. The attack generalizes
across compilers, hardware, and floating-point settings. In the natural
setting, we analyze the top 100 HuggingFace models (including one with 220M+
downloads) and find natural triggers in 31 models. This shows that compilers
can introduce risks even without adversarial manipulation.
  Our results reveal an overlooked threat: unmodified DL compilers can silently
alter model semantics. To our knowledge, this is the first work to expose
inherent security risks in DL compiler design, opening a new direction for
secure and trustworthy ML.

</details>


### [35] [DMLDroid: Deep Multimodal Fusion Framework for Android Malware Detection with Resilience to Code Obfuscation and Adversarial Perturbations](https://arxiv.org/abs/2509.11187)
*Doan Minh Trung,Tien Duc Anh Hao,Luong Hoang Minh,Nghi Hoang Khoa,Nguyen Tan Cam,Van-Hau Pham,Phan The Duy*

Main category: cs.CR

TL;DR: DMLDroid是一个基于多模态融合的Android恶意软件检测系统，结合权限意图、DEX文件图像和API调用序列三种特征表示，通过动态加权融合机制实现了高精度检测和强鲁棒性。


<details>
  <summary>Details</summary>
Motivation: 现有的Android恶意软件检测方法（基于字符串、图像和图的方法）在真实环境中面对代码混淆和对抗样本时鲁棒性不足，多模态学习虽然前景广阔但缺乏系统性研究。

Method: 提出DMLDroid多模态融合检测方法，整合三种特征表示：权限意图（表格型）、DEX文件表示（图像型）、API调用（图衍生序列型），采用不同的融合策略进行实验。

Result: 在CICMalDroid 2020数据集上，动态加权融合机制达到97.98%准确率和98.67% F1分数，在混淆和对抗攻击场景下仍保持超过98%的准确率和F1分数。

Conclusion: 多模态融合能显著提升Android恶意软件检测的准确性和对不断演变的威胁的鲁棒性。

Abstract: In recent years, learning-based Android malware detection has seen
significant advancements, with detectors generally falling into three
categories: string-based, image-based, and graph-based approaches. While these
methods have shown strong detection performance, they often struggle to sustain
robustness in real-world settings, particularly when facing code obfuscation
and adversarial examples (AEs). Deep multimodal learning has emerged as a
promising solution, leveraging the strengths of multiple feature types to
enhance robustness and generalization. However, a systematic investigation of
multimodal fusion for both accuracy and resilience remains underexplored. In
this study, we propose DMLDroid, an Android malware detection based on
multimodal fusion that leverages three different representations of malware
features, including permissions & intents (tabular-based), DEX file
representations (image-based), and API calls (graph-derived sequence-based). We
conduct exhaustive experiments independently on each feature, as well as in
combination, using different fusion strategies. Experimental results on the
CICMalDroid 2020 dataset demonstrate that our multimodal approach with the
dynamic weighted fusion mechanism achieves high performance, reaching 97.98%
accuracy and 98.67% F1-score on original malware detection. Notably, the
proposed method maintains strong robustness, sustaining over 98% accuracy and
98% F1-score under both obfuscation and adversarial attack scenarios. Our
findings highlight the benefits of multimodal fusion in improving both
detection accuracy and robustness against evolving Android malware threats.

</details>


### [36] [Implementation of Learning with Errors in Non-Commuting Multiplicative Groups](https://arxiv.org/abs/2509.11237)
*Aleksejus Mihalkovič,Lina Dindiene,Eligijus Sakalauskas*

Main category: cs.CR

TL;DR: 将LWE推广到非交换的模极大循环群M2t，利用其双循环结构构造消息恢复准则，实现与原始LWE相当的安全级别


<details>
  <summary>Details</summary>
Motivation: 将学习错误问题(LWE)从交换群推广到非交换群，探索非交换性在密码学中的潜在优势

Method: 利用模极大循环群M2t的两个极大乘法阶循环结构，构造消息位恢复准则，并基于Regev原始思想在非交换群中实现

Result: 成功实现了在非交换群M2t中的LWE推广，能够以压倒性概率恢复消息位

Conclusion: 该方法能够在非交换群中达到与原始LWE方案相当的安全级别，为非交换群在密码学中的应用提供了新途径

Abstract: In this paper, we demonstrate a way to generalize learning with errors (LWE)
to the family of so-called modular-maximal cyclic groups which are
non-commuting. Since the group M2t has two cycles of maximal multiplicative
order, we use this fact to construct an accurate criterion for restoring the
message bit with overwhelming probability. Furthermore, we implement the
original idea by O. Regev in the considered group to gain benefits from the
non-commutativity of M2t . Also we prove that using this approach we can
achieve a level of security comparable to the original idea.

</details>


### [37] [Exploring and Exploiting the Resource Isolation Attack Surface of WebAssembly Containers](https://arxiv.org/abs/2509.11242)
*Zhaofeng Yu,Dongyang Zhan,Lin Ye,Haining Yu,Hongli Zhang,Zhihong Tian*

Main category: cs.CR

TL;DR: 本文系统分析了WebAssembly运行时的资源隔离攻击面，发现通过WASI/WASIX接口可以耗尽主机资源并干扰其他容器实例，提出了静态分析方法和利用策略，实验证明恶意Wasm实例能导致系统性能显著下降。


<details>
  <summary>Details</summary>
Motivation: 虽然WebAssembly被设计为安全的容器运行时，但当前Wasm运行时在资源隔离方面存在不足，攻击者可以通过WASI/WASIX接口耗尽主机资源来干扰其他容器实例的执行，这一攻击面尚未得到充分探索和测量。

Method: 提出了几种静态Wasm运行时分析方法来系统探索资源隔离攻击面，基于分析结果提出了多种利用策略来破坏Wasm运行时的资源隔离。

Result: 实验结果表明，恶意Wasm实例不仅能消耗大量系统资源，还能向底层操作系统的其他组件引入高工作负载，导致整个系统的性能显著下降。

Conclusion: Wasm运行时的资源隔离存在安全风险，需要采取缓解措施来加强保护，本文的研究为理解和解决这一问题提供了重要见解。

Abstract: Recently, the WebAssembly (or Wasm) technology has been rapidly evolving,
with many runtimes actively under development, providing cross-platform secure
sandboxes for Wasm modules to run as portable containers. Compared with Docker,
which isolates applications at the operating system level, Wasm runtimes
provide more security mechanisms, such as linear memory, type checking, and
protected call stacks. Although Wasm is designed with security in mind and
considered to be a more secure container runtime, various security challenges
have arisen, and researchers have focused on the security of Wasm runtimes,
such as discovering vulnerabilities or proposing new security mechanisms to
achieve robust isolation. However, we have observed that the resource isolation
is not well protected by the current Wasm runtimes, and attackers can exhaust
the host's resources to interfere with the execution of other container
instances by exploiting the WASI/WASIX interfaces. And the attack surface has
not been well explored and measured. In this paper, we explore the resource
isolation attack surface of Wasm runtimes systematically by proposing several
static Wasm runtime analysis approaches. Based on the analysis results, we
propose several exploitation strategies to break the resource isolation of Wasm
runtimes. The experimental results show that malicious Wasm instances can not
only consume large amounts of system resources on their own but also introduce
high workloads into other components of the underlying operating system,
leading to a substantial performance degradation of the whole system. In
addition, the mitigation approaches have also been discussed.

</details>


### [38] [Make Identity Unextractable yet Perceptible: Synthesis-Based Privacy Protection for Subject Faces in Photos](https://arxiv.org/abs/2509.11249)
*Tao Wang,Yushu Zhang,Xiangli Xiao,Kun Xu,Lin Yuan,Wenying Wen,Yuming Fang*

Main category: cs.CR

TL;DR: 本文揭示了基于扰动的面部隐私保护方法存在虚假隐私保护问题，提出了首个基于合成的面部隐私保护方法PerceptFace，在身份保护和身份感知之间实现了优越的平衡。


<details>
  <summary>Details</summary>
Motivation: 深度学习面部识别技术加剧了照片分享中的隐私问题，现有基于扰动的方法虽然允许熟人肉眼识别但存在隐私保护不可靠的问题，需要寻找新的解决方案。

Method: 提出PerceptFace方法，基于合成技术保护面部隐私，设计新的感知相似性损失函数来增强身份感知，减少对人类视觉敏感区域的改变。

Result: PerceptFace在身份保护和身份感知之间实现了优越的权衡，相比现有方法表现更好，能够使身份不可提取但可感知。

Conclusion: PerceptFace作为首个基于合成的面部隐私保护方法，具有成为实用反面部识别工具的潜力，提供了可靠的隐私保护解决方案。

Abstract: Deep learning-based face recognition (FR) technology exacerbates privacy
concerns in photo sharing. In response, the research community developed a
suite of anti-FR methods to block identity extraction by unauthorized FR
systems. Benefiting from quasi-imperceptible alteration, perturbation-based
methods are well-suited for privacy protection of subject faces in photos, as
they allow familiar persons to recognize subjects via naked eyes. However, we
reveal that perturbation-based methods provide a false sense of privacy through
theoretical analysis and experimental validation.
  Therefore, new alternative solutions should be found to protect subject
faces. In this paper, we explore synthesis-based methods as a promising
solution, whose challenge is to enable familiar persons to recognize subjects.
To solve the challenge, we present a key insight: In most photo sharing
scenarios, familiar persons recognize subjects through identity perception
rather than meticulous face analysis. Based on the insight, we propose the
first synthesis-based method dedicated to subject faces, i.e., PerceptFace,
which can make identity unextractable yet perceptible. To enhance identity
perception, a new perceptual similarity loss is designed for faces, reducing
the alteration in regions of high sensitivity to human vision.
  As a synthesis-based method, PerceptFace can inherently provide reliable
identity protection. Meanwhile, out of the confine of meticulous face analysis,
PerceptFace focuses on identity perception from a more practical scenario,
which is also enhanced by the designed perceptual similarity loss. Sufficient
experiments show that PerceptFace achieves a superior trade-off between
identity protection and identity perception compared to existing methods. We
provide a public API of PerceptFace and believe that it has great potential to
become a practical anti-FR tool.

</details>


### [39] [Realistic Environmental Injection Attacks on GUI Agents](https://arxiv.org/abs/2509.11250)
*Yitong Zhang,Ximo Li,Liyi Cai,Jia Li*

Main category: cs.CR

TL;DR: 本文提出了Chameleon攻击框架，针对GUI代理在动态网页环境中的安全漏洞，通过LLM驱动的环境模拟和注意力黑洞机制，显著提升了在现实威胁模型下的攻击效果。


<details>
  <summary>Details</summary>
Motivation: 现有的环境注入攻击研究假设过于理想化，未能反映真实网页的动态性和小尺寸触发图像的现实场景，需要更真实的威胁模型来暴露GUI代理的潜在漏洞。

Method: 提出Chameleon攻击框架，包含两个创新：LLM驱动的环境模拟自动生成多样化高保真网页模拟；注意力黑洞机制将注意力权重转化为显式监督信号，引导代理关注触发区域。

Result: 在6个真实网站和4个代表性LVLM驱动的GUI代理上评估，Chameleon显著优于现有方法，消融研究证实两个创新点对性能都至关重要。

Conclusion: 研究揭示了现代GUI代理中未被充分探索的漏洞，为开放世界GUI代理系统的防御研究奠定了坚实基础。

Abstract: GUI agents built on LVLMs are increasingly used to interact with websites.
However, their exposure to open-world content makes them vulnerable to
Environmental Injection Attacks (EIAs) that hijack agent behavior via webpage
elements. Many recent studies assume the attacker to be a regular user who can
only upload a single trigger image, which is more realistic than earlier
assumptions of website-level administrative control. However, these works still
fall short of realism: (1) the trigger's position and surrounding context
remain largely fixed between training and testing, failing to capture the
dynamic nature of real webpages and (2) the trigger often occupies an
unrealistically large area, whereas real-world images are typically small. To
better reflect real-world scenarios, we introduce a more realistic threat model
where the attacker is a regular user and the trigger image is small and
embedded within a dynamically changing environment. As a result, existing
attacks prove largely ineffective under this threat model.
  To better expose the vulnerabilities of GUI agents, we propose Chameleon, an
attack framework with two main novelties. The first is LLM-Driven Environment
Simulation, which automatically generates diverse and high-fidelity webpage
simulations. The second is Attention Black Hole, which transforms attention
weights into explicit supervisory signals that guide the agent's focus toward
the trigger region. We evaluate Chameleon on 6 realistic websites and 4
representative LVLM-powered GUI agents, where it significantly outperforms
existing methods. Ablation studies confirm that both novelties are critical to
performance. Our findings reveal underexplored vulnerabilities in modern GUI
agents and establish a robust foundation for future research on defense in
open-world GUI agent systems. The code is publicly available at
https://github.com/zhangyitonggg/attack2gui.

</details>


### [40] [Thunderhammer: Rowhammer Bitflips via PCIe and Thunderbolt (USB-C)](https://arxiv.org/abs/2509.11440)
*Robert Dumitru,Junpeng Wan,Daniel Genkin,Rick Kennell,Dave,Tian,Yuval Yarom*

Main category: cs.CR

TL;DR: Thunderhammer攻击通过PCIe或Thunderbolt恶意外设实现Rowhammer攻击，首次展示了从外围设备触发DDR4内存位翻转的能力


<details>
  <summary>Details</summary>
Motivation: Rowhammer攻击传统上通过本地代码或远程代码执行实现，但此前未探索通过PCIe等外围设备接口的攻击向量

Method: 设计定制设备逆向工程PCIe请求调度关键参数，开发精确时序的访问模式，通过PCIe插槽和Thunderbolt端口执行攻击

Result: 成功在DDR4内存模块中通过PCIe连接和Thunderbolt端口诱导出Rowhammer位翻转

Conclusion: Thunderhammer揭示了Rowhammer攻击的新向量，表明恶意外围设备也能构成严重安全威胁，需要新的防御机制

Abstract: In recent years, Rowhammer has attracted significant attention from academia
and industry alike. This technique, first published in 2014, flips bits in
memory by repeatedly accessing neighbouring memory locations. Since its
discovery, researchers have developed a substantial body of work exploiting
Rowhammer and proposing countermeasures. These works demonstrate that Rowhammer
can be mounted not only through native code, but also via remote code
execution, such as JavaScript in browsers, and over networks.
  In this work, we uncover a previously unexplored Rowhammer vector. We present
Thunderhammer, an attack that induces DRAM bitflips from malicious peripherals
connected via PCIe or Thunderbolt (which tunnels PCIe). On modern DDR4 systems,
we observe that triggering bitflips through PCIe requests requires precisely
timed access patterns tailored to the target system. We design a custom device
to reverse engineer critical architectural parameters that shape PCIe request
scheduling, and to execute effective hammering access patterns. Leveraging this
knowledge, we successfully demonstrate Rowhammer-induced bitflips in DDR4
memory modules via both PCIe slot connections and Thunderbolt ports tunnelling
PCIe.

</details>


### [41] [MAUI: Reconstructing Private Client Data in Federated Transfer Learning](https://arxiv.org/abs/2509.11451)
*Ahaan Dabholkar,Atul Sharma,Z. Berkay Celik,Saurabh Bagchi*

Main category: cs.CR

TL;DR: MAUI是一种隐蔽的数据重建攻击方法，仅利用分类头的梯度就能在联邦学习的迁移学习设置中实现高精度的输入数据重建，无需修改模型架构或权重。


<details>
  <summary>Details</summary>
Motivation: 现有联邦学习中的数据重建攻击在迁移学习设置中存在两个主要弱点：1）初始模型层的强输入相关梯度信息不共享，重建精度低；2）需要服务器对模型结构进行明显修改，容易被客户端检测。

Method: MAUI仅使用分类头的梯度，首先提取输入批次的"鲁棒"特征表示，然后将这些特征表示反演为原始输入。该方法不需要对模型架构或权重进行任何明显修改。

Result: 在CIFAR10和ImageNet数据集上，对多种模型架构（CNN、VGG11、ResNets、ShuffleNet-V2、ViT B-32）实现了高精度重建，无论批量大小如何。PSNR分数比现有方法提高40-120%。

Conclusion: MAUI证明了仅通过分类头梯度就能实现高效数据重建，对联邦学习中的隐私保护提出了新的挑战，需要开发更强大的防御机制。

Abstract: Recent works in federated learning (FL) have shown the utility of leveraging
transfer learning for balancing the benefits of FL and centralized learning. In
this setting, federated training happens after a stable point has been reached
through conventional training. Global model weights are first centrally
pretrained by the server on a public dataset following which only the last few
linear layers (the classification head) of the model are finetuned across
clients. In this scenario, existing data reconstruction attacks (DRAs) in FL
show two key weaknesses. First, strongly input-correlated gradient information
from the initial model layers is never shared, significantly degrading
reconstruction accuracy. Second, DRAs in which the server makes highly
specific, handcrafted manipulations to the model structure or parameters (for
e.g., layers with all zero weights, identity mappings and rows with identical
weight patterns) are easily detectable by an active client.
  Improving on these, we propose MAUI, a stealthy DRA that does not require any
overt manipulations to the model architecture or weights, and relies solely on
the gradients of the classification head. MAUI first extracts "robust" feature
representations of the input batch from the gradients of the classification
head and subsequently inverts these representations to the original inputs. We
report highly accurate reconstructions on the CIFAR10 and ImageNet datasets on
a variety of model architectures including convolution networks (CNN, VGG11),
ResNets (18, 50), ShuffleNet-V2 and Vision Transformer (ViT B-32), regardless
of the batch size. MAUI significantly outperforms prior DRAs in reconstruction
quality, achieving 40-120% higher PSNR scores.

</details>


### [42] [Dstack: A Zero Trust Framework for Confidential Containers](https://arxiv.org/abs/2509.11555)
*Shunfan Zhou,Kevin Wang,Hang Yin*

Main category: cs.CR

TL;DR: dstack是一个将原始TEE技术转化为零信任平台的框架，通过便携式机密容器、去中心化代码管理和可验证域管理三大创新，为Web3应用提供安全可靠的执行环境。


<details>
  <summary>Details</summary>
Motivation: Web3应用需要不依赖中心化信任机构的执行平台来保证机密性和完整性。虽然TEE技术有潜力，但现有实现存在安全可靠性、抗审查性和供应商独立性等方面的局限。

Method: 提出dstack框架，包含三个核心组件：dstack-OS、dstack-KMS和dstack-Gateway。采用便携式机密容器实现异构TEE环境间的无缝工作负载迁移，使用智能合约进行去中心化代码管理，并通过可验证域管理确保应用身份安全。

Result: 评估显示dstack在提供全面安全保证的同时，保持了实际应用的可用性，既能获得VM级TEE解决方案的性能优势，又能满足Web3应用的无信任保证要求。

Conclusion: dstack成功将原始TEE技术转化为真正的零信任平台，为Web3应用提供了既安全又实用的执行环境解决方案。

Abstract: Web3 applications require execution platforms that maintain confidentiality
and integrity without relying on centralized trust authorities. While Trusted
Execution Environments (TEEs) offer promising capabilities for confidential
computing, current implementations face significant limitations when applied to
Web3 contexts, particularly in security reliability, censorship resistance, and
vendor independence.
  This paper presents dstack, a comprehensive framework that transforms raw TEE
technology into a true Zero Trust platform. We introduce three key innovations:
(1) Portable Confidential Containers that enable seamless workload migration
across heterogeneous TEE environments while maintaining security guarantees,
(2) Decentralized Code Management that leverages smart contracts for
transparent governance of TEE applications, and (3) Verifiable Domain
Management that ensures secure and verifiable application identity without
centralized authorities.
  These innovations are implemented through three core components: dstack-OS,
dstack-KMS, and dstack-Gateway. Together, they demonstrate how to achieve both
the performance advantages of VM-level TEE solutions and the trustless
guarantees required by Web3 applications. Our evaluation shows that dstack
provides comprehensive security guarantees while maintaining practical
usability for real-world applications.

</details>


### [43] [ILA: Correctness via Type Checking for Fully Homomorphic Encryption](https://arxiv.org/abs/2509.11559)
*Tarakaram Gollamudi,Anitha Gollamudi,Joshua Gancher*

Main category: cs.CR

TL;DR: 提出了一个面向正确性的中间表示语言ILA，用于同态加密电路的类型检查，通过类型系统追踪噪声边界和环绕错误，确保功能正确性


<details>
  <summary>Details</summary>
Motivation: 现有的FHE库和编译器对噪声静态追踪支持有限，且存在有限模运算的环绕错误问题，使得FHE应用开发困难且缺乏信心

Method: 设计了一个中间语言ILA，包含类型系统来追踪低层次量化边界（如密文噪声），不依赖密钥，并基于FHE模型进行实例化

Result: 实现了对BGV、BFV和TFHE等FHE方案的功能正确性证明，能够识别和防止噪声溢出和环绕错误

Conclusion: ILA IR为FHE电路开发提供了静态正确性保证，提高了开发信心，支持多种FHE方案，具有通用性

Abstract: RLWE-based Fully Homomorphic Encryption (FHE) schemes add some small
\emph{noise} to the message during encryption. The noise accumulates with each
homomorphic operation. When the noise exceeds a critical value, the FHE circuit
produces an incorrect output. This makes developing FHE applications quite
subtle, as one must closely track the noise to ensure correctness. However,
existing libraries and compilers offer limited support to statically track the
noise. Additionally, FHE circuits are also plagued by wraparound errors that
are common in finite modulus arithmetic. These two limitations of existing
compilers and libraries make FHE applications too difficult to develop with
confidence.
  In this work, we present a \emph{correctness-oriented} IR, Intermediate
Language for Arithmetic circuits, for type-checking circuits intended for
homomorphic evaluation. Our IR is backed by a type system that tracks low-level
quantitative bounds (e.g., ciphertext noise) without using the secret key.
Using our type system, we identify and prove a strong \emph{functional
correctness} criterion for \ila circuits. Additionally, we have designed \ila
to be maximally general: our core type system does not directly assume a
particular FHE scheme, but instead axiomatizes a \emph{model} of FHE. We
instantiate this model with the exact FHE schemes (BGV, BFV and TFHE), and
obtain functional correctness for free.

</details>


### [44] [Cyber Threat Hunting: Non-Parametric Mining of Attack Patterns from Cyber Threat Intelligence for Precise Threats Attribution](https://arxiv.org/abs/2509.11615)
*Rimsha Kanwal,Umara Noor,Zafar Iqbal,Zahid Rashid*

Main category: cs.CR

TL;DR: 提出基于机器学习的网络威胁归因方法Cyber-Attack Pattern Explorer (CAPE)，通过交互式可视化和挖掘技术帮助安全分析师识别攻击模式并进行威胁归因


<details>
  <summary>Details</summary>
Motivation: 现有网络威胁归因方法存在准确性低、误报率高的问题，且网络威胁情报文档数量庞大难以有效组织和检索，需要自动化工具辅助安全分析师

Method: 使用非参数挖掘技术从网络威胁情报文档中提取攻击模式数据集，训练机器学习算法进行威胁归因，并开发交互式可视化工具CAPE

Result: 提出的方法能够语义化地对齐常用攻击主题，便于解释，实现了对网络威胁的有效归因

Conclusion: CAPE系统通过机器学习和可视化技术有效解决了网络威胁归因中的信息组织和检索难题，为安全分析师提供了实用的分析工具

Abstract: With the ever-changing landscape of cyber threats, identifying their origin
has become paramount, surpassing the simple task of attack classification.
Cyber threat attribution gives security analysts the insights they need to
device effective threat mitigation strategies. Such strategies empower
enterprises to proactively detect and defend against future cyber-attacks.
However, existing approaches exhibit limitations in accurately identifying
threat actors, leading to low precision and a significant occurrence of false
positives. Machine learning offers the potential to automate certain aspects of
cyber threat attribution. The distributed nature of information regarding cyber
threat actors and their intricate attack methodologies has hindered substantial
progress in this domain. Cybersecurity analysts deal with an ever-expanding
collection of cyber threat intelligence documents. While these documents hold
valuable insights, their sheer volume challenges efficient organization and
retrieval of pertinent information. To assist the cybersecurity analyst
activities, we propose a machine learning based approach featuring visually
interactive analytics tool named the Cyber-Attack Pattern Explorer (CAPE),
designed to facilitate efficient information discovery by employing interactive
visualization and mining techniques. In the proposed system, a non-parametric
mining technique is proposed to create a dataset for identifying the attack
patterns within cyber threat intelligence documents. These attack patterns
align semantically with commonly employed themes ensuring ease of
interpretation. The extracted dataset is used for training of proposed machine
learning algorithms that enables the attribution of cyber threats with
respective to the actors.

</details>


### [45] [Cyber Attack Mitigation Framework for Denial of Service (DoS) Attacks in Fog Computing](https://arxiv.org/abs/2509.11668)
*Fizza Khurshid,Umara Noor,Zahid Rashid*

Main category: cs.CR

TL;DR: 提出了一种针对DDoS攻击的多层自动化威胁缓解框架，结合设备层、雾网络层和云层的协同防御机制


<details>
  <summary>Details</summary>
Motivation: 网络安全威胁不断演变，但自动化威胁缓解领域研究不足，特别是检测之外的挑战解决方面缺乏学术关注

Method: 开发多层安全框架：设备层使用智能设备进行防火墙规则包检测，雾网络层进行统计行为分析和深度包检测，云层进行确认性检测和防火墙缓解

Result: 构建了全面的网络保护系统，增强了对抗网络威胁的鲁棒性，提供了实用的实施和评估策略

Conclusion: 该框架为解决当前网络安全挑战提供了重要方法，并为未来自动化缓解方法的发展奠定了基础

Abstract: Innovative solutions to cyber security issues are shaped by the ever-changing
landscape of cyber threats. Automating the mitigation of these threats can be
achieved through a new methodology that addresses the domain of mitigation
automation, which is often overlooked. This literature overview emphasizes the
lack of scholarly work focusing specifically on automated cyber threat
mitigation, particularly in addressing challenges beyond detection. The
proposed methodology comprise of the development of an automatic cyber threat
mitigation framework tailored for Distributed Denial-of-Service (DDoS) attacks.
This framework adopts a multi-layer security approach, utilizing smart devices
at the device layer, and leveraging fog network and cloud computing layers for
deeper understanding and technological adaptability. Initially, firewall
rule-based packet inspection is conducted on simulated attack traffic to filter
out DoS packets, forwarding legitimate packets to the fog. The methodology
emphasizes the integration of fog detection through statistical and behavioral
analysis, specification-based detection, and deep packet inspection, resulting
in a comprehensive cyber protection system. Furthermore, cloud-level inspection
is performed to confirm and mitigate attacks using firewalls, enhancing
strategic defense and increasing robustness against cyber threats. These
enhancements enhance understanding of the research framework's practical
implementation and assessment strategies, substantiating its importance in
addressing current cyber security challenges and shaping future automation
mitigation approaches.

</details>


### [46] [An Unsupervised Learning Approach For A Reliable Profiling Of Cyber Threat Actors Reported Globally Based On Complete Contextual Information Of Cyber Attacks](https://arxiv.org/abs/2509.11683)
*Sawera Shahid,Umara Noor,Zahid Rashid*

Main category: cs.CR

TL;DR: 提出基于无监督层次聚类方法的网络犯罪团伙画像技术，通过分析威胁情报中的上下文信息来识别攻击者群体特征和关联关系


<details>
  <summary>Details</summary>
Motivation: 现有监督学习方法依赖结构化数据集和专家主观判断，特征数量有限且处理流程耗时，需要更高效准确的方法来应对快速增长的网络安全威胁

Method: 采用无监督的凝聚层次聚类技术，基于网络威胁行为者的全面上下文威胁信息进行聚类分析，识别共同特征和群体关系

Result: 该方法能够自动识别网络威胁行为者之间的关系，基于共同特征进行聚合，并成功构建网络犯罪团伙的画像

Conclusion: 无监督层次聚类方法为网络威胁行为者画像提供了更高效准确的解决方案，能够快速识别攻击模式并建立防御机制，相比传统监督学习方法具有明显优势

Abstract: Cyber attacks are rapidly increasing with the advancement of technology and
there is no protection for our information. To prevent future cyberattacks it
is critical to promptly recognize cyberattacks and establish strong defense
mechanisms against them. To respond to cybersecurity threats immediately, it is
essential to examine the attackers skills, knowledge, and behaviors with the
goal of evaluating their impact on the system and comprehending the traits
associated with these attacks. Creating a profile of cyber threat actors based
on their traits or patterns of behavior can help to create effective defenses
against cyberattacks in advance. In the current literature, multiple supervised
machine learning based approaches considered a smaller number of features for
attacker profiling that are reported in textual cyber threat incident documents
although these profiles have been developed based on the security experts own
perception, we cannot rely on them. Supervised machine learning approaches
strictly depend upon the structure data set. This usually leads to a two step
process where we first have to establish a structured data set before we can
analyze it and then employ it to construct defense mechanisms, which takes
time. In this paper, an unsupervised efficient agglomerative hierarchal
clustering technique is proposed for profiling cybercriminal groups based on
their comprehensive contextual threat information in order to address the
aforementioned issues. The main objective of this report is to identify the
relationship between cyber threat actors based on their common features,
aggregate them, and also profile cyber criminal groups.

</details>


### [47] [Time-Based State-Management of Hash-Based Signature CAs for VPN-Authentication](https://arxiv.org/abs/2509.11695)
*Daniel Herzinger,Linus Heise,Daniel Loebenberger,Matthias Söllner*

Main category: cs.CR

TL;DR: 提出了一种基于XMSS哈希签名方案的时间状态管理VPN认证设计，使用短期有效的传统密码学证书，实现量子安全且资源高效的IPsec VPN认证


<details>
  <summary>Details</summary>
Motivation: 量子计算发展需要迁移到后量子密码学，现有IPsec VPN的量子安全认证方案未考虑状态哈希签名方案，尽管其签名小且长期安全可信

Method: 设计基于时间状态管理，使用XMSS哈希签名方案的CA颁发短期有效（如4小时）的传统密码学叶证书，量子计算机破解所需时间远超证书有效期

Result: 在OpenBSD上实现了量子安全且灵活的VPN认证设计，相比现有方案显著减少带宽和计算资源需求

Conclusion: 该设计为IPsec VPN提供了实用的量子安全认证解决方案，通过时间状态管理和短期证书实现了资源高效的安全保障

Abstract: Advances in quantum computing necessitate migrating the entire technology
stack to post-quantum cryptography. This includes IPsec-based VPN connection
authentication. Although there is an RFC draft for post-quantum authentication
in this setting, the draft does not consider (stateful) hash-based signatures
despite their small signature size and trusted long-term security.
  We propose a design with time-based state-management that assigns VPN devices
a certificate authority (CA) based on the hash-based signature scheme XMSS. The
CA then issues leaf certificates which are based on classical cryptography but
have a short validity time, e. g., four hours. It is to be expected that even
large quantum computers will take significantly longer to break the
cryptography, making the design quantum-secure. We propose strategies to make
the timekeeping more resilient to faults and tampering, as well as strategies
to recognize a wrong system time, minimize its potential damage, and quickly
recover.
  The result is an OpenBSD implementation of a quantum-safe and, regarding the
leaf certificates, highly flexible VPN authentication design that requires
significantly less bandwidth and computational resources compared to existing
alternatives.

</details>


### [48] [A Holistic Approach to E-Commerce Innovation: Redefining Security and User Experience](https://arxiv.org/abs/2509.11712)
*Mohammad Olid Ali Akash,Priyangana Saha*

Main category: cs.CR

TL;DR: 本研究提出了一种新的电子商务平台，通过直观界面和强大安全措施解决Android购物应用的用户体验和安全问题


<details>
  <summary>Details</summary>
Motivation: 现代电子商务中，许多Android应用存在界面复杂导致用户难以快速找到商品，以及支付选项有限、认证机制薄弱等安全问题，影响用户体验和数据安全

Method: 开发新型电商平台，采用组织良好的产品分类和高效结账流程提升用户体验，集成Google认证和SSL安全支付网关等安全功能保护用户数据

Result: 该平台能够重塑电子商务用户体验，提供符合现代用户需求和期望的可行框架

Conclusion: 通过关注用户友好性、安全性和个性化，该电商平台为未来相关发展开辟了新途径，提升了电子商务平台的整体水平

Abstract: In the modern, fast-moving world of e-commerce, many Android apps face
challenges in providing a simple and secure shopping experience. Many of these
apps, often enough, have complicated designs that prevent users from finding
what they want quickly, thus frustrating them and wasting their precious time.
Another major issue is that of security; with the limitation of payment options
and weak authentication mechanisms, users' sensitive information can be
compromised. This research presents a new e-commerce platform that responds to
the above challenges with an intuitive interface and strong security measures.
The platform makes online shopping easy with well-organized categories of
products and a fast, efficient checkout process. It also gives priority to
security by incorporating features such as Google authentication and
SSL-secured payment gateways to protect user data and ensure secure
transactions. This paper discusses how a focus on user-friendliness, security,
and personalization steps up the game for e-commerce platforms, providing
workable frameworks that match modern user needs and expectations. The findings
show the e-commerce user experience can be remodelled by the platform, hence
opening ways for future developments in that respect.

</details>


### [49] [Removal Attack and Defense on AI-generated Content Latent-based Watermarking](https://arxiv.org/abs/2509.11745)
*De Zhang Lee,Han Fang,Hanyi Wang,Ee-Chien Chang*

Main category: cs.CR

TL;DR: 本文研究AI生成内容水印的安全性，发现不可区分性不能保证抗移除攻击，提出基于边界信息泄露的新型攻击方法，并设计秘密变换防御机制来隐藏边界信息。


<details>
  <summary>Details</summary>
Motivation: 现有数字水印技术虽然能实现不可区分性，但在面对移除攻击时存在安全漏洞，需要研究如何提高水印的抗攻击能力。

Method: 提出利用水印对象位置泄露的边界信息进行攻击的方法，并设计秘密变换防御机制来隐藏边界信息，通过理论证明和实验验证有效性。

Result: 新型攻击方法在特定设置下比基线白噪声攻击减少高达15倍的失真度，防御机制能有效将攻击者的扰动等同于白噪声攻击者的扰动。

Conclusion: 边界信息泄露是潜在水印方案中的重要安全问题，需要采用秘密变换等防御措施来提高水印的安全性。

Abstract: Digital watermarks can be embedded into AI-generated content (AIGC) by
initializing the generation process with starting points sampled from a secret
distribution. When combined with pseudorandom error-correcting codes, such
watermarked outputs can remain indistinguishable from unwatermarked objects,
while maintaining robustness under whitenoise. In this paper, we go beyond
indistinguishability and investigate security under removal attacks. We
demonstrate that indistinguishability alone does not necessarily guarantee
resistance to adversarial removal. Specifically, we propose a novel attack that
exploits boundary information leaked by the locations of watermarked objects.
This attack significantly reduces the distortion required to remove watermarks
-- by up to a factor of $15 \times$ compared to a baseline whitenoise attack
under certain settings. To mitigate such attacks, we introduce a defense
mechanism that applies a secret transformation to hide the boundary, and prove
that the secret transformation effectively rendering any attacker's
perturbations equivalent to those of a naive whitenoise adversary. Our
empirical evaluations, conducted on multiple versions of Stable Diffusion,
validate the effectiveness of both the attack and the proposed defense,
highlighting the importance of addressing boundary leakage in latent-based
watermarking schemes.

</details>


### [50] [On Spatial-Provenance Recovery in Wireless Networks with Relaxed-Privacy Constraints](https://arxiv.org/abs/2509.11761)
*Manish Bansal,Pramsu Shrivastava,J. Harshan*

Main category: cs.CR

TL;DR: 提出了一种在V2X网络中实现放松隐私的位置共享协议，车辆使用相关线性Bloom过滤器嵌入位置信息，平衡隐私保护与通信开销。


<details>
  <summary>Details</summary>
Motivation: 解决V2X网络中车辆因隐私顾虑不愿分享精确GPS坐标，但RSU又需要位置数据提供服务的矛盾。

Method: 使用相关线性Bloom过滤器嵌入部分位置信息，考虑定位分辨率、自组网协议和无线技术覆盖范围的空间溯源恢复协议。

Result: 理论分析显示在放松隐私和通信开销之间存在权衡，实验证明只需少量包头比特即可提供安全功能如定位低功耗干扰源。

Conclusion: 提出的放松隐私模型和空间溯源恢复协议能有效平衡车辆隐私保护和RSU位置服务需求，具有低延迟和低通信开销的优势。

Abstract: In Vehicle-to-Everything (V2X) networks with multi-hop communication, Road
Side Units (RSUs) intend to gather location data from the vehicles to offer
various location-based services. Although vehicles use the Global Positioning
System (GPS) for navigation, they may refrain from sharing their exact GPS
coordinates to the RSUs due to privacy considerations. Thus, to address the
localization expectations of the RSUs and the privacy concerns of the vehicles,
we introduce a relaxed-privacy model wherein the vehicles share their partial
location information in order to avail the location-based services. To
implement this notion of relaxed-privacy, we propose a low-latency protocol for
spatial-provenance recovery, wherein vehicles use correlated linear Bloom
filters to embed their position information. Our proposed spatial-provenance
recovery process takes into account the resolution of localization, the
underlying ad hoc protocol, and the coverage range of the wireless technology
used by the vehicles. Through a rigorous theoretical analysis, we present
extensive analysis on the underlying trade-off between relaxed-privacy and the
communication-overhead of the protocol. Finally, using a wireless testbed, we
show that our proposed method requires a few bits in the packet header to
provide security features such as localizing a low-power jammer executing a
denial-of-service attack.

</details>


### [51] [Anomaly Detection in Industrial Control Systems Based on Cross-Domain Representation Learning](https://arxiv.org/abs/2509.11786)
*Dongyang Zhan,Wenqi Zhang,Lin Ye,Xiangzhan Yu,Hongli Zhang,Zheng He*

Main category: cs.CR

TL;DR: 提出了一种基于跨域表示学习的工业控制系统异常检测方法，通过图神经网络学习多域行为的联合特征，并使用多任务学习分别识别不同域的异常


<details>
  <summary>Details</summary>
Motivation: 工业控制系统(ICS)的安全稳定至关重要，现有异常检测方法主要分析单一域（网络流量或传感器数据），但不同域的行为相互关联，仅分析单一域难以全面识别异常

Method: 构建跨域图表示ICS中多域行为，利用图神经网络学习联合特征，采用多任务学习方法分别识别不同域的异常并进行联合训练

Result: 实验结果表明该方法在识别ICS异常方面性能优于现有方法

Conclusion: 跨域表示学习和多任务学习方法能够有效提升工业控制系统异常检测的准确性和全面性

Abstract: Industrial control systems (ICSs) are widely used in industry, and their
security and stability are very important. Once the ICS is attacked, it may
cause serious damage. Therefore, it is very important to detect anomalies in
ICSs. ICS can monitor and manage physical devices remotely using communication
networks. The existing anomaly detection approaches mainly focus on analyzing
the security of network traffic or sensor data. However, the behaviors of
different domains (e.g., network traffic and sensor physical status) of ICSs
are correlated, so it is difficult to comprehensively identify anomalies by
analyzing only a single domain. In this paper, an anomaly detection approach
based on cross-domain representation learning in ICSs is proposed, which can
learn the joint features of multi-domain behaviors and detect anomalies within
different domains. After constructing a cross-domain graph that can represent
the behaviors of multiple domains in ICSs, our approach can learn the joint
features of them by leveraging graph neural networks. Since anomalies behave
differently in different domains, we leverage a multi-task learning approach to
identify anomalies in different domains separately and perform joint training.
The experimental results show that the performance of our approach is better
than existing approaches for identifying anomalies in ICSs.

</details>


### [52] [Off-Path TCP Exploits: PMTUD Breaks TCP Connection Isolation in IP Address Sharing Scenarios](https://arxiv.org/abs/2509.11833)
*Xuewei Feng,Zhaoxi Li,Qi Li,Ziqiang Wang,Kun Sun,Ke Xu*

Main category: cs.CR

TL;DR: 本文揭示了路径MTU发现(PMTUD)在IP地址共享环境中的安全漏洞，攻击者可利用此漏洞进行离径TCP劫持攻击，成功率高达70%，平均耗时220秒。


<details>
  <summary>Details</summary>
Motivation: 研究PMTUD在广泛使用的IP地址共享实践中的安全漏洞，因为PMTUD设计时未充分考虑IP地址共享场景，存在被攻击者利用的风险。

Method: 通过观察服务器为共享公共IP地址确定的路径MTU值，离径攻击者与恶意设备协作，推断其他合法设备TCP连接的序列号，从而实施TCP劫持攻击。

Result: 实验显示攻击平均耗时220秒，成功率70%。在50个真实网络环境测试中，38个存在漏洞。攻击成功应用于SSH DoS、FTP流量污染和HTTP注入等场景。

Conclusion: PMTUD在IP地址共享环境中存在严重安全漏洞，需要采取相应防护措施。研究结果已获得IETF、Linux和Cisco等组织的认可，并提出了相应的解决方案。

Abstract: Path MTU Discovery (PMTUD) and IP address sharing are integral aspects of
modern Internet infrastructure. In this paper, we investigate the security
vulnerabilities associated with PMTUD within the context of prevalent IP
address sharing practices. We reveal that PMTUD is inadequately designed to
handle IP address sharing, creating vulnerabilities that attackers can exploit
to perform off-path TCP hijacking attacks. We demonstrate that by observing the
path MTU value determined by a server for a public IP address (shared among
multiple devices), an off-path attacker on the Internet, in collaboration with
a malicious device, can infer the sequence numbers of TCP connections
established by other legitimate devices sharing the same IP address. This
vulnerability enables the attacker to perform off-path TCP hijacking attacks,
significantly compromising the security of the affected TCP connections. Our
attack involves first identifying a target TCP connection originating from the
shared IP address, followed by inferring the sequence numbers of the identified
connection. We thoroughly assess the impacts of our attack under various
network configurations. Experimental results reveal that the attack can be
executed within an average time of 220 seconds, achieving a success rate of
70%.Case studies, including SSH DoS, FTP traffic poisoning, and HTTP injection,
highlight the threat it poses to various applications. Additionally, we
evaluate our attack across 50 real-world networks with IP address
sharing--including public Wi-Fi, VPNs, and 5G--and find 38 vulnerable. Finally,
we responsibly disclose the vulnerabilities, receive recognition from
organizations such as IETF, Linux, and Cisco, and propose our countermeasures.

</details>


### [53] [A Practical Adversarial Attack against Sequence-based Deep Learning Malware Classifiers](https://arxiv.org/abs/2509.11836)
*Kai Tan,Dongyang Zhan,Lin Ye,Hongli Zhang,Binxing Fang*

Main category: cs.CR

TL;DR: 基于深度Q网络和启发式回溯搜索的对抗攻击方法，通过生成满足实际条件的扰动序列并映射回源代码，有效生成能逃避恶意软件检测的对抗样本。


<details>
  <summary>Details</summary>
Motivation: 现有的对抗样本生成方法通常直接删除或替换关键行为序列，或插入可能违反行为约束的良性行为，这些方法难以在实际中应用。需要一种能够生成满足实际条件且可实现的对抗样本的方法。

Method: 提出基于深度Q网络和启发式回溯搜索策略的对抗攻击方法，生成满足实际条件的扰动序列，并使用新颖的转换方法将修改映射回源代码，避免直接修改行为日志序列。

Result: 评估结果表明该方法能有效从真实恶意软件行为序列生成对抗样本，具有很高的逃避异常检测模型的成功率。

Conclusion: 该方法不仅有效，而且实用，能够在保持修改软件功能的同时生成对抗样本，解决了现有方法难以实际应用的问题。

Abstract: Sequence-based deep learning models (e.g., RNNs), can detect malware by
analyzing its behavioral sequences. Meanwhile, these models are susceptible to
adversarial attacks. Attackers can create adversarial samples that alter the
sequence characteristics of behavior sequences to deceive malware classifiers.
The existing methods for generating adversarial samples typically involve
deleting or replacing crucial behaviors in the original data sequences, or
inserting benign behaviors that may violate the behavior constraints. However,
these methods that directly manipulate sequences make adversarial samples
difficult to implement or apply in practice. In this paper, we propose an
adversarial attack approach based on Deep Q-Network and a heuristic
backtracking search strategy, which can generate perturbation sequences that
satisfy practical conditions for successful attacks. Subsequently, we utilize a
novel transformation approach that maps modifications back to the source code,
thereby avoiding the need to directly modify the behavior log sequences. We
conduct an evaluation of our approach, and the results confirm its
effectiveness in generating adversarial samples from real-world malware
behavior sequences, which have a high success rate in evading anomaly detection
models. Furthermore, our approach is practical and can generate adversarial
samples while maintaining the functionality of the modified software.

</details>


### [54] [NeuroStrike: Neuron-Level Attacks on Aligned LLMs](https://arxiv.org/abs/2509.11864)
*Lichao Wu,Sasha Behrouzi,Mohamadreza Rostami,Maximilian Thang,Stjepan Picek,Ahmad-Reza Sadeghi*

Main category: cs.CR

TL;DR: NeuroStrike是一种新的攻击框架，通过识别和修剪安全神经元来绕过LLM的安全对齐机制，在白盒和黑盒设置下都有效，攻击成功率高达76.9%。


<details>
  <summary>Details</summary>
Motivation: 当前的安全对齐技术（如监督微调和人类反馈强化学习）存在脆弱性，容易被精心设计的对抗提示绕过。现有攻击方法依赖试错，缺乏跨模型通用性，且受限于可扩展性和可靠性。

Method: NeuroStrike利用安全对齐技术引入的基本漏洞：依赖稀疏的专门安全神经元来检测和抑制有害输入。白盒设置下通过前向激活分析识别安全神经元并在推理时修剪；黑盒设置下提出首个LLM分析攻击，利用安全神经元的可转移性，在开源替代模型上训练对抗提示生成器后部署到黑盒目标。

Result: 在20多个开源LLM上评估，通过移除目标层中不到0.6%的神经元，使用普通恶意提示实现平均76.9%的攻击成功率。对4个多模态LLM实现100%攻击成功率。安全神经元在架构间有效转移，在11个微调模型上达到78.5%成功率，在5个蒸馏模型上达到77.7%成功率。黑盒攻击在5个黑盒模型上平均达到63.7%成功率。

Conclusion: 安全神经元存在跨模型的可转移性漏洞，当前的安全对齐机制存在根本性脆弱，需要开发更鲁棒的安全防御方法。

Abstract: Safety alignment is critical for the ethical deployment of large language
models (LLMs), guiding them to avoid generating harmful or unethical content.
Current alignment techniques, such as supervised fine-tuning and reinforcement
learning from human feedback, remain fragile and can be bypassed by carefully
crafted adversarial prompts. Unfortunately, such attacks rely on trial and
error, lack generalizability across models, and are constrained by scalability
and reliability.
  This paper presents NeuroStrike, a novel and generalizable attack framework
that exploits a fundamental vulnerability introduced by alignment techniques:
the reliance on sparse, specialized safety neurons responsible for detecting
and suppressing harmful inputs. We apply NeuroStrike to both white-box and
black-box settings: In the white-box setting, NeuroStrike identifies safety
neurons through feedforward activation analysis and prunes them during
inference to disable safety mechanisms. In the black-box setting, we propose
the first LLM profiling attack, which leverages safety neuron transferability
by training adversarial prompt generators on open-weight surrogate models and
then deploying them against black-box and proprietary targets. We evaluate
NeuroStrike on over 20 open-weight LLMs from major LLM developers. By removing
less than 0.6% of neurons in targeted layers, NeuroStrike achieves an average
attack success rate (ASR) of 76.9% using only vanilla malicious prompts.
Moreover, Neurostrike generalizes to four multimodal LLMs with 100% ASR on
unsafe image inputs. Safety neurons transfer effectively across architectures,
raising ASR to 78.5% on 11 fine-tuned models and 77.7% on five distilled
models. The black-box LLM profiling attack achieves an average ASR of 63.7%
across five black-box models, including the Google Gemini family.

</details>


### [55] [Efficient Byzantine-Robust Privacy-Preserving Federated Learning via Dimension Compression](https://arxiv.org/abs/2509.11870)
*Xian Qin,Xue Yang,Xiaohu Tang*

Main category: cs.CR

TL;DR: 提出了一种结合同态加密和维度压缩的联邦学习方案，在保护隐私的同时有效防御拜占庭攻击，并显著降低计算开销


<details>
  <summary>Details</summary>
Motivation: 联邦学习在保护隐私的同时面临梯度泄露和恶意客户端攻击的风险，现有解决方案在隐私保护、拜占庭鲁棒性和计算效率之间存在权衡

Method: 采用双服务器架构，结合同态加密和基于Johnson-Lindenstrauss变换的维度压缩技术，在密文域实现安全的拜占庭防御

Result: 计算复杂度从O(dn)降低到O(kn)，在多个数据集上保持与非私有联邦学习相当的模型精度，能有效防御高达40%的拜占庭客户端

Conclusion: 该方法成功平衡了隐私保护、拜占庭鲁棒性和计算效率三个关键目标，为联邦学习提供了实用的安全解决方案

Abstract: Federated Learning (FL) allows collaborative model training across
distributed clients without sharing raw data, thus preserving privacy. However,
the system remains vulnerable to privacy leakage from gradient updates and
Byzantine attacks from malicious clients. Existing solutions face a critical
trade-off among privacy preservation, Byzantine robustness, and computational
efficiency. We propose a novel scheme that effectively balances these competing
objectives by integrating homomorphic encryption with dimension compression
based on the Johnson-Lindenstrauss transformation. Our approach employs a
dual-server architecture that enables secure Byzantine defense in the
ciphertext domain while dramatically reducing computational overhead through
gradient compression. The dimension compression technique preserves the
geometric relationships necessary for Byzantine defence while reducing
computation complexity from $O(dn)$ to $O(kn)$ cryptographic operations, where
$k \ll d$. Extensive experiments across diverse datasets demonstrate that our
approach maintains model accuracy comparable to non-private FL while
effectively defending against Byzantine clients comprising up to $40\%$ of the
network.

</details>


### [56] [zkToken: Empowering Holders to Limit Revocation Checks for Verifiable Credentials](https://arxiv.org/abs/2509.11934)
*Praveensankar Manimaran,Mayank Raikwar,Thiago Garrett,Arlindo F. da Conceição,Leander Jehl,Roman Vitenberg*

Main category: cs.CR

TL;DR: 提出了一种新颖的时间限制连续验证框架，允许持有者单独配置验证期限，并在验证期结束后保证撤销状态的不可追踪性。


<details>
  <summary>Details</summary>
Motivation: 现有的可验证凭证系统在撤销已颁发凭证时，允许验证者监控凭证的有效性状态，这会泄露敏感信息。目前缺乏合适的解决方案来保护撤销状态的隐私。

Method: 采用可扩展的黑名单方法，将撤销凭证对应的令牌存储在注册表中。使用零知识证明（ZK proofs）允许持有者证明自己不在黑名单中，并支持持有者配置个性化的验证期限。

Result: 通过理论和实验评估证明，该方法在安全性方面得到保障，并且在带宽消耗方面显著优于现有方案，在其他性能指标上与最先进解决方案相当。

Conclusion: 该框架为可验证凭证系统提供了一种隐私保护的撤销机制，既能保证撤销状态的可验证性，又能防止验证期结束后的追踪问题，具有较好的可扩展性和性能表现。

Abstract: Systems managing Verifiable Credentials are becoming increasingly popular.
Unfortunately, their support for revoking previously issued credentials allows
verifiers to effectively monitor the validity of the credentials, which is
sensitive information. While the issue started to gain recognition, no adequate
solution has been proposed so far.
  In this work, we propose a novel framework for time-limited continuous
verification. The holder is able to individually configure the verification
period when sharing information with the verifier, and the system guarantees
proven untraceability of the revocation status after the verification period
expires. Different from existing systems, the implementation adopts a more
scalable blacklist approach where tokens corresponding to revoked credentials
are stored in the registry. The approach employs ZK proofs that allow holders
to prove non-membership in the blacklist. In addition to theoretically proving
security, we evaluate the approach analytically and experimentally and show
that it significantly improves bandwidth consumption on the holder while being
on par with state-of-the-art solutions with respect to the other performance
metrics.

</details>


### [57] [Poison to Detect: Detection of Targeted Overfitting in Federated Learning](https://arxiv.org/abs/2509.11974)
*Soumia Zohra El Mestari,Maciej Krzysztof Zuziak,Gabriele Lenzini*

Main category: cs.CR

TL;DR: 本文研究了联邦学习中协调器操纵聚合过程导致特定客户端本地模型过拟合的威胁，提出了三种客户端检测技术来验证全局聚合的完整性。


<details>
  <summary>Details</summary>
Motivation: 联邦学习虽然保护数据隐私，但仍易受隐私攻击，特别是协调器故意操纵聚合过程导致特定客户端过拟合的威胁。现有研究主要关注减少训练过程中的信息泄露，而本文关注客户端早期检测目标过拟合的能力。

Method: 提出了三种检测技术：(a)标签翻转，(b)后门触发器注入，(c)模型指纹识别，使客户端能够验证全局聚合的完整性。

Result: 在多个数据集和不同攻击场景下的评估显示，三种方法都能可靠检测协调器诱导的目标过拟合，但在计算复杂度、检测延迟和误报率方面存在差异。

Conclusion: 提出的检测技术能够有效识别联邦学习中的目标过拟合攻击，使客户端能够在造成重大损害前及时退出，为联邦学习系统提供了重要的安全保障机制。

Abstract: Federated Learning (FL) enables collaborative model training across
decentralised clients while keeping local data private, making it a widely
adopted privacy-enhancing technology (PET). Despite its privacy benefits, FL
remains vulnerable to privacy attacks, including those targeting specific
clients. In this paper, we study an underexplored threat where a dishonest
orchestrator intentionally manipulates the aggregation process to induce
targeted overfitting in the local models of specific clients. Whereas many
studies in this area predominantly focus on reducing the amount of information
leakage during training, we focus on enabling an early client-side detection of
targeted overfitting, thereby allowing clients to disengage before significant
harm occurs. In line with this, we propose three detection techniques - (a)
label flipping, (b) backdoor trigger injection, and (c) model fingerprinting -
that enable clients to verify the integrity of the global aggregation. We
evaluated our methods on multiple datasets under different attack scenarios.
Our results show that the three methods reliably detect targeted overfitting
induced by the orchestrator, but they differ in terms of computational
complexity, detection latency, and false-positive rates.

</details>


### [58] [LOKI: Proactively Discovering Online Scam Websites by Mining Toxic Search Queries](https://arxiv.org/abs/2509.12181)
*Pujan Paudel,Gianluca Stringhini*

Main category: cs.CR

TL;DR: LOKI是一个基于LUPI和SERP特征提取的系统，能够高效识别可能返回高比例欺诈网站的搜索引擎查询，相比基线方法发现效率提升20.58倍


<details>
  <summary>Details</summary>
Motivation: 现有电商诈骗检测系统虽然准确，但缺乏有效发现候选诈骗网站的方法。用户报告反应慢，主动搜索方法覆盖率低且无法泛化到新诈骗类型

Method: 基于学习特权信息(LUPI)框架和搜索引擎结果页面(SERP)特征提取的关键词评分模型

Result: 使用仅1,663个已知诈骗网站作为种子，发现了52,493个未报告的诈骗网站，在10个主要诈骗类别中相比基线方法发现效率提升20.58倍

Conclusion: LOKI系统能够有效发现欺诈网站，具有良好的泛化能力，可用于发现新兴威胁

Abstract: Online e-commerce scams, ranging from shopping scams to pet scams, globally
cause millions of dollars in financial damage every year. In response, the
security community has developed highly accurate detection systems able to
determine if a website is fraudulent. However, finding candidate scam websites
that can be passed as input to these downstream detection systems is
challenging: relying on user reports is inherently reactive and slow, and
proactive systems issuing search engine queries to return candidate websites
suffer from low coverage and do not generalize to new scam types. In this
paper, we present LOKI, a system designed to identify search engine queries
likely to return a high fraction of fraudulent websites. LOKI implements a
keyword scoring model grounded in Learning Under Privileged Information (LUPI)
and feature distillation from Search Engine Result Pages (SERPs). We rigorously
validate LOKI across 10 major scam categories and demonstrate a 20.58 times
improvement in discovery over both heuristic and data-driven baselines across
all categories. Leveraging a small seed set of only 1,663 known scam sites, we
use the keywords identified by our method to discover 52,493 previously
unreported scams in the wild. Finally, we show that LOKI generalizes to
previously-unseen scam categories, highlighting its utility in surfacing
emerging threats.

</details>
