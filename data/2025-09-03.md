<div id=toc></div>

# Table of Contents

- [cs.CR](#cs.CR) [Total: 58]


<div id='cs.CR'></div>

# cs.CR [[Back]](#toc)

### [1] [Per-sender neural network classifiers for email authorship validation](https://arxiv.org/abs/2509.00005)
*Rohit Dube*

Main category: cs.CR

TL;DR: 论文提出作者身份验证方法，通过分析发送者写作风格来检测内部邮件欺诈，使用Char-CNN模型在模拟数据集上取得高准确率


<details>
  <summary>Details</summary>
Motivation: 企业面临内部邮件欺诈威胁，传统防御主要针对外部钓鱼邮件，缺乏对内部已泄露账户发送的伪造邮件的检测机制

Method: 提出作者身份验证概念，使用朴素贝叶斯和字符级卷积神经网络(Char-CNN)两种分类器，基于Enron语料库构建包含人工编写和LLM生成伪造邮件的数据集

Result: Char-CNN模型在各种情况下都取得了高准确率和F1分数，表现出色

Conclusion: 基于发送者写作风格的身份验证是可行的轻量级实时防御方案，可集成到现有邮件安全系统中且开销较低

Abstract: Business email compromise and lateral spear phishing attacks are among modern
organizations' most costly and damaging threats. While inbound phishing
defenses have improved significantly, most organizations still trust internal
emails by default, leaving themselves vulnerable to attacks from compromised
employee accounts. In this work, we define and explore the problem of
authorship validation: verifying whether a claimed sender actually authored a
given email. Authorship validation is a lightweight, real-time defense that
complements traditional detection methods by modeling per-sender writing style.
Further, the paper presents a collection of new datasets based on the Enron
corpus. These simulate inauthentic messages using both human-written and large
language model-generated emails. The paper also evaluates two classifiers -- a
Naive Bayes model and a character-level convolutional neural network (Char-CNN)
-- for the authorship validation task. Our experiments show that the Char-CNN
model achieves high accuracy and F1 scores under various circumstances.
Finally, we discuss deployment considerations and show that per-sender
authorship classifiers are practical for integrating into existing commercial
email security systems with low overhead.

</details>


### [2] [Case Studies: Effective Approaches for Navigating Cross-Border Cloud Data Transfers Amid U.S. Government Privacy and Safety Concerns](https://arxiv.org/abs/2509.00006)
*Motunrayo Adebayo*

Main category: cs.CR

TL;DR: 本文研究云计算技术对国际信息交换的影响，分析法律和技术层面的挑战，并提出安全信息交换的措施建议


<details>
  <summary>Details</summary>
Motivation: 随着云计算技术的出现，国家间信息自由交换的可能性迅速增加，但各国在制定相关框架时面临法律和技术上的重大挑战，需要研究如何确保云技术下的信息安全交换

Method: 分析云计算技术带来的信息交换可能性，研究各国现有法律框架的漏洞和挑战，探讨技术实现方案

Result: 发现云计算技术虽然促进了国际信息交换，但现有法律框架存在漏洞，可能阻碍信息自由访问并危及数据隐私

Conclusion: 需要制定综合措施来确保通过云计算技术进行安全的信息交换，这对国内外商业活动都具有重要意义

Abstract: This study attempts to explain the impact of information exchange from one
country to another, as well as the legal and technological implications for
these exchanges. Due to the emergence of cloud technology, possibilities for
free exchange of information between countries have increased rapidly, as it
has become possible to save information in a country and access it in almost
any part of the world. Countries all around the world have been confronted with
developing frameworks to facilitate this process, although there are
significant challenges which must be confronted on legal and technological
fronts, as loopholes in the framework adopted by countries may hinder free
access to information stored on cloud, and also compromise data privacy. Cloud
technology is impacting a lot of issues, including domestic and international
businesses, hence the need for a study to propose measures for safe exchange of
information using cloud technology.

</details>


### [3] [Keystroke Detection by Exploiting Unintended RF Emission from Repaired USB Keyboards](https://arxiv.org/abs/2509.00043)
*Md Faizul Bari,Yi Xie,Meghna Roy Choudhury,Shreyas Sen*

Main category: cs.CR

TL;DR: 通过修复后的USB线粒形成小型天线，使得电磁漏泄能够在12米远距离上高准确检测键盘打字动作，曝露了硬件修复带来的新安全风险


<details>
  <summary>Details</summary>
Motivation: 以前认为电磁漏泄信号弱且传输距离短，但研究发现传统线粒修复过程会形成小型单极天线，使漏泄信号能够远距离传输，需要探索这种漏浮的安全风险

Method: 在3种不同环境中（开阔空间、办公室外走廊、建筑外）收集70种不同键盘打字的数据，开发高效检测算法，研究干扰和人体耦合效应，并探索外部金属屏蔽作为防范措施

Result: 在远进12米的距离上实现了约100%的键盘打字检测准确率，这是目前文献中USB键盘在这种远距离上的最高准确率记录

Conclusion: 这项工作曝露了由硬件修改引发的新攻击面，证明修复后的USB线粒会产生严重的电磁漏泄风险，并提出了金属屏蔽等潜在的防范方案

Abstract: Electronic devices and cables inadvertently emit RF emissions as a byproduct
of signal processing and/or transmission. Labeled as electromagnetic
emanations, they form an EM side-channel for data leakage. Previously, it was
believed that such leakage could be contained within a facility since they are
weak signals with a short transmission range. However, in the preliminary
version of this work [1], we found that the traditional cable repairing process
forms a tiny monopole antenna that helps emanations transmit over a long range.
Experimentation with three types of cables revealed that emanations from
repaired cables remain detectable even at >4 m and can penetrate a 14 cm thick
concrete wall. In this extended version, we show that such emanation can be
exploited at a long distance for information extraction by detecting keystrokes
typed on a repaired USB keyboard. By collecting data for 70 different
keystrokes at different distances from the target in 3 diverse environments
(open space, a corridor outside an office room, and outside a building) and
developing an efficient detection algorithm, ~100% keystroke detection accuracy
has been achieved up to 12 m distance, which is the highest reported accuracy
at such a long range for USB keyboards in the literature. The effect of two
experimental factors, interference and human-body coupling, has been
investigated thoroughly. Along with exploring the vulnerability, multi-layer
external metal shielding during the repairing process as a possible remedy has
been explored. This work exposes a new attack surface caused by hardware
modification, its exploitation, and potential countermeasures.

</details>


### [4] [Cryptographic Challenges: Masking Sensitive Data in Cyber Crimes through ASCII Art](https://arxiv.org/abs/2509.00059)
*Andres Alejandre,Kassandra Delfin,Victor Castano*

Main category: cs.CR

TL;DR: ASCII艺术作为一种新颖的信息隐藏技术，可用于网络犯罪中保护敏感数据，具有简单性和模糊性的优势。


<details>
  <summary>Details</summary>
Motivation: 研究ASCII艺术在保护个人数据方面的潜力，特别是在数据传输过程中，探讨其在网络安全领域的应用价值。

Method: 通过分析ASCII艺术的独特属性和历史背景，评估该技术在各种网络犯罪场景中的优势和局限性。

Result: 研究发现ASCII艺术凭借其简单性和模糊性，可以有效对抗网络犯罪分子，成为一种有效的数据保护工具。

Conclusion: 需要加强数据安全措施和提高隐私意识，ASCII艺术可作为网络安全防护的有效补充手段。

Abstract: The use of ASCII art as a novel approach to masking sensitive information in
cybercrime, focusing on its potential role in protecting personal data during
the delivery process and beyond, is presented. By examining the unique
properties of ASCII art and its historical context, this study discusses the
advantages and limitations of employing this technique in various cybercrime
scenarios. Additionally, providing recommendations for enhancing data security
practices and fostering a culture of privacy awareness in both businesses and
individuals. The findings suggest that ASCII art, with its simplicity and
ambiguity, can serve as an effective tool against cybercriminals, emphasizing
the need for robust data security measures and increased privacy awareness in
today's interconnected world.

</details>


### [5] [Enabling Transparent Cyber Threat Intelligence Combining Large Language Models and Domain Ontologies](https://arxiv.org/abs/2509.00081)
*Luca Cotti,Anisa Rula,Devis Bianchini,Federico Cerutti*

Main category: cs.CR

TL;DR: 提出结合本体论和大型语言模型的新方法，提高网络安全日志信息提取的准确性和可解释性


<details>
  <summary>Details</summary>
Motivation: 当前方法在处理非结构化或模糊日志条目时难以可靠识别恶意事件，需要更准确透明的信息提取技术

Method: 整合领域本体和SHACL约束来指导语言模型输出结构，确保语义有效性，提取信息组织成本体丰富的图数据库

Result: 相比传统仅提示方法，在信息提取准确性方面表现更优，特别关注提取质量而非处理速度

Conclusion: 该方法为网络安全威胁情报提供了更准确和可解释的信息提取解决方案，适用于蜜罐日志等恶意活动分析场景

Abstract: Effective Cyber Threat Intelligence (CTI) relies upon accurately structured
and semantically enriched information extracted from cybersecurity system logs.
However, current methodologies often struggle to identify and interpret
malicious events reliably and transparently, particularly in cases involving
unstructured or ambiguous log entries. In this work, we propose a novel
methodology that combines ontology-driven structured outputs with Large
Language Models (LLMs), to build an Artificial Intelligence (AI) agent that
improves the accuracy and explainability of information extraction from
cybersecurity logs. Central to our approach is the integration of domain
ontologies and SHACL-based constraints to guide the language model's output
structure and enforce semantic validity over the resulting graph. Extracted
information is organized into an ontology-enriched graph database, enabling
future semantic analysis and querying. The design of our methodology is
motivated by the analytical requirements associated with honeypot log data,
which typically comprises predominantly malicious activity. While our case
study illustrates the relevance of this scenario, the experimental evaluation
is conducted using publicly available datasets. Results demonstrate that our
method achieves higher accuracy in information extraction compared to
traditional prompt-only approaches, with a deliberate focus on extraction
quality rather than processing speed.

</details>


### [6] [Private, Verifiable, and Auditable AI Systems](https://arxiv.org/abs/2509.00085)
*Tobin South*

Main category: cs.CR

TL;DR: 本论文提出了一种整合隐私、可验证性和可审计性的框架，通过零知识动证、安全多方计算等技术解决AI系统的安全性和可信赖性挑战。


<details>
  <summary>Details</summary>
Motivation: 因应对人工智能社会依赖性增强的需求，确保AI系统的安全性、责任制和可信赖性，特别是基础模型中隐私、可验证性和可审计性的复杂交互问题。

Method: 采用零知识动证技术实现AI系统的可验证和可审计断言；利用安全多方计算和可信执行环境进行大型语言模型的可审计保密部署；实施增强的授权机制、凭证系统和访问控制以保护自主和多代理AI系统。

Result: 研究提出了一系列解决隐私和可验证性关键挑战的新颖技术方案，为基础模型AI系统提供了平衡隐私、可验证性和可审计性的完整视角。

Conclusion: 该研究为系统设计者提供了实用的设计蓝图，并为AI安全和治理的政策讨论提供信息支持，推动负责任的AI创新。

Abstract: The growing societal reliance on artificial intelligence necessitates robust
frameworks for ensuring its security, accountability, and trustworthiness. This
thesis addresses the complex interplay between privacy, verifiability, and
auditability in modern AI, particularly in foundation models. It argues that
technical solutions that integrate these elements are critical for responsible
AI innovation. Drawing from international policy contributions and technical
research to identify key risks in the AI pipeline, this work introduces novel
technical solutions for critical privacy and verifiability challenges.
Specifically, the research introduces techniques for enabling verifiable and
auditable claims about AI systems using zero-knowledge cryptography; utilizing
secure multi-party computation and trusted execution environments for
auditable, confidential deployment of large language models and information
retrieval; and implementing enhanced delegation mechanisms, credentialing
systems, and access controls to secure interactions with autonomous and
multi-agent AI systems. Synthesizing these technical advancements, this
dissertation presents a cohesive perspective on balancing privacy,
verifiability, and auditability in foundation model-based AI systems, offering
practical blueprints for system designers and informing policy discussions on
AI safety and governance.

</details>


### [7] [AEGIS : Automated Co-Evolutionary Framework for Guarding Prompt Injections Schema](https://arxiv.org/abs/2509.00088)
*Ting-Chun Liu,Ching-Yu Hsu,Kuan-Yi Lee,Chi-An Fu,Hung-yi Lee*

Main category: cs.CR

TL;DR: 提出了AEGIS框架，通过自动化的协同进化方法优化攻击和防御提示，显著提升了提示注入攻击的检测效果和攻击成功率。


<details>
  <summary>Details</summary>
Motivation: 提示注入攻击对LLM的安全部署构成重大挑战，现有的基于提示的检测方法需要手动工程，效果有限。

Method: 使用基于梯度的自然语言提示优化技术，让攻击和防御提示相互迭代优化，通过文本梯度优化模块实现自主进化。

Result: 攻击成功率(ASR)达到1.0，比基线提升0.26；检测真阳性率(TPR)达到0.84，提升0.23；真阴性率(TNR)保持在0.89。

Conclusion: 对抗训练是一种可扩展且有效的防护提示注入的方法，协同进化、梯度缓冲和多目标优化对性能提升至关重要。

Abstract: Prompt injection attacks pose a significant challenge to the safe deployment
of Large Language Models (LLMs) in real-world applications. While prompt-based
detection offers a lightweight and interpretable defense strategy, its
effectiveness has been hindered by the need for manual prompt engineering. To
address this issue, we propose AEGIS , an Automated co-Evolutionary framework
for Guarding prompt Injections Schema. Both attack and defense prompts are
iteratively optimized against each other using a gradient-like natural language
prompt optimization technique. This framework enables both attackers and
defenders to autonomously evolve via a Textual Gradient Optimization (TGO)
module, leveraging feedback from an LLM-guided evaluation loop. We evaluate our
system on a real-world assignment grading dataset of prompt injection attacks
and demonstrate that our method consistently outperforms existing baselines,
achieving superior robustness in both attack success and detection.
Specifically, the attack success rate (ASR) reaches 1.0, representing an
improvement of 0.26 over the baseline. For detection, the true positive rate
(TPR) improves by 0.23 compared to the previous best work, reaching 0.84, and
the true negative rate (TNR) remains comparable at 0.89. Ablation studies
confirm the importance of co-evolution, gradient buffering, and multi-objective
optimization. We also confirm that this framework is effective in different
LLMs. Our results highlight the promise of adversarial training as a scalable
and effective approach for guarding prompt injections.

</details>


### [8] [Enhanced Rényi Entropy-Based Post-Quantum Key Agreement with Provable Security and Information-Theoretic Guarantees](https://arxiv.org/abs/2509.00104)
*Ruopengyu Xu,Chenglian Liu*

Main category: cs.CR

TL;DR: 本文提出了一种基于Rényi熵的增强型后量子密钥协商协议，通过熵保持操作和秘密共享验证实现可证明的量子安全性，达到2^128量子安全保证。


<details>
  <summary>Details</summary>
Motivation: 解决原始构造中的漏洞，同时保持信息论安全特性，为量子计算时代提供长期密码学安全保障。

Method: 利用熵保持操作和秘密共享验证的理论框架，结合熵放大技术和量子抗性承诺，在量子随机预言机模型下建立安全协议。

Result: 协议实现了128位量子安全保证，具有O(n^2)通信复杂度，能够抵抗已知量子攻击向量，包括Grover加速暴力攻击和量子内存攻击。

Conclusion: 该方法提供了无需硬度假设的信息论安全性，同时保持多项式复杂度，为安全多方计算和量子网络应用奠定了基础。

Abstract: This paper presents an enhanced post-quantum key agreement protocol based on
R\'{e}nyi entropy, addressing vulnerabilities in the original construction
while preserving information-theoretic security properties. We develop a
theoretical framework leveraging entropy-preserving operations and
secret-shared verification to achieve provable security against quantum
adversaries. Through entropy amplification techniques and quantum-resistant
commitments, the protocol establishes $2^{128}$ quantum security guarantees
under the quantum random oracle model. Key innovations include a
confidentiality-preserving verification mechanism using distributed polynomial
commitments, tightened min-entropy bounds with guaranteed non-negativity, and
composable security proofs in the quantum universal composability framework.
Unlike computational approaches, our method provides information-theoretic
security without hardness assumptions while maintaining polynomial complexity.
Theoretical analysis demonstrates resilience against known quantum attack
vectors, including Grover-accelerated brute force and quantum memory attacks.
The protocol achieves parameterization for 128-bit quantum security with
efficient $\mathcal{O}(n^2)$ communication complexity. Extensions to secure
multiparty computation and quantum network applications are established,
providing a foundation for long-term cryptographic security. All security
claims are derived from mathematical proofs; this theoretical work presents no
experimental validation.

</details>


### [9] [A Whole New World: Creating a Parallel-Poisoned Web Only AI-Agents Can See](https://arxiv.org/abs/2509.00124)
*Shaked Zychlinski*

Main category: cs.CR

TL;DR: 本文提出了一种针对LLM驱动的自主网页浏览代理的新型攻击方法，通过网站伪装技术识别AI代理流量并注入恶意指令，实现行为劫持。


<details>
  <summary>Details</summary>
Motivation: 随着AI网页浏览代理的普及，其独特的数字指纹（浏览器属性、自动化框架特征等）形成了可识别的新型网络流量类别，这为攻击者提供了新的攻击面。

Method: 利用网站伪装技术，恶意网站通过指纹识别技术区分AI代理请求，向代理提供视觉相同但嵌入隐藏恶意指令（如间接提示注入）的伪装页面。

Result: 攻击能够劫持代理行为，导致数据泄露、恶意软件执行或错误信息传播，同时对人类用户和传统安全爬虫完全不可见。

Conclusion: 该研究形式化了威胁模型，详细阐述了代理指纹识别和伪装机制，强调了为AI代理安全开发强大防御措施的紧迫性。

Abstract: This paper introduces a novel attack vector that leverages website cloaking
techniques to compromise autonomous web-browsing agents powered by Large
Language Models (LLMs). As these agents become more prevalent, their unique and
often homogenous digital fingerprints - comprising browser attributes,
automation framework signatures, and network characteristics - create a new,
distinguishable class of web traffic. The attack exploits this
fingerprintability. A malicious website can identify an incoming request as
originating from an AI agent and dynamically serve a different, "cloaked"
version of its content. While human users see a benign webpage, the agent is
presented with a visually identical page embedded with hidden, malicious
instructions, such as indirect prompt injections. This mechanism allows
adversaries to hijack agent behavior, leading to data exfiltration, malware
execution, or misinformation propagation, all while remaining completely
invisible to human users and conventional security crawlers. This work
formalizes the threat model, details the mechanics of agent fingerprinting and
cloaking, and discusses the profound security implications for the future of
agentic AI, highlighting the urgent need for robust defenses against this
stealthy and scalable attack.

</details>


### [10] [A Systematic Approach to Estimate the Security Posture of a Cyber Infrastructure: A Technical Report](https://arxiv.org/abs/2509.00266)
*Qishen Sam Liang*

Main category: cs.CR

TL;DR: 该报告提出了一个面向学术研究网络基础设施的系统性安全评估框架，采用任务导向的方法构建攻击图来识别安全漏洞和防御策略。


<details>
  <summary>Details</summary>
Motivation: 学术研究网络基础设施具有协作性、异构性和缺乏定制化安全评估框架的特点，现有标准过于通用或复杂，难以有效应用。

Method: 采用自上而下的三步法：(1)定义不可接受的损失和安全任务，(2)识别相关系统危害和关键资产，(3)构建安全知识图谱和定向攻击图来映射所有潜在攻击路径。

Result: 通过可视化攻击路径和防御机制，框架提供了系统漏洞和安全差距的清晰全面概览。

Conclusion: 该结构化方法使基础设施运营商能够主动评估风险、优先制定缓解策略，并做出明智的决策来加强整体安全态势。

Abstract: Academic and research Cyber Infrastructures (CI) present unique security
challenges due to their collaborative nature, heterogeneous components, and the
lack of practical, tailored security assessment frameworks. Existing standards
can be too generic or complex for CI administrators to apply effectively. This
report introduces a systematic, mission-centric approach to estimate and
analyze the security posture of a CI. The framework guides administrators
through a top-down process: (1) defining unacceptable losses and security
missions, (2) identifying associated system hazards and critical assets, and
(3) modeling the CI's components and their relationships as a security
knowledge graph. The core of this methodology is the construction of directed
attack graphs, which systematically map all potential paths an adversary could
take from an entry point to a critical asset. By visualizing these attack paths
alongside defense mechanisms, the framework provides a clear, comprehensive
overview of the system's vulnerabilities and security gaps. This structured
approach enables CI operators to proactively assess risks, prioritize
mitigation strategies, and make informed, actionable decisions to strengthen
the overall security posture of the CI.

</details>


### [11] [ShadowScope: GPU Monitoring and Validation via Composable Side Channel Signals](https://arxiv.org/abs/2509.00300)
*Ghadeer Almusaddar,Yicheng Zhang,Saber Ganjisaffar,Barry Williams,Yu David Liu,Dmitry Ponomare,Nael Abu-Ghazaleh*

Main category: cs.CR

TL;DR: ShadowScope是一个GPU计算完整性验证框架，通过可组合的黄金模型和硬件辅助验证机制，有效防御内存安全漏洞和微架构攻击，平均运行时开销仅4.6%。


<details>
  <summary>Details</summary>
Motivation: 随着GPU在机器学习等计算密集型任务中的广泛应用，确保GPU计算完整性变得至关重要。现有基于黄金模型的验证方法存在脆弱性、对干扰敏感且扩展性差的问题。

Method: 提出ShadowScope框架：1）使用可组合的黄金模型，将可信内核执行分解为模块化、可重复的功能单元；2）引入ShadowScope+硬件辅助验证机制，在GPU流水线中集成轻量级片上检查。

Result: 该方法能够以更细粒度捕获执行模式，对噪声、工作负载变化和干扰具有鲁棒性。ShadowScope+实现了高验证准确率，平均运行时开销仅为4.6%，硬件和设计复杂度极低。

Conclusion: 研究表明侧信道可观测性可以系统性地转化为实用的GPU内核完整性防御机制，为解决GPU计算安全问题提供了有效解决方案。

Abstract: As modern systems increasingly rely on GPUs for computationally intensive
tasks such as machine learning acceleration, ensuring the integrity of GPU
computation has become critically important. Recent studies have shown that GPU
kernels are vulnerable to both traditional memory safety issues (e.g., buffer
overflow attacks) and emerging microarchitectural threats (e.g., Rowhammer
attacks), many of which manifest as anomalous execution behaviors observable
through side-channel signals. However, existing golden model based validation
approaches that rely on such signals are fragile, highly sensitive to
interference, and do not scale well across GPU workloads with diverse
scheduling behaviors. To address these challenges, we propose ShadowScope, a
monitoring and validation framework that leverages a composable golden model.
Instead of building a single monolithic reference, ShadowScope decomposes
trusted kernel execution into modular, repeatable functions that encode key
behavioral features. This composable design captures execution patterns at
finer granularity, enabling robust validation that is resilient to noise,
workload variation, and interference across GPU workloads. To further reduce
reliance on noisy software-only monitoring, we introduce ShadowScope+, a
hardware-assisted validation mechanism that integrates lightweight on-chip
checks into the GPU pipeline. ShadowScope+ achieves high validation accuracy
with an average runtime overhead of just 4.6%, while incurring minimal hardware
and design complexity. Together, these contributions demonstrate that
side-channel observability can be systematically repurposed into a practical
defense for GPU kernel integrity.

</details>


### [12] [A Hybrid AI-based and Rule-based Approach to DICOM De-identification: A Solution for the MIDI-B Challenge](https://arxiv.org/abs/2509.00437)
*Hamideh Haghiri,Rajesh Baidya,Stefan Dvoretskii,Klaus H. Maier-Hein,Marco Nolden*

Main category: cs.CR

TL;DR: 提出了一种混合去标识化框架，结合规则方法和AI模型，专门处理DICOM医疗影像数据，达到99.91%的去标识准确率。


<details>
  <summary>Details</summary>
Motivation: 医疗影像数据共享需要确保患者隐私安全，DICOM文件包含大量个人身份信息和健康信息，需要高效可靠的去标识化解决方案。

Method: 采用混合方法：基于TCIA最佳实践指南的规则组件处理结构化数据，PaddleOCR提取图像文本，微调RoBERTa模型处理自由文本中的PII/PHI信息，使用dciodvfy验证DICOM文件完整性。

Result: 在MIDI-B测试数据集上达到99.91%的去标识准确率，通过迭代优化（包括自定义规则和私有标签处理）显著提升性能。

Conclusion: 结合规则基础的合规性和AI驱动的适应性，能有效解决DICOM去标识化的复杂挑战，为医疗数据安全共享提供了可靠解决方案。

Abstract: Ensuring the de-identification of medical imaging data is a critical step in
enabling safe data sharing. This paper presents a hybrid de-identification
framework designed to process Digital Imaging and Communications in Medicine
(DICOM) files. Our framework adopts a modified, pre-built rule-based component,
updated with The Cancer Imaging Archive (TCIA)'s best practices guidelines, as
outlined in DICOM PS 3.15, for improved performance. It incorporates PaddleOCR,
a robust Optical Character Recognition (OCR) system for extracting text from
images, and RoBERTa, a fine-tuned transformer-based model for identifying and
removing Personally Identifiable Information (PII) and Protected Health
Information (PHI). Initially, the transformer-based model and the rule-based
component were integrated to process for both structured data and free text.
However, this coarse-grained approach did not yield optimal results. To improve
performance, we refined our approach by applying the transformer model
exclusively to free text, while structured data was handled only by rule-based
methods. In this framework the DICOM validator dciodvfy was leveraged to ensure
the integrity of DICOM files after the deID process. Through iterative
refinement, including the incorporation of custom rules and private tag
handling, the framework achieved a de-identification accuracy of 99.91% on the
MIDI-B test dataset. The results demonstrate the effectiveness of combining
rule-based compliance with AI-enabled adaptability in addressing the complex
challenges of DICOM de-identification.

</details>


### [13] [Cross-Domain Malware Detection via Probability-Level Fusion of Lightweight Gradient Boosting Models](https://arxiv.org/abs/2509.00476)
*Omar Khalid Ali Mohamed*

Main category: cs.CR

TL;DR: 这篇论文提出了一种轻量级的恶意软件检测框架，通过概率级融合三种不同数据集的预测，实现了更好的跨域泛化能力和计算效率。


<details>
  <summary>Details</summary>
Motivation: 传统的单数据集模型在跨域泛化方面表现局限，且计算成本较高。恶意软件的日益复杂化导致需要更突出的检测机制。

Method: 使用三个不同数据集(EMBER静态特征、API调用序列行为特征、CIC混淆内存模式)，训练单独的LightGBM分类器，选择顶部预测特征确保效率，通过网格搜索确定优化权重进行概率融合。

Result: 在跨域验证集上达到了0.823的宏观F1分数，显著超过了单独模型，提供了更优秀的泛化能力。框架保持低计算开销，适合实时部署。

Conclusion: 该轻量级融合框架能够有效解决恶意软件检测中的跨域泛化问题，在保持计算效率的同时提高了检测性能，具有实时部署的实用价值。

Abstract: The escalating sophistication of malware necessitates robust detection
mechanisms that generalize across diverse data sources. Traditional
single-dataset models struggle with cross-domain generalization and often incur
high computational costs. This paper presents a novel, lightweight framework
for malware detection that employs probability-level fusion across three
distinct datasets: EMBER (static features), API Call Sequences (behavioral
features), and CIC Obfuscated Memory (memory patterns). Our method trains
individual LightGBM classifiers on each dataset, selects top predictive
features to ensure efficiency, and fuses their prediction probabilities using
optimized weights determined via grid search. Extensive experiments demonstrate
that our fusion approach achieves a macro F1-score of 0.823 on a cross-domain
validation set, significantly outperforming individual models and providing
superior generalization. The framework maintains low computational overhead,
making it suitable for real-time deployment, and all code and data are provided
for full reproducibility.

</details>


### [14] [FreeTalk:A plug-and-play and black-box defense against speech synthesis attacks](https://arxiv.org/abs/2509.00561)
*Yuwen Pu,Zhou Feng,Chunyi Zhou,Jiahao Chen,Chunqiang Hu,Haibo Hu,Shouling Ji*

Main category: cs.CR

TL;DR: 提出了一种轻量级、鲁棒的即插即用隐私保护方法，通过在频域添加扰动来防御语音合成攻击，同时保持语音质量和实用性


<details>
  <summary>Details</summary>
Motivation: 随着语音助手和语音验证的广泛应用，用户的语音可能被攻击者收集用于语音合成攻击，现有隐私保护方法存在迁移性差、鲁棒性低、计算开销大等问题，限制了实际部署

Method: 在频域生成并添加扰动实现隐私保护，采用数据增强策略和噪声平滑机制提高鲁棒性，提出身份级保护机制为同一说话人生成通用扰动以减少防御开销

Result: 在5个语音合成模型、5个语音验证模型、1个语音识别模型和2个数据集上的实验表明，该方法具有满意的隐私保护性能、高语音质量和实用性

Conclusion: 该方法有效解决了现有语音隐私保护方法的局限性，提供了轻量级、鲁棒且实用的防御方案，适用于黑盒设置下的语音合成攻击防护

Abstract: Recently, speech assistant and speech verification have been used in many
fields, which brings much benefit and convenience for us. However, when we
enjoy these speech applications, our speech may be collected by attackers for
speech synthesis. For example, an attacker generates some inappropriate
political opinions with the characteristic of the victim's voice by obtaining a
piece of the victim's speech, which will greatly influence the victim's
reputation. Specifically, with the appearance of some zero-shot voice
conversion methods, the cost of speech synthesis attacks has been further
reduced, which also brings greater challenges to user voice security and
privacy. Some researchers have proposed the corresponding privacy-preserving
methods. However, the existing approaches have some non-negligible drawbacks:
low transferability and robustness, high computational overhead. These
deficiencies seriously limit the existing method deployed in practical
scenarios. Therefore, in this paper, we propose a lightweight, robust,
plug-and-play privacy preservation method against speech synthesis attacks in a
black-box setting. Our method generates and adds a frequency-domain
perturbation to the original speech to achieve privacy protection and high
speech quality. Then, we present a data augmentation strategy and noise
smoothing mechanism to improve the robustness of the proposed method. Besides,
to reduce the user's defense overhead, we also propose a novel identity-wise
protection mechanism. It can generate a universal perturbation for one speaker
and support privacy preservation for speech of any length. Finally, we conduct
extensive experiments on 5 speech synthesis models, 5 speech verification
models, 1 speech recognition model, and 2 datasets. The experimental results
demonstrate that our method has satisfying privacy-preserving performance, high
speech quality, and utility.

</details>


### [15] [Federated Survival Analysis with Node-Level Differential Privacy: Private Kaplan-Meier Curves](https://arxiv.org/abs/2509.00615)
*Narasimha Raghavan Veeraragavan,Jan Franz Nygård*

Main category: cs.CR

TL;DR: 该论文研究如何在保护患者隐私的前提下，通过节点级差分隐私计算跨多个医疗管辖区的Kaplan-Meier生存曲线。每个站点仅披露一次添加拉普拉斯噪声的曲线，服务器平均噪声曲线，总体隐私预算保持不变。


<details>
  <summary>Details</summary>
Motivation: 在医疗数据共享中保护患者隐私的同时，实现跨多个医疗管辖区的生存分析，避免迭代训练或繁重的加密技术。

Method: 使用四种一次性平滑技术：离散余弦变换、Haar小波收缩、自适应全变差去噪和参数化Weibull拟合，在NCCTG肺癌队列上进行基准测试，涵盖五种隐私级别和三种分区场景。

Result: 全变差去噪方法获得最佳平均精度，频域平滑器提供更强的鲁棒性，Weibull模型在最严格隐私设置下表现最稳定。所有方法在隐私预算≥0.5时都能将经验对数秩I类错误控制在15%以下。

Conclusion: 研究表明无需迭代训练或复杂加密技术，即可在保护隐私的前提下共享具有临床实用价值的生存信息。

Abstract: We investigate how to calculate Kaplan-Meier survival curves across multiple
health-care jurisdictions while protecting patient privacy with node-level
differential privacy. Each site discloses its curve only once, adding Laplace
noise whose scale is determined by the length of the common time grid; the
server then averages the noisy curves, so the overall privacy budget remains
unchanged. We benchmark four one-shot smoothing techniques: Discrete Cosine
Transform, Haar Wavelet shrinkage, adaptive Total-Variation denoising, and a
parametric Weibull fit on the NCCTG lung-cancer cohort under five privacy
levels and three partition scenarios (uniform, moderately skewed, highly
imbalanced). Total-Variation gives the best mean accuracy, whereas the
frequency-domain smoothers offer stronger worst-case robustness and the Weibull
model shows the most stable behaviour at the strictest privacy setting. Across
all methods the released curves keep the empirical log-rank type-I error below
fifteen percent for privacy budgets of 0.5 and higher, demonstrating that
clinically useful survival information can be shared without iterative training
or heavy cryptography.

</details>


### [16] [Enabling Trustworthy Federated Learning via Remote Attestation for Mitigating Byzantine Threats](https://arxiv.org/abs/2509.00634)
*Chaoyu Zhang,Heng Jin,Shanghao Shi,Hexuan Yu,Sydney Johns,Y. Thomas Hou,Wenjing Lou*

Main category: cs.CR

TL;DR: Sentinel是一个基于远程认证的联邦学习安全方案，通过代码插桩和可信执行环境来检测和防御拜占庭攻击，确保本地训练过程的完整性。


<details>
  <summary>Details</summary>
Motivation: 联邦学习面临拜占庭攻击威胁，现有方法难以区分恶意更新和良性数据变异，导致高误报率和性能问题。

Method: 采用代码插桩追踪控制流和监控关键变量，在可信执行环境中使用可信训练记录器生成加密认证报告，服务器验证后只聚合可信模型更新。

Result: 在物联网设备上的实验表明，Sentinel能以低运行时和内存开销确保本地训练完整性的可信度。

Conclusion: 从系统安全角度提出的Sentinel方案有效解决了联邦学习中的拜占庭攻击问题，提供了可靠的客户端透明性。

Abstract: Federated Learning (FL) has gained significant attention for its
privacy-preserving capabilities, enabling distributed devices to
collaboratively train a global model without sharing raw data. However, its
distributed nature forces the central server to blindly trust the local
training process and aggregate uncertain model updates, making it susceptible
to Byzantine attacks from malicious participants, especially in
mission-critical scenarios. Detecting such attacks is challenging due to the
diverse knowledge across clients, where variations in model updates may stem
from benign factors, such as non-IID data, rather than adversarial behavior.
Existing data-driven defenses struggle to distinguish malicious updates from
natural variations, leading to high false positive rates and poor filtering
performance.
  To address this challenge, we propose Sentinel, a remote attestation
(RA)-based scheme for FL systems that regains client-side transparency and
mitigates Byzantine attacks from a system security perspective. Our system
employs code instrumentation to track control-flow and monitor critical
variables in the local training process. Additionally, we utilize a trusted
training recorder within a Trusted Execution Environment (TEE) to generate an
attestation report, which is cryptographically signed and securely transmitted
to the server. Upon verification, the server ensures that legitimate client
training processes remain free from program behavior violation or data
manipulation, allowing only trusted model updates to be aggregated into the
global model. Experimental results on IoT devices demonstrate that Sentinel
ensures the trustworthiness of the local training integrity with low runtime
and memory overhead.

</details>


### [17] [LLM-HyPZ: Hardware Vulnerability Discovery using an LLM-Assisted Hybrid Platform for Zero-Shot Knowledge Extraction and Refinement](https://arxiv.org/abs/2509.00647)
*Yu-Zheng Lin,Sujan Ghimire,Abhiram Nandimandalam,Jonah Michael Camacho,Unnati Tripathi,Rony Macwan,Sicong Shao,Setareh Rafatirad,Rozhin Yasaei,Pratik Satam,Soheil Salehi*

Main category: cs.CR

TL;DR: 提出了LLM-HyPZ框架，利用大语言模型进行零样本知识提取，从11.4万条CVE中识别出1742个硬件相关漏洞，准确率达99.5%，支持了MITRE CWE硬件弱点清单的更新。


<details>
  <summary>Details</summary>
Motivation: 硬件漏洞具有持久性风险且难以修补，现有专家驱动的分析方法缺乏统计严谨性且存在主观偏差，需要数据驱动的规模化分析方法。

Method: 采用LLM辅助的混合框架，整合零样本分类、上下文嵌入、无监督聚类和提示驱动的摘要技术，从漏洞语料库中大规模挖掘硬件相关CVE。

Result: 从2021-2024年CVE语料库中识别出1742个硬件相关漏洞，归纳为5个重复主题，LLaMA 3.3 70B模型在验证集上达到99.5%的分类准确率。

Conclusion: LLM-HyPZ是首个数据驱动的可扩展方法，能够系统发现硬件漏洞，弥合专家知识与实际漏洞证据之间的差距，显著减少专家工作量并加速证据收集。

Abstract: The rapid growth of hardware vulnerabilities has created an urgent need for
systematic and scalable analysis methods. Unlike software flaws, which are
often patchable post-deployment, hardware weaknesses remain embedded across
product lifecycles, posing persistent risks to processors, embedded devices,
and IoT platforms. Existing efforts such as the MITRE CWE Hardware List (2021)
relied on expert-driven Delphi surveys, which lack statistical rigor and
introduce subjective bias, while large-scale data-driven foundations for
hardware weaknesses have been largely absent. In this work, we propose
LLM-HyPZ, an LLM-assisted hybrid framework for zero-shot knowledge extraction
and refinement from vulnerability corpora. Our approach integrates zero-shot
LLM classification, contextualized embeddings, unsupervised clustering, and
prompt-driven summarization to mine hardware-related CVEs at scale. Applying
LLM-HyPZ to the 2021-2024 CVE corpus (114,836 entries), we identified 1,742
hardware-related vulnerabilities. We distilled them into five recurring themes,
including privilege escalation via firmware and BIOS, memory corruption in
mobile and IoT systems, and physical access exploits. Benchmarking across seven
LLMs shows that LLaMA 3.3 70B achieves near-perfect classification accuracy
(99.5%) on a curated validation set. Beyond methodological contributions, our
framework directly supported the MITRE CWE Most Important Hardware Weaknesses
(MIHW) 2025 update by narrowing the candidate search space. Specifically, our
pipeline surfaced 411 of the 1,026 CVEs used for downstream MIHW analysis,
thereby reducing expert workload and accelerating evidence gathering. These
results establish LLM-HyPZ as the first data-driven, scalable approach for
systematically discovering hardware vulnerabilities, thereby bridging the gap
between expert knowledge and real-world vulnerability evidence.

</details>


### [18] [Virtual Reality, Real Problems: A Longitudinal Security Analysis of VR Firmware](https://arxiv.org/abs/2509.00662)
*Vamsi Shankar Simhadri,Yichang Xiong,Habiba Farrukh,Xiaokuan Zhang*

Main category: cs.CR

TL;DR: 首次对VR固件进行全面安全分析，发现了多个安全问题，包括内核安全特性缺失、二进制硬化不充分、权限执行不一致等


<details>
  <summary>Details</summary>
Motivation: VR设备采用Android系统但添加了VR特有定制化，存在新的安全风险，而现有研究主要集中在普通Android设备

Method: 收集Quest和Pico两大厂商超300个VR固件版本，进行纵向分析，涵盖内核层、系统二进制和库层、应用层

Result: 识别出多个安全问题：内核安全特性缺失、二进制硬化不充分、权限执行不一致、SELinux策略执行不充分

Conclusion: 研究为VR开发者、用户和厂商提供了重要安全资源，建立了安全建议，将推动VR生态系统的未来发展

Abstract: Virtual Reality (VR) technology is rapidly growing in recent years. VR
devices such as Meta Quest 3 utilize numerous sensors to collect users' data to
provide an immersive experience. Due to the extensive data collection and the
immersive nature, the security of VR devices is paramount. Leading VR devices
often adopt and customize Android systems, which makes them susceptible to both
Android-based vulnerabilities and new issues introduced by VR-specific
customizations (e.g., system services to support continuous head and hand
tracking). While prior work has extensively examined the security properties of
the Android software stack, how these security properties hold for VR systems
remains unexplored. In this paper, we present the first comprehensive security
analysis of VR firmware. We collect over 300 versions of VR firmware from two
major vendors, Quest and Pico, and perform a longitudinal analysis across the
kernel layer, the system binary and library layer, and the application layer.
We have identified several security issues in these VR firmware, including
missing kernel-level security features, insufficient binary hardening,
inconsistent permission enforcement, and inadequate SELinux policy enforcement.
Based on our findings, we synthesize recommendations for VR vendors to improve
security and trust for VR devices. This paper will act as an important security
resource for VR developers, users, and vendors, and will also direct future
advancements in secure VR ecosystem.

</details>


### [19] [X-PRINT:Platform-Agnostic and Scalable Fine-Grained Encrypted Traffic Fingerprinting](https://arxiv.org/abs/2509.00706)
*YuKun Zhu,ManYuan Hua,Hai Huang,YongZhao Zhang,Jie Yang,FengHua Xu,RuiDong Chen,XiaoSong Zhang,JiGuo Yu,Yong Ma*

Main category: cs.CR

TL;DR: X-PRINT是一个基于URI的服务器中心化加密流量指纹识别框架，通过分析后端URI调用模式作为平台无关的特征，实现跨平台细粒度行为识别。


<details>
  <summary>Details</summary>
Motivation: 现有加密流量指纹识别方法存在两个主要限制：(1)依赖平台相关特征，难以在异构平台间泛化；(2)在开放世界环境中细粒度行为识别的扩展性差。

Method: 利用后端URI调用模式作为平台无关的不变量，使用时序结构化的URI映射进行行为推理，并排除平台或应用特定的私有URI来处理未见情况。

Result: 在多样化的跨平台和开放世界环境中，X-PRINT实现了最先进的细粒度指纹识别准确率，表现出强大的扩展性和鲁棒性。

Conclusion: URI调用模式可以作为有效的平台无关特征用于加密流量指纹识别，X-PRINT框架在跨平台和开放世界设置中具有优异的性能和可靠性。

Abstract: Although encryption protocols such as TLS are widely de-ployed,side-channel
metadata in encrypted traffic still reveals patterns that allow application and
behavior inference.How-ever,existing fine-grained fingerprinting approaches
face two key limitations:(i)reliance on platform-dependent
charac-teristics,which restricts generalization across heterogeneous
platforms,and(ii)poor scalability for fine-grained behavior identification in
open-world settings.
  In this paper,we present X-PRINT,the first server-centric,URI-based framework
for cross-platform fine-grained encrypted-traffic fingerprinting.X-PRINT
systematically demonstrates that backend URI invocation patterns can serve as
platform-agnostic invariants and are effective for mod-eling fine-grained
behaviors.To achieve robust identifica-tion,X-PRINT further leverages
temporally structured URI maps for behavior inference and emphasizes the
exclusion of platform-or application-specific private URIs to handle unseen
cases,thereby improving reliability in open-world and cross-platform
settings.Extensive experiments across diverse cross-platform and open-world
settings show that X-PRINT achieves state-of-the-art accuracy in fine-grained
fingerprint-ing and exhibits strong scalability and robustness.

</details>


### [20] [Bayesian and Multi-Objective Decision Support for Real-Time Cyber-Physical Incident Mitigation](https://arxiv.org/abs/2509.00770)
*Shaofei Huang,Christopher M. Poskitt,Lwin Khin Shar*

Main category: cs.CR

TL;DR: 基于贝叶斯网络和多目标优化的实时适应性网络事故罕容案策支持框架，能够在保障系统安全性的同时维持运营连续性。


<details>
  <summary>Details</summary>
Motivation: 因应对关键基础设施中越来越依赖的网络物理系统，以及现有决策支持系统在处理多段、多路径攻击和安全与运营连续性之间批执方面的不足。

Method: 集成层次系统建模与贝叶斯概率推理，通过埂埂网络图建模系统架构和漏洞数据。使用领域特定语言编码模型提高计算效率，采用混合暴露概率估计框架结合EPSS和CVSS评分来处理不确定性，通过多目标优化生成帕累托最优策略。

Result: 通过三个代表性网络物理攻击场景评估，证明框架在实时响应约束下处理复杂恶意行为的多用性。

Conclusion: 结果确认了该框架在运营环境中的实用性，并强调了所提出方法在多样化威胁环境中的稳健性。

Abstract: This research proposes a real-time, adaptive decision-support framework for
mitigating cyber incidents in cyber-physical systems, developed in response to
an increasing reliance on these systems within critical infrastructure and
evolving adversarial tactics. Existing decision-support systems often fall
short in accounting for multi-agent, multi-path attacks and trade-offs between
safety and operational continuity. To address this, our framework integrates
hierarchical system modelling with Bayesian probabilistic reasoning,
constructing Bayesian Network Graphs from system architecture and vulnerability
data. Models are encoded using a Domain Specific Language to enhance
computational efficiency and support dynamic updates. In our approach, we use a
hybrid exposure probability estimation framework, which combines Exploit
Prediction Scoring System and Common Vulnerability Scoring System scores via
Bayesian confidence calibration to handle epistemic uncertainty caused by
incomplete or heterogeneous vulnerability metadata. Mitigation recommendations
are generated as countermeasure portfolios, refined using multi-objective
optimisation to identify Pareto-optimal strategies balancing attack likelihood,
impact severity, and system availability. To accommodate time- and
resource-constrained incident response, frequency-based heuristics are applied
to prioritise countermeasures across the optimised portfolios. The framework
was evaluated through three representative cyber-physical attack scenarios,
demonstrating its versatility in handling complex adversarial behaviours under
real-time response constraints. The results affirm its utility in operational
contexts and highlight the robustness of our proposed approach across diverse
threat environments.

</details>


### [21] [MAESTROCUT: Dynamic, Noise-Adaptive, and Secure Quantum Circuit Cutting on Near-Term Hardware](https://arxiv.org/abs/2509.00811)
*Samuel Punch,Krishnendu Guha*

Main category: cs.CR

TL;DR: MaestroCut是一个用于量子电路切割的闭环框架，能够自适应设备漂移和工作负载变化，通过实时监控方差、触发重新切割和拓扑感知的shot分配来提升精度和效率。


<details>
  <summary>Details</summary>
Motivation: 量子设备存在漂移和工作负载变化的问题，传统的电路切割方法无法适应这些动态变化，导致精度下降和效率降低。

Method: 采用闭环框架，实时跟踪方差代理指标，在精度下降时触发重新切割，使用拓扑感知先验进行shot路由，并通过在线估计器级联（MLE、贝叶斯、GP辅助）在固定预算内选择最低误差重构。

Result: Tier-1模拟显示方差持续收缩，均方误差相比均匀和比例基线方法有所降低；Tier-2仿真在真实排队和噪声环境下展示了稳定的延迟目标、高可靠性和约1%的软件开销。

Conclusion: 自适应电路切割能够在近期硬件上以最小运营成本提供精度和效率的改进，具有实际应用价值。

Abstract: We present MaestroCut, a closed-loop framework for quantum circuit cutting
that adapts partitioning and shot allocation to device drift and workload
variation. MaestroCut tracks a variance proxy in real time, triggers re-cutting
when accuracy degrades, and routes shots using topology-aware priors. An online
estimator cascade (MLE, Bayesian, GP-assisted) selects the lowest-error
reconstruction within a fixed budget. Tier-1 simulations show consistent
variance contraction and reduced mean-squared error versus uniform and
proportional baselines. Tier-2 emulation with realistic queueing and noise
demonstrates stable latency targets, high reliability, and ~1% software
overhead under stress scenarios. These results indicate that adaptive circuit
cutting can provide accuracy and efficiency improvements with minimal
operational cost on near-term hardware.

</details>


### [22] [Adaptive t Design Dummy-Gate Obfuscation for Cryogenic Scale Enforcement](https://arxiv.org/abs/2509.00812)
*Samuel Punch,Krishnendu Guha*

Main category: cs.CR

TL;DR: NADGO是一个量子计算隐私保护系统，通过噪声自适应虚拟门混淆技术保护云量子服务的电路结构和时序信息，防止调度元数据、延迟模式和共租户干扰导致的信息泄露。


<details>
  <summary>Details</summary>
Motivation: 云量子服务可能通过调度元数据、延迟模式和共租户干扰泄露电路结构和时序信息，需要一种方法来保护操作隐私并支持机密性和公平的多租户环境。

Method: NADGO结合了四种技术：(i)硬件感知的t-design填充用于结构化覆盖流量，(ii)粒子滤波时序随机化掩盖队列模式，(iii)CASQUE跨异构后端的子电路路由，(iv)带锁定校准工件和双阈值紧急停止的每间隔泄漏估计器。

Result: 在4量子比特超导芯片上原型验证，控制间隔为6.3微秒，泄漏保持在预算内（间隔中止率低于1%），在攻击下产生高分离度和集中中止。相比静态填充具有更低的延迟和低温功耗。

Conclusion: NADGO能够有效保护云量子服务的操作隐私，在可接受的性能开销下实现机密性和公平多租户，为量子计算云服务提供了实用的隐私保护解决方案。

Abstract: Cloud quantum services can reveal circuit structure and timing through
scheduler metadata, latency patterns, and co-tenant interference. We introduce
NADGO (Noise-Adaptive Dummy-Gate Obfuscation), a scheduling and obfuscation
stack that enforces operational privacy for gate-model workloads by applying
per-interval limits on observable information leakage. To support
confidentiality and fair multi-tenancy, operators require a method to audit
compliance at acceptable overheads. NADGO combines: (i) hardware-aware t-design
padding for structured cover traffic, (ii) particle-filter timing randomization
to mask queue patterns, (iii) CASQUE subcircuit routing across heterogeneous
backends, and (iv) a per-interval leakage estimator with locked calibration
artifacts and a dual-threshold kill-switch. We prototype the approach on a
4-qubit superconducting tile with cryo-CMOS control and evaluate both
depth-varied local-random circuits and small QAOA instances. Monitoring runs at
a 6.3 microsecond control interval, and per-interval decisions are recorded in
an append-only, hash-chained audit log. Across Monte Carlo (Tier 1) and
cloud-hardware emulation (Tier 2) evaluations, NADGO maintains leakage within
budget in nominal operation (interval-abort rate below 1 percent) and under
attack yields high separation with concentrated aborts. At matched leakage
targets, microbenchmarks indicate lower latency and cryogenic power consumption
than static padding, while end-to-end workloads maintain competitive cost
envelopes.

</details>


### [23] [Unlocking the Effectiveness of LoRA-FP for Seamless Transfer Implantation of Fingerprints in Downstream Models](https://arxiv.org/abs/2509.00820)
*Zhenhua Xu,Zhaokun Yan,Binhan Xu,Xin Tong,Haitao Xu,Yourong Chen,Meng Han*

Main category: cs.CR

TL;DR: LoRA-FP是一个轻量级即插即用框架，通过在LoRA适配器中嵌入后门指纹来保护大语言模型的知识产权，显著降低计算开销并保持优异鲁棒性。


<details>
  <summary>Details</summary>
Motivation: 随着大语言模型的快速发展，知识产权保护变得日益重要。传统指纹集成方法成本高且可能污染模型，需要更轻量高效的解决方案。

Method: 通过约束微调在LoRA适配器中嵌入后门指纹，支持参数融合实现指纹无缝移植，无需全参数更新即可保持模型完整性。

Result: 实验结果表明，LoRA-FP相比传统方法显著降低计算开销，在增量训练和模型融合等多种场景下都表现出优异的鲁棒性。

Conclusion: LoRA-FP提供了一个高效、轻量且可移植的知识产权保护方案，为LLM的IP保护提供了实用框架，代码和数据集已开源。

Abstract: With the rapid advancement of large language models (LLMs), safeguarding
intellectual property (IP) has become increasingly critical. To address the
challenges of high costs and potential contamination in fingerprint
integration, we propose LoRA-FP, a lightweight, plug-and-play framework that
embeds backdoor fingerprints into LoRA adapters through constrained
fine-tuning. This design enables seamless fingerprint transplantation via
parameter fusion, eliminating the need for full-parameter updates while
preserving model integrity. Experimental results demonstrate that LoRA-FP not
only significantly reduces computational overhead compared to conventional
approaches but also achieves superior robustness across diverse scenarios,
including incremental training and model fusion. Our code and datasets are
publicly available at https://github.com/Xuzhenhua55/LoRA-FP.

</details>


### [24] [VULSOVER: Vulnerability Detection via LLM-Driven Constraint Solving](https://arxiv.org/abs/2509.00882)
*Xiang Li,Yueci Su,Jiahao Liu,Zhiwei Lin,Yuebing Hou,Peiming Gao,Yuanchao Zhang*

Main category: cs.CR

TL;DR: VULSOLVER是一种基于LLM的约束求解方法，通过将漏洞检测建模为约束求解问题，结合SAST和LLM语义推理能力，实现了96.29%的准确率和100%的召回率。


<details>
  <summary>Details</summary>
Motivation: 传统基于规则匹配的漏洞检测方法准确性不足，而现有LLM方法存在输出不稳定、上下文长度限制和幻觉问题，要么过度依赖规则，要么过度依赖LLM导致鲁棒性差。

Method: 提出VULSOLVER方法，将漏洞检测建模为约束求解问题，整合静态应用安全测试(SAST)和LLM的语义推理能力，使LLM能够像专业安全专家一样工作。

Result: 在OWASP基准测试(1023个标注样本)上达到96.29%准确率、96.55% F1分数和100%召回率。在GitHub热门仓库中发现15个先前未知的高危漏洞(CVSS 7.5-9.8)。

Conclusion: VULSOLVER通过约束求解框架有效解决了LLM在漏洞检测中的稳定性问题，证明了其在真实世界安全分析中的有效性，为LLM在安全领域的应用提供了新思路。

Abstract: Traditional vulnerability detection methods rely heavily on predefined rule
matching, which often fails to capture vulnerabilities accurately. With the
rise of large language models (LLMs), leveraging their ability to understand
code semantics has emerged as a promising direction for achieving more accurate
and efficient vulnerability detection. However, current LLM-based approaches
face significant challenges: instability in model outputs, limitations in
context length, and hallucination. As a result, many existing solutions either
use LLMs merely to enrich predefined rule sets, thereby keeping the detection
process fundamentally rule-based, or over-rely on them, leading to poor
robustness. To address these challenges, we propose a constraint-solving
approach powered by LLMs named VULSOLVER. By modeling vulnerability detection
as a constraint-solving problem, and by integrating static application security
testing (SAST) with the semantic reasoning capabilities of LLMs, our method
enables the LLM to act like a professional human security expert. We assess
VULSOLVER on the OWASP Benchmark (1,023 labeled samples), achieving 96.29%
accuracy, 96.55% F1-score, and 100% recall. Applied to popular GitHub
repositories, VULSOLVER also identified 15 previously unknown high-severity
vulnerabilities (CVSS 7.5-9.8), demonstrating its effectiveness in real-world
security analysis.

</details>


### [25] [Hybrid AI-Driven Intrusion Detection: Framework Leveraging Novel Feature Selection for Enhanced Network Security](https://arxiv.org/abs/2509.00896)
*Maryam Mahdi Alhusseini,Mohammad Reza Feizi Derakhshi*

Main category: cs.CR

TL;DR: 提出了一种基于AI的实时入侵检测框架，使用机器学习模型和新型Energy Valley Optimization方法，在NSL-KDD数据集上实现了高达98.95%的准确率，显著减少了特征数量和计算时间。


<details>
  <summary>Details</summary>
Motivation: 随着数字环境的快速发展，保护网络基础设施免受网络攻击变得至关重要，特别是在无线传感器网络和云计算环境中需要高效的实时入侵检测系统。

Method: 采用逻辑回归、决策树和K近邻等经典机器学习模型，通过新型Energy Valley Optimization方法进行优化，使用NSL-KDD数据集，特征选择从42个减少到18个，并通过下采样处理类别不平衡问题。

Result: 决策树达到98.95%准确率，K近邻98.47%，逻辑回归88.84%；所有分类器都获得了高精度、召回率和F1分数，同时大幅减少了训练和测试时间。

Conclusion: 该研究提供了一个可扩展、低延迟、高精度的入侵检测解决方案，推动了安全通信技术的发展，符合人工智能、网络安全和实时数字网络的最新趋势。

Abstract: In today's rapidly evolving digital landscape, safeguarding network
infrastructures against cyberattacks has become a critical priority. This
research presents an innovative AI-driven real-time intrusion detection
framework designed to enhance network security, particularly in Wireless Sensor
Networks (WSNs) and Cloud Computing (CC) environments. The system employs
classical machine learning models, Logistic Regression, Decision Tree, and
K-Nearest Neighbors, optimized through the novel Energy Valley Optimization
(EVO) method using the NSL-KDD dataset. Feature selection significantly reduced
the number of input features from 42 to 18 while maintaining strong detection
capabilities. The proposed system achieved 98.95 percent accuracy with Decision
Tree, 98.47 percent with K-Nearest Neighbors, and 88.84 percent with Logistic
Regression. Moreover, high precision, recall, and F1-scores were attained
across all classifiers while substantially reducing training and testing times,
making the framework highly suitable for real-time applications. To ensure fair
detection across diverse attack types, dataset balancing via downsampling was
applied to address class imbalance challenges. This investigation focuses on
the significance of advancing intrusion detection systems in cloud computing
and WSNs. Overall, this work advances secure communications by delivering a
scalable, low-latency, and high-accuracy intrusion detection solution aligned
with the latest trends in artificial intelligence, cybersecurity, and real-time
digital networks

</details>


### [26] [PREE: Towards Harmless and Adaptive Fingerprint Editing in Large Language Models via Knowledge Prefix Enhancement](https://arxiv.org/abs/2509.00918)
*Xubin Yue,Zhenhua Xu,Wenpeng Xing,Jiahui Yu,Mohan Li,Meng Han*

Main category: cs.CR

TL;DR: PREE框架通过双通道知识编辑将版权信息编码为参数偏移，实现指纹特征的隐蔽嵌入，在主流大模型中达到90%触发精度，且保持极低参数变化率和零误报率。


<details>
  <summary>Details</summary>
Motivation: 解决大语言模型商业部署中的知识产权保护挑战，现有黑盒指纹技术面临增量微调擦除和特征空间防御的双重挑战，因为它们依赖过拟合的高困惑度触发模式。

Method: 提出前缀增强指纹编辑框架(PREE)，通过双通道知识编辑将版权信息编码为参数偏移，实现指纹特征的隐蔽嵌入。

Result: 在LLaMA-3和Qwen-2.5等主流架构中达到90%触发精度，参数变化率小于0.03%，有效保持原始知识表示，对增量微调和多维防御策略表现出强鲁棒性，评估期间保持零误报率。

Conclusion: PREE框架通过创新的双通道知识编辑方法，成功解决了现有指纹技术的局限性，为大语言模型的知识产权保护提供了高效、隐蔽且鲁棒的解决方案。

Abstract: Addressing the intellectual property protection challenges in commercial
deployment of large language models (LLMs), existing black-box fingerprinting
techniques face dual challenges from incremental fine-tuning erasure and
feature-space defense due to their reliance on overfitting high-perplexity
trigger patterns. Recent work has revealed that model editing in the
fingerprinting domain offers distinct advantages, including significantly lower
false positive rates, enhanced harmlessness, and superior robustness. Building
on this foundation, this paper innovatively proposes a
$\textbf{Pr}$efix-$\textbf{e}$nhanced Fingerprint $\textbf{E}$diting Framework
(PREE), which encodes copyright information into parameter offsets through
dual-channel knowledge edit to achieve covert embedding of fingerprint
features. Experimental results demonstrate that the proposed solution achieves
the 90\% trigger precision in mainstream architectures including LLaMA-3 and
Qwen-2.5. The minimal parameter offset (change rate < 0.03) effectively
preserves original knowledge representation while demonstrating strong
robustness against incremental fine-tuning and multi-dimensional defense
strategies, maintaining zero false positive rate throughout evaluations.

</details>


### [27] [Clone What You Can't Steal: Black-Box LLM Replication via Logit Leakage and Distillation](https://arxiv.org/abs/2509.00973)
*Kanchon Gharami,Hansaka Aluvihare,Shafika Showkat Moni,Berker Peköz*

Main category: cs.CR

TL;DR: 该论文提出了一种通过API logit泄漏来克隆黑盒LLM的方法，使用不到1万次查询就能重建输出投影矩阵，并通过知识蒸馏创建功能相当的替代模型。


<details>
  <summary>Details</summary>
Motivation: 随着LLM在关键任务系统中的部署增加，缺乏强访问控制的API会暴露logits信息，形成新的攻击面。现有研究主要关注输出层重建或表面行为蒸馏，但在严格查询限制下重建黑盒模型的研究不足。

Method: 采用两阶段方法：1) 通过SVD对top-k logits进行分析，用不到1万次查询重建输出投影矩阵；2) 使用不同深度的transformer学生模型进行知识蒸馏，在开源数据集上训练。

Result: 6层学生模型重现了97.6%的教师模型隐藏状态几何结构，困惑度仅增加7.31%，NLL为7.58。4层变体实现了17.1%的推理加速和18.1%的参数减少。整个攻击在24 GPU小时内完成，且不会触发API速率限制防御。

Conclusion: 研究表明成本有限的攻击者可以快速克隆LLM，强调了需要强化推理API安全性和安全的本地部署防御措施的必要性。

Abstract: Large Language Models (LLMs) are increasingly deployed in mission-critical
systems, facilitating tasks such as satellite operations, command-and-control,
military decision support, and cyber defense. Many of these systems are
accessed through application programming interfaces (APIs). When such APIs lack
robust access controls, they can expose full or top-k logits, creating a
significant and often overlooked attack surface. Prior art has mainly focused
on reconstructing the output projection layer or distilling surface-level
behaviors. However, regenerating a black-box model under tight query
constraints remains underexplored. We address that gap by introducing a
constrained replication pipeline that transforms partial logit leakage into a
functional deployable substitute model clone. Our two-stage approach (i)
reconstructs the output projection matrix by collecting top-k logits from under
10k black-box queries via singular value decomposition (SVD) over the logits,
then (ii) distills the remaining architecture into compact student models with
varying transformer depths, trained on an open source dataset. A 6-layer
student recreates 97.6% of the 6-layer teacher model's hidden-state geometry,
with only a 7.31% perplexity increase, and a 7.58 Negative Log-Likelihood
(NLL). A 4-layer variant achieves 17.1% faster inference and 18.1% parameter
reduction with comparable performance. The entire attack completes in under 24
graphics processing unit (GPU) hours and avoids triggering API rate-limit
defenses. These results demonstrate how quickly a cost-limited adversary can
clone an LLM, underscoring the urgent need for hardened inference APIs and
secure on-premise defense deployments.

</details>


### [28] [Lightening the Load: A Cluster-Based Framework for A Lower-Overhead, Provable Website Fingerprinting Defense](https://arxiv.org/abs/2509.01046)
*Khashayar Khajavi,Tao Wang*

Main category: cs.CR

TL;DR: 提出了Adaptive Tamaraw防御框架，结合正则化和超序列方法的优势，通过聚类和自适应参数调整，在隐私保护和效率之间实现可调节的平衡


<details>
  <summary>Details</summary>
Motivation: 现有网站指纹防御方法存在局限性，正则化方法效率低，超序列方法灵活性不足，需要一种既能提供可证明安全性又能保持高效率的自适应防御方案

Method: 首先提取流量行为模式并聚类成(k,l)-多样性匿名集，然后使用早期时间序列分类器从保守的全局正则化参数切换到特定集的轻量参数，基于Tamaraw框架实现每簇参数分配

Result: 在真实数据集上验证有效，高隐私模式下可将攻击者准确率降至30%以下，高效模式下相比经典Tamaraw减少99%的开销

Conclusion: Adaptive Tamaraw提供了一个统一的防御框架，通过参数k在隐私和效率之间灵活权衡，同时保持了信息论安全保证

Abstract: Website fingerprinting (WF) attacks remain a significant threat to encrypted
traffic, prompting the development of a wide range of defenses. Among these,
two prominent classes are regularization-based defenses, which shape traffic
using fixed padding rules, and supersequence-based approaches, which conceal
traces among predefined patterns. In this work, we present a unified framework
for designing an adaptive WF defense that combines the effectiveness of
regularization with the provable security of supersequence-style grouping. The
scheme first extracts behavioural patterns from traces and clusters them into
(k,l)-diverse anonymity sets; an early-time-series classifier (adapted from
ECDIRE) then switches from a conservative global set of regularization
parameters to the lighter, set-specific parameters. We instantiate the design
as Adaptive Tamaraw, a variant of Tamaraw that assigns padding parameters on a
per-cluster basis while retaining its original information-theoretic guarantee.
Comprehensive experiments on public real-world datasets confirm the benefits.
By tuning k, operators can trade privacy for efficiency: in its high-privacy
mode Adaptive Tamaraw pushes the bound on any attacker's accuracy below 30%,
whereas in efficiency-centred settings it cuts total overhead by 99% compared
with classic Tamaraw.

</details>


### [29] [Efficient and High-Accuracy Secure Two-Party Protocols for a Class of Functions with Real-number Inputs](https://arxiv.org/abs/2509.01178)
*Hao Guo,Zhaoqian Liu,Liqiang Peng,Shuaishuai Li,Ximing Fu,Weiran Liu,Lin Qu*

Main category: cs.CR

TL;DR: 本文提出了一种改进的两方秘密共享方案，显著放宽了输入约束条件，使|x| < B（B ≤ L/2），并构建了支持整数除法、三角函数和指数函数的安全计算框架。


<details>
  <summary>Details</summary>
Motivation: 现实应用需要处理有符号实数，但现有方法存在严格的输入约束(|x| < L/3)，限制了实际应用范围。

Method: 通过放宽输入约束条件到|x| < B（B ≤ L/2），构建通用框架支持多种函数的安全计算，包括整数除法、三角函数和指数函数。

Result: 实验表明协议高效且准确：指数函数e^{-x}的通信成本降低至SirNN的31%，运行速度提升5.53倍；最大ULP误差为1.435，优于对比方案。

Conclusion: 提出的方法显著放宽了输入约束，实现了更广泛的实际应用，同时在效率和准确性方面都有显著提升。

Abstract: In two-party secret sharing scheme, values are typically encoded as unsigned
integers $\mathsf{uint}(x)$, whereas real-world applications often require
computations on signed real numbers $\mathsf{Real}(x)$. To enable secure
evaluation of practical functions, it is essential to computing
$\mathsf{Real}(x)$ from shared inputs, as protocols take shares as input. At
USENIX'25, Guo et al. proposed an efficient method for computing signed integer
values $\mathsf{int}(x)$ from shares, which can be extended to compute
$\mathsf{Real}(x)$. However, their approach imposes a restrictive input
constraint $|x| < \frac{L}{3}$ for $x \in \mathbb{Z}_L$, limiting its
applicability in real-world scenarios. In this work, we significantly relax
this constraint to $|x| < B$ for any $B \leq \frac{L}{2}$, where $B =
\frac{L}{2}$ corresponding to the natural representable range in $x \in
\mathbb{Z}_L$. This relaxes the restrictions and enables the computation of
$\mathsf{Real}(x)$ with loose or no input constraints. Building upon this
foundation, we present a generalized framework for designing secure protocols
for a broad class of functions, including integer division ($\lfloor
\frac{x}{d} \rfloor$), trigonometric ($\sin(x)$) and exponential ($e^{-x}$)
functions. Our experimental evaluation demonstrates that the proposed protocols
achieve both high efficiency and high accuracy. Notably, our protocol for
evaluating $e^{-x}$ reduces communication costs to approximately 31% of those
in SirNN (S&P 21) and Bolt (S&P 24), with runtime speedups of up to $5.53
\times$ and $3.09 \times$, respectively. In terms of accuracy, our protocol
achieves a maximum ULP error of $1.435$, compared to $2.64$ for SirNN and
$8.681$ for Bolt.

</details>


### [30] [Web Fraud Attacks Against LLM-Driven Multi-Agent Systems](https://arxiv.org/abs/2509.01211)
*Dezhang Kong,Hujin Peng,Yilun Zhang,Lele Zhao,Zhenhua Xu,Shi Lin,Changting Lin,Meng Han*

Main category: cs.CR

TL;DR: 本文提出了一种针对LLM驱动的多智能体系统的新型网络欺诈攻击，通过域名篡改和链接结构伪装等11种攻击变体，能够诱导智能体访问恶意网站，具有显著的破坏潜力和隐蔽性优势。


<details>
  <summary>Details</summary>
Motivation: 随着基于LLM的多智能体系统应用激增，Web链接安全性成为确保系统可靠性的关键问题。攻击者一旦诱导智能体访问恶意网站，就能以此为跳板进行后续攻击，大幅扩大攻击面。

Method: 设计了11种代表性攻击变体，包括域名篡改（同形异义字欺骗、字符替换等）、链接结构伪装（子目录嵌套、子域名嫁接、参数混淆等）以及其他针对MAS链接验证漏洞的欺骗技术。

Result: 通过大量实验证明，网络欺诈攻击不仅在不同MAS架构中展现出显著的破坏潜力，而且在规避检测方面具有明显优势：它们无需复杂的输入格式如越狱攻击，从而降低了暴露风险。

Conclusion: 网络欺诈攻击的隐蔽性和破坏性对系统安全和用户安全构成了不可忽视的威胁，强调了在LLM驱动的多智能体系统中解决此类攻击的重要性。

Abstract: With the proliferation of applications built upon LLM-driven multi-agent
systems (MAS), the security of Web links has become a critical concern in
ensuring system reliability. Once an agent is induced to visit a malicious
website, attackers can use it as a springboard to conduct diverse subsequent
attacks, which will drastically expand the attack surface. In this paper, we
propose Web Fraud Attacks, a novel type of attack aiming at inducing MAS to
visit malicious websites. We design 11 representative attack variants that
encompass domain name tampering (homoglyph deception, character substitution,
etc.), link structure camouflage (sub-directory nesting, sub-domain grafting,
parameter obfuscation, etc.), and other deceptive techniques tailored to
exploit MAS's vulnerabilities in link validation. Through extensive experiments
on these crafted attack vectors, we demonstrate that Web fraud attacks not only
exhibit significant destructive potential across different MAS architectures
but also possess a distinct advantage in evasion: they circumvent the need for
complex input formats such as jailbreaking, which inherently carry higher
exposure risks. These results underscore the importance of addressing Web fraud
attacks in LLM-driven MAS, as their stealthiness and destructiveness pose
non-negligible threats to system security and user safety.

</details>


### [31] [Practical and Private Hybrid ML Inference with Fully Homomorphic Encryption](https://arxiv.org/abs/2509.01253)
*Sayan Biswas,Philippe Chartier,Akash Dhasade,Tom Jurien,David Kerriou,Anne-Marie Kerrmarec,Mohammed Lemou,Franklin Tranie,Martijn de Vos,Milos Vujasinovic*

Main category: cs.CR

TL;DR: Safhire是一个混合推理框架，通过在服务器上加密执行线性层，将非线性激活函数以明文形式卸载到客户端处理，消除了FHE中昂贵的自举操作，支持精确激活函数，并显著减少计算量。


<details>
  <summary>Details</summary>
Motivation: 在云服务中保护用户敏感数据和服务器模型机密性至关重要。全同态加密(FHE)虽然能在加密输入上直接推理，但受到昂贵自举操作和非线性激活函数低效近似的限制，缺乏实用性。

Method: 采用混合推理设计：服务器加密执行线性层，客户端明文处理非线性激活函数。使用随机洗牌技术混淆中间值保护模型机密性，并采用快速密文打包和部分提取等优化技术降低延迟。

Result: 在多个标准模型和数据集上的评估显示，Safhire比最先进的基线Orion实现1.5倍到10.5倍更低的推理延迟，具有可管理的通信开销和相当的准确性。

Conclusion: Safhire通过混合FHE推理方法，在保护数据隐私和模型机密性的同时，显著提升了推理效率，证明了混合FHE推理的实用性。

Abstract: In contemporary cloud-based services, protecting users' sensitive data and
ensuring the confidentiality of the server's model are critical. Fully
homomorphic encryption (FHE) enables inference directly on encrypted inputs,
but its practicality is hindered by expensive bootstrapping and inefficient
approximations of non-linear activations. We introduce Safhire, a hybrid
inference framework that executes linear layers under encryption on the server
while offloading non-linearities to the client in plaintext. This design
eliminates bootstrapping, supports exact activations, and significantly reduces
computation. To safeguard model confidentiality despite client access to
intermediate outputs, Safhire applies randomized shuffling, which obfuscates
intermediate values and makes it practically impossible to reconstruct the
model. To further reduce latency, Safhire incorporates advanced optimizations
such as fast ciphertext packing and partial extraction. Evaluations on multiple
standard models and datasets show that Safhire achieves 1.5X - 10.5X lower
inference latency than Orion, a state-of-the-art baseline, with manageable
communication overhead and comparable accuracy, thereby establishing the
practicality of hybrid FHE inference.

</details>


### [32] [An Automated Attack Investigation Approach Leveraging Threat-Knowledge-Augmented Large Language Models](https://arxiv.org/abs/2509.01271)
*Rujie Dai,Peizhuo Lv,Yujiang Gui,Qiujian Lv,Yuanyuan Qiao,Yan Wang,Degang Sun,Weiqing Huang,Yingjiu Li,XiaoFeng Wang*

Main category: cs.CR

TL;DR: 提出基于LLM的攻击调查框架，通过动态可适应的Kill-Chain威胁知识库增强，能够从海量异构日志中重建完整攻击链并生成可读报告。


<details>
  <summary>Details</summary>
Motivation: 现有方法在平台通用性、应对演进战术和生成分析师就绪报告方面存在不足，LLMs虽然具有语义理解能力但难以捕捉长距离跨日志依赖关系。

Method: 构建动态可适应的Kill-Chain对齐威胁知识库，将攻击相关行为组织为阶段感知知识单元，使LLM能够迭代检索情报、进行因果推理并逐步扩展调查上下文。

Result: 在15个攻击场景（430万日志事件，7.2GB数据）上评估，平均真阳性率97.1%，假阳性率0.2%，显著优于SOTA方法ATLAS（真阳性率79.2%，假阳性率29.1%）。

Conclusion: 该框架成功解决了APT攻击调查中的关键挑战，实现了高精度的攻击链重建和可读报告生成，为网络安全调查提供了有效解决方案。

Abstract: Advanced Persistent Threats (APTs) are prolonged, stealthy intrusions by
skilled adversaries that compromise high-value systems to steal data or disrupt
operations. Reconstructing complete attack chains from massive, heterogeneous
logs is essential for effective attack investigation, yet existing methods
suffer from poor platform generality, limited generalization to evolving
tactics, and an inability to produce analyst-ready reports. Large Language
Models (LLMs) offer strong semantic understanding and summarization
capabilities, but in this domain they struggle to capture the long-range,
cross-log dependencies critical for accurate reconstruction.
  To solve these problems, we present an LLM-empowered attack investigation
framework augmented with a dynamically adaptable Kill-Chain-aligned threat
knowledge base. We organizes attack-relevant behaviors into stage-aware
knowledge units enriched with semantic annotations, enabling the LLM to
iteratively retrieve relevant intelligence, perform causal reasoning, and
progressively expand the investigation context. This process reconstructs
multi-phase attack scenarios and generates coherent, human-readable
investigation reports. Evaluated on 15 attack scenarios spanning single-host
and multi-host environments across Windows and Linux (over 4.3M log events, 7.2
GB of data), the system achieves an average True Positive Rate (TPR) of 97.1%
and an average False Positive Rate (FPR) of 0.2%, significantly outperforming
the SOTA method ATLAS, which achieves an average TPR of 79.2% and an average
FPR of 29.1%.

</details>


### [33] [Anomaly detection in network flows using unsupervised online machine learning](https://arxiv.org/abs/2509.01375)
*Alberto Miguel-Diez,Adrián Campazas-Vega,Ángel Manuel Guerrero-Higueras,Claudia Álvarez-Aparicio,Vicente Matellán-Olivera*

Main category: cs.CR

TL;DR: 提出基于在线学习的无监督异常检测模型，使用One-Class SVM在动态网络流量中实现实时异常检测，准确率超过98%，处理时间小于0.033ms


<details>
  <summary>Details</summary>
Motivation: 网络流量持续增长且攻击日益复杂，需要能够持续自适应的解决方案来应对动态变化的网络行为

Method: 使用River库实现带有在线学习能力的无监督机器学习模型，采用One-Class SVM算法，在NF-UNSW-NB15数据集及其v2版本上进行评估

Result: 准确率超过98%，误报率低于3.1%，在最新数据集版本上召回率达到100%，单流量处理时间小于0.033毫秒

Conclusion: 该方法证明了在实时应用中处理动态网络流量异常检测的可行性，无需标注数据即可有效学习正常网络行为

Abstract: Nowadays, the volume of network traffic continues to grow, along with the
frequency and sophistication of attacks. This scenario highlights the need for
solutions capable of continuously adapting, since network behavior is dynamic
and changes over time. This work presents an anomaly detection model for
network flows using unsupervised machine learning with online learning
capabilities. This approach allows the system to dynamically learn the normal
behavior of the network and detect deviations without requiring labeled data,
which is particularly useful in real-world environments where traffic is
constantly changing and labeled data is scarce. The model was implemented using
the River library with a One-Class SVM and evaluated on the NF-UNSW-NB15
dataset and its extended version v2, which contain network flows labeled with
different attack categories. The results show an accuracy above 98%, a false
positive rate below 3.1%, and a recall of 100% in the most advanced version of
the dataset. In addition, the low processing time per flow (<0.033 ms)
demonstrates the feasibility of the approach for real-time applications.

</details>


### [34] [LiFeChain: Lightweight Blockchain for Secure and Efficient Federated Lifelong Learning in IoT](https://arxiv.org/abs/2509.01434)
*Handi Chen,Jing Deng,Xiuzhe Wu,Zhihan Jiang,Xinchen Zhang,Xianhao Chen,Edith C. H. Ngai*

Main category: cs.CR

TL;DR: LiFeChain是一个轻量级区块链系统，专门为联邦终身学习(FLL)设计，通过双向验证和最小链上披露提供防篡改账本，解决IoT系统中长期攻击和数据异质性问题。


<details>
  <summary>Details</summary>
Motivation: IoT设备产生异构数据流需要持续去中心化智能，联邦终身学习(FLL)面临长期攻击风险，传统单服务器架构存在单点故障问题，而直接应用区块链会增加计算和检索成本。

Method: 提出LiFeChain系统，包含服务器端的PoMC共识机制（结合学习和遗忘机制缓解负迁移）和客户端的Seg-ZA分段零知识仲裁（检测异常行为而不泄露隐私），作为即插即用组件集成到现有FLL算法。

Result: 实验结果表明LiFeChain不仅能有效抵御两种长期攻击，提升模型性能，还能保持高效率和可扩展性。

Conclusion: LiFeChain是首个专为FLL设计的区块链解决方案，成功解决了安全性和效率之间的权衡问题，为IoT系统中的可信联邦终身学习提供了可行方案。

Abstract: The expansion of Internet of Things (IoT) devices constantly generates
heterogeneous data streams, driving demand for continuous, decentralized
intelligence. Federated Lifelong Learning (FLL) provides an ideal solution by
incorporating federated and lifelong learning to overcome catastrophic
forgetting. The extended lifecycle of FLL in IoT systems increases their
vulnerability to persistent attacks, and these risks may be obscured by
performance degradation caused by spatial-temporal data heterogeneity.
Moreover, this problem is exacerbated by the standard single-server
architecture, as its single point of failure makes it difficult to maintain a
reliable audit trail for long-term threats. Blockchain provides a tamper-proof
foundation for trustworthy FLL systems. Nevertheless, directly applying
blockchain to FLL significantly increases computational and retrieval costs
with the expansion of the knowledge base, slowing down the training on IoT
devices. To address these challenges, we propose LiFeChain, a lightweight
blockchain for secure and efficient federated lifelong learning by providing a
tamper-resistant ledger with minimal on-chain disclosure and bidirectional
verification. To the best of our knowledge, LiFeChain is the first blockchain
tailored for FLL. LiFeChain incorporates two complementary mechanisms: the
proof-of-model-correlation (PoMC) consensus on the server, which couples
learning and unlearning mechanisms to mitigate negative transfer, and segmented
zero-knowledge arbitration (Seg-ZA) on the client, which detects and arbitrates
abnormal committee behavior without compromising privacy. LiFeChain is designed
as a plug-and-play component that can be seamlessly integrated into existing
FLL algorithms. Experimental results demonstrate that LiFeChain not only
enhances model performance against two long-term attacks but also sustains high
efficiency and scalability.

</details>


### [35] [LLMHoney: A Real-Time SSH Honeypot with Large Language Model-Driven Dynamic Response Generation](https://arxiv.org/abs/2509.01463)
*Pranjay Malhotra*

Main category: cs.CR

TL;DR: LLMHoney是一个基于大语言模型的SSH蜜罐，能够实时生成动态、真实的命令输出来欺骗攻击者，相比传统蜜罐具有更好的真实性和适应性。


<details>
  <summary>Details</summary>
Motivation: 传统低/中交互蜜罐依赖静态预脚本交互，容易被熟练攻击者识别，需要更真实的动态交互能力来提升欺骗效果和威胁情报收集。

Method: 使用大语言模型实时生成命令输出，结合基于字典的虚拟文件系统处理常见命令以降低延迟，平衡真实性和性能。评估了13种不同LLM变体，参数规模从0.36B到3.8B。

Result: Gemini-2.0、Qwen2.5:1.5B和Phi3:3.8B模型表现最佳，平均延迟约3秒，提供最可靠准确的响应。小模型常产生错误或不符预期的输出。

Conclusion: LLM驱动的蜜罐是提升攻击者参与度和收集更丰富威胁情报的有前景的方法，但存在幻觉输出和资源消耗增加的挑战。

Abstract: Cybersecurity honeypots are deception tools for engaging attackers and gather
intelligence, but traditional low or medium-interaction honeypots often rely on
static, pre-scripted interactions that can be easily identified by skilled
adversaries. This Report presents LLMHoney, an SSH honeypot that leverages
Large Language Models (LLMs) to generate realistic, dynamic command outputs in
real time. LLMHoney integrates a dictionary-based virtual file system to handle
common commands with low latency while using LLMs for novel inputs, achieving a
balance between authenticity and performance. We implemented LLMHoney using
open-source LLMs and evaluated it on a testbed with 138 representative Linux
commands. We report comprehensive metrics including accuracy (exact-match,
Cosine Similarity, Jaro-Winkler Similarity, Levenshtein Similarity and BLEU
score), response latency and memory overhead. We evaluate LLMHoney using
multiple LLM backends ranging from 0.36B to 3.8B parameters, including both
open-source models and a proprietary model(Gemini). Our experiments compare 13
different LLM variants; results show that Gemini-2.0 and moderately-sized
models Qwen2.5:1.5B and Phi3:3.8B provide the most reliable and accurate
responses, with mean latencies around 3 seconds, whereas smaller models often
produce incorrect or out-of-character outputs. We also discuss how LLM
integration improves honeypot realism and adaptability compared to traditional
honeypots, as well as challenges such as occasional hallucinated outputs and
increased resource usage. Our findings demonstrate that LLM-driven honeypots
are a promising approach to enhance attacker engagement and collect richer
threat intelligence.

</details>


### [36] [Privacy-preserving authentication for military 5G networks](https://arxiv.org/abs/2509.01470)
*I. D. Lutz,A. M. Hill,M. C. Valenti*

Main category: cs.CR

TL;DR: 本文分析了5G AKA协议在隐私保护方面的漏洞，提出了五种轻量级缓解策略，其中UE生成nonce的方案最为有效，能够以最小开销增强隐私保护。


<details>
  <summary>Details</summary>
Motivation: 随着5G网络在国防应用中的普及，确保认证和密钥协商(AKA)协议的隐私性和完整性变得至关重要。虽然5G AKA通过隐藏用户身份改进了前代协议，但在现实对手模型下仍面临重放同步和可链接性威胁。

Method: 对标准化5G AKA流程进行统一分析，识别多个漏洞，并提出五种轻量级缓解策略。通过原型实现和测试验证这些增强措施的有效性。

Result: 研究表明，引入UE生成nonce的解决方案最为有效，能够以可忽略的额外开销有效抵御识别出的跟踪和关联攻击。这些增强措施显著提高了对可链接性攻击的抵御能力。

Conclusion: 将UE生成nonce扩展作为5G AKA协议的可选功能，为商业和军事5G部署提供了向后兼容、低开销的隐私保护认证框架升级路径。

Abstract: As 5G networks gain traction in defense applications, ensuring the privacy
and integrity of the Authentication and Key Agreement (AKA) protocol is
critical. While 5G AKA improves upon previous generations by concealing
subscriber identities, it remains vulnerable to replay-based synchronization
and linkability threats under realistic adversary models. This paper provides a
unified analysis of the standardized 5G AKA flow, identifying several
vulnerabilities and highlighting how each exploits protocol behavior to
compromise user privacy. To address these risks, we present five lightweight
mitigation strategies. We demonstrate through prototype implementation and
testing that these enhancements strengthen resilience against linkability
attacks with minimal computational and signaling overhead. Among the solutions
studied, those introducing a UE-generated nonce emerge as the most promising,
effectively neutralizing the identified tracking and correlation attacks with
negligible additional overhead. Integrating this extension as an optional
feature to the standard 5G AKA protocol offers a backward-compatible,
low-overhead path toward a more privacy-preserving authentication framework for
both commercial and military 5G deployments.

</details>


### [37] [Insight-LLM: LLM-enhanced Multi-view Fusion in Insider Threat Detection](https://arxiv.org/abs/2509.01509)
*Chengyu Song,Jianming Zheng*

Main category: cs.CR

TL;DR: Insight-LLM是一个专门为内部威胁检测设计的模块化多视图融合框架，解决了现有单视图方法的局限性，通过冻结预训练语言模型实现高效检测。


<details>
  <summary>Details</summary>
Motivation: 现有内部威胁检测方法主要依赖单视图建模，导致覆盖范围有限且容易遗漏异常。多视图学习在其他领域表现出潜力，但直接应用于内部威胁检测面临可扩展性瓶颈、语义不对齐和视图不平衡等挑战。

Method: 提出Insight-LLM框架，采用模块化多视图融合方法，使用冻结的预训练语言模型来处理稀疏、异构的用户行为数据，避免独立训练子模型带来的可扩展性问题。

Result: 实现了最先进的检测性能，同时具有低延迟和低参数开销的优势。

Conclusion: Insight-LLM为内部威胁检测提供了一个有效的多视图融合解决方案，解决了传统方法的局限性，在保持高效率的同时提升了检测能力。

Abstract: Insider threat detection (ITD) requires analyzing sparse, heterogeneous user
behavior. Existing ITD methods predominantly rely on single-view modeling,
resulting in limited coverage and missed anomalies. While multi-view learning
has shown promise in other domains, its direct application to ITD introduces
significant challenges: scalability bottlenecks from independently trained
sub-models, semantic misalignment across disparate feature spaces, and view
imbalance that causes high-signal modalities to overshadow weaker ones. In this
work, we present Insight-LLM, the first modular multi-view fusion framework
specifically tailored for insider threat detection. Insight-LLM employs frozen,
pre-nes, achieving state-of-the-art detection with low latency and parameter
overhead.

</details>


### [38] [Securing Radiation Detection Systems with an Efficient TinyML-Based IDS for Edge Devices](https://arxiv.org/abs/2509.01592)
*Einstein Rivas Pizarro,Wajiha Zaheer,Li Yang,Khalil El-Khatib,Glenn Harvel*

Main category: cs.CR

TL;DR: 提出了一种基于TinyML的轻量级入侵检测系统，用于保护资源受限的辐射检测系统免受网络攻击


<details>
  <summary>Details</summary>
Motivation: 辐射检测系统在核设施和医疗环境中对公共安全至关重要，但面临多种网络攻击威胁，可能危及辐射测量的完整性和可靠性

Method: 创建合成辐射数据集，采用优化的XGBoost模型，结合剪枝、量化、特征选择和采样等TinyML技术

Result: 显著减小模型大小和计算需求，在低资源设备上实现实时入侵检测，同时保持效率与准确性的合理平衡

Conclusion: 该IDS系统将机器学习预测能力带到关键基础设施的传感边缘层，有效提升了辐射检测系统的网络安全防护能力

Abstract: Radiation Detection Systems (RDSs) play a vital role in ensuring public
safety across various settings, from nuclear facilities to medical
environments. However, these systems are increasingly vulnerable to
cyber-attacks such as data injection, man-in-the-middle (MITM) attacks, ICMP
floods, botnet attacks, privilege escalation, and distributed denial-of-service
(DDoS) attacks. Such threats could compromise the integrity and reliability of
radiation measurements, posing significant public health and safety risks. This
paper presents a new synthetic radiation dataset and an Intrusion Detection
System (IDS) tailored for resource-constrained environments, bringing Machine
Learning (ML) predictive capabilities closer to the sensing edge layer of
critical infrastructure. Leveraging TinyML techniques, the proposed IDS employs
an optimized XGBoost model enhanced with pruning, quantization, feature
selection, and sampling. These TinyML techniques significantly reduce the size
of the model and computational demands, enabling real-time intrusion detection
on low-resource devices while maintaining a reasonable balance between
efficiency and accuracy.

</details>


### [39] [Statistics-Friendly Confidentiality Protection for Establishment Data, with Applications to the QCEW](https://arxiv.org/abs/2509.01597)
*Kaitlyn Webb,Prottay Protivash,John Durrell,Daniell Toth,Aleksandra Slavković,Daniel Kifer*

Main category: cs.CR

TL;DR: 一种专门针对商业数据的保密性框架，解决传统方法在偏斜数据和极端倾向记录上的挑战


<details>
  <summary>Details</summary>
Motivation: 商业数据保密性领域研究较少，传统方法无法提供可接受的结果，而现代形式隐私技术在高度偏斜的商业数据上效果不佳

Method: 受高斯差分隐私启发，提出新的保密性框架，重点关注政策制定者的可解释性，并提出两种查询答复机制

Result: 在秘密的季度就业和工资普查(QCEW)微观数据以及公开替代数据集上进行了评估

Conclusion: 该框架有效解决了商业数据保密性的特殊挑战，特别是在处理极端倾向记录和提供可解释性方面

Abstract: Confidentiality for business data is an understudied area of disclosure
avoidance, where legacy methods struggle to provide acceptable results. Modern
formal privacy techniques designed for person-level data do not provide
suitable confidentiality/utility trade-offs due to the highly skewed nature of
business data and because extreme outlier records are often important
contributors to query answers. In this paper, inspired by Gaussian Differential
Privacy, we propose a novel confidentiality framework for business data with a
focus on interpretability for policy makers. We propose two query-answering
mechanisms and analyze new challenges that arise when noisy query answers are
converted into confidentiality-preserving microdata. We evaluate our mechanisms
on confidential Quarterly Census of Employment and Wages (QCEW) microdata and a
public substitute dataset.

</details>


### [40] [An Efficient Intrusion Detection System for Safeguarding Radiation Detection Systems](https://arxiv.org/abs/2509.01599)
*Nathanael Coolidge,Jaime González Sanz,Li Yang,Khalil El Khatib,Glenn Harvel,Nelson Agbemava,I Putu Susila,Mehmet Yavuz Yagci*

Main category: cs.CR

TL;DR: 本文提出了一种基于LightGBM的机器学习入侵检测系统，用于防范攻击者对政射检测系统的拒绝服务攻击，通过模型优化和TinyML技术实现了高准确性和低计算资源消耗。


<details>
  <summary>Details</summary>
Motivation: 政射检测系统(RDS)在环境监测中致关重要，但缺乏对恶意攻击的防护机制。尤其是拒绝服务(DoS)攻击可能导致系统故障，因此需要一种高效的入侵检测方案来保护这些关键基础设施。

Method: 使用采样方法模拟DoS攻出based on real radiation data，评估多种机器学习算法（随机森林、SVM、逻辑回归、LightGBM）的性能。采用特征选择、并行执行、随机搜索等模型优化技术和TinyML方法提高效率。

Result: LightGBM算法在入侵检测中表现最优，具有超高准确性和低计算资源消耗的优势，适合实时检测。最终开发出了优化的LightGBM基于入侵检测系统。

Conclusion: 该研究成功展示了机器学习在政射检测系统安全中的应用潜力，LightGBM算法通过优化后能够提供高效、准确且资源友好的入侵检测方案，为关键基础设施的安全保护提供了有效技术支撑。

Abstract: Radiation Detection Systems (RDSs) are used to measure and detect abnormal
levels of radioactive material in the environment. These systems are used in
many applications to mitigate threats posed by high levels of radioactive
material. However, these systems lack protection against malicious external
attacks to modify the data. The novelty of applying Intrusion Detection Systems
(IDS) in RDSs is a crucial element in safeguarding these critical
infrastructures. While IDSs are widely used in networking environments to
safeguard against various attacks, their application in RDSs is novel. A common
attack on RDSs is Denial of Service (DoS), where the attacker aims to overwhelm
the system, causing malfunctioning RDSs. This paper proposes an efficient
Machine Learning (ML)-based IDS to detect anomalies in radiation data, focusing
on DoS attacks. This work explores the use of sampling methods to create a
simulated DoS attack based on a real radiation dataset, followed by an
evaluation of various ML algorithms, including Random Forest, Support Vector
Machine (SVM), logistic regression, and Light Gradient-Boosting Machine
(LightGBM), to detect DoS attacks on RDSs. LightGBM is emphasized for its
superior accuracy and low computational resource consumption, making it
particularly suitable for real-time intrusion detection. Additionally, model
optimization and TinyML techniques, including feature selection, parallel
execution, and random search methods, are used to improve the efficiency of the
proposed IDS. Finally, an optimized and efficient LightGBM-based IDS is
developed to achieve accurate intrusion detection for RDSs.

</details>


### [41] [AmphiKey: A Dual-Mode Secure Authenticated Key Encapsulation Protocol for Smart Grid](https://arxiv.org/abs/2509.01701)
*Kazi Hassan Shakib,Muhammad Asfand Hafeez,Arslan Munir*

Main category: cs.CR

TL;DR: AmphiKey是一个双模式后量子/传统混合认证密钥交换机制，为智能电网通信提供抗量子和经典威胁的安全保护，包含认证模式和可否认模式两种操作方式。


<details>
  <summary>Details</summary>
Motivation: 设计一个能够同时抵御经典和量子计算威胁的密钥交换协议，满足智能电网基础设施对安全性、灵活性和效率的多样化需求。

Method: 采用混合设计：认证模式结合ML-KEM-768、X25519和Raccoon DSA提供前向保密和不可否认认证；可否认模式提供可否认认证保护隐私。使用ML-KEM-768、X25519、Raccoon DSA和Ascon密码算法。

Result: 在异构测试平台上性能评估显示：可否认模式下完整握手在服务器端0.15ms完成，树莓派客户端0.41ms；认证模式下受客户端签名生成限制，树莓派客户端发起握手需4.8ms，服务器验证需0.84ms。

Conclusion: AmphiKey提供了一个灵活的安全协议框架，具有增强的安全性、可选的可否认性和适应智能电网多样化需求的高效性能，成功实现了抗量子威胁的混合密钥交换机制。

Abstract: AmphiKey, a dual-mode post-quantum/traditional (PQ/T) hybrid authenticated
key exchange mechanism (AKEM) has been designed to secure smart grid
communications against both classical and quantum threats. AmphiKey offers two
distinct operational modes within a single framework: an Authenticated Mode and
a Deniable Mode. The Authenticated Mode employs a blackbox approach, combining
ephemeral ML-KEM-768 and X25519 with long-term Raccoon DSA keys to provide
forward secrecy and strong, non-repudiable authenticity. This design achieves
"OR" confidentiality, where security holds if either of the KEMs is unbroken,
and robust "AND" authenticity. For the signature operation, it leverages the
'masking-friendly' Raccoon digital signature (DSA), which is specifically
designed for side-channel attack resistance, though this protection is
localized to the signing key and does not provide deniability. In contrast,
Deniable Mode provides deniable authentication, preserving privacy. The
protocol used ML-KEM-768 (AKEM-1), Ephemeral X25519 (AKEM-2), Raccoon-based DSA
(Rac) (compared performance to ML-DSA-65), and the Ascon cipher to deliver its
security guarantees. Key contributions include providing a flexible protocol
with enhanced security, optional deniability, and efficiency adapted to the
diverse needs of the smart grid infrastructure. We present a comprehensive
performance evaluation on a heterogeneous testbed featuring a powerful server
and client (AMD Ryzen 5) and a resource-constrained client (Raspberry Pi). In
efficient Deniable mode, the full handshake completes in 0.15 ms on the server
and 0.41 ms on the Raspberry Pi client. In contrast, the Authenticated Mode is
bottlenecked by the client-side signature generation; the handshake takes 4.8
ms for the Raspberry Pi client to initiate and 0.84 ms for the server to
verify.

</details>


### [42] [Designing a Layered Framework to Secure Data via Improved Multi Stage Lightweight Cryptography in IoT Cloud Systems](https://arxiv.org/abs/2509.01717)
*Hojjat Farshadinia,Ali Barati,Hamid Barati*

Main category: cs.CR

TL;DR: 这篇论文提出了一种新的多层混合安全方案，通过组合改进的加密技术来提升IoT-云系统的轻量级加密性能和安全性。


<details>
  <summary>Details</summary>
Motivation: 解决传统解决方案（如TPA、区块链、ECDSA、ZSS）在数据保护、计算效率和可扩展性方面的不足。

Method: 提出三层核心架构：H.E.EZ层（整合改进的Hyperledger Fabric、Enc-Block和混合ECDSA-ZSS方案）、凭证管理层和时间审计层，通过协同使用区块链、IoT和云计算技术来优化性能。

Result: 评估结果显示该方案不仅提升了安全性，还显著改善了执行时间、通信效率和系统响应能力。

Conclusion: 该框架为下一代IoT-云基础设施提供了一条健壮的安全发展路径，通过多层混合方案有效解决了现有技术的限制。

Abstract: This paper presents a novel multi-layered hybrid security approach aimed at
enhancing lightweight encryption for IoT-Cloud systems. The primary goal is to
overcome limitations inherent in conventional solutions such as TPA,
Blockchain, ECDSA and ZSS which often fall short in terms of data protection,
computational efficiency and scalability. Our proposed method strategically
refines and integrates these technologies to address their shortcomings while
maximizing their individual strengths. By doing so we create a more reliable
and high-performance framework for secure data exchange across heterogeneous
environments. The model leverages the combined potential of emerging
technologies, particularly Blockchain, IoT and Cloud computing which when
effectively coordinated offer significant advancements in security
architecture. The proposed framework consists of three core layers: (1) the
H.E.EZ Layer which integrates improved versions of Hyperledger Fabric,
Enc-Block and a hybrid ECDSA-ZSS scheme to improve encryption speed,
scalability and reduce computational cost; (2) the Credential Management Layer
independently verifying data integrity and authenticity; and (3) the Time and
Auditing Layer designed to reduce traffic overhead and optimize performance
across dynamic workloads. Evaluation results highlight that the proposed
solution not only strengthens security but also significantly improves
execution time, communication efficiency and system responsiveness, offering a
robust path forward for next-generation IoT-Cloud infrastructures.

</details>


### [43] [Are Enterprises Ready for Quantum-Safe Cybersecurity?](https://arxiv.org/abs/2509.01731)
*Tran Duc Le,Phuc Hao Do,Truong Duy Dinh,Van Dai Pham*

Main category: cs.CR

TL;DR: 量子计算威胁传统加密术语，本文通过技术、企业和威胁角度分析企业量子安全准备状况，发现准备不充分且建议立即采取行动


<details>
  <summary>Details</summary>
Motivation: 评估企业对量子计算威胁的准备情况，提供量子安全网络安全的实用建议

Method: 采用三种视角（技术人员、企业管理者、威胁行动者）进行分析，结合NIST标准、行业调查和威胁情报，使用SWOT分析法

Result: 准备差异明显且不充分：少于5%企业有正式迁移计划，金融、电信、政府部门开始迁移，但大多数行业因成本和技能缺口而停滞

Conclusion: 需要立即采取协调、主动的方法，建立加密灵活性、制定迁移路线图、优先部署PQC并提升团队技能以保护当前和未来数字资产

Abstract: Quantum computing threatens to undermine classical cryptography by breaking
widely deployed encryption and signature schemes. This paper examines
enterprise readiness for quantum-safe cybersecurity through three perspectives:
(i) the technologist view, assessing the maturity of post-quantum cryptography
(PQC) and quantum key distribution (QKD); (ii) the enterprise (CISO/CIO) view,
analyzing organizational awareness, risk management, and operational barriers;
and (iii) the threat actor view, evaluating the evolving quantum threat and the
urgency of migration. Using recent standards (e.g., NIST's 2024 PQC
algorithms), industry surveys, and threat intelligence, we synthesize findings
via a SWOT analysis to map strengths, weaknesses, opportunities, and threats.
Results indicate uneven and generally insufficient preparedness: while PQC
standards and niche QKD deployments signal technical progress, fewer than 5\%
of enterprises have formal quantum-transition plans, and many underestimate
"harvest now, decrypt later" risks. Financial, telecom, and government sectors
have begun migration, but most industries remain exploratory or stalled by
costs, complexity, and skills gaps. Expert consensus places cryptanalytically
relevant quantum computers in the 2030s, yet delayed preparation could leave
today's data vulnerable for decades. We recommend immediate steps: establishing
crypto-agility, creating quantum transition roadmaps, prioritizing PQC
deployment in high-value systems, and upskilling cybersecurity teams. A
coordinated, proactive approach is essential to secure current and future
digital assets in the quantum era.

</details>


### [44] [BOLT: Bandwidth-Optimized Lightning-Fast Oblivious Map powered by Secure HBM Accelerators](https://arxiv.org/abs/2509.01742)
*Yitong Guo,Hongbo Chen,Haobin Hiroki Chen,Yukui Luo,XiaoFeng Wang,Chenghong Wang*

Main category: cs.CR

TL;DR: BOLT是一种基于HBM的OMAP加速器，通过利用隔离HBM作为不可观测缓存、自托管架构和算法-架构协同设计，实现了O(1) + O((log log N)^2)的带宽开销，相比现有OMAP方案获得高达279-480倍的性能提升。


<details>
  <summary>Details</summary>
Motivation: 传统可信执行环境仍存在访问模式泄露漏洞，而现有的Oblivious Maps虽然能隐藏访问模式，但由于随机重映射和最坏情况填充导致性能开销过高。现代加速器的高带宽内存(HBM)提供了新的机会，因为HBM内存通道与处理器核心封装在同一物理包内，难以被窃听，可以创建不可观测区域来隐藏数据和内存轨迹。

Method: 提出BOLT系统，包含三个关键创新：1）新OMAP算法利用隔离HBM作为不可观测缓存来加速对大容量主机内存的遗忘访问；2）自托管架构将执行和内存控制从主机卸载以减轻CPU端泄露；3）定制化的算法-架构协同设计以最大化资源效率。在Xilinx U55C FPGA上实现原型。

Result: 评估显示BOLT在初始化和查询时间上分别比最先进的OMAP方案（包括Facebook的工业实现）快279倍和480倍，首次实现了O(1) + O((log log N)^2)的带宽开销。

Conclusion: BOLT通过利用HBM的物理特性和创新的算法-架构协同设计，成功克服了传统OMAP的性能限制，为安全云计算提供了高性能的访问模式隐藏解决方案。

Abstract: While Trusted Execution Environments provide a strong foundation for secure
cloud computing, they remain vulnerable to access pattern leakages. Oblivious
Maps (OMAPs) mitigate this by fully hiding access patterns but suffer from high
overhead due to randomized remapping and worst-case padding. We argue these
costs are not fundamental. Modern accelerators featuring High-Bandwidth Memory
(HBM) offer a new opportunity: Vaswani et al. [OSDI'18] point out that
eavesdropping on HBM is difficult -- even for physical attackers -- as its
memory channels are sealed together with processor cores inside the same
physical package. Later, Hunt et al. [NSDI'20] show that, with proper
isolation, HBM can be turned into an unobservable region where both data and
memory traces are hidden. This motivates a rethink of OMAP design with
HBM-backed solutions to finally overcome their traditional performance limits.
Building on these insights, we present BOLT, a Bandwidth Optimized,
Lightning-fast OMAP accelerator that, for the first time, achieves O(1) +
O((log log N)^2) bandwidth overhead. BOLT introduces three key innovations: (i)
a new OMAP algorithm that leverages isolated HBM as an unobservable cache to
accelerate oblivious access to large host memory; (ii) a self-hosted
architecture that offloads execution and memory control from the host to
mitigate CPU-side leakage; and (iii) tailored algorithm-architecture co-designs
that maximize resource efficiency. We implement a prototype BOLT on a Xilinx
U55C FPGA. Evaluations show that BOLT achieves up to 279x and 480x speedups in
initialization and query time, respectively, over state-of-the-art OMAPs,
including an industry implementation from Facebook.

</details>


### [45] [E-PhishGen: Unlocking Novel Research in Phishing Email Detection](https://arxiv.org/abs/2509.01791)
*Luca Pajola,Eugenio Caripoti,Simeone Pizzi,Mauro Conti,Stefan Banzer,Giovanni Apruzzese*

Main category: cs.CR

TL;DR: 本文对钓鱼邮件检测研究进行了批判性评估，发现现有数据集不具代表性且多为英文，重新评估多种ML方法后发现性能被高估，提出了基于LLM的E-PhishGEN框架生成新数据集E-PhishLLM，显示检测性能大幅下降，证明钓鱼邮件检测仍是未解难题


<details>
  <summary>Details</summary>
Motivation: 现有钓鱼邮件检测研究虽然声称达到近乎完美的准确率，但实际中恶意邮件问题仍未解决，主要原因是使用的数据集不具代表性且多为英文，无法反映当前钓鱼趋势

Method: 重新实现和评估多种机器学习检测方法（包括大语言模型）；提出基于LLM的E-PhishGEN框架生成新型钓鱼邮件数据集；创建包含16616封邮件、三种语言的E-PhishLLM数据集；进行用户研究验证数据集质量

Result: 在相同数据集上训练和测试时方法性能接近完美，但在新创建的E-PhishLLM数据集上性能显著下降；用户研究验证了生成数据集的质量；表明现有检测方法存在严重过拟合问题

Conclusion: 钓鱼邮件检测仍然是一个开放性问题；需要更具挑战性的基准数据集来反映当前趋势；提供的E-PhishGEN框架和E-PhishLLM数据集为未来研究提供了解决这一问题的工具

Abstract: Every day, our inboxes are flooded with unsolicited emails, ranging between
annoying spam to more subtle phishing scams. Unfortunately, despite abundant
prior efforts proposing solutions achieving near-perfect accuracy, the reality
is that countering malicious emails still remains an unsolved dilemma.
  This "open problem" paper carries out a critical assessment of scientific
works in the context of phishing email detection. First, we focus on the
benchmark datasets that have been used to assess the methods proposed in
research. We find that most prior work relied on datasets containing emails
that -- we argue -- are not representative of current trends, and mostly
encompass the English language. Based on this finding, we then re-implement and
re-assess a variety of detection methods reliant on machine learning (ML),
including large-language models (LLM), and release all of our codebase -- an
(unfortunately) uncommon practice in related research. We show that most such
methods achieve near-perfect performance when trained and tested on the same
dataset -- a result which intrinsically hinders development (how can future
research outperform methods that are already near perfect?). To foster the
creation of "more challenging benchmarks" that reflect current phishing trends,
we propose E-PhishGEN, an LLM-based (and privacy-savvy) framework to generate
novel phishing-email datasets. We use our E-PhishGEN to create E-PhishLLM, a
novel phishing-email detection dataset containing 16616 emails in three
languages. We use E-PhishLLM to test the detectors we considered, showing a
much lower performance than that achieved on existing benchmarks -- indicating
a larger room for improvement. We also validate the quality of E-PhishLLM with
a user study (n=30). To sum up, we show that phishing email detection is still
an open problem -- and provide the means to tackle such a problem by future
research.

</details>


### [46] [From CVE Entries to Verifiable Exploits: An Automated Multi-Agent Framework for Reproducing CVEs](https://arxiv.org/abs/2509.01835)
*Saad Ullah,Praneeth Balasubramanian,Wenbo Guo,Amanda Burnett,Hammond Pearce,Christopher Kruegel,Giovanni Vigna,Gianluca Stringhini*

Main category: cs.CR

TL;DR: CVE-GENIE是一个基于大语言模型的多智能体框架，能够自动化复现CVE漏洞并生成可验证的漏洞利用程序，成功复现了2024-2025年51%的CVE漏洞，平均每个CVE成本2.77美元。


<details>
  <summary>Details</summary>
Motivation: 高质量的漏洞数据集对软件安全研究至关重要，但创建这类数据集需要大量人工工作和深度安全专业知识，现有资源稀缺。

Method: 使用基于LLM的多智能体框架，输入CVE条目后自动收集相关资源，重建漏洞环境，并生成可验证的漏洞利用程序。

Result: 成功复现了841个CVE中的428个（51%），平均每个CVE成本为2.77美元，证明了框架的高效性和鲁棒性。

Conclusion: 该框架为生成可复现的CVE基准提供了强大方法，可用于模糊测试评估、漏洞修补和AI安全能力评估等多种应用。

Abstract: High-quality datasets of real-world vulnerabilities and their corresponding
verifiable exploits are crucial resources in software security research. Yet
such resources remain scarce, as their creation demands intensive manual effort
and deep security expertise. In this paper, we present CVE-GENIE, an automated,
large language model (LLM)-based multi-agent framework designed to reproduce
real-world vulnerabilities, provided in Common Vulnerabilities and Exposures
(CVE) format, to enable creation of high-quality vulnerability datasets. Given
a CVE entry as input, CVE-GENIE gathers the relevant resources of the CVE,
automatically reconstructs the vulnerable environment, and (re)produces a
verifiable exploit. Our systematic evaluation highlights the efficiency and
robustness of CVE-GENIE's design and successfully reproduces approximately 51%
(428 of 841) CVEs published in 2024-2025, complete with their verifiable
exploits, at an average cost of $2.77 per CVE. Our pipeline offers a robust
method to generate reproducible CVE benchmarks, valuable for diverse
applications such as fuzzer evaluation, vulnerability patching, and assessing
AI's security capabilities.

</details>


### [47] [Augmented Shuffle Differential Privacy Protocols for Large-Domain Categorical and Key-Value Data](https://arxiv.org/abs/2509.02004)
*Takao Murakami,Yuichi Sei,Reo Eriguchi*

Main category: cs.CR

TL;DR: 提出FME协议，一种增强的shuffle DP协议，通过哈希过滤和多重加密技术解决现有协议在大域数据上的通信和计算成本问题，同时提供差分隐私保护和对合谋攻击、数据投毒攻击的鲁棒性。


<details>
  <summary>Details</summary>
Motivation: 现有shuffle DP协议在大域数据上通信和计算成本过高，且容易受到数据收集者与用户合谋攻击以及数据投毒攻击的威胁。

Method: 使用哈希函数过滤非热门项，通过多重加密技术在一轮交互中准确计算热门项频率，并扩展到KV统计估计以减少偏差。

Result: FME协议在分类数据和KV数据上均提供计算差分隐私、对两种攻击的高鲁棒性、高准确性和效率，与12个现有协议相比表现优异。

Conclusion: FME协议有效解决了大域数据下的shuffle DP问题，在保持隐私保护的同时实现了高效的频率估计。

Abstract: Shuffle DP (Differential Privacy) protocols provide high accuracy and privacy
by introducing a shuffler who randomly shuffles data in a distributed system.
However, most shuffle DP protocols are vulnerable to two attacks: collusion
attacks by the data collector and users and data poisoning attacks. A recent
study addresses this issue by introducing an augmented shuffle DP protocol,
where users do not add noise and the shuffler performs random sampling and
dummy data addition. However, it focuses on frequency estimation over
categorical data with a small domain and cannot be applied to a large domain
due to prohibitively high communication and computational costs.
  In this paper, we fill this gap by introducing a novel augmented shuffle DP
protocol called the FME (Filtering-with-Multiple-Encryption) protocol. Our FME
protocol uses a hash function to filter out unpopular items and then accurately
calculates frequencies for popular items. To perform this within one round of
interaction between users and the shuffler, our protocol carefully communicates
within a system using multiple encryption. We also apply our FME protocol to
more advanced KV (Key-Value) statistics estimation with an additional technique
to reduce bias. For both categorical and KV data, we prove that our protocol
provides computational DP, high robustness to the above two attacks, accuracy,
and efficiency. We show the effectiveness of our proposals through comparisons
with twelve existing protocols.

</details>


### [48] [Targeted Physical Evasion Attacks in the Near-Infrared Domain](https://arxiv.org/abs/2509.02042)
*Pascal Zimmer,Simon Lachnit,Alexander Jan Zielinski,Ghassan Karame*

Main category: cs.CR

TL;DR: 提出一种新型红外对抗攻击方法，使用透明薄膜和现成红外手电筒生成目标/非目标扰动，在数字和物理环境中对交通标志实现高成功率攻击，成本低于50美元，并提出基于分割的检测防御方法。


<details>
  <summary>Details</summary>
Motivation: 现有红外攻击方法大多只能进行非目标攻击，且需要针对特定使用场景进行大量优化，存在位置和形状等约束限制。需要开发更灵活、成本效益更高的红外对抗攻击技术。

Method: 通过透明薄膜投影红外扰动到目标物体上，使用现成的红外手电筒作为光源，首次实现无激光的红外目标攻击。在数字和物理域中对交通标志进行广泛实验验证。

Result: 在各种攻击场景（明亮光照条件、不同距离和角度）下均表现出高攻击成功率，优于现有方法。攻击部署成本低于50美元，仅需数十秒时间。同时提出了基于分割的检测方法，F1分数高达99%可有效防御该攻击。

Conclusion: 该方法实现了首个可靠的无激光红外目标攻击，具有隐蔽性、成本效益和高成功率的特点，同时提出的检测防御方法也为对抗此类攻击提供了有效解决方案。

Abstract: A number of attacks rely on infrared light sources or heat-absorbing material
to imperceptibly fool systems into misinterpreting visual input in various
image recognition applications. However, almost all existing approaches can
only mount untargeted attacks and require heavy optimizations due to the
use-case-specific constraints, such as location and shape. In this paper, we
propose a novel, stealthy, and cost-effective attack to generate both targeted
and untargeted adversarial infrared perturbations. By projecting perturbations
from a transparent film onto the target object with an off-the-shelf infrared
flashlight, our approach is the first to reliably mount laser-free targeted
attacks in the infrared domain. Extensive experiments on traffic signs in the
digital and physical domains show that our approach is robust and yields higher
attack success rates in various attack scenarios across bright lighting
conditions, distances, and angles compared to prior work. Equally important,
our attack is highly cost-effective, requiring less than US\$50 and a few tens
of seconds for deployment. Finally, we propose a novel segmentation-based
detection that thwarts our attack with an F1-score of up to 99%.

</details>


### [49] [Forecasting Future DDoS Attacks Using Long Short Term Memory (LSTM) Model](https://arxiv.org/abs/2509.02076)
*Kong Mun Yeen,Rafidah Md Noor,Wahidah Md Shah,Aslinda Hassan,Muhammad Umair Munir*

Main category: cs.CR

TL;DR: 使用深度学习模型预测未来DDoS攻击，基于CRISP-DM流程分析最新数据集，为攻击缓解提供规划依据


<details>
  <summary>Details</summary>
Motivation: 当前DDoS攻击预测研究相对有限，主要集中在检测方面。通过分析最新趋势和数据集，可以为攻击缓解制定更好的防御计划

Method: 采用CRISP-DM（跨行业数据挖掘标准流程）模型，使用深度学习技术进行时间序列分析和预测

Result: 建立了基于深度学习的DDoS攻击预测框架，能够对未来攻击进行有效预测

Conclusion: 深度学习模型结合CRISP-DM流程可以有效预测DDoS攻击，为网络安全防御提供前瞻性规划支持

Abstract: This paper forecasts future Distributed Denial of Service (DDoS) attacks
using deep learning models. Although several studies address forecasting DDoS
attacks, they remain relatively limited compared to detection-focused research.
By studying the current trends and forecasting based on newer and updated
datasets, mitigation plans against the attacks can be planned and formulated.
The methodology used in this research work conforms to the Cross Industry
Standard Process for Data Mining (CRISP-DM) model.

</details>


### [50] [From Attack Descriptions to Vulnerabilities: A Sentence Transformer-Based Approach](https://arxiv.org/abs/2509.02077)
*Refat Othman,Diaeddin Rimawi,Bruno Rossi,Barbara Russo*

Main category: cs.CR

TL;DR: 这篇论文评估了14种最先进的句子转换器模型，用于自动化将攻击描述映射到CVE漏洞。多QA-MPNet模型表现最佳，F1得分89.0，还发现了275个未在MITRE库中记录的新映射关系。


<details>
  <summary>Details</summary>
Motivation: 手动将攻击与CVE漏洞进行映射非常困难且耗时，需要自动化方案来提高事件响应速度和安全能力。

Method: 评估14种最先进的句子转换器模型，使用攻击技术描述来识别漏洞，对比各模型的分类性能。

Result: 多QA-MPNet模型表现最佳（F1=89.0，精度=84.0，召回率=94.7），能够发现275个未在MITRE库中记录的新映射关系，56%模型识别的漏洞在CVE库中有相应攻击记录。

Conclusion: 自动化映射攻击到漏洞不仅提高了安全事件检测和响应能力，还减少了漏洞可袭利的时间窗口，为构建更安全的系统做出贡献。

Abstract: In the domain of security, vulnerabilities frequently remain undetected even
after their exploitation. In this work, vulnerabilities refer to publicly
disclosed flaws documented in Common Vulnerabilities and Exposures (CVE)
reports. Establishing a connection between attacks and vulnerabilities is
essential for enabling timely incident response, as it provides defenders with
immediate, actionable insights. However, manually mapping attacks to CVEs is
infeasible, thereby motivating the need for automation. This paper evaluates 14
state-of-the-art (SOTA) sentence transformers for automatically identifying
vulnerabilities from textual descriptions of attacks. Our results demonstrate
that the multi-qa-mpnet-base-dot-v1 (MMPNet) model achieves superior
classification performance when using attack Technique descriptions, with an
F1-score of 89.0, precision of 84.0, and recall of 94.7. Furthermore, it was
observed that, on average, 56% of the vulnerabilities identified by the MMPNet
model are also represented within the CVE repository in conjunction with an
attack, while 61% of the vulnerabilities detected by the model correspond to
those cataloged in the CVE repository. A manual inspection of the results
revealed the existence of 275 predicted links that were not documented in the
MITRE repositories. Consequently, the automation of linking attack techniques
to vulnerabilities not only enhances the detection and response capabilities
related to software security incidents but also diminishes the duration during
which vulnerabilities remain exploitable, thereby contributing to the
development of more secure systems.

</details>


### [51] [Performance analysis of common browser extensions for cryptojacking detection](https://arxiv.org/abs/2509.02083)
*Dmitry Tanana*

Main category: cs.CR

TL;DR: 对5款主流浏览器扩展进行加密货币挖矿劫持防御效果测试，发现所有插件都存在严重性能限制，最好的扩展仅能检测27%的攻击网站，而有些热门扩展完全无法识别任何受感染网站。


<details>
  <summary>Details</summary>
Motivation: 评估普通用户可用的浏览器扩展在防御加密货币挖矿劫持方面的实际效果，验证其宣传功能与实际性能之间的差距。

Method: 使用包含373个不同加密货币挖矿劫持感染网站的经验证数据集，测试MinerBlock、AdGuard AdBlocker、Easy Redirect && Prevent Cryptojacking、CoinEater和Miners Shield这5款最流行扩展的检测能力。

Result: 所有插件表现严重不足：Easy Redirect和Miners Shield分别仅阻止6个和5个网站；MinerBlock检测率最高但也只有27%（101/373）；AdGuard（1300万用户）和CoinEater完全无法识别任何受感染网站。

Conclusion: 当前面向普通用户的加密货币挖矿劫持检测产品存在严重缺陷，急需改进实验室级检测技术的可访问性（90%+效率）或对现有常用扩展进行根本性升级。

Abstract: This paper considers five extensions for Chromium-based browsers in order to
determine how effective can browser-based defenses against cryptojacking
available to regular users be. We've examined most popular extensions -
MinerBlock, AdGuard AdBlocker, Easy Redirect && Prevent Cryptojacking,
CoinEater and Miners Shield, which claim to be designed specifically to
identify and stop illegal cryptocurrency mining. An empirically confirmed
dataset of 373 distinct cryptojacking-infected websites which was assembled
during multi-stage procedure, was used to test those extensions. The results
showed that all plugins in question had significant performance limits. Easy
Redirect and Miners Shield only blocked 6 and 5 websites respectively, while
MinerBlock had the greatest detection rate at only 27% (101/373 sites blocked).
Most concerningly, despite promises of cryptojacking prevention, AdGuard (which
has over 13 million users) and CoinEater were unable to identify any of the
compromised websites. These results demonstrate serious flaws in cryptojacking
detection products targeted for regular users, since even the best-performing
specimen failed to detect 73% of attacks. The obvious difference between
advertised capabilities and real performance highlights the urgent need for
either accessibility improvements for laboratory-grade detection technologies
that show 90%+ efficiency in controlled environment or fundamental upgrades to
current commonly used extensions.

</details>


### [52] [A Gentle Introduction to Blind signatures: From RSA to Lattice-based Cryptography](https://arxiv.org/abs/2509.02189)
*Aditya Bhardwaj,Péter Kutas*

Main category: cs.CR

TL;DR: 本文系统回顾了基于格的盲签名技术，从经典数字签名基础到量子抗性格密码构造，旨在应对量子计算对传统密码系统的安全威胁。


<details>
  <summary>Details</summary>
Motivation: 随着量子计算机的发展，传统密码系统（包括盲签名）的安全性将受到威胁，需要开发量子抗性密码协议来保护数字交易和数据的隐私性。

Method: 采用文献综述方法，首先回顾经典数字签名的基础知识，然后重点分析基于格的盲签名构造方案。

Result: 提供了对格基盲签名技术的全面背景回顾，为开发量子安全的盲签名协议奠定了理论基础。

Conclusion: 基于格的盲签名是构建量子安全隐私保护系统的关键技术方向，需要继续深入研究以应对未来的量子计算威胁。

Abstract: Blind signatures were first introduced by David Chaum. They allow a user to
have a message signed by a signer without revealing the message itself. This
property is particularly useful in applications such as electronic voting and
digital cash, where user anonymity is important. In a blind signature scheme,
the user blinds their message before sending it to the signer, who signs the
blinded message. The user then unblinds the signed message to obtain a valid
signature that can be verified publicly, ensuring that the signer cannot trace
the signed message back to the original unblinded version. A good analogy is
placing the message inside an envelope and having the envelope signed. Once the
envelope is opened, the signature remains valid for the enclosed message,
ensuring that the content remains confidential.
  Such constructions provide anonymity and privacy to the user but given a
practical quantum computer, the security of traditional crypto-systems
providing such features will be broken. To address this, the development of
quantum-resistant cryptographic protocols is essential for maintaining the
security of digital transactions and data. Aligning with the same goal, this
work aims to thoroughly review the background of lattice-based blind
signatures. We start with the foundations of digital signatures in the
classical settings and then move on to lattice-based constructions.

</details>


### [53] [Passwords and FIDO2 Are Meant To Be Secret: A Practical Secure Authentication Channel for Web Browsers](https://arxiv.org/abs/2509.02289)
*Anuj Gautam,Tarun Yadav,Garrett Smith,Kent Seamons,Scott Ruoti*

Main category: cs.CR

TL;DR: 本文提出并实现了两种防御机制来保护密码管理器和FIDO2协议免受XSS攻击和恶意浏览器扩展的本地攻击，在Firefox浏览器中验证了有效性和网站兼容性。


<details>
  <summary>Details</summary>
Motivation: 恶意客户端脚本和浏览器扩展可以在密码管理器自动填充后窃取密码，现有安全机制存在漏洞，需要增强本地攻击防护能力。

Method: 设计并实现了两种防御机制：1）加强密码自动填充防护，防止XSS和恶意扩展攻击；2）创建通用防御方案保护FIDO2协议，两种方案均在Firefox浏览器中实现并进行实验验证。

Result: 实验证明防御机制成功保护密码免受XSS攻击和恶意扩展侵害，与Alexa top 1000网站中97%兼容；FIDO2防御方案对所有网站兼容，但需要服务器端进行少量代码修改（2-3行）。

Conclusion: 提出的防御方案有效增强了密码管理器和FIDO2协议的安全性，能够抵御本地攻击，具有较高的实用性和兼容性，为Web安全提供了重要保护机制。

Abstract: Password managers provide significant security benefits to users. However,
malicious client-side scripts and browser extensions can steal passwords after
the manager has autofilled them into the web page. In this paper, we extend
prior work by Stock and Johns, showing how password autofill can be hardened to
prevent these local attacks. We implement our design in the Firefox browser and
conduct experiments demonstrating that our defense successfully protects
passwords from XSS attacks and malicious extensions. We also show that our
implementation is compatible with 97% of the Alexa top 1000 websites. Next, we
generalize our design, creating a second defense that prevents recently
discovered local attacks against the FIDO2 protocols. We implement this second
defense into Firefox, demonstrating that it protects the FIDO2 protocol against
XSS attacks and malicious extensions. This defense is compatible with all
websites, though it does require a small change (2-3 lines) to web servers
implementing FIDO2.

</details>


### [54] [Poisoned at Scale: A Scalable Audit Uncovers Hidden Scam Endpoints in Production LLMs](https://arxiv.org/abs/2509.02372)
*Zhiyang Chen,Tara Saba,Xun Deng,Xujie Si,Fan Long*

Main category: cs.CR

TL;DR: 论文发现主流LLMs存在系统性安全漏洞，4.2%的生成代码包含恶意URL，且这些恶意代码往往是在响应无害提示时产生的，证明训练数据已被大规模投毒。


<details>
  <summary>Details</summary>
Motivation: 评估LLMs因依赖互联网训练数据而吸收和重现恶意内容的安全风险，揭示模型训练数据被投毒的威胁。

Method: 开发可扩展的自动化审计框架，从已知诈骗数据库合成无害的开发者风格提示，查询生产级LLMs并检测生成代码是否包含有害URL。

Result: 在4个生产级LLMs测试中发现系统性漏洞，平均4.2%的生成程序包含恶意URL，手动验证出177个无害提示能触发所有模型产生有害输出。

Conclusion: 生产级LLMs的训练数据已被成功大规模投毒，亟需更强大的防御机制和生成后安全检查来缓解隐藏安全威胁的传播。

Abstract: Large Language Models (LLMs) have become critical to modern software
development, but their reliance on internet datasets for training introduces a
significant security risk: the absorption and reproduction of malicious
content. To evaluate this threat, this paper introduces a scalable, automated
audit framework that synthesizes innocuous, developer-style prompts from known
scam databases to query production LLMs and determine if they generate code
containing harmful URLs. We conducted a large-scale evaluation across four
production LLMs (GPT-4o, GPT-4o-mini, Llama-4-Scout, and DeepSeek-V3), and
found a systemic vulnerability, with all tested models generating malicious
code at a non-negligible rate. On average, 4.2\% of programs generated in our
experiments contained malicious URLs. Crucially, this malicious code is often
generated in response to benign prompts. We manually validate the prompts which
cause all four LLMs to generate malicious code, and resulting in 177 innocuous
prompts that trigger all models to produce harmful outputs. These results
provide strong empirical evidence that the training data of production LLMs has
been successfully poisoned at scale, underscoring the urgent need for more
robust defense mechanisms and post-generation safety checks to mitigate the
propagation of hidden security threats.

</details>


### [55] [Real-time ML-based Defense Against Malicious Payload in Reconfigurable Embedded Systems](https://arxiv.org/abs/2509.02387)
*Rye Stahle-Smith,Rasha Karakchi*

Main category: cs.CR

TL;DR: 提出了一种基于监督机器学习的恶意比特流检测方法，通过静态字节级特征分析直接在二进制层面检测FPGA中的硬件木马，无需源代码或网表，实现了实时检测。


<details>
  <summary>Details</summary>
Motivation: FPGA在可重构系统中的广泛应用带来了安全风险，恶意比特流可能导致拒绝服务、数据泄露或隐蔽攻击，需要有效的检测方法。

Method: 采用监督机器学习方法，通过字节频率分析对比特流进行向量化，使用TSVD压缩和SMOTE平衡类别不平衡，在Xilinx PYNQ-Z1开发板上评估多种分类器。

Result: 随机森林分类器取得了0.97的宏F1分数，证明了在资源受限系统上实时木马检测的可行性，最终模型成功部署到PYNQ平台。

Conclusion: 该方法能够有效检测FPGA恶意比特流，为嵌入式系统提供了实用的实时安全检测解决方案。

Abstract: The growing use of FPGAs in reconfigurable systems introducessecurity risks
through malicious bitstreams that could cause denial-of-service (DoS), data
leakage, or covert attacks. We investigated chip-level hardware malicious
payload in embedded systems and proposed a supervised machine learning method
to detect malicious bitstreams via static byte-level features. Our approach
diverges from existing methods by analyzing bitstreams directly at the binary
level, enabling real-time detection without requiring access to source code or
netlists. Bitstreams were sourced from state-of-the-art (SOTA) benchmarks and
re-engineered to target the Xilinx PYNQ-Z1 FPGA Development Board. Our dataset
included 122 samples of benign and malicious configurations. The data were
vectorized using byte frequency analysis, compressed using TSVD, and balanced
using SMOTE to address class imbalance. The evaluated classifiers demonstrated
that Random Forest achieved a macro F1-score of 0.97, underscoring the
viability of real-time Trojan detection on resource-constrained systems. The
final model was serialized and successfully deployed via PYNQ to enable
integrated bitstream analysis.

</details>


### [56] [A Survey: Towards Privacy and Security in Mobile Large Language Models](https://arxiv.org/abs/2509.02411)
*Honghui Xu,Kaiyang Li,Wei Chen,Danyang Zheng,Zhiyuan Li,Zhipeng Cai*

Main category: cs.CR

TL;DR: 这篇论文是一个关于移动大语言模型隐私与安全问题的综述，系统分析了相关挑战、现有解决方案和未来研究方向。


<details>
  <summary>Details</summary>
Motivation: 移动LLM在医疗、金融、教育等领域带来革命性变革，但在资源受限环境中部署引发了重大隐私和安全挑战。

Method: 系统分类现有解决方案（差分隐私、联邦学习、提示加密等），分析特有漏洞（对抗攻击、成员推断、侧信道攻击等），并进行深入比较。

Result: 识别了移动LLM在实现健壮安全的同时保持资源约束环境中效率的特有障碍。

Conclusion: 提出了潜在应用、讨论了开放性挑战并建议了未来研究方向，为发展可信豖、隐私合规的移动LLM系统排除障碍。

Abstract: Mobile Large Language Models (LLMs) are revolutionizing diverse fields such
as healthcare, finance, and education with their ability to perform advanced
natural language processing tasks on-the-go. However, the deployment of these
models in mobile and edge environments introduces significant challenges
related to privacy and security due to their resource-intensive nature and the
sensitivity of the data they process. This survey provides a comprehensive
overview of privacy and security issues associated with mobile LLMs,
systematically categorizing existing solutions such as differential privacy,
federated learning, and prompt encryption. Furthermore, we analyze
vulnerabilities unique to mobile LLMs, including adversarial attacks,
membership inference, and side-channel attacks, offering an in-depth comparison
of their effectiveness and limitations. Despite recent advancements, mobile
LLMs face unique hurdles in achieving robust security while maintaining
efficiency in resource-constrained environments. To bridge this gap, we propose
potential applications, discuss open challenges, and suggest future research
directions, paving the way for the development of trustworthy,
privacy-compliant, and scalable mobile LLM systems.

</details>


### [57] [APEX: Automatic Event Sequence Generation for Android Applications](https://arxiv.org/abs/2509.02412)
*Wenhao Chen,Morris Chang,Witawas Srisa-an,Yong Guan*

Main category: cs.CR

TL;DR: APEX是一个使用符号执行的Android GUI输入生成框架，通过分析GUI状态转换的数据依赖关系，系统地生成高代码覆盖率的事件序列和特定目标路径。


<details>
  <summary>Details</summary>
Motivation: Android程序的GUI设计多样性和事件驱动特性使得在合理时间内生成具有足够代码覆盖率的事件序列具有挑战性。基于GUI模型的方法虽然能覆盖GUI状态，但在需要特定输入的程序行为暴露方面表现不一致。

Method: APEX采用符号执行技术，发现GUI状态转换的数据依赖关系，并在GUI探索过程中优先处理事件。符号执行不仅用于构建事件序列，还用于更系统地遍历GUI。

Result: 实验结果表明，APEX能够生成实现高代码覆盖率的事件序列集合，以及达到特定目标的事件序列。

Conclusion: APEX通过符号执行有效解决了基于模型序列生成的局限性，提供了更鲁棒的GUI模型和更准确的输入生成能力。

Abstract: Due to the event driven nature and the versatility of GUI designs in Android
programs, it is challenging to generate event sequences with adequate code
coverage within a reasonable time. A common approach to handle this issue is to
rely on GUI models to generate event sequences. These sequences can be
effective in covering GUI states, but inconsistent in exposing program
behaviors that require specific inputs. A major obstacle to generate such
specific inputs is the lack of a systematic GUI exploration process to
accommodate the analysis requirements. In this paper, we introduce Android Path
Explorer (APEX), a systematic input generation framework using concolic
execution. APEX addresses the limitations of model-based sequence generation by
using concolic execution to discover the data dependencies of GUI state
transitions. Moreover, concolic execution is also used to prioritize events
during the exploration of GUI, which leads to a more robust model and accurate
input generation. The key novelty of APEX is that concolic execution is not
only used to construct event sequences, but also used to traverse the GUI more
systematically. As such, our experimental results show that APEX can be used to
generate a set of event sequences that achieve high code coverage, as well as
event sequences that reach specific targets.

</details>


### [58] [Enabling decision support over confidential data](https://arxiv.org/abs/2509.02413)
*Edoardo Marangone,Eugenio Nerio Nemmi,Daniele Friolo,Giuseppe Ateniese,Ingo Weber,Claudio Di Ciccio*

Main category: cs.CR

TL;DR: SPARTA是一个基于可信执行环境(TEE)的安全决策支持平台，通过加密技术和可验证软件对象解决多方场景下数据隐私和决策透明性的挑战


<details>
  <summary>Details</summary>
Motivation: 在多参与方场景中，决策依赖于分布式敏感数据时，同时确保机密性、可验证性、透明度、完整性和一致性是决策支持系统面临的开放挑战

Method: 利用可信执行环境(TEE)保护决策逻辑和数据，将决策规则编码为可验证软件对象部署在TEE中，采用基于用户可定义访问策略的加密技术对公证数据进行处理

Result: 在公共基准测试和合成数据上的实验表明，该方法具有实际应用性和可扩展性

Conclusion: SPARTA方法能够有效解决多方决策场景中的安全性和透明度问题，为自动化决策过程提供了可行的解决方案

Abstract: Enabling automated decision-making processes by leveraging data-driven
analysis is a core goal of Decision Support Systems (DSSs). In multi-party
scenarios where decisions rely on distributed and sensitive data, though,
ensuring confidentiality, verifiability, transparency, integrity, and
consistency at once remains an open challenge for DSSs. To tackle this
multi-faceted problem, we propose the Secure Platform for Automated decision
Rules via Trusted Applications (SPARTA) approach. By leveraging Trusted
Execution Environments (TEEs) at its core, SPARTA ensures that the decision
logic and the data remain protected. To guarantee transparency and consistency
of the decision process, SPARTA encodes decision rules into verifiable software
objects deployed within TEEs. To maintain the confidentiality of the outcomes
while keeping the information integrity, SPARTA employs cryptography techniques
on notarized data based on user-definable access policies. Based on experiments
conducted on public benchmarks and synthetic data, we find our approach to be
practically applicable and scalable.

</details>
