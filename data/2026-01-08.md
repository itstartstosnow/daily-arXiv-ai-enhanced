<div id=toc></div>

# Table of Contents

- [cs.CR](#cs.CR) [Total: 18]


<div id='cs.CR'></div>

# cs.CR [[Back]](#toc)

### [1] [Automated Post-Incident Policy Gap Analysis via Threat-Informed Evidence Mapping using Large Language Models](https://arxiv.org/abs/2601.03287)
*Huan Lin Oh,Jay Yong Jun Jie,Mandy Lee Ling Siu,Jonathan Pan*

Main category: cs.CR

TL;DR: LLM驱动的框架用于自动化网络安全事件后审查，通过分析日志数据、映射到MITRE ATT&CK框架，并评估安全策略的充分性，生成可追溯的修复建议。


<details>
  <summary>Details</summary>
Motivation: 当前网络安全事件后审查工作劳动密集、耗时且依赖专家判断，需要提高效率和一致性。

Method: 提出基于威胁情报的智能体框架，使用GPT-4o进行推理，LangGraph进行多智能体工作流编排，LlamaIndex进行可追溯策略检索，通过模拟暴力攻击场景（MITRE ATT&CK T1110）进行验证。

Result: 实验结果表明LLM管道能够解释日志证据，识别不足或缺失的策略控制，并生成具有明确证据到策略可追溯性的可操作修复建议。

Conclusion: LLM辅助分析有潜力提高事件后评估的效率、一致性和可审计性，但在高风险网络安全决策中仍需人工监督。

Abstract: Cybersecurity post-incident reviews are essential for identifying control failures and improving organisational resilience, yet they remain labour-intensive, time-consuming, and heavily reliant on expert judgment. This paper investigates whether Large Language Models (LLMs) can augment post-incident review workflows by autonomously analysing system evidence and identifying security policy gaps. We present a threat-informed, agentic framework that ingests log data, maps observed behaviours to the MITRE ATT&CK framework, and evaluates organisational security policies for adequacy and compliance. Using a simulated brute-force attack scenario against a Windows OpenSSH service (MITRE ATT&CK T1110), the system leverages GPT-4o for reasoning, LangGraph for multi-agent workflow orchestration, and LlamaIndex for traceable policy retrieval. Experimental results indicate that the LLM-based pipeline can interpret log-derived evidence, identify insufficient or missing policy controls, and generate actionable remediation recommendations with explicit evidence-to-policy traceability. Unlike prior work that treats log analysis and policy validation as isolated tasks, this study integrates both into a unified end-to-end proof-of-concept post-incident review framework. The findings suggest that LLM-assisted analysis has the potential to improve the efficiency, consistency, and auditability of post-incident evaluations, while highlighting the continued need for human oversight in high-stakes cybersecurity decision-making.

</details>


### [2] [How Real is Your Jailbreak? Fine-grained Jailbreak Evaluation with Anchored Reference](https://arxiv.org/abs/2601.03288)
*Songyang Liu,Chaozhuo Li,Rui Pu,Litian Zhang,Chenxu Wang,Zejian Chen,Yuting Zhang,Yiming Hei*

Main category: cs.CR

TL;DR: FJAR是一个细粒度越狱评估框架，通过锚定参考解决现有方法对攻击成功率的高估问题，将越狱响应分为五类，并引入无害树分解构建高质量参考来指导评估。


<details>
  <summary>Details</summary>
Motivation: 当前LLM越狱攻击的自动化评估方法主要依赖粗粒度分类，主要关注有害性，导致对攻击成功率的严重高估。需要更精细的评估框架来准确评估越狱攻击的实际效果。

Method: 1) 将越狱响应分为五类：拒绝型、无关型、无帮助型、错误型、成功型；2) 引入无害树分解方法，通过分解原始查询构建高质量的锚定参考；3) 使用这些参考指导评估者判断响应是否真正满足原始查询意图。

Result: 大量实验表明，FJAR在与人判断的一致性方面达到最高水平，能有效识别越狱失败的根本原因，为改进攻击策略提供可操作的指导。

Conclusion: FJAR框架通过细粒度分类和锚定参考解决了现有越狱评估方法的局限性，提供了更准确、可解释的评估结果，有助于更好地理解和改进LLM的安全性。

Abstract: Jailbreak attacks present a significant challenge to the safety of Large Language Models (LLMs), yet current automated evaluation methods largely rely on coarse classifications that focus mainly on harmfulness, leading to substantial overestimation of attack success. To address this problem, we propose FJAR, a fine-grained jailbreak evaluation framework with anchored references. We first categorized jailbreak responses into five fine-grained categories: Rejective, Irrelevant, Unhelpful, Incorrect, and Successful, based on the degree to which the response addresses the malicious intent of the query. This categorization serves as the basis for FJAR. Then, we introduce a novel harmless tree decomposition approach to construct high-quality anchored references by breaking down the original queries. These references guide the evaluator in determining whether the response genuinely fulfills the original query. Extensive experiments demonstrate that FJAR achieves the highest alignment with human judgment and effectively identifies the root causes of jailbreak failures, providing actionable guidance for improving attack strategies.

</details>


### [3] [Differentiation Between Faults and Cyberattacks through Combined Analysis of Cyberspace Logs and Physical Measurements](https://arxiv.org/abs/2601.03289)
*Mohammad Shamim Ahsan,Haizhou Wang,Venkateswara Reddy Motakatla,Minghui Zhu,Peng Liu*

Main category: cs.CR

TL;DR: 提出一种基于虚拟物理变量导向污点分析(PVOTA)和模式匹配的方法，用于自动区分分布式能源资源系统中的未检测故障和网络攻击。


<details>
  <summary>Details</summary>
Motivation: 分布式能源资源系统中，网络攻击和物理故障都可能导致系统失效，且许多故障未被检测到。现有方法依赖物理定律或测量，无法准确区分未检测故障和网络攻击。行业通常采用物理测量与网络信息集成分析，但需要大量人工时间。

Method: 1) 使用新颖的虚拟物理变量导向污点分析(PVOTA)算法构建特殊依赖图；2) 基于上下文相关操作进行节点剪枝简化图；3) 推导捕获领域知识的模式以弥合网络与物理侧的语义鸿沟；4) 将模式与故障事件匹配，基于匹配结果推断根本原因。

Result: 通过四个案例研究评估方法有效性，包括FDI攻击、未检测故障和内存损坏攻击导致的故障事件，证明了自动集成分析方法的效能。

Conclusion: 该方法能够自动区分DER系统中的未检测故障和网络攻击，解决了现有方法依赖物理定律或测量、行业方法耗时长的关键问题，实现了高效准确的故障诊断。

Abstract: In recent years, cyberattacks - along with physical faults - have become an increasing factor causing system failures, especially in DER (Distributed Energy Resources) systems. In addition, according to the literature, a number of faults have been reported to remain undetected. Consequently, unlike anomaly detection works that only identify abnormalities, differentiating undetected faults and cyberattacks is a challenging task. Although several works have studied this problem, they crucially fall short of achieving an accurate distinction due to the reliance on physical laws or physical measurements. To resolve this issue, the industry typically conducts an integrated analysis with physical measurements and cyberspace information. Nevertheless, this industry approach consumes a significant amount of time due to the manual efforts required in the analysis. In this work, we focus on addressing these crucial gaps by proposing a non-trivial approach of distinguishing undetected faults and cyberattacks in DER systems. Specifically, first, a special kind of dependency graph is constructed using a novel virtual physical variable-oriented taint analysis (PVOTA) algorithm. Then, the graph is simplified using an innovative node pruning technique, which is based on a set of context-dependent operations. Next, a set of patterns capturing domain-specific knowledge is derived to bridge the semantic gaps between the cyber and physical sides. Finally, these patterns are matched to the relevant events that occurred during failure incidents, and possible root causes are concluded based on the pattern matching results. In the end, the efficacy of our proposed automatic integrated analysis is evaluated through four case studies covering failure incidents caused by the FDI attack, undetected faults, and memory corruption attacks.

</details>


### [4] [AgentMark: Utility-Preserving Behavioral Watermarking for Agents](https://arxiv.org/abs/2601.03294)
*Kaibo Huang,Jin Tan,Yukun Wei,Wanling Li,Zipei Zhang,Hui Tian,Zhongliang Yang,Linna Zhou*

Main category: cs.CR

TL;DR: AgentMark：一种行为水印框架，可在智能体规划决策中嵌入多比特标识符，同时保持任务效用，解决LLM智能体行为溯源问题


<details>
  <summary>Details</summary>
Motivation: LLM智能体被广泛部署解决复杂任务，需要IP保护和监管溯源。传统内容水印只能识别LLM生成的输出，无法直接识别高层规划行为（如工具选择和子目标选择），而这些行为控制着多步执行过程。在规划行为层进行水印面临独特挑战：决策中的微小分布偏差会在长期智能体操作中累积，降低效用；许多智能体作为黑盒运行，难以直接干预。

Method: 提出AgentMark行为水印框架，通过从智能体引出显式行为分布，并应用保持分布的条件采样，在规划决策中嵌入多比特标识符。该方法可在黑盒API下部署，同时与动作层内容水印兼容。

Result: 在具身、工具使用和社交环境中的实验表明，AgentMark具有实用的多比特容量，能从部分日志中稳健恢复标识符，并保持任务效用。

Conclusion: AgentMark填补了LLM智能体行为溯源的技术空白，通过在规划行为层嵌入水印，实现了对智能体高层决策行为的有效识别和溯源，同时保持任务执行效果。

Abstract: LLM-based agents are increasingly deployed to autonomously solve complex tasks, raising urgent needs for IP protection and regulatory provenance. While content watermarking effectively attributes LLM-generated outputs, it fails to directly identify the high-level planning behaviors (e.g., tool and subgoal choices) that govern multi-step execution. Critically, watermarking at the planning-behavior layer faces unique challenges: minor distributional deviations in decision-making can compound during long-term agent operation, degrading utility, and many agents operate as black boxes that are difficult to intervene in directly. To bridge this gap, we propose AgentMark, a behavioral watermarking framework that embeds multi-bit identifiers into planning decisions while preserving utility. It operates by eliciting an explicit behavior distribution from the agent and applying distribution-preserving conditional sampling, enabling deployment under black-box APIs while remaining compatible with action-layer content watermarking. Experiments across embodied, tool-use, and social environments demonstrate practical multi-bit capacity, robust recovery from partial logs, and utility preservation. The code is available at https://github.com/Tooooa/AgentMark.

</details>


### [5] [TRYLOCK: Defense-in-Depth Against LLM Jailbreaks via Layered Preference and Representation Engineering](https://arxiv.org/abs/2601.03300)
*Scott Thornton*

Main category: cs.CR

TL;DR: TRYLOCK是一个多层防御架构，结合了四种异构机制来防御LLM越狱攻击，在Mistral-7B-Instruct上实现了88%的相对攻击成功率降低，同时减少了过度拒绝。


<details>
  <summary>Details</summary>
Motivation: 大型语言模型仍然容易受到越狱攻击，单层防御往往需要在安全性和可用性之间做出权衡。需要一种深度防御架构来同时提高安全性和保持可用性。

Method: 提出了TRYLOCK防御架构，包含四个层次：1) 权重级安全对齐（DPO）；2) 激活级控制（RepE表示工程）；3) 轻量级侧边分类器选择自适应转向强度；4) 输入规范化以中和基于编码的绕过攻击。

Result: 在Mistral-7B-Instruct上评估249个提示的攻击集，TRYLOCK实现了88.0%的相对攻击成功率降低（从46.5%降至5.6%）。RepE阻止了36%的绕过DPO的攻击，规范化捕获了14%的编码攻击。自适应侧边分类器将过度拒绝从60%降至48%。

Conclusion: TRYLOCK展示了安全性和可用性不必相互排斥，通过多层异构防御架构可以有效防御越狱攻击。发现了非单调转向现象，并提供了RepE-DPO干扰的机制解释。所有组件开源以确保可复现性。

Abstract: Large language models remain vulnerable to jailbreak attacks, and single-layer defenses often trade security for usability. We present TRYLOCK, the first defense-in-depth architecture that combines four heterogeneous mechanisms across the inference stack: weight-level safety alignment via DPO, activation-level control via Representation Engineering (RepE) steering, adaptive steering strength selected by a lightweight sidecar classifier, and input canonicalization to neutralize encoding-based bypasses. On Mistral-7B-Instruct evaluated against a 249-prompt attack set spanning five attack families, TRYLOCK achieves 88.0% relative ASR reduction (46.5% to 5.6%), with each layer contributing unique coverage: RepE blocks 36% of attacks that bypass DPO alone, while canonicalization catches 14% of encoding attacks that evade both. We discover a non-monotonic steering phenomenon -- intermediate strength (alpha=1.0) degrades safety below baseline -- and provide mechanistic hypotheses explaining RepE-DPO interference. The adaptive sidecar reduces over-refusal from 60% to 48% while maintaining identical attack defense, demonstrating that security and usability need not be mutually exclusive. We release all components -- trained adapters, steering vectors, sidecar classifier, preference pairs, and complete evaluation methodology -- enabling full reproducibility.

</details>


### [6] [Autonomous Threat Detection and Response in Cloud Security: A Comprehensive Survey of AI-Driven Strategies](https://arxiv.org/abs/2601.03303)
*Gaurav Sarraf,Vibhor Pal*

Main category: cs.CR

TL;DR: AI技术正在变革云安全，通过深度学习、机器学习和强化学习实现自主防护、异常检测和实时分析，提高检测准确性并减少误报，但面临数据隐私、对抗性机器学习等挑战。


<details>
  <summary>Details</summary>
Motivation: 云计算虽然带来了可扩展性、适应性和降低开销等优势，但其分布式和多租户特性带来了严重的安全问题。传统的基于固定签名、预定义规则和人工操作的威胁检测方法在面对日益复杂的云基础设施网络攻击时效果越来越差。

Method: 采用人工智能技术，包括深度学习、机器学习和强化学习，构建具有持续学习能力的入侵检测系统。结合大规模语言模型和高效编排平台，实现更快速、更精确的威胁响应。

Result: AI驱动的云安全系统能够实现更高的检测准确性、更低的误报率，并支持自适应和预测性安全。能够实现自动事件控制、自愈网络和基于策略的防御机制。

Conclusion: AI在云安全领域展现出巨大潜力，能够支持自主、可扩展和主动的安全运维。但需要解决数据隐私、对抗性机器学习和集成复杂性等关键挑战，以实现AI在云安全中的未来应用。

Abstract: Cloud computing has changed online communities in three dimensions, which are scalability, adaptability and reduced overhead. But there are serious security concerns which are brought about by its distributed and multi-tenant characteristics. The old methods of detecting and reacting to threats which are mostly reliant on fixed signatures, predefined rules and human operators are becoming less and less effective even in the advanced stages of cyberattacks of cloud infrastructures. The recent trend in the field of addressing these limitations is the creation of technologies of artificial intelligence (AI). The strategies allow independent protection, anomaly detection, and real-time analysis with references to using deep learning, machine learning, and reinforcement learning. Through imbuing AI with a constantly-learning feature, it enables the intrusion detection system to be more accurate and generate a lesser number of false positives and it also enables the possibility of adaptive and predictive security. The fusion of large-scale language models with efficient orchestration platforms contributes to reacting to the arising threats with a quicker and more precise response. This allows automatic control over incidences, self-healing network, and defense mechanisms on a policy basis. Considering the current detection and response methods, this discussion assesses their strengths and weaknesses and outlines key issues such as data privacy, adversarial machine learning and integration complexity in the context of AI-based cloud security. These results suggest the future application of AI to support autonomous, scalable and active cloud security operations.

</details>


### [7] [AI-Driven Cybersecurity Threats: A Survey of Emerging Risks and Defensive Strategies](https://arxiv.org/abs/2601.03304)
*Sai Teja Erukude,Viswa Chaitanya Marella,Suhasnadh Reddy Veluru*

Main category: cs.CR

TL;DR: 论文分析了AI在网络安全中的双重用途性质，重点关注深度伪造、对抗性AI攻击、自动化恶意软件和AI驱动的社会工程四大威胁类别，提出了分类法、防御策略和研究方向。


<details>
  <summary>Details</summary>
Motivation: AI的双重用途性质正在改变网络安全格局，既带来防御优势也创造新的攻击手段。论文旨在分析AI在网络安全中的新兴风险、攻击机制和防御不足，为构建更安全的数字生态系统提供指导。

Method: 1. 引入连接AI能力与威胁模式和防御的比较分类法；2. 回顾70多个学术和行业参考文献；3. 按威胁类型进行主题结构化分析，每个部分涵盖技术背景、真实案例、法律框架和应对措施。

Result: 识别了有影响力的研究机会，如混合检测管道和基准测试框架。强调了构建可解释、跨学科且符合监管要求的AI防御系统的紧迫性，以维护数字生态系统中的信任和安全。

Conclusion: AI在网络安全中既是机遇也是挑战，需要开发可解释、跨学科且符合监管的AI防御系统来应对新兴威胁，维护数字信任和安全。

Abstract: Artificial Intelligence's dual-use nature is revolutionizing the cybersecurity landscape, introducing new threats across four main categories: deepfakes and synthetic media, adversarial AI attacks, automated malware, and AI-powered social engineering. This paper aims to analyze emerging risks, attack mechanisms, and defense shortcomings related to AI in cybersecurity. We introduce a comparative taxonomy connecting AI capabilities with threat modalities and defenses, review over 70 academic and industry references, and identify impactful opportunities for research, such as hybrid detection pipelines and benchmarking frameworks. The paper is structured thematically by threat type, with each section addressing technical context, real-world incidents, legal frameworks, and countermeasures. Our findings emphasize the urgency for explainable, interdisciplinary, and regulatory-compliant AI defense systems to maintain trust and security in digital ecosystems.

</details>


### [8] [Listen to Rhythm, Choose Movements: Autoregressive Multimodal Dance Generation via Diffusion and Mamba with Decoupled Dance Dataset](https://arxiv.org/abs/2601.03323)
*Oran Duan,Yinghua Shen,Yingzhu Lv,Luyang Jie,Yaxin Liu,Qiong Wu*

Main category: cs.CR

TL;DR: LRCM是一个多模态引导的扩散框架，支持多种输入模态和自回归舞蹈动作生成，通过特征解耦和时序模块实现精细语义控制和长序列连贯性。


<details>
  <summary>Details</summary>
Motivation: 当前舞蹈动作生成方法存在语义控制粗糙和长序列连贯性差的问题，需要更精细的多模态控制和更好的时序一致性。

Method: 提出特征解耦范式分离运动捕捉数据、音频节奏和文本描述，采用音频潜在Conformer和文本潜在Cross-Conformer架构，并引入Motion Temporal Mamba Module实现平滑的自回归合成。

Result: LRCM在功能能力和量化指标上都表现出色，在多模态输入场景和长序列生成方面显示出显著潜力。

Conclusion: 该框架通过多模态引导和时序建模有效解决了舞蹈生成中的语义控制和连贯性问题，具有实际应用价值。

Abstract: Advances in generative models and sequence learning have greatly promoted research in dance motion generation, yet current methods still suffer from coarse semantic control and poor coherence in long sequences. In this work, we present Listen to Rhythm, Choose Movements (LRCM), a multimodal-guided diffusion framework supporting both diverse input modalities and autoregressive dance motion generation. We explore a feature decoupling paradigm for dance datasets and generalize it to the Motorica Dance dataset, separating motion capture data, audio rhythm, and professionally annotated global and local text descriptions. Our diffusion architecture integrates an audio-latent Conformer and a text-latent Cross-Conformer, and incorporates a Motion Temporal Mamba Module (MTMM) to enable smooth, long-duration autoregressive synthesis. Experimental results indicate that LRCM delivers strong performance in both functional capability and quantitative metrics, demonstrating notable potential in multimodal input scenarios and extended sequence generation. We will release the full codebase, dataset, and pretrained models publicly upon acceptance.

</details>


### [9] [DeepLeak: Privacy Enhancing Hardening of Model Explanations Against Membership Leakage](https://arxiv.org/abs/2601.03429)
*Firas Ben Hmida,Zain Sbeih,Philemon Hailemariam,Birhanu Eshete*

Main category: cs.CR

TL;DR: DeepLeak是一个审计和缓解后解释方法隐私风险的系统，通过更强的成员推理攻击量化隐私泄露，提供轻量级缓解策略，并分析泄露根源，在图像基准测试中显著降低隐私泄露同时保持解释效用。


<details>
  <summary>Details</summary>
Motivation: 机器学习解释性在高风险领域（如预测诊断和贷款审批）至关重要，但这些领域同时需要严格的隐私保证，导致解释性和隐私之间存在紧张关系。现有工作表明解释方法可能泄露成员信息，但实践者缺乏系统指导来选择或部署平衡透明度和隐私的解释技术。

Method: DeepLeak系统包含三个核心部分：(1) 全面的泄露分析：开发更强的解释感知成员推理攻击来量化默认配置下代表性解释方法的成员信息泄露；(2) 轻量级加固策略：引入实用的模型无关缓解措施，包括灵敏度校准噪声、归因裁剪和掩码，大幅减少成员泄露同时保持解释效用；(3) 根源分析：通过受控实验确定驱动泄露的算法特性（如归因稀疏性和灵敏度）。

Result: 在图像基准测试中评估15种解释技术，发现默认设置可泄露比先前报告多74.9%的成员信息。提出的缓解措施将泄露减少高达95%（最低46.5%），平均效用损失仅≤3.3%。

Conclusion: DeepLeak为隐私敏感机器学习中的安全解释性提供了一条系统、可复现的路径，帮助实践者在保持解释效用的同时显著降低隐私风险。

Abstract: Machine learning (ML) explainability is central to algorithmic transparency in high-stakes settings such as predictive diagnostics and loan approval. However, these same domains require rigorous privacy guaranties, creating tension between interpretability and privacy. Although prior work has shown that explanation methods can leak membership information, practitioners still lack systematic guidance on selecting or deploying explanation techniques that balance transparency with privacy.
  We present DeepLeak, a system to audit and mitigate privacy risks in post-hoc explanation methods. DeepLeak advances the state-of-the-art in three ways: (1) comprehensive leakage profiling: we develop a stronger explanation-aware membership inference attack (MIA) to quantify how much representative explanation methods leak membership information under default configurations; (2) lightweight hardening strategies: we introduce practical, model-agnostic mitigations, including sensitivity-calibrated noise, attribution clipping, and masking, that substantially reduce membership leakage while preserving explanation utility; and (3) root-cause analysis: through controlled experiments, we pinpoint algorithmic properties (e.g., attribution sparsity and sensitivity) that drive leakage.
  Evaluating 15 explanation techniques across four families on image benchmarks, DeepLeak shows that default settings can leak up to 74.9% more membership information than previously reported. Our mitigations cut leakage by up to 95% (minimum 46.5%) with only <=3.3% utility loss on average. DeepLeak offers a systematic, reproducible path to safer explainability in privacy-sensitive ML.

</details>


### [10] [Security Parameter Analysis of the LINEture Post-Quantum Digital Signature Scheme](https://arxiv.org/abs/2601.03465)
*Yevgen Kotukh,Gennady Khalimov*

Main category: cs.CR

TL;DR: 本文对基于初等阿贝尔2-群矩阵代数的LINEture后量子数字签名方案进行了全面的密码学分析，研究了三个主要参数对密码强度的影响，并提出了参数优化选择规则。


<details>
  <summary>Details</summary>
Motivation: 分析LINEture后量子数字签名方案的安全参数影响，特别是参数l的双重性质，为实际部署提供参数选择指导。

Method: 采用密码学分析方法，研究三个关键参数：字大小m（二次影响）、向量维度l和会话密钥中子矩阵数量q（线性影响），深入分析验证机制和参数间的阈值关系。

Result: 发现参数l具有双重性质：不影响猜测攻击抵抗性，但在验证机制中建立l×m位的验证屏障；建立了l < (q-1)×m的阈值关系，当低于此阈值时l成为安全关键参数；提出了l ≈ (q-1)×m的最优选择规则。

Conclusion: 参数l在LINEture方案中具有安全关键作用，提出了最优参数选择规则，并与NIST后量子密码标准进行了比较分析，提供了实际参数建议。

Abstract: This paper presents a comprehensive cryptographic analysis of the security parameters of the LINEture post-quantum digital signature scheme, which is constructed using matrix algebra over elementary abelian 2-groups. We investigate the influence of three principal parameters. First, the word size m (exhibiting quadratic impact), the second is a vector dimension l, and the third is a number of submatrices in the session key q (exhibiting linear impact) on cryptographic strength. Our analysis reveals a dualistic nature of the parameter l. According to the previous analysis, it does not affect resistance to guessing attacks. A deeper examination of the verification mechanism demonstrates that l establishes a kind of verification barrier of l times m bits. We establish the threshold relationship l less q minus 1 times m, below which parameter l becomes security-critical. The optimal selection rule l near q minus 1 times m is proposed for maximum cryptographic efficiency. Comparative analysis with NIST PQC standards and practical parameter recommendations are provided.

</details>


### [11] [Full-Stack Knowledge Graph and LLM Framework for Post-Quantum Cyber Readiness](https://arxiv.org/abs/2601.03504)
*Rasmus Erlemann,Charles Colyer Morris,Sanjyot Sathe*

Main category: cs.CR

TL;DR: 提出基于知识图谱的企业级后量子密码就绪度评估框架，通过图模型量化密码资产暴露风险，支持规模化迁移优先级决策。


<details>
  <summary>Details</summary>
Motivation: 大规模量子计算威胁现有公钥密码体系，企业缺乏可扩展的定量框架来评估后量子密码就绪度、测量密码暴露风险并确定迁移优先级。

Method: 构建异构知识图谱建模企业密码资产、依赖关系和漏洞；使用图论风险函数量化后量子暴露风险；通过沙普利值分解跨密码域归因风险；集成大语言模型与人在回路验证支持可扩展性和数据质量。

Result: 框架产生可解释、标准化的就绪度指标，支持持续监控、比较分析和修复优先级排序，为企业后量子迁移提供决策支持。

Conclusion: 知识图谱方法为复杂企业基础设施提供了可扩展、定量的后量子密码就绪度评估框架，通过依赖驱动的风险传播建模和可解释指标，解决了组织在后量子标准制定期间面临的迁移优先级挑战。

Abstract: The emergence of large-scale quantum computing threatens widely deployed public-key cryptographic systems, creating an urgent need for enterprise-level methods to assess post-quantum (PQ) readiness. While PQ standards are under development, organizations lack scalable and quantitative frameworks for measuring cryptographic exposure and prioritizing migration across complex infrastructures. This paper presents a knowledge graph based framework that models enterprise cryptographic assets, dependencies, and vulnerabilities to compute a unified PQ readiness score. Infrastructure components, cryptographic primitives, certificates, and services are represented as a heterogeneous graph, enabling explicit modeling of dependency-driven risk propagation. PQ exposure is quantified using graph-theoretic risk functionals and attributed across cryptographic domains via Shapley value decomposition. To support scalability and data quality, the framework integrates large language models with human-in-the-loop validation for asset classification and risk attribution. The resulting approach produces explainable, normalized readiness metrics that support continuous monitoring, comparative analysis, and remediation prioritization.

</details>


### [12] [A Critical Analysis of the Medibank Health Data Breach and Differential Privacy Solutions](https://arxiv.org/abs/2601.03508)
*Zhuohan Cui,Qianqian Lang,Zikun Song*

Main category: cs.CR

TL;DR: 提出基于熵感知差分隐私的医疗数据保护框架，针对Medibank数据泄露问题，通过自适应噪声注入在降低90.3%重识别风险的同时保持分析效用损失低于24%


<details>
  <summary>Details</summary>
Motivation: 针对2022年Medibank健康保险数据泄露事件（暴露970万人敏感医疗记录），该事件暴露了未加密存储、集中访问和缺乏隐私保护分析等漏洞，需要开发有效的医疗数据保护解决方案

Method: 提出熵感知差分隐私框架，整合拉普拉斯和高斯机制与自适应预算分配，采用TLS加密数据库访问、字段级机制选择和平滑敏感性模型，使用合成Medibank数据集（N=131,000）进行实验验证

Result: 实验结果显示重识别概率降低90.3%，分析效用损失保持在24%以下，框架符合GDPR第32条和澳大利亚隐私原则11.1，实现了隐私保护与实用性的平衡

Conclusion: 该工作通过结合严格的隐私保证与实用可用性，为医疗数据保护提供了可扩展且技术可行的解决方案，为构建弹性、可信且符合法规的医疗分析系统提供了路径

Abstract: This paper critically examines the 2022 Medibank health insurance data breach, which exposed sensitive medical records of 9.7 million individuals due to unencrypted storage, centralized access, and the absence of privacy-preserving analytics. To address these vulnerabilities, we propose an entropy-aware differential privacy (DP) framework that integrates Laplace and Gaussian mechanisms with adaptive budget allocation. The design incorporates TLS-encrypted database access, field-level mechanism selection, and smooth sensitivity models to mitigate re-identification risks. Experimental validation was conducted using synthetic Medibank datasets (N = 131,000) with entropy-calibrated DP mechanisms, where high-entropy attributes received stronger noise injection. Results demonstrate a 90.3% reduction in re-identification probability while maintaining analytical utility loss below 24%. The framework further aligns with GDPR Article 32 and Australian Privacy Principle 11.1, ensuring regulatory compliance. By combining rigorous privacy guarantees with practical usability, this work contributes a scalable and technically feasible solution for healthcare data protection, offering a pathway toward resilient, trustworthy, and regulation-ready medical analytics.

</details>


### [13] [Deontic Knowledge Graphs for Privacy Compliance in Multimodal Disaster Data Sharing](https://arxiv.org/abs/2601.03587)
*Kelvin Uzoma Echenim,Karuna Pande Joshi*

Main category: cs.CR

TL;DR: 提出基於義務知識圖譜的災害響應隱私合規框架，整合災害管理知識圖譜與政策知識圖譜，支持允許、阻止、允許但轉換三種決策，並驗證轉換後合規性。


<details>
  <summary>Details</summary>
Motivation: 災害響應需要共享異質性資料（表格記錄、無人機影像等），但面臨多重隱私法規要求。現有系統常簡化為二元存取控制，在時間緊迫的工作流程中過於僵化。

Method: 建立義務知識圖譜框架，整合災害管理知識圖譜(DKG)與政策知識圖譜(PKG)，後者源自IoT-Reg和FEMA/DHS隱私法規。決策函數支持三種結果：允許、阻止、允許但轉換，轉換後透過溯源鏈接驗證合規性。

Result: 在包含510萬三元組的DKG和31.6萬張影像上評估，顯示決策完全正確，每次決策延遲低於1秒，在單圖譜和聯邦工作負載下均具互動式查詢性能。

Conclusion: 義務知識圖譜框架能有效解決災害響應中的隱私合規挑戰，提供細粒度決策支持，並在實際規模資料上展現高效能。

Abstract: Disaster response requires sharing heterogeneous artifacts, from tabular assistance records to UAS imagery, under overlapping privacy mandates. Operational systems often reduce compliance to binary access control, which is brittle in time-critical workflows. We present a novel deontic knowledge graph-based framework that integrates a Disaster Management Knowledge Graph (DKG) with a Policy Knowledge Graph (PKG) derived from IoT-Reg and FEMA/DHS privacy drivers. Our release decision function supports three outcomes: Allow, Block, and Allow-with-Transform. The latter binds obligations to transforms and verifies post-transform compliance via provenance-linked derived artifacts; blocked requests are logged as semantic privacy incidents. Evaluation on a 5.1M-triple DKG with 316K images shows exact-match decision correctness, sub-second per-decision latency, and interactive query performance across both single-graph and federated workloads.

</details>


### [14] [Jailbreaking LLMs & VLMs: Mechanisms, Evaluation, and Unified Defense](https://arxiv.org/abs/2601.03594)
*Zejian Chen,Chaozhuo Li,Chao Li,Xi Zhang,Litian Zhang,Yiming He*

Main category: cs.CR

TL;DR: 这篇论文系统综述了大语言模型和视觉语言模型的越狱攻击与防御方法，提出了三维分析框架，并总结了统一防御原则。


<details>
  <summary>Details</summary>
Motivation: 越狱漏洞源于结构性因素如训练数据不完整、语言歧义和生成不确定性，现有研究缺乏对文本到多模态场景的全面覆盖，需要统一的分析框架和防御原则。

Method: 提出三维调查框架：攻击维度（模板/编码、上下文学习操纵、强化/对抗学习、LLM辅助、微调攻击等）、防御维度（提示级混淆、输出评估、模型级对齐/微调）、评估维度（攻击成功率、毒性分数、查询/时间成本等）。

Result: 总结了从文本到多模态的完整攻击防御谱系，提出了统一的防御原则：感知层的变体一致性和梯度敏感性检测、生成层的安全感知解码和输出审查、参数层的对抗增强偏好对齐。

Conclusion: 越狱攻击与防御需要系统化研究，未来方向包括自动化红队测试、跨模态协同防御和标准化评估，为构建更安全的AI系统提供指导。

Abstract: This paper provides a systematic survey of jailbreak attacks and defenses on Large Language Models (LLMs) and Vision-Language Models (VLMs), emphasizing that jailbreak vulnerabilities stem from structural factors such as incomplete training data, linguistic ambiguity, and generative uncertainty. It further differentiates between hallucinations and jailbreaks in terms of intent and triggering mechanisms. We propose a three-dimensional survey framework: (1) Attack dimension-including template/encoding-based, in-context learning manipulation, reinforcement/adversarial learning, LLM-assisted and fine-tuned attacks, as well as prompt- and image-level perturbations and agent-based transfer in VLMs; (2) Defense dimension-encompassing prompt-level obfuscation, output evaluation, and model-level alignment or fine-tuning; and (3) Evaluation dimension-covering metrics such as Attack Success Rate (ASR), toxicity score, query/time cost, and multimodal Clean Accuracy and Attribute Success Rate. Compared with prior works, this survey spans the full spectrum from text-only to multimodal settings, consolidating shared mechanisms and proposing unified defense principles: variant-consistency and gradient-sensitivity detection at the perception layer, safety-aware decoding and output review at the generation layer, and adversarially augmented preference alignment at the parameter layer. Additionally, we summarize existing multimodal safety benchmarks and discuss future directions, including automated red teaming, cross-modal collaborative defense, and standardized evaluation.

</details>


### [15] [Detection and Prevention of Process Disruption Attacks in the Electrical Power Systems using MMS Traffic: An EPIC Case](https://arxiv.org/abs/2601.03690)
*Praneeta K Maganti,Daisuke Mashima,Rajib Ranjan Maiti*

Main category: cs.CR

TL;DR: 提出用于IEC61850智能变电站的自动化攻击检测与防御框架，针对通过MMS协议进行的网络攻击，能准确识别恶意流量并增强电网网络弹性。


<details>
  <summary>Details</summary>
Motivation: 智能电网因依赖互联通信网络而面临日益复杂的网络威胁，如乌克兰电网攻击事件。IEC61850变电站中的MMS协议可能被攻击者利用进行侦察、未授权状态读取和恶意命令注入，破坏电网运行。

Method: 提出全自动攻击检测与防御框架，分析MMS协议并提取关键字段值对，在正常SCADA操作和攻击条件下进行对比。使用七个数据集验证，包括良性操作场景和多种攻击实例（基于IEC61850Bean和libiec61850库的攻击）。

Result: 框架能准确识别携带攻击签名的MMS数据包，特别是针对EPIC测试平台智能家居区域IED和PLC的断路器状态攻击。结果证明框架能精确检测恶意MMS流量，增强IEC61850智能电网环境的网络弹性。

Conclusion: 提出的自动化框架能有效应对IEC61850智能变电站中的远程网络攻击，通过分析MMS协议特征实现精准攻击检测，为智能电网提供重要网络安全保障。

Abstract: Smart grids are increasingly exposed to sophisticated cyber threats due to their reliance on interconnected communication networks, as demonstrated by real world incidents such as the cyberattacks on the Ukrainian power grid. In IEC61850 based smart substations, the Manufacturing Message Specification protocol operates over TCP to facilitate communication between SCADA systems and field devices such as Intelligent Electronic Devices and Programmable Logic Controllers. Although MMS enables efficient monitoring and control, it can be exploited by adversaries to generate legitimate looking packets for reconnaissance, unauthorized state reading, and malicious command injection, thereby disrupting grid operations. In this work, we propose a fully automated attack detection and prevention framework for IEC61850 compliant smart substations to counter remote cyberattacks that manipulate process states through compromised PLCs and IEDs. A detailed analysis of the MMS protocol is presented, and critical MMS field value pairs are extracted during both normal SCADA operation and active attack conditions. The proposed framework is validated using seven datasets comprising benign operational scenarios and multiple attack instances, including IEC61850Bean based attacks and script driven attacks leveraging the libiec61850 library. Our approach accurately identifies attack signature carrying MMS packets that attempt to disrupt circuit breaker status, specifically targeting the smart home zone IED and PLC of the EPIC testbed. The results demonstrate the effectiveness of the proposed framework in precisely detecting malicious MMS traffic and enhancing the cyber resilience of IEC61850 based smart grid environments.

</details>


### [16] [Human Challenge Oracle: Designing AI-Resistant, Identity-Bound, Time-Limited Tasks for Sybil-Resistant Consensus](https://arxiv.org/abs/2601.03923)
*Homayoun Maleki,Nekane Sainz,Jon Legarda*

Main category: cs.CR

TL;DR: HCO是一种新型安全原语，通过实时人类认知挑战来持续验证身份，对抗Sybil攻击，使维持多个活跃身份的成本随时间窗口线性增长。


<details>
  <summary>Details</summary>
Motivation: 现有防御机制（如CAPTCHA和一次性人格证明）主要针对身份创建，对长期、大规模的Sybil参与保护有限，特别是随着自动化求解器和AI系统的不断改进。

Method: 提出人类挑战预言机（HCO），通过发布与个体身份加密绑定的短期、有时间限制的挑战，要求实时解决。核心思想是利用人类认知努力（如感知、注意力和交互推理）作为难以并行化或跨身份分摊的稀缺资源。

Result: 形式化了HCO的设计目标和安全属性，证明在明确且温和的假设下，维持s个活跃身份的成本在每个时间窗口内随s线性增长。提出了可接受挑战的抽象类别和基于浏览器的具体实现，初步实证研究表明这些挑战人类可在几秒内轻松解决，但在严格时间约束下对当代自动化系统仍然困难。

Conclusion: HCO为持续、速率限制的人类验证提供了新的安全原语，能够有效对抗Sybil攻击，利用人类实时认知努力作为稀缺资源来限制攻击者维持大量虚假身份的能力。

Abstract: Sybil attacks remain a fundamental obstacle in open online systems, where adversaries can cheaply create and sustain large numbers of fake identities. Existing defenses, including CAPTCHAs and one-time proof-of-personhood mechanisms, primarily address identity creation and provide limited protection against long-term, large-scale Sybil participation, especially as automated solvers and AI systems continue to improve.
  We introduce the Human Challenge Oracle (HCO), a new security primitive for continuous, rate-limited human verification. HCO issues short, time-bound challenges that are cryptographically bound to individual identities and must be solved in real time. The core insight underlying HCO is that real-time human cognitive effort, such as perception, attention, and interactive reasoning, constitutes a scarce resource that is inherently difficult to parallelize or amortize across identities.
  We formalize the design goals and security properties of HCO and show that, under explicit and mild assumptions, sustaining s active identities incurs a cost that grows linearly with s in every time window. We further describe abstract classes of admissible challenges and concrete browser-based instantiations, and present an initial empirical study illustrating that these challenges are easily solvable by humans within seconds while remaining difficult for contemporary automated systems under strict time constraints.

</details>


### [17] [SoK: Privacy Risks and Mitigations in Retrieval-Augmented Generation Systems](https://arxiv.org/abs/2601.03979)
*Andreea-Elena Bodea,Stephen Meisenbacher,Alexandra Klymenko,Florian Matthes*

Main category: cs.CR

TL;DR: 本文首次系统化分析了RAG系统中的隐私风险，提出了风险分类、缓解技术和评估策略，并提供了RAG隐私风险分类法和过程图。


<details>
  <summary>Details</summary>
Motivation: 随着RAG技术的广泛应用，结合领域知识库与LLMs引发了数据隐私担忧，特别是处理敏感信息时的风险。目前缺乏对RAG隐私风险的系统性研究，需要统一理解风险、测量方法和缓解措施。

Method: 通过系统文献综述方法，分析RAG隐私相关研究，将发现系统化为隐私风险分类、缓解技术和评估策略，并创建RAG隐私风险分类法和过程图两个主要成果。

Result: 建立了首个RAG隐私风险系统化框架，包括全面的风险分类、缓解技术分析和评估策略，揭示了RAG隐私缓解的重要考虑因素和当前缓解措施的成熟度评估。

Conclusion: 本文填补了RAG隐私研究的空白，提供了系统化的风险理解和缓解框架，为未来RAG隐私保护研究奠定了基础，并指出了当前缓解措施的成熟度不足。

Abstract: The continued promise of Large Language Models (LLMs), particularly in their natural language understanding and generation capabilities, has driven a rapidly increasing interest in identifying and developing LLM use cases. In an effort to complement the ingrained "knowledge" of LLMs, Retrieval-Augmented Generation (RAG) techniques have become widely popular. At its core, RAG involves the coupling of LLMs with domain-specific knowledge bases, whereby the generation of a response to a user question is augmented with contextual and up-to-date information. The proliferation of RAG has sparked concerns about data privacy, particularly with the inherent risks that arise when leveraging databases with potentially sensitive information. Numerous recent works have explored various aspects of privacy risks in RAG systems, from adversarial attacks to proposed mitigations. With the goal of surveying and unifying these works, we ask one simple question: What are the privacy risks in RAG, and how can they be measured and mitigated? To answer this question, we conduct a systematic literature review of RAG works addressing privacy, and we systematize our findings into a comprehensive set of privacy risks, mitigation techniques, and evaluation strategies. We supplement these findings with two primary artifacts: a Taxonomy of RAG Privacy Risks and a RAG Privacy Process Diagram. Our work contributes to the study of privacy in RAG not only by conducting the first systematization of risks and mitigations, but also by uncovering important considerations when mitigating privacy risks in RAG systems and assessing the current maturity of proposed mitigations.

</details>


### [18] [HoneyTrap: Deceiving Large Language Model Attackers to Honeypot Traps with Resilient Multi-Agent Defense](https://arxiv.org/abs/2601.04034)
*Siyuan Li,Xi Lin,Jun Wu,Zehao Liu,Haoyu Li,Tianjie Ju,Xiang Chen,Jianhua Li*

Main category: cs.CR

TL;DR: HoneyTrap是一个利用协作防御者对抗越狱攻击的欺骗性LLM防御框架，通过四个专门的安全代理协同工作，在多轮渐进式越狱攻击中显著降低攻击成功率并消耗攻击者资源。


<details>
  <summary>Details</summary>
Motivation: 现有反应式防御方法难以应对快速演化的多轮越狱攻击，攻击者通过持续深化攻击策略来利用漏洞，需要更主动的防御机制来应对这一关键挑战。

Method: 提出HoneyTrap欺骗性LLM防御框架，集成四个防御代理：威胁拦截器、误导控制器、取证追踪器和系统协调器，每个代理执行专门的安全角色并协作完成欺骗性防御。同时引入MTJ-Pro多轮渐进式越狱数据集和两个新评估指标（误导成功率和攻击资源消耗）。

Result: 在GPT-4、GPT-3.5-turbo、Gemini-1.5-pro和LLaMa-3.1上的实验显示，HoneyTrap相比最先进基线平均降低68.77%的攻击成功率。即使在强化条件的自适应攻击者设置中，仍能保持韧性，通过欺骗性互动延长交互时间，显著增加成功利用所需的时间和计算成本。

Conclusion: HoneyTrap通过欺骗性防御策略有效对抗多轮越狱攻击，不仅降低攻击成功率，还能战略性地消耗攻击者资源而不影响良性查询，在误导成功率和攻击资源消耗指标上分别提升118.11%和149.16%，为LLM安全提供了创新的主动防御方案。

Abstract: Jailbreak attacks pose significant threats to large language models (LLMs), enabling attackers to bypass safeguards. However, existing reactive defense approaches struggle to keep up with the rapidly evolving multi-turn jailbreaks, where attackers continuously deepen their attacks to exploit vulnerabilities. To address this critical challenge, we propose HoneyTrap, a novel deceptive LLM defense framework leveraging collaborative defenders to counter jailbreak attacks. It integrates four defensive agents, Threat Interceptor, Misdirection Controller, Forensic Tracker, and System Harmonizer, each performing a specialized security role and collaborating to complete a deceptive defense. To ensure a comprehensive evaluation, we introduce MTJ-Pro, a challenging multi-turn progressive jailbreak dataset that combines seven advanced jailbreak strategies designed to gradually deepen attack strategies across multi-turn attacks. Besides, we present two novel metrics: Mislead Success Rate (MSR) and Attack Resource Consumption (ARC), which provide more nuanced assessments of deceptive defense beyond conventional measures. Experimental results on GPT-4, GPT-3.5-turbo, Gemini-1.5-pro, and LLaMa-3.1 demonstrate that HoneyTrap achieves an average reduction of 68.77% in attack success rates compared to state-of-the-art baselines. Notably, even in a dedicated adaptive attacker setting with intensified conditions, HoneyTrap remains resilient, leveraging deceptive engagement to prolong interactions, significantly increasing the time and computational costs required for successful exploitation. Unlike simple rejection, HoneyTrap strategically wastes attacker resources without impacting benign queries, improving MSR and ARC by 118.11% and 149.16%, respectively.

</details>
