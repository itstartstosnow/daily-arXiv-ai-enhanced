{"id": "2511.00111", "categories": ["cs.CR"], "pdf": "https://arxiv.org/pdf/2511.00111", "abs": "https://arxiv.org/abs/2511.00111", "authors": ["Abel C. H. Chen"], "title": "A Comparative Study of Hybrid Post-Quantum Cryptographic X.509 Certificate Schemes", "comment": "in Chinese language", "summary": "As quantum computing hardware continues to advance, the integration of such\ntechnology with quantum algorithms is anticipated to enable the decryption of\nciphertexts produced by RSA and Elliptic Curve Cryptography (ECC) within\npolynomial time. In response to this emerging threat, the U.S. National\nInstitute of Standards and Technology (NIST) finalized a series of Post-Quantum\nCryptography (PQC) standards in August 2024 and outlined a roadmap for PQC\nmigration. Consequently, the design of X.509 certificates that adhere to PQC\nstandards has become a crucial focus in the development of certificate\nmanagement systems. To further strengthen security and facilitate a smooth\nmigration process, several hybrid certificate schemes have been proposed\ninternationally based on the X.509 certificate format, including the composite\nscheme, the catalyst scheme, and the chameleon scheme. This study presents a\ncomprehensive analysis and comparison of these hybrid certificate schemes from\nmultiple perspectives (e.g., certificate size, computational efficiency, and\nmigration feasibility) to assess their suitability for various applications and\nservices."}
{"id": "2511.00118", "categories": ["cs.CR", "cs.CL"], "pdf": "https://arxiv.org/pdf/2511.00118", "abs": "https://arxiv.org/abs/2511.00118", "authors": ["Stanislav Selitskiy"], "title": "Real-time and Zero-footprint Bag of Synthetic Syllables Algorithm for E-mail Spam Detection Using Subject Line and Short Text Fields", "comment": null, "summary": "Contemporary e-mail services have high availability expectations from the\ncustomers and are resource-strained because of the high-volume throughput and\nspam attacks. Deep Machine Learning architectures, which are resource hungry\nand require off-line processing due to the long processing times, are not\nacceptable at the front line filters. On the other hand, the bulk of the\nincoming spam is not sophisticated enough to bypass even the simplest\nalgorithms. While the small fraction of the intelligent, highly mutable spam\ncan be detected only by the deep architectures, the stress on them can be\nunloaded by the simple near real-time and near zero-footprint algorithms such\nas the Bag of Synthetic Syllables algorithm applied to the short texts of the\ne-mail subject lines and other short text fields. The proposed algorithm\ncreates a circa 200 sparse dimensional hash or vector for each e-mail subject\nline that can be compared for the cosine or euclidean proximity distance to\nfind similarities to the known spammy subjects. The algorithm does not require\nany persistent storage, dictionaries, additional hardware upgrades or software\npackages. The performance of the algorithm is presented on the one day of the\nreal SMTP traffic."}
{"id": "2511.00140", "categories": ["cs.CR", "cs.OS", "cs.RO", "cs.SY", "eess.SY"], "pdf": "https://arxiv.org/pdf/2511.00140", "abs": "https://arxiv.org/abs/2511.00140", "authors": ["Tahmid Hasan Sakib", "Yago Romano Martinez", "Carter Brady", "Syed Rafay Hasan", "Terry N. Guo"], "title": "Supply Chain Exploitation of Secure ROS 2 Systems: A Proof-of-Concept on Autonomous Platform Compromise via Keystore Exfiltration", "comment": "Author-accepted version (preprint). Presented at IEEE MILCOM 2025\n  Workshops, WS07: 2nd Workshop on Security, Resilience, and Robustness of\n  Systems and Software (SRRSS), Los Angeles, Oct 2025. 6 pages. Primary: cs.CR;\n  cross-lists: cs.RO, cs.OS. Program:\n  https://milcom2025.ieee-milcom.org/workshop/ws07-2nd-workshop-security-resilient-and-robustness-systems-and-software/program", "summary": "This paper presents a proof-of-concept supply chain attack against the Secure\nROS 2 (SROS 2) framework, demonstrated on a Quanser QCar2 autonomous vehicle\nplatform. A Trojan-infected Debian package modifies core ROS 2 security\ncommands to exfiltrate newly generated keystore credentials via DNS in\nbase64-encoded chunks to an attacker-controlled nameserver. Possession of these\ncredentials enables the attacker to rejoin the SROS 2 network as an\nauthenticated participant and publish spoofed control or perception messages\nwithout triggering authentication failures. We evaluate this capability on a\nsecure ROS 2 Humble testbed configured for a four-stop-sign navigation routine\nusing an Intel RealSense camera for perception. Experimental results show that\ncontrol-topic injections can cause forced braking, sustained high-speed\nacceleration, and continuous turning loops, while perception-topic spoofing can\ninduce phantom stop signs or suppress real detections. The attack generalizes\nto any data distribution service (DDS)-based robotic system using SROS 2,\nhighlighting the need for both supply chain integrity controls and runtime\nsemantic validation to safeguard autonomous systems against insider and\nimpersonation threats."}
{"id": "2511.00237", "categories": ["cs.CR"], "pdf": "https://arxiv.org/pdf/2511.00237", "abs": "https://arxiv.org/abs/2511.00237", "authors": ["Oisin O Sullivan", "Colin Flanagan", "Eoin O Connell"], "title": "Identifying Linux Kernel Instability Due to Poor RCU Synchronization", "comment": "Conference: 36th Irish Signals and Systems Conference (ISSC) 2025 6\n  pages; 4 Figures", "summary": "Read-Copy-Update (RCU) is widely used in the Linux kernel to manage\nconcurrent access to shared data structures.However, improper synchronization\nwhen removing RCU protected hash table entries can lead to stale pointers,\ninconsistent lookups, and critical use after free (UAF) vulnerabilities. This\npaper investigates a driver-level synchronization issue arising from the\nomission of explicit synchronize_rcu() calls during hash table updates, using a\ndiscovered weakness in the Intel ICE network drivers Virtual Function (VF)\nmanagement. Previous kernel vulnerabilities, such as a bug in the Reliable\nDatagram Sockets (RDS) subsystem, show how improper RCU synchronization can\ndirectly cause kernel crashes. Experimental results demonstrate that removing\nVF entries without proper synchronization leaves transient stale entries,\ndelays memory reclamation, and results in significant memory fragmentation\nunder rapid insert/delete workloads. RCU hash tables are widely deployed in\nLinux kernel subsystems such as networking, virtualization, and file systems;\nimproper synchronization can cause memory fragmentation, kernel instability,\nand out-of-memory (OOM) conditions. Mitigations are proposed, recommending\nexplicit insertion of synchronize_rcu() calls to ensure timely and safe memory\nreclamation. These findings reinforce established best practices for RCU\nsynchronization, highlighting their importance for maintaining kernel stability\nand memory safety.\n  Keywords: RCU, kernel synchronization, hash tables, ICE driver, memory\nfragmentation, use-after-free"}
{"id": "2511.00249", "categories": ["cs.CR"], "pdf": "https://arxiv.org/pdf/2511.00249", "abs": "https://arxiv.org/abs/2511.00249", "authors": ["Sushil Khairnar"], "title": "Application of Blockchain Frameworks for Decentralized Identity and Access Management of IoT Devices", "comment": null, "summary": "The growth in IoT devices means an ongoing risk of data vulnerability. The\ntransition from centralized ecosystems to decentralized ecosystems is of\nparamount importance due to security, privacy, and data use concerns. Since the\nmajority of IoT devices will be used by consumers in peer-to-peer applications,\na centralized approach raises many issues of trust related to privacy, control,\nand censorship. Identity and access management lies at the heart of any\nuser-facing system. Blockchain technologies can be leveraged to augment user\nauthority, transparency, and decentralization. This study proposes a\ndecentralized identity management framework for IoT environments using\nHyperledger Fabric and Decentralized Identifiers (DIDs). The system was\nsimulated using Node-RED to model IoT data streams, and key functionalities\nincluding device onboarding, authentication, and secure asset querying were\nsuccessfully implemented. Results demonstrated improved data integrity,\ntransparency, and user control, with reduced reliance on centralized\nauthorities. These findings validate the practicality of blockchain-based\nidentity management in enhancing the security and trustworthiness of IoT\ninfrastructures."}
{"id": "2511.00336", "categories": ["cs.CR", "cs.DC", "cs.LG"], "pdf": "https://arxiv.org/pdf/2511.00336", "abs": "https://arxiv.org/abs/2511.00336", "authors": ["Siva Sai", "Manish Prasad", "Animesh Bhargava", "Vinay Chamola", "Rajkumar Buyya"], "title": "Split Learning-Enabled Framework for Secure and Light-weight Internet of Medical Things Systems", "comment": "11 pages, 5 figures, Under review in an IEEE Transactions journal", "summary": "The rapid growth of Internet of Medical Things (IoMT) devices has resulted in\nsignificant security risks, particularly the risk of malware attacks on\nresource-constrained devices. Conventional deep learning methods are\nimpractical due to resource limitations, while Federated Learning (FL) suffers\nfrom high communication overhead and vulnerability to non-IID (heterogeneous)\ndata. In this paper, we propose a split learning (SL) based framework for IoT\nmalware detection through image-based classification. By dividing the neural\nnetwork training between the clients and an edge server, the framework reduces\ncomputational burden on resource-constrained clients while ensuring data\nprivacy. We formulate a joint optimization problem that balances computation\ncost and communication efficiency by using a game-theoretic approach for\nattaining better training performance. Experimental evaluations show that the\nproposed framework outperforms popular FL methods in terms of accuracy\n(+6.35%), F1-score (+5.03%), high convergence speed (+14.96%), and less\nresource consumption (33.83%). These results establish the potential of SL as a\nscalable and secure paradigm for next-generation IoT security."}
{"id": "2511.00342", "categories": ["cs.CR", "cs.AI", "cs.LG", "cs.PF", "68T01", "I.2; E.0"], "pdf": "https://arxiv.org/pdf/2511.00342", "abs": "https://arxiv.org/abs/2511.00342", "authors": ["Hendrio Braganca", "Diego Kreutz", "Vanderson Rocha", "Joner Assolin", "and Eduardo Feitosa"], "title": "MH-1M: A 1.34 Million-Sample Comprehensive Multi-Feature Android Malware Dataset for Machine Learning, Deep Learning, Large Language Models, and Threat Intelligence Research", "comment": "17 pages, 7 figures, 13 tables, submitted to the Scientific Data\n  journal published by Nature Research", "summary": "We present MH-1M, one of the most comprehensive and up-to-date datasets for\nadvanced Android malware research. The dataset comprises 1,340,515\napplications, encompassing a wide range of features and extensive metadata. To\nensure accurate malware classification, we employ the VirusTotal API,\nintegrating multiple detection engines for comprehensive and reliable\nassessment. Our GitHub, Figshare, and Harvard Dataverse repositories provide\nopen access to the processed dataset and its extensive supplementary metadata,\ntotaling more than 400 GB of data and including the outputs of the feature\nextraction pipeline as well as the corresponding VirusTotal reports. Our\nfindings underscore the MH-1M dataset's invaluable role in understanding the\nevolving landscape of malware."}
{"id": "2511.00346", "categories": ["cs.CR", "cs.AI", "cs.LG", "68T01", "I.2"], "pdf": "https://arxiv.org/pdf/2511.00346", "abs": "https://arxiv.org/abs/2511.00346", "authors": ["Kayua Oleques Paim", "Rodrigo Brandao Mansilha", "Diego Kreutz", "Muriel Figueredo Franco", "Weverton Cordeiro"], "title": "Exploiting Latent Space Discontinuities for Building Universal LLM Jailbreaks and Data Extraction Attacks", "comment": "10 pages, 5 figures, 4 tables, Published at the Brazilian Symposium\n  on Cybersecurity (SBSeg 2025)", "summary": "The rapid proliferation of Large Language Models (LLMs) has raised\nsignificant concerns about their security against adversarial attacks. In this\nwork, we propose a novel approach to crafting universal jailbreaks and data\nextraction attacks by exploiting latent space discontinuities, an architectural\nvulnerability related to the sparsity of training data. Unlike previous\nmethods, our technique generalizes across various models and interfaces,\nproving highly effective in seven state-of-the-art LLMs and one image\ngeneration model. Initial results indicate that when these discontinuities are\nexploited, they can consistently and profoundly compromise model behavior, even\nin the presence of layered defenses. The findings suggest that this strategy\nhas substantial potential as a systemic attack vector."}
{"id": "2511.00348", "categories": ["cs.CR", "eess.AS"], "pdf": "https://arxiv.org/pdf/2511.00348", "abs": "https://arxiv.org/abs/2511.00348", "authors": ["Michael P. Hasselbeck"], "title": "Ultralow-power standoff acoustic leak detection", "comment": "5 pages, 4 figures", "summary": "An automated, standoff acoustic leak detection scheme has been designed,\nbuilt, and tested. It merges the principles of glass breakage and smoke\ndetection to alert for the presence of leaks emanating from pressurized\nplumbing. A simulated water leak flowing at 0.15 l/min has been reliably\ndetected at a standoff distance of more than 10 m. The device is also effective\nat identifying the presence of leaks located behind surfaces such as walls,\ndoors, floors, and ceilings. The anticipated application is as an autonomous,\nbattery-powered, remote wireless node. All signal processing and analysis takes\nplace on the edge with no need to stream audio data to the cloud. Sensor status\nis conveyed on-demand with only a few bytes of information, requiring minimal\nbandwidth. Power consumption is the range of 20--200 micro-Watts, depending on\nthe amount of environmental noise and desired sensor latency. To attain optimum\nsensitivity and reliability, the hardware operates at acoustic frequencies well\nabove the range of human conversations, making eavesdropping impossible.\nDevelopment has been done with water escaping from pressurized plumbing, but\nthe sensor concept can be used effectively to detect gas leaks."}
{"id": "2511.00360", "categories": ["cs.CR", "cs.AI", "cs.LG"], "pdf": "https://arxiv.org/pdf/2511.00360", "abs": "https://arxiv.org/abs/2511.00360", "authors": ["Adrita Rahman Tory", "Khondokar Fida Hasan", "Md Saifur Rahman", "Nickolaos Koroniotis", "Mohammad Ali Moni"], "title": "Mind the Gap: Missing Cyber Threat Coverage in NIDS Datasets for the Energy Sector", "comment": "13 pages", "summary": "Network Intrusion Detection Systems (NIDS) developed us- ing publicly\navailable datasets predominantly focus on enterprise environ- ments, raising\nconcerns about their effectiveness for converged Informa- tion Technology (IT)\nand Operational Technology (OT) in energy infras- tructures. This study\nevaluates the representativeness of five widely used datasets: CIC-IDS2017,\nSWaT, WADI, Sherlock, and CIC-Modbus2023 against network-detectable MITRE\nATT&CK techniques extracted from documented energy sector incidents. Using a\nstructured five-step analyt- ical approach, this article successfully developed\nand performed a gap analysis that identified 94 network observable techniques\nfrom an initial pool of 274 ATT&CK techniques. Sherlock dataset exhibited the\nhigh- est mean coverage (0.56), followed closely by CIC-IDS2017 (0.55), while\nSWaT and WADI recorded the lowest scores (0.38). Combining CIC- IDS2017,\nSherlock, and CIC-Modbus2023 achieved an aggregate coverage of 92%,\nhighlighting their complementary strengths. The analysis identi- fies critical\ngaps, particularly in lateral movement and industrial protocol manipulation,\nproviding a clear pathway for dataset enhancement and more robust NIDS\nevaluation in hybrid IT/OT energy environments."}
{"id": "2511.00361", "categories": ["cs.CR", "cs.AI", "cs.LG", "I.2"], "pdf": "https://arxiv.org/pdf/2511.00361", "abs": "https://arxiv.org/abs/2511.00361", "authors": ["Kayua Oleques Paim", "Angelo Gaspar Diniz Nogueira", "Diego Kreutz", "Weverton Cordeiro", "Rodrigo Brandao Mansilha"], "title": "MalDataGen: A Modular Framework for Synthetic Tabular Data Generation in Malware Detection", "comment": "10 pages, 6 figures, 2 tables. Published at the Brazilian Symposium\n  on Cybersecurity (SBSeg 2025)", "summary": "High-quality data scarcity hinders malware detection, limiting ML\nperformance. We introduce MalDataGen, an open-source modular framework for\ngenerating high-fidelity synthetic tabular data using modular deep learning\nmodels (e.g., WGAN-GP, VQ-VAE). Evaluated via dual validation (TR-TS/TS-TR),\nseven classifiers, and utility metrics, MalDataGen outperforms benchmarks like\nSDV while preserving data utility. Its flexible design enables seamless\nintegration into detection pipelines, offering a practical solution for\ncybersecurity applications."}
{"id": "2511.00363", "categories": ["cs.CR", "cs.NI", "cs.OS"], "pdf": "https://arxiv.org/pdf/2511.00363", "abs": "https://arxiv.org/abs/2511.00363", "authors": ["Yicheng Liu", "Rafail Ostrovsky", "Scott Shenker", "Sam Kumar"], "title": "Fast Networks for High-Performance Distributed Trust", "comment": "10 pages, 2 figures", "summary": "Organizations increasingly need to collaborate by performing a computation on\ntheir combined dataset, while keeping their data hidden from each other.\nCertain kinds of collaboration, such as collaborative data analytics and AI,\nrequire a level of performance beyond what current cryptographic techniques for\ndistributed trust can provide. This is because the organizations run software\nin different trust domains, which can require them to communicate over WANs or\nthe public Internet. In this paper, we explore how to instead run such\napplications using fast datacenter-type LANs. We show that, by carefully\nredesigning distributed trust frameworks for LANs, we can achieve up to\norder-of-magnitude better performance than na\\\"ively using a LAN. Then, we\ndevelop deployment models for Distributed But Proximate Trust (DBPT) that allow\nparties to use a LAN while remaining physically and logically distinct. These\ndevelopments make secure collaborative data analytics and AI significantly more\npractical and set new research directions for developing systems and\ncryptographic theory for high-performance distributed trust."}
{"id": "2511.00408", "categories": ["cs.CR"], "pdf": "https://arxiv.org/pdf/2511.00408", "abs": "https://arxiv.org/abs/2511.00408", "authors": ["Xiaoqi Li", "Wenkai Li", "Zhiquan Liu", "Yuqing Zhang", "Yingjie Mao"], "title": "Penetrating the Hostile: Detecting DeFi Protocol Exploits through Cross-Contract Analysis", "comment": "This work is accepted by TIFS", "summary": "Decentralized finance (DeFi) protocols are crypto projects developed on the\nblockchain to manage digital assets. Attacks on DeFi have been frequent and\nhave resulted in losses exceeding $80 billion. Current tools detect and locate\npossible vulnerabilities in contracts by analyzing the state changes that may\noccur during malicious events. However, this victim-only approaches seldom\npossess the capability to cover the attacker's interaction intention logic.\nFurthermore, only a minuscule percentage of DeFi protocols experience attacks\nin real-world scenarios, which poses a significant challenge for these\ndetection tools to demonstrate practical effectiveness. In this paper, we\npropose DeFiTail, the first framework that utilizes deep learning technology\nfor access control and flash loan exploit detection. Through feeding the\ncross-contract static data flow, DeFiTail automatically learns the attack logic\nin real-world malicious events that occur on DeFi protocols, capturing the\nthreat patterns between attacker and victim contracts. Since the DeFi protocol\nevents involve interactions with multi-account transactions, the execution path\nwith external and internal transactions requires to be unified. Moreover, to\nmitigate the impact of mistakes in Control Flow Graph (CFG) connections,\nDeFiTail validates the data path by employing the symbolic execution stack.\nFurthermore, we feed the data paths through our model to achieve the inspection\nof DeFi protocols. Comparative experiment results indicate that DeFiTail\nachieves the highest accuracy, with 98.39% in access control and 97.43% in\nflash loan exploits. DeFiTail also demonstrates an enhanced capability to\ndetect malicious contracts, identifying 86.67% accuracy from the CVE dataset."}
{"id": "2511.00415", "categories": ["cs.CR"], "pdf": "https://arxiv.org/pdf/2511.00415", "abs": "https://arxiv.org/abs/2511.00415", "authors": ["Jotaro Yano"], "title": "Zero-Knowledge Extensions on Solana: A Theory of ZK Architecture", "comment": null, "summary": "This paper reconstructs zero-knowledge extensions on Solana as an\narchitecture theory. Drawing on the existing ecosystem and on the author's\nprior papers and implementations as reference material, we propose a two-axis\nmodel that normalizes zero-knowledge (ZK) use by purpose (scalability vs.\nprivacy) and by placement (on-chain vs. off-chain). On this grid we define five\nlayer-crossing invariants: origin authenticity, replay-safety, finality\nalignment, parameter binding, and private consumption, which serve as a common\nvocabulary for reasoning about correctness across modules and chains. The\nframework covers the Solana Foundation's three pillars (ZK Compression,\nConfidential Transfer, light clients/bridges) together with surrounding\ncomponents (Light Protocol/Helius, Succinct SP1, RISC Zero, Wormhole,\nTinydancer, Arcium). From the theory we derive two design abstractions -\nProof-Carrying Message (PCM) and a Verifier Router Interface - and a\ncross-chain counterpart, Proof-Carrying Interchain Message (PCIM), indicating\nconcrete avenues for extending the three pillars."}
{"id": "2511.00447", "categories": ["cs.CR", "cs.AI"], "pdf": "https://arxiv.org/pdf/2511.00447", "abs": "https://arxiv.org/abs/2511.00447", "authors": ["Ruofan Liu", "Yun Lin", "Jin Song Dong"], "title": "DRIP: Defending Prompt Injection via De-instruction Training and Residual Fusion Model Architecture", "comment": null, "summary": "Large language models (LLMs) have demonstrated impressive\ninstruction-following capabilities. However, these capabilities also expose\nmodels to prompt injection attacks, where maliciously crafted inputs overwrite\nor distract from the intended instructions. A core vulnerability lies in the\nmodel's lack of semantic role understanding: it cannot distinguish directive\nintent from descriptive content, leading it to execute instruction-like phrases\nembedded in data.\n  We propose DRIP, a training-time defense grounded in a semantic modeling\nperspective, which enforces robust separation between instruction and data\nsemantics without sacrificing utility. DRIP introduces two lightweight yet\ncomplementary mechanisms: (1) a token-wise de-instruction shift that performs\nsemantic disentanglement, weakening directive semantics in data tokens while\npreserving content meaning; and (2) a residual fusion pathway that provides a\npersistent semantic anchor, reinforcing the influence of the true top-level\ninstruction during generation. Experimental results on LLaMA-8B and Mistral-7B\nacross three prompt injection benchmarks (SEP, AlpacaFarm, and InjecAgent)\ndemonstrate that DRIP outperforms state-of-the-art defenses, including StruQ,\nSecAlign, ISE, and PFT, improving role separation by 49%, and reducing attack\nsuccess rate by 66% for adaptive attacks. Meanwhile, DRIP's utility is on par\nwith the undefended model across AlpacaEval, IFEval, and MT-Bench. Our findings\nunderscore the power of lightweight representation edits and role-aware\nsupervision in securing LLMs against adaptive prompt injection."}
{"id": "2511.00460", "categories": ["cs.CR", "cs.AI"], "pdf": "https://arxiv.org/pdf/2511.00460", "abs": "https://arxiv.org/abs/2511.00460", "authors": ["Mohammed N. Swileh", "Shengli Zhang"], "title": "Proactive DDoS Detection and Mitigation in Decentralized Software-Defined Networking via Port-Level Monitoring and Zero-Training Large Language Models", "comment": null, "summary": "Centralized Software-Defined Networking (cSDN) offers flexible and\nprogrammable control of networks but suffers from scalability and reliability\nissues due to its reliance on centralized controllers. Decentralized SDN (dSDN)\nalleviates these concerns by distributing control across multiple local\ncontrollers, yet this architecture remains highly vulnerable to Distributed\nDenial-of-Service (DDoS) attacks. In this paper, we propose a novel detection\nand mitigation framework tailored for dSDN environments. The framework\nleverages lightweight port-level statistics combined with prompt engineering\nand in-context learning, enabling the DeepSeek-v3 Large Language Model (LLM) to\nclassify traffic as benign or malicious without requiring fine-tuning or\nretraining. Once an anomaly is detected, mitigation is enforced directly at the\nattacker's port, ensuring that malicious traffic is blocked at their origin\nwhile normal traffic remains unaffected. An automatic recovery mechanism\nrestores normal operation after the attack inactivity, ensuring both security\nand availability. Experimental evaluation under diverse DDoS attack scenarios\ndemonstrates that the proposed approach achieves near-perfect detection, with\n99.99% accuracy, 99.97% precision, 100% recall, 99.98% F1-score, and an AUC of\n1.0. These results highlight the effectiveness of combining distributed\nmonitoring with zero-training LLM inference, providing a proactive and scalable\ndefense mechanism for securing dSDN infrastructures against DDoS threats."}
{"id": "2511.00481", "categories": ["cs.CR"], "pdf": "https://arxiv.org/pdf/2511.00481", "abs": "https://arxiv.org/abs/2511.00481", "authors": ["Rahul Mishra", "Sudhanshu Kumar Jha", "Omar Faruq Osama", "Bishnu Bhusal", "Sneha Sudhakaran", "Naresh Kshetri"], "title": "An Efficient Anomaly Detection Framework for Wireless Sensor Networks Using Markov Process", "comment": "21 pages, 5 figures", "summary": "Wireless Sensor Networks forms the backbone of modern cyber physical systems\nused in various applications such as environmental monitoring, healthcare\nmonitoring, industrial automation, and smart infrastructure. Ensuring the\nreliability of data collected through these networks is essential as these data\nmay contain anomalies due to many reasons such as sensor faults, environmental\ndisturbances, or malicious intrusions. In this paper a lightweight and\ninterpretable anomaly detection framework based on a first order Markov chain\nmodel has been proposed. The method discretizes continuous sensor readings into\nfinite states and models the temporal dynamics of sensor transitions through a\ntransition probability matrix. Anomalies are detected when observed transitions\noccur with probabilities below a computed threshold, allowing for real time\ndetection without labeled data or intensive computation. The proposed framework\nwas validated using the Intel Berkeley Research Lab dataset, as a case study on\nindoor environmental monitoring demonstrates its capability to identify thermal\nspikes, voltage related faults, and irregular temperature fluctuations with\nhigh precision. Comparative analysis with Z score, Hidden Markov Model, and\nAuto encoder based methods shows that the proposed Markov based framework\nachieves a balanced trade-off between accuracy, F1 score is 0.86,\ninteroperability, and computational efficiency. The systems scalability and low\nresource footprint highlight its suitability for large-scale and real time\nanomaly detection in WSN deployments."}
{"id": "2511.00664", "categories": ["cs.CR", "cs.AI"], "pdf": "https://arxiv.org/pdf/2511.00664", "abs": "https://arxiv.org/abs/2511.00664", "authors": ["Kasimir Schulz", "Amelia Kawasaki", "Leo Ring"], "title": "ShadowLogic: Backdoors in Any Whitebox LLM", "comment": null, "summary": "Large language models (LLMs) are widely deployed across various applications,\noften with safeguards to prevent the generation of harmful or restricted\ncontent. However, these safeguards can be covertly bypassed through adversarial\nmodifications to the computational graph of a model. This work highlights a\ncritical security vulnerability in computational graph-based LLM formats,\ndemonstrating that widely used deployment pipelines may be susceptible to\nobscured backdoors. We introduce ShadowLogic, a method for creating a backdoor\nin a white-box LLM by injecting an uncensoring vector into its computational\ngraph representation. We set a trigger phrase that, when added to the beginning\nof a prompt into the LLM, applies the uncensoring vector and removes the\ncontent generation safeguards in the model. We embed trigger logic directly\ninto the computational graph which detects the trigger phrase in a prompt. To\nevade detection of our backdoor, we obfuscate this logic within the graph\nstructure, making it similar to standard model functions. Our method requires\nminimal alterations to model parameters, making backdoored models appear benign\nwhile retaining the ability to generate uncensored responses when activated. We\nsuccessfully implement ShadowLogic in Phi-3 and Llama 3.2, using ONNX for\nmanipulating computational graphs. Implanting the uncensoring vector achieved a\n>60% attack success rate for further malicious queries."}
{"id": "2511.00737", "categories": ["cs.CR", "cs.AI"], "pdf": "https://arxiv.org/pdf/2511.00737", "abs": "https://arxiv.org/abs/2511.00737", "authors": ["Jaewoo Park", "Chenghao Quan", "Jongeun Lee"], "title": "EP-HDC: Hyperdimensional Computing with Encrypted Parameters for High-Throughput Privacy-Preserving Inference", "comment": "To appear on ASP-DAC 2026", "summary": "While homomorphic encryption (HE) provides strong privacy protection, its\nhigh computational cost has restricted its application to simple tasks.\nRecently, hyperdimensional computing (HDC) applied to HE has shown promising\nperformance for privacy-preserving machine learning (PPML). However, when\napplied to more realistic scenarios such as batch inference, the HDC-based HE\nhas still very high compute time as well as high encryption and data\ntransmission overheads. To address this problem, we propose HDC with encrypted\nparameters (EP-HDC), which is a novel PPML approach featuring client-side HE,\ni.e., inference is performed on a client using a homomorphically encrypted\nmodel. Our EP-HDC can effectively mitigate the encryption and data transmission\noverhead, as well as providing high scalability with many clients while\nproviding strong protection for user data and model parameters. In addition to\napplication examples for our client-side PPML, we also present design space\nexploration involving quantization, architecture, and HE-related parameters.\nOur experimental results using the BFV scheme and the Face/Emotion datasets\ndemonstrate that our method can improve throughput and latency of batch\ninference by orders of magnitude over previous PPML methods (36.52~1068x and\n6.45~733x, respectively) with less than 1% accuracy degradation."}
{"id": "2511.00828", "categories": ["cs.CR", "cs.AI"], "pdf": "https://arxiv.org/pdf/2511.00828", "abs": "https://arxiv.org/abs/2511.00828", "authors": ["Huiyao Dong", "Igor Kotenko"], "title": "Towards Ultra-Low Latency: Binarized Neural Network Architectures for In-Vehicle Network Intrusion Detection", "comment": "6 pages, accepted and presented at INISTA 2025\n  (https://conferences.sigappfr.org/inista2025/)", "summary": "The Control Area Network (CAN) protocol is essential for in-vehicle\ncommunication, facilitating high-speed data exchange among Electronic Control\nUnits (ECUs). However, its inherent design lacks robust security features,\nrendering vehicles susceptible to cyberattacks. While recent research has\ninvestigated machine learning and deep learning techniques to enhance network\nsecurity, their practical applicability remains uncertain. This paper presents\na lightweight intrusion detection technique based on Binarized Neural Networks\n(BNNs), which utilizes payload data, message IDs, and CAN message frequencies\nfor effective intrusion detection. Additionally, we develop hybrid binary\nencoding techniques to integrate non-binary features, such as message IDs and\nfrequencies. The proposed method, namely the BNN framework specifically\noptimized for in-vehicle intrusion detection combined with hybrid binary\nquantization techniques for non-payload attributes, demonstrates efficacy in\nboth anomaly detection and multi-class network traffic classification. The\nsystem is well-suited for deployment on micro-controllers and Gateway ECUs,\naligning with the real-time requirements of CAN bus safety applications."}
{"id": "2511.00894", "categories": ["cs.CR", "cs.AI", "cs.LG"], "pdf": "https://arxiv.org/pdf/2511.00894", "abs": "https://arxiv.org/abs/2511.00894", "authors": ["Hasan Abdulla"], "title": "Android Malware Detection: A Machine Leaning Approach", "comment": null, "summary": "This study examines machine learning techniques like Decision Trees, Support\nVector Machines, Logistic Regression, Neural Networks, and ensemble methods to\ndetect Android malware. The study evaluates these models on a dataset of\nAndroid applications and analyzes their accuracy, efficiency, and real-world\napplicability. Key findings show that ensemble methods demonstrate superior\nperformance, but there are trade-offs between model interpretability,\nefficiency, and accuracy. Given its increasing threat, the insights guide\nfuture research and practical use of ML to combat Android malware."}
{"id": "2511.00930", "categories": ["cs.CR"], "pdf": "https://arxiv.org/pdf/2511.00930", "abs": "https://arxiv.org/abs/2511.00930", "authors": ["Xijie Ba", "Qin Liu", "Xiaohong Li", "Jianting Ning"], "title": "Leakage-abuse Attack Against Substring-SSE with Partially Known Dataset", "comment": null, "summary": "Substring-searchable symmetric encryption (substring-SSE) has become\nincreasingly critical for privacy-preserving applications in cloud systems.\nHowever, existing schemes remain vulnerable to information leakage during\nsearch operations, particularly when adversaries possess partial knowledge of\nthe target dataset. Although leakage-abuse attacks have been widely studied for\ntraditional SSE, their applicability to substring-SSE under partially known\ndata assumptions remains unexplored. In this paper, we present the first\nleakage-abuse attack on substring-SSE under partially-known dataset conditions.\nWe develop a novel matrix-based correlation technique that extends and\noptimizes the LEAP framework for substring-SSE, enabling efficient recovery of\nplaintext data from encrypted suffix tree structures. Unlike existing\napproaches that rely on independent auxiliary datasets, our method directly\nexploits known data fragments to establish high-confidence mappings between\nciphertext tokens and plaintext substrings through iterative matrix\ntransformations. Comprehensive experiments on real-world datasets demonstrate\nthe effectiveness of the attack, with recovery rates reaching 98.32% for\nsubstrings given 50% auxiliary knowledge. Even with only 10% prior knowledge,\nthe attack achieves 74.42% substring recovery while maintaining strong\nscalability across datasets of varying sizes. The result reveals significant\nprivacy risks in current substring-SSE designs and highlights the urgent need\nfor leakage-resilient constructions."}
{"id": "2511.00973", "categories": ["cs.CR", "cs.AI", "eess.SP", "68T07, 68P25, 94A60, 68Q32, 68Q87, 94A17, 68M12", "I.2.6; E.3; D.4.6; C.2.0; I.5.1; C.2.2; K.6.5; C.3"], "pdf": "https://arxiv.org/pdf/2511.00973", "abs": "https://arxiv.org/abs/2511.00973", "authors": ["Ayşe S. Okatan", "Mustafa İlhan Akbaş", "Laxima Niure Kandel", "Berker Peköz"], "title": "Keys in the Weights: Transformer Authentication Using Model-Bound Latent Representations", "comment": "Cite as A. S. Okatan, M. I. Akbas, L. N. Kandel, and B. Pekoz, \"Keys\n  in the weights: Transformer authentication using model-bound latent\n  representations,\" in Proc. 2025 Cyber Awareness and Research Symp. (IEEE CARS\n  2025), Grand Forks, ND, Oct. 2025, pp. 6", "summary": "We introduce Model-Bound Latent Exchange (MoBLE), a decoder-binding property\nin Transformer autoencoders formalized as Zero-Shot Decoder Non-Transferability\n(ZSDN). In identity tasks using iso-architectural models trained on identical\ndata but differing in seeds, self-decoding achieves more than 0.91 exact match\nand 0.98 token accuracy, while zero-shot cross-decoding collapses to chance\nwithout exact matches. This separation arises without injected secrets or\nadversarial training, and is corroborated by weight-space distances and\nattention-divergence diagnostics. We interpret ZSDN as model binding, a\nlatent-based authentication and access-control mechanism, even when the\narchitecture and training recipe are public: encoder's hidden state\nrepresentation deterministically reveals the plaintext, yet only the correctly\nkeyed decoder reproduces it in zero-shot. We formally define ZSDN, a\ndecoder-binding advantage metric, and outline deployment considerations for\nsecure artificial intelligence (AI) pipelines. Finally, we discuss learnability\nrisks (e.g., adapter alignment) and outline mitigations. MoBLE offers a\nlightweight, accelerator-friendly approach to secure AI deployment in\nsafety-critical domains, including aviation and cyber-physical systems."}
{"id": "2511.01124", "categories": ["cs.CR", "cs.FL"], "pdf": "https://arxiv.org/pdf/2511.01124", "abs": "https://arxiv.org/abs/2511.01124", "authors": ["Max von Hippel"], "title": "Verification and Attack Synthesis for Network Protocols", "comment": "PhD dissertation", "summary": "Network protocols are programs with inputs and outputs that follow predefined\ncommunication patterns to synchronize and exchange information. There are many\nprotocols and each serves a different purpose, e.g., routing, transport, secure\ncommunication, etc. The functional and performance requirements for a protocol\ncan be expressed using a formal specification, such as, a set of logical\npredicates over its traces. A protocol could be prevented from achieving its\nrequirements due to a bug in its design or implementation, a component failure\n(e.g., a crash), or an attack. This dissertation shows that formal methods can\nfeasibly characterize the functionality and performance of network protocols\nunder normal conditions as well as when subjected to attacks."}
{"id": "2511.01144", "categories": ["cs.CR", "cs.AI"], "pdf": "https://arxiv.org/pdf/2511.01144", "abs": "https://arxiv.org/abs/2511.01144", "authors": ["Md Tanvirul Alam", "Dipkamal Bhusal", "Salman Ahmad", "Nidhi Rastogi", "Peter Worth"], "title": "AthenaBench: A Dynamic Benchmark for Evaluating LLMs in Cyber Threat Intelligence", "comment": null, "summary": "Large Language Models (LLMs) have demonstrated strong capabilities in natural\nlanguage reasoning, yet their application to Cyber Threat Intelligence (CTI)\nremains limited. CTI analysis involves distilling large volumes of unstructured\nreports into actionable knowledge, a process where LLMs could substantially\nreduce analyst workload. CTIBench introduced a comprehensive benchmark for\nevaluating LLMs across multiple CTI tasks. In this work, we extend CTIBench by\ndeveloping AthenaBench, an enhanced benchmark that includes an improved dataset\ncreation pipeline, duplicate removal, refined evaluation metrics, and a new\ntask focused on risk mitigation strategies. We evaluate twelve LLMs, including\nstate-of-the-art proprietary models such as GPT-5 and Gemini-2.5 Pro, alongside\nseven open-source models from the LLaMA and Qwen families. While proprietary\nLLMs achieve stronger results overall, their performance remains subpar on\nreasoning-intensive tasks, such as threat actor attribution and risk\nmitigation, with open-source models trailing even further behind. These\nfindings highlight fundamental limitations in the reasoning capabilities of\ncurrent LLMs and underscore the need for models explicitly tailored to CTI\nworkflows and automation."}
{"id": "2511.01180", "categories": ["cs.CR", "cs.SE"], "pdf": "https://arxiv.org/pdf/2511.01180", "abs": "https://arxiv.org/abs/2511.01180", "authors": ["Jingyi Shi", "Yufeng Chen", "Yang Xiao", "Yuekang Li", "Zhengzi Xu", "Sihao Qiu", "Chi Zhang", "Keyu Qi", "Yeting Li", "Xingchu Chen", "Yanyan Zou", "Yang Liu", "Wei Huo"], "title": "A Large Scale Study of AI-based Binary Function Similarity Detection Techniques for Security Researchers and Practitioners", "comment": "Accepted by ASE 2025", "summary": "Binary Function Similarity Detection (BFSD) is a foundational technique in\nsoftware security, underpinning a wide range of applications including\nvulnerability detection, malware analysis. Recent advances in AI-based BFSD\ntools have led to significant performance improvements. However, existing\nevaluations of these tools suffer from three key limitations: a lack of\nin-depth analysis of performance-influencing factors, an absence of realistic\napplication analysis, and reliance on small-scale or low-quality datasets.\n  In this paper, we present the first large-scale empirical study of AI-based\nBFSD tools to address these gaps. We construct two high-quality and diverse\ndatasets: BinAtlas, comprising 12,453 binaries and over 7 million functions for\ncapability evaluation; and BinAres, containing 12,291 binaries and 54\nreal-world 1-day vulnerabilities for evaluating vulnerability detection\nperformance in practical IoT firmware settings. Using these datasets, we\nevaluate nine representative BFSD tools, analyze the challenges and limitations\nof existing BFSD tools, and investigate the consistency among BFSD tools. We\nalso propose an actionable strategy for combining BFSD tools to enhance overall\nperformance (an improvement of 13.4%). Our study not only advances the\npractical adoption of BFSD tools but also provides valuable resources and\ninsights to guide future research in scalable and automated binary similarity\ndetection."}
{"id": "2511.01197", "categories": ["cs.CR"], "pdf": "https://arxiv.org/pdf/2511.01197", "abs": "https://arxiv.org/abs/2511.01197", "authors": ["Yifan Zhou", "Tianshi Xu", "Jue Hong", "Ye Wu", "Meng Li"], "title": "CryptoMoE: Privacy-Preserving and Scalable Mixture of Experts Inference via Balanced Expert Routing", "comment": "NeurIPS'2025", "summary": "Private large language model (LLM) inference based on cryptographic\nprimitives offers a promising path towards privacy-preserving deep learning.\nHowever, existing frameworks only support dense LLMs like LLaMA-1 and struggle\nto scale to mixture-of-experts (MoE) architectures. The key challenge comes\nfrom securely evaluating the dynamic routing mechanism in MoE layers, which may\nreveal sensitive input information if not fully protected. In this paper, we\npropose CryptoMoE, the first framework that enables private, efficient, and\naccurate inference for MoE-based models. CryptoMoE balances expert loads to\nprotect expert routing information and proposes novel protocols for secure\nexpert dispatch and combine. CryptoMoE also develops a confidence-aware token\nselection strategy and a batch matrix multiplication protocol to improve\naccuracy and efficiency further. Extensive experiments on DeepSeekMoE-16.4B,\nOLMoE-6.9B, and QWenMoE-14.3B show that CryptoMoE achieves $2.8\\sim3.5\\times$\nend-to-end latency reduction and $2.9\\sim4.3\\times$ communication reduction\nover a dense baseline with minimum accuracy loss. We also adapt CipherPrune\n(ICLR'25) for MoE inference and demonstrate CryptoMoE can reduce the\ncommunication by up to $4.3 \\times$. Code is available at:\nhttps://github.com/PKU-SEC-Lab/CryptoMoE."}
{"id": "2511.01268", "categories": ["cs.CR", "cs.AI", "cs.IR", "D.4.6; K.6.5"], "pdf": "https://arxiv.org/pdf/2511.01268", "abs": "https://arxiv.org/abs/2511.01268", "authors": ["Minseok Kim", "Hankook Lee", "Hyungjoon Koo"], "title": "Rescuing the Unpoisoned: Efficient Defense against Knowledge Corruption Attacks on RAG Systems", "comment": "15 pages, 7 figures, 10 tables. To appear in the Proceedings of the\n  2025 Annual Computer Security Applications Conference (ACSAC)", "summary": "Large language models (LLMs) are reshaping numerous facets of our daily\nlives, leading widespread adoption as web-based services. Despite their\nversatility, LLMs face notable challenges, such as generating hallucinated\ncontent and lacking access to up-to-date information. Lately, to address such\nlimitations, Retrieval-Augmented Generation (RAG) has emerged as a promising\ndirection by generating responses grounded in external knowledge sources. A\ntypical RAG system consists of i) a retriever that probes a group of relevant\npassages from a knowledge base and ii) a generator that formulates a response\nbased on the retrieved content. However, as with other AI systems, recent\nstudies demonstrate the vulnerability of RAG, such as knowledge corruption\nattacks by injecting misleading information. In response, several defense\nstrategies have been proposed, including having LLMs inspect the retrieved\npassages individually or fine-tuning robust retrievers. While effective, such\napproaches often come with substantial computational costs.\n  In this work, we introduce RAGDefender, a resource-efficient defense\nmechanism against knowledge corruption (i.e., by data poisoning) attacks in\npractical RAG deployments. RAGDefender operates during the post-retrieval\nphase, leveraging lightweight machine learning techniques to detect and filter\nout adversarial content without requiring additional model training or\ninference. Our empirical evaluations show that RAGDefender consistently\noutperforms existing state-of-the-art defenses across multiple models and\nadversarial scenarios: e.g., RAGDefender reduces the attack success rate (ASR)\nagainst the Gemini model from 0.89 to as low as 0.02, compared to 0.69 for\nRobustRAG and 0.24 for Discern-and-Answer when adversarial passages outnumber\nlegitimate ones by a factor of four (4x)."}
{"id": "2511.01303", "categories": ["cs.CR", "cs.LG"], "pdf": "https://arxiv.org/pdf/2511.01303", "abs": "https://arxiv.org/abs/2511.01303", "authors": ["Tomer Shoham", "Moshe Shenfeld", "Noa Velner-Harris", "Katrina Ligett"], "title": "Black-Box Differentially Private Nonparametric Confidence Intervals Under Minimal Assumptions", "comment": null, "summary": "We introduce a simple, general framework that takes any differentially\nprivate estimator of any arbitrary quantity as a black box, and from it\nconstructs a differentially private nonparametric confidence interval of that\nquantity. Our approach repeatedly subsamples the data, applies the private\nestimator to each subsample, and then post-processes the resulting empirical\nCDF to a confidence interval. Our analysis uses the randomness from the\nsubsampling to achieve privacy amplification. Under mild assumptions, the\nempirical CDF we obtain approaches the CDF of the private statistic as the\nsample size grows. We use this to show that the confidence intervals we\nestimate are asymptotically valid, tight, and equivalent to their non-private\ncounterparts. We provide empirical evidence that our method performs well\ncompared with the (less-general) state-of-the-art algorithms."}
{"id": "2511.01391", "categories": ["cs.CR", "cs.NI"], "pdf": "https://arxiv.org/pdf/2511.01391", "abs": "https://arxiv.org/abs/2511.01391", "authors": ["Dang Kien Nguyen", "Rim El Malki", "Filippo Rebecchi", "Raymond Knopp", "Melek Önen"], "title": "Beyond Static Thresholds: Adaptive RRC Signaling Storm Detection with Extreme Value Theory", "comment": "Accepted to MSWiM 2025", "summary": "In 5G and beyond networks, the radio communication between a User Equipment\n(UE) and a base station (gNodeB or gNB), also known as the air interface, is a\ncritical component of network access and connectivity. During the connection\nestablishment procedure, the Radio Resource Control (RRC) layer can be\nvulnerable to signaling storms, which threaten the availability of the radio\naccess control plane. These attacks may occur when one or more UEs send a large\nnumber of connection requests to the gNB, preventing new UEs from establishing\nconnections. In this paper, we investigate the detection of such threats and\npropose an adaptive threshold-based detection system based on Extreme Value\nTheory (EVT). The proposed solution is evaluated numerically by applying\nsimulated attack scenarios based on a realistic threat model on top of\nreal-world RRC traffic data from an operator network. We show that, by\nleveraging features from the RRC layer only, the detection system can not only\nidentify the attacks but also differentiate them from legitimate high-traffic\nsituations. The adaptive threshold calculated using EVT ensures that the system\ncan work under diverse traffic conditions. The results show high accuracy,\nprecision, and recall values (above 93%), and a low detection latency even\nunder complex conditions."}
{"id": "2511.01393", "categories": ["cs.CR"], "pdf": "https://arxiv.org/pdf/2511.01393", "abs": "https://arxiv.org/abs/2511.01393", "authors": ["Hanzhong Liang", "Yue Duan", "Xing Su", "Xiao Li", "Yating Liu", "Yulong Tian", "Fengyuan Xu", "Sheng Zhong"], "title": "ConneX: Automatically Resolving Transaction Opacity of Cross-Chain Bridges for Security Analysis", "comment": null, "summary": "As the Web3 ecosystem evolves toward a multi-chain architecture, cross-chain\nbridges have become critical infrastructure for enabling interoperability\nbetween diverse blockchain networks. However, while connecting isolated\nblockchains, the lack of cross-chain transaction pairing records introduces\nsignificant challenges for security analysis like cross-chain fund tracing,\nadvanced vulnerability detection, and transaction graph-based analysis. To\naddress this gap, we introduce ConneX, an automated and general-purpose system\ndesigned to accurately identify corresponding transaction pairs across both\nends of cross-chain bridges. Our system leverages Large Language Models (LLMs)\nto efficiently prune the semantic search space by identifying semantically\nplausible key information candidates within complex transaction records.\nFurther, it deploys a novel examiner module that refines these candidates by\nvalidating them against transaction values, effectively addressing semantic\nambiguities and identifying the correct semantics. Extensive evaluations on a\ndataset of about 500,000 transactions from five major bridge platforms\ndemonstrate that ConneX achieves an average F1 score of 0.9746, surpassing\nbaselines by at least 20.05\\%, with good efficiency that reduces the semantic\nsearch space by several orders of magnitude (1e10 to less than 100). Moreover,\nits successful application in tracing illicit funds (including a cross-chain\ntransfer worth $1 million) in real-world hacking incidents underscores its\npractical utility for enhancing cross-chain security and transparency."}
{"id": "2511.01451", "categories": ["cs.CR"], "pdf": "https://arxiv.org/pdf/2511.01451", "abs": "https://arxiv.org/abs/2511.01451", "authors": ["Jiacheng Wang", "Changyuan Zhao", "Jialing He", "Geng Sun", "Weijie Yuan", "Dusit Niyato", "Liehuang Zhu", "Tao Xiang"], "title": "Security-Aware Joint Sensing, Communication, and Computing Optimization in Low Altitude Wireless Networks", "comment": "14 pages, 10 figures", "summary": "As terrestrial resources become increasingly saturated, the research\nattention is shifting to the low-altitude airspace, with many emerging\napplications such as urban air taxis and aerial inspection. Low-Altitude\nWireless Networks (LAWNs) are the foundation for these applications, with\nintegrated sensing, communications, and computing (ISCC) being one of the core\nparts of LAWNs. However, the openness of low-altitude airspace exposes\ncommunications to security threats, degrading ISCC performance and ultimately\ncompromising the reliability of applications supported by LAWNs. To address\nthese challenges, this paper studies joint performance optimization of ISCC\nwhile considering secrecyness of the communications. Specifically, we derive\nbeampattern error, secrecy rate, and age of information (AoI) as performance\nmetrics for sensing, secrecy communication, and computing. Building on these\nmetrics, we formulate a multi-objective optimization problem that balances\nsensing and computation performance while keeping the probability of\ncommunication being detected below a required threshold. We then propose a deep\nQ-network (DQN)-based multi-objective evolutionary algorithm, which adaptively\nselects evolutionary operators according to the evolving optimization\nobjectives, thereby leading to more effective solutions. Extensive simulations\nshow that the proposed method achieves a superior balance among sensing\naccuracy, communication secrecyness, and information freshness compared with\nbaseline algorithms, thereby safeguarding ISCC performance and LAWN-supported\nlow-altitude applications."}
{"id": "2511.01583", "categories": ["cs.CR", "cs.AI", "cs.DC", "cs.LG"], "pdf": "https://arxiv.org/pdf/2511.01583", "abs": "https://arxiv.org/abs/2511.01583", "authors": ["Daniel M. Jimenez-Gutierrez", "Enrique Zuazua", "Joaquin Del Rio", "Oleksii Sliusarenko", "Xabi Uribe-Etxebarria"], "title": "Federated Cyber Defense: Privacy-Preserving Ransomware Detection Across Distributed Systems", "comment": null, "summary": "Detecting malware, especially ransomware, is essential to securing today's\ninterconnected ecosystems, including cloud storage, enterprise file-sharing,\nand database services. Training high-performing artificial intelligence (AI)\ndetectors requires diverse datasets, which are often distributed across\nmultiple organizations, making centralization necessary. However, centralized\nlearning is often impractical due to security, privacy regulations, data\nownership issues, and legal barriers to cross-organizational sharing.\nCompounding this challenge, ransomware evolves rapidly, demanding models that\nare both robust and adaptable.\n  In this paper, we evaluate Federated Learning (FL) using the Sherpa.ai FL\nplatform, which enables multiple organizations to collaboratively train a\nransomware detection model while keeping raw data local and secure. This\nparadigm is particularly relevant for cybersecurity companies (including both\nsoftware and hardware vendors) that deploy ransomware detection or firewall\nsystems across millions of endpoints. In such environments, data cannot be\ntransferred outside the customer's device due to strict security, privacy, or\nregulatory constraints. Although FL applies broadly to malware threats, we\nvalidate the approach using the Ransomware Storage Access Patterns (RanSAP)\ndataset.\n  Our experiments demonstrate that FL improves ransomware detection accuracy by\na relative 9% over server-local models and achieves performance comparable to\ncentralized training. These results indicate that FL offers a scalable,\nhigh-performing, and privacy-preserving framework for proactive ransomware\ndetection across organizational and regulatory boundaries."}
{"id": "2511.01634", "categories": ["cs.CR", "cs.AI"], "pdf": "https://arxiv.org/pdf/2511.01634", "abs": "https://arxiv.org/abs/2511.01634", "authors": ["Daniyal Ganiuly", "Assel Smaiyl"], "title": "Prompt Injection as an Emerging Threat: Evaluating the Resilience of Large Language Models", "comment": "10 pages, 6 figures", "summary": "Large Language Models (LLMs) are increasingly used in intelligent systems\nthat perform reasoning, summarization, and code generation. Their ability to\nfollow natural-language instructions, while powerful, also makes them\nvulnerable to a new class of attacks known as prompt injection. In these\nattacks, hidden or malicious instructions are inserted into user inputs or\nexternal content, causing the model to ignore its intended task or produce\nunsafe responses. This study proposes a unified framework for evaluating how\nresistant Large Language Models (LLMs) are to prompt injection attacks. The\nframework defines three complementary metrics such as the Resilience\nDegradation Index (RDI), Safety Compliance Coefficient (SCC), and Instructional\nIntegrity Metric (IIM) to jointly measure robustness, safety, and semantic\nstability. We evaluated four instruction-tuned models (GPT-4, GPT-4o, LLaMA-3\n8B Instruct, and Flan-T5-Large) on five common language tasks: question\nanswering, summarization, translation, reasoning, and code generation. Results\nshow that GPT-4 performs best overall, while open-weight models remain more\nvulnerable. The findings highlight that strong alignment and safety tuning are\nmore important for resilience than model size alone. Results show that all\nmodels remain partially vulnerable, especially to indirect and direct-override\nattacks. GPT-4 achieved the best overall resilience (RDR = 9.8 %, SCR = 96.4\n%), while open-source models exhibited higher performance degradation and lower\nsafety scores. The findings demonstrate that alignment strength and safety\ntuning play a greater role in resilience than model size alone. The proposed\nframework offers a structured, reproducible approach for assessing model\nrobustness and provides practical insights for improving LLM safety and\nreliability."}
{"id": "2511.01654", "categories": ["cs.CR", "cs.LG"], "pdf": "https://arxiv.org/pdf/2511.01654", "abs": "https://arxiv.org/abs/2511.01654", "authors": ["Congcong Chen", "Xinyu Liu", "Kaifeng Huang", "Lifei Wei", "Yang Shi"], "title": "Panther: A Cost-Effective Privacy-Preserving Framework for GNN Training and Inference Services in Cloud Environments", "comment": "Accepted for publication in IEEE Transactions on Services Computing\n  (TSC)", "summary": "Graph Neural Networks (GNNs) have marked significant impact in traffic state\nprediction, social recommendation, knowledge-aware question answering and so\non. As more and more users move towards cloud computing, it has become a\ncritical issue to unleash the power of GNNs while protecting the privacy in\ncloud environments. Specifically, the training data and inference data for GNNs\nneed to be protected from being stolen by external adversaries. Meanwhile, the\nfinancial cost of cloud computing is another primary concern for users.\nTherefore, although existing studies have proposed privacy-preserving\ntechniques for GNNs in cloud environments, their additional computational and\ncommunication overhead remain relatively high, causing high financial costs\nthat limit their widespread adoption among users.\n  To protect GNN privacy while lowering the additional financial costs, we\nintroduce Panther, a cost-effective privacy-preserving framework for GNN\ntraining and inference services in cloud environments. Technically, Panther\nleverages four-party computation to asynchronously executing the secure array\naccess protocol, and randomly pads the neighbor information of GNN nodes. We\nprove that Panther can protect privacy for both training and inference of GNN\nmodels. Our evaluation shows that Panther reduces the training and inference\ntime by an average of 75.28% and 82.80%, respectively, and communication\noverhead by an average of 52.61% and 50.26% compared with the state-of-the-art,\nwhich is estimated to save an average of 55.05% and 59.00% in financial costs\n(based on on-demand pricing model) for the GNN training and inference process\non Google Cloud Platform."}
{"id": "2511.01746", "categories": ["cs.CR", "cs.AI"], "pdf": "https://arxiv.org/pdf/2511.01746", "abs": "https://arxiv.org/abs/2511.01746", "authors": ["Chen-Wei Chang", "Shailik Sarkar", "Hossein Salemi", "Hyungmin Kim", "Shutonu Mitra", "Hemant Purohit", "Fengxiu Zhang", "Michin Hong", "Jin-Hee Cho", "Chang-Tien Lu"], "title": "Scam Shield: Multi-Model Voting and Fine-Tuned LLMs Against Adversarial Attacks", "comment": "8 pages", "summary": "Scam detection remains a critical challenge in cybersecurity as adversaries\ncraft messages that evade automated filters. We propose a Hierarchical Scam\nDetection System (HSDS) that combines a lightweight multi-model voting front\nend with a fine-tuned LLaMA 3.1 8B Instruct back end to improve accuracy and\nrobustness against adversarial attacks. An ensemble of four classifiers\nprovides preliminary predictions through majority vote, and ambiguous cases are\nescalated to the fine-tuned model, which is optimized with adversarial training\nto reduce misclassification. Experiments show that this hierarchical design\nboth improves adversarial scam detection and shortens inference time by routing\nmost cases away from the LLM, outperforming traditional machine-learning\nbaselines and proprietary LLM baselines. The findings highlight the\neffectiveness of a hybrid voting mechanism and adversarial fine-tuning in\nfortifying LLMs against evolving scam tactics, enhancing the resilience of\nautomated scam detection systems."}
