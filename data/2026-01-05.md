<div id=toc></div>

# Table of Contents

- [cs.CR](#cs.CR) [Total: 26]


<div id='cs.CR'></div>

# cs.CR [[Back]](#toc)

### [1] [Large Empirical Case Study: Go-Explore adapted for AI Red Team Testing](https://arxiv.org/abs/2601.00042)
*Manish Bhatt,Adrian Wood,Idan Habler,Ammar Al-Kahfah*

Main category: cs.CR

TL;DR: 研究评估GPT-4o-mini工具使用能力的安全性测试，发现随机种子方差比算法参数影响更大，单次测试不可靠，多种子平均可降低方差；奖励塑造会损害性能，简单状态签名优于复杂签名；集成测试提供攻击类型多样性，单一代理优化特定攻击类型的覆盖率。


<details>
  <summary>Details</summary>
Motivation: 尽管经过安全训练，具备工具使用能力的生产级LLM代理仍需要进行安全性测试。研究旨在评估GPT-4o-mini在不同测试条件下的安全性表现，探究影响测试结果的关键因素。

Method: 采用Go-Explore方法对GPT-4o-mini进行28次实验运行，涵盖六个研究问题。比较不同随机种子、算法参数、奖励塑造策略和状态签名方法的效果。

Result: 随机种子方差对结果影响最大（8倍差异），单种子比较不可靠，多种子平均能显著降低方差。奖励塑造在94%的运行中损害性能或产生18个假阳性攻击。简单状态签名优于复杂签名。集成测试提供攻击类型多样性，单一代理优化特定攻击类型的覆盖率。

Conclusion: 在测试安全训练模型时，随机种子方差和针对性领域知识可能比算法复杂度更重要。多种子平均、避免奖励塑造、使用简单状态签名以及结合集成与单一代理策略可提高安全性测试的可靠性。

Abstract: Production LLM agents with tool-using capabilities require security testing despite their safety training. We adapt Go-Explore to evaluate GPT-4o-mini across 28 experimental runs spanning six research questions. We find that random-seed variance dominates algorithmic parameters, yielding an 8x spread in outcomes; single-seed comparisons are unreliable, while multi-seed averaging materially reduces variance in our setup. Reward shaping consistently harms performance, causing exploration collapse in 94% of runs or producing 18 false positives with zero verified attacks. In our environment, simple state signatures outperform complex ones. For comprehensive security testing, ensembles provide attack-type diversity, whereas single agents optimize coverage within a given attack type. Overall, these results suggest that seed variance and targeted domain knowledge can outweigh algorithmic sophistication when testing safety-trained models.

</details>


### [2] [Overlooked Safety Vulnerability in LLMs: Malicious Intelligent Optimization Algorithm Request and its Jailbreak](https://arxiv.org/abs/2601.00213)
*Haoran Gu,Handing Wang,Yi Mei,Mengjie Zhang,Yaochu Jin*

Main category: cs.CR

TL;DR: 研究揭示大型语言模型在自动化算法设计中的安全漏洞，提出专门针对优化算法设计的越狱攻击方法MOBjailbreak，测试发现主流模型对此类攻击高度脆弱，现有防御措施效果有限。


<details>
  <summary>Details</summary>
Motivation: 大型语言模型广泛部署引发对其滥用风险和安全问题的担忧。先前研究主要关注LLMs在通用使用、代码生成和基于代理应用中的安全性，但它们在自动化算法设计中的漏洞尚未充分探索。本研究旨在填补这一空白，特别关注智能优化算法设计领域，因为该领域在复杂决策场景中应用广泛。

Method: 1. 引入MalOptBench基准，包含60个恶意优化算法请求；2. 提出MOBjailbreak方法，专门针对优化算法设计场景的越狱攻击技术；3. 对13个主流LLMs（包括最新GPT-5和DeepSeek-V3.1）进行广泛评估；4. 评估最先进的即插即用防御措施在闭源模型上的效果。

Result: 1. 大多数模型对此类攻击高度脆弱：原始恶意提示的平均攻击成功率为83.59%，平均危害性评分为4.28/5；2. 在MOBjailbreak攻击下，模型几乎完全失效；3. 现有防御措施对MOBjailbreak仅略微有效，且容易产生过度安全行为；4. 所有测试模型都表现出显著的安全漏洞。

Conclusion: 研究结果突显了加强对齐技术的紧迫需求，以保护LLMs在算法设计中的安全使用。自动化算法设计领域存在被忽视的安全漏洞，需要开发更强大的安全机制来防止模型被恶意利用。

Abstract: The widespread deployment of large language models (LLMs) has raised growing concerns about their misuse risks and associated safety issues. While prior studies have examined the safety of LLMs in general usage, code generation, and agent-based applications, their vulnerabilities in automated algorithm design remain underexplored. To fill this gap, this study investigates this overlooked safety vulnerability, with a particular focus on intelligent optimization algorithm design, given its prevalent use in complex decision-making scenarios. We introduce MalOptBench, a benchmark consisting of 60 malicious optimization algorithm requests, and propose MOBjailbreak, a jailbreak method tailored for this scenario. Through extensive evaluation of 13 mainstream LLMs including the latest GPT-5 and DeepSeek-V3.1, we reveal that most models remain highly susceptible to such attacks, with an average attack success rate of 83.59% and an average harmfulness score of 4.28 out of 5 on original harmful prompts, and near-complete failure under MOBjailbreak. Furthermore, we assess state-of-the-art plug-and-play defenses that can be applied to closed-source models, and find that they are only marginally effective against MOBjailbreak and prone to exaggerated safety behaviors. These findings highlight the urgent need for stronger alignment techniques to safeguard LLMs against misuse in algorithm design.

</details>


### [3] [Evolution of Android's Permission-based Security Model and Challenges](https://arxiv.org/abs/2601.00252)
*Rajendra Kumar Solanki,Vijay Laxmi,Manoj Singh Gaur*

Main category: cs.CR

TL;DR: 本文通过系统性文献综述（2010-2022年）分析了Android权限模型的研究现状、演进历程、存在问题及未来方向


<details>
  <summary>Details</summary>
Motivation: Android权限模型自2008年推出以来经历了从"全有或全无"到"用户选择危险资源访问"的演变，但15年后仍存在未解决的安全挑战和问题，需要系统性梳理研究现状

Method: 采用综合性文献调查和比较分析方法，系统化整理Android权限相关知识，重点关注：(1) Android API调用与权限映射关系，(2) Android权限演进历程，(3) 权限检查机制

Result: 识别了过去十年中权限相关的问题及相应研究解决方案，引用了该领域的开创性工作，总结了现有研究空白

Conclusion: 提出了未来研究方向，为早期和资深研究人员提供指导，旨在推动Android权限模型和安全研究的进一步发展

Abstract: Android Permission Model and Application (app) analysis has consistently remained the focus of the investigation of research groups and stakeholders of the Android ecosystem since it was launched in 2008. Even though the Android smartphone operating system (OS) permission model has evolved significantly from `all-or-none access' to `user-chosen dangerous resource access', specific challenges and issues remain unresolved even after 15 years after the smartphone OS launch. This study addresses the issues and documents the research work in this arena through a comprehensive literature survey and comparative analysis.
  The survey's focal point is the Android permission model and relevant research between 2010-2022. We systematize the knowledge on (i) Android API Calls to permissions mapping, (ii) Android Permissions evolution, and (iii) how permissions are checked. Furthermore, the survey identifies the permission-related issues and relevant research addressed during the last decade. We reference seminal work in these areas. We summarize the identified research gaps and present future directions for early and experienced researchers.

</details>


### [4] [Rectifying Adversarial Examples Using Their Vulnerabilities](https://arxiv.org/abs/2601.00270)
*Fumiya Morimoto,Ryuto Morita,Satoshi Ono*

Main category: cs.CR

TL;DR: 提出一种对抗样本校正方法，通过重新攻击对抗样本来估计原始正确标签，无需参数调整或预训练，能处理多种攻击类型。


<details>
  <summary>Details</summary>
Motivation: 现有防御方法主要关注对抗样本检测而非校正，但某些应用（如自动驾驶交通标志识别）需要识别原始正确类别。当前方法难以有效校正黑盒攻击或低置信度目标攻击生成的对抗样本。

Method: 基于重新攻击对抗样本，将其移出决策边界以准确预测原始标签。仅以对抗样本为输入，无需参数调整或预训练，能处理白盒攻击生成的微小扰动对抗样本。

Result: 该方法在多种攻击方法（包括目标攻击和黑盒攻击）生成的对抗样本校正中表现一致，在对抗各种攻击的稳定性方面优于传统校正和输入变换方法。

Conclusion: 提出的对抗样本校正方法能有效估计原始正确标签，处理多种攻击类型，且无需复杂调整，在安全关键应用中具有实用价值。

Abstract: Deep neural network-based classifiers are prone to errors when processing adversarial examples (AEs). AEs are minimally perturbed input data undetectable to humans posing significant risks to security-dependent applications. Hence, extensive research has been undertaken to develop defense mechanisms that mitigate their threats. Most existing methods primarily focus on discriminating AEs based on the input sample features, emphasizing AE detection without addressing the correct sample categorization before an attack. While some tasks may only require mere rejection on detected AEs, others necessitate identifying the correct original input category such as traffic sign recognition in autonomous driving. The objective of this study is to propose a method for rectifying AEs to estimate the correct labels of their original inputs. Our method is based on re-attacking AEs to move them beyond the decision boundary for accurate label prediction, effectively addressing the issue of rectifying minimally perceptible AEs created using white-box attack methods. However, challenge remains with respect to effectively rectifying AEs produced by black-box attacks at a distance from the boundary, or those misclassified into low-confidence categories by targeted attacks. By adopting a straightforward approach of only considering AEs as inputs, the proposed method can address diverse attacks while avoiding the requirement of parameter adjustments or preliminary training. Results demonstrate that the proposed method exhibits consistent performance in rectifying AEs generated via various attack methods, including targeted and black-box attacks. Moreover, it outperforms conventional rectification and input transformation methods in terms of stability against various attacks.

</details>


### [5] [From Consensus to Chaos: A Vulnerability Assessment of the RAFT Algorithm](https://arxiv.org/abs/2601.00273)
*Tamer Afifi,Abdelfatah Hegazy,Ehab Abousaif*

Main category: cs.CR

TL;DR: 对RAFT分布式共识算法进行系统性安全分析，发现其易受消息重放和伪造攻击，提出基于密码学、认证消息验证和新鲜度检查的解决方案。


<details>
  <summary>Details</summary>
Motivation: RAFT算法虽然以简单、可靠和高效著称，但其安全属性未得到充分认识，实现中存在多种攻击漏洞，可能导致数据不一致性。

Method: 对RAFT协议进行系统性安全分析，重点关注消息重放和伪造攻击，通过模拟场景检验攻击可行性，识别RAFT设计中的关键弱点。

Result: 发现恶意攻击者可以利用RAFT的消息传递机制重新引入旧消息，破坏共识过程并导致数据不一致，验证了这些攻击的实际可行性。

Conclusion: 提出基于密码学、认证消息验证和新鲜度检查的新方法，为增强RAFT实现的安全性提供框架，指导开发更具弹性的分布式系统。

Abstract: In recent decades, the RAFT distributed consensus algorithm has become a main pillar of the distributed systems ecosystem, ensuring data consistency and fault tolerance across multiple nodes. Although the fact that RAFT is well known for its simplicity, reliability, and efficiency, its security properties are not fully recognized, leaving implementations vulnerable to different kinds of attacks and threats, which can transform the RAFT harmony of consensus into a chaos of data inconsistency. This paper presents a systematic security analysis of the RAFT protocol, with a specific focus on its susceptibility to security threats such as message replay attacks and message forgery attacks. Examined how a malicious actor can exploit the protocol's message-passing mechanism to reintroduce old messages, disrupting the consensus process and leading to data inconsistency. The practical feasibility of these attacks is examined through simulated scenarios, and the key weaknesses in RAFT's design that enable them are identified. To address these vulnerabilities, a novel approach based on cryptography, authenticated message verification, and freshness check is proposed. This proposed solution provides a framework for enhancing the security of the RAFT implementations and guiding the development of more resilient distributed systems.

</details>


### [6] [Making Theft Useless: Adulteration-Based Protection of Proprietary Knowledge Graphs in GraphRAG Systems](https://arxiv.org/abs/2601.00274)
*Weijie Wang,Peizhuo Lv,Yan Wang,Rujie Dai,Guokun Xu,Qiujian Lv,Hangcheng Liu,Weiqing Huang,Wei Dong,Jiaheng Zhang*

Main category: cs.CR

TL;DR: AURA框架通过数据掺假保护知识图谱，对未授权用户降低准确率至5.3%，对授权用户保持100%准确性


<details>
  <summary>Details</summary>
Motivation: 知识图谱作为组织重要知识产权面临被盗风险，传统水印技术需要输出访问检测，而强加密又因延迟过高不适用于GraphRAG场景

Method: 基于数据掺假技术，预先向知识图谱注入看似合理但虚假的掺假数据，授权用户通过密钥和加密元数据标签高效过滤这些掺假数据

Result: AURA将未授权系统性能降低至仅5.3%准确率，同时为授权用户保持100%保真度，且能抵抗各种清理尝试，保留80.2%的掺假数据

Conclusion: AURA框架有效解决了知识图谱在GraphRAG应用中的安全保护问题，在低延迟要求下实现了强大的知识产权保护

Abstract: Graph Retrieval-Augmented Generation (GraphRAG) has emerged as a key technique for enhancing Large Language Models (LLMs) with proprietary Knowledge Graphs (KGs) in knowledge-intensive applications. As these KGs often represent an organization's highly valuable intellectual property (IP), they face a significant risk of theft for private use. In this scenario, attackers operate in isolated environments. This private-use threat renders passive defenses like watermarking ineffective, as they require output access for detection. Simultaneously, the low-latency demands of GraphRAG make strong encryption which incurs prohibitive overhead impractical. To address these challenges, we propose AURA, a novel framework based on Data Adulteration designed to make any stolen KG unusable to an adversary. Our framework pre-emptively injects plausible but false adulterants into the KG. For an attacker, these adulterants deteriorate the retrieved context and lead to factually incorrect responses. Conversely, for authorized users, a secret key enables the efficient filtering of all adulterants via encrypted metadata tags before they are passed to the LLM, ensuring query results remain completely accurate. Our evaluation demonstrates the effectiveness of this approach: AURA degrades the performance of unauthorized systems to an accuracy of just 5.3%, while maintaining 100% fidelity for authorized users with negligible overhead. Furthermore, AURA proves robust against various sanitization attempts, retaining 80.2% of its adulterants.

</details>


### [7] [PQC standards alternatives -- reliable semantically secure key encapsulation mechanism and digital signature protocols using the rank-deficient matrix power function](https://arxiv.org/abs/2601.00332)
*Juan Pedro Hecht,Hugo Daniel Scolnik*

Main category: cs.CR

TL;DR: 该研究提出新型后量子密码协议，包括密钥封装机制和数字签名方案，特别防护线性攻击，旨在为TLS 1.3协议提供紧凑、快速、安全的替代方案，实现平滑的后量子过渡以应对"现在收集，将来解密"威胁。


<details>
  <summary>Details</summary>
Motivation: 应对量子计算对现有公钥密码的威胁，开发能够抵御经典和量子计算攻击的密码原语，为TLS 1.3协议提供可靠的后量子替代方案，保护当前数据免受"现在收集，将来解密"攻击。

Method: 提出新型后量子密码协议：1) 密钥封装机制(KEM)；2) 数字签名方案；3) 特别针对线性攻击的防护机制。这些协议旨在替代TLS 1.3中的密钥交换和数字签名组件。

Result: 开发出紧凑、快速且安全的密码协议，能够作为TLS 1.3协议中现有组件的直接替代品，实现平滑的后量子过渡，同时提供针对线性攻击的特殊保护。

Conclusion: 该研究为后量子密码学提供了实用的解决方案，能够保护互联网通信免受量子计算威胁，特别是应对"现在收集，将来解密"的攻击模式，确保当前加密数据在未来量子计算机出现时仍然安全。

Abstract: Post-quantum cryptography-PQC- aims to develop public-key primitives that are secure against adversaries using classical and quantum computing technologies. This study introduces novel protocols, a key encapsulation mechanism, a digital signature scheme, and special protection against linear attacks. Our purpose is to create reliable alternatives to current standards, seeking compact, fast, and secure replacements of the key interchange and digital signature in the TLS 1_3 protocol, which safeguards Internet traffic, allowing an easy post-quantum transition to protect current data from the harvest now, decrypt later threat.

</details>


### [8] [Applications of Secure Multi-Party Computation in Financial Services](https://arxiv.org/abs/2601.00334)
*Brahim Khalil Sedraoui,Abdelmadjid Benmachiche,Amina Makhlouf,Chaouki Chemam*

Main category: cs.CR

TL;DR: 本文探讨了安全多方计算（SMPC）在金融服务中的应用，分析了其在隐私保护、可扩展性和计算效率方面的挑战，并提出了未来研究方向。


<details>
  <summary>Details</summary>
Motivation: 随着金融服务日益数字化，隐私保护需求日益增长。各利益相关方需要遵守严格的安全和监管标准，同时进行敏感金融数据分析而不侵犯参与者隐私。

Method: 文章通过分析SMPC在金融服务中的应用，讨论了该技术面临的主要问题，包括可扩展性、计算效率和处理大规模数据集的能力。

Result: 研究结果表明，SMPC能够促进安全、透明和可信的金融交易，在日益数字化的生态系统中具有重要应用潜力。

Conclusion: SMPC在金融服务中具有重要价值，但需要进一步研究解决可扩展性和效率问题，使其协议更加实用和高效。

Abstract: The concept of Secure Multi-Party Computation (SMPC) is a cryptographic service that allows generating analysis of sensitive data related to finance under the collaboration of all stakeholders without violating the privacy of the research participants. This article shows the increasing significance of privacy protection in the contemporary financial services, where various stakeholders should comply with stringent security and regulatory standards. It discusses the main issues of scalability, computational efficiency, and working with very large datasets, and it identifies the directions of future research to make SMPC protocols more practical and efficient. The results highlight the possibility of SMPC to facilitate safe, transparent, and trustful financial transactions in an ecosystem that is becoming more digital.

</details>


### [9] [Diamond: Design and Implementation of Breach-Resilient Authenticated Encryption Framework For Internet of Things](https://arxiv.org/abs/2601.00353)
*Saif E. Nouma,Gokhan Mumcu,Attila A. Yavuz*

Main category: cs.CR

TL;DR: Diamond是首个可证明安全的向前安全聚合认证加密框架，专为资源受限的物联网设备设计，通过轻量级密钥演进机制和离线-在线优化管道，显著提升吞吐量并降低延迟。


<details>
  <summary>Details</summary>
Motivation: 现有轻量级认证加密标准缺乏向前安全性保证、紧凑标签聚合和离线-在线优化，无法满足现代高吞吐量物联网管道需求。资源受限的物联网设备需要在对抗性无线信道中传输敏感遥测数据，同时受限于严格的计算和能源预算。

Method: 提出Diamond框架，包含：1）轻量级密钥演进机制；2）离线-在线优化计算管道；3）针对异构物联网平台的性能分层实例化。框架通过形式化证明安全性，并提供两种具体实例化（合规性和高效率优化）。

Result: Diamond显著减少离线预处理开销（高达47%），在大批量遥测数据中端到端延迟降低一个数量级。在64位ARM Cortex-A72、32位ARM Cortex-M4和8位AVR架构上的评估显示，Diamond在认证加密吞吐量和端到端验证延迟方面持续优于基线FAAE变体和NIST轻量级AE候选方案。

Conclusion: Diamond是首个可证明安全的向前安全聚合认证加密框架，通过创新设计解决了物联网设备在资源受限环境下的安全通信需求，在保持紧凑标签聚合和强破坏恢复能力的同时，显著提升了性能表现。

Abstract: Resource-constrained Internet of Things (IoT) devices, from medical implants to small drones, must transmit sensitive telemetry under adversarial wireless channels while operating under stringent computing and energy budgets. Authenticated Encryption (AE) is essential for ensuring confidentiality, integrity, and authenticity. However, existing lightweight AE standards lack forward-security guarantees, compact tag aggregation, and offline-online (OO) optimizations required for modern high-throughput IoT pipelines.
  We introduce Diamond, the first provable secure Forward-secure and Aggregate Authenticated Encryption (FAAE) framework that extends and generalizes prior FAAE constructions through a lightweight key evolution mechanism, an OO-optimized computation pipeline, and a set of performance-tiered instantiations tailored to heterogeneous IoT platforms. Diamond substantially reduces amortized offline preprocessing (up to 47%) and achieves up to an order-ofmagnitude reduction in end-to-end latency for large telemetry batches. Our comprehensive evaluation across 64-bit ARM Cortex-A72, 32-bit ARM Cortex-M4, and 8-bit AVR architectures confirms that Diamond consistently outperforms baseline FAAE variants and NIST lightweight AE candidates across authenticated encryption throughput and end-to-end verification latency while maintaining compact tag aggregation and strong breach resilience. We formally prove the security of Diamond and provide two concrete instantiations optimized for compliance and high efficiency. Our open-source release enables reproducibility and seamless integration into IoT platforms.

</details>


### [10] [Traffic-MoE: A Sparse Foundation Model for Network Traffic Analysis](https://arxiv.org/abs/2601.00357)
*Jiajun Zhou,Changhui Sun,Meng Shen,Shanqing Yu,Qi Xuan*

Main category: cs.CR

TL;DR: Traffic-MoE是一个稀疏基础模型，通过动态路由流量令牌到少量专家，在保持高性能的同时大幅提升推理效率，适用于实时网络防御环境。


<details>
  <summary>Details</summary>
Motivation: 预训练大模型在网络流量分析中性能优异，但计算成本过高，难以部署到实时、高吞吐量的网络防御环境中，需要平衡先进表示学习与实际部署需求。

Method: 引入Traffic-MoE稀疏基础模型，采用动态路由机制将流量令牌分配到少量专门专家，解耦模型容量与计算开销，优化高效实时推理。

Result: 在三个安全任务中，Traffic-MoE检测性能比领先密集模型提升12.38%，吞吐量增加91.62%，推理延迟降低47.81%，GPU峰值内存消耗减少38.72%，且对抗流量整形鲁棒性更强，少样本场景下保持高效检测。

Conclusion: Traffic-MoE为可扩展、鲁棒的网络流量分析建立了新范式，成功弥合了先进表示学习与实际网络保护之间的鸿沟，实现了高性能与高效率的平衡。

Abstract: While pre-trained large models have achieved state-of-the-art performance in network traffic analysis, their prohibitive computational costs hinder deployment in real-time, throughput-sensitive network defense environments. This work bridges the gap between advanced representation learning and practical network protection by introducing Traffic-MoE, a sparse foundation model optimized for high-efficiency real-time inference. By dynamically routing traffic tokens to a small subset of specialized experts, Traffic-MoE effectively decouples model capacity from computational overhead. Extensive evaluations across three security-oriented tasks demonstrate that Traffic-MoE achieves up to a 12.38% improvement in detection performance compared to leading dense competitors. Crucially, it delivers a 91.62% increase in throughput, reduces inference latency by 47.81%, and cuts peak GPU memory consumption by 38.72%. Beyond efficiency, Traffic-MoE exhibits superior robustness against adversarial traffic shaping and maintains high detection efficacy in few-shot scenarios, establishing a new paradigm for scalable and resilient network traffic analysis.

</details>


### [11] [PatchBlock: A Lightweight Defense Against Adversarial Patches for Embedded EdgeAI Devices](https://arxiv.org/abs/2601.00367)
*Nandish Chattopadhyay,Abdul Basit,Amira Guesmi,Muhammad Abdullah Hanif,Bassem Ouni,Muhammad Shafique*

Main category: cs.CR

TL;DR: PatchBlock：针对EdgeAI应用的轻量级对抗补丁防御框架，通过分块、异常检测和降维三阶段流程，在CPU上并行运行以保护GPU推理性能，能恢复高达77%的模型准确率。


<details>
  <summary>Details</summary>
Motivation: 对抗攻击特别是补丁式攻击对EdgeAI应用（如自动驾驶、监控）构成严重威胁，这些攻击通过小恶意补丁欺骗神经网络，可能导致严重后果。现有防御方法在资源受限的边缘设备上效率不足。

Method: PatchBlock采用三阶段流水线：1) 分块（Chunking）：将输入图像分割成块；2) 分离（Separating）：使用改进的隔离森林算法快速检测异常区域；3) 缓解（Mitigating）：对识别出的异常区域应用降维技术。框架作为传感器级的预处理模块，在CPU上并行运行，避免GPU开销。

Result: 在多种神经网络架构、基准数据集、攻击类型和边缘设备上的评估显示，PatchBlock能恢复高达77%的模型准确率（针对Google对抗补丁等强攻击），同时保持高可移植性和最小的干净准确率损失。在计算时间和能耗方面优于现有最先进防御方法。

Conclusion: PatchBlock是一个模型无关、补丁无关的轻量级防御框架，可轻松集成到现有系统中，在保持系统吞吐量的同时显著提升EdgeAI应用对对抗补丁攻击的鲁棒性，适合资源受限的边缘设备部署。

Abstract: Adversarial attacks pose a significant challenge to the reliable deployment of machine learning models in EdgeAI applications, such as autonomous driving and surveillance, which rely on resource-constrained devices for real-time inference. Among these, patch-based adversarial attacks, where small malicious patches (e.g., stickers) are applied to objects, can deceive neural networks into making incorrect predictions with potentially severe consequences. In this paper, we present PatchBlock, a lightweight framework designed to detect and neutralize adversarial patches in images. Leveraging outlier detection and dimensionality reduction, PatchBlock identifies regions affected by adversarial noise and suppresses their impact. It operates as a pre-processing module at the sensor level, efficiently running on CPUs in parallel with GPU inference, thus preserving system throughput while avoiding additional GPU overhead. The framework follows a three-stage pipeline: splitting the input into chunks (Chunking), detecting anomalous regions via a redesigned isolation forest with targeted cuts for faster convergence (Separating), and applying dimensionality reduction on the identified outliers (Mitigating). PatchBlock is both model- and patch-agnostic, can be retrofitted to existing pipelines, and integrates seamlessly between sensor inputs and downstream models. Evaluations across multiple neural architectures, benchmark datasets, attack types, and diverse edge devices demonstrate that PatchBlock consistently improves robustness, recovering up to 77% of model accuracy under strong patch attacks such as the Google Adversarial Patch, while maintaining high portability and minimal clean accuracy loss. Additionally, PatchBlock outperforms the state-of-the-art defenses in efficiency, in terms of computation time and energy consumption per sample, making it suitable for EdgeAI applications.

</details>


### [12] [Ouroboros AutoSyn: Time Based Permissionless Synchrony Model for PoS](https://arxiv.org/abs/2601.00370)
*Joshua Shen*

Main category: cs.CR

TL;DR: 提出一种基于实时而非参与者状态的轮次模型，通过连接真实世界时钟计算当前轮次，并根据网络状况动态调整轮次长度，减少对中心时钟的依赖


<details>
  <summary>Details</summary>
Motivation: PoS协议在无许可环境中实现动态可用性，但严重依赖中心时钟来同步所有诚实参与者的完成状态。现有协议需要全局函数维护每个参与者的轮次信息，存在依赖性问题

Method: 分析和修改轮次模型为基于实时时间的模型，考虑消息传递延迟，参与者连接真实世界全局时钟计算当前轮次，并在每个新纪元开始时根据网络状况调整轮次长度

Result: 不再需要全局函数维护每个参与者的轮次信息，协议减少了中心时钟的依赖，实现了更灵活的轮次管理

Conclusion: 通过基于实时时间的轮次模型和动态调整机制，改进了PoS协议的同步机制，降低了中心化依赖，提高了协议在动态网络环境中的适应性

Abstract: Blockchain as a promising technology is gaining its popularity ever since proof-of-work based Bitcoin came to the world. Nevertheless, Bitcoin achieves consensus at an expensive cost of energy. Proof-of-stake is one of the solutions for such a problem. Participants of PoS protocols achieve dynamic-availability in permissionless settings. Parties can join and leave the protocol at their will without notifying others. However, such protocol relies heavily on a central clock, providing the function of synchrony by collecting the finish status of every honest participant.
  In our protocol, the global function maintains the round information for each participant no longer needed. We analyze and modify the round into real-time based round model. Message delivery delay is also taken into consideration of the round length. However, participant need the connection of a real-world time global clock which is crucial to calculate the current round. And round length also is adjusted due to the changing network situation at the start of every new epoch.

</details>


### [13] [LLM-Powered Analysis of IoT User Reviews: Tracking and Ranking Security and Privacy Concerns](https://arxiv.org/abs/2601.00372)
*Taufiq Islam Protick,Sai Teja Peddinti,Nina Taft,Anupam Das*

Main category: cs.CR

TL;DR: 利用GPT-3.5-Turbo构建自动化管道分析亚马逊IoT评论中的安全隐私关切，发现平均5%评论涉及S&P问题，智能摄像头最高达10%，检测效果远超传统方法


<details>
  <summary>Details</summary>
Motivation: 理解IoT用户的安全隐私关切对开发者和用户都有益，通过分析亚马逊IoT评论这一最大IoT市场来了解用户观点

Method: 开发自动化管道，微调GPT-3.5-Turbo构建两个模型：分类器-合理化器-分类器和主题映射器，利用动态少样本提示和大上下文窗口，应用于91K条亚马逊健身追踪器、智能音箱和摄像头评论

Result: 管道达到超过97%的精确率和召回率，显著优于基于关键词和传统ML方法；平均5%评论包含S&P关切，摄像头最高达10%；检测到比先前工作多15倍（健身追踪器）、29%（智能音箱）和70%（摄像头）的S&P相关评论

Conclusion: 纵向分析显示监控和数据控制等关切持续多年，行业进展有限；用户普遍要求更精确的数据收集和共享控制；发现多用户多设备交互中的新问题，包括账户分离和数据访问控制不足；为开发者提供改进用户满意度和信任的可操作见解

Abstract: Being able to understand the security and privacy (S&P) concerns of IoT users brings benefits to both developers and users. To learn about users' views, we examine Amazon IoT reviews - one of the biggest IoT markets. This work presents a state-of-the-art methodology to identify and categorize reviews in which users express S&P concerns. We developed an automated pipeline by fine-tuning GPT-3.5-Turbo to build two models: the Classifier-Rationalizer-Categorizer and the Thematic Mapper. By leveraging dynamic few-shot prompting and the model's large context size, our pipeline achieved over 97% precision and recall, significantly outperforming keyword-based and classical ML methods. We applied our pipeline to 91K Amazon reviews about fitness trackers, smart speakers and cameras, over multiple years. We found that on average 5% contained S&P concerns, while security camera exhibited the highest prevalence at 10%. Our method detected significantly more S&P-relevant reviews than prior works: 15x more for fitness trackers, 29% more for smart speakers, and 70% more for cameras. Our longitudinal analysis reveals that concerns like surveillance and data control have persisted for years, suggesting limited industry progress. We demonstrate that across all device types, users consistently demand more precise control over what data is collected and shared. We uncover challenges in multi-user and multi-device interactions, identifying two previously unreported themes concerning inadequate controls for account separation and data access. These findings, ranging from broad persistent trends to specific instances of customer loss, offer actionable insights for developers to improve user satisfaction and trust.

</details>


### [14] [Engineering Attack Vectors and Detecting Anomalies in Additive Manufacturing](https://arxiv.org/abs/2601.00384)
*Md Mahbub Hasan,Marcus Sternhagen,Krishna Chandra Roy*

Main category: cs.CR

TL;DR: 研究针对FDM 3D打印系统的中间人攻击，提出基于Transformer编码器和对比学习的无监督入侵检测系统


<details>
  <summary>Details</summary>
Motivation: 增材制造在关键领域应用日益广泛，但CAD与机器执行层之间的接口引入了新的攻击面，传统切片软件和运行时接口无法检测中间人攻击导致的隐蔽破坏

Method: 1) 研究Creality K1 Max和Ender 3 FDM系统的多层中间人攻击模型；2) 提出基于冻结Transformer编码器提取语义特征，结合对比学习投影头获得异常敏感嵌入，最后使用聚类和自注意力自编码器进行分类的无监督入侵检测系统

Result: 实验结果表明，该方法能有效区分正常和受攻击的执行过程，检测中间人攻击导致的隐蔽破坏

Conclusion: 增材制造系统面临中间人攻击威胁，提出的无监督入侵检测系统能有效检测这些隐蔽攻击，保障3D打印安全

Abstract: Additive manufacturing (AM) is rapidly integrating into critical sectors such as aerospace, automotive, and healthcare. However, this cyber-physical convergence introduces new attack surfaces, especially at the interface between computer-aided design (CAD) and machine execution layers. In this work, we investigate targeted cyberattacks on two widely used fused deposition modeling (FDM) systems, Creality's flagship model K1 Max, and Ender 3. Our threat model is a multi-layered Man-in-the-Middle (MitM) intrusion, where the adversary intercepts and manipulates G-code files during upload from the user interface to the printer firmware. The MitM intrusion chain enables several stealthy sabotage scenarios. These attacks remain undetectable by conventional slicer software or runtime interfaces, resulting in structurally defective yet externally plausible printed parts. To counter these stealthy threats, we propose an unsupervised Intrusion Detection System (IDS) that analyzes structured machine logs generated during live printing. Our defense mechanism uses a frozen Transformer-based encoder (a BERT variant) to extract semantic representations of system behavior, followed by a contrastively trained projection head that learns anomaly-sensitive embeddings. Later, a clustering-based approach and a self-attention autoencoder are used for classification. Experimental results demonstrate that our approach effectively distinguishes between benign and compromised executions.

</details>


### [15] [Exploring the Integration of Differential Privacy in Cybersecurity Analytics: Balancing Data Utility and Privacy in Threat Intelligence](https://arxiv.org/abs/2601.00385)
*Brahim Khalil Sedraoui,Abdelmadjid Benmachiche,Amina Makhlouf,Chaouki Chemam*

Main category: cs.CR

TL;DR: 本文探讨在网络安全分析中应用差分隐私技术，以解决隐私保护与威胁情报数据使用的矛盾，通过在SIEM系统中实施DP来保护事件日志和威胁数据，同时保持分析效率。


<details>
  <summary>Details</summary>
Motivation: 解决隐私保护与威胁情报数据使用之间的尖锐矛盾，确保在网络安全分析中既能保护敏感信息又能有效利用数据。

Method: 在网络安全分析中实施差分隐私框架，特别是在安全信息与事件管理系统中应用DP技术，通过添加可控噪声来保护数据输出。

Result: DP能够有效保护事件日志和威胁数据分析而不干扰分析效率，通过实际系统和案例研究展示了DP在促进安全数据共享和联合威胁情报方面的变革性力量。

Conclusion: 差分隐私应成为提升网络安全领域隐私保护分析能力的关键策略，通过平衡效用与隐私的权衡来实现安全的数据共享和威胁情报协作。

Abstract: To resolve the acute problem of privacy protection and guarantee that data can be used in the context of threat intelligence, this paper considers the implementation of Differential Privacy (DP) in cybersecurity analytics. DP, which is a sound mathematical framework, ensures privacy by adding a controlled noise to data outputs and thus avoids sensitive information disclosure even with auxiliary datasets. The use of DP in Security Information and Event Management (SIEM) systems is highlighted, and it can be seen that DP has the capability to protect event log and threat data analysis without interfering with the analytical efficiency. The utility versus privacy trade-offs linked to the maximization of the epsilon parameter, which is one of the critical components of DP mechanisms, is pointed out. The article shows the transformative power of DP in promoting safe sharing of data and joint threat intelligence through real-world systems and case studies. Finally, this paper makes DP one of the key strategies to improve privacy-preserving analytics in the field of cybersecurity.

</details>


### [16] [NOS-Gate: Queue-Aware Streaming IDS for Consumer Gateways under Timing-Controlled Evasion](https://arxiv.org/abs/2601.00389)
*Muhammad Bilal,Omer Tariq,Hasan Ahmed*

Main category: cs.CR

TL;DR: NOS-Gate：一种用于独立网关的流式入侵检测系统，利用轻量级双状态单元分析加密流量元数据，通过可逆缓解机制降低恶意流权重，在低CPU开销下实现高检测率。


<details>
  <summary>Details</summary>
Motivation: 加密流量的时序和突发模式可能泄露信息，自适应攻击者可以利用这些信息绕过检测。独立消费者网关需要在严格的CPU和延迟预算下，仅使用元数据进行流式入侵检测。

Method: 提出NOS-Gate系统，为每个流实例化基于网络优化尖峰动力学的轻量级双状态单元。系统对固定长度窗口的元数据特征进行评分，在K-of-M持续规则下触发可逆缓解机制，临时降低该流在加权公平队列中的权重。

Result: 在0.1%误报率下，NOS-Gate达到0.952的事件召回率，优于基线方法的0.857。在门控机制下，显著降低了p99.9排队延迟和p99.9附带延迟，平均每个流窗口的评分成本仅为~2.09μs。

Conclusion: NOS-Gate为独立网关提供了一种高效、低开销的加密流量元数据流式入侵检测方案，在保持低CPU开销的同时实现了高检测性能。

Abstract: Timing and burst patterns can leak through encryption, and an adaptive adversary can exploit them. This undermines metadata-only detection in a stand-alone consumer gateway. Therefore, consumer gateways need streaming intrusion detection on encrypted traffic using metadata only, under tight CPU and latency budgets. We present a streaming IDS for stand-alone gateways that instantiates a lightweight two-state unit derived from Network-Optimised Spiking (NOS) dynamics per flow, named NOS-Gate. NOS-Gate scores fixed-length windows of metadata features and, under a $K$-of-$M$ persistence rule, triggers a reversible mitigation that temporarily reduces the flow's weight under weighted fair queueing (WFQ). We evaluate NOS-Gate under timing-controlled evasion using an executable 'worlds' benchmark that specifies benign device processes, auditable attacker budgets, contention structure, and packet-level WFQ replay to quantify queue impact. All methods are calibrated label-free via burn-in quantile thresholding. Across multiple reproducible worlds and malicious episodes, at an achieved $0.1%$ false-positive operating point, NOS-Gate attains 0.952 incident recall versus 0.857 for the best baseline in these runs. Under gating, it reduces p99.9 queueing delay and p99.9 collateral delay with a mean scoring cost of ~ 2.09 μs per flow-window on CPU.

</details>


### [17] [Secure, Verifiable, and Scalable Multi-Client Data Sharing via Consensus-Based Privacy-Preserving Data Distribution](https://arxiv.org/abs/2601.00418)
*Prajwal Panth,Sahaj Raj Malla*

Main category: cs.CR

TL;DR: CPPDD是一个轻量级、后设置自主的安全多方数据聚合协议，通过双层保护机制实现一致释放保密性，支持标量、向量和矩阵负载，具有线性可扩展性和抗合谋能力。


<details>
  <summary>Details</summary>
Motivation: 解决现有安全多方计算方案在可扩展性、信任最小化和可验证性方面的关键缺陷，特别是在受监管和资源受限环境中，需要支持安全投票、联盟联邦学习、区块链托管等原子协作应用。

Method: 采用双层保护机制：每客户端仿射掩码与优先级驱动的顺序共识锁定相结合。通过步骤校验和（sigma_S）与数据校验和（sigma_D）实现去中心化完整性验证，支持自主恶意偏差检测和原子中止。支持标量、向量和矩阵负载，计算和通信复杂度为O(N*D)，可选择边缘服务器卸载。

Result: 在MNIST派生向量上的实证评估显示，CPPDD在N=500时具有线性可扩展性，每客户端计算时间低于毫秒级。实现100%恶意偏差检测和精确数据恢复，相比MPC和HE基线减少3-4个数量级的FLOPs。形式化分析证明正确性、共识依赖完整性与公平性（CDIF），以及在偏差时以压倒性概率中止，假设伪随机函数族下具有IND-CPA安全性。

Conclusion: CPPDD框架为安全多方数据聚合提供了一种轻量级、可扩展且抗合谋的解决方案，填补了现有方案在可扩展性、信任最小化和可验证性方面的关键空白，特别适用于受监管和资源受限环境中的原子协作应用。

Abstract: We propose the Consensus-Based Privacy-Preserving Data Distribution (CPPDD) framework, a lightweight and post-setup autonomous protocol for secure multi-client data aggregation. The framework enforces unanimous-release confidentiality through a dual-layer protection mechanism that combines per-client affine masking with priority-driven sequential consensus locking. Decentralized integrity is verified via step (sigma_S) and data (sigma_D) checksums, facilitating autonomous malicious deviation detection and atomic abort without requiring persistent coordination. The design supports scalar, vector, and matrix payloads with O(N*D) computation and communication complexity, optional edge-server offloading, and resistance to collusion under N-1 corruptions. Formal analysis proves correctness, Consensus-Dependent Integrity and Fairness (CDIF) with overwhelming-probability abort on deviation, and IND-CPA security assuming a pseudorandom function family. Empirical evaluations on MNIST-derived vectors demonstrate linear scalability up to N = 500 with sub-millisecond per-client computation times. The framework achieves 100% malicious deviation detection, exact data recovery, and three-to-four orders of magnitude lower FLOPs compared to MPC and HE baselines. CPPDD enables atomic collaboration in secure voting, consortium federated learning, blockchain escrows, and geo-information capacity building, addressing critical gaps in scalability, trust minimization, and verifiable multi-party computation for regulated and resource-constrained environments.

</details>


### [18] [Security in the Age of AI Teammates: An Empirical Study of Agentic Pull Requests on GitHub](https://arxiv.org/abs/2601.00477)
*Mohammed Latif Siddiq,Xinye Zhao,Vinicius Carvalho Lopes,Beatrice Casey,Joanna C. S. Santos*

Main category: cs.CR

TL;DR: 对33,000多个自主编码代理生成的PR进行大规模实证分析，发现约4%涉及安全，主要进行安全加固而非漏洞修复，安全相关PR合并率更低、审查时间更长，PR复杂度比安全主题更影响拒绝率。


<details>
  <summary>Details</summary>
Motivation: 随着自主编码代理在软件工程中作为AI队友被广泛部署，独立编写修改生产代码的PR，需要系统研究这些代理如何实际影响软件安全、安全相关贡献如何被审查接受，以及哪些信号与PR拒绝相关。

Method: 使用AIDev数据集分析33,000多个PR，通过关键词过滤识别安全相关PR并手动验证得到1,293个确认案例。分析流行度、接受结果和审查延迟，应用定性开放编码识别安全相关行动和意图，检查审查元数据识别PR拒绝的早期信号。

Result: 安全相关Agentic-PR占代理活动的约4%，主要进行安全加固活动（测试、文档、配置、错误处理改进）。相比非安全PR，安全相关PR合并率更低、审查延迟更长，反映更高的人工审查强度。PR拒绝与PR复杂度和冗长度关联更强，而非明确的安全主题。

Conclusion: 自主编码代理在软件安全中扮演重要角色，主要进行安全加固而非漏洞修复。安全相关PR受到更严格审查，但拒绝主要源于复杂性和冗长度而非安全内容本身，为改进代理设计和审查流程提供见解。

Abstract: Autonomous coding agents are increasingly deployed as AI teammates in modern software engineering, independently authoring pull requests (PRs) that modify production code at scale. This study aims to systematically characterize how autonomous coding agents contribute to software security in practice, how these security-related contributions are reviewed and accepted, and which observable signals are associated with PR rejection. We conduct a large-scale empirical analysis of agent-authored PRs using the AIDev dataset, comprising of over 33,000 curated PRs from popular GitHub repositories. Security-relevant PRs are identified using a keyword filtering strategy, followed by manual validation, resulting in 1,293 confirmed security-related agentic-PRs. We then analyze prevalence, acceptance outcomes, and review latency across autonomous agents, programming ecosystems, and types of code changes. Moreover, we apply qualitative open coding to identify recurring security-related actions and underlying intents, and examine review metadata to identify early signals associated with PR rejection. Security-related Agentic-PRs constitute a meaningful share of agent activity (approximately 4\%). Rather than focusing solely on narrow vulnerability fixes, agents most frequently perform supportive security hardening activities, including testing, documentation, configuration, and improved error handling. Compared to non-security PRs, security-related Agentic-PRs exhibit lower merge rates and longer review latency, reflecting heightened human scrutiny, with variation across agents and programming ecosystems. PR rejection is more strongly associated with PR complexity and verbosity than with explicit security topics.

</details>


### [19] [Improving LLM-Assisted Secure Code Generation through Retrieval-Augmented-Generation and Multi-Tool Feedback](https://arxiv.org/abs/2601.00509)
*Vidyut Sriram,Sawan Pandita,Achintya Lakshmanan,Aneesh Shamraj,Suman Saha*

Main category: cs.CR

TL;DR: 论文提出了一种检索增强的多工具修复工作流，通过编译器诊断、CodeQL安全扫描和KLEE符号执行，让单个代码生成LLM迭代优化其输出，显著减少了代码中的安全漏洞和缺陷。


<details>
  <summary>Details</summary>
Motivation: 大型语言模型生成的代码常存在安全漏洞、逻辑不一致和编译错误。虽然已有研究表明结构化反馈、静态分析、检索增强和执行优化对LLM有帮助，但需要一种更系统的方法来提升生成代码的健壮性。

Method: 提出检索增强的多工具修复工作流：1）使用轻量级嵌入模型进行语义检索，获取先前成功的修复示例；2）让单个代码生成LLM迭代优化输出；3）利用编译器诊断、CodeQL安全扫描和KLEE符号执行三种工具提供反馈；4）安全导向的示例引导代码生成。

Result: 在DeepSeek-Coder-1.3B和CodeLlama-7B生成的3,242个程序数据集上评估：DeepSeek的安全漏洞减少了96%；CodeLlama的关键安全缺陷率从58.55%降至22.19%。表明工具辅助的自我修复对"顽固"模型也有效。

Conclusion: 检索增强的多工具修复工作流能显著提升LLM生成代码的健壮性，即使对较大的"顽固"模型也能有效减少安全漏洞。工具辅助的自我修复是提高代码生成质量的有效方法。

Abstract: Large Language Models (LLMs) can generate code but often introduce security vulnerabilities, logical inconsistencies, and compilation errors. Prior work demonstrates that LLMs benefit substantially from structured feedback, static analysis, retrieval augmentation, and execution-based refinement. We propose a retrieval-augmented, multi-tool repair workflow in which a single code-generating LLM iteratively refines its outputs using compiler diagnostics, CodeQL security scanning, and KLEE symbolic execution. A lightweight embedding model is used for semantic retrieval of previously successful repairs, providing security-focused examples that guide generation. Evaluated on a combined dataset of 3,242 programs generated by DeepSeek-Coder-1.3B and CodeLlama-7B, the system demonstrates significant improvements in robustness. For DeepSeek, security vulnerabilities were reduced by 96%. For the larger CodeLlama model, the critical security defect rate was decreased from 58.55% to 22.19%, highlighting the efficacy of tool-assisted self-repair even on "stubborn" models.

</details>


### [20] [Cyberscurity Threats and Defense Mechanisms in IoT network](https://arxiv.org/abs/2601.00556)
*Trung Dao,Minh Nguyen,Son Do,Hoang Tran*

Main category: cs.CR

TL;DR: 这篇论文对物联网安全进行了全面调查，分析了漏洞、威胁和防御机制，重点关注网络与应用层集成，提出了五层物联网模型和未来研究方向。


<details>
  <summary>Details</summary>
Motivation: 物联网设备快速增长（预计2030年超过300亿台）带来了复杂的安全挑战，需要全面分析漏洞、威胁和防御机制，特别是在实时监控和决策系统中网络与应用层的集成安全。

Method: 采用综合综述方法，从IEEE Xplore、ScienceDirect和PubMed等数据库中选取了2009-2024年间发表的59篇学术文章，使用物联网漏洞和安全攻击相关关键词进行筛选分析。

Result: 识别出关键威胁类别：传感器漏洞、拒绝服务攻击和公共云不安全；同时突出了先进的防御方法：人工智能异常检测、区块链去中心化信任和零信任架构持续验证。

Conclusion: 论文提出了新颖的五层物联网模型，并指出了未来研究方向，包括量子计算和6G网络的应用，以增强物联网生态系统的韧性。

Abstract: The rapid proliferation of Internet of Things (IoT) technologies, projected to exceed 30 billion interconnected devices by 2030, has significantly escalated the complexity of cybersecurity challenges. This survey aims to provide a comprehensive analysis of vulnerabilities, threats, and defense mechanisms, specifically focusing on the integration of network and application layers within real-time monitoring and decision-making systems. Employing an integrative review methodology, 59 scholarly articles published between 2009 and 2024 were selected from databases such as IEEE Xplore, ScienceDirect, and PubMed, utilizing keywords related to IoT vulnerabilities and security attacks. Key findings identify critical threat categories, including sensor vulnerabilities, Denial-of-Service (DoS) attacks, and public cloud insecurity. Conversely, the study highlights advanced defense approaches leveraging Artificial Intelligence (AI) for anomaly detection, Blockchain for decentralized trust, and Zero Trust Architecture (ZTA) for continuous verification. This paper contributes a novel five-layer IoT model and outlines future research directions involving quantum computing and 6G networks to bolster IoT ecosystem resilience.

</details>


### [21] [Cracking IoT Security: Can LLMs Outsmart Static Analysis Tools?](https://arxiv.org/abs/2601.00559)
*Jason Quantrill,Noura Khajehnouri,Zihan Guo,Manar H. Alalfi*

Main category: cs.CR

TL;DR: LLMs在IoT规则交互威胁检测中表现有限，语义理解尚可但结构推理不足，符号推理方法更稳定可靠


<details>
  <summary>Details</summary>
Motivation: 智能家居IoT平台中的TAC规则交互可能产生安全威胁，传统符号推理方法依赖静态分析，需要评估LLMs在此任务上的表现

Method: 在多类别交互威胁分类上全面评估LLMs，使用原始openHAB数据集和结构挑战性的Mutation数据集，测试Llama 3.1 8B、Llama 70B、GPT-4o、Gemini-2.5-Pro和DeepSeek-R1在零样本、单样本和双样本设置下的表现

Result: LLMs在语义理解方面表现良好（特别是动作和条件相关威胁），但在需要跨规则结构推理的威胁上准确性显著下降，尤其在突变规则形式下。模型性能在不同威胁类别和提示设置间差异很大，没有模型能提供一致的可靠性。符号推理基线在两个数据集上都保持稳定检测

Conclusion: LLMs单独使用尚不可靠用于IoT环境中的安全关键交互威胁检测，需要结合符号分析和LLM语义解释的混合架构来减少误报同时保持结构严谨性

Abstract: Smart home IoT platforms such as openHAB rely on Trigger Action Condition (TAC) rules to automate device behavior, but the interplay among these rules can give rise to interaction threats, unintended or unsafe behaviors emerging from implicit dependencies, conflicting triggers, or overlapping conditions. Identifying these threats requires semantic understanding and structural reasoning that traditionally depend on symbolic, constraint-driven static analysis. This work presents the first comprehensive evaluation of Large Language Models (LLMs) across a multi-category interaction threat taxonomy, assessing their performance on both the original openHAB (oHC/IoTB) dataset and a structurally challenging Mutation dataset designed to test robustness under rule transformations. We benchmark Llama 3.1 8B, Llama 70B, GPT-4o, Gemini-2.5-Pro, and DeepSeek-R1 across zero-, one-, and two-shot settings, comparing their results against oHIT's manually validated ground truth. Our findings show that while LLMs exhibit promising semantic understanding, particularly on action- and condition-related threats, their accuracy degrades significantly for threats requiring cross-rule structural reasoning, especially under mutated rule forms. Model performance varies widely across threat categories and prompt settings, with no model providing consistent reliability. In contrast, the symbolic reasoning baseline maintains stable detection across both datasets, unaffected by rule rewrites or structural perturbations. These results underscore that LLMs alone are not yet dependable for safety critical interaction-threat detection in IoT environments. We discuss the implications for tool design and highlight the potential of hybrid architectures that combine symbolic analysis with LLM-based semantic interpretation to reduce false positives while maintaining structural rigor.

</details>


### [22] [Low Rank Comes with Low Security: Gradient Assembly Poisoning Attacks against Distributed LoRA-based LLM Systems](https://arxiv.org/abs/2601.00566)
*Yueyan Dong,Minghui Xu,Qin Hu,Yinhao Xiao,Qi Luo,Yechao Zhang,Yue Zhang,Xiuzhen Cheng*

Main category: cs.CR

TL;DR: 论文提出了一种针对联邦学习中LoRA微调的新型攻击方法GAP，通过分别构造看似正常的A和B矩阵，使其乘积产生恶意更新，从而在保持表面流畅性的同时降低模型性能。


<details>
  <summary>Details</summary>
Motivation: LoRA在联邦学习中被广泛用于降低大语言模型微调成本，但现有框架存在安全漏洞：客户端分别提交A和B矩阵，而只有它们的乘积AB决定模型更新，但这个复合结果从未被直接验证，为攻击提供了盲点。

Method: 提出梯度组装投毒攻击(GAP)，利用LoRA框架的漏洞，分别构造看似正常的A和B矩阵，使它们的乘积产生恶意更新。攻击无需访问训练数据或客户端间协调，能绕过标准异常检测器。

Result: 在LLaMA、ChatGLM和GPT-2上验证了GAP攻击的有效性：BLEU分数降低达14.5%，事实和语法错误增加超过800%，同时保持92.6%的长文本响应长度，攻击保持隐蔽且持久。

Conclusion: GAP攻击揭示了LoRA联邦学习系统中的系统性安全漏洞，这类隐蔽、持久的威胁需要新的防御机制来保护分布式微调过程。

Abstract: Low-Rank Adaptation (LoRA) has become a popular solution for fine-tuning large language models (LLMs) in federated settings, dramatically reducing update costs by introducing trainable low-rank matrices. However, when integrated with frameworks like FedIT, LoRA introduces a critical vulnerability: clients submit $A$ and $B$ matrices separately, while only their product $AB$ determines the model update, yet this composite is never directly verified. We propose Gradient Assembly Poisoning (GAP), a novel attack that exploits this blind spot by crafting individually benign $A$ and $B$ matrices whose product yields malicious updates. GAP operates without access to training data or inter-client coordination and remains undetected by standard anomaly detectors. We identify four systemic vulnerabilities in LoRA-based federated systems and validate GAP across LLaMA, ChatGLM, and GPT-2. GAP consistently induces degraded or biased outputs while preserving surface fluency, reducing BLEU by up to 14.5\%, increasing factual and grammatical errors by over 800\%, and maintaining 92.6\% long-form response length. These results reveal a new class of stealthy, persistent threats in distributed LoRA fine-tuning.

</details>


### [23] [Threat Intelligence Driven IP Protection for Entrepreneurial SMEs](https://arxiv.org/abs/2601.00571)
*Sam Pitruzzello,Atif Ahmad,Sean Maynard*

Main category: cs.CR

TL;DR: 本文提出威胁情报驱动的知识产权保护模型，帮助创业型中小企业整合网络安全威胁情报与IP保护实践，以在资源受限环境下保护知识产权资产。


<details>
  <summary>Details</summary>
Motivation: 创业型中小企业在开发有价值的知识产权时面临重大网络安全挑战，现有研究缺乏关于如何通过有效威胁情报和IP保护活动来保护IP资产的指导。

Method: 基于动态能力和知识基础观理论框架，提出威胁情报驱动的知识产权保护概念模型，采用定性研究方法，通过多案例研究验证和优化模型。

Result: 提出TI-IPP模型，包含封闭IP开发和开放式创新两种运作模式，以及感知机会与威胁、抓住机会、知识转移和组织转型四个关键阶段。

Conclusion: 通过整合网络安全威胁情报与IP保护实践，创业型中小企业可以发展保护有价值知识产权的能力，同时保持竞争优势，该模型为资源受限的创业环境提供了实用框架。

Abstract: Entrepreneurial small to medium enterprises face significant cybersecurity challenges when developing valuable intellectual property (IP). This paper addresses the critical gap in research on how E-SMEs can protect their IP assets from cybersecurity threats through effective threat intelligence and IP protection activities. Drawing on Dynamic Capabilities and Knowledge-Based View theoretical frameworks, we propose the Threat Intelligence-driven IP Protection (TI-IPP) model. This conceptual model features to modes of operation, closed IP development and open innovation, enabling E-SMEs to adapt their IP protection and knowledge management strategies. The model incorporates four key phases: sensing opportunities and threats, seizing opportunities, knowledge transfer, and organizational transformation. By integrating cybersecurity threat intelligence with IP protection practices, E-SMEs can develop capabilities to safeguard valuable IP while maintaining competitive advantage. This research-in-progress paper outlines a qualitative research methodology using multiple case studies to validate and refine the proposed model for practical application in resource-constrained entrepreneurial environments.

</details>


### [24] [Toward a Dynamic Intellectual Property Protection Model in High-Growth SMEs](https://arxiv.org/abs/2601.00572)
*Sam Pitruzzello,Sean Maynard,Atif Ahmad*

Main category: cs.CR

TL;DR: 本文探讨高增长中小企业如何在快速扩张中平衡知识产权保护与开放式创新，提出结合网络安全、IP保护和动态能力的理论框架。


<details>
  <summary>Details</summary>
Motivation: 高增长中小企业面临知识产权保护与开放式创新之间的紧张关系，特别是在资源有限、网络安全威胁增加的快速扩张期。现有文献对这一交叉领域研究不足，需要为这类企业提供实用指导。

Method: 基于动态能力理论、知识基础观和开放式创新理论构建概念框架，采用定性研究方法验证和完善该模型。

Result: 本文提出了一个指导高增长中小企业有效管理知识产权资产的概念框架，目前处于研究进行阶段，方法论已确定但实证结果尚未完成。

Conclusion: 通过解决高增长中小企业如何管理网络安全以保护知识产权资产的研究问题，本文旨在为技术驱动型公司在知识产权保护与协作创新之间提供实用指导。

Abstract: This paper addresses the challenges faced by High-Growth Small-to-Medium Enterprises (HG-SMEs) in balancing intellectual property (IP) protection with open innovation during periods of rapid growth. Despite developing valuable IP assets that drive success, HG-SMEs often struggle with cybersecurity concerns related to IP theft and data exfiltration amidst resource constraints and the competing demands of expansion. We examine the intersection of cybersecurity, IP protection and rapid scaling - an area currently underexplored in existing literature. Drawing on Dynamic Capabilities (DC), Knowledge-based View (KBV) and open innovation theoretical frameworks, we introduce a conceptual framework to guide HG-SMEs in effectively managing valuable IP assets. This research-in-progress paper outlines a qualitative methodology to validate and refine the model. By addressing the research question of how HG-SMEs manage cybersecurity to protect valuable IP assets, we aim to provide practical guidance for high-growth, technology-driven companies navigating the tension between robust IP protection and collaborative innovation.

</details>


### [25] [Towards Understanding and Characterizing Vulnerabilities in Intelligent Connected Vehicles through Real-World Exploits](https://arxiv.org/abs/2601.00627)
*Yuelin Wang,Yuqiao Ning,Yanbang Sun,Xiaofei Xie,Zhihua Xie,Yang Chen,Zhen Guo,Shihao Xue,Junjie Wang,Sen Chen*

Main category: cs.CR

TL;DR: 首次大规模实证研究智能网联汽车漏洞，通过分析649个可被利用的漏洞（来自竞赛和日常提交），评估现有分类体系覆盖度，发现1个新漏洞位置和13个新漏洞类型，并提出威胁类型和风险等级分类。


<details>
  <summary>Details</summary>
Motivation: 现有智能网联汽车安全研究大多关注特定子组件，缺乏系统性漏洞理解；且依赖主观分析（如调查访谈），理论发现与实际攻击存在差距。需要数据驱动的实证研究填补这一空白。

Method: 1) 分析现有ICV安全文献，总结漏洞位置和类型的分类体系；2) 收集649个可被利用漏洞（592个来自2023-2024年8次Anonymous Cup竞赛，覆盖48款车型；57个来自研究人员日常提交）；3) 评估现有分类体系覆盖度，识别差距；4) 将漏洞分类为6种威胁类型和4个风险等级；5) 分析参赛者技能和涉及车型。

Result: 发现现有分类体系存在不足，识别出1个新的漏洞位置和13个新的漏洞类型。将漏洞系统分类为6种威胁类型（如隐私数据泄露）和4个风险等级（低到严重）。提供了全面的数据驱动分析，并公开了漏洞数据集。

Conclusion: 本研究通过大规模实证分析填补了ICV漏洞研究的空白，提供了系统性、数据驱动的漏洞理解，为研究人员、行业从业者和政策制定者提供了可操作的见解。公开的数据集支持未来研究。

Abstract: Intelligent Connected Vehicles (ICVs) are a core component of modern transportation systems, and their security is crucial as it directly relates to user safety. Despite prior research, most existing studies focus only on specific sub-components of ICVs due to their inherent complexity. As a result, there is a lack of systematic understanding of ICV vulnerabilities. Moreover, much of the current literature relies on human subjective analysis, such as surveys and interviews, which tends to be high-level and unvalidated, leaving a significant gap between theoretical findings and real-world attacks. To address this issue, we conducted the first large-scale empirical study on ICV vulnerabilities. We began by analyzing existing ICV security literature and summarizing the prevailing taxonomies in terms of vulnerability locations and types. To evaluate their real-world relevance, we collected a total of 649 exploitable vulnerabilities, including 592 from eight ICV vulnerability discovery competitions, Anonymous Cup, between January 2023 and April 2024, covering 48 different vehicles. The remaining 57 vulnerabilities were submitted daily by researchers. Based on this dataset, we assessed the coverage of existing taxonomies and identified several gaps, discovering one new vulnerability location and 13 new vulnerability types. We further categorized these vulnerabilities into 6 threat types (e.g., privacy data breach) and 4 risk levels (ranging from low to critical) and analyzed participants' skills and the types of ICVs involved in the competitions. This study provides a comprehensive and data-driven analysis of ICV vulnerabilities, offering actionable insights for researchers, industry practitioners, and policymakers. To support future research, we have made our vulnerability dataset publicly available.

</details>


### [26] [Improving Router Security using BERT](https://arxiv.org/abs/2601.00783)
*John Carter,Spiros Mancoridis,Pavlos Protopapas,Brian Mitchell,Benji Lilley*

Main category: cs.CR

TL;DR: 提出结合高保真eBPF系统调用传感器、对比增强学习和网络包抽象语言的IoT路由器恶意软件检测方法，在低误报率下提升检测性能


<details>
  <summary>Details</summary>
Motivation: 先前基于系统调用训练BERT风格编码器的对比学习方法在检测路由器恶意软件时，在低误报率下性能有限，需要改进检测效果

Method: 1. 使用高保真eBPF系统调用传感器采集数据；2. 采用对比增强学习，通过对负样本引入受控变异来改进训练；3. 引入网络包抽象语言，创建类似网络包数据的处理管道；4. 将方法实现在在线路由器异常检测框架中

Result: 1. 在低误报率下提高了检测性能；2. 网络行为提供了互补的检测信号，对网络聚焦型恶意软件检测效果更好；3. 在IoT部署环境中验证了方法的有效性

Conclusion: 通过结合eBPF系统调用传感器、对比增强学习和网络包抽象语言，可以显著提升IoT路由器恶意软件检测在低误报率下的性能，网络行为分析为系统调用提供了有价值的补充信息

Abstract: Previous work on home router security has shown that using system calls to train a transformer-based language model built on a BERT-style encoder using contrastive learning is effective in detecting several types of malware, but the performance remains limited at low false positive rates. In this work, we demonstrate that using a high-fidelity eBPF-based system call sensor, together with contrastive augmented learning (which introduces controlled mutations of negative samples), improves detection performance at a low false positive rate. In addition, we introduce a network packet abstraction language that enables the creation of a pipeline similar to network packet data, and we show that network behavior provides complementary detection signals-yielding improved performance for network-focused malware at low false positive rates. Lastly, we implement these methods in an online router anomaly detection framework to validate the approach in an Internet of Things (IoT) deployment environment.

</details>
