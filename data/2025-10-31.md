<div id=toc></div>

# Table of Contents

- [cs.CR](#cs.CR) [Total: 25]


<div id='cs.CR'></div>

# cs.CR [[Back]](#toc)

### [1] [Attention Augmented GNN RNN-Attention Models for Advanced Cybersecurity Intrusion Detection](https://arxiv.org/abs/2510.25802)
*Jayant Biradar,Smit Shah,Tanmay Naik*

Main category: cs.CR

TL;DR: 提出了一种结合图神经网络、循环神经网络和多头注意力机制的混合深度学习架构，用于提升网络安全入侵检测能力，在UNSW-NB15数据集上表现出色。


<details>
  <summary>Details</summary>
Motivation: 现代实时入侵检测系统需要能够有效捕捉网络流量的空间依赖性和时间动态，同时提供模型可解释性，以帮助安全分析师专注于高影响安全事件。

Method: 采用混合深度学习架构，结合GNNs捕捉空间结构关系，RNNs分析时序动态，多头注意力机制提供特征选择和模型可解释性。

Result: 在UNSW-NB15数据集上的实验表明，该模型在准确率、精确率、召回率和F1分数等指标上优于传统机器学习方法和单一深度学习模型，特别擅长检测APT、DDoS和零日漏洞等复杂攻击。

Conclusion: 该混合模型是复杂网络环境中下一代网络安全应用的有前途解决方案，能够有效检测各类复杂攻击模式。

Abstract: In this paper, we propose a novel hybrid deep learning architecture that
synergistically combines Graph Neural Networks (GNNs), Recurrent Neural
Networks (RNNs), and multi-head attention mechanisms to significantly enhance
cybersecurity intrusion detection capabilities. By leveraging the comprehensive
UNSW-NB15 dataset containing diverse network traffic patterns, our approach
effectively captures both spatial dependencies through graph structural
relationships and temporal dynamics through sequential analysis of network
events. The integrated attention mechanism provides dual benefits of improved
model interpretability and enhanced feature selection, enabling cybersecurity
analysts to focus computational resources on high-impact security events -- a
critical requirement in modern real-time intrusion detection systems. Our
extensive experimental evaluation demonstrates that the proposed hybrid model
achieves superior performance compared to traditional machine learning
approaches and standalone deep learning models across multiple evaluation
metrics, including accuracy, precision, recall, and F1-score. The model
achieves particularly strong performance in detecting sophisticated attack
patterns such as Advanced Persistent Threats (APTs), Distributed Denial of
Service (DDoS) attacks, and zero-day exploits, making it a promising solution
for next-generation cybersecurity applications in complex network environments.

</details>


### [2] [APThreatHunter: An automated planning-based threat hunting framework](https://arxiv.org/abs/2510.25806)
*Mustafa F. Abdelwahed,Ahmed Shafee,Joan Espasa*

Main category: cs.CR

TL;DR: APThreatHunter是一个自动化网络威胁狩猎解决方案，通过自动生成假设来减少人工干预，消除分析师偏见，降低时间和成本。


<details>
  <summary>Details</summary>
Motivation: 网络攻击威胁经济利益、关键基础设施和公共健康安全。传统网络威胁狩猎需要手动创建和确认假设，耗时且存在偏见。

Method: APThreatHunter基于系统当前状态和一组指标，自动生成可能的风险假设，并使用自动化规划技术进行目标假设生成。

Result: 使用真实Android恶意软件样本进行评估，结果显示自动化规划在威胁狩猎活动中具有实用性。

Conclusion: 自动化规划技术可用于网络威胁狩猎中的目标假设生成，证明了该方法的可行性和有效性。

Abstract: Cyber attacks threaten economic interests, critical infrastructure, and
public health and safety. To counter this, entities adopt cyber threat hunting,
a proactive approach that involves formulating hypotheses and searching for
attack patterns within organisational networks. Automating cyber threat hunting
presents challenges, particularly in generating hypotheses, as it is a manually
created and confirmed process, making it time-consuming. To address these
challenges, we introduce APThreatHunter, an automated threat hunting solution
that generates hypotheses with minimal human intervention, eliminating analyst
bias and reducing time and cost. This is done by presenting possible risks
based on the system's current state and a set of indicators to indicate whether
any of the detected risks are happening or not. We evaluated APThreatHunter
using real-world Android malware samples, and the results revealed the
practicality of using automated planning for goal hypothesis generation in
cyber threat hunting activities.

</details>


### [3] [Adversarial Pre-Padding: Generating Evasive Network Traffic Against Transformer-Based Classifiers](https://arxiv.org/abs/2510.25810)
*Quanliang Jing,Xinxin Fan,Yanyan Liu,Jingping Bi*

Main category: cs.CR

TL;DR: 提出AdvTraffic方法，通过预填充策略和强化学习优化网络流量扰动，有效对抗基于Transformer的流量分类器，将分类准确率从99%降至25.68%。


<details>
  <summary>Details</summary>
Motivation: 现有流量混淆技术面对基于Transformer的预训练分类器变得脆弱，这些分类器能达到99%以上的准确率，需要新的防御方法。

Method: 采用预填充策略修改数据包，并使用强化学习模型优化网络流量扰动，最大化对抗基于Transformer分类器的效果。

Result: 在多个真实数据集上的实验表明，该方法能有效削弱Transformer分类器的性能，将分类准确率从99%显著降低到25.68%。

Conclusion: 这是首次将对抗扰动技术应用于防御基于Transformer的流量分类器，方法易于在实际网络环境中部署，能有效保护网络数据隐私和安全。

Abstract: To date, traffic obfuscation techniques have been widely adopted to protect
network data privacy and security by obscuring the true patterns of traffic.
Nevertheless, as the pre-trained models emerge, especially transformer-based
classifiers, existing traffic obfuscation methods become increasingly
vulnerable, as witnessed by current studies reporting the traffic
classification accuracy up to 99\% or higher. To counter such high-performance
transformer-based classification models, we in this paper propose a novel and
effective \underline{adv}ersarial \underline{traffic}-generating approach
(AdvTraffic\footnote{The code and data are available at: http://xxx}). Our
approach has two key innovations: (i) a pre-padding strategy is proposed to
modify packets, which effectively overcomes the limitations of existing
research against transformer-based models for network traffic classification;
and (ii) a reinforcement learning model is employed to optimize network traffic
perturbations, aiming to maximize adversarial effectiveness against
transformer-based classification models. To the best of our knowledge, this is
the first attempt to apply adversarial perturbation techniques to defend
against transformer-based traffic classifiers. Furthermore, our method can be
easily deployed into practical network environments. Finally, multi-faceted
experiments are conducted across several real-world datasets, and the
experimental results demonstrate that our proposed method can effectively
undermine transformer-based classifiers, significantly reducing classification
accuracy from 99\% to as low as 25.68\%.

</details>


### [4] [Identity Management for Agentic AI: The new frontier of authorization, authentication, and security for an AI agent world](https://arxiv.org/abs/2510.25819)
*Tobin South,Subramanya Nagabhushanaradhya,Ayesha Dissanayaka,Sarah Cecchetti,George Fletcher,Victor Lu,Aldo Pietropaolo,Dean H. Saxe,Jeff Lombardo,Abhishek Maligehalli Shivalingaiah,Stan Bounev,Alex Keisner,Andor Kesselman,Zack Proser,Ginny Fahs,Andrew Bunyea,Ben Moskowitz,Atul Tulshibagwale,Dazza Greenwood,Jiaxin Pei,Alex Pentland*

Main category: cs.CR

TL;DR: 该白皮书分析了AI代理在认证、授权和身份管理方面的挑战，提出了现有解决方案和未来战略议程。


<details>
  <summary>Details</summary>
Motivation: AI代理的快速发展带来了认证、授权和身份管理的紧迫挑战，需要明确最佳实践和解决长期复杂问题。

Method: 通过分析当前代理中心协议（如MCP）的需求，并展望高度自治代理的长期问题，制定战略议程。

Result: 概述了现有可用于保护当前代理的资源，并提出了解决未来广泛自治系统基础认证、授权和身份问题的战略议程。

Conclusion: 该白皮书为AI代理和访问管理交叉领域的利益相关者提供了资源指南和战略方向，以应对日益增长的自主系统安全挑战。

Abstract: The rapid rise of AI agents presents urgent challenges in authentication,
authorization, and identity management. Current agent-centric protocols (like
MCP) highlight the demand for clarified best practices in authentication and
authorization. Looking ahead, ambitions for highly autonomous agents raise
complex long-term questions regarding scalable access control, agent-centric
identities, AI workload differentiation, and delegated authority. This OpenID
Foundation whitepaper is for stakeholders at the intersection of AI agents and
access management. It outlines the resources already available for securing
today's agents and presents a strategic agenda to address the foundational
authentication, authorization, and identity problems pivotal for tomorrow's
widespread autonomous systems.

</details>


### [5] [A Critical Roadmap to Driver Authentication via CAN Bus: Dataset Review, Introduction of the Kidmose CANid Dataset (KCID), and Proof of Concept](https://arxiv.org/abs/2510.25856)
*Brooke Elizabeth Kidmose,Andreas Brasen Kidmose,Cliff C. Zou*

Main category: cs.CR

TL;DR: 本文提出了Kidmose CANid数据集(KCID)，解决了现有驾驶员指纹识别数据集的局限性，并开发了基于CAN总线的驾驶员认证防盗系统原型。


<details>
  <summary>Details</summary>
Motivation: 现代车辆安全系统存在漏洞，犯罪分子可以利用CAN总线系统绕过认证机制。驾驶员认证作为深度防御的附加层具有潜力，但现有数据集存在诸多限制。

Method: 创建KCID数据集，包含16名驾驶员在4辆车上的原始CAN总线数据，提供人口统计信息和日常驾驶数据。开发驾驶员认证防盗框架并在单板计算机上实现原型系统。

Result: 通过实车道路试验证明了基于CAN总线的驾驶员认证防盗系统的实际可行性。KCID数据集支持多种应用，包括驾驶员分析、机械异常检测等。

Conclusion: 本研究为开发稳健、可部署的驾驶员认证系统提供了必要的数据和方法基础，推动了车辆安全技术的发展。

Abstract: Modern vehicles remain vulnerable to unauthorized use and theft despite
traditional security measures including immobilizers and keyless entry systems.
Criminals exploit vulnerabilities in Controller Area Network (CAN) bus systems
to bypass authentication mechanisms, while social media trends have expanded
auto theft to include recreational joyriding by underage drivers. Driver
authentication via CAN bus data offers a promising additional layer of
defense-in-depth protection, but existing open-access driver fingerprinting
datasets suffer from critical limitations including reliance on decoded
diagnostic data rather than raw CAN traffic, artificial fixed-route
experimental designs, insufficient sampling rates, and lack of demographic
information.
  This paper provides a comprehensive review of existing open-access driver
fingerprinting datasets, analyzing their strengths and limitations to guide
practitioners in dataset selection. We introduce the Kidmose CANid Dataset
(KCID), which addresses these fundamental shortcomings by providing raw CAN bus
data from 16 drivers across four vehicles, including essential demographic
information and both daily driving and controlled fixed-route data. Beyond
dataset contributions, we present a driver authentication anti-theft framework
and implement a proof-of-concept prototype on a single-board computer. Through
live road trials with an unaltered passenger vehicle, we demonstrate the
practical feasibility of CAN bus-based driver authentication anti-theft
systems. Finally, we explore diverse applications of KCID beyond driver
authentication, including driver profiling for insurance and safety
assessments, mechanical anomaly detection, young driver monitoring, and
impaired driving detection. This work provides researchers with both the data
and methodological foundation necessary to develop robust, deployable driver
authentication systems...

</details>


### [6] [AAGATE: A NIST AI RMF-Aligned Governance Platform for Agentic AI](https://arxiv.org/abs/2510.25863)
*Ken Huang,Jerry Huang,Yasir Mehmood,Hammad Atta,Muhammad Zeeshan Baig,Muhammad Aziz Ul Haq*

Main category: cs.CR

TL;DR: AAGATE是一个Kubernetes原生的控制平面，专门解决自主语言模型驱动代理在生产环境中的安全和治理挑战，通过整合NIST AI风险管理框架和多个专业安全框架，提供持续可验证的治理解决方案。


<details>
  <summary>Details</summary>
Motivation: 传统应用安全工具无法应对即兴、机器速度的自主AI系统带来的独特安全和治理挑战，需要专门的控制平面来确保安全、负责任和可扩展的部署。

Method: 采用Kubernetes原生架构，整合NIST AI RMF框架，结合Agentic AI Threat Modeling MAESTRO、OWASP AIVSS与SEI SSVC混合框架、CSA Agentic AI Red Teaming Guide等专业安全框架，并集成零信任服务网格、可解释策略引擎、行为分析和去中心化问责钩子等技术。

Result: 构建了一个持续可验证的治理解决方案，能够安全、负责任地部署自主AI代理，治理范围涵盖系统性、对抗性和道德风险。

Conclusion: AAGATE为自主AI系统提供了有效的安全和治理保障，通过整合多个专业框架和技术组件，解决了传统工具无法应对的新型安全挑战。

Abstract: This paper introduces the Agentic AI Governance Assurance & Trust Engine
(AAGATE), a Kubernetes-native control plane designed to address the unique
security and governance challenges posed by autonomous, language-model-driven
agents in production. Recognizing the limitations of traditional Application
Security (AppSec) tooling for improvisational, machine-speed systems, AAGATE
operationalizes the NIST AI Risk Management Framework (AI RMF). It integrates
specialized security frameworks for each RMF function: the Agentic AI Threat
Modeling MAESTRO framework for Map, a hybrid of OWASP's AIVSS and SEI's SSVC
for Measure, and the Cloud Security Alliance's Agentic AI Red Teaming Guide for
Manage. By incorporating a zero-trust service mesh, an explainable policy
engine, behavioral analytics, and decentralized accountability hooks, AAGATE
provides a continuous, verifiable governance solution for agentic AI, enabling
safe, accountable, and scalable deployment. The framework is further extended
with DIRF for digital identity rights, LPCI defenses for logic-layer injection,
and QSAF monitors for cognitive degradation, ensuring governance spans
systemic, adversarial, and ethical risks.

</details>


### [7] [Foundations of Fiat-Denominated Loans Collateralized by Cryptocurrencies](https://arxiv.org/abs/2510.25878)
*Pavel Hubáček,Jan Václavek,Michelle Yeo*

Main category: cs.CR

TL;DR: 该论文研究以加密货币为抵押的法币贷款安全协议，提出基于可信仲裁的有限托管协议并进行博弈论分析。


<details>
  <summary>Details</summary>
Motivation: 随着加密货币作为金融资产的重要性上升，需要将其从投机对象转变为更接近标准金融工具（如贷款）的应用场景。

Method: 开发基于可信仲裁的有限托管协议，用于以比特币等加密货币为抵押的法币贷款，并进行博弈论分析。

Result: 提出了可行的安全协议框架，能够支持加密货币抵押的法币贷款业务。

Conclusion: 该研究为加密货币抵押贷款领域提供了基础协议设计，并指出了未来研究的多个有趣方向。

Abstract: The rising importance of cryptocurrencies as financial assets pushed their
applicability from an object of speculation closer to standard financial
instruments such as loans. In this work, we initiate the study of secure
protocols that enable fiat-denominated loans collateralized by cryptocurrencies
such as Bitcoin. We provide limited-custodial protocols for such loans relying
only on trusted arbitration and provide their game-theoretical analysis. We
also highlight various interesting directions for future research.

</details>


### [8] [FakeZero: Real-Time, Privacy-Preserving Misinformation Detection for Facebook and X](https://arxiv.org/abs/2510.25932)
*Soufiane Essahli,Oussama Sarsar,Imane Fouad,Anas Motii,Ahmed Bentajer*

Main category: cs.CR

TL;DR: FakeZero是一个完全客户端、跨平台的浏览器扩展，能够在用户滚动时实时标记Facebook和X平台上的不可靠帖子，所有计算都在本地运行，不泄露个人数据。


<details>
  <summary>Details</summary>
Motivation: 社交媒体以空前速度传播信息，加速了错误信息的传播并威胁公共话语。需要一种保护隐私的本地化解决方案来检测虚假信息。

Method: 采用三阶段训练课程：基线微调、域自适应训练（使用焦点损失、对抗增强和后训练量化）。使用DistilBERT-Quant和TinyBERT-Quant模型，所有计算通过Chromium消息API在本地运行。

Result: 在239,000个帖子的数据集上，DistilBERT-Quant模型（67.6 MB）达到97.1%宏F1、97.4%准确率和0.996 AUROC，中位延迟约103毫秒。TinyBERT-Quant变体（14.7 MB）保持95.7%宏F1和96.1%准确率，延迟降至约40毫秒。

Conclusion: 高质量虚假新闻检测在严格资源预算下是可行的，性能损失很小。该扩展可为政策制定者提供有价值的工具，并在用户同意下为研究人员收集大规模假新闻数据集打开大门。

Abstract: Social platforms distribute information at unprecedented speed, which in turn
accelerates the spread of misinformation and threatens public discourse. We
present FakeZero, a fully client-side, cross-platform browser extension that
flags unreliable posts on Facebook and X (formerly Twitter) while the user
scrolls. All computation, DOM scraping, tokenisation, Transformer inference,
and UI rendering run locally through the Chromium messaging API, so no personal
data leaves the device.FakeZero employs a three-stage training curriculum:
baseline fine-tuning and domain-adaptive training enhanced with focal loss,
adversarial augmentation, and post-training quantisation. Evaluated on a
dataset of 239,000 posts, the DistilBERT-Quant model (67.6 MB) reaches 97.1%
macro-F1, 97.4% accuracy, and an AUROC of 0.996, with a median latency of
approximately 103 ms on a commodity laptop. A memory-efficient TinyBERT-Quant
variant retains 95.7% macro-F1 and 96.1% accuracy while shrinking the model to
14.7 MB and lowering latency to approximately 40 ms, showing that high-quality
fake-news detection is feasible under tight resource budgets with only modest
performance loss.By providing inline credibility cues, the extension can serve
as a valuable tool for policymakers seeking to curb the spread of
misinformation across social networks. With user consent, FakeZero also opens
the door for researchers to collect large-scale datasets of fake news in the
wild, enabling deeper analysis and the development of more robust detection
techniques.

</details>


### [9] [SoK: Honeypots & LLMs, More Than the Sum of Their Parts?](https://arxiv.org/abs/2510.25939)
*Robert A. Bridges,Thomas R. Mitchell,Mauricio Muñoz,Ted Henriksson*

Main category: cs.CR

TL;DR: 本文对基于大语言模型（LLM）的蜜罐研究进行了首次系统性综述，提出了检测向量分类、架构分析和日志分析演进的综合框架，并展望了自主欺骗系统的未来发展方向。


<details>
  <summary>Details</summary>
Motivation: 解决蜜罐设计中高逼真度与低操作风险的长期矛盾，填补LLM蜜罐研究领域缺乏系统性理解的空白，为这一新兴领域提供结构化分析。

Method: 采用知识系统化方法，系统调研三个关键研究领域：蜜罐检测向量分类、LLM蜜罐架构分析和蜜罐日志分析演进路径。

Result: 建立了LLM蜜罐研究的综合框架，识别了典型架构模式和评估趋势，揭示了从简单数据缩减到自动化情报生成的演进路径。

Conclusion: LLM蜜罐技术的真正潜力在于创建自主、自我改进的欺骗系统，以应对智能自动化攻击者的新兴威胁。

Abstract: The advent of Large Language Models (LLMs) promised to resolve the
long-standing paradox in honeypot design: achieving high-fidelity deception
with low operational risk. However, despite a flurry of research since late
2022, progress has been incremental, and the field lacks a cohesive
understanding of the emerging architectural patterns, core challenges, and
evaluation paradigms. To fill this gap, this Systematization of Knowledge (SoK)
paper provides the first comprehensive overview of this new domain. We survey
and systematize three critical, intersecting research areas: first, we provide
a taxonomy of honeypot detection vectors, structuring the core problems that
LLM-based realism must solve; second, we synthesize the emerging literature on
LLM-honeypots, identifying a canonical architecture and key evaluation trends;
and third, we chart the evolutionary path of honeypot log analysis, from simple
data reduction to automated intelligence generation. We synthesize these
findings into a forward-looking research roadmap, arguing that the true
potential of this technology lies in creating autonomous, self-improving
deception systems to counter the emerging threat of intelligent, automated
attackers.

</details>


### [10] [WaveVerif: Acoustic Side-Channel based Verification of Robotic Workflows](https://arxiv.org/abs/2510.25960)
*Zeynep Yasemin Erdogan,Shishir Nagaraja,Chuadhry Mujeeb Ahmed,Ryan Shah*

Main category: cs.CR

TL;DR: 提出基于声学侧信道分析的机器人指令执行验证框架，利用机器人运动产生的声音信号，通过机器学习分类器验证实时行为是否符合预期命令。


<details>
  <summary>Details</summary>
Motivation: 在敏感机器人环境中需要低成本、被动式的实时验证方法，无需硬件修改即可监控机器人是否正确执行指令。

Method: 开发基于机器学习的验证系统，使用四种分类器（SVM、DNN、RNN、CNN）分析机器人运动产生的声音信号，考虑运动速度、方向和麦克风距离等因素。

Result: 在基准条件下，单个机器人运动验证准确率超过80%，拾取放置和包装等工作流程也能以类似高置信度识别。

Conclusion: 声学信号能够支持敏感机器人环境中的实时、低成本、被动验证，无需硬件修改。

Abstract: In this paper, we present a framework that uses acoustic side-channel
analysis (ASCA) to monitor and verify whether a robot correctly executes its
intended commands. We develop and evaluate a machine-learning-based workflow
verification system that uses acoustic emissions generated by robotic
movements. The system can determine whether real-time behavior is consistent
with expected commands. The evaluation takes into account movement speed,
direction, and microphone distance. The results show that individual robot
movements can be validated with over 80% accuracy under baseline conditions
using four different classifiers: Support Vector Machine (SVM), Deep Neural
Network (DNN), Recurrent Neural Network (RNN), and Convolutional Neural Network
(CNN). Additionally, workflows such as pick-and-place and packing could be
identified with similarly high confidence. Our findings demonstrate that
acoustic signals can support real-time, low-cost, passive verification in
sensitive robotic environments without requiring hardware modifications.

</details>


### [11] [Message Recovery Attack in NTRU via Knapsack](https://arxiv.org/abs/2510.26003)
*Eirini Poimenidou,K. A. Draziotis*

Main category: cs.CR

TL;DR: 基于模背包问题对NTRU-HPS密码系统的消息恢复攻击，当已知约45%的明文和随机向量系数时，可在几分钟内恢复消息。


<details>
  <summary>Details</summary>
Motivation: 研究在已知部分消息和随机向量系数的情况下，需要多少信息才能实现NTRU-HPS密码系统的消息恢复攻击。

Method: 使用模背包问题将消息解密转化为在格中寻找短向量的问题，采用FLATTER约简算法。

Result: 当已知约45%的系数时，可在几分钟内成功恢复消息。

Conclusion: NTRU-HPS密码系统在已知部分明文信息时存在安全风险，需要约45%的信息泄露即可实现有效攻击。

Abstract: In the present paper, we introduce a message-recovery attack based on the
Modular Knapsack Problem, applicable to all variants of the NTRU-HPS
cryptosystem. Assuming that a fraction $\epsilon$ of the coefficients of the
message ${\bf{m}}\in\{-1,0,1\}^N$ and of the nonce vector ${\bf
r}\in\{-1,0,1\}^N$ are known in advance at random positions, we reduce message
decryption to finding a short vector in a lattice that encodes an instance of a
modular knapsack system. This allows us to address a key question: how much
information about ${\bf m}$, or about the pair $({\bf m},{\bf r})$, is required
before recovery becomes feasible? A FLATTER reduction successfully recovers the
message, in practice when $\epsilon\approx 0.45$. Our implementation finds
${\bf m}$ within a few minutes on a commodity desktop.

</details>


### [12] [SIRAJ: Diverse and Efficient Red-Teaming for LLM Agents via Distilled Structured Reasoning](https://arxiv.org/abs/2510.26037)
*Kaiwen Zhou,Ahmed Elgohary,A S M Iftekhar,Amin Saied*

Main category: cs.CR

TL;DR: SIRAJ是一个通用的红队测试框架，用于发现黑盒LLM代理的安全漏洞。它采用动态两步流程：生成多样化的种子测试用例，然后基于执行轨迹迭代构建对抗攻击。通过模型蒸馏方法优化成本，小模型性能超越大模型。


<details>
  <summary>Details</summary>
Motivation: LLM代理调用工具的能力带来了新的安全风险，需要全面的红队测试系统来发现漏洞并确保安全部署。

Method: 采用动态两步流程：1) 基于代理定义生成覆盖各种风险结果、工具使用轨迹和风险源的种子测试用例；2) 基于先前执行轨迹迭代构建和优化模型驱动的对抗攻击。使用模型蒸馏方法，利用教师模型的结构化推理训练更小的模型。

Result: 种子测试用例生成方法将风险结果和工具调用轨迹的覆盖率提高了2-2.5倍。蒸馏出的8B红队测试模型攻击成功率提升100%，超越671B的Deepseek-R1模型。消融实验验证了迭代框架、结构化推理和模型泛化能力的有效性。

Conclusion: SIRAJ框架能有效发现LLM代理的安全漏洞，通过模型蒸馏方法在保持性能的同时显著降低成本，为LLM代理的安全部署提供了重要保障。

Abstract: The ability of LLM agents to plan and invoke tools exposes them to new safety
risks, making a comprehensive red-teaming system crucial for discovering
vulnerabilities and ensuring their safe deployment. We present SIRAJ: a generic
red-teaming framework for arbitrary black-box LLM agents. We employ a dynamic
two-step process that starts with an agent definition and generates diverse
seed test cases that cover various risk outcomes, tool-use trajectories, and
risk sources. Then, it iteratively constructs and refines model-based
adversarial attacks based on the execution trajectories of former attempts. To
optimize the red-teaming cost, we present a model distillation approach that
leverages structured forms of a teacher model's reasoning to train smaller
models that are equally effective. Across diverse evaluation agent settings,
our seed test case generation approach yields 2 -- 2.5x boost to the coverage
of risk outcomes and tool-calling trajectories. Our distilled 8B red-teamer
model improves attack success rate by 100%, surpassing the 671B Deepseek-R1
model. Our ablations and analyses validate the effectiveness of the iterative
framework, structured reasoning, and the generalization of our red-teamer
models.

</details>


### [13] [PEEL: A Poisoning-Exposing Encoding Theoretical Framework for Local Differential Privacy](https://arxiv.org/abs/2510.26102)
*Lisha Shuai,Jiuling Dong,Nan Zhang,Shaofeng Tan,Haokun Zhang,Zilong Song,Gaoya Dong,Xiaolong Yang*

Main category: cs.CR

TL;DR: PEEL是一个针对LDP的投毒攻击防御框架，通过重新编码LDP扰动数据来暴露投毒攻击，同时保持统计准确性和低计算成本。


<details>
  <summary>Details</summary>
Motivation: 现有LDP防御方法要么资源开销过大，要么依赖领域先验知识，限制了实际部署。需要一种轻量级且不依赖先验的防御方案。

Method: PEEL通过稀疏化、归一化和低秩投影重新编码LDP扰动数据，放大投毒效应，在重构空间中通过结构不一致性揭示投毒攻击。

Result: PEEL在投毒暴露准确率上优于四种最先进防御方法，同时显著降低客户端计算成本，适合大规模IoT部署。

Conclusion: PEEL提供了一个理论框架，既能保持LDP的统计准确性，又能有效防御投毒攻击，是IoT环境中实用的LDP防御方案。

Abstract: Local Differential Privacy (LDP) is a widely adopted privacy-protection model
in the Internet of Things (IoT) due to its lightweight, decentralized, and
scalable nature. However, it is vulnerable to poisoning attacks, and existing
defenses either incur prohibitive resource overheads or rely on domain-specific
prior knowledge, limiting their practical deployment. To address these
limitations, we propose PEEL, a Poisoning-Exposing Encoding theoretical
framework for LDP, which departs from resource- or prior-dependent
countermeasures and instead leverages the inherent structural consistency of
LDP-perturbed data. As a non-intrusive post-processing module, PEEL amplifies
stealthy poisoning effects by re-encoding LDP-perturbed data via
sparsification, normalization, and low-rank projection, thereby revealing both
output and rule poisoning attacks through structural inconsistencies in the
reconstructed space. Theoretical analysis proves that PEEL, integrated with
LDP, retains unbiasedness and statistical accuracy, while being robust to
expose both output and rule poisoning attacks. Moreover, evaluation results
show that LDP-integrated PEEL not only outperforms four state-of-the-art
defenses in terms of poisoning exposure accuracy but also significantly reduces
client-side computational costs, making it highly suitable for large-scale IoT
deployments.

</details>


### [14] [Security Vulnerabilities in AI-Generated Code: A Large-Scale Analysis of Public GitHub Repositories](https://arxiv.org/abs/2510.26103)
*Maximilian Schreiber,Pascal Tippe*

Main category: cs.CR

TL;DR: 对GitHub上AI生成代码安全漏洞的实证分析，发现87.9%的代码无CWE漏洞，但Python语言漏洞率最高(16.18%-18.50%)，不同AI工具在不同语言上表现各异。


<details>
  <summary>Details</summary>
Motivation: 随着AI代码生成工具的广泛使用，需要系统评估其生成代码的安全性和漏洞模式，以指导安全实践。

Method: 收集7,703个来自ChatGPT、GitHub Copilot等AI工具的代码文件，使用CodeQL静态分析识别4,241个CWE漏洞实例。

Result: Python漏洞率最高，GitHub Copilot在Python和TypeScript上安全密度更好，ChatGPT在JavaScript上表现更佳，39%文件用于文档生成。

Conclusion: 研究为AI生成代码的安全集成提供了语言特定和上下文感知的安全实践指导，强调了文档生成应用的重要性。

Abstract: This paper presents a comprehensive empirical analysis of security
vulnerabilities in AI-generated code across public GitHub repositories. We
collected and analyzed 7,703 files explicitly attributed to four major AI
tools: ChatGPT (91.52\%), GitHub Copilot (7.50\%), Amazon CodeWhisperer
(0.52\%), and Tabnine (0.46\%). Using CodeQL static analysis, we identified
4,241 Common Weakness Enumeration (CWE) instances across 77 distinct
vulnerability types. Our findings reveal that while 87.9\% of AI-generated code
does not contain identifiable CWE-mapped vulnerabilities, significant patterns
emerge regarding language-specific vulnerabilities and tool performance. Python
consistently exhibited higher vulnerability rates (16.18\%-18.50\%) compared to
JavaScript (8.66\%-8.99\%) and TypeScript (2.50\%-7.14\%) across all tools. We
observed notable differences in security performance, with GitHub Copilot
achieving better security density for Python (1,739 LOC per CWE) and
TypeScript, while ChatGPT performed better for JavaScript. Additionally, we
discovered widespread use of AI tools for documentation generation (39\% of
collected files), an understudied application with implications for software
maintainability. These findings extend previous work with a significantly
larger dataset and provide valuable insights for developing language-specific
and context-aware security practices for the responsible integration of
AI-generated code into software development workflows.

</details>


### [15] [Confidential FRIT via Homomorphic Encryption](https://arxiv.org/abs/2510.26179)
*Haruki Hoshino,Jungjin Park,Osamu Kaneko,Kiminao Kogiso*

Main category: cs.CR

TL;DR: 提出基于同态加密的保密数据驱动增益调谐框架，用于保护外包到边缘服务器的CPS增益调谐过程安全。


<details>
  <summary>Details</summary>
Motivation: 边缘计算虽然减轻了CPS的数据驱动控制计算负担，但日益复杂的网络攻击需要超越传统IT保护的安全措施，以解决CPS特有的脆弱性。

Method: 使用同态加密方案（如ElGamal和CKKS），通过将矩阵求逆操作替换为向量求和形式，实现对FRIT的保密实现，使同态操作得以应用。

Result: 在128位安全级别下的数值示例证实，该方法性能与传统方法相当，同时为安全CPS选择合适的加密方案提供了指导。

Conclusion: 该框架在保持性能的同时增强了CPS增益调谐过程的网络安全，为安全CPS的加密方案选择提供了实用指南。

Abstract: Edge computing alleviates the computation burden of data-driven control in
cyber-physical systems (CPSs) by offloading complex processing to edge servers.
However, the increasing sophistication of cyberattacks underscores the need for
security measures that go beyond conventional IT protections and address the
unique vulnerabilities of CPSs. This study proposes a confidential data-driven
gain-tuning framework using homomorphic encryption, such as ElGamal and CKKS
encryption schemes, to enhance cybersecurity in gain-tuning processes
outsourced to external servers. The idea for realizing confidential FRIT is to
replace the matrix inversion operation with a vector summation form, allowing
homomorphic operations to be applied. Numerical examples under 128-bit security
confirm performance comparable to conventional methods while providing
guidelines for selecting suitable encryption schemes for secure CPS.

</details>


### [16] [Who Moved My Transaction? Uncovering Post-Transaction Auditability Vulnerabilities in Modern Super Apps](https://arxiv.org/abs/2510.26210)
*Junlin Liu,Zhaomeng Deng,Ziming Wang,Mengyu Yao,Yifeng Cai,Yutao Hu,Ziqi Zhang,Yao Guo,Ding Li*

Main category: cs.CR

TL;DR: 研究发现超级应用普遍存在交易记录删除漏洞，83%的应用缺乏强认证保护，允许用户永久删除交易历史，暴露了后交易审计完整性的严重安全缺陷。


<details>
  <summary>Details</summary>
Motivation: 当前超级应用安全范式过度关注交易前认证，忽视了后交易审计轨迹的脆弱性，用户可轻易删除交易记录来隐藏未授权或敏感活动。

Method: 对6个超级应用进行实证研究，招募6名志愿者进行交叉评估，分析交易记录删除功能的安全性。

Result: 所有6个应用都允许删除交易记录，但其中5个(83%)缺乏强认证保护，仅1个应用要求生物识别验证。

Conclusion: 这揭示了移动安全领域的关键漏洞，迫切需要范式转变以确保后交易审计完整性。

Abstract: Super apps are the cornerstones of modern digital life, embedding financial
transactions into nearly every aspect of daily routine. The prevailing security
paradigm for these platforms is overwhelmingly focused on pre-transaction
authentication, preventing unauthorized payments before they occur. We argue
that a critical vulnerability vector has been largely overlooked: the fragility
of post-transaction audit trails. We investigate the ease with which a user can
permanently erase their transaction history from an app's interface, thereby
concealing unauthorized or sensitive activities from the account owner. To
quantify this threat, we conducted an empirical study with 6 volunteers who
performed a cross-evaluation on six super apps. Our findings are alarming: all
six applications studied allow users to delete transaction records, yet a
staggering five out of six (83+\%) fail to protect these records with strong
authentication. Only one app in our study required biometric verification for
deletion. This study provides the first concrete evidence of this
near-ubiquitous vulnerability, demonstrating a critical gap in the current
mobile security landscape and underscoring the urgent need for a paradigm shift
towards ensuring post-transaction audit integrity.

</details>


### [17] [Who Grants the Agent Power? Defending Against Instruction Injection via Task-Centric Access Control](https://arxiv.org/abs/2510.26212)
*Yifeng Cai,Ziming Wang,Zhaomeng Deng,Mengyu Yao,Junlin Liu,Yutao Hu,Ziqi Zhang,Yao Guo,Ding Li*

Main category: cs.CR

TL;DR: AgentSentry是一个轻量级运行时任务中心访问控制框架，通过动态生成和执行与用户特定任务对齐的最小临时权限策略，防止AI代理遭受指令注入攻击。


<details>
  <summary>Details</summary>
Motivation: AI代理依赖过度特权、静态权限进行GUI理解和移动任务自动化，这造成了关键漏洞：指令注入。恶意指令可以劫持代理执行未授权操作。

Method: AgentSentry动态生成和执行与用户特定任务对齐的最小临时权限策略，而不是授予广泛、持久的权限，并在任务完成后撤销这些权限。

Result: AgentSentry成功防止了指令注入攻击（如诱骗代理转发私人邮件），同时允许合法任务完成。

Conclusion: 该方法强调了为安全治理下一代自主代理而建立意图对齐安全模型的紧迫需求。

Abstract: AI agents capable of GUI understanding and Model Context Protocol are
increasingly deployed to automate mobile tasks. However, their reliance on
over-privileged, static permissions creates a critical vulnerability:
instruction injection. Malicious instructions, embedded in otherwise benign
content like emails, can hijack the agent to perform unauthorized actions. We
present AgentSentry, a lightweight runtime task-centric access control
framework that enforces dynamic, task-scoped permissions. Instead of granting
broad, persistent permissions, AgentSentry dynamically generates and enforces
minimal, temporary policies aligned with the user's specific task (e.g.,
register for an app), revoking them upon completion. We demonstrate that
AgentSentry successfully prevents an instruction injection attack, where an
agent is tricked into forwarding private emails, while allowing the legitimate
task to complete. Our approach highlights the urgent need for intent-aligned
security models to safely govern the next generation of autonomous agents.

</details>


### [18] [PVMark: Enabling Public Verifiability for LLM Watermarking Schemes](https://arxiv.org/abs/2510.26274)
*Haohua Duan,Liyao Xiang,Xin Zhang*

Main category: cs.CR

TL;DR: PVMark是一个基于零知识证明的插件，使LLM水印检测过程能够被第三方公开验证，同时不泄露任何密钥，解决了当前水印方案中的信任问题。


<details>
  <summary>Details</summary>
Motivation: 当前的LLM水印方案存在信任问题：非公开的水印检测无法证明自身忠实执行了检测过程，这源于密钥管理的两难困境——公开密钥会导致攻击者发起移除攻击，私有密钥则使检测过程不透明。

Method: 基于零知识证明构建水印检测的'正确执行'证明，包括映射、随机数生成、比较和求和等约束条件，实现了多种变体，涵盖三种水印方案、三种哈希函数和四种ZKP协议。

Result: PVMark在多种情况下都能有效工作，能够高效地为最先进的LLM水印方案提供公开可验证性，且不影响水印性能，有望在实际中部署。

Conclusion: PVMark成功解决了LLM水印检测的信任问题，通过零知识证明实现了公开可验证的检测过程，同时保护了密钥安全，具有实际部署的潜力。

Abstract: Watermarking schemes for large language models (LLMs) have been proposed to
identify the source of the generated text, mitigating the potential threats
emerged from model theft. However, current watermarking solutions hardly
resolve the trust issue: the non-public watermark detection cannot prove itself
faithfully conducting the detection. We observe that it is attributed to the
secret key mostly used in the watermark detection -- it cannot be public, or
the adversary may launch removal attacks provided the key; nor can it be
private, or the watermarking detection is opaque to the public. To resolve the
dilemma, we propose PVMark, a plugin based on zero-knowledge proof (ZKP),
enabling the watermark detection process to be publicly verifiable by third
parties without disclosing any secret key. PVMark hinges upon the proof of
`correct execution' of watermark detection on which a set of ZKP constraints
are built, including mapping, random number generation, comparison, and
summation. We implement multiple variants of PVMark in Python, Rust and Circom,
covering combinations of three watermarking schemes, three hash functions, and
four ZKP protocols, to show our approach effectively works under a variety of
circumstances. By experimental results, PVMark efficiently enables public
verifiability on the state-of-the-art LLM watermarking schemes yet without
compromising the watermarking performance, promising to be deployed in
practice.

</details>


### [19] [A Survey of Heterogeneous Graph Neural Networks for Cybersecurity Anomaly Detection](https://arxiv.org/abs/2510.26307)
*Laura Jiang,Reza Ryan,Qian Li,Nasim Ferdosian*

Main category: cs.CR

TL;DR: 这是一篇关于异构图神经网络在网络安全异常检测中的综述论文，系统梳理了该领域的研究现状、方法分类、基准数据集和未来挑战。


<details>
  <summary>Details</summary>
Motivation: 当前基于异构图神经网络的异常检测研究存在碎片化问题，缺乏统一的分类框架、有限的比较评估以及标准化的基准，需要建立系统性的研究基础。

Method: 提出了一个按异常类型和图动态性分类的分类法，分析了代表性模型，并将其映射到关键网络安全应用中，同时回顾了常用基准数据集和评估指标。

Result: 建立了异构图神经网络在网络安全异常检测领域的结构化基础，识别了建模、数据和部署方面的关键开放挑战。

Conclusion: 该综述旨在推动异构图神经网络异常检测向可扩展、可解释和实际可部署的解决方案发展，为未来研究指明了方向。

Abstract: Anomaly detection is a critical task in cybersecurity, where identifying
insider threats, access violations, and coordinated attacks is essential for
ensuring system resilience. Graph-based approaches have become increasingly
important for modeling entity interactions, yet most rely on homogeneous and
static structures, which limits their ability to capture the heterogeneity and
temporal evolution of real-world environments. Heterogeneous Graph Neural
Networks (HGNNs) have emerged as a promising paradigm for anomaly detection by
incorporating type-aware transformations and relation-sensitive aggregation,
enabling more expressive modeling of complex cyber data. However, current
research on HGNN-based anomaly detection remains fragmented, with diverse
modeling strategies, limited comparative evaluation, and an absence of
standardized benchmarks. To address this gap, we provide a comprehensive survey
of HGNN-based anomaly detection methods in cybersecurity. We introduce a
taxonomy that classifies approaches by anomaly type and graph dynamics, analyze
representative models, and map them to key cybersecurity applications. We also
review commonly used benchmark datasets and evaluation metrics, highlighting
their strengths and limitations. Finally, we identify key open challenges
related to modeling, data, and deployment, and outline promising directions for
future research. This survey aims to establish a structured foundation for
advancing HGNN-based anomaly detection toward scalable, interpretable, and
practically deployable solutions.

</details>


### [20] [SSCL-BW: Sample-Specific Clean-Label Backdoor Watermarking for Dataset Ownership Verification](https://arxiv.org/abs/2510.26420)
*Yingjia Wang,Ting Qiao,Xing Liu,Chongzuo Li,Sixing Wu,Jianbin Li*

Main category: cs.CR

TL;DR: 提出SSCL-BW方法，通过样本特定的干净标签后门水印解决数据集版权保护问题，克服了传统静态水印模式易被检测和移除的缺陷。


<details>
  <summary>Details</summary>
Motivation: 深度神经网络依赖大规模高质量数据集，但未经授权的商业使用侵犯了数据集所有者的知识产权。现有后门水印方法存在标签不一致、技术复杂、高分辨率图像失效等问题。

Method: 训练基于U-Net的水印样本生成器，为每个样本生成独特水印；设计包含目标样本损失、非目标样本损失和感知相似性损失的复合损失函数；使用黑盒测试进行版权验证。

Result: 在基准数据集上的广泛实验表明该方法有效，并对潜在水印移除攻击具有鲁棒性。

Conclusion: SSCL-BW方法通过样本特定水印生成和复合损失函数设计，成功解决了数据集版权保护中的关键挑战，为数据集知识产权保护提供了有效解决方案。

Abstract: The rapid advancement of deep neural networks (DNNs) heavily relies on
large-scale, high-quality datasets. However, unauthorized commercial use of
these datasets severely violates the intellectual property rights of dataset
owners. Existing backdoor-based dataset ownership verification methods suffer
from inherent limitations: poison-label watermarks are easily detectable due to
label inconsistencies, while clean-label watermarks face high technical
complexity and failure on high-resolution images. Moreover, both approaches
employ static watermark patterns that are vulnerable to detection and removal.
To address these issues, this paper proposes a sample-specific clean-label
backdoor watermarking (i.e., SSCL-BW). By training a U-Net-based watermarked
sample generator, this method generates unique watermarks for each sample,
fundamentally overcoming the vulnerability of static watermark patterns. The
core innovation lies in designing a composite loss function with three
components: target sample loss ensures watermark effectiveness, non-target
sample loss guarantees trigger reliability, and perceptual similarity loss
maintains visual imperceptibility. During ownership verification, black-box
testing is employed to check whether suspicious models exhibit predefined
backdoor behaviors. Extensive experiments on benchmark datasets demonstrate the
effectiveness of the proposed method and its robustness against potential
watermark removal attacks.

</details>


### [21] [CyberNER: A Harmonized STIX Corpus for Cybersecurity Named Entity Recognition](https://arxiv.org/abs/2510.26499)
*Yasir Ech-Chammakhy,Anas Motii,Anass Rabii,Oussama Azrara,Jaafar Chbili*

Main category: cs.CR

TL;DR: CyberNER是一个大规模统一语料库，通过将四个主要网络安全数据集（CyNER、DNRTI、APTNER和Attacker）系统化地协调到STIX 2.1标准上，解决了命名实体识别中标注模式不兼容的问题。


<details>
  <summary>Details</summary>
Motivation: 网络安全领域命名实体识别(NER)面临数据集标注模式不兼容的挑战，简单合并这些资源会导致噪声标签空间，严重降低模型性能。

Method: 采用原则性方法解决语义歧义，将50多个不同的源标签整合为21个一致的实体类型，创建统一的CyberNER语料库。

Result: 在CyberNER上训练的模型相比简单拼接基线实现了约30%的相对F1分数提升，性能显著改善。

Conclusion: 通过公开发布CyberNER语料库，为网络安全领域提供了标准化的基准，支持创建和严格比较更鲁棒、可泛化的实体提取模型。

Abstract: Extracting structured intelligence via Named Entity Recognition (NER) is
critical for cybersecurity, but the proliferation of datasets with incompatible
annotation schemas hinders the development of comprehensive models. While
combining these resources is desirable, we empirically demonstrate that naively
concatenating them results in a noisy label space that severely degrades model
performance. To overcome this critical limitation, we introduce CyberNER, a
large-scale, unified corpus created by systematically harmonizing four
prominent datasets (CyNER, DNRTI, APTNER, and Attacker) onto the STIX 2.1
standard. Our principled methodology resolves semantic ambiguities and
consolidates over 50 disparate source tags into 21 coherent entity types. Our
experiments show that models trained on CyberNER achieve a substantial
performance gain, with a relative F1-score improvement of approximately 30%
over the naive concatenation baseline. By publicly releasing the CyberNER
corpus, we provide a crucial, standardized benchmark that enables the creation
and rigorous comparison of more robust and generalizable entity extraction
models for the cybersecurity domain.

</details>


### [22] [Interdependent Privacy in Smart Homes: Hunting for Bystanders in Privacy Policies](https://arxiv.org/abs/2510.26523)
*Shuaishuai Liu,Gergely Acs,Gergely Biczók*

Main category: cs.CR

TL;DR: 本文分析了20个视频门铃和智能摄像头的隐私政策，重点关注旁观者隐私问题，发现厂商主要通过免责声明转移责任，并提出改进建议。


<details>
  <summary>Details</summary>
Motivation: 智能家居设备普及带来便利的同时，也引发了旁观者隐私问题，即设备所有者行为可能影响非用户的隐私，而现有法规对此监管不足。

Method: 对20款视频门铃和智能摄像头产品进行隐私政策分析，重点关注旁观者方面，并检查实际案例。

Result: 研究发现虽然部分厂商承认旁观者存在，但主要通过免责声明将收集非用户数据的道德责任转移给设备所有者。

Conclusion: 基于分析结果，结合现有法律框架和技术能力，提出了改进隐私政策语言和系统设计的实用建议，以增强透明度并赋权于旁观者和设备所有者。

Abstract: Smart home devices such as video doorbells and security cameras are becoming
increasingly common in everyday life. While these devices offer convenience and
safety, they also raise new privacy concerns: how these devices affect others,
like neighbors, visitors, or people passing by. This issue is generally known
as interdependent privacy, where one person's actions (or inaction) may impact
the privacy of others, and, specifically, bystander privacy in the context of
smart homes. Given lax data protection regulations in terms of shared physical
spaces and amateur joint data controllers, we expect that the privacy policies
of smart home products reflect the missing regulatory incentives. This paper
presents a focused privacy policy analysis of 20 video doorbell and smart
camera products, concentrating explicitly on the bystander aspect. We show that
although some of the vendors acknowledge bystanders, they address it only to
the extent of including disclaimers, shifting the ethical responsibility for
collecting the data of non-users to the device owner. In addition, we identify
and examine real-world cases related to bystander privacy, demonstrating how
current deployments can impact non-users. Based on our findings, we analyze
vendor privacy policies in light of existing legal frameworks and technical
capabilities, and we provide practical recommendations for both policy language
and system design to enhance transparency and empower both bystanders and
device owners.

</details>


### [23] [A Comprehensive Evaluation and Practice of System Penetration Testing](https://arxiv.org/abs/2510.26555)
*Chunyi Zhang,Jin Zeng,Xiaoqi Li*

Main category: cs.CR

TL;DR: 本文研究了系统安全渗透测试的方法与实践，探讨了如何通过系统化的渗透测试流程和技术手段提升系统安全性，分析了现有渗透工具的特点和适用领域，并通过实际案例总结了攻击经验。


<details>
  <summary>Details</summary>
Motivation: 随着信息技术快速发展，应用复杂性不断增加，网络安全挑战日益严峻，需要研究有效的系统安全渗透测试方法来应对这些挑战。

Method: 采用系统化的渗透测试流程，分析现有渗透工具的优缺点和适用领域，选择合适工具在目标范围和目标机器上复现攻击过程，并通过实际案例进行分析。

Result: 建立了系统化的渗透测试流程框架，明确了各类渗透工具的特点和适用场景，通过实际攻击案例验证了所提方法的有效性。

Conclusion: 系统化的渗透测试流程和合适的工具选择能够有效提升系统安全性，实际案例分析为未来研究提供了有价值的经验总结。

Abstract: With the rapid advancement of information technology, the complexity of
applications continues to increase, and the cybersecurity challenges we face
are also escalating. This paper aims to investigate the methods and practices
of system security penetration testing, exploring how to enhance system
security through systematic penetration testing processes and technical
approaches. It also examines existing penetration tools, analyzing their
strengths, weaknesses, and applicable domains to guide penetration testers in
tool selection. Furthermore, based on the penetration testing process outlined
in this paper, appropriate tools are selected to replicate attack processes
using target ranges and target machines. Finally, through practical case
analysis, lessons learned from successful attacks are summarized to inform
future research.

</details>


### [24] [A DRL-Empowered Multi-Level Jamming Approach for Secure Semantic Communication](https://arxiv.org/abs/2510.26610)
*Weixuan Chen,Qianqian Yang*

Main category: cs.CR

TL;DR: 提出一种基于深度强化学习的多级干扰方法，结合语义层和物理层干扰来保护语义通信系统安全，通过DDPG算法动态优化预编码矩阵，在保证安全性的同时提升合法用户的图像重建质量。


<details>
  <summary>Details</summary>
Motivation: 语义通信虽然提高了通信效率，但只传输任务相关信息会暴露语义信息给窃听者，存在安全风险。

Method: 采用语义层干扰（编码任务无关文本）和物理层干扰（编码高斯噪声）相结合的多级干扰方法，使用DDPG算法动态优化预编码矩阵，并通过交替优化策略联合训练语义通信模型和DDPG智能体。

Result: 与加密基准（ESCS）和编码干扰基准（EJ）相比，该方法在保持相当安全性的同时，将合法用户的峰值信噪比（PSNR）提升了约0.6 dB。

Conclusion: 提出的多级干扰方法能有效保护语义通信安全，同时提升合法用户的通信质量，为语义通信安全提供了新思路。

Abstract: Semantic communication (SemCom) aims to transmit only task-relevant
information, thereby improving communication efficiency but also exposing
semantic information to potential eavesdropping. In this paper, we propose a
deep reinforcement learning (DRL)-empowered multi-level jamming approach to
enhance the security of SemCom systems over MIMO fading wiretap channels. This
approach combines semantic layer jamming, achieved by encoding task-irrelevant
text, and physical layer jamming, achieved by encoding random Gaussian noise.
These two-level jamming signals are superposed with task-relevant semantic
information to protect the transmitted semantics from eavesdropping. A deep
deterministic policy gradient (DDPG) algorithm is further introduced to
dynamically design and optimize the precoding matrices for both taskrelevant
semantic information and multi-level jamming signals, aiming to enhance the
legitimate user's image reconstruction while degrading the eavesdropper's
performance. To jointly train the SemCom model and the DDPG agent, we propose
an alternating optimization strategy where the two modules are updated
iteratively. Experimental results demonstrate that, compared with both the
encryption-based (ESCS) and encoded jammer-based (EJ) benchmarks, our method
achieves comparable security while improving the legitimate user's peak
signalto-noise ratio (PSNR) by up to approximately 0.6 dB.

</details>


### [25] [Toward Automated Security Risk Detection in Large Software Using Call Graph Analysis](https://arxiv.org/abs/2510.26620)
*Nicholas Pecka,Lotfi Ben Othmane,Renee Bryce*

Main category: cs.CR

TL;DR: 该论文提出了一种通过聚类调用图来自动化软件威胁建模的方法，使用基于密度和社区检测算法来识别安全风险集群。


<details>
  <summary>Details</summary>
Motivation: 传统手动威胁建模方法劳动密集且容易出错，需要自动化解决方案来识别和缓解安全风险。

Method: 使用基于密度和社区检测算法对软件调用图进行聚类，然后分析识别出的集群相关的威胁。

Result: 通过对Splunk Forwarder Operator的案例研究验证了该方法的可行性，能够有效评估代码密度相关的安全弱点。

Conclusion: 该方法有助于推进面向现代云原生环境的可扩展、半自动化威胁建模框架的发展。

Abstract: Threat modeling plays a critical role in the identification and mitigation of
security risks; however, manual approaches are often labor intensive and prone
to error. This paper investigates the automation of software threat modeling
through the clustering of call graphs using density-based and community
detection algorithms, followed by an analysis of the threats associated with
the identified clusters. The proposed method was evaluated through a case study
of the Splunk Forwarder Operator (SFO), wherein selected clustering metrics
were applied to the software's call graph to assess pertinent code-density
security weaknesses. The results demonstrate the viability of the approach and
underscore its potential to facilitate systematic threat assessment. This work
contributes to the advancement of scalable, semi-automated threat modeling
frameworks tailored for modern cloud-native environments.

</details>
