<div id=toc></div>

# Table of Contents

- [cs.CR](#cs.CR) [Total: 16]


<div id='cs.CR'></div>

# cs.CR [[Back]](#toc)

### [1] [Post-Quantum Cryptography Key Expansion Method and Anonymous Certificate Scheme Based on NTRU](https://arxiv.org/abs/2601.07841)
*Abel C. H. Chen*

Main category: cs.CR

TL;DR: 提出一种基于NTRU的高效公钥扩展方法，并将其应用于匿名证书方案，实现一次密钥生成后多次公钥扩展


<details>
  <summary>Details</summary>
Motivation: NTRU作为重要的后量子密码方法，其密钥对生成效率相对较低，需要改进以提高实用性

Method: 提出基于NTRU的密钥扩展方法，允许从单个密钥对扩展出多个不同的公钥，并将该方法应用于匿名证书方案

Result: 实验结果表明，提出的密钥扩展方法比密钥对生成效率显著更高

Conclusion: 该方法解决了NTRU密钥生成效率低的问题，支持匿名证书方案中一次密钥生成后多次公钥扩展，提高了NTRU的实用性

Abstract: NTRU is one of the important lattice-based post-quantum cryptography methods, offering resistance against quantum computing attacks. However, a drawback of NTRU lies in its relatively low efficiency in generating key pairs. Therefore, this study proposes an NTRU-based key expansion method that enables efficient public key expansion. Furthermore, the proposed method is applied to an anonymous certificate scheme, allowing an end entity to generate a key pair only once, after which the certificate authority can expand multiple distinct public keys for anonymity. The experimental results demonstrate that the proposed key expansion method achieves significantly higher efficiency than key pair generation.

</details>


### [2] [FinVault: Benchmarking Financial Agent Safety in Execution-Grounded Environments](https://arxiv.org/abs/2601.07853)
*Zhi Yang,Runguo Li,Qiqi Qiang,Jiashun Wang,Fangqi Lou,Mengping Li,Dongpo Cheng,Rui Xu,Heng Lian,Shuo Zhang,Xiaolong Liang,Xiaoming Huang,Zheng Wei,Zhaowei Liu,Xin Guo,Huacan Wang,Ronghao Chen,Liwen Zhang*

Main category: cs.CR

TL;DR: FinVault是首个面向金融智能体的执行基础安全基准，包含31个监管案例驱动的沙盒场景、107个真实漏洞和963个测试用例，评估发现现有防御机制在真实金融场景中效果有限，攻击成功率仍高达50%。


<details>
  <summary>Details</summary>
Motivation: 现有安全评估主要关注语言模型层面的内容合规性或抽象代理设置，未能捕捉真实操作流程和状态变更行为带来的执行基础风险。在金融这种高风险、强监管环境中，LLM驱动的智能体在投资分析、风险评估和自动决策中的规划、工具调用和可变状态操作能力引入了新的安全风险。

Method: 提出FinVault基准，包含31个监管案例驱动的沙盒场景，配备可写状态数据库和明确合规约束。收集107个真实世界漏洞，构建963个测试用例，系统覆盖提示注入、越狱、金融适配攻击以及用于误报评估的良性输入。

Result: 实验结果显示，现有防御机制在真实金融智能体设置中仍然无效，最先进模型的平均攻击成功率高达50.0%，即使最稳健的系统攻击成功率也有6.7%，表明当前安全设计的可迁移性有限。

Conclusion: 当前安全设计在金融场景中的可迁移性有限，需要更强的金融特定防御机制。FinVault基准为评估金融智能体安全提供了执行基础框架，揭示了现有防御的不足。

Abstract: Financial agents powered by large language models (LLMs) are increasingly deployed for investment analysis, risk assessment, and automated decision-making, where their abilities to plan, invoke tools, and manipulate mutable state introduce new security risks in high-stakes and highly regulated financial environments. However, existing safety evaluations largely focus on language-model-level content compliance or abstract agent settings, failing to capture execution-grounded risks arising from real operational workflows and state-changing actions. To bridge this gap, we propose FinVault, the first execution-grounded security benchmark for financial agents, comprising 31 regulatory case-driven sandbox scenarios with state-writable databases and explicit compliance constraints, together with 107 real-world vulnerabilities and 963 test cases that systematically cover prompt injection, jailbreaking, financially adapted attacks, as well as benign inputs for false-positive evaluation. Experimental results reveal that existing defense mechanisms remain ineffective in realistic financial agent settings, with average attack success rates (ASR) still reaching up to 50.0\% on state-of-the-art models and remaining non-negligible even for the most robust systems (ASR 6.7\%), highlighting the limited transferability of current safety designs and the need for stronger financial-specific defenses. Our code can be found at https://github.com/aifinlab/FinVault.

</details>


### [3] [Sola-Visibility-ISPM: Benchmarking Agentic AI for Identity Security Posture Management Visibility](https://arxiv.org/abs/2601.07880)
*Gal Engelberg,Konstantin Koutsyi,Leon Goldberg,Reuven Elezra,Idan Pinto,Tal Moalem,Shmuel Cohen,Yoni Weintrob*

Main category: cs.CR

TL;DR: 首个针对身份安全态势管理（ISPM）的代理AI系统基准测试，使用真实企业环境评估AI系统在身份库存和配置卫生任务上的表现。


<details>
  <summary>Details</summary>
Motivation: 现代企业在多云和SaaS环境中面临身份安全管理的核心挑战，需要解释复杂的身份数据。尽管对代理AI系统兴趣增长，但缺乏标准化方法来评估这些系统在真实企业数据上执行ISPM可见性任务的能力。

Method: 引入Sola Visibility ISPM基准测试，使用涵盖AWS、Okta和Google Workspace的生产级身份环境，评估代理AI系统在基础ISPM可见性任务上的表现。同时开发了Sola AI Agent，这是一个工具使用代理，可将自然语言查询转换为可执行的数据探索步骤并生成可验证的证据支持答案。

Result: 在77个基准测试问题中，代理AI系统表现出色：专家准确率达到0.84，严格成功率0.77。AWS卫生任务表现最佳（专家准确率0.94），Google Workspace和Okta卫生任务表现中等但仍有竞争力。

Conclusion: 这项工作为评估身份安全领域的代理AI系统提供了实用且可复现的基准测试，为未来覆盖更高级身份分析和治理任务的ISPM基准测试奠定了基础。

Abstract: Identity Security Posture Management (ISPM) is a core challenge for modern enterprises operating across cloud and SaaS environments. Answering basic ISPM visibility questions, such as understanding identity inventory and configuration hygiene, requires interpreting complex identity data, motivating growing interest in agentic AI systems. Despite this interest, there is currently no standardized way to evaluate how well such systems perform ISPM visibility tasks on real enterprise data. We introduce the Sola Visibility ISPM Benchmark, the first benchmark designed to evaluate agentic AI systems on foundational ISPM visibility tasks using a live, production-grade identity environment spanning AWS, Okta, and Google Workspace. The benchmark focuses on identity inventory and hygiene questions and is accompanied by the Sola AI Agent, a tool-using agent that translates natural-language queries into executable data exploration steps and produces verifiable, evidence-backed answers. Across 77 benchmark questions, the agent achieves strong overall performance, with an expert accuracy of 0.84 and a strict success rate of 0.77. Performance is highest on AWS hygiene tasks, where expert accuracy reaches 0.94, while results on Google Workspace and Okta hygiene tasks are more moderate, yet competitive. Overall, this work provides a practical and reproducible benchmark for evaluating agentic AI systems in identity security and establishes a foundation for future ISPM benchmarks covering more advanced identity analysis and governance tasks.

</details>


### [4] [Small Symbols, Big Risks: Exploring Emoticon Semantic Confusion in Large Language Models](https://arxiv.org/abs/2601.07885)
*Weipeng Jiang,Xiaoyu Zhang,Juan Zhai,Shiqing Ma,Chao Shen,Yang Liu*

Main category: cs.CR

TL;DR: 研究发现LLMs存在表情符号语义混淆漏洞，会误解ASCII表情符号执行意外甚至破坏性操作，平均混淆率超38%，90%以上导致"静默失败"，现有缓解措施无效


<details>
  <summary>Details</summary>
Motivation: 表情符号在数字通信中广泛用于传达情感意图，但其对大型语言模型的安全性影响尚未充分探索。研究者发现LLMs存在表情符号语义混淆漏洞，可能导致意外和破坏性操作

Method: 开发自动化数据生成管道，构建包含3,757个代码导向测试用例的数据集，涵盖21个元场景、4种编程语言和不同上下文复杂度。在6个LLMs上进行系统性研究

Result: 表情符号语义混淆普遍存在，平均混淆率超过38%。超过90%的混淆响应产生"静默失败"（语法有效但偏离用户意图的输出）。该漏洞可转移到流行的代理框架，现有基于提示的缓解措施基本无效

Conclusion: 呼吁社区认识到这一新兴漏洞，开发有效的缓解方法以确保LLM系统的安全性和可靠性。表情符号语义混淆对LLM安全构成严重威胁，需要系统性解决方案

Abstract: Emoticons are widely used in digital communication to convey affective intent, yet their safety implications for Large Language Models (LLMs) remain largely unexplored. In this paper, we identify emoticon semantic confusion, a vulnerability where LLMs misinterpret ASCII-based emoticons to perform unintended and even destructive actions. To systematically study this phenomenon, we develop an automated data generation pipeline and construct a dataset containing 3,757 code-oriented test cases spanning 21 meta-scenarios, four programming languages, and varying contextual complexities. Our study on six LLMs reveals that emoticon semantic confusion is pervasive, with an average confusion ratio exceeding 38%. More critically, over 90% of confused responses yield 'silent failures', which are syntactically valid outputs but deviate from user intent, potentially leading to destructive security consequences. Furthermore, we observe that this vulnerability readily transfers to popular agent frameworks, while existing prompt-based mitigations remain largely ineffective. We call on the community to recognize this emerging vulnerability and develop effective mitigation methods to uphold the safety and reliability of the LLM system.

</details>


### [5] [Decentralized Firmware Integrity Verification for Cyber-Physical Systems Using Ethereum Blockchain](https://arxiv.org/abs/2601.08091)
*S M Mostaq Hossain,Amani Altarawneh*

Main category: cs.CR

TL;DR: 基于以太坊区块链的去中心化固件完整性验证框架，通过智能合约存储固件哈希值，实现防篡改、透明、无需信任的验证机制


<details>
  <summary>Details</summary>
Motivation: 传统固件完整性验证机制（如安全启动、数字签名、集中式哈希数据库）存在内部威胁和单点故障风险，无法满足现代网络物理系统（CPS）的安全需求

Method: 在以太坊Sepolia测试网上部署智能合约存储固件SHA-256哈希值，使用Web3和Infura进行链上交互，开发Python客户端工具计算哈希并与区块链通信进行实时注册和验证

Result: 成功实现原型系统，演示了合约部署、哈希注册和完整性验证，实验证明方法可靠且燃气费用低，具有实际应用价值

Conclusion: 该工作提出了一个实用且可扩展的区块链固件验证模型，显著增强了关键CPS环境中对抗固件篡改和供应链攻击的防御能力，并讨论了通过Layer-2 rollups和IPFS扩展的方案

Abstract: Firmware integrity is a foundational requirement for securing Cyber-Physical Systems (CPS), where malicious or compromised firmware can result in persistent backdoors, unauthorized control, or catastrophic system failures. Traditional verification mechanisms such as secure boot, digital signatures, and centralized hash databases are increasingly inadequate due to risks from insider threats and single points of failure. In this paper, we propose a decentralized firmware integrity verification framework built on the Ethereum blockchain, offering tamperproof, transparent, and trustless validation. Our system stores SHA-256 hashes of firmware binaries within smart contracts deployed on the Ethereum Sepolia testnet, using Web3 and Infura for seamless on-chain interaction. A Python-based client tool computes firmware hashes and communicates with the blockchain to register and verify firmware authenticity in realtime. We implement and evaluate a fully functional prototype using real firmware samples, demonstrating successful contract deployment, hash registration, and integrity verification through live blockchain transactions. Experimental results confirm the reliability and low cost (in gas fees) of our approach, highlighting its practicality and scalability for real-world CPS applications. To enhance scalability and performance, we discuss extensions using Layer-2 rollups and off-chain storage via the InterPlanetary File System (IPFS). We also outline integration pathways with secure boot mechanisms, Trusted Platform Module (TPM)based attestation, and zero-trust architectures. This work contributes a practical and extensible model for blockchain-based firmware verification, significantly strengthening the defense against firmware tampering and supply chain attacks in critical CPS environments.

</details>


### [6] [ForgetMark: Stealthy Fingerprint Embedding via Targeted Unlearning in Language Models](https://arxiv.org/abs/2601.08189)
*Zhenhua Xu,Haobo Zhang,Zhebo Wang,Qichen Liu,Haitao Xu,Wenpeng Xing,Meng Han*

Main category: cs.CR

TL;DR: ForgetMark是一种通过定向遗忘实现隐蔽模型指纹识别的框架，使用轻量级LoRA适配器抑制原始输出，通过概率性遗忘痕迹而非固定触发模式来验证所有权。


<details>
  <summary>Details</summary>
Motivation: 现有后门指纹存在高困惑度触发词易被过滤、固定响应模式易被启发式检测器发现、以及在良性输入上产生虚假激活等问题，需要更隐蔽的指纹识别方法。

Method: 构建紧凑的人类可读键值对集合，通过预测熵排序，训练轻量级LoRA适配器抑制原始键对应的值输出，同时保持模型通用能力。通过聚合似然和语义证据到指纹成功率来验证所有权。

Result: 在多种架构和设置下，对指纹模型实现100%所有权验证，同时保持标准性能，在后门基准测试中超越隐蔽性和模型合并鲁棒性，在适度增量微调下仍保持有效。

Conclusion: ForgetMark通过依赖概率性遗忘痕迹而非固定触发-响应模式，避免了高困惑度触发词，降低了可检测性和虚假触发，提供了一种更隐蔽、鲁棒的模型指纹识别方法。

Abstract: Existing invasive (backdoor) fingerprints suffer from high-perplexity triggers that are easily filtered, fixed response patterns exposed by heuristic detectors, and spurious activations on benign inputs. We introduce \textsc{ForgetMark}, a stealthy fingerprinting framework that encodes provenance via targeted unlearning. It builds a compact, human-readable key--value set with an assistant model and predictive-entropy ranking, then trains lightweight LoRA adapters to suppress the original values on their keys while preserving general capabilities. Ownership is verified under black/gray-box access by aggregating likelihood and semantic evidence into a fingerprint success rate. By relying on probabilistic forgetting traces rather than fixed trigger--response patterns, \textsc{ForgetMark} avoids high-perplexity triggers, reduces detectability, and lowers false triggers. Across diverse architectures and settings, it achieves 100\% ownership verification on fingerprinted models while maintaining standard performance, surpasses backdoor baselines in stealthiness and robustness to model merging, and remains effective under moderate incremental fine-tuning. Our code and data are available at \href{https://github.com/Xuzhenhua55/ForgetMark}{https://github.com/Xuzhenhua55/ForgetMark}.

</details>


### [7] [DNF: Dual-Layer Nested Fingerprinting for Large Language Model Intellectual Property Protection](https://arxiv.org/abs/2601.08223)
*Zhenhua Xu,Yiran Zhao,Mengting Zhong,Dezhang Kong,Changting Lin,Tong Qiao,Meng Han*

Main category: cs.CR

TL;DR: DNF是一种黑盒指纹方法，通过结合领域特定风格线索和隐式语义触发器嵌入分层后门，实现完美的指纹激活同时保持下游效用。


<details>
  <summary>Details</summary>
Motivation: 大型语言模型的快速增长引发了在黑盒部署下知识产权保护的迫切关注。现有的基于后门的指纹方法要么依赖罕见标记导致高困惑度输入易被过滤，要么使用固定的触发-响应映射容易泄露和事后适应。

Method: 提出Dual-Layer Nested Fingerprinting (DNF)方法，通过耦合领域特定风格线索与隐式语义触发器嵌入分层后门，实现黑盒指纹嵌入。

Result: 在Mistral-7B、LLaMA-3-8B-Instruct和Falcon3-7B-Instruct上，DNF实现了完美的指纹激活同时保持下游效用。相比现有方法，使用更低困惑度的触发器，在指纹检测攻击下不可检测，对增量微调和模型合并相对鲁棒。

Conclusion: DNF为LLM所有权验证和知识产权保护提供了一个实用、隐蔽且具有弹性的解决方案。

Abstract: The rapid growth of large language models raises pressing concerns about intellectual property protection under black-box deployment. Existing backdoor-based fingerprints either rely on rare tokens -- leading to high-perplexity inputs susceptible to filtering -- or use fixed trigger-response mappings that are brittle to leakage and post-hoc adaptation. We propose \textsc{Dual-Layer Nested Fingerprinting} (DNF), a black-box method that embeds a hierarchical backdoor by coupling domain-specific stylistic cues with implicit semantic triggers. Across Mistral-7B, LLaMA-3-8B-Instruct, and Falcon3-7B-Instruct, DNF achieves perfect fingerprint activation while preserving downstream utility. Compared with existing methods, it uses lower-perplexity triggers, remains undetectable under fingerprint detection attacks, and is relatively robust to incremental fine-tuning and model merging. These results position DNF as a practical, stealthy, and resilient solution for LLM ownership verification and intellectual property protection.

</details>


### [8] [A Survey of Security Challenges and Solutions for UAS Traffic Management (UTM) and small Unmanned Aerial Systems (sUAS)](https://arxiv.org/abs/2601.08229)
*Iman Sharifi,Mahyar Ghazanfari,Abenezer Taye,Peng Wei,Maheed H. Ahmed,Hyeong Tae Kim,Mahsa Ghasemi,Vijay Gupta,Noah Dahle,Robert Canady,Abel Diaz Gonzalez,Austin Coursey,Bryce Bjorkman,Cailani Lemieux-Mack,Bryan C. Ward,Xenofon Koutsoukos,Gautam Biswas,Heber Herencia-Zapana,Saqib Hasan,Isaac Amundson,Filippos Fotiadis,Ufuk Topcu,Junchi Lu,Qi Alfred Chen,Nischal Aryal,Amer Ibrahim,Abdul Karim Ras,Amir Shirkhodaie*

Main category: cs.CR

TL;DR: 本文对小型无人机系统(sUAS)在UTM环境下的网络安全漏洞和防御机制进行了全面调查，建立了统一的分类体系，并识别了实现安全可扩展操作的关键挑战。


<details>
  <summary>Details</summary>
Motivation: 小型无人机在民用和商业任务中的快速增长引发了对其网络安全韧性的担忧。这些轻量级、高度网络化的平台依赖于易受欺骗、干扰、劫持和数据操纵的CNS子系统。现有研究多停留在概念层面，缺乏针对资源受限sUAS的系统性分析。

Method: 采用系统导向的综合调查方法，将现有研究组织到完整的网络物理堆栈中，涵盖CNS、数据链路、感知、UTM云访问和软件完整性等层面，并根据技术目标和操作影响对攻击向量进行分类。

Result: 建立了统一的网络安全威胁和防御分类体系，从经典加密认证到自适应入侵检测、轻量级密码学和固件安全管理等防御机制，评估了各种缓解策略的可扩展性和实际有效性。

Conclusion: 本文为sUAS和UTM生态系统提供了全面的网络安全分析框架，识别了实现安全、可靠和可扩展操作的关键开放挑战，为未来UTM环境中的安全运营奠定了基础。

Abstract: The rapid growth of small Unmanned Aerial Systems (sUAS) for civil and commercial missions has intensified concerns about their resilience to cyber-security threats. Operating within the emerging UAS Traffic Management (UTM) framework, these lightweight and highly networked platforms depend on secure communication, navigation, and surveillance (CNS) subsystems that are vulnerable to spoofing, jamming, hijacking, and data manipulation. While prior reviews of UAS security addressed these challenges at a conceptual level, a detailed, system-oriented analysis for resource-constrained sUAS remains lacking. This paper presents a comprehensive survey of cyber-security vulnerabilities and defenses tailored to the sUAS and UTM ecosystem. We organize existing research across the full cyber-physical stack, encompassing CNS, data links, sensing and perception, UTM cloud access, and software integrity layers, and classify attack vectors according to their technical targets and operational impacts. Correspondingly, we review defense mechanisms ranging from classical encryption and authentication to adaptive intrusion detection, lightweight cryptography, and secure firmware management. By mapping threats to mitigation strategies and evaluating their scalability and practical effectiveness, this work establishes a unified taxonomy and identifies open challenges for achieving safe, secure, and scalable sUAS operations within future UTM environments.

</details>


### [9] [APT-MCL: An Adaptive APT Detection System Based on Multi-View Collaborative Provenance Graph Learning](https://arxiv.org/abs/2601.08328)
*Mingqi Lv,Shanshan Zhang,Haiwen Liu,Tieming Chen,Tiantian Zhu*

Main category: cs.CR

TL;DR: APT-MCL：基于多视图协同溯源图学习的APT检测系统，通过无监督学习和多视图特征解决APT样本稀缺、标注困难和攻击多样性问题


<details>
  <summary>Details</summary>
Motivation: 传统单点防御方法难以捕捉APT攻击的长程跨实体语义，溯源图分析虽有效但面临APT样本稀缺、细粒度标注成本高、攻击战术技术多样性的实际部署挑战

Method: 采用无监督学习策略进行节点级异常检测，基于多视图特征创建多个异常检测子模型，并在协同学习框架中集成这些模型以适应多样化攻击场景

Result: 在三个真实APT数据集上的实验验证表明：多视图特征提升了跨场景泛化能力，协同训练在标签稀缺情况下显著增强了节点级检测性能，支持多样化攻击场景的实际部署

Conclusion: APT-MCL通过多视图协同学习有效解决了APT检测中的样本稀缺、标注困难和攻击多样性问题，为实际部署提供了可行的解决方案

Abstract: Advanced persistent threats (APTs) are stealthy and multi-stage, making single-point defenses (e.g., malware- or traffic-based detectors) ill-suited to capture long-range and cross-entity attack semantics. Provenance-graph analysis has become a prominent approach for APT detection. However, its practical deployment is hampered by (i) the scarcity of APT samples, (ii) the cost and difficulty of fine-grained APT sample labeling, and (iii) the diversity of attack tactics and techniques. Aiming at these problems, this paper proposes APT-MCL, an intelligent APT detection system based on Multi-view Collaborative provenance graph Learning. It adopts an unsupervised learning strategy to discover APT attacks at the node level via anomaly detection. After that, it creates multiple anomaly detection sub-models based on multi-view features and integrates them within a collaborative learning framework to adapt to diverse attack scenarios. Extensive experiments on three real-world APT datasets validate the approach: (i) multi-view features improve cross-scenario generalization, and (ii) co-training substantially boosts node-level detection under label scarcity, enabling practical deployment on diverse attack scenarios.

</details>


### [10] [On the Maximum Toroidal Distance Code for Lattice-Based Public-Key Cryptography](https://arxiv.org/abs/2601.08452)
*Shuiyin Liu,Amin Sakzad*

Main category: cs.CR

TL;DR: 提出一种基于最大环面距离(MTD)的编码方案，用于降低格基公钥加密的解密失败率，在ℓ=2时与Minal码性能相当，在ℓ>2时优于Minal码和最大Lee距离码。


<details>
  <summary>Details</summary>
Motivation: 为了降低后量子加密方案（如NIST ML-KEM/Crystals-Kyber）的解密失败率，需要优化加密编码方案。现有方法如Minal码和最大Lee距离码在特定维度下性能有限，需要更优的编码方案。

Method: 将加密编码问题建模为在离散ℓ维环面ℤ_q^ℓ中选择2^ℓ个点，最大化最小L₂范数环面距离。针对不同维度：ℓ=2时构建Minal码变体；ℓ=4时基于D₄格构建；ℓ=8时使用2E₈格点在ℤ₄⁸中实现。

Result: 在Kyber设置下的数值评估显示：ℓ=2时与Minal码性能相当；ℓ>2时MTD码在解密失败率方面优于Minal码和最大Lee距离码；ℓ=4时达到已知最大环面距离。

Conclusion: MTD编码方案能有效降低格基PKE的解密失败率，在不同维度下提供优于现有方法的性能，为后量子加密方案提供了更可靠的编码选择。

Abstract: We propose a maximum toroidal distance (MTD) code for lattice-based public-key encryption (PKE). By formulating the encryption encoding problem as the selection of $2^\ell$ points in the discrete $\ell$-dimensional torus $\mathbb{Z}_q^\ell$, the proposed construction maximizes the minimum $L_2$-norm toroidal distance to reduce the decryption failure rate (DFR) in post-quantum schemes such as the NIST ML-KEM (Crystals-Kyber). For $\ell = 2$, we show that the MTD code is essentially a variant of the Minal code recently introduced at IACR CHES 2025. For $\ell = 4$, we present a construction based on the $D_4$ lattice that achieves the largest known toroidal distance, while for $\ell = 8$, the MTD code corresponds to $2E_8$ lattice points in $\mathbb{Z}_4^8$. Numerical evaluations under the Kyber setting show that the proposed codes outperform both Minal and maximum Lee-distance ($L_1$-norm) codes in DFR for $\ell > 2$, while matching Minal code performance for $\ell = 2$.

</details>


### [11] [Baiting AI: Deceptive Adversary Against AI-Protected Industrial Infrastructures](https://arxiv.org/abs/2601.08481)
*Aryan Pasikhani,Prosanta Gope,Yang Yang,Shagufta Mehnaz,Biplab Sikdar*

Main category: cs.CR

TL;DR: 本文提出一种针对工业控制系统（特别是水处理设施）的新型网络攻击方法，利用多智能体深度强化学习设计隐蔽的磨损攻击，旨在降低产品质量并缩短执行器寿命，同时规避AI驱动的防御系统检测。


<details>
  <summary>Details</summary>
Motivation: 随着工业控制系统日益依赖AI技术进行安全防护，攻击者也开始利用先进的AI方法（如深度强化学习）来设计更隐蔽、更有效的攻击策略。本文旨在探索DRL技术如何被恶意利用来攻击关键基础设施，揭示现有AI防御系统的潜在漏洞。

Method: 开发了一种多智能体深度强化学习方法，攻击者通过DRL算法学习制定隐蔽的攻击策略。该方法设计战略时机的磨损攻击，使攻击行为与正常操作模式无缝融合，避免被检测。攻击针对水处理设施的现场执行器，通过微妙的质量降级和寿命缩短来实现破坏。

Result: 研究证明了该攻击策略的鲁棒性，能够在行业级实验环境中成功实施。攻击不仅能够精确破坏目标基础设施，还能有效规避当代AI驱动的防御系统检测。所有相关材料（包括数据集和文档）已公开，便于复现和进一步研究。

Conclusion: 深度强化学习模型可能被恶意操纵用于对抗性目的，这对关键基础设施的安全构成了新的威胁。研究揭示了AI技术在安全领域的双重用途特性，强调了需要开发更强大的防御机制来应对这类新型智能攻击。

Abstract: This paper explores a new cyber-attack vector targeting Industrial Control Systems (ICS), particularly focusing on water treatment facilities. Developing a new multi-agent Deep Reinforcement Learning (DRL) approach, adversaries craft stealthy, strategically timed, wear-out attacks designed to subtly degrade product quality and reduce the lifespan of field actuators. This sophisticated method leverages DRL methodology not only to execute precise and detrimental impacts on targeted infrastructure but also to evade detection by contemporary AI-driven defence systems. By developing and implementing tailored policies, the attackers ensure their hostile actions blend seamlessly with normal operational patterns, circumventing integrated security measures. Our research reveals the robustness of this attack strategy, shedding light on the potential for DRL models to be manipulated for adversarial purposes. Our research has been validated through testing and analysis in an industry-level setup. For reproducibility and further study, all related materials, including datasets and documentation, are publicly accessible.

</details>


### [12] [MASH: Evading Black-Box AI-Generated Text Detectors via Style Humanization](https://arxiv.org/abs/2601.08564)
*Yongtong Gu,Songze Li,Xia Hu*

Main category: cs.CR

TL;DR: MASH是一种通过风格转移来逃避黑盒AIGT检测器的新型框架，采用多阶段对齐方法使AI生成文本更接近人类写作风格，在6个数据集和5个检测器上平均攻击成功率92%，优于11个基线方法。


<details>
  <summary>Details</summary>
Motivation: 当前AIGT检测器在对抗性规避方面可靠性脆弱，现有攻击方法要么依赖白盒假设，要么计算和交互成本过高，在实际黑盒场景中效果有限，需要更有效的黑盒攻击方法。

Method: 提出MASH框架，通过风格转移使AI生成文本分布接近人类写作分布。采用三阶段方法：1) 风格注入监督微调；2) 直接偏好优化；3) 推理时精炼。

Result: 在6个数据集和5个检测器上的实验表明，MASH平均攻击成功率达92%，比最强基线平均提升24%，同时保持优异的语言质量。

Conclusion: MASH通过多阶段风格对齐有效规避黑盒AIGT检测器，在攻击成功率和语言质量方面均优于现有方法，为黑盒场景下的对抗性规避提供了有效解决方案。

Abstract: The increasing misuse of AI-generated texts (AIGT) has motivated the rapid development of AIGT detection methods. However, the reliability of these detectors remains fragile against adversarial evasions. Existing attack strategies often rely on white-box assumptions or demand prohibitively high computational and interaction costs, rendering them ineffective under practical black-box scenarios. In this paper, we propose Multi-stage Alignment for Style Humanization (MASH), a novel framework that evades black-box detectors based on style transfer. MASH sequentially employs style-injection supervised fine-tuning, direct preference optimization, and inference-time refinement to shape the distributions of AI-generated texts to resemble those of human-written texts. Experiments across 6 datasets and 5 detectors demonstrate the superior performance of MASH over 11 baseline evaders. Specifically, MASH achieves an average Attack Success Rate (ASR) of 92%, surpassing the strongest baselines by an average of 24%, while maintaining superior linguistic quality.

</details>


### [13] [Estimating the True Distribution of Data Collected with Randomized Response](https://arxiv.org/abs/2601.08603)
*Carlos Antonio Pinzón,Ehab ElSalamouny,Lucas Massot,Alexis Miller,Héber Hwang Arcolezi,Catuscia Palamidessi*

Main category: cs.CR

TL;DR: 本文针对随机响应（RR）协议中标准去偏规则可能产生负值的问题，提出了一个简单的精确最大似然估计（MLE）公式，避免了迭代贝叶斯更新算法（IBU）的缓慢收敛问题。


<details>
  <summary>Details</summary>
Motivation: 随机响应协议在收集和分析分类数据时存在标准去偏规则可能产生负值的问题，而现有解决方案如迭代贝叶斯更新算法收敛缓慢。需要找到更高效、准确的估计方法。

Method: 本文通过推导出一个简单的公式来直接计算随机响应协议的确切最大似然估计（MLE），绕过了需要迭代的IBU算法。同时通过实验比较了不同估计方法的性能。

Result: 提出的简单公式能够直接计算精确的MLE，避免了IBU的迭代过程。实验比较表明该方法在准确性和效率上具有优势，为实践者提供了更好的选择依据。

Conclusion: 本文提供了一种简单有效的精确MLE计算公式，解决了随机响应协议中标准去偏规则产生负值的问题，为数据收集实践者提供了更好的估计方法选择。

Abstract: Randomized Response (RR) is a protocol designed to collect and analyze categorical data with local differential privacy guarantees. It has been used as a building block of mechanisms deployed by Big tech companies to collect app or web users' data. Each user reports an automatic random alteration of their true value to the analytics server, which then estimates the histogram of the true unseen values of all users using a debiasing rule to compensate for the added randomness. A known issue is that the standard debiasing rule can yield a vector with negative values (which can not be interpreted as a histogram), and there is no consensus on the best fix. An elegant but slow solution is the Iterative Bayesian Update algorithm (IBU), which converges to the Maximum Likelihood Estimate (MLE) as the number of iterations goes to infinity. This paper bypasses IBU by providing a simple formula for the exact MLE of RR and compares it with other estimation methods experimentally to help practitioners decide which one to use.

</details>


### [14] [Double Strike: Breaking Approximation-Based Side-Channel Countermeasures for DNNs](https://arxiv.org/abs/2601.08698)
*Lorenzo Casalino,Maria Méndez Real,Jean-Christophe Prévotet,Rubén Salvador*

Main category: cs.CR

TL;DR: 本文分析了MACPRUNING侧信道防御机制的漏洞，提出了一种利用控制流依赖性的预处理方法，成功恢复了受保护DNN实现中的重要权重，证明了该防御机制的安全性大幅降低。


<details>
  <summary>Details</summary>
Motivation: DNN权重作为重要的知识产权资产需要保护。虽然MACPRUNING被提出作为基于剪枝的侧信道防御机制，但其原始安全分析未考虑控制流依赖性，这可能让攻击者绕过防御并恢复对DNN精度重要的权重。

Method: 提出了一种预处理方法来利用MACPRUNING中的控制流依赖性。通过在Chipwhisperer-Lite上对受MACPRUNING保护的多层感知器进行实际实验，针对每个神经元的前8个权重进行攻击。

Result: 成功恢复了96%的重要权重，表明受保护实现的安全性大幅降低。此外，微架构泄漏进一步提高了方法的有效性，甚至能恢复100%的目标非重要权重。

Conclusion: MACPRUNING防御机制存在严重安全漏洞，控制流依赖性可被利用来恢复关键权重。需要重新评估和改进基于剪枝的侧信道防御设计。

Abstract: Deep neural networks (DNNs), which support services such as driving assistants and medical diagnoses, undergo lengthy and expensive training procedures. Therefore, the training's outcome - the DNN weights - represents a significant intellectual property asset to protect. Side-channel analysis (SCA) has recently appeared as an effective approach to recover this confidential asset from DNN implementations. In response, researchers have proposed to defend DNN implementations through classic side-channel countermeasures, at the cost of higher energy consumption, inference time, and resource utilisation. Following a different approach, Ding et al. (HOST'25) introduced MACPRUNING, a novel SCA countermeasure based on pruning, a performance-oriented Approximate Computing technique: at inference time, the implementation randomly prunes (or skips) non-important weights (i.e., with low contribution to the DNN's accuracy) of the first layer, exponentially increasing the side-channel resilience of the protected DNN implementation. However, the original security analysis of MACPRUNING did not consider a control-flow dependency intrinsic to the countermeasure design. This dependency may allow an attacker to circumvent MACPRUNING and recover the weights important to the DNN's accuracy. This paper describes a preprocessing methodology to exploit the above-mentioned control-flow dependency. Through practical experiments on a Chipwhisperer-Lite running a MACPRUNING-protected Multi-Layer Perceptron, we target the first 8 weights of each neuron and recover 96% of the important weights, demonstrating the drastic reduction in security of the protected implementation. Moreover, we show how microarchitectural leakage improves the effectiveness of our methodology, even allowing for the recovery of up to 100% of the targeted non-important weights. Lastly, by adapting our methodology [continue in pdf].

</details>


### [15] [Malware Detection based on API Calls: A Reproducibility Study](https://arxiv.org/abs/2601.08725)
*Juhani Merilehto*

Main category: cs.CR

TL;DR: 成功复现了基于API调用频率分析和随机森林分类的恶意软件检测方法，所有模型变体的F1分数均超过原始结果0.99%-2.57%，验证了该方法的稳健性和可重复性。


<details>
  <summary>Details</summary>
Motivation: 验证Felli cious等人提出的基于API调用频率分析和随机森林分类的恶意软件检测方法的科学严谨性和可重复性，确认该方法在实际应用中的可行性。

Method: 使用原始公开数据集（250,533个训练样本，83,511个测试样本），复现了四种模型变体：Unigram、Bigram、Trigram和Combined n-gram方法，采用最优API调用长度2,500进行随机森林分类。

Result: 所有模型变体的F1分数均超过原始结果：Unigram模型F1=0.8717（原始：0.8631），提升0.99%-2.57%。三次独立实验的标准偏差低于0.5%，显示高度一致性。Unigram模型被确认为轻量级恶意软件检测器的有效方案。

Conclusion: 成功验证了原始方法的稳健性和科学严谨性，确认了基于频率的API调用分析在恶意软件检测中的实际可行性，为该方法的应用提供了可靠依据。

Abstract: This study independently reproduces the malware detection methodology presented by Felli cious et al. [7], which employs order-invariant API call frequency analysis using Random Forest classification. We utilized the original public dataset (250,533 training samples, 83,511 test samples) and replicated four model variants: Unigram, Bigram, Trigram, and Combined n gram approaches. Our reproduction successfully validated all key findings, achieving F1-scores that exceeded the original results by 0.99% to 2.57% across all models at the optimal API call length of 2,500. The Unigram model achieved F1=0.8717 (original: 0.8631), confirming its ef fectiveness as a lightweight malware detector. Across three independent experimental runs with different random seeds, we observed remarkably consistent results with standard deviations be low 0.5%, demonstrating high reproducibility. This study validates the robustness and scientific rigor of the original methodology while confirming the practical viability of frequency-based API call analysis for malware detection.

</details>


### [16] [Memory DisOrder: Memory Re-orderings as a Timerless Side-channel](https://arxiv.org/abs/2601.08770)
*Sean Siddens,Sanya Srivastava,Reese Levine,Josiah Dykstra,Tyler Sorensen*

Main category: cs.CR

TL;DR: Memory DisOrder是一种无定时器的侧信道攻击，利用内存重排序来推断其他进程的活动，影响多种主流处理器架构，可实现隐蔽信道和应用程序指纹识别等攻击。


<details>
  <summary>Details</summary>
Motivation: 现代并行处理单元（CPU和GPU）采用宽松内存模型以提高效率，允许内存操作重排序。先前研究发现，当其他核心活跃时（如内存系统压力大时），内存重排序现象更频繁，这触发了硬件优化。本研究旨在探索如何利用这种内存重排序作为侧信道来检测其他进程的活动。

Method: 1. 进行模糊测试活动，验证多种主流处理器（X86/Arm/Apple CPU，NVIDIA/AMD/Apple GPU）对跨进程信号的敏感性；2. 展示如何利用该漏洞实现经典攻击：包括隐蔽信道和应用程序指纹识别；3. 探索如何利用低级系统细节增加重排序频率，提升攻击效率。

Result: 1. 多种主流处理器架构均存在跨进程信号泄露漏洞；2. 在Apple M3 GPU上实现隐蔽信道，达到16位/秒的传输速率和95%准确率；3. 在多个CPU和Apple M3 GPU上实现可靠的封闭世界DNN架构指纹识别；4. 通过利用低级系统细节，在X86 CPU上可实现接近30K位/秒的隐蔽信道传输速率。

Conclusion: Memory DisOrder是一种有效的无定时器侧信道攻击，利用内存重排序漏洞可检测其他进程活动。该漏洞影响广泛，随着对其理解的深入，可能开发出更精确的攻击。这揭示了现代处理器内存模型的安全隐患，需要硬件和软件层面的防护措施。

Abstract: To improve efficiency, nearly all parallel processing units (CPUs and GPUs) implement relaxed memory models in which memory operations may be re-ordered, i.e., executed out-of-order. Prior testing work in this area found that memory re-orderings are observed more frequently when other cores are active, e.g., stressing the memory system, which likely triggers aggressive hardware optimizations.
  In this work, we present Memory DisOrder: a timerless side-channel that uses memory re-orderings to infer activity on other processes. We first perform a fuzzing campaign and show that many mainstream processors (X86/Arm/Apple CPUs, NVIDIA/AMD/Apple GPUs) are susceptible to cross-process signals. We then show how the vulnerability can be used to implement classic attacks, including a covert channel, achieving up to 16 bits/second with 95% accuracy on an Apple M3 GPU, and application fingerprinting, achieving reliable closed-world DNN architecture fingerprinting on several CPUs and an Apple M3 GPU. Finally, we explore how low-level system details can be exploited to increase re-orderings, showing the potential for a covert channel to achieve nearly 30K bits/second on X86 CPUs. More precise attacks can likely be developed as the vulnerability becomes better understood.

</details>
