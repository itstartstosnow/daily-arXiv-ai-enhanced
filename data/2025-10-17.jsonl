{"id": "2510.13822", "categories": ["cs.CR", "cs.NI"], "pdf": "https://arxiv.org/pdf/2510.13822", "abs": "https://arxiv.org/abs/2510.13822", "authors": ["Bartosz Burgiel"], "title": "Noisy Networks, Nosy Neighbors: Inferring Privacy Invasive Information from Encrypted Wireless Traffic", "comment": "80 pages, 49 figures, bachelor thesis at the data privacy and\n  security chair of the leipzig university", "summary": "This thesis explores the extent to which passive observation of wireless\ntraffic in a smart home environment can be used to infer privacy-invasive\ninformation about its inhabitants. Using a setup that mimics the capabilities\nof a nosy neighbor in an adjacent flat, we analyze raw 802.11 packets and\nBluetooth Low Energy advertisemets. From this data, we identify devices, infer\ntheir activity states and approximate their location using RSSI-based\ntrilateration. Despite the encrypted nature of the data, we demonstrate that it\nis possible to detect active periods of multimedia devices, infer common\nactivities such as sleeping, working and consuming media, and even approximate\nthe layout of the neighbor's apartment. Our results show that privacy risks in\nsmart homes extend beyond traditional data breaches: a nosy neighbor behind the\nwall can gain privacy-invasive insights into the lives of their neighbors\npurely from encrypted network traffic."}
{"id": "2510.13824", "categories": ["cs.CR", "cs.NI"], "pdf": "https://arxiv.org/pdf/2510.13824", "abs": "https://arxiv.org/abs/2510.13824", "authors": ["Wai Ming Chan", "Remi Chou", "Taejoon Kim"], "title": "Multi-Layer Secret Sharing for Cross-Layer Attack Defense in 5G Networks: a COTS UE Demonstration", "comment": null, "summary": "This demo presents the first implementation of multi-layer secret sharing on\ncommercial-off-the-shelf (COTS) 5G user equipment (UE), operating without\ninfrastructure modifications or pre-shared keys. Our XOR-based approach\ndistributes secret shares across network operators and distributed relays,\nensuring perfect recovery and data confidentiality even if one network operator\nand one relay are simultaneously lost (e.g., under denial of service (DoS) or\nunanticipated attacks)."}
{"id": "2510.13825", "categories": ["cs.CR", "cs.AI"], "pdf": "https://arxiv.org/pdf/2510.13825", "abs": "https://arxiv.org/abs/2510.13825", "authors": ["Eugene Neelou", "Ivan Novikov", "Max Moroz", "Om Narayan", "Tiffany Saade", "Mika Ayenson", "Ilya Kabanov", "Jen Ozmen", "Edward Lee", "Vineeth Sai Narajala", "Emmanuel Guilherme Junior", "Ken Huang", "Huseyin Gulsin", "Jason Ross", "Marat Vyshegorodtsev", "Adelin Travers", "Idan Habler", "Rahul Jadav"], "title": "A2AS: Agentic AI Runtime Security and Self-Defense", "comment": null, "summary": "The A2AS framework is introduced as a security layer for AI agents and\nLLM-powered applications, similar to how HTTPS secures HTTP. A2AS enforces\ncertified behavior, activates model self-defense, and ensures context window\nintegrity. It defines security boundaries, authenticates prompts, applies\nsecurity rules and custom policies, and controls agentic behavior, enabling a\ndefense-in-depth strategy. The A2AS framework avoids latency overhead, external\ndependencies, architectural changes, model retraining, and operational\ncomplexity. The BASIC security model is introduced as the A2AS foundation: (B)\nBehavior certificates enable behavior enforcement, (A) Authenticated prompts\nenable context window integrity, (S) Security boundaries enable untrusted input\nisolation, (I) In-context defenses enable secure model reasoning, (C) Codified\npolicies enable application-specific rules. This first paper in the series\nintroduces the BASIC security model and the A2AS framework, exploring their\npotential toward establishing the A2AS industry standard."}
{"id": "2510.14005", "categories": ["cs.CR", "cs.LG"], "pdf": "https://arxiv.org/pdf/2510.14005", "abs": "https://arxiv.org/abs/2510.14005", "authors": ["Wei Zou", "Yupei Liu", "Yanting Wang", "Ying Chen", "Neil Gong", "Jinyuan Jia"], "title": "PIShield: Detecting Prompt Injection Attacks via Intrinsic LLM Features", "comment": "The code is available at https://github.com/weizou52/PIShield", "summary": "LLM-integrated applications are vulnerable to prompt injection attacks, where\nan attacker contaminates the input to inject malicious prompts, causing the LLM\nto follow the attacker's intent instead of the original user's. Existing prompt\ninjection detection methods often have sub-optimal performance and/or high\ncomputational overhead. In this work, we propose PIShield, a detection method\nthat is both effective and efficient. Our key observation is that the internal\nrepresentation of the final token in a prompt-extracted from a specific layer\nof the LLM, which we term the injection-critical layer-captures distinguishing\nfeatures between clean and contaminated prompts. Leveraging this insight, we\ntrain a simple linear classifier on these internal representations using a\nlabeled set of clean and contaminated prompts. We compare PIShield against 11\nbaselines across 5 diverse benchmark datasets and 8 prompt injection attacks.\nThe results demonstrate that PIShield is both highly effective and efficient,\nsubstantially outperforming existing methods. Additionally, we show that\nPIShield resists strong adaptive attacks."}
{"id": "2510.14066", "categories": ["cs.CR"], "pdf": "https://arxiv.org/pdf/2510.14066", "abs": "https://arxiv.org/abs/2510.14066", "authors": ["Rajendra Upadhyay", "Al Nahian Bin Emran", "Rajendra Paudyal", "Lisa Donnan", "Duminda Wijesekera"], "title": "Quantitative Analysis of UAV Intrusion Mitigation for Border Security in 5G with LEO Backhaul Impairments", "comment": null, "summary": "Uncooperative unmanned aerial vehicles (UAVs) pose emerging threats to\ncritical infrastructure and border protection by operating as rogue user\nequipment (UE) within cellular networks, consuming resources, creating\ninterference, and potentially violating restricted airspaces. This paper\npresents minimal features of the operating space, yet an end-to-end simulation\nframework to analyze detect-to-mitigate latency of such intrusions in a hybrid\nterrestrial-non-terrestrial (LEO satellite) 5G system. The system model\nincludes terrestrial gNBs, satellite backhaul (with stochastic outages), and a\ndetection logic (triggered by handover instability and signal quality\nvariance). A lockdown mechanism is invoked upon detection, with optional local\nfallback to cap mitigation delays. Monte Carlo sweeps across UAV altitudes,\nspeeds, and satellite outage rates yield several insights. First, satellite\nbackhaul outages can cause arbitrarily long mitigation delays, yet, to meet\nfallback deadlines, they need to be effectively bounded. Second, while handover\ninstability was hypothesized, our results show that extra handovers have a\nnegligible effect within the range of parameters we considered. The main\nbenefit of resilience from fallback comes from the delay in limiting\nmitigation. Third, patrol UEs experience negligible collateral impact, with\nhandover rates close to terrestrial baselines. Stress scenarios further\nhighlight that fallback is indispensable in preventing extreme control-plane\nand physical security vulnerabilities: Without fallback, prolonged outages in\nthe satellite backhaul delay lockdown commands, allowing rogue UAVs to linger\ninside restricted corridors for several seconds longer. These results\nunderscore the importance of complementing non-terrestrial links with local\ncontrol to ensure robust and timely response against uncooperative UAV\nintrusions."}
{"id": "2510.14086", "categories": ["cs.CR", "cs.AI"], "pdf": "https://arxiv.org/pdf/2510.14086", "abs": "https://arxiv.org/abs/2510.14086", "authors": ["Matthew Finlayson", "Xiang Ren", "Swabha Swayamdipta"], "title": "Every Language Model Has a Forgery-Resistant Signature", "comment": null, "summary": "The ubiquity of closed-weight language models with public-facing APIs has\ngenerated interest in forensic methods, both for extracting hidden model\ndetails (e.g., parameters) and for identifying models by their outputs. One\nsuccessful approach to these goals has been to exploit the geometric\nconstraints imposed by the language model architecture and parameters. In this\nwork, we show that a lesser-known geometric constraint--namely, that language\nmodel outputs lie on the surface of a high-dimensional ellipse--functions as a\nsignature for the model and can be used to identify the source model of a given\noutput. This ellipse signature has unique properties that distinguish it from\nexisting model-output association methods like language model fingerprints. In\nparticular, the signature is hard to forge: without direct access to model\nparameters, it is practically infeasible to produce log-probabilities\n(logprobs) on the ellipse. Secondly, the signature is naturally occurring,\nsince all language models have these elliptical constraints. Thirdly, the\nsignature is self-contained, in that it is detectable without access to the\nmodel inputs or the full weights. Finally, the signature is compact and\nredundant, as it is independently detectable in each logprob output from the\nmodel. We evaluate a novel technique for extracting the ellipse from small\nmodels and discuss the practical hurdles that make it infeasible for\nproduction-scale models. Finally, we use ellipse signatures to propose a\nprotocol for language model output verification, analogous to cryptographic\nsymmetric-key message authentication systems."}
{"id": "2510.14171", "categories": ["cs.CR"], "pdf": "https://arxiv.org/pdf/2510.14171", "abs": "https://arxiv.org/abs/2510.14171", "authors": ["Jack Vanlyssel"], "title": "Power Grid Cybersecurity: Policy Analysis White Paper", "comment": null, "summary": "The U.S. power grid underpins national security, public safety, and economic\nstability, but faces growing cyber risks from vulnerabilities in industrial\ncontrol systems, remote access, and poor cyber hygiene. Despite its critical\nimportance, current policy remains fragmented and reactive. This paper proposes\na dual policy approach to strengthen grid cybersecurity: enhanced information\nsharing between government and private utilities to improve threat detection\nand response, and standardized cyber hygiene practices to reduce common attack\nvectors. For long-term resilience, a Unified National Cybersecurity Framework\nis recommended to align existing NERC, IEC, IEEE, and NIST standards, eliminate\nregulatory overlap, and adapt to evolving threats. Together, these policies\noffer both immediate and sustainable improvements in safeguarding the nation's\nmost vital infrastructure."}
{"id": "2510.14185", "categories": ["cs.CR"], "pdf": "https://arxiv.org/pdf/2510.14185", "abs": "https://arxiv.org/abs/2510.14185", "authors": ["Jack Vanlyssel"], "title": "Securing U.S. Critical Infrastructure: Lessons from Stuxnet and the Ukraine Power Grid Attacks", "comment": null, "summary": "Industrial Control Systems (ICS) underpin the United States' critical\ninfrastructure, managing essential services such as power, water, and\ntransportation that are vital to national security and public safety. However,\nincreasing digital integration has exposed these systems to escalating cyber\nthreats. Historical attacks like Stuxnet and the Ukraine power grid incident\nrevealed exploitable weaknesses-poor network segmentation, outdated software,\nweak authentication, and inadequate monitoring-that persist in many U.S. ICS\nenvironments today. This paper analyzes these landmark attacks to identify\nrecurring vulnerabilities and assess their relevance to current U.S.\ninfrastructure. It argues that without immediate reforms, similar exploits\ncould lead to catastrophic disruptions and national security crises. To address\nthese risks, the paper proposes policy measures focused on implementing\nzero-trust architecture and improved network segmentation to enhance system\nresilience. These recommendations aim to guide policymakers and industry\nleaders in securing the nation's most critical operational technologies against\nfuture cyber threats."}
{"id": "2510.14198", "categories": ["cs.CR"], "pdf": "https://arxiv.org/pdf/2510.14198", "abs": "https://arxiv.org/abs/2510.14198", "authors": ["Morium Akter Munny", "Mahbub Alam", "Sonjoy Kumar Paul", "Daniel Timko", "Muhammad Lutfor Rahman", "Nitesh Saxena"], "title": "Infrastructure Patterns in Toll Scam Domains: A Comprehensive Analysis of Cybercriminal Registration and Hosting Strategies", "comment": "This paper has been accepted for presentation at eCrime 2025", "summary": "Toll scams involve criminals registering fake domains that pretend to be\nlegitimate transportation agencies to trick users into making fraudulent\npayments. Although these scams are rapidly increasing and causing significant\nharm, they have not been extensively studied. We present the first large-scale\nanalysis of toll scam domains, using a newly created dataset of 67,907\nconfirmed scam domains mostly registered in 2025. Our study reveals that\nattackers exploit permissive registrars and less common top-level domains, with\n86.9% of domains concentrated in just five non-mainstream TLDs and 72.9%\nregistered via a single provider. We also discover specific registration\npatterns, including short bursts of activity that suggest automated,\ncoordinated attacks, with over half of domains registered in the first quarter\nof 2025. This extreme temporal clustering reflects highly synchronized campaign\nlaunches. Additionally, we build a simple predictive model using only domain\nregistration data to predict which scam domains are likely to be suspended -- a\nproxy for confirmed abuse -- achieving 80.4% accuracy, and 92.3% sensitivity.\nOur analysis reveals attacker strategies for evading detection -- such as\nexploiting obscure TLDs, permissive registrars, and coordinated registration\nbursts -- which can inform more targeted interventions by registrars, hosting\nproviders, and security platforms. However, our results suggest that\nregistration metadata alone may be insufficient, and incorporating features\nfrom domain URLs and webpage content could further improve detection."}
{"id": "2510.14218", "categories": ["cs.CR"], "pdf": "https://arxiv.org/pdf/2510.14218", "abs": "https://arxiv.org/abs/2510.14218", "authors": ["Chaoyue Huang", "Gejian Zhao", "Hanzhou Wu", "Zhihua Xia", "Asad Malik"], "title": "An Information Asymmetry Game for Trigger-based DNN Model Watermarking", "comment": null, "summary": "As a valuable digital product, deep neural networks (DNNs) face increasingly\nsevere threats to the intellectual property, making it necessary to develop\neffective technical measures to protect them. Trigger-based watermarking\nmethods achieve copyright protection by embedding triggers into the host DNNs.\nHowever, the attacker may remove the watermark by pruning or fine-tuning. We\nmodel this interaction as a game under conditions of information asymmetry,\nnamely, the defender embeds a secret watermark with private knowledge, while\nthe attacker can only access the watermarked model and seek removal. We define\nstrategies, costs, and utilities for both players, derive the attacker's\noptimal pruning budget, and establish an exponential lower bound on the\naccuracy of watermark detection after attack. Experimental results demonstrate\nthe feasibility of the watermarked model, and indicate that sparse watermarking\ncan resist removal with negligible accuracy loss. This study highlights the\neffectiveness of game-theoretic analysis in guiding the design of robust\nwatermarking schemes for model copyright protection."}
{"id": "2510.14233", "categories": ["cs.CR"], "pdf": "https://arxiv.org/pdf/2510.14233", "abs": "https://arxiv.org/abs/2510.14233", "authors": ["Fanchao Meng", "Jiaping Gui", "Yunbo Li", "Yue Wu"], "title": "RHINO: Guided Reasoning for Mapping Network Logs to Adversarial Tactics and Techniques with Large Language Models", "comment": null, "summary": "Modern Network Intrusion Detection Systems generate vast volumes of low-level\nalerts, yet these outputs remain semantically fragmented, requiring\nlabor-intensive manual correlation with high-level adversarial behaviors.\nExisting solutions for automating this mapping-rule-based systems and machine\nlearning classifiers-suffer from critical limitations: rule-based approaches\nfail to adapt to novel attack variations, while machine learning methods lack\ncontextual awareness and treat tactic-technique mapping as a syntactic matching\nproblem rather than a reasoning task. Although Large Language Models have shown\npromise in cybersecurity tasks, preliminary experiments reveal that existing\nLLM-based methods frequently hallucinate technique names or produce\ndecontextualized mappings due to their single-step classification approach.\n  To address these challenges, we introduce RHINO, a novel framework that\ndecomposes LLM-based attack analysis into three interpretable phases mirroring\nhuman reasoning: (1) behavioral abstraction, where raw logs are translated into\ncontextualized narratives; (2) multi-role collaborative inference, generating\ncandidate techniques by evaluating behavioral evidence against MITRE ATT&CK\nknowledge; and (3) validation, cross-referencing predictions with official\nMITRE definitions to rectify hallucinations. RHINO bridges the semantic gap\nbetween low-level observations and adversarial intent while improving output\nreliability through structured reasoning.\n  We evaluate RHINO on three benchmarks across four backbone models. RHINO\nachieved high accuracy, with model performance ranging from 86.38% to 88.45%,\nresulting in relative gains from 24.25% to 76.50% across different models. Our\nresults demonstrate that RHINO significantly enhances the interpretability and\nscalability of threat analysis, offering a blueprint for deploying LLMs in\noperational security settings."}
{"id": "2510.14283", "categories": ["cs.CR", "cs.AI", "cs.LG"], "pdf": "https://arxiv.org/pdf/2510.14283", "abs": "https://arxiv.org/abs/2510.14283", "authors": ["Xinhao Deng", "Jingyou Chen", "Linxiao Yu", "Yixiang Zhang", "Zhongyi Gu", "Changhao Qiu", "Xiyuan Zhao", "Ke Xu", "Qi Li"], "title": "Beyond a Single Perspective: Towards a Realistic Evaluation of Website Fingerprinting Attacks", "comment": null, "summary": "Website Fingerprinting (WF) attacks exploit patterns in encrypted traffic to\ninfer the websites visited by users, posing a serious threat to anonymous\ncommunication systems. Although recent WF techniques achieve over 90% accuracy\nin controlled experimental settings, most studies remain confined to single\nscenarios, overlooking the complexity of real-world environments. This paper\npresents the first systematic and comprehensive evaluation of existing WF\nattacks under diverse realistic conditions, including defense mechanisms,\ntraffic drift, multi-tab browsing, early-stage detection, open-world settings,\nand few-shot scenarios. Experimental results show that many WF techniques with\nstrong performance in isolated settings degrade significantly when facing other\nconditions. Since real-world environments often combine multiple challenges,\ncurrent WF attacks are difficult to apply directly in practice. This study\nhighlights the limitations of WF attacks and introduces a multidimensional\nevaluation framework, offering critical insights for developing more robust and\npractical WF attacks."}
{"id": "2510.14344", "categories": ["cs.CR", "cs.AI"], "pdf": "https://arxiv.org/pdf/2510.14344", "abs": "https://arxiv.org/abs/2510.14344", "authors": ["Zichen Liu", "Shao Yang", "Xusheng Xiao"], "title": "BinCtx: Multi-Modal Representation Learning for Robust Android App Behavior Detection", "comment": null, "summary": "Mobile app markets host millions of apps, yet undesired behaviors (e.g.,\ndisruptive ads, illegal redirection, payment deception) remain hard to catch\nbecause they often do not rely on permission-protected APIs and can be easily\ncamouflaged via UI or metadata edits. We present BINCTX, a learning approach\nthat builds multi-modal representations of an app from (i) a global\nbytecode-as-image view that captures code-level semantics and family-style\npatterns, (ii) a contextual view (manifested actions, components, declared\npermissions, URL/IP constants) indicating how behaviors are triggered, and\n(iii) a third-party-library usage view summarizing invocation frequencies along\ninter-component call paths. The three views are embedded and fused to train a\ncontextual-aware classifier. On real-world malware and benign apps, BINCTX\nattains a macro F1 of 94.73%, outperforming strong baselines by at least\n14.92%. It remains robust under commercial obfuscation (F1 84%\npost-obfuscation) and is more resistant to adversarial samples than\nstate-of-the-art bytecode-only systems."}
{"id": "2510.14384", "categories": ["cs.CR", "cs.SE"], "pdf": "https://arxiv.org/pdf/2510.14384", "abs": "https://arxiv.org/abs/2510.14384", "authors": ["Sebastian Jänich", "Merlin Sievers", "Johannes Kinder"], "title": "Match & Mend: Minimally Invasive Local Reassembly for Patching N-day Vulnerabilities in ARM Binaries", "comment": null, "summary": "Low-cost Internet of Things (IoT) devices are increasingly popular but often\ninsecure due to poor update regimes. As a result, many devices run outdated and\nknown-vulnerable versions of open-source software. We address this problem by\nproposing to patch IoT firmware at the binary level, without requiring vendor\nsupport. In particular, we introduce minimally invasive local reassembly, a new\ntechnique for automatically patching known (n-day) vulnerabilities in IoT\nfirmware. Our approach is designed to minimize side effects and reduce the risk\nof introducing breaking changes. We systematically evaluate our approach both\non 108 binaries within the controlled environment of the MAGMA benchmarks, as\nwell as on 30 real-world Linux-based IoT firmware images from the KARONTE\ndataset. Our prototype successfully patches 83% of targeted vulnerabilities in\nMAGMA and 96% in the firmware dataset."}
{"id": "2510.14470", "categories": ["cs.CR", "cs.AI"], "pdf": "https://arxiv.org/pdf/2510.14470", "abs": "https://arxiv.org/abs/2510.14470", "authors": ["Xiaoyu Xue", "Yuni Lai", "Chenxi Huang", "Yulin Zhu", "Gaolei Li", "Xiaoge Zhang", "Kai Zhou"], "title": "Stealthy Dual-Trigger Backdoors: Attacking Prompt Tuning in LM-Empowered Graph Foundation Models", "comment": null, "summary": "The emergence of graph foundation models (GFMs), particularly those\nincorporating language models (LMs), has revolutionized graph learning and\ndemonstrated remarkable performance on text-attributed graphs (TAGs). However,\ncompared to traditional GNNs, these LM-empowered GFMs introduce unique security\nvulnerabilities during the unsecured prompt tuning phase that remain\nunderstudied in current research. Through empirical investigation, we reveal a\nsignificant performance degradation in traditional graph backdoor attacks when\noperating in attribute-inaccessible constrained TAG systems without explicit\ntrigger node attribute optimization. To address this, we propose a novel\ndual-trigger backdoor attack framework that operates at both text-level and\nstruct-level, enabling effective attacks without explicit optimization of\ntrigger node text attributes through the strategic utilization of a\npre-established text pool. Extensive experimental evaluations demonstrate that\nour attack maintains superior clean accuracy while achieving outstanding attack\nsuccess rates, including scenarios with highly concealed single-trigger nodes.\nOur work highlights critical backdoor risks in web-deployed LM-empowered GFMs\nand contributes to the development of more robust supervision mechanisms for\nopen-source platforms in the era of foundation models."}
{"id": "2510.14480", "categories": ["cs.CR", "cs.SE"], "pdf": "https://arxiv.org/pdf/2510.14480", "abs": "https://arxiv.org/abs/2510.14480", "authors": ["Massimo Bartoletti", "Riccardo Marchesin", "Roberto Zunino"], "title": "Certifying optimal MEV strategies with Lean", "comment": null, "summary": "Maximal Extractable Value (MEV) refers to a class of attacks to decentralized\napplications where the adversary profits by manipulating the ordering,\ninclusion, or exclusion of transactions in a blockchain. Decentralized Finance\n(DeFi) protocols are a primary target of these attacks, as their logic depends\ncritically on transaction sequencing. To date, MEV attacks have already\nextracted billions of dollars in value, underscoring their systemic impact on\nblockchain security. Verifying the absence of MEV attacks requires determining\nsuitable upper bounds, i.e. proving that no adversarial strategy can extract\nmore value (if any) than expected by protocol designers. This problem is\nnotoriously difficult: the space of adversarial strategies is extremely vast,\nmaking empirical studies and pen-and-paper reasoning insufficiently rigorous.\nIn this paper, we present the first mechanized formalization of MEV in the Lean\ntheorem prover. We introduce a methodology to construct machine-checked proofs\nof MEV bounds, providing correctness guarantees beyond what is possible with\nexisting techniques. To demonstrate the generality of our approach, we model\nand analyse the MEV of two paradigmatic DeFi protocols. Notably, we develop the\nfirst machine-checked proof of the optimality of sandwich attacks in Automated\nMarket Makers, a fundamental DeFi primitive."}
{"id": "2510.14522", "categories": ["cs.CR"], "pdf": "https://arxiv.org/pdf/2510.14522", "abs": "https://arxiv.org/abs/2510.14522", "authors": ["Evangelos Lamprou", "Julian Dai", "Grigoris Ntousakis", "Martin C. Rinard", "Nikos Vasilakis"], "title": "Lexo: Eliminating Stealthy Supply-Chain Attacks via LLM-Assisted Program Regeneration", "comment": null, "summary": "Software supply-chain attacks are an important and ongoing concern in the\nopen source software ecosystem. These attacks maintain the standard\nfunctionality that a component implements, but additionally hide malicious\nfunctionality activated only when the component reaches its target environment.\nLexo addresses such stealthy attacks by automatically learning and regenerating\nvulnerability-free versions of potentially malicious components. Lexo first\ngenerates a set of input-output pairs to model a component's full observable\nbehavior, which it then uses to synthesize a new version of the original\ncomponent. The new component implements the original functionality but avoids\nstealthy malicious behavior. Throughout this regeneration process, Lexo\nconsults several distinct instances of Large Language Models (LLMs), uses\ncorrectness and coverage metrics to shepherd these instances, and guardrails\ntheir results. Our evaluation on 100+ real-world packages, including high\nprofile stealthy supply-chain attacks, indicates that Lexo scales across\nmultiple domains, regenerates code efficiently (<100s on average), maintains\ncompatibility, and succeeds in eliminating malicious code in several real-world\nsupply-chain-attacks, even in cases when a state-of-the-art LLM fails to\neliminate malicious code when prompted to do so."}
{"id": "2510.14589", "categories": ["cs.CR"], "pdf": "https://arxiv.org/pdf/2510.14589", "abs": "https://arxiv.org/abs/2510.14589", "authors": ["Vaishnavi Sundararajan", "Rithwik"], "title": "Symbolic verification of Apple's Find My location-tracking protocol", "comment": null, "summary": "Tracking devices, while designed to help users find their belongings in case\nof loss/theft, bring in new questions about privacy and surveillance of not\njust their own users, but in the case of crowd-sourced location tracking, even\nthat of others even orthogonally associated with these platforms. Apple's Find\nMy is perhaps the most ubiquitous such system which can even locate devices\nwhich do not possess any cellular support or GPS, running on millions of\ndevices worldwide. Apple claims that this system is private and secure, but the\ncode is proprietary, and such claims have to be taken on faith. It is well\nknown that even with perfect cryptographic guarantees, logical flaws might\ncreep into protocols, and allow undesirable attacks. In this paper, we present\na symbolic model of the Find My protocol, as well as a precise formal\nspecification of desirable properties, and provide automated, machine-checkable\nproofs of these properties in the Tamarin prover."}
{"id": "2510.14638", "categories": ["cs.CR"], "pdf": "https://arxiv.org/pdf/2510.14638", "abs": "https://arxiv.org/abs/2510.14638", "authors": ["Silvia Lucia Sanna", "Leonardo Regano", "Davide Maiorca", "Giorgio Giacinto"], "title": "Improving Cybercrime Detection and Digital Forensics Investigations with Artificial Intelligence", "comment": null, "summary": "According to a recent EUROPOL report, cybercrime is still recurrent in\nEurope, and different activities and countermeasures must be taken to limit,\nprevent, detect, analyze, and fight it. Cybercrime must be prevented with\nspecific measures, tools, and techniques, for example through automated network\nand malware analysis. Countermeasures against cybercrime can also be improved\nwith proper \\df analysis in order to extract data from digital devices trying\nto retrieve information on the cybercriminals. Indeed, results obtained through\na proper \\df analysis can be leveraged to train cybercrime detection systems to\nprevent the success of similar crimes. Nowadays, some systems have started to\nadopt Artificial Intelligence (AI) algorithms for cyberattack detection and \\df\nanalysis improvement. However, AI can be better applied as an additional\ninstrument in these systems to improve the detection and in the \\df analysis.\nFor this reason, we highlight how cybercrime analysis and \\df procedures can\ntake advantage of AI. On the other hand, cybercriminals can use these systems\nto improve their skills, bypass automatic detection, and develop advanced\nattack techniques. The case study we presented highlights how it is possible to\nintegrate the use of the three popular chatbots {\\tt Gemini}, {\\tt Copilot} and\n{\\tt chatGPT} to develop a Python code to encode and decoded images with\nsteganographic technique, even though their presence is not an indicator of\ncrime, attack or maliciousness but used by a cybercriminal as anti-forensics\ntechnique."}
{"id": "2510.14675", "categories": ["cs.CR"], "pdf": "https://arxiv.org/pdf/2510.14675", "abs": "https://arxiv.org/abs/2510.14675", "authors": ["Nicolas Dutly", "Friederike Groschupp", "Ivan Puddu", "Kari Kostiainen", "Srdjan Capkun"], "title": "AEX-NStep: Probabilistic Interrupt Counting Attacks on Intel SGX", "comment": "Author's version, to appear, 2026 IEEE Symposium on Security and\n  Privacy (SP)", "summary": "To mitigate interrupt-based stepping attacks (notably using SGX-Step), Intel\nintroduced AEX-Notify, an ISA extension to Intel SGX that aims to prevent\ndeterministic single-stepping. In this work, we introduce AEX-NStep, the first\ninterrupt counting attack on AEX-Notify-enabled Enclaves. We show that\ndeterministic single-stepping is not required for interrupt counting attacks to\nbe practical and that, therefore, AEX-Notify does not entirely prevent such\nattacks. We specifically show that one of AEX-Notify's security guarantees,\nobfuscated forward progress, does not hold, and we introduce two new\nprobabilistic interrupt counting attacks. We use these attacks to construct a\npractical ECDSA key leakage attack on an AEX-Notify-enabled SGX enclave. Our\nresults extend the original security analysis of AEX-Notify and inform the\ndesign of future mitigations."}
{"id": "2510.14693", "categories": ["cs.CR"], "pdf": "https://arxiv.org/pdf/2510.14693", "abs": "https://arxiv.org/abs/2510.14693", "authors": ["Simon Malatrait", "Alex Sirac"], "title": "FibRace: a large-scale benchmark of client-side proving on mobile devices", "comment": "14 pages, 5 figures, 2 tables", "summary": "FibRace, jointly developed by KKRT Labs and Hyli, was the first large-scale\nexperiment to test client-side proof generation on smartphones using Cairo M.\nPresented as a mobile game in which players proved Fibonacci numbers and\nclimbed a leaderboard, FibRace served a dual purpose: to engage the public and\nto provide empirical benchmarking. Over a three-week campaign (September 11-30,\n2025), 6,047 players across 99 countries generated 2,195,488 proofs on 1,420\nunique device models. The results show that most modern smartphones can\ncomplete a proof in under 5 seconds, confirming that *mobile devices are now\ncapable of producing zero-knowledge proofs reliably*, without the need for\nremote provers or specialized hardware. Performance was correlated primarily\nwith RAM capacity and SoC (System on Chip) performance: devices with at least 3\nGB of RAM proved stably, when Apple's A19 Pro and M-series chips achieved the\nfastest proving times. Hyli's blockchain natively verified every proof onchain\nwithout congestion. FibRace provides the most comprehensive dataset to date on\nmobile proving performance, establishing a practical baseline for future\nresearch in lightweight provers, proof-powered infrastructure, and\nprivacy-preserving mobile applications."}
{"id": "2510.14708", "categories": ["cs.CR"], "pdf": "https://arxiv.org/pdf/2510.14708", "abs": "https://arxiv.org/abs/2510.14708", "authors": ["Ha Xuan Son", "Nguyen Quoc Anh", "Phat T. Tran-Truong", "Le Thanh Tuan", "Pham Thanh Nghiem"], "title": "SLIE: A Secure and Lightweight Cryptosystem for Data Sharing in IoT Healthcare Services", "comment": "Paper has been accepted for publication in the Proceedings of the\n  23th International Conference on Service-Oriented Computing 2025", "summary": "The Internet of Medical Things (IoMT) has revolutionized healthcare by\ntransforming medical operations into standardized, interoperable services.\nHowever, this service-oriented model introduces significant security\nvulnerabilities in device management and communication, which are especially\ncritical given the sensitivity of medical data. To address these risks, this\npaper proposes SLIE (Secure and Lightweight Identity Encryption), a novel\ncryptosystem based on Wildcard Key Derivation Identity-Based Encryption\n(WKD-IBE). SLIE ensures scalable trust and secure omnidirectional communication\nthrough end-to-end encryption, hierarchical access control, and a lightweight\nkey management system designed for resource-constrained devices. It\nincorporates constant-time operations, memory obfuscation, and expiry-based key\nrevocation to counter side-channel, man-in-the-middle, and unauthorized access\nattacks, thereby ensuring compliance with standards like HIPAA and GDPR.\nEvaluations show that SLIE significantly outperforms RSA, with encryption and\ndecryption times of 0.936ms and 0.217ms for 1KB of data, an 84.54% improvement\nin encryption speed, a 99.70% improvement in decryption speed, and an energy\nefficiency of 0.014 J/KB."}
{"id": "2510.14894", "categories": ["cs.CR", "cs.LG"], "pdf": "https://arxiv.org/pdf/2510.14894", "abs": "https://arxiv.org/abs/2510.14894", "authors": ["Marc Damie", "Florian Hahn", "Andreas Peter", "Jan Ramon"], "title": "Secure Sparse Matrix Multiplications and their Applications to Privacy-Preserving Machine Learning", "comment": null, "summary": "To preserve privacy, multi-party computation (MPC) enables executing Machine\nLearning (ML) algorithms on secret-shared or encrypted data. However, existing\nMPC frameworks are not optimized for sparse data. This makes them unsuitable\nfor ML applications involving sparse data, e.g., recommender systems or\ngenomics. Even in plaintext, such applications involve high-dimensional sparse\ndata, that cannot be processed without sparsity-related optimizations due to\nprohibitively large memory requirements.\n  Since matrix multiplication is central in ML algorithms, we propose MPC\nalgorithms to multiply secret sparse matrices. On the one hand, our algorithms\navoid the memory issues of the \"dense\" data representation of classic secure\nmatrix multiplication algorithms. On the other hand, our algorithms can\nsignificantly reduce communication costs (some experiments show a factor 1000)\nfor realistic problem sizes. We validate our algorithms in two ML applications\nin which existing protocols are impractical.\n  An important question when developing MPC algorithms is what assumptions can\nbe made. In our case, if the number of non-zeros in a row is a sensitive piece\nof information then a short runtime may reveal that the number of non-zeros is\nsmall. Existing approaches make relatively simple assumptions, e.g., that there\nis a universal upper bound to the number of non-zeros in a row. This often\ndoesn't align with statistical reality, in a lot of sparse datasets the amount\nof data per instance satisfies a power law. We propose an approach which allows\nadopting a safe upper bound on the distribution of non-zeros in rows/columns of\nsparse matrices."}
{"id": "2510.14906", "categories": ["cs.CR"], "pdf": "https://arxiv.org/pdf/2510.14906", "abs": "https://arxiv.org/abs/2510.14906", "authors": ["Zixuan Liu", "Yi Zhao", "Zhuotao Liu", "Qi Li", "Chuanpu Fu", "Guangmeng Zhou", "Ke Xu"], "title": "A Hard-Label Black-Box Evasion Attack against ML-based Malicious Traffic Detection Systems", "comment": null, "summary": "Machine Learning (ML)-based malicious traffic detection is a promising\nsecurity paradigm. It outperforms rule-based traditional detection by\nidentifying various advanced attacks. However, the robustness of these ML\nmodels is largely unexplored, thereby allowing attackers to craft adversarial\ntraffic examples that evade detection. Existing evasion attacks typically rely\non overly restrictive conditions (e.g., encrypted protocols, Tor, or\nspecialized setups), or require detailed prior knowledge of the target (e.g.,\ntraining data and model parameters), which is impractical in realistic\nblack-box scenarios. The feasibility of a hard-label black-box evasion attack\n(i.e., applicable across diverse tasks and protocols without internal target\ninsights) thus remains an open challenge. To this end, we develop\nNetMasquerade, which leverages reinforcement learning (RL) to manipulate attack\nflows to mimic benign traffic and evade detection. Specifically, we establish a\ntailored pre-trained model called Traffic-BERT, utilizing a network-specialized\ntokenizer and an attention mechanism to extract diverse benign traffic\npatterns. Subsequently, we integrate Traffic-BERT into the RL framework,\nallowing NetMasquerade to effectively manipulate malicious packet sequences\nbased on benign traffic patterns with minimal modifications. Experimental\nresults demonstrate that NetMasquerade enables both brute-force and stealthy\nattacks to evade 6 existing detection methods under 80 attack scenarios,\nachieving over 96.65% attack success rate. Notably, it can evade the methods\nthat are either empirically or certifiably robust against existing evasion\nattacks. Finally, NetMasquerade achieves low-latency adversarial traffic\ngeneration, demonstrating its practicality in real-world scenarios."}
