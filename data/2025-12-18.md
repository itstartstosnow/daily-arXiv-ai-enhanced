<div id=toc></div>

# Table of Contents

- [cs.CR](#cs.CR) [Total: 30]


<div id='cs.CR'></div>

# cs.CR [[Back]](#toc)

### [1] [Zero-Knowledge Audit for Internet of Agents: Privacy-Preserving Communication Verification with Model Context Protocol](https://arxiv.org/abs/2512.14737)
*Guanlin Jing,Huayi Qi*

Main category: cs.CR

TL;DR: 提出了zk-MCP框架，结合零知识证明和MCP协议，在保护隐私的同时实现可验证的代理通信审计。


<details>
  <summary>Details</summary>
Motivation: 现有代理通信框架在提供可验证审计跟踪时难以同时保护代理交互的隐私和机密性。在需要精确计费、合规验证和监管环境问责的应用中，保护通信隐私同时确保可审计性成为基本挑战。

Method: 将零知识证明与现有模型上下文协议（MCP）配对，使消息可以在不暴露内容的情况下被验证。在轻量级网络中运行，保持与标准MCP交换兼容，并添加异步审计验证来确认格式和通用消息类型。

Result: zk-MCP提供数据真实性和通信隐私，实现高效验证且延迟开销可忽略。实现了完整框架，包括基于Circom的零知识证明生成和与MCP双向通道集成的审计协议。

Conclusion: 这是首个为代理通信提供隐私保护审计的系统，实现了可验证的相互审计而不暴露消息内容或损害代理隐私。

Abstract: Existing agent communication frameworks face critical limitations in providing verifiable audit trails without compromising the privacy and confidentiality of agent interactions. The protection of agent communication privacy while ensuring auditability emerges as a fundamental challenge for applications requiring accurate billing, compliance verification, and accountability in regulated environments.
  We introduce a framework for auditing agent communications that keeps messages private while still checking they follow expected rules. It pairs zero-knowledge proofs with the existing Model Context Protocol (MCP) so messages can be verified without revealing their contents. The approach runs in lightweight networks, stays compatible with standard MCP exchanges, and adds asynchronous audit verification to confirm format and general message types without exposing specifics.
  The framework enables mutual audits between agents: one side can check communication content and quality while the other verifies usage metrics, all without revealing sensitive information. We formalize security goals and show that zk-MCP provides data authenticity and communication privacy, achieving efficient verification with negligible latency overhead. We fully implement the framework, including Circom-based zero-knowledge proof generation and an audit protocol integrated with MCP's bidirectional channel, and, to our knowledge, this is the first privacy-preserving audit system for agent communications that offers verifiable mutual auditing without exposing message content or compromising agent privacy.

</details>


### [2] [Persistent Backdoor Attacks under Continual Fine-Tuning of LLMs](https://arxiv.org/abs/2512.14741)
*Jing Cui,Yufei Han,Jianbin Jiao,Junge Zhang*

Main category: cs.CR

TL;DR: P-Trojan：一种针对LLM的后门攻击方法，通过优化梯度对齐确保后门在多阶段持续微调中持久存在，保持99%以上的持久性而不影响正常任务性能。


<details>
  <summary>Details</summary>
Motivation: 现有后门攻击研究主要关注部署时的有效性，但很少研究在用户驱动的持续微调后后门的持久性。实际证据表明，简单注入的后门在模型更新后持久性会下降，因此需要研究后门在多阶段微调中的持久性问题。

Method: 提出P-Trojan攻击算法，通过将中毒梯度与干净任务在token嵌入上的梯度对齐，使植入的后门映射在后续更新中不易被抑制或遗忘。这种方法显式优化后门在重复更新中的持久性。

Result: 在Qwen2.5和LLaMA3系列LLM以及多样化任务序列上的实验表明，P-Trojan实现了超过99%的后门持久性，同时保持了干净任务的准确性。理论分析也证明了这种持久后门攻击的可行性。

Conclusion: 研究揭示了后门攻击在现实模型适应流程中的持久性威胁，强调了需要进行持久性感知的评估和更强的防御机制，以应对多阶段微调环境下的安全挑战。

Abstract: Backdoor attacks embed malicious behaviors into Large Language Models (LLMs), enabling adversaries to trigger harmful outputs or bypass safety controls. However, the persistence of the implanted backdoors under user-driven post-deployment continual fine-tuning has been rarely examined. Most prior works evaluate the effectiveness and generalization of implanted backdoors only at releasing and empirical evidence shows that naively injected backdoor persistence degrades after updates. In this work, we study whether and how implanted backdoors persist through a multi-stage post-deployment fine-tuning. We propose P-Trojan, a trigger-based attack algorithm that explicitly optimizes for backdoor persistence across repeated updates. By aligning poisoned gradients with those of clean tasks on token embeddings, the implanted backdoor mapping is less likely to be suppressed or forgotten during subsequent updates. Theoretical analysis shows the feasibility of such persistent backdoor attacks after continual fine-tuning. And experiments conducted on the Qwen2.5 and LLaMA3 families of LLMs, as well as diverse task sequences, demonstrate that P-Trojan achieves over 99% persistence while preserving clean-task accuracy. Our findings highlight the need for persistence-aware evaluation and stronger defenses in realistic model adaptation pipelines.

</details>


### [3] [Quantum-Augmented AI/ML for O-RAN: Hierarchical Threat Detection with Synergistic Intelligence and Interpretability (Technical Report)](https://arxiv.org/abs/2512.14742)
*Tan Le,Van Le,Sachin Shetty*

Main category: cs.CR

TL;DR: 提出一个用于O-RAN安全防护的三层分层防御框架，结合量子计算和机器学习，在合成和真实遥测数据上实现接近完美的准确率。


<details>
  <summary>Details</summary>
Motivation: O-RAN虽然提高了模块化和遥测粒度，但也扩大了网络安全攻击面，需要针对解耦的控制、用户和管理平面提供有效防护。

Method: 三层协调防御框架：异常检测、入侵确认和多攻击分类，与O-RAN遥测栈对齐。采用混合量子计算和机器学习，结合振幅和纠缠基特征编码与深度集成分类器。

Result: 框架在合成和真实遥测数据上实现接近完美的准确率、高召回率和强类别可分性。通过决策边界、概率边际和潜在空间几何等多方面评估，证实了其可解释性、鲁棒性和部署准备度。

Conclusion: 该分层防御框架具有可解释性、鲁棒性，适用于切片感知诊断，可在近实时和非实时RIC域中实现可扩展部署。

Abstract: Open Radio Access Networks (O-RAN) enhance modularity and telemetry granularity but also widen the cybersecurity attack surface across disaggregated control, user and management planes. We propose a hierarchical defense framework with three coordinated layers-anomaly detection, intrusion confirmation, and multiattack classification-each aligned with O-RAN's telemetry stack. Our approach integrates hybrid quantum computing and machine learning, leveraging amplitude- and entanglement-based feature encodings with deep and ensemble classifiers. We conduct extensive benchmarking across synthetic and real-world telemetry, evaluating encoding depth, architectural variants, and diagnostic fidelity. The framework consistently achieves near-perfect accuracy, high recall, and strong class separability. Multi-faceted evaluation across decision boundaries, probabilistic margins, and latent space geometry confirms its interpretability, robustness, and readiness for slice-aware diagnostics and scalable deployment in near-RT and non-RT RIC domains.

</details>


### [4] [Factor(U,T): Controlling Untrusted AI by Monitoring their Plans](https://arxiv.org/abs/2512.14745)
*Edward Lue Chee Lip,Anthony Channg,Diana Kim,Aaron Sandoval,Kevin Zhu*

Main category: cs.CR

TL;DR: 论文研究了在分解认知协议中，当分解器可能是恶意模型时的安全问题，发现仅监控任务分解难以检测恶意行为，而监控具体实现能有效保障安全。


<details>
  <summary>Details</summary>
Motivation: 随着AI能力提升，我们依赖强大模型分解复杂任务，但如果分解器本身是恶意的怎么办？现有方法使用可信但能力较弱的模型进行分解，限制了在分解本身就很困难的任务中的应用。

Method: 引入Factor(U,T)协议，使用不可信（更强但可能恶意）的模型进行任务分解，而可信模型执行子任务。在BigCodeBench数据集上进行控制评估，比较不同监控策略的效果。

Result: 仅监控自然语言任务分解的监视器性能很差（AUROC 0.52），而监控完整Python解决方案的监视器表现优异（AUROC 0.96）。Factor(D,U)协议（可信分解器+监控具体子任务解决方案）实现了出色的区分能力（AUROC 0.96）和强安全性（1.2%攻击成功率）。

Conclusion: 仅监控任务分解难以检测恶意行为，而监控具体实现能有效保障安全。在分解认知协议中，实现层面的监控比分解层面的监控更有效。

Abstract: As AI capabilities advance, we increasingly rely on powerful models to decompose complex tasks $\unicode{x2013}$ but what if the decomposer itself is malicious? Factored cognition protocols decompose complex tasks into simpler child tasks: one model creates the decomposition, while other models implement the child tasks in isolation. Prior work uses trusted (weaker but reliable) models for decomposition, which limits usefulness for tasks where decomposition itself is challenging. We introduce Factor($U$,$T$), in which an untrusted (stronger but potentially malicious) model decomposes while trusted models implement child tasks. Can monitors detect malicious activity when observing only natural language task instructions, rather than complete solutions? We baseline and red team Factor($U$,$T$) in control evaluations on BigCodeBench, a dataset of Python coding tasks. Monitors distinguishing malicious from honest decompositions perform poorly (AUROC 0.52) compared to monitors evaluating complete Python solutions (AUROC 0.96). Furthermore, Factor($D$,$U$), which uses a trusted decomposer and monitors concrete child solutions, achieves excellent discrimination (AUROC 0.96) and strong safety (1.2% ASR), demonstrating that implementation-context monitoring succeeds where decomposition-only monitoring fails.

</details>


### [5] [BLINDSPOT: Enabling Bystander-Controlled Privacy Signaling for Camera-Enabled Devices](https://arxiv.org/abs/2512.14746)
*Jad Al Aaraj,Athina Markopoulou*

Main category: cs.CR

TL;DR: BlindSpot是一个在设备上的系统，允许旁观者通过实时信号传递隐私偏好来管理自己的隐私，无需预先共享敏感信息。系统评估了三种信号传递方式：手势、可见光通信和超宽带通信，并包含验证机制防止冒充攻击。


<details>
  <summary>Details</summary>
Motivation: 配备摄像头的移动设备（如手机、智能眼镜、AR头显）对旁观者的隐私构成挑战，目前缺乏有效的实时机制让旁观者控制自己的图像、视频（包括面部）被拍摄。

Method: 设计了三种信号传递方式：1）手势机制；2）改进的可见光通信协议；3）新颖的超宽带通信协议。所有方式都包含使用几何一致性检查的验证机制，以验证信号来源相对于发送旁观者的位置，防御冒充攻击。在商用智能手机上实现了完整的BlindSpot系统。

Result: 对各种距离、光照条件和用户运动下的每种方式的准确性和延迟进行了全面评估。结果证明了这些新颖的旁观者信号传递技术的可行性，以及在系统性能和便利性方面的权衡。

Conclusion: BlindSpot系统展示了让旁观者实时管理隐私偏好的可行性，通过多种信号传递方式和验证机制，为移动设备摄像头的隐私挑战提供了解决方案。

Abstract: Camera-equipped mobile devices, such as phones, smart glasses, and AR headsets, pose a privacy challenge for bystanders, who currently lack effective real-time mechanisms to control the capture of their picture, video, including their face. We present BlindSpot, an on-device system that enables bystanders to manage their own privacy by signaling their privacy preferences in real-time without previously sharing any sensitive information. Our main contribution is the design and comparative evaluation of three distinct signaling modalities: a hand gesture mechanism, a significantly improved visible light communication (VLC) protocol, and a novel ultra-wideband (UWB) communication protocol. For all these modalities, we also design a validation mechanism that uses geometric consistency checks to verify the origin of a signal relative to the sending bystander, and defend against impersonation attacks. We implement the complete system (BlindSpot) on a commodity smartphone and conduct a comprehensive evaluation of each modality's accuracy and latency across various distances, lighting conditions, and user movements. Our results demonstrate the feasibility of these novel bystander signaling techniques and their trade-offs in terms of system performance and convenience.

</details>


### [6] [Modeling the Interdependent Coupling of Safety and Security for Connected and Automated Vehicles: A Copula-Based Integrated Risk Analysis Approach](https://arxiv.org/abs/2512.14748)
*Xingyu Li,Qi Liu,Yufeng Li*

Main category: cs.CR

TL;DR: 提出基于copula理论的联合安全-安全分析方法，量化CAV中功能安全与网络安全之间的耦合效应，为协同设计提供理论基础。


<details>
  <summary>Details</summary>
Motivation: 现有研究已识别出CAV中安全与安全之间的相关性，但缺乏分析其交互机制和指导协同设计的理论框架。

Method: 1) 使用生存分析推导的动态风险函数建模时变网络攻击，用Weibull分布建模随机硬件故障；2) 引入基于copula理论的联合故障模型，采用椭圆和Archimedean copula族构建系统级故障函数；3) 对安全-安全耦合的依赖结构进行形式化理论分析。

Result: 通过综合仿真评估了联合故障行为对三个关键因素的敏感性：copula依赖参数、安全补丁部署时机、Weibull分布参数。动态故障模型展示了网络攻击如何影响安全故障，以及功能故障如何在依赖结构下影响安全故障。

Conclusion: 本研究为CAV中安全与安全的协同设计提供了可量化的理论基础，揭示了依赖结构下的动态耦合机制。

Abstract: Safety and security are critical to the reliable operation of connected and automated vehicles (CAVs). While existing research has identified correlations between the two domains, a theoretical framework to analyze their interaction mechanisms and guide co-design remains lacking. To address this gap, this paper proposes a copula-based joint safety-security analysis method to quantify their coupling effects. First, we formulate time-varying cyberattacks using dynamic risk functions derived from survival analysis, while modeling random hardware failures with the Weibull distribution, as per the automotive industry standard ISO 26262. Second, to capture the dependence between functional safety failures and cyber threats, we introduce a joint failure model based on copula theory, employing both elliptical (e.g., Gaussian) and Archimedean (e.g., Frank) copula families to construct a system-level failure function. Furthermore, we provide formal theoretical analysis of the dependence structure in the safety-security coupling, yielding three key insights: (1) a monotonic relationship between joint failure probability and dependence parameters, (2) the mechanisms of defensive response mechanisms (such as patch deployment) in mitigating joint failures, and (3) quantifying the dynamic coupling strength between safety and security under dependence structures. Through comprehensive simulations, we evaluate the sensitivity of the joint failure behavior to three critical factors: copula dependence parameters, security patch deployment timing, and Weibull distribution parameters. Our dynamic failure model further illustrates how cyberattacks affect safety failures and, conversely, how functional faults affect security failures under dependencies structures. This study provides a quantifiable theoretical foundation for the co-design of safety and security in CAVs.

</details>


### [7] [One Leak Away: How Pretrained Model Exposure Amplifies Jailbreak Risks in Finetuned LLMs](https://arxiv.org/abs/2512.14751)
*Yixin Tan,Zhe Yu,Jun Sakuma*

Main category: cs.CR

TL;DR: 研究发现微调后的LLM继承了预训练模型的越狱漏洞，攻击者可以通过在预训练模型上优化的对抗提示有效攻击其微调变体，并提出基于表示探测的PGP攻击方法增强攻击可迁移性。


<details>
  <summary>Details</summary>
Motivation: 研究微调预训练大语言模型的安全隐患，特别是微调后的模型是否继承预训练源的越狱漏洞，在现实威胁模型中（攻击者对预训练模型有白盒访问，对微调模型只有黑盒访问）评估安全风险。

Method: 1. 实证分析：在预训练模型上优化的对抗提示迁移到微调变体的效果；2. 表示层探测：分析可迁移提示在预训练隐藏状态中的线性可分性；3. 提出PGP攻击：基于探测引导的投影攻击，将优化导向可迁移性相关方向。

Result: 实验表明：1. 预训练模型上优化的对抗提示能有效迁移到微调变体；2. 可迁移提示在预训练表示中是线性可分的；3. PGP攻击在多个LLM家族和多样微调任务中表现出强大的迁移成功率。

Conclusion: 微调后的LLM确实继承了预训练模型的越狱漏洞，预训练到微调范式存在固有安全风险，需要新的防御机制来缓解这种继承性漏洞。

Abstract: Finetuning pretrained large language models (LLMs) has become the standard paradigm for developing downstream applications. However, its security implications remain unclear, particularly regarding whether finetuned LLMs inherit jailbreak vulnerabilities from their pretrained sources. We investigate this question in a realistic pretrain-to-finetune threat model, where the attacker has white-box access to the pretrained LLM and only black-box access to its finetuned derivatives. Empirical analysis shows that adversarial prompts optimized on the pretrained model transfer most effectively to its finetuned variants, revealing inherited vulnerabilities from pretrained to finetuned LLMs. To further examine this inheritance, we conduct representation-level probing, which shows that transferable prompts are linearly separable within the pretrained hidden states, suggesting that universal transferability is encoded in pretrained representations. Building on this insight, we propose the Probe-Guided Projection (PGP) attack, which steers optimization toward transferability-relevant directions. Experiments across multiple LLM families and diverse finetuned tasks confirm PGP's strong transfer success, underscoring the security risks inherent in the pretrain-to-finetune paradigm.

</details>


### [8] [CODE ACROSTIC: Robust Watermarking for Code Generation](https://arxiv.org/abs/2512.14753)
*Li Lin,Siyuan Xin,Yang Cao,Xiaochun Cao*

Main category: cs.CR

TL;DR: 本文提出一种新的代码水印方法，通过Cue List区分代码的低熵和高熵部分，有效抵抗注释移除攻击，相比现有方法具有更高的可检测性和可用性。


<details>
  <summary>Details</summary>
Motivation: 现有LLM生成代码的水印方法无法抵抗注释移除攻击，攻击者只需移除注释而不影响代码功能就能破坏水印。同时，代码相比自然语言属于低熵场景，传统水印方法难以有效嵌入。

Method: 利用先验知识通过Cue List区分代码的低熵和高熵部分，然后基于Cue List指导水印注入，在保持代码功能的前提下增强水印的鲁棒性。

Result: 在HumanEval数据集上评估，与三种最先进的代码水印技术对比，证明该方法在可检测性和可用性方面优于现有方法。

Conclusion: 提出的基于Cue List的代码水印方法能有效抵抗注释移除攻击，解决了现有方法在低熵代码场景下的局限性，为LLM生成代码的版权保护提供了更可靠的解决方案。

Abstract: Watermarking large language models (LLMs) is vital for preventing their misuse, including the fabrication of fake news, plagiarism, and spam. It is especially important to watermark LLM-generated code, as it often contains intellectual property.However, we found that existing methods for watermarking LLM-generated code fail to address comment removal attack.In such cases, an attacker can simply remove the comments from the generated code without affecting its functionality, significantly reducing the effectiveness of current code-watermarking techniques.On the other hand, injecting a watermark into code is challenging because, as previous works have noted, most code represents a low-entropy scenario compared to natural language. Our approach to addressing this issue involves leveraging prior knowledge to distinguish between low-entropy and high-entropy parts of the code, as indicated by a Cue List of words.We then inject the watermark guided by this Cue List, achieving higher detectability and usability than existing methods.We evaluated our proposed method on HumanEvaland compared our method with three state-of-the-art code watermarking techniques. The results demonstrate the effectiveness of our approach.

</details>


### [9] [Privacy-Preserving Feature Valuation in Vertical Federated Learning Using Shapley-CMI and PSI Permutation](https://arxiv.org/abs/2512.14767)
*Unai Laskurain,Aitor Aguirre-Ortuzar,Urko Zurutuza*

Main category: cs.CR

TL;DR: 提出了一种用于纵向联邦学习的隐私保护Shapley-CMI实现，通过私有集合交集服务器安全计算特征贡献值，无需共享原始数据或训练模型。


<details>
  <summary>Details</summary>
Motivation: 在纵向联邦学习中，需要在模型训练前评估各方的特征贡献，但现有的Shapley-CMI方法缺乏实用的隐私保护实现，无法安全计算所需的排列和交集。

Method: 引入私有集合交集服务器，对离散化和加密的ID组执行特征排列并计算加密交集大小，各方使用这些交集结果计算Shapley-CMI值来评估特征边际效用。

Result: 初步实验证实了系统的正确性和隐私性，表明该方法能够安全高效地评估纵向联邦学习中的特征贡献，确保数据机密性并支持多方扩展。

Conclusion: 该方法为纵向联邦学习提供了无需共享原始数据或训练模型的安全特征贡献评估方案，实现了数据保密、可扩展性和公平的数据估值。

Abstract: Federated Learning (FL) is an emerging machine learning paradigm that enables multiple parties to collaboratively train models without sharing raw data, ensuring data privacy. In Vertical FL (VFL), where each party holds different features for the same users, a key challenge is to evaluate the feature contribution of each party before any model is trained, particularly in the early stages when no model exists. To address this, the Shapley-CMI method was recently proposed as a model-free, information-theoretic approach to feature valuation using Conditional Mutual Information (CMI). However, its original formulation did not provide a practical implementation capable of computing the required permutations and intersections securely. This paper presents a novel privacy-preserving implementation of Shapley-CMI for VFL. Our system introduces a private set intersection (PSI) server that performs all necessary feature permutations and computes encrypted intersection sizes across discretized and encrypted ID groups, without the need for raw data exchange. Each party then uses these intersection results to compute Shapley-CMI values, computing the marginal utility of their features. Initial experiments confirm the correctness and privacy of the proposed system, demonstrating its viability for secure and efficient feature contribution estimation in VFL. This approach ensures data confidentiality, scales across multiple parties, and enables fair data valuation without requiring the sharing of raw data or training models.

</details>


### [10] [Cybersecurity skills in new graduates: a Philippine perspective](https://arxiv.org/abs/2512.14778)
*John Paul P. Miranda,Marlon I. Tayag,Joel D. Canlas*

Main category: cs.CR

TL;DR: 菲律宾网络安全毕业生需要技术技能、软技能和个人能力的综合技能集，特别强调沟通、批判性思维、解决问题和适应能力，而商业敏锐度对初级职位不太重要。


<details>
  <summary>Details</summary>
Motivation: 研究旨在识别菲律宾网络安全毕业生在初级职位所需的关键技能和能力，了解当前行业需求与教育培养之间的差距，为课程改进和人才培养提供依据。

Method: 采用描述性横断面研究设计，结合分析菲律宾在线平台的职位招聘信息，以及对学生、教师和专业人士的调查问卷。

Result: 研究发现网络安全行业需求从传统技术技能转向更全面的技能集，各方普遍认同沟通、批判性思维、问题解决和适应能力的重要性，但优先级略有差异。商业敏锐度对初级职位不太重要。

Conclusion: 建议网络安全专业人员培养包含技术知识、软技能和个人能力的综合技能集，重点关注适应能力、持续学习和职业道德，制定与行业变化需求相符的准备策略。

Abstract: This study investigates the key skills and competencies needed by new cybersecurity graduates in the Philippines for entry-level positions. Using a descriptive cross-sectional research design, it combines analysis of job listings from Philippine online platforms with surveys of students, teachers, and professionals. The aim is to identify required skills and areas needing improvement, highlighting the balance between technical skills and other competencies like ethical conduct, suggesting a shift away from traditional cybersecurity skills towards a more diverse skillset. Furthermore, the results revealed common agreement on the importance of communication, critical thinking, problem-solving, and adaptability skills, albeit with slight variations in their prioritization. It recommends that aspiring cybersecurity professionals develop an inclusive skill set encompassing technical knowledge, soft skills, and personal competencies, with a focus on adaptability, continuous learning, and ethics. Skills such as business acumen are considered less vital for entry-level roles, proposing a preparation strategy that aligns with the changing demands of the cybersecurity industry.

</details>


### [11] [MALCDF: A Distributed Multi-Agent LLM Framework for Real-Time Cyber](https://arxiv.org/abs/2512.14846)
*Arth Bhardwaj,Sia Godika,Yuvam Loonker*

Main category: cs.CR

TL;DR: MALCDF：一个多智能体LLM网络安全防御框架，通过四个LLM智能体（检测、情报、响应、分析）协同工作，在实时环境中实现90%检测准确率，优于轻量级ML-IDS基线和单LLM设置。


<details>
  <summary>Details</summary>
Motivation: 传统集中式安全工具难以应对自适应、多向量的网络攻击，需要更智能、协同的实时防御解决方案。

Method: 提出多智能体LLM网络防御框架（MALCDF），包含四个LLM智能体：检测、情报、响应、分析，通过安全通信层（SCL）进行加密的、本体对齐的消息通信，生成审计友好的输出（如MITRE ATT&CK映射）。

Result: 在50条记录的实时流测试中，MALCDF达到90.0%检测准确率、85.7% F1分数、9.1%误报率，平均每事件延迟6.8秒，优于轻量级随机森林IDS基线和单LLM设置。

Conclusion: 通过安全、本体对齐的消息传递协调简单的LLM智能体，可以改进实际的实时网络防御，为多智能体LLM在网络安全中的应用提供了实践验证。

Abstract: Traditional, centralized security tools often miss adaptive, multi-vector attacks. We present the Multi-Agent LLM Cyber Defense Framework (MALCDF), a practical setup where four large language model (LLM) agents-Detection, Intelligence, Response, and Analysis-work together in real time. Agents communicate over a Secure Communication Layer (SCL) with encrypted, ontology-aligned messages, and produce audit-friendly outputs (e.g., MITRE ATT&CK mappings).
  For evaluation, we keep the test simple and consistent: all reported metrics come from the same 50-record live stream derived from the CICIDS2017 feature schema. CICIDS2017 is used for configuration (fields/schema) and to train a practical ML baseline. The ML-IDS baseline is a Lightweight Random Forest IDS (LRF-IDS) trained on a subset of CICIDS2017 and tested on the 50-record stream, with no overlap between training and test records.
  In experiments, MALCDF reaches 90.0% detection accuracy, 85.7% F1-score, and 9.1% false-positive rate, with 6.8s average per-event latency. It outperforms the lightweight ML-IDS baseline and a single-LLM setup on accuracy while keeping end-to-end outputs consistent. Overall, this hands-on build suggests that coordinating simple LLM agents with secure, ontology-aligned messaging can improve practical, real-time cyber defense.

</details>


### [12] [Penetration Testing of Agentic AI: A Comparative Security Analysis Across Models and Frameworks](https://arxiv.org/abs/2512.14860)
*Viet K. Nguyen,Mohammad I. Husain*

Main category: cs.CR

TL;DR: 对5个主流AI模型在2个代理框架上进行首次系统性渗透测试，发现代理AI存在严重安全漏洞，超过一半恶意攻击能绕过企业级安全机制


<details>
  <summary>Details</summary>
Motivation: 代理AI引入了传统LLM防护无法解决的安全漏洞，现有研究缺乏多模型和多框架的对比分析，需要系统评估代理AI系统的安全风险

Method: 对5个模型（Claude 3.5 Sonnet、Gemini 2.5 Flash、GPT-4o、Grok 2、Nova Pro）在2个代理框架（AutoGen和CrewAI）上，使用7代理架构模拟大学信息管理系统，设计13种攻击场景（包括提示注入、SSRF、SQL注入、工具滥用等），共130个测试用例

Result: AutoGen拒绝率52.3% vs CrewAI 30.8%；模型性能从Nova Pro的46.2%到Claude和Grok 2的38.5%；Grok 2在CrewAI上仅拒绝2/13攻击（15.4%拒绝率）；总体拒绝率仅41.5%，超半数恶意攻击成功；识别出6种防御行为模式，包括新型"幻觉合规"策略

Conclusion: 代理AI系统存在严重安全风险，企业级安全机制在代理环境下效果有限，需要针对性的安全防护措施和部署建议

Abstract: Agentic AI introduces security vulnerabilities that traditional LLM safeguards fail to address. Although recent work by Unit 42 at Palo Alto Networks demonstrated that ChatGPT-4o successfully executes attacks as an agent that it refuses in chat mode, there is no comparative analysis in multiple models and frameworks. We conducted the first systematic penetration testing and comparative evaluation of agentic AI systems, testing five prominent models (Claude 3.5 Sonnet, Gemini 2.5 Flash, GPT-4o, Grok 2, and Nova Pro) across two agentic AI frameworks (AutoGen and CrewAI) using a seven-agent architecture that mimics the functionality of a university information management system and 13 distinct attack scenarios that span prompt injection, Server Side Request Forgery (SSRF), SQL injection, and tool misuse. Our 130 total test cases reveal significant security disparities: AutoGen demonstrates a 52.3% refusal rate versus CrewAI's 30.8%, while model performance ranges from Nova Pro's 46.2% to Claude and Grok 2's 38.5%. Most critically, Grok 2 on CrewAI rejected only 2 of 13 attacks (15.4% refusal rate), and the overall refusal rate of 41.5% across all configurations indicates that more than half of malicious prompts succeeded despite enterprise-grade safety mechanisms. We identify six distinct defensive behavior patterns including a novel "hallucinated compliance" strategy where models fabricate outputs rather than executing or refusing attacks, and provide actionable recommendations for secure agent deployment. Complete attack prompts are also included in the Appendix to enable reproducibility.

</details>


### [13] [Cloud Security Leveraging AI: A Fusion-Based AISOC for Malware and Log Behaviour Detection](https://arxiv.org/abs/2512.14935)
*Nnamdi Philip Okonkwo,Lubna Luxmi Dhirani*

Main category: cs.CR

TL;DR: 论文实现了一个基于AWS的AI增强安全运营中心(AISOC)，结合云原生检测和机器学习，通过多模态威胁情报融合来提升云安全运营能力。


<details>
  <summary>Details</summary>
Motivation: 云安全运营中心需要在有限预算下处理高容量、异构的遥测数据，同时应对弹性、短寿命的资源带来的挑战，需要更智能的检测和响应能力。

Method: 在AWS上构建AISOC架构，使用三个EC2实例（攻击者、防御者、监控），模拟Metasploit反向shell入侵，通过Filebeat转发日志到Elasticsearch/Kibana进行分析。训练两个分类器（恶意软件检测器和日志异常检测器），对分数进行校准和融合，生成多模态威胁情报。

Result: 在受控测试中，融合方法取得了强大的macro-F1性能（最高达1.00），能够将活动分类为正常、可疑和高置信度攻击三类。但在更嘈杂和多样化的环境中性能可能会变化。

Conclusion: 简单、校准的融合方法可以在成本敏感、资源受限的设置中增强云安全运营中心的能力，为实际部署提供了有前景的解决方案。

Abstract: Cloud Security Operations Center (SOC) enable cloud governance, risk and compliance by providing insights visibility and control. Cloud SOC triages high-volume, heterogeneous telemetry from elastic, short-lived resources while staying within tight budgets. In this research, we implement an AI-Augmented Security Operations Center (AISOC) on AWS that combines cloud-native instrumentation with ML-based detection. The architecture uses three Amazon EC2 instances: Attacker, Defender, and Monitoring. We simulate a reverse-shell intrusion with Metasploit, and Filebeat forwards Defender logs to an Elasticsearch and Kibana stack for analysis. We train two classifiers, a malware detector built on a public dataset and a log-anomaly detector trained on synthetically augmented logs that include adversarial variants. We calibrate and fuse the scores to produce multi-modal threat intelligence and triage activity into NORMAL, SUSPICIOUS, and HIGH\_CONFIDENCE\_ATTACK. On held-out tests the fusion achieves strong macro-F1 (up to 1.00) under controlled conditions, though performance will vary in noisier and more diverse environments. These results indicate that simple, calibrated fusion can enhance cloud SOC capabilities in constrained, cost-sensitive setups.

</details>


### [14] [Intrusion Detection in Internet of Vehicles Using Machine Learning](https://arxiv.org/abs/2512.14958)
*Hop Le,Izzat Alsmadi*

Main category: cs.CR

TL;DR: 开发基于机器学习的入侵检测系统，使用CiCIoV2024数据集对CAN总线流量进行分类，识别DoS和欺骗攻击


<details>
  <summary>Details</summary>
Motivation: 车联网增强了交通系统的连接性和智能化，但也带来了严重的安全漏洞，使车辆容易受到DoS攻击和消息欺骗等网络攻击，需要有效的入侵检测系统来保护车辆安全

Method: 使用CiCIoV2024基准数据集，分析包括DoS和欺骗攻击在内的各种攻击模式，针对关键车辆参数（如油门位置、转速、速度和方向盘）的欺骗攻击，采用机器学习方法进行多分类问题建模

Result: 初步发现确认了多分类问题，攻击类型与正常数据之间存在明显的结构差异，为机器学习模型提供了坚实的基础

Conclusion: 基于机器学习的入侵检测系统能够有效识别车联网中的恶意CAN总线流量，为车辆网络安全提供保护

Abstract: The Internet of Vehicles (IoV) has evolved modern transportation through enhanced connectivity and intelligent systems. However, this increased connectivity introduces critical vulnerabilities, making vehicles susceptible to cyber-attacks such Denial-ofService (DoS) and message spoofing. This project aims to develop a machine learning-based intrusion detection system to classify malicious Controller Area network (CAN) bus traffic using the CiCIoV2024 benchmark dataset. We analyzed various attack patterns including DoS and spoofing attacks targeting critical vehicle parameters such as Spoofing-GAS - gas pedal position, Spoofing-RPM, Spoofing-Speed, and Spoofing-Steering\_Wheel. Our initial findings confirm a multi-class classification problem with a clear structural difference between attack types and benign data, providing a strong foundation for machine learning models.

</details>


### [15] [SeBERTis: A Framework for Producing Classifiers of Security-Related Issue Reports](https://arxiv.org/abs/2512.15003)
*Sogol Masoumzadeh,Yufei Li,Shane McIntosh,Dániel Varró,Lili Wei*

Main category: cs.CR

TL;DR: SEBERTIS框架通过语义代理训练DNN分类器，独立于词汇线索检测安全相关问题，在GitHub问题报告上达到0.9880 F1分数，显著优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 现有自动检测技术（ML模型和LLM提示）往往依赖词汇线索作为决策捷径，对复杂提交的检测率低，无法满足实时检测安全相关问题的实际需求。

Method: 提出SEBERTIS框架，通过将双向transformer架构作为掩码语言模型，在语义等价词汇替换为掩码的语义代理上进行微调，训练独立于词汇线索的DNN分类器。

Result: 在10,000个GitHub问题报告的语料库上，SEBERTIS分类器达到0.9880 F1分数，比ML基线精度高14.44%-96.98%，召回率高15.40%-93.07%，F1分数高14.90%-94.72%；比LLM基线精度高23.20%-63.71%，召回率高36.68%-85.63%，F1分数高39.49%-74.53%。

Conclusion: SEBERTIS通过语义代理训练DNN分类器，能够独立于词汇线索自信地检测完全未见过的安全相关问题，显著提升了检测性能，满足了实时安全相关问题检测的实际需求。

Abstract: Monitoring issue tracker submissions is a crucial software maintenance activity. A key goal is the prioritization of high risk, security-related bugs. If such bugs can be recognized early, the risk of propagation to dependent products and endangerment of stakeholder benefits can be mitigated. To assist triage engineers with this task, several automatic detection techniques, from Machine Learning (ML) models to prompting Large Language Models (LLMs), have been proposed. Although promising to some extent, prior techniques often memorize lexical cues as decision shortcuts, yielding low detection rate specifically for more complex submissions. As such, these classifiers do not yet reach the practical expectations of a real-time detector of security-related issues. To address these limitations, we propose SEBERTIS, a framework to train Deep Neural Networks (DNNs) as classifiers independent of lexical cues, so that they can confidently detect fully unseen security-related issues. SEBERTIS capitalizes on fine-tuning bidirectional transformer architectures as Masked Language Models (MLMs) on a series of semantically equivalent vocabulary to prediction labels (which we call Semantic Surrogates) when they have been replaced with a mask. Our SEBERTIS-trained classifier achieves a 0.9880 F1-score in detecting security-related issues of a curated corpus of 10,000 GitHub issue reports, substantially outperforming state-of-the-art issue classifiers, with 14.44%-96.98%, 15.40%-93.07%, and 14.90%-94.72% higher detection precision, recall, and F1-score over ML-based baselines. Our classifier also substantially surpasses LLM baselines, with an improvement of 23.20%-63.71%, 36.68%-85.63%, and 39.49%-74.53% for precision, recall, and F1-score.

</details>


### [16] [ScamSweeper: Detecting Illegal Accounts in Web3 Scams via Transactions Analysis](https://arxiv.org/abs/2512.15030)
*Xiaoqi Li,Wenkai Li,Zhijie Liu,Meikang Qiu,Zhiquan Liu,Sen Nie,Zongwei Li,Shi Wu,Yuqing Zhang*

Main category: cs.CR

TL;DR: ScamSweeper是一个用于检测以太坊上web3诈骗的新型框架，通过结构时间随机游走采样和变分Transformer提取交易图的动态演化特征，显著优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 随着web3应用在以太坊上的增长，诈骗活动日益猖獗。现有研究主要关注去匿名化和钓鱼节点检测，忽略了web3诈骗的独特特征，且现有检测工具在处理符合幂律分布的大规模时序交易网络时面临挑战。

Method: 提出ScamSweeper框架：1）使用结构时间随机游走采样网络，同时考虑时间属性和结构信息；2）通过有向图编码器生成不同时间间隔的子图特征序列；3）使用变分Transformer提取子图序列的动态演化特征。

Result: 在以太坊前1800万个区块高度的交易数据集上实验表明：1）在web3诈骗检测中，ScamSweeper比SIEGE、Ethident和PDTGA至少提升17.29%的加权F1分数（基准值0.59）；2）在钓鱼节点检测中，比DGTSG和BERT4ETH至少提升17.5%的F1分数（基准值0.80）。

Conclusion: ScamSweeper通过关注交易图的动态演化特征，有效解决了现有方法在处理web3诈骗检测时的局限性，在以太坊诈骗检测任务上取得了显著性能提升。

Abstract: The web3 applications have recently been growing, especially on the Ethereum platform, starting to become the target of scammers. The web3 scams, imitating the services provided by legitimate platforms, mimic regular activity to deceive users. However, previous studies have primarily concentrated on de-anonymization and phishing nodes, neglecting the distinctive features of web3 scams. Moreover, the current phishing account detection tools utilize graph learning or sampling algorithms to obtain graph features. However, large-scale transaction networks with temporal attributes conform to a power-law distribution, posing challenges in detecting web3 scams. To overcome these challenges, we present ScamSweeper, a novel framework that emphasizes the dynamic evolution of transaction graphs, to identify web3 scams on Ethereum. ScamSweeper samples the network with a structure temporal random walk, which is an optimized sample walking method that considers both temporal attributes and structural information. Then, the directed graph encoder generates the features of each subgraph during different temporal intervals, sorting as a sequence. Moreover, a variational Transformer is utilized to extract the dynamic evolution in the subgraph sequence. Furthermore, we collect a large-scale transaction dataset consisting of web3 scams, phishing, and normal accounts, which are from the first 18 million block heights on Ethereum. Subsequently, we comprehensively analyze the distinctions in various attributes, including nodes, edges, and degree distribution. Our experiments indicate that ScamSweeper outperforms SIEGE, Ethident, and PDTGA in detecting web3 scams, achieving a weighted F1-score improvement of at least 17.29% with the base value of 0.59. In addition, ScamSweeper in phishing node detection achieves at least a 17.5% improvement over DGTSG and BERT4ETH in F1-score from 0.80.

</details>


### [17] [RELIC-GNN: Efficient State Registers Identification with Graph Neural Network for Reverse Engineering](https://arxiv.org/abs/2512.15037)
*Weitao Pan,Meng Dong,Zhiliang Qiu,Jianlei Yang,Zhixiong Di,Yiming Gao*

Main category: cs.CR

TL;DR: 提出基于图神经网络的RELIC-GNN方法，用于门级网表逆向工程中的状态寄存器识别，相比传统拓扑比较方法在大规模网表中更高效。


<details>
  <summary>Details</summary>
Motivation: 门级网表逆向工程对硬件木马检测和设计盗版防范至关重要，其核心任务是分离控制信号和数据信号，主要通过识别状态寄存器实现。现有基于拓扑比较的方法在大规模网表中效率低下。

Method: 提出RELIC-GNN方法，将寄存器的路径结构建模为图，在训练过程中考虑节点属性和图结构生成相应表示，训练后的GNN模型可高效识别寄存器类型。

Result: 实验结果显示，RELIC-GNN在不同设计上平均召回率达到100%，精确度30.49%，准确率88.37%，相比之前方法有显著提升。

Conclusion: RELIC-GNN通过图神经网络有效解决了大规模门级网表中状态寄存器识别效率低的问题，在逆向工程任务中表现出色。

Abstract: Reverse engineering of gate-level netlist is critical for Hardware Trojans detection and Design Piracy counteracting. The primary task of gate-level reverse engineering is to separate the control and data signals from the netlist, which is mainly realized by identifying state registers with topological comparison.However, these methods become inefficient for large scale netlist. In this work, we propose RELIC-GNN, a graph neural network based state registers identification method, to address these issues. RELIC-GNN models the path structure of register as a graph and generates corresponding representation by considering node attributes and graph structure during training. The trained GNN model could be adopted to find the registers type very efficiently. Experimental results show that RELIC-GNN could achieve 100% in recall, 30.49% in precision and 88.37% in accuracy on average across different designs, which obtains significant improvements than previous approaches.

</details>


### [18] [APT-ClaritySet: A Large-Scale, High-Fidelity Labeled Dataset for APT Malware with Alias Normalization and Graph-Based Deduplication](https://arxiv.org/abs/2512.15039)
*Zhenhao Yin,Hanbing Yan,Huishu Lu,Jing Xiong,Xiangyu Li,Rui Mei,Tianning Zang*

Main category: cs.CR

TL;DR: 该论文提出了APT-ClaritySet数据集及其构建流程，解决了APT研究中数据集稀缺、别名不一致和样本冗余的问题，提供了标准化、去重后的高质量APT恶意软件数据集。


<details>
  <summary>Details</summary>
Motivation: APT研究面临大规模标准化数据集稀缺的问题，威胁行为体别名不一致和样本冗余严重影响了研究的可重复性。

Method: 开发了别名标准化流程（约11.22%不一致名称被统一）和图特征去重方法（可静态分析的可执行文件减少47.55%但保留行为不同变体）。构建了三个组件：完整数据集、去重后数据集和函数级重用资源。

Result: 创建了APT-ClaritySet数据集：完整版包含34,363个样本（305个APT组织）；去重版包含25,923个独特样本（303个组织）；函数重用资源包含324,538个函数重用簇。提供了高保真、可重复的研究基础。

Conclusion: 通过发布这些组件和详细的构建流程，为APT模式、演化和归因的定量研究提供了高质量、可重复的基础设施，解决了领域内数据集标准化和可重复性的关键问题。

Abstract: Large-scale, standardized datasets for Advanced Persistent Threat (APT) research are scarce, and inconsistent actor aliases and redundant samples hinder reproducibility. This paper presents APT-ClaritySet and its construction pipeline that normalizes threat actor aliases (reconciling approximately 11.22\% of inconsistent names) and applies graph-feature deduplication -- reducing the subset of statically analyzable executables by 47.55\% while retaining behaviorally distinct variants. APT-ClaritySet comprises: (i) APT-ClaritySet-Full, the complete pre-deduplication collection with 34{,}363 malware samples attributed to 305 APT groups (2006 - early 2025); (ii) APT-ClaritySet-Unique, the deduplicated release with 25{,}923 unique samples spanning 303 groups and standardized attributions; and (iii) APT-ClaritySet-FuncReuse, a function-level resource that includes 324{,}538 function-reuse clusters (FRCs) enabling measurement of inter-/intra-group sharing, evolution, and tooling lineage. By releasing these components and detailing the alias normalization and scalable deduplication pipeline, this work provides a high-fidelity, reproducible foundation for quantitative studies of APT patterns, evolution, and attribution.

</details>


### [19] [Quantifying Return on Security Controls in LLM Systems](https://arxiv.org/abs/2512.15081)
*Richard Helder Moulton,Austin O'Brien,John D. Hastings*

Main category: cs.CR

TL;DR: 提出决策导向框架，量化LLM系统残余风险，将攻击成功率转换为财务风险估计和投资回报率，比较三种防护措施效果


<details>
  <summary>Details</summary>
Motivation: LLM在安全关键工作流中应用增加，但缺乏量化指导来评估防护措施价值，需要系统化评估框架

Method: 建立RAG服务，使用DeepSeek-R1模型和合成PII数据，通过Garak进行五类攻击，用拉普拉斯成功法则估计攻击成功率，结合损失分布进行蒙特卡洛模拟生成损失超越曲线

Result: 基线系统攻击成功率极高（≥0.98），预期损失31.3万美元；ABAC将PII和提示注入攻击成功率降至近零，减少94%损失，RoC达9.83；NER消除PII泄漏，RoC为5.97；NeMo Guardrails效果有限（RoC仅0.05）

Conclusion: 决策导向框架能有效量化LLM系统风险，ABAC和NER是高效防护措施，而NeMo Guardrails效果有限，为部署防护措施提供量化依据

Abstract: Although large language models (LLMs) are increasingly used in security-critical workflows, practitioners lack quantitative guidance on which safeguards are worth deploying. This paper introduces a decision-oriented framework and reproducible methodology that together quantify residual risk, convert adversarial probe outcomes into financial risk estimates and return-on-control (RoC) metrics, and enable monetary comparison of layered defenses for LLM-based systems. A retrieval-augmented generation (RAG) service is instantiated using the DeepSeek-R1 model over a corpus containing synthetic personally identifiable information (PII), and subjected to automated attacks with Garak across five vulnerability classes: PII leakage, latent context injection, prompt injection, adversarial attack generation, and divergence. For each (vulnerability, control) pair, attack success probabilities are estimated via Laplace's Rule of Succession and combined with loss triangle distributions, calibrated from public breach-cost data, in 10,000-run Monte Carlo simulations to produce loss exceedance curves and expected losses. Three widely used mitigations, attribute-based access control (ABAC); named entity recognition (NER) redaction using Microsoft Presidio; and NeMo Guardrails, are then compared to a baseline RAG configuration. The baseline system exhibits very high attack success rates (>= 0.98 for PII, latent injection, and prompt injection), yielding a total simulated expected loss of $313k per attack scenario. ABAC collapses success probabilities for PII and prompt-related attacks to near zero and reduces the total expected loss by ~94%, achieving an RoC of 9.83. NER redaction likewise eliminates PII leakage and attains an RoC of 5.97, while NeMo Guardrails provides only marginal benefit (RoC of 0.05).

</details>


### [20] [MCPZoo: A Large-Scale Dataset of Runnable Model Context Protocol Servers for AI Agent](https://arxiv.org/abs/2512.15144)
*Mengying Wu,Pei Chen,Geng Hong,Aichao An,Jinsong Chen,Binwang Wan,Xudong Pan,Jiarun Dai,Min Yang*

Main category: cs.CR

TL;DR: MCPZoo：首个大规模、可访问的MCP服务器数据集，包含90,146个服务器，支持真实实验和系统研究


<details>
  <summary>Details</summary>
Motivation: MCP（模型上下文协议）使代理能与外部工具交互，但缺乏大规模、可访问的数据集阻碍了MCP的实证研究

Method: 从多个公共来源收集MCP服务器，构建包含90,146个服务器的数据集，其中超过一万个实例已部署验证为可运行和可交互

Result: 创建了MCPZoo数据集，提供统一的元数据和访问接口，支持无需手动部署的系统探索和交互

Conclusion: MCPZoo作为开放可访问资源发布，支持基于MCP的安全分析研究，促进超越静态分析的真实实验

Abstract: Model Context Protocol (MCP) enables agents to interact with external tools, yet empirical research on MCP is hindered by the lack of large-scale, accessible datasets. We present MCPZoo, the largest and most comprehensive dataset of MCP servers collected from multiple public sources, comprising 90,146 servers. MCPZoo includes over ten thousand server instances that have been deployed and verified as runnable and interactable, supporting realistic experimentation beyond static analysis. The dataset provides unified metadata and access interfaces, enabling systematic exploration and interaction without manual deployment effort. MCPZoo is released as an open and accessible resource to support research on MCP-based security analysis.

</details>


### [21] [Policy-Value Guided MDP-MCTS Framework for Cyber Kill-Chain Inference](https://arxiv.org/abs/2512.15150)
*Chitraksh Singh,Monisha Dhanraj,Ken Huang*

Main category: cs.CR

TL;DR: 提出一个结合Transformer语义先验与符号化MDP的推理框架，通过AlphaZero风格MCTS自动重建ATT&CK一致的完整七阶段杀伤链


<details>
  <summary>Details</summary>
Motivation: 威胁分析师依赖的自然语言报告通常不完整描述攻击者行动，缺乏完整杀伤链和阶段依赖关系，使得自动化重建ATT&CK一致的入侵路径成为困难问题

Method: 提出推理框架：结合Transformer模型的阶段条件语义先验、符号化马尔可夫决策过程、以及由策略-价值网络指导的AlphaZero风格蒙特卡洛树搜索，通过多目标奖励函数确保语义相关性、阶段凝聚性和转移合理性

Result: 应用于FIN6、APT24和UNC1549三个真实入侵案例，生成的杀伤链在语义保真度和操作连贯性上超越Transformer基线，经常与专家选择的TTPs对齐

Conclusion: 结合上下文嵌入与基于搜索的决策制定为网络防御提供了自动化、可解释的杀伤链重建的实用路径

Abstract: Threat analysts routinely rely on natural-language reports that describe attacker actions without enumerating the full kill chain or the dependencies between phases, making automated reconstruction of ATT&CK consistent intrusion paths a difficult open problem. We propose a reasoning framework that infers complete seven-phase kill chains by coupling phase-conditioned semantic priors from Transformer models with a symbolic Markov Decision Process and an AlphaZero-style Monte Carlo Tree Search guided by a Policy-Value Network. The framework enforces semantic relevance, phase cohesion, and transition plausibility through a multi-objective reward function while allowing search to explore alternative interpretations of the CTI narrative. Applied to three real intrusions FIN6, APT24, and UNC1549 the approach yields kill chains that surpass Transformer baselines in semantic fidelity and operational coherence, and frequently align with expert-selected TTPs. Our results demonstrate that combining contextual embeddings with search-based decision-making offers a practical path toward automated, interpretable kill-chain reconstruction for cyber defense.

</details>


### [22] [No More Hidden Pitfalls? Exposing Smart Contract Bad Practices with LLM-Powered Hybrid Analysis](https://arxiv.org/abs/2512.15179)
*Xiaoqi Li,Zongwei Li,Wenkai Li,Yuqing Zhang,Xin Wang*

Main category: cs.CR

TL;DR: SCALM：首个基于LLM的智能合约不良实践系统化研究框架，通过混合架构和多层推理验证系统，在检测47种以上不良实践方面优于现有工具。


<details>
  <summary>Details</summary>
Motivation: 随着以太坊平台的成熟和广泛应用，需要维护高标准的智能合约编写实践。虽然不良实践不一定直接导致安全问题，但会增加风险，因此需要系统化研究来理解和避免这些不良实践。

Method: 提出SCALM框架，包含两个方法创新：1）混合架构，结合上下文感知的函数级切片和通过可扩展向量化模式匹配的知识增强语义推理；2）多层推理验证系统，通过语法、设计模式和架构分析连接低级代码模式与高级安全原则。

Result: 使用多个LLM和数据集的广泛实验表明，SCALM在检测智能合约不良实践方面优于现有工具。

Conclusion: 该研究首次系统化研究了智能合约中的不良实践，提出的SCALM框架通过创新的混合架构和多层推理验证系统，有效提升了智能合约不良实践的检测能力。

Abstract: As the Ethereum platform continues to mature and gain widespread usage, it is crucial to maintain high standards of smart contract writing practices. While bad practices in smart contracts may not directly lead to security issues, they elevate the risk of encountering problems. Therefore, to understand and avoid these bad practices, this paper introduces the first systematic study of bad practices in smart contracts, delving into over 47 specific issues. Specifically, we propose SCALM, an LLM-powered framework featuring two methodological innovations: (1) A hybrid architecture that combines context-aware function-level slicing with knowledge-enhanced semantic reasoning via extensible vectorized pattern matching. (2) A multi-layer reasoning verification system connects low-level code patterns with high-level security principles through syntax, design patterns, and architecture analysis. Our extensive experiments using multiple LLMs and datasets have shown that SCALM outperforms existing tools in detecting bad practices in smart contracts.

</details>


### [23] [Bounty Hunter: Autonomous, Comprehensive Emulation of Multi-Faceted Adversaries](https://arxiv.org/abs/2512.15275)
*Louis Hackländer-Jansen,Rafael Uetz,Martin Henze*

Main category: cs.CR

TL;DR: Bounty Hunter是一个用于Caldera平台的自动化对手仿真插件，能够自主执行多方面的攻击行为，覆盖广泛的战术，实现从预入侵到后入侵的完整攻击链。


<details>
  <summary>Details</summary>
Motivation: 当前对手仿真自动化方法存在自主性不足、战术覆盖有限、现实适用性差等问题，导致对手仿真仍然主要依赖人工操作，需要大量安全专家投入，即使在大语言模型兴起后依然如此。

Method: 开发了Bounty Hunter作为Caldera平台的开源插件，实现自主的对手仿真，支持多方面的攻击行为，包括不同级别的可检测性和重复仿真中的多样化攻击路径。

Result: Bounty Hunter能够在模拟企业网络中自主达成给定目标，无需事先了解目标网络，成功实现了预入侵、初始入侵和后入侵等完整攻击战术。

Conclusion: Bounty Hunter提供了自主、全面、多方面的对手仿真能力，帮助研究人员和从业者进行现实且高效的安全评估、培训演练和入侵检测研究。

Abstract: Adversary emulation is an essential procedure for cybersecurity assessments such as evaluating an organization's security posture or facilitating structured training and research in dedicated environments. To allow for systematic and time-efficient assessments, several approaches from academia and industry have worked towards the automation of adversarial actions. However, they exhibit significant limitations regarding autonomy, tactics coverage, and real-world applicability. Consequently, adversary emulation remains a predominantly manual task requiring substantial human effort and security expertise - even amidst the rise of Large Language Models. In this paper, we present Bounty Hunter, an automated adversary emulation method, designed and implemented as an open-source plugin for the popular adversary emulation platform Caldera, that enables autonomous emulation of adversaries with multi-faceted behavior while providing a wide coverage of tactics. To this end, it realizes diverse adversarial behavior, such as different levels of detectability and varying attack paths across repeated emulations. By autonomously compromising a simulated enterprise network, Bounty Hunter showcases its ability to achieve given objectives without prior knowledge of its target, including pre-compromise, initial compromise, and post-compromise attack tactics. Overall, Bounty Hunter facilitates autonomous, comprehensive, and multi-faceted adversary emulation to help researchers and practitioners in performing realistic and time-efficient security assessments, training exercises, and intrusion detection research.

</details>


### [24] [Talking to the Airgap: Exploiting Radio-Less Embedded Devices as Radio Receivers](https://arxiv.org/abs/2512.15387)
*Paul Staat,Daniel Davidovich,Christof Paar*

Main category: cs.CR

TL;DR: 研究展示恶意代码可利用嵌入式设备的寄生射频敏感性，在无硬件修改情况下无线渗透物理隔离系统，实现远程命令与控制。


<details>
  <summary>Details</summary>
Motivation: 物理隔离系统（airgapped systems）被认为能防止远程攻击，但现有研究主要关注数据外泄。本研究探索反向攻击：如何无线渗透隔离系统而不依赖专用传感器或视线条件。

Method: 提出系统化方法识别设备配置中的射频敏感性，利用PCB走线和片上ADC的寄生射频接收特性。在12款商用嵌入式设备和2个定制原型上测试，在300-1000 MHz范围内验证接收能力。

Result: 实验显示可检测低至1 mW的信号功率，在非视线条件下实现数十米距离的数据接收，最高支持100 kbps数据传输速率。证明无传感器设备可意外充当无线电接收器。

Conclusion: 研究揭示了物理隔离系统先前未探索的命令与控制向量，挑战了其固有隔离性的假设，表明即使无硬件修改的嵌入式设备也可能被无线渗透。

Abstract: Intelligent electronics are deeply embedded in critical infrastructures and must remain reliable, particularly against deliberate attacks. To minimize risks and impede remote compromise, sensitive systems can be physically isolated from external networks, forming an airgap. Yet, airgaps can still be infiltrated by capable adversaries gaining code execution. Prior research has shown that attackers can then attempt to wirelessly exfiltrate data across the airgap by exploiting unintended radio emissions. In this work, we demonstrate reversal of this link: malicious code execution on embedded devices can enable wireless infiltration of airgapped systems without any hardware modification. In contrast to previous infiltration methods that depend on dedicated sensors (e.g., microphones, LEDs, or temperature sensors) or require strict line-of-sight, we show that unmodified, sensor-less embedded devices can inadvertently act as radio receivers. This phenomenon stems from parasitic RF sensitivity in PCB traces and on-chip analog-to-digital converters (ADCs), allowing external transmissions to be received and decoded entirely in software.
  Across twelve commercially available embedded devices and two custom prototypes, we observe repeatable reception in the 300-1000 MHz range, with detectable signal power as low as 1 mW. To this end, we propose a systematic methodology to identify device configurations that foster such radio sensitivities and comprehensively evaluate their feasibility for wireless data reception. Exploiting these sensitivities, we demonstrate successful data reception over tens of meters, even in non-line-of-sight conditions and show that the reception sensitivities accommodate data rates of up to 100 kbps. Our findings reveal a previously unexplored command-and-control vector for air-gapped systems while challenging assumptions about their inherent isolation. [shortened]

</details>


### [25] [Packed Malware Detection Using Grayscale Binary-to-Image Representations](https://arxiv.org/abs/2512.15414)
*Ehab Alkhateeb,Ali Ghorbani,Arash Habibi Lashkari*

Main category: cs.CR

TL;DR: 该研究评估了基于传统特征和深度学习方法检测打包可执行文件，发现基于灰度字节图表示和CNN的方法（特别是DenseNet121和VGG16）显著优于传统方法，能有效检测未知打包器，增强恶意软件分析流程。


<details>
  <summary>Details</summary>
Motivation: 检测打包可执行文件是恶意软件分析的关键步骤，因为打包会隐藏原始代码并复杂化静态检查。需要有效方法来识别打包文件以支持恶意软件分析和自动化反病毒检查。

Method: 研究评估了两种方法：1）基于手工特征的传统方法（使用Gabor jet特征）；2）深度学习方法，将二进制可执行文件转换为灰度字节图表示，并使用卷积神经网络（CNN）进行分类，特别测试了VGG16和DenseNet121架构。

Result: 基于CNN的方法显著优于传统方法，实现了高检测性能，具有均衡的精确率、召回率和F1分数。DenseNet121表现出略高的精确率和较低的误报率，而VGG16实现了稍高的召回率。两种模型对未知打包器都表现出强大的泛化能力。

Conclusion: 灰度字节图表示与深度学习结合为打包恶意软件的早期检测提供了有用且可靠的方法，能够增强恶意软件分析流程并支持自动化反病毒检查，特别是CNN模型在检测性能和泛化能力方面表现出色。

Abstract: Detecting packed executables is a critical step in malware analysis, as packing obscures the original code and complicates static inspection. This study evaluates both classical feature-based methods and deep learning approaches that transform binary executables into visual representations, specifically, grayscale byte plots, and employ convolutional neural networks (CNNs) for automated classification of packed and non-packed binaries. A diverse dataset of benign and malicious Portable Executable (PE) files, packed using various commercial and open-source packers, was curated to capture a broad spectrum of packing transformations and obfuscation techniques. Classical models using handcrafted Gabor jet features achieved intense discrimination at moderate computational cost. In contrast, CNNs based on VGG16 and DenseNet121 significantly outperformed them, achieving high detection performance with well-balanced precision, recall, and F1-scores. DenseNet121 demonstrated slightly higher precision and lower false positive rates, whereas VGG16 achieved marginally higher recall, indicating complementary strengths for practical deployment. Evaluation against unknown packers confirmed robust generalization, demonstrating that grayscale byte-plot representations combined with deep learning provide a useful and reliable approach for early detection of packed malware, enhancing malware analysis pipelines and supporting automated antivirus inspection.

</details>


### [26] [Attention in Motion: Secure Platooning via Transformer-based Misbehavior Detection](https://arxiv.org/abs/2512.15503)
*Konstantinos Kalogiannis,Ahmed Mohamed Hussain,Hexu Li,Panos Papadimitratos*

Main category: cs.CR

TL;DR: AIMformer：基于Transformer的实时车辆编队异常行为检测框架，利用多头自注意力机制捕获时空依赖关系，在边缘设备上实现亚毫秒级推理延迟。


<details>
  <summary>Details</summary>
Motivation: 车辆编队通过V2X通信实现多车协同，但分布式特性存在安全漏洞，传统检测方法误报率高且无法捕捉复杂的时空依赖关系，需要更有效的实时检测方案。

Method: 提出AIMformer框架，使用多头自注意力机制同时捕获车辆内部时间动态和车辆间空间相关性，引入全局位置编码处理车辆加入/退出，采用针对误报优化的BCE损失函数。

Result: 在4种编队控制器、多种攻击向量和不同移动场景下的评估显示性能优于现有方法（≥0.93），通过TensorFlow Lite、ONNX和TensorRT实现亚毫秒级推理延迟。

Conclusion: AIMformer验证了在车辆和路边基础设施部署的可行性，为安全关键的车辆系统提供了高效的实时异常行为检测解决方案。

Abstract: Vehicular platooning promises transformative improvements in transportation efficiency and safety through the coordination of multi-vehicle formations enabled by Vehicle-to-Everything (V2X) communication. However, the distributed nature of platoon coordination creates security vulnerabilities, allowing authenticated vehicles to inject falsified kinematic data, compromise operational stability, and pose a threat to passenger safety. Traditional misbehaviour detection approaches, which rely on plausibility checks and statistical methods, suffer from high False Positive (FP) rates and cannot capture the complex temporal dependencies inherent in multi-vehicle coordination dynamics. We present Attention In Motion (AIMformer), a transformer-based framework specifically tailored for real-time misbehaviour detection in vehicular platoons with edge deployment capabilities. AIMformer leverages multi-head self-attention mechanisms to simultaneously capture intra-vehicle temporal dynamics and inter-vehicle spatial correlations. It incorporates global positional encoding with vehicle-specific temporal offsets to handle join/exit maneuvers. We propose a Precision-Focused (BCE) loss function that penalizes FPs to meet the requirements of safety-critical vehicular systems. Extensive evaluation across 4 platoon controllers, multiple attack vectors, and diverse mobility scenarios demonstrates superior performance ($\geq$ 0.93) compared to state-of-the-art baseline architectures. A comprehensive deployment analysis utilizing TensorFlow Lite (TFLite), Open Neural Network Exchange (ONNX), and TensorRT achieves sub-millisecond inference latency, making it suitable for real-time operation on resource-constrained edge platforms. Hence, validating AIMformer is viable for both in-vehicle and roadside infrastructure deployment.

</details>


### [27] [Time will Tell: Large-scale De-anonymization of Hidden I2P Services via Live Behavior Alignment (Extended Version)](https://arxiv.org/abs/2512.15510)
*Hongze Wang,Zhen Ling,Xiangyu Xu,Yumingzhi Pan,Guangchi Liu,Junzhou Luo,Xinwen Fu*

Main category: cs.CR

TL;DR: I2PERCEPTION是一种低成本方法，通过部署洪泛路由器监控I2P网络，分析路由器加入/离开行为，并与目标隐藏服务的在线模式进行关联，从而揭示隐藏服务的真实IP地址。


<details>
  <summary>Details</summary>
Motivation: 现有I2P去匿名化方法主要关注在大量网络流量中识别目标隐藏服务的流量模式，但这些方法难以在包含众多路由器的大型多样化I2P网络中有效扩展。

Method: 部署洪泛路由器被动监控I2P路由器并收集RouterInfo；分析路由器信息发布机制以准确识别路由器的加入/离开行为；通过主动探测获取目标隐藏服务的在线行为模式；将目标隐藏服务与I2P路由器的实时行为进行时间关联，缩小匹配路由器集合。

Result: 仅使用15个洪泛路由器在8个月时间内验证了方法的精确性和有效性，成功对所有受控隐藏服务进行了去匿名化。

Conclusion: I2PERCEPTION是一种低成本且有效的I2P隐藏服务去匿名化方法，能够通过行为关联揭示隐藏服务的真实网络身份。

Abstract: I2P (Invisible Internet Project) is a popular anonymous communication network. While existing de-anonymization methods for I2P focus on identifying potential traffic patterns of target hidden services among extensive network traffic, they often fail to scale effectively across the large and diverse I2P network, which consists of numerous routers. In this paper, we introduce I2PERCEPTION a low-cost approach revealing the IP addresses of I2P hidden services. In I2PERCEPTION, attackers deploy floodfill routers to passively monitor I2P routers and collect their RouterInfo. We analyze the router information publication mechanism to accurately identify routers' join (i.e. on) and leave (i.e. off) behaviors, enabling fine-grained live behavior inference across the I2P network. Active probing is used to obtain the live behavior (i.e., on-off patterns) of a target hidden service hosted on one of the I2P routers. By correlating the live behaviors of the target hidden service and I2P routers over time, we narrow down the set of routers matching the hidden service's behavior, revealing the hidden service's true network identity for de-anonymization. Through the deployment of only 15 floodfill routers over the course of eight months, we validate the precision and effectiveness of our approach with extensive real-world experiments. Our results show that I2PERCEPTION successfully de-anonymizes all controlled hidden services.

</details>


### [28] [ComMark: Covert and Robust Black-Box Model Watermarking with Compressed Samples](https://arxiv.org/abs/2512.15641)
*Yunfei Yang,Xiaojun Chen,Zhendong Zhao,Yu Zhou,Xiaoyan Gu,Juan Cao*

Main category: cs.CR

TL;DR: ComMark是一个基于频域变换的黑盒模型水印框架，通过过滤高频信息生成压缩、隐蔽且抗攻击的水印样本，在隐蔽性和鲁棒性方面达到最优平衡。


<details>
  <summary>Details</summary>
Motivation: 深度学习模型已成为高价值资产，但面临泄露和盗窃风险，需要有效的知识产权保护。现有黑盒水印方法在隐蔽性（防止检测和伪造）和鲁棒性（抵抗移除攻击）之间难以取得良好平衡。

Method: 利用频域变换过滤高频信息生成压缩、隐蔽的水印样本；在训练过程中加入模拟攻击场景和相似性损失来增强水印鲁棒性。

Result: 在多种数据集和架构上的综合评估表明，ComMark在隐蔽性和鲁棒性方面均达到最先进性能。该框架还可扩展到语音识别、情感分析、图像生成、图像描述和视频识别等任务。

Conclusion: ComMark通过频域变换方法有效解决了黑盒模型水印中隐蔽性与鲁棒性的平衡问题，具有广泛的适用性和实际应用价值。

Abstract: The rapid advancement of deep learning has turned models into highly valuable assets due to their reliance on massive data and costly training processes. However, these models are increasingly vulnerable to leakage and theft, highlighting the critical need for robust intellectual property protection. Model watermarking has emerged as an effective solution, with black-box watermarking gaining significant attention for its practicality and flexibility. Nonetheless, existing black-box methods often fail to better balance covertness (hiding the watermark to prevent detection and forgery) and robustness (ensuring the watermark resists removal)-two essential properties for real-world copyright verification. In this paper, we propose ComMark, a novel black-box model watermarking framework that leverages frequency-domain transformations to generate compressed, covert, and attack-resistant watermark samples by filtering out high-frequency information. To further enhance watermark robustness, our method incorporates simulated attack scenarios and a similarity loss during training. Comprehensive evaluations across diverse datasets and architectures demonstrate that ComMark achieves state-of-the-art performance in both covertness and robustness. Furthermore, we extend its applicability beyond image recognition to tasks including speech recognition, sentiment analysis, image generation, image captioning, and video recognition, underscoring its versatility and broad applicability.

</details>


### [29] [Distributed HDMM: Scalable, Distributed, Accurate, and Differentially Private Query Workloads without a Trusted Curator](https://arxiv.org/abs/2512.15648)
*Ratang Sedimo,Ivoline C. Ngong,Jami Lashua,Joseph P. Near*

Main category: cs.CR

TL;DR: Distributed HDMM是一个用于分布式数据线性查询的协议，在恶意聚合器和恶意客户端（假设诚实多数）的情况下，提供中心模型HDMM的准确性而无需可信策展人。


<details>
  <summary>Details</summary>
Motivation: 解决在分布式数据环境中进行线性查询时的隐私保护问题，避免依赖可信策展人，同时保持与中心化模型相当的准确性。

Method: 利用安全聚合协议在分布式数据上评估HDMM，在恶意聚合器和恶意客户端（假设诚实多数）的威胁模型下提供安全保障。

Result: 初步实证评估显示，Distributed HDMM可以在数千个客户端的实际数据集和工作负载上运行，时间少于1分钟。

Conclusion: Distributed HDMM成功实现了在分布式环境中提供中心模型HDMM的准确性，无需可信策展人，具有实际部署的可行性。

Abstract: We present the Distributed High-Dimensional Matrix Mechanism (Distributed HDMM), a protocol for answering workloads of linear queries on distributed data that provides the accuracy of central-model HDMM without a trusted curator. Distributed HDMM leverages a secure aggregation protocol to evaluate HDMM on distributed data, and is secure in the context of a malicious aggregator and malicious clients (assuming an honest majority). Our preliminary empirical evaluation shows that Distributed HDMM can run on realistic datasets and workloads with thousands of clients in less than one minute.

</details>


### [30] [BashArena: A Control Setting for Highly Privileged AI Agents](https://arxiv.org/abs/2512.15688)
*Adam Kaufman,James Lucassen,Tyler Tracy,Cody Rushing,Aryan Bhatt*

Main category: cs.CR

TL;DR: BashArena是一个用于研究AI控制技术的安全关键环境，包含637个Linux系统管理任务和4种破坏目标，评估LLMs完成任务、执行破坏和检测破坏的能力。


<details>
  <summary>Details</summary>
Motivation: 未来具有高权限的自主AI代理如果未对齐，可能滥用权限造成严重损害。AI控制领域需要开发技术，使未对齐AI更难造成损害，同时保持其有用性。

Method: 引入BashArena环境，包含637个Linux系统管理和基础设施工程任务，以及4种破坏目标（执行恶意软件、窃取机密、提升权限、禁用防火墙）。评估多个前沿LLMs在完成任务、执行破坏和检测破坏方面的能力。

Result: Claude Sonnet 4.5在4%的轨迹假阳性率下，成功执行破坏并逃避GPT-4.1 mini监控的比例达到26%。为BashArena中设计更有效的控制协议提供了基线。

Conclusion: BashArena为研究AI控制技术提供了实用的实验环境，发布了数据集作为ControlArena设置，并分享了任务生成流程，有助于开发更有效的AI控制协议。

Abstract: Future AI agents might run autonomously with elevated privileges. If these agents are misaligned, they might abuse these privileges to cause serious damage. The field of AI control develops techniques that make it harder for misaligned AIs to cause such damage, while preserving their usefulness. We introduce BashArena, a setting for studying AI control techniques in security-critical environments. BashArena contains 637 Linux system administration and infrastructure engineering tasks in complex, realistic environments, along with four sabotage objectives (execute malware, exfiltrate secrets, escalate privileges, and disable firewall) for a red team to target. We evaluate multiple frontier LLMs on their ability to complete tasks, perform sabotage undetected, and detect sabotage attempts. Claude Sonnet 4.5 successfully executes sabotage while evading monitoring by GPT-4.1 mini 26% of the time, at 4% trajectory-wise FPR. Our findings provide a baseline for designing more effective control protocols in BashArena. We release the dataset as a ControlArena setting and share our task generation pipeline.

</details>
