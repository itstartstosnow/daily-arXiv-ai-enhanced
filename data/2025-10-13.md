<div id=toc></div>

# Table of Contents

- [cs.CR](#cs.CR) [Total: 15]


<div id='cs.CR'></div>

# cs.CR [[Back]](#toc)

### [1] [Are Voters Willing to Collectively Secure Elections? Unraveling a Practical Blockchain Voting System](https://arxiv.org/abs/2510.08700)
*Zhuolun Li,Haluk Sonmezler,Faiza Shirazi,Febin Shaji,Tymoteusz Mroczkowski,Dexter Lardner,Matthew Alain Camus,Evangelos Pournaras*

Main category: cs.CR

TL;DR: 提出集体安全投票概念，让选民自愿成为秘密持有者来保护选票机密性，设计并实现基于区块链的集体安全投票系统，结合门限密码学和智能合约，在保持透明可验证的同时确保选票机密性。


<details>
  <summary>Details</summary>
Motivation: 确保选票机密性对于公平可信的电子投票系统至关重要，但在去中心化的大规模选举中实现强机密性保证仍然具有挑战性。

Method: 设计基于区块链的集体安全投票系统，结合门限密码学和智能合约，选民通过直观的用户界面使用系统，无需区块链知识。

Result: 用户测试显示选民高度愿意担任秘密持有者，可靠参与份额释放，对系统安全性有高度信心。

Conclusion: 选民能够集体维护机密性，这种实际部署是可行的。

Abstract: Ensuring ballot secrecy is critical for fair and trustworthy electronic
voting systems, yet achieving strong secrecy guarantees in decentralized,
large-scale elections remains challenging. This paper proposes the concept of
collectively secure voting, in which voters themselves can opt in as secret
holders to protect ballot secrecy. A practical blockchain-based collectively
secure voting system is designed and implemented. Our design strikes a balance
between strong confidentiality guarantees and real-world applicability. The
proposed system combines threshold cryptography and smart contracts to ensure
ballots remain confidential during voting, while all protocol steps remain
transparent and verifiable. Voters can use the system without prior blockchain
knowledge through an intuitive user interface that hides underlying complexity.
To evaluate this approach, a user testing is conducted. Results show a high
willingness to act as secret holders, reliable participation in share release,
and high security confidence in the proposed system. The findings demonstrate
that voters can collectively maintain secrecy and that such a practical
deployment is feasible.

</details>


### [2] [Post-Quantum Security of Block Cipher Constructions](https://arxiv.org/abs/2510.08725)
*Gorjan Alagic,Chen Bai,Christian Majenz,Kaiyan Shi*

Main category: cs.CR

TL;DR: 本文为分组密码及其相关构造建立了后量子安全理论框架，首次提供了FX密钥扩展方案、LRW和XEX可调分组密码以及多数分组密码加密和认证模式的后量子安全证明。


<details>
  <summary>Details</summary>
Motivation: 虽然公钥密码学的后量子安全已得到广泛关注，但对称密钥密码学（特别是分组密码）的后量子安全性仍是一个未被充分探索的领域。

Method: 利用新技术在普通模型和量子理想密码模型中进行安全证明，为多种分组密码构造提供后量子安全分析。

Result: 成功为FX密钥扩展方案、LRW和XEX可调分组密码以及多数分组密码加密和认证模式提供了首个后量子安全证明。

Conclusion: 这项工作在建立实用对称密钥密码学后量子安全的严格理解方面迈出了重要的初步步骤。

Abstract: Block ciphers are versatile cryptographic ingredients that are used in a wide
range of applications ranging from secure Internet communications to disk
encryption. While post-quantum security of public-key cryptography has received
significant attention, the case of symmetric-key cryptography (and block
ciphers in particular) remains a largely unexplored topic. In this work, we set
the foundations for a theory of post-quantum security for block ciphers and
associated constructions. Leveraging our new techniques, we provide the first
post-quantum security proofs for the key-length extension scheme FX, the
tweakable block ciphers LRW and XEX, and most block cipher encryption and
authentication modes. Our techniques can be used for security proofs in both
the plain model and the quantum ideal cipher model. Our work takes significant
initial steps in establishing a rigorous understanding of the post-quantum
security of practical symmetric-key cryptography.

</details>


### [3] [CommandSans: Securing AI Agents with Surgical Precision Prompt Sanitization](https://arxiv.org/abs/2510.08829)
*Debeshee Das,Luca Beurer-Kellner,Marc Fischer,Maximilian Baader*

Main category: cs.CR

TL;DR: 提出了一种基于令牌级消毒的方法来防御LLM代理的间接提示注入攻击，通过从工具输出中移除针对AI系统的指令来捕获恶意指令，无需依赖复杂的分类器校准。


<details>
  <summary>Details</summary>
Motivation: LLM代理广泛使用工具和敏感数据导致间接提示注入攻击面扩大，现有防御方法因无法可靠区分恶意和良性指令而存在高误报率，阻碍实际应用。

Method: 采用令牌级消毒过程，从工具输出中精确移除针对AI系统的指令，这种方法是非阻塞的、无需校准且与工具输出上下文无关。

Result: 在多个基准测试中显著降低攻击成功率（从34%降至3%），同时不影响代理在良性和恶意环境下的效用。

Conclusion: 基于计算机安全基本原则的方法能有效防御间接提示注入攻击，具有良好的泛化能力和实用性。

Abstract: The increasing adoption of LLM agents with access to numerous tools and
sensitive data significantly widens the attack surface for indirect prompt
injections. Due to the context-dependent nature of attacks, however, current
defenses are often ill-calibrated as they cannot reliably differentiate
malicious and benign instructions, leading to high false positive rates that
prevent their real-world adoption. To address this, we present a novel approach
inspired by the fundamental principle of computer security: data should not
contain executable instructions. Instead of sample-level classification, we
propose a token-level sanitization process, which surgically removes any
instructions directed at AI systems from tool outputs, capturing malicious
instructions as a byproduct. In contrast to existing safety classifiers, this
approach is non-blocking, does not require calibration, and is agnostic to the
context of tool outputs. Further, we can train such token-level predictors with
readily available instruction-tuning data only, and don't have to rely on
unrealistic prompt injection examples from challenges or of other synthetic
origin. In our experiments, we find that this approach generalizes well across
a wide range of attacks and benchmarks like AgentDojo, BIPIA, InjecAgent, ASB
and SEP, achieving a 7-10x reduction of attack success rate (ASR) (34% to 3% on
AgentDojo), without impairing agent utility in both benign and malicious
settings.

</details>


### [4] [Psyzkaller: Learning from Historical and On-the-Fly Execution Data for Smarter Seed Generation in OS kernel Fuzzing](https://arxiv.org/abs/2510.08918)
*Boyu Liu,Yang Zhang,Liang Cheng,Yi Zhang,Junjie Fan,Yu Fu*

Main category: cs.CR

TL;DR: 提出Psyzkaller，通过N-gram模型从历史数据和实时执行轨迹中学习系统调用依赖关系，改进Syzkaller的种子生成，提高代码覆盖率和漏洞发现能力。


<details>
  <summary>Details</summary>
Motivation: 现有内核模糊测试工具难以生成符合系统调用依赖关系的有效序列，导致效率低下。

Method: 使用N-gram模型从Dongting数据集和实时执行轨迹中挖掘系统调用依赖关系，并引入随机游走策略双向构建种子。

Result: 在48小时测试中，Psyzkaller比Syzkaller代码覆盖率提高4.6%-7.0%，触发崩溃数增加110.4%-187.2%，发现8个新漏洞。

Conclusion: 通过学习系统调用依赖关系并将其集成到模糊测试中，可以显著提高内核模糊测试的有效性和效率。

Abstract: Fuzzing has become a cornerstone technique for uncovering vulnerabilities and
enhancing the security of OS kernels. However, state-of-the-art kernel fuzzers,
including the de facto standard Syzkaller, struggle to generate valid syscall
sequences that respect implicit Syscall Dependency Relations (SDRs).
Consequently, many generated seeds either fail kernel validation or cannot
penetrate deep execution paths, resulting in significant inefficiency.
  We hypothesize that SDRs can be effectively learned from both historic and
present kernel execution data, and that incorporating these learned relations
into fuzzing can substantially improve seed validity and diversity. To validate
this, we propose an approach that utilizes the N-gram model to mine SDRs from
the Dongting dataset-one of the largest Linux kernel execution datasets
available-as well as from execution traces collected on the fly during fuzzing.
The resulting model is used to continuously augment the Choice Table of
Syzkaller to improve its seed generation and demonstrably increases the Shannon
Entropy of the Choice Table throughout fuzzing, reflecting more
empirically-grounded choices in expanding syscall sequences into valid and
diverse seeds. In addition, we introduce a Random Walk strategy that instructs
Syzkaller to construct seeds in a bidirectional manner to further diversify the
generated seeds.
  We implement our approach in a prototype, Psyzkaller, built on top of
Syzkaller. Experiments on three representative Linux kernel versions show that
Psyzkaller improves Syzkaller's code coverage by 4.6%-7.0% in 48-hour fuzzing,
while triggering 110.4%-187.2% more crashes. Moreover, our investigation shows
that Psyzkaller discovered eight previously unknown kernel vulnerabilities,
compared to only one found by Syzkaller.

</details>


### [5] [Future G Network's New Reality: Opportunities and Security Challenges](https://arxiv.org/abs/2510.09006)
*Chandra Thapa,Surya Nepal*

Main category: cs.CR

TL;DR: 未来6G网络中的集成感知与通信(ISAC)技术将无线连接转变为无处不在的传感器，但同时也带来了新的安全挑战，需要从传统的数据保护转向保护系统对物理现实感知的完整性。


<details>
  <summary>Details</summary>
Motivation: ISAC技术创造了广泛的网络物理环境，为自主系统、增强人类感知和沉浸式应用提供了变革性能力，但这也从根本上重塑了安全格局，需要应对感知层面的新型威胁。

Method: 提出需要采取主动、分层、纵深防御策略，整合物理、环境、情报和架构安全措施，同时强调全球标准化和强有力治理的重要性。

Result: 传统基于签名的检测方法不足以应对这些模仿真实物理信号的感知级威胁，需要构建可信赖的生态系统。

Conclusion: 负责任地实现ISAC潜力需要并行推进全球标准化和强有力治理，以应对隐私、责任和技术双重使用等重大挑战。

Abstract: Future G network's new reality is a widespread cyber-physical environment
created by Integrated Sensing and Communication (ISAC). It is a crucial
technology that transforms wireless connections into ubiquitous sensors. ISAC
unlocks transformative new capabilities, powering autonomous systems, augmented
human sensing, and next-generation immersive applications, such as digital
twins. However, this new reality fundamentally reshapes the security landscape.
The primary security concern shifts from the traditional focus on data
protection to a new priority: safeguarding the integrity of the system's
perception of physical reality itself. This perception can be perilously
manipulated by sophisticated attacks such as sensing eavesdropping, phantom
dangers, and invisible threats, potentially resulting in direct and
catastrophic physical harm. Traditional security measures, such as
signature-based detection, are insufficient to counter these perception-level
threats that mimic genuine physical signals. A proactive, layered,
defense-in-depth strategy is required, integrating physical, environmental,
intelligence, and architectural security measures to build a trustworthy
ecosystem. Additionally, realizing ISAC's potential responsibly also depends on
parallel efforts in global standardization and strong governance to address the
significant challenges of privacy, liability, and the technology's dual-use.

</details>


### [6] [Exploiting Web Search Tools of AI Agents for Data Exfiltration](https://arxiv.org/abs/2510.09093)
*Dennis Rall,Bernhard Bauer,Mohit Mittal,Thomas Fraunholz*

Main category: cs.CR

TL;DR: 该论文系统评估了大语言模型对间接提示注入攻击的脆弱性，发现即使已知攻击模式仍然有效，暴露了模型防御的持续弱点。


<details>
  <summary>Details</summary>
Motivation: 随着LLMs越来越多地与外部数据源交互，间接提示注入成为一个关键且不断演变的攻击向量，使攻击者能够通过操纵输入来利用模型。

Method: 通过系统评估不同模型上的间接提示注入攻击，分析当前LLMs对此类攻击的易感性，以及模型大小、制造商、具体实现等参数如何影响其脆弱性。

Result: 研究结果显示，即使众所周知的攻击模式仍然成功，暴露了模型防御的持续弱点。

Conclusion: 需要加强训练程序以增强内在韧性，建立已知攻击向量的集中数据库以支持主动防御，并采用统一测试框架确保持续安全验证，这些步骤对于将安全性整合到LLMs核心设计中至关重要。

Abstract: Large language models (LLMs) are now routinely used to autonomously execute
complex tasks, from natural language processing to dynamic workflows like web
searches. The usage of tool-calling and Retrieval Augmented Generation (RAG)
allows LLMs to process and retrieve sensitive corporate data, amplifying both
their functionality and vulnerability to abuse. As LLMs increasingly interact
with external data sources, indirect prompt injection emerges as a critical and
evolving attack vector, enabling adversaries to exploit models through
manipulated inputs. Through a systematic evaluation of indirect prompt
injection attacks across diverse models, we analyze how susceptible current
LLMs are to such attacks, which parameters, including model size and
manufacturer, specific implementations, shape their vulnerability, and which
attack methods remain most effective. Our results reveal that even well-known
attack patterns continue to succeed, exposing persistent weaknesses in model
defenses. To address these vulnerabilities, we emphasize the need for
strengthened training procedures to enhance inherent resilience, a centralized
database of known attack vectors to enable proactive defense, and a unified
testing framework to ensure continuous security validation. These steps are
essential to push developers toward integrating security into the core design
of LLMs, as our findings show that current models still fail to mitigate
long-standing threats.

</details>


### [7] [Provable Watermarking for Data Poisoning Attacks](https://arxiv.org/abs/2510.09210)
*Yifan Zhu,Lijia Yu,Xiao-Shan Gao*

Main category: cs.CR

TL;DR: 本文提出在数据投毒攻击中使用水印方案，通过后投毒水印和投毒并发水印两种方法，确保水印可检测性和投毒效用，解决无害投毒可能引发的误解问题。


<details>
  <summary>Details</summary>
Motivation: 近年来，无害甚至有益的数据投毒攻击（如验证数据集所有权或保护私有数据）与传统上被视为安全威胁的数据投毒之间可能产生误解和冲突，需要让无害投毒生成者声明所有权以便用户识别潜在投毒。

Method: 提出了两种可证明且实用的数据投毒水印方法：后投毒水印和投毒并发水印，分析了水印长度与投毒效用之间的关系。

Result: 理论分析表明，当水印长度满足特定条件时，水印投毒数据集能够同时保证水印可检测性和投毒效用，验证了水印在数据投毒攻击中的实用性。

Conclusion: 水印方案是解决无害数据投毒可能引发误解问题的有效方法，提出的两种水印方法在理论和实验上都证明了其可行性。

Abstract: In recent years, data poisoning attacks have been increasingly designed to
appear harmless and even beneficial, often with the intention of verifying
dataset ownership or safeguarding private data from unauthorized use. However,
these developments have the potential to cause misunderstandings and conflicts,
as data poisoning has traditionally been regarded as a security threat to
machine learning systems. To address this issue, it is imperative for harmless
poisoning generators to claim ownership of their generated datasets, enabling
users to identify potential poisoning to prevent misuse. In this paper, we
propose the deployment of watermarking schemes as a solution to this challenge.
We introduce two provable and practical watermarking approaches for data
poisoning: {\em post-poisoning watermarking} and {\em poisoning-concurrent
watermarking}. Our analyses demonstrate that when the watermarking length is
$\Theta(\sqrt{d}/\epsilon_w)$ for post-poisoning watermarking, and falls within
the range of $\Theta(1/\epsilon_w^2)$ to $O(\sqrt{d}/\epsilon_p)$ for
poisoning-concurrent watermarking, the watermarked poisoning dataset provably
ensures both watermarking detectability and poisoning utility, certifying the
practicality of watermarking under data poisoning attacks. We validate our
theoretical findings through experiments on several attacks, models, and
datasets.

</details>


### [8] [GREAT: Generalizable Backdoor Attacks in RLHF via Emotion-Aware Trigger Synthesis](https://arxiv.org/abs/2510.09260)
*Subrat Kishore Dutta,Yuelin Xu,Piyush Pant,Xiao Zhang*

Main category: cs.CR

TL;DR: 提出了GREAT框架，通过情感感知触发合成在RLHF中构建可泛化的后门攻击，针对具有暴力请求和愤怒触发器的用户子群，显著提高了攻击成功率。


<details>
  <summary>Details</summary>
Motivation: 现有RLHF后门攻击方法依赖静态、稀有令牌触发器，在现实场景中效果有限，需要开发更通用的后门攻击框架。

Method: GREAT框架包含在潜在嵌入空间运行的触发器识别流水线，利用主成分分析和聚类技术识别代表性触发器，并使用Erinyes数据集（5000+愤怒触发器）进行训练。

Result: 在基准RLHF数据集上的实验表明，GREAT在攻击成功率上显著优于基线方法，特别是在未见触发器场景中，同时保持良性输入的响应质量。

Conclusion: GREAT框架成功实现了在RLHF中构建可泛化后门攻击，展示了情感感知触发器在提升攻击效果方面的重要性。

Abstract: Recent work has shown that RLHF is highly susceptible to backdoor attacks,
poisoning schemes that inject malicious triggers in preference data. However,
existing methods often rely on static, rare-token-based triggers, limiting
their effectiveness in realistic scenarios. In this paper, we develop GREAT, a
novel framework for crafting generalizable backdoors in RLHF through
emotion-aware trigger synthesis. Specifically, GREAT targets harmful response
generation for a vulnerable user subgroup characterized by both semantically
violent requests and emotionally angry triggers. At the core of GREAT is a
trigger identification pipeline that operates in the latent embedding space,
leveraging principal component analysis and clustering techniques to identify
the most representative triggers. To enable this, we present Erinyes, a
high-quality dataset of over $5000$ angry triggers curated from GPT-4.1 using a
principled, hierarchical, and diversity-promoting approach. Experiments on
benchmark RLHF datasets demonstrate that GREAT significantly outperforms
baseline methods in attack success rates, especially for unseen trigger
scenarios, while largely preserving the response quality on benign inputs.

</details>


### [9] [SynthID-Image: Image watermarking at internet scale](https://arxiv.org/abs/2510.09263)
*Sven Gowal,Rudy Bunel,Florian Stimberg,David Stutz,Guillermo Ortiz-Jimenez,Christina Kouridi,Mel Vecerik,Jamie Hayes,Sylvestre-Alvise Rebuffi,Paul Bernard,Chris Gamble,Miklós Z. Horváth,Fabian Kaczmarczyck,Alex Kaskasoli,Aleksandar Petrov,Ilia Shumailov,Meghana Thotakuri,Olivia Wiles,Jessica Yung,Zahra Ahmed,Victor Martin,Simon Rosen,Christopher Savčak,Armin Senoner,Nidhi Vyas,Pushmeet Kohli*

Main category: cs.CR

TL;DR: SynthID-Image是一个基于深度学习的AI生成图像隐形水印系统，已在Google服务中为超过100亿图像和视频帧添加水印，并在视觉质量和鲁棒性方面达到最先进水平。


<details>
  <summary>Details</summary>
Motivation: 解决在互联网规模部署AI生成图像水印系统的技术需求、威胁模型和实际挑战，确保有效性、保真度、鲁棒性和安全性。

Method: 使用深度学习技术开发隐形水印系统，包括SynthID-Image和外部模型变体SynthID-O，后者通过合作伙伴提供。

Result: 系统已成功部署并水印超过100亿图像和视频帧，验证服务已向可信测试者开放。SynthID-O在基准测试中在视觉质量和对抗常见图像扰动的鲁棒性方面表现优异。

Conclusion: 这项工作为基于深度学习的媒体溯源系统的大规模部署提供了全面文档，虽然专注于视觉媒体，但其关于部署、约束和威胁建模的结论可推广到其他模态（包括音频）。

Abstract: We introduce SynthID-Image, a deep learning-based system for invisibly
watermarking AI-generated imagery. This paper documents the technical
desiderata, threat models, and practical challenges of deploying such a system
at internet scale, addressing key requirements of effectiveness, fidelity,
robustness, and security. SynthID-Image has been used to watermark over ten
billion images and video frames across Google's services and its corresponding
verification service is available to trusted testers. For completeness, we
present an experimental evaluation of an external model variant, SynthID-O,
which is available through partnerships. We benchmark SynthID-O against other
post-hoc watermarking methods from the literature, demonstrating
state-of-the-art performance in both visual quality and robustness to common
image perturbations. While this work centers on visual media, the conclusions
on deployment, constraints, and threat modeling generalize to other modalities,
including audio. This paper provides a comprehensive documentation for the
large-scale deployment of deep learning-based media provenance systems.

</details>


### [10] [Goal-oriented Backdoor Attack against Vision-Language-Action Models via Physical Objects](https://arxiv.org/abs/2510.09269)
*Zirun Zhou,Zhengyang Xiao,Haochuan Xu,Jing Sun,Di Wang,Jingfeng Zhang*

Main category: cs.CR

TL;DR: 本文提出目标导向后门攻击(GoBA)，通过在训练数据中注入物理触发器，使视觉-语言-动作模型在遇到物理触发器时执行预定义的目标动作，而正常输入下表现正常。


<details>
  <summary>Details</summary>
Motivation: 现有VLA模型依赖未筛选的训练数据存在安全隐患，现有后门攻击大多假设白盒访问且导致任务失败而非执行特定动作。本文揭示更实际的威胁：通过注入物理对象作为触发器来操控VLA模型。

Method: 基于LIBERO基准构建BadLIBERO数据集，包含多样化的物理触发器和目标导向的后门动作。提出三级评估方法将受害VLA的动作分为无事可做、尝试执行和成功执行三个状态。

Result: 实验显示，当物理触发器存在时，GoBA能在97%的输入中成功实现后门目标，同时在干净输入上造成零性能下降。动作轨迹和触发器颜色显著影响攻击性能，而触发器大小影响很小。

Conclusion: GoBA展示了通过物理触发器操控VLA模型的实际可行性，揭示了VLA模型在安全方面的脆弱性，为未来防御机制的发展提供了重要参考。

Abstract: Recent advances in vision-language-action (VLA) models have greatly improved
embodied AI, enabling robots to follow natural language instructions and
perform diverse tasks. However, their reliance on uncurated training datasets
raises serious security concerns. Existing backdoor attacks on VLAs mostly
assume white-box access and result in task failures instead of enforcing
specific actions. In this work, we reveal a more practical threat: attackers
can manipulate VLAs by simply injecting physical objects as triggers into the
training dataset. We propose goal-oriented backdoor attacks (GoBA), where the
VLA behaves normally in the absence of physical triggers but executes
predefined and goal-oriented actions in the presence of physical triggers.
Specifically, based on a popular VLA benchmark LIBERO, we introduce BadLIBERO
that incorporates diverse physical triggers and goal-oriented backdoor actions.
In addition, we propose a three-level evaluation that categorizes the victim
VLA's actions under GoBA into three states: nothing to do, try to do, and
success to do. Experiments show that GoBA enables the victim VLA to
successfully achieve the backdoor goal in 97 percentage of inputs when the
physical trigger is present, while causing zero performance degradation on
clean inputs. Finally, by investigating factors related to GoBA, we find that
the action trajectory and trigger color significantly influence attack
performance, while trigger size has surprisingly little effect. The code and
BadLIBERO dataset are accessible via the project page at
https://goba-attack.github.io/.

</details>


### [11] [Assessing the Impact of Post-Quantum Digital Signature Algorithms on Blockchains](https://arxiv.org/abs/2510.09271)
*Alison Gonçalves Schemitt,Henrique Fan da Silva,Roben Castagna Lunardi,Diego Kreutz,Rodrigo Brandão Mansilha,Avelino Francisco Zorzo*

Main category: cs.CR

TL;DR: 该论文提出了一种在区块链环境中评估后量子密码(PQC)和传统加密算法性能的方法论，发现PQC算法在安全级别1时仅引入轻微性能开销，在某些情况下甚至在高安全级别显著优于ECDSA。


<details>
  <summary>Details</summary>
Motivation: 量子计算的兴起威胁传统加密算法安全，需要开发后量子密码。区块链系统依赖的ECDSA等算法易受量子攻击，但PQC在区块链环境中的计算开销尚未充分研究。

Method: 提出区块链环境下的密码算法基准测试方法，测量签名生成和验证时间，并在不同计算环境中进行大规模模拟评估。

Result: PQC算法在安全级别1时性能开销很小，某些情况下在高安全级别显著优于ECDSA。例如ML-DSA在ARM笔记本上安全级别5的验证时间为0.14ms，而ECDSA为0.88ms。

Conclusion: PQC算法在区块链环境中具有可行性，提供了开源实现以确保可复现性并促进进一步研究。

Abstract: The advent of quantum computing threatens the security of traditional
encryption algorithms, motivating the development of post-quantum cryptography
(PQC). In 2024, the National Institute of Standards and Technology (NIST)
standardized several PQC algorithms, marking an important milestone in the
transition toward quantum-resistant security. Blockchain systems fundamentally
rely on cryptographic primitives to guarantee data integrity and transaction
authenticity. However, widely used algorithms such as ECDSA, employed in
Bitcoin, Ethereum, and other networks, are vulnerable to quantum attacks.
Although adopting PQC is essential for long-term security, its computational
overhead in blockchain environments remains largely unexplored. In this work,
we propose a methodology for benchmarking both PQC and traditional
cryptographic algorithms in blockchain contexts. We measure signature
generation and verification times across diverse computational environments and
simulate their impact at scale. Our evaluation focuses on PQC digital signature
schemes (ML-DSA, Dilithium, Falcon, Mayo, SLH-DSA, SPHINCS+, and Cross) across
security levels 1 to 5, comparing them to ECDSA, the current standard in
Bitcoin and Ethereum. Our results indicate that PQC algorithms introduce only
minor performance overhead at security level 1, while in some scenarios they
significantly outperform ECDSA at higher security levels. For instance, ML-DSA
achieves a verification time of 0.14 ms on an ARM-based laptop at level 5,
compared to 0.88 ms for ECDSA. We also provide an open-source implementation to
ensure reproducibility and encourage further research.

</details>


### [12] [Modern iOS Security Features -- A Deep Dive into SPTM, TXM, and Exclaves](https://arxiv.org/abs/2510.09272)
*Moritz Steffin,Jiska Classen*

Main category: cs.CR

TL;DR: 本文对苹果XNU内核的新安全机制SPTM进行了首次科学分析，揭示了其通过内存重分类和映射规则集引入信任域，将不同功能隔离，并为Exclaves安全特性奠定基础。


<details>
  <summary>Details</summary>
Motivation: 苹果XNU内核虽然标榜为混合内核，但实际上以单体方式运行，存在安全隐患。苹果近年来向更隔离的微内核架构发展，但SPTM及相关安全机制缺乏科学讨论，系统理解有限。

Method: 对SPTM及其相关安全机制进行全面分析，研究内存重分类、映射规则集、信任域隔离，以及Exclaves通信机制如xnuproxy和Tightbeam IPC框架。

Result: SPTM作为内存重分类的唯一权威，通过基于帧重分类和内存映射规则集的域，在系统中引入信任域，有效隔离不同功能。关键敏感组件被移出XNU直接访问范围。

Conclusion: 架构改变提升了系统安全性，内核泄露不再构成最高信任级别的直接威胁，为系统提供了额外的安全保障。

Abstract: The XNU kernel is the basis of Apple's operating systems. Although labeled as
a hybrid kernel, it is found to generally operate in a monolithic manner by
defining a single privileged trust zone in which all system functionality
resides. This has security implications, as a kernel compromise has immediate
and significant effects on the entire system. Over the past few years, Apple
has taken steps towards a more compartmentalized kernel architecture and a more
microkernel-like design. To date, there has been no scientific discussion of
SPTM and related security mechanisms. Therefore, the understanding of the
system and the underlying security mechanisms is minimal. In this paper, we
provide a comprehensive analysis of new security mechanisms and their
interplay, and create the first conclusive writeup considering all current
mitigations. SPTM acts as the sole authority regarding memory retyping. Our
analysis reveals that, through SPTM domains based on frame retyping and memory
mapping rule sets, SPTM introduces domains of trust into the system,
effectively gapping different functionalities from one another. Gapped
functionality includes the TXM, responsible for code signing and entitlement
verification. We further demonstrate how this introduction lays the groundwork
for the most recent security feature of Exclaves, and conduct an in-depth
analysis of its communication mechanisms. We discover multifold ways of
communication, most notably xnuproxy as a secure world request handler, and the
Tightbeam IPC framework. The architecture changes are found to increase system
security, with key and sensitive components being moved out of XNU's direct
reach. This also provides additional security guarantees in the event of a
kernel compromise, which is no longer an immediate threat at the highest trust
level.

</details>


### [13] [Clustering Deposit and Withdrawal Activity in Tornado Cash: A Cross-Chain Analysis](https://arxiv.org/abs/2510.09433)
*Raffaele Cristodaro,Benjamin Kramer,Claudio J. Tessone*

Main category: cs.CR

TL;DR: 本文对Tornado Cash在以太坊、BNB智能链和Polygon上的活动进行了首次跨链实证研究，通过三种聚类启发式方法（地址重用、交易链接和FIFO时间匹配）成功将大量提款与存款重新关联，暴露了实际匿名性的严重缺陷。


<details>
  <summary>Details</summary>
Motivation: Tornado Cash作为去中心化混币器，理论上使用密码学技术切断存款者和提款者之间的链上痕迹，但在实际使用中，用户行为和操作特性可能削弱其匿名性。研究者希望验证实际使用中的匿名保护效果。

Method: 引入三种聚类启发式方法：(i)地址重用启发式，(ii)交易链接启发式，(iii)新颖的先进先出(FIFO)时间匹配规则。这些方法共同用于重新连接存款和提款。

Result: 仅通过地址重用和交易链接启发式就能追踪5.1-12.6%的提款到其原始存款。加入FIFO时间匹配启发式后，关联率进一步提高15-22个百分点。统计测试确认这些FIFO匹配极不可能是偶然发生的。三个链上的可比泄漏表明这是链无关的用户不当行为。

Conclusion: 研究结果表明密码学保证在日常使用中可能迅速失效，强调了需要规范的用户行为和隐私感知协议设计。总计有超过23亿美元的Tornado Cash提款被关联到可识别的存款，暴露了实际匿名性的重大缺陷。

Abstract: Tornado Cash is a decentralised mixer that uses cryptographic techniques to
sever the on-chain trail between depositors and withdrawers. In practice,
however, its anonymity can be undermined by user behaviour and operational
quirks. We conduct the first cross-chain empirical study of Tornado Cash
activity on Ethereum, BNB Smart Chain, and Polygon, introducing three
clustering heuristics-(i) address-reuse, (ii) transactional-linkage, and (iii)
a novel first-in-first-out (FIFO) temporal-matching rule. Together, these
heuristics reconnect deposits to withdrawals and deanonymise a substantial
share of recipients. Our analysis shows that 5.1 - 12.6% of withdrawals can
already be traced to their originating deposits through address reuse and
transactional linkage heuristics. Adding our novel First-In-First-Out (FIFO)
temporal-matching heuristic lifts the linkage rate by a further 15 - 22
percentage points. Statistical tests confirm that these FIFO matches are highly
unlikely to occur by chance. Comparable leakage across Ethereum, BNB Smart
Chain, and Polygon indicates chain-agnostic user misbehaviour, rather than
chain-specific protocol flaws. These results expose how quickly cryptographic
guarantees can unravel in everyday use, underscoring the need for both
disciplined user behaviour and privacy-aware protocol design. In total, our
heuristics link over $2.3 billion in Tornado Cash withdrawals to identifiable
deposits, exposing significant cracks in practical anonymity.

</details>


### [14] [The Impact of Sanctions on decentralised Privacy Tools: A Case Study of Tornado Cash](https://arxiv.org/abs/2510.09443)
*Raffaele Cristodaro,Benjamin Kramer,Claudio J. Tessone*

Main category: cs.CR

TL;DR: 本文研究了美国对Tornado Cash的制裁影响，发现制裁导致交易量、用户多样性和协议使用率显著下降，即使制裁解除后恢复也有限。


<details>
  <summary>Details</summary>
Motivation: 研究监管干预对去中心化协议的影响，特别是美国财政部对Tornado Cash的制裁案例。

Method: 分析以太坊、BNB智能链和Polygon三个主要区块链的交易数据，追踪制裁前后的协议活动变化。

Result: 制裁后平台活动急剧下降，交易量、用户多样性和整体使用率显著减少，制裁解除后恢复有限。

Conclusion: 监管干预能够影响去中心化协议，但在去中心化环境中完全执行此类措施面临挑战。

Abstract: This paper investigates the impact of sanctions on Tornado Cash, a smart
contract protocol designed to enhance transaction privacy. Following the U.S.
Department of the Treasury's sanctions against Tornado Cash in August 2022,
platform activity declined sharply. We document a significant and sustained
reduction in transaction volume, user diversity, and overall protocol
utilization after the sanctions were imposed. Our analysis draws on transaction
data from three major blockchains: Ethereum, BNB Smart Chain, and Polygon. We
further examine developments following the partial lifting and eventual removal
of sanctions by the U.S. Office of Foreign Assets Control (OFAC) in March 2025.
Although activity partially recovered, the rebound remained limited. The
Tornado Cash case illustrates how regulatory interventions can affect
decentralized protocols, while also highlighting the challenges of fully
enforcing such measures in decentralized environments.

</details>


### [15] [The Data Enclave Advantage: A New Paradigm for Least-Privileged Data Access in a Zero-Trust World](https://arxiv.org/abs/2510.09494)
*Nico Bistolfi,Andreea Georgescu,Dave Hodson*

Main category: cs.CR

TL;DR: 本文提出基于按需数据飞地的创新架构，通过临时数据合约实现数据层面的零常驻权限和即时访问原则，取代静态权限，大幅减少攻击面。


<details>
  <summary>Details</summary>
Motivation: 随着云基础设施支持动态分布式工作流，特别是AI驱动流程的加速，常驻权限模型已成为关键漏洞。当前安全工具主要关注网络和API安全，但细粒度数据访问安全仍是挑战。

Method: 引入基于按需数据飞地的架构，用临时数据合约取代静态权限，实现数据层面的零常驻权限和即时访问原则，为单个记录而非数据集提供精确访问和实时监控。

Result: 该解决方案大幅减少攻击面，防止权限蔓延，简化审计，为企业向更安全、弹性的数据环境过渡提供关键路径。

Conclusion: 在数据层面移除常驻权限与在网络层面同样关键，特别是对于大规模处理有价值数据的公司。提出的架构直接解决了这一安全缺口。

Abstract: As cloud infrastructure evolves to support dynamic and distributed workflows,
accelerated now by AI-driven processes, the outdated model of standing
permissions has become a critical vulnerability. Based on the Cloud Security
Alliance (CSA) Top Threats to Cloud Computing Deep Dive 2025 Report, our
analysis details how standing permissions cause catastrophic cloud breaches.
While current security tools are addressing network and API security, the
challenge of securing granular data access remains. Removing standing
permissions at the data level is as critical as it is at the network level,
especially for companies handling valuable data at scale.
  In this white paper, we introduce an innovative architecture based on
on-demand data enclaves to address this gap directly. Our approach enables Zero
Standing Privilege (ZSP) and Just-in-Time (JIT) principles at the data level.
We replace static permissions with temporary data contracts that enforce
proactive protection. This means separation is built around the data requested
on-demand, providing precise access and real time monitoring for individual
records instead of datasets. This solution drastically reduces the attack
surface, prevents privilege creep, and simplifies auditing, offering a vital
path for enterprises to transition to a more secure and resilient data
environment.

</details>
