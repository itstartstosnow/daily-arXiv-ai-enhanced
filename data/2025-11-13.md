<div id=toc></div>

# Table of Contents

- [cs.CR](#cs.CR) [Total: 17]


<div id='cs.CR'></div>

# cs.CR [[Back]](#toc)

### [1] [QOC DAO -- Stepwise Development Towards an AI Driven Decentralized Autonomous Organization](https://arxiv.org/abs/2511.08641)
*Marc Jansen,Christophe Verdot*

Main category: cs.CR

TL;DR: 提出将QOC模型与AI代理结合的结构化方法，改善DAO决策过程，从人工评估逐步过渡到全自动AI驱动治理框架。


<details>
  <summary>Details</summary>
Motivation: 提升DAO决策的透明度、公平性和可解释性，为Web3生态系统建立可扩展且可信赖的治理基础。

Method: 采用问题-选项-标准(QOC)模型分解决策为基于权重的标准评估，结合大语言模型(LLM)和利益相关者对齐的AI代理支持或自动化评估，并加入统计安全保障机制。

Result: 构建了一个分步治理框架，能够增强DAO投票过程的透明度、公平性和可解释性。

Conclusion: 该框架为DAO提供了从人工主导到全自动AI驱动治理的演进路径，建立了可扩展且可信赖的Web3治理基础。

Abstract: This paper introduces a structured approach to improving decision making in Decentralized Autonomous Organizations (DAO) through the integration of the Question-Option-Criteria (QOC) model and AI agents. We outline a stepwise governance framework that evolves from human led evaluations to fully autonomous, AI-driven processes. By decomposing decisions into weighted, criterion based evaluations, the QOC model enhances transparency, fairness, and explainability in DAO voting. We demonstrate how large language models (LLMs) and stakeholder aligned AI agents can support or automate evaluations, while statistical safeguards help detect manipulation. The proposed framework lays the foundation for scalable and trustworthy governance in the Web3 ecosystem.

</details>


### [2] [Binary and Multiclass Cyberattack Classification on GeNIS Dataset](https://arxiv.org/abs/2511.08660)
*Miguel Silva,Daniela Pinto,João Vitorino,Eva Maia,Isabel Praça,Ivone Amorim,Maria João Viamonte*

Main category: cs.CR

TL;DR: 该研究验证了GeNIS数据集在AI驱动的网络入侵检测系统中的可靠性，通过特征选择方法减少维度，使用决策树集成和深度神经网络进行分类，结果表明GeNIS支持智能入侵检测。


<details>
  <summary>Details</summary>
Motivation: 由于机器学习和深度学习模型严重依赖训练数据质量，缺乏多样化和最新数据集阻碍了它们在检测未见网络流量中恶意活动时的泛化能力。

Method: 结合五种特征选择方法（信息增益、卡方检验、递归特征消除、平均绝对偏差、分散比）识别GeNIS数据集最相关特征并降维，训练三种决策树集成和两种深度神经网络进行二元和多类分类。

Result: 所有模型都达到了高准确率和F1分数，机器学习集成在保持更高效率的同时实现了略好的泛化性能。

Conclusion: GeNIS数据集支持基于时间和数量行为特征的智能入侵检测和网络攻击分类，可作为未来基准测试的基础。

Abstract: The integration of Artificial Intelligence (AI) in Network Intrusion Detection Systems (NIDS) is a promising approach to tackle the increasing sophistication of cyberattacks. However, since Machine Learning (ML) and Deep Learning (DL) models rely heavily on the quality of their training data, the lack of diverse and up-to-date datasets hinders their generalization capability to detect malicious activity in previously unseen network traffic. This study presents an experimental validation of the reliability of the GeNIS dataset for AI-based NIDS, to serve as a baseline for future benchmarks. Five feature selection methods, Information Gain, Chi-Squared Test, Recursive Feature Elimination, Mean Absolute Deviation, and Dispersion Ratio, were combined to identify the most relevant features of GeNIS and reduce its dimensionality, enabling a more computationally efficient detection. Three decision tree ensembles and two deep neural networks were trained for both binary and multiclass classification tasks. All models reached high accuracy and F1-scores, and the ML ensembles achieved slightly better generalization while remaining more efficient than DL models. Overall, the obtained results indicate that the GeNIS dataset supports intelligent intrusion detection and cyberattack classification with time-based and quantity-based behavioral features.

</details>


### [3] [Automated Hardware Trojan Insertion in Industrial-Scale Designs](https://arxiv.org/abs/2511.08703)
*Yaroslav Popryho,Debjit Pal,Inna Partin-Vaisband*

Main category: cs.CR

TL;DR: 提出了一种自动化、可扩展的方法，在工业规模网表中生成硬件木马类模式，用于压力测试检测工具而不改变用户可见功能。


<details>
  <summary>Details</summary>
Motivation: 工业SoC包含数百万个网和连接边，对硬件木马检测器进行实证评估既必要又困难。公共基准测试规模较小且手工制作，而发布真正恶意的RTL存在伦理和操作风险。

Method: 流水线包括：(i)将大型门级设计解析为连接图，(ii)使用SCOAP可测试性指标探索稀有区域，(iii)应用参数化、功能保持的图变换来合成模仿隐蔽硬件木马统计足迹的触发器-有效载荷对。

Result: 在本工作生成的基准测试上评估时，代表性的最先进图学习模型无法检测到木马。

Conclusion: 该框架通过提供可重复的挑战实例，缩小了学术电路与现代SoC之间的评估差距，推进安全研究而无需分享逐步攻击指令。

Abstract: Industrial Systems-on-Chips (SoCs) often comprise hundreds of thousands to millions of nets and millions to tens of millions of connectivity edges, making empirical evaluation of hardware-Trojan (HT) detectors on realistic designs both necessary and difficult. Public benchmarks remain significantly smaller and hand-crafted, while releasing truly malicious RTL raises ethical and operational risks. This work presents an automated and scalable methodology for generating HT-like patterns in industry-scale netlists whose purpose is to stress-test detection tools without altering user-visible functionality. The pipeline (i) parses large gate-level designs into connectivity graphs, (ii) explores rare regions using SCOAP testability metrics, and (iii) applies parameterized, function-preserving graph transformations to synthesize trigger-payload pairs that mimic the statistical footprint of stealthy HTs. When evaluated on the benchmarks generated in this work, representative state-of-the-art graph-learning models fail to detect Trojans. The framework closes the evaluation gap between academic circuits and modern SoCs by providing reproducible challenge instances that advance security research without sharing step-by-step attack instructions.

</details>


### [4] [Channel-Robust RFF for Low-Latency 5G Device Identification in SIMO Scenarios](https://arxiv.org/abs/2511.08902)
*Yingjie Sun,Guyue Li,Hongfu Chou,Aiqun Hu*

Main category: cs.CR

TL;DR: 提出了一种新的射频指纹提取技术，利用多天线信号解决多径问题而不增加延迟，通过计算多天线共时信道频率响应的对数线性增量比来保持区分性特征。


<details>
  <summary>Details</summary>
Motivation: 5G超低延迟对身份识别提出严格要求，现有加密方案增加计算开销导致延迟增加，而射频指纹在物理层识别设备可显著降低延迟，但多径信道会降低其准确性。

Method: 使用多接收天线的信号，计算共时信道频率响应的对数线性增量比(LLDR)，将频带分割为子带并在每个子带内单独计算LLDR，避免多时间采样。

Result: 在20路径信道和20dB信噪比下，对30个用户设备达到96.13%的识别准确率，空中接口延迟为0.491ms，满足URLLC延迟要求。

Conclusion: 该方法能有效解决多径信道对射频指纹的影响，在不增加延迟的情况下实现高精度设备识别，满足5G超可靠低延迟通信的要求。

Abstract: Ultra-low latency, the hallmark of fifth-generation mobile communications (5G), imposes exacting timing demands on identification as well. Current cryptographic solutions introduce additional computational overhead, which results in heightened identification delays. Radio frequency fingerprint (RFF) identifies devices at the physical layer, blocking impersonation attacks while significantly reducing latency. Unfortunately, multipath channels compromise RFF accuracy, and existing channel-resilient methods demand feedback or processing across multiple time points, incurring extra signaling latency. To address this problem, the paper introduces a new RFF extraction technique that employs signals from multiple receiving antennas to address multipath issues without adding latency. Unlike single-domain methods, the Log-Linear Delta Ratio (LLDR) of co-temporal channel frequency responses (CFRs) from multiple antennas is employed to preserve discriminative RFF features, eliminating multi-time sampling and reducing acquisition time. To overcome the challenge of the reliance on minimal channel variation, the frequency band is segmented into sub-bands, and the LLDR is computed within each sub-band individually. Simulation results indicate that the proposed scheme attains a 96.13% identification accuracy for 30 user equipments (UEs) within a 20-path channel under a signal-to-noise ratio (SNR) of 20 dB. Furthermore, we evaluate the theoretical latency using the Roofline model, resulting in the air interface latency of 0.491 ms, which satisfies ultra-reliable and low-latency communications (URLLC) latency requirements.

</details>


### [5] [iSeal: Encrypted Fingerprinting for Reliable LLM Ownership Verification](https://arxiv.org/abs/2511.08905)
*Zixun Xiong,Gaoyi Wu,Qingyang Yu,Mingyu Derek Ma,Lingfeng Yao,Miao Pan,Xiaojiang Du,Hao Wang*

Main category: cs.CR

TL;DR: iSeal是一种针对大语言模型的指纹认证方法，能够在模型窃贼完全控制LLM推理过程的情况下进行可靠的所有权验证。


<details>
  <summary>Details</summary>
Motivation: 现有LLM指纹认证方法在验证过程中容易受到攻击，当模型窃贼完全控制LLM推理过程时，现有方法无法有效验证所有权。

Method: iSeal通过将独特特征注入到模型和外部模块中，结合纠错机制和基于相似性的验证策略，抵抗验证时攻击。

Result: 在12个LLM上对抗10多种攻击时，iSeal实现了100%的指纹成功率，而基线方法在去学习和响应操纵攻击下失效。

Conclusion: iSeal是首个能够在端到端控制场景下可靠验证LLM知识产权的指纹认证方法，具有理论分析和实证结果支持。

Abstract: Given the high cost of large language model (LLM) training from scratch, safeguarding LLM intellectual property (IP) has become increasingly crucial. As the standard paradigm for IP ownership verification, LLM fingerprinting thus plays a vital role in addressing this challenge. Existing LLM fingerprinting methods verify ownership by extracting or injecting model-specific features. However, they overlook potential attacks during the verification process, leaving them ineffective when the model thief fully controls the LLM's inference process. In such settings, attackers may share prompt-response pairs to enable fingerprint unlearning or manipulate outputs to evade exact-match verification. We propose iSeal, the first fingerprinting method designed for reliable verification when the model thief controls the suspected LLM in an end-to-end manner. It injects unique features into both the model and an external module, reinforced by an error-correction mechanism and a similarity-based verification strategy. These components are resistant to verification-time attacks, including collusion-based fingerprint unlearning and response manipulation, backed by both theoretical analysis and empirical results. iSeal achieves 100 percent Fingerprint Success Rate (FSR) on 12 LLMs against more than 10 attacks, while baselines fail under unlearning and response manipulations.

</details>


### [6] [DeepTracer: Tracing Stolen Model via Deep Coupled Watermarks](https://arxiv.org/abs/2511.08985)
*Yunfei Yang,Xiaojun Chen,Yuexin Xuan,Zhendong Zhao,Xin Zhao,He Li*

Main category: cs.CR

TL;DR: 提出了一个名为DeepTracer的鲁棒水印框架，通过新颖的水印样本构建方法和同类耦合损失约束，在模型窃取攻击中保持水印有效性。


<details>
  <summary>Details</summary>
Motivation: 现有模型水印技术在面对模型窃取攻击时容易被移除，导致模型所有者难以有效验证被盗模型的版权。

Method: DeepTracer框架采用新型水印样本构建方法和同类耦合损失约束，使水印任务与主要任务高度耦合，同时提出水印样本过滤机制来增强水印可靠性。

Result: 在多个数据集和模型上的广泛实验表明，该方法在防御各种模型窃取攻击和水印攻击方面超越了现有方法，达到了最先进的有效性和鲁棒性。

Conclusion: DeepTracer框架能够有效解决现有水印方法在模型窃取场景下的失效问题，为模型版权保护提供了更可靠的解决方案。

Abstract: Model watermarking techniques can embed watermark information into the protected model for ownership declaration by constructing specific input-output pairs. However, existing watermarks are easily removed when facing model stealing attacks, and make it difficult for model owners to effectively verify the copyright of stolen models. In this paper, we analyze the root cause of the failure of current watermarking methods under model stealing scenarios and then explore potential solutions. Specifically, we introduce a robust watermarking framework, DeepTracer, which leverages a novel watermark samples construction method and a same-class coupling loss constraint. DeepTracer can incur a high-coupling model between watermark task and primary task that makes adversaries inevitably learn the hidden watermark task when stealing the primary task functionality. Furthermore, we propose an effective watermark samples filtering mechanism that elaborately select watermark key samples used in model ownership verification to enhance the reliability of watermarks. Extensive experiments across multiple datasets and models demonstrate that our method surpasses existing approaches in defending against various model stealing attacks, as well as watermark attacks, and achieves new state-of-the-art effectiveness and robustness.

</details>


### [7] [MedHE: Communication-Efficient Privacy-Preserving Federated Learning with Adaptive Gradient Sparsification for Healthcare](https://arxiv.org/abs/2511.09043)
*Farjana Yesmin*

Main category: cs.CR

TL;DR: MedHE是一个结合自适应梯度稀疏化和CKKS同态加密的医疗联邦学习框架，在保护隐私的同时显著减少通信开销。


<details>
  <summary>Details</summary>
Motivation: 医疗联邦学习需要在资源受限的医疗机构间实现强隐私保护，同时保持计算效率。

Method: 采用自适应梯度稀疏化与CKKS同态加密相结合的方法，引入带误差补偿的动态阈值机制进行top-k梯度选择。

Result: 实现了97.5%的通信减少，准确率达到89.5%±0.8%，与标准联邦学习性能相当(p=0.32)，每轮训练通信量从1277MB降至32MB。

Conclusion: MedHE框架具有实际部署可行性，符合HIPAA合规要求，可扩展到100+机构，为医疗数据协作学习提供了有效的隐私保护解决方案。

Abstract: Healthcare federated learning requires strong privacy guarantees while maintaining computational efficiency across resource-constrained medical institutions. This paper presents MedHE, a novel framework combining adaptive gradient sparsification with CKKS homomorphic encryption to enable privacy-preserving collaborative learning on sensitive medical data. Our approach introduces a dynamic threshold mechanism with error compensation for top-k gradient selection, achieving 97.5 percent communication reduction while preserving model utility. We provide formal security analysis under Ring Learning with Errors assumptions and demonstrate differential privacy guarantees with epsilon less than or equal to 1.0. Statistical testing across 5 independent trials shows MedHE achieves 89.5 percent plus or minus 0.8 percent accuracy, maintaining comparable performance to standard federated learning (p=0.32) while reducing communication from 1277 MB to 32 MB per training round. Comprehensive evaluation demonstrates practical feasibility for real-world medical deployments with HIPAA compliance and scalability to 100 plus institutions.

</details>


### [8] [Attack-Centric by Design: A Program-Structure Taxonomy of Smart Contract Vulnerabilities](https://arxiv.org/abs/2511.09051)
*Parsa Hedayatnia,Tina Tavakkoli,Hadi Amini,Mohammad Allahbakhsh,Haleh Amintoosi*

Main category: cs.CR

TL;DR: 本文提出了一个基于攻击的、程序结构导向的漏洞分类法，将Solidity漏洞统一为8个根本原因家族，为漏洞检测、审计和安全教育提供了一致的词汇表和实用检查清单。


<details>
  <summary>Details</summary>
Motivation: 智能合约将高价值资产和复杂逻辑集中在小型不可变程序中，即使微小错误也可能导致重大损失。现有分类法和工具仍然零散，围绕重入等表面症状而非结构原因组织。

Method: 引入基于攻击的、程序结构导向的分类法，将Solidity漏洞统一为控制流、外部调用、状态完整性、算术安全、环境依赖、访问控制、输入验证和跨域协议假设等8个根本原因家族，并通过Solidity示例、利用机制和缓解措施进行说明。

Result: 该分类法为静态、动态和基于学习的工具提供了可观察的检测信号，并通过交叉映射传统数据集揭示了标签漂移和覆盖差距。

Conclusion: 该分类法提供了一致的词汇表和实用检查清单，使研究人员和从业者能够进行更可解释的检测、可重现的审计和结构化的安全教育。

Abstract: Smart contracts concentrate high value assets and complex logic in small, immutable programs, where even minor bugs can cause major losses. Existing taxonomies and tools remain fragmented, organized around symptoms such as reentrancy rather than structural causes. This paper introduces an attack-centric, program-structure taxonomy that unifies Solidity vulnerabilities into eight root-cause families covering control flow, external calls, state integrity, arithmetic safety, environmental dependencies, access control, input validation, and cross-domain protocol assumptions. Each family is illustrated through concise Solidity examples, exploit mechanics, and mitigations, and linked to the detection signals observable by static, dynamic, and learning-based tools. We further cross-map legacy datasets (SmartBugs, SolidiFI) to this taxonomy to reveal label drift and coverage gaps. The taxonomy provides a consistent vocabulary and practical checklist that enable more interpretable detection, reproducible audits, and structured security education for both researchers and practitioners.

</details>


### [9] [Toward an Intrusion Detection System for a Virtualization Framework in Edge Computing](https://arxiv.org/abs/2511.09068)
*Everton de Matos,Hazaa Alameri,Willian Tessaro Lunardi,Martin Andreoni,Eduardo Viegas*

Main category: cs.CR

TL;DR: 在边缘计算环境中部署轻量级深度异常检测系统LDPI，通过虚拟化框架提供安全隔离，并与传统基于签名的IDS进行比较评估。


<details>
  <summary>Details</summary>
Motivation: 边缘计算将计算推向数据源，但也扩大了资源受限设备的攻击面，需要轻量级的安全解决方案。

Method: 采用深度学习方法的LDPI系统，在虚拟化框架中作为隔离服务部署，并与Suricata和Snort等基于签名的IDS在相同工作负载下进行比较。

Result: LDPI在训练中达到AUC 0.999（5折均值），在保守操作点具有高F1分数，在边缘节点上部署时检测网络洪水攻击。

Conclusion: LDPI在边缘环境中表现出色，为资源受限设备提供了有效的轻量级安全防护方案。

Abstract: Edge computing pushes computation closer to data sources, but it also expands the attack surface on resource-constrained devices. This work explores the deployment of the Lightweight Deep Anomaly Detection for Network Traffic (LDPI) integrated as an isolated service within a virtualization framework that provides security by separation. LDPI, adopting a Deep Learning approach, achieved strong training performance, reaching AUC 0.999 (5-fold mean) across the evaluated packet-window settings (n, l), with high F1 at conservative operating points. We deploy LDPI on a laptop-class edge node and evaluate its overhead and performance in two scenarios: (i) comparing it with representative signature-based IDSes (Suricata and Snort) deployed on the same framework under identical workloads, and (ii) while detecting network flooding attacks.

</details>


### [10] [Improving Sustainability of Adversarial Examples in Class-Incremental Learning](https://arxiv.org/abs/2511.09088)
*Taifeng Liu,Xinjing Liu,Liangqiu Dong,Yang Liu,Yilong Yang,Zhuo Ma*

Main category: cs.CR

TL;DR: 提出了SAE方法，通过语义校正和过滤增强模块，增强对抗样本在类增量学习更新后的可持续性，解决现有对抗样本因领域漂移而失效的问题。


<details>
  <summary>Details</summary>
Motivation: 现有的对抗样本通常针对静态模型设计，但在类增量学习场景下，模型需要不断更新，导致对抗样本因显著的领域漂移而失效。

Method: SAE包含两个核心模块：1) 语义校正模块，利用视觉语言模型生成通用语义，并结合CIL模型校正AE语义优化方向；2) 过滤增强模块，识别潜在空间中具有目标类语义的非目标样本并进行增强。

Result: 在类别数量增加9倍的情况下，SAE比基线方法平均提升了31.28%的性能。

Conclusion: SAE通过增强对抗样本语义的鲁棒性，有效解决了类增量学习更新后对抗样本失效的问题，具有显著的实际应用价值。

Abstract: Current adversarial examples (AEs) are typically designed for static models. However, with the wide application of Class-Incremental Learning (CIL), models are no longer static and need to be updated with new data distributed and labeled differently from the old ones. As a result, existing AEs often fail after CIL updates due to significant domain drift. In this paper, we propose SAE to enhance the sustainability of AEs against CIL. The core idea of SAE is to enhance the robustness of AE semantics against domain drift by making them more similar to the target class while distinguishing them from all other classes. Achieving this is challenging, as relying solely on the initial CIL model to optimize AE semantics often leads to overfitting. To resolve the problem, we propose a Semantic Correction Module. This module encourages the AE semantics to be generalized, based on a visual-language model capable of producing universal semantics. Additionally, it incorporates the CIL model to correct the optimization direction of the AE semantics, guiding them closer to the target class. To further reduce fluctuations in AE semantics, we propose a Filtering-and-Augmentation Module, which first identifies non-target examples with target-class semantics in the latent space and then augments them to foster more stable semantics. Comprehensive experiments demonstrate that SAE outperforms baselines by an average of 31.28% when updated with a 9-fold increase in the number of classes.

</details>


### [11] [Differentially Private Rankings via Outranking Methods and Performance Data Aggregation](https://arxiv.org/abs/2511.09120)
*Luis Del Vasto-Terrientes*

Main category: cs.CR

TL;DR: 将多准则决策方法与差分隐私技术结合，在保护用户隐私的同时实现有效的排名决策


<details>
  <summary>Details</summary>
Motivation: 多准则决策方法在推荐系统等数据驱动领域应用广泛，但处理敏感个人数据时缺乏有效的隐私保护机制

Method: 提出集成方法，结合MCDM排序方法和差分隐私技术，通过预处理步骤聚合用户评估为性能矩阵

Result: 真实排名与匿名化排名之间存在强到极强的统计相关性，同时确保强大的隐私参数保证

Conclusion: 该方法成功实现了在保护个人贡献隐私的同时，保持多准则决策排名的有效性

Abstract: Multiple-Criteria Decision Making (MCDM) is a sub-discipline of Operations Research that helps decision-makers in choosing, ranking, or sorting alternatives based on conflicting criteria. Over time, its application has been expanded into dynamic and data-driven domains, such as recommender systems. In these contexts, the availability and handling of personal and sensitive data can play a critical role in the decision-making process. Despite this increased reliance on sensitive data, the integration of privacy mechanisms with MCDM methods is underdeveloped. This paper introduces an integrated approach that combines MCDM outranking methods with Differential Privacy (DP), safeguarding individual contributions' privacy in ranking problems. This approach relies on a pre-processing step to aggregate multiple user evaluations into a comprehensive performance matrix. The evaluation results show a strong to very strong statistical correlation between the true rankings and their anonymized counterparts, ensuring robust privacy parameter guarantees.

</details>


### [12] [One Signature, Multiple Payments: Demystifying and Detecting Signature Replay Vulnerabilities in Smart Contracts](https://arxiv.org/abs/2511.09134)
*Zexu Wang,Jiachi Chen,Zewei Lin,Wenqing Chen,Kaiwen Ning,Jianxing Yu,Yuming Feng,Yu Zhang,Weizhe Zhang,Zibin Zheng*

Main category: cs.CR

TL;DR: 本文首次对智能合约中的签名重放漏洞(SRV)进行了实证研究，提出了LASiR检测工具，结合LLM语义理解和符号执行技术，在15,383个合约中发现了广泛存在的SRV问题，涉及476万美元资产。


<details>
  <summary>Details</summary>
Motivation: 智能合约中数字签名验证缺乏使用条件检查会导致重复验证，增加权限滥用风险，威胁合约资产安全。目前缺乏对签名重放漏洞的系统研究。

Method: 设计了LASiR检测工具，利用大语言模型的语义理解能力辅助静态污点分析，识别签名重用行为，并通过符号执行进行路径可达性验证。

Result: 从37家安全公司的1,419份审计报告中识别出108个SRV案例，分类为5种类型。在15,383个涉及签名验证的合约中发现SRV广泛存在，以太坊上19.63%使用签名的合约存在SRV，涉及476万美元活跃资产。LASiR检测F1分数达87.90%。

Conclusion: 签名重放漏洞在智能合约中普遍存在且危害严重，LASiR结合LLM语义分析能有效检测此类漏洞，显著提升检测性能。

Abstract: Smart contracts have significantly advanced blockchain technology, and digital signatures are crucial for reliable verification of contract authority. Through signature verification, smart contracts can ensure that signers possess the required permissions, thus enhancing security and scalability. However, lacking checks on signature usage conditions can lead to repeated verifications, increasing the risk of permission abuse and threatening contract assets. We define this issue as the Signature Replay Vulnerability (SRV). In this paper, we conducted the first empirical study to investigate the causes and characteristics of the SRVs. From 1,419 audit reports across 37 blockchain security companies, we identified 108 with detailed SRV descriptions and classified five types of SRVs. To detect these vulnerabilities automatically, we designed LASiR, which utilizes the general semantic understanding ability of Large Language Models (LLMs) to assist in the static taint analysis of the signature state and identify the signature reuse behavior. It also employs path reachability verification via symbolic execution to ensure effective and reliable detection. To evaluate the performance of LASiR, we conducted large-scale experiments on 15,383 contracts involving signature verification, selected from the initial dataset of 918,964 contracts across four blockchains: Ethereum, Binance Smart Chain, Polygon, and Arbitrum. The results indicate that SRVs are widespread, with affected contracts holding $4.76 million in active assets. Among these, 19.63% of contracts that use signatures on Ethereum contain SRVs. Furthermore, manual verification demonstrates that LASiR achieves an F1-score of 87.90% for detection. Ablation studies and comparative experiments reveal that the semantic information provided by LLMs aids static taint analysis, significantly enhancing LASiR's detection performance.

</details>


### [13] [Unveiling Hidden Threats: Using Fractal Triggers to Boost Stealthiness of Distributed Backdoor Attacks in Federated Learning](https://arxiv.org/abs/2511.09252)
*Jian Wang,Hong Shen,Chan-Tong Lam*

Main category: cs.CR

TL;DR: 提出FTDBA方法，利用分形自相似性增强子触发器特征强度，显著减少所需中毒数据量，同时通过动态角度扰动机制平衡效率和隐蔽性。


<details>
  <summary>Details</summary>
Motivation: 传统分布式后门攻击需要更多中毒数据来维持攻击强度，增加了暴露风险。需要一种既能保持攻击效果又能减少中毒数据量的方法。

Method: 利用分形自相似性增强子触发器特征强度，引入动态角度扰动机制在训练阶段自适应调整扰动强度以平衡效率和隐蔽性。

Result: FTDBA仅需传统DBA方法62.4%的中毒数据量就能达到92.3%的攻击成功率，同时检测率降低22.8%，KL散度降低41.2%。

Conclusion: 该研究提出了一种低暴露、高效率的联邦后门攻击范式，并扩展了分形特征在对抗样本生成中的应用。

Abstract: Traditional distributed backdoor attacks (DBA) in federated learning improve stealthiness by decomposing global triggers into sub-triggers, which however requires more poisoned data to maintian the attck strength and hence increases the exposure risk. To overcome this defect, This paper proposes a novel method, namely Fractal-Triggerred Distributed Backdoor Attack (FTDBA), which leverages the self-similarity of fractals to enhance the feature strength of sub-triggers and hence significantly reduce the required poisoning volume for the same attack strength. To address the detectability of fractal structures in the frequency and gradient domains, we introduce a dynamic angular perturbation mechanism that adaptively adjusts perturbation intensity across the training phases to balance efficiency and stealthiness. Experiments show that FTDBA achieves a 92.3\% attack success rate with only 62.4\% of the poisoning volume required by traditional DBA methods, while reducing the detection rate by 22.8\% and KL divergence by 41.2\%. This study presents a low-exposure, high-efficiency paradigm for federated backdoor attacks and expands the application of fractal features in adversarial sample generation.

</details>


### [14] [SecTracer: A Framework for Uncovering the Root Causes of Network Intrusions via Security Provenance](https://arxiv.org/abs/2511.09266)
*Seunghyeon Lee,Hyunmin Seo,Hwanjo Heo,Anduo Wang,Seungwon Shin,Jinwoo Kim*

Main category: cs.CR

TL;DR: SecTracer是一个企业网络安全溯源框架，通过软件定义网络(SDN)收集数据，构建溯源图重建攻击历史，并利用概率模型进行主动攻击预测，在真实APT模拟中证明有效且仅引入不到1%的网络吞吐开销。


<details>
  <summary>Details</summary>
Motivation: 现代企业网络系统异构复杂，管理员难以追踪和分析APT等多向量攻击，需要建立网络级安全溯源来识别安全事件的根本原因。

Method: 提出网络级安全溯源概念，通过SDN实现企业网络全面高效的数据收集，构建溯源图重建攻击历史，并使用概率模型进行主动攻击预测。

Result: 在真实APT模拟中验证了SecTracer的有效性，能够增强威胁缓解能力，同时仅引入不到1%的网络吞吐开销和可忽略的延迟影响。

Conclusion: SecTracer框架通过系统化的网络级安全溯源分析，为企业网络提供了准确识别安全事件根本原因和主动预测攻击的能力，具有实际部署价值。

Abstract: Modern enterprise networks comprise diverse and heterogeneous systems that support a wide range of services, making it challenging for administrators to track and analyze sophisticated attacks such as advanced persistent threats (APTs), which often exploit multiple vectors. To address this challenge, we introduce the concept of network-level security provenance, which enables the systematic establishment of causal relationships across hosts at the network level, facilitating the accurate identification of the root causes of security incidents. Building on this concept, we present SecTracer as a framework for a network-wide provenance analysis. SecTracer offers three main contributions: (i) comprehensive and efficient forensic data collection in enterprise networks via software-defined networking (SDN), (ii) reconstruction of attack histories through provenance graphs to provide a clear and interpretable view of intrusions, and (iii) proactive attack prediction using probabilistic models. We evaluated the effectiveness and efficiency of SecTracer through a real-world APT simulation, demonstrating its capability to enhance threat mitigation while introducing less than 1% network throughput overhead and negligible latency impact.

</details>


### [15] [Quantum Meet-in-the-Middle Attacks on Key-Length Extension Constructions](https://arxiv.org/abs/2511.09351)
*Min Liang,Ruihao Gao,Jiali Wu*

Main category: cs.CR

TL;DR: 本文提出了针对两种密钥长度扩展构造的量子中间相遇攻击：对2kTE的两种Q2模型攻击（基于量子爪查找和Grover算法），以及对3XCE的Q1模型攻击。还扩展了量子筛中间攻击框架，可应用于更广泛的构造。


<details>
  <summary>Details</summary>
Motivation: 研究密钥长度扩展技术的量子安全性，评估在量子计算模型下这些构造是否仍能提供预期的安全增强。

Method: 使用量子中间相遇攻击技术，包括量子爪查找算法、Grover算法和量子筛中间攻击框架，针对2kTE和3XCE构造进行分析。

Result: 对2kTE的攻击在Q2模型下达到O(2^{2κ/3})和O(2^{κ/2})的时间复杂度；对3XCE的攻击在Q1模型下达到O(2^{(κ+n)/2})的时间复杂度，相比经典攻击实现二次加速。

Conclusion: 2kTE在Q2模型下无法有效增强安全性，而量子中间相遇和筛中间攻击技术为量子密码分析提供了有效工具。

Abstract: Key-length extension (KLE) techniques provide a general approach to enhancing the security of block ciphers by using longer keys. There are mainly two classes of KLE techniques, cascade encryption and XOR-cascade encryption. This paper presents several quantum meet-in-the-middle (MITM) attacks against two specific KLE constructions.
  For the two-key triple encryption (2kTE), we propose two quantum MITM attacks under the Q2 model. The first attack, leveraging the quantum claw-finding (QCF) algorithm, achieves a time complexity of $O(2^{2κ/3})$ with $O(2^{2κ/3})$ quantum random access memory (QRAM). The second attack, based on Grover's algorithm, achieves a time complexity of $O(2^{κ/2})$ with $O(2^κ)$ QRAM. The latter complexity is nearly identical to Grover-based brute-force attack on the underlying block cipher, indicating that 2kTE does not enhance security under the Q2 model when sufficient QRAM resources are available.
  For the 3XOR-cascade encryption (3XCE), we propose a quantum MITM attack applicable to the Q1 model. This attack requires no QRAM and has a time complexity of $O(2^{(κ+n)/2})$ ($κ$ and $n$ are the key length and block length of the underlying block cipher, respectively.), achieving a quadratic speedup over classical MITM attack.
  Furthermore, we extend the quantum MITM attack to quantum sieve-in-the-middle (SITM) attack, which is applicable for more constructions. We present a general quantum SITM framework for the construction $ELE=E^2\circ L\circ E^1$ and provide specific attack schemes for three different forms of the middle layer $L$. The quantum SITM attack technique can be further applied to a broader range of quantum cryptanalysis scenarios.

</details>


### [16] [Enhancing Password Security Through a High-Accuracy Scoring Framework Using Random Forests](https://arxiv.org/abs/2511.09492)
*Muhammed El Mustaqeem Mazelan,Noor Hazlina Abdul,Nouar AlDahoul*

Main category: cs.CR

TL;DR: 本文实现并评估了一个基于机器学习的密码强度评分系统，通过比较随机森林、支持向量机、CNN和逻辑回归四种模型，使用超过66万个真实密码数据集，提出了新颖的混合特征工程方法。


<details>
  <summary>Details</summary>
Motivation: 传统密码强度检测器依赖静态规则（如字符类型要求）容易失效，容易被常见密码模式绕过，给用户带来虚假的安全感。需要更智能的方法来准确评估密码安全性。

Method: 采用四种机器学习模型（RF、SVM、CNN、逻辑回归），提出混合特征工程方法，包括leet语归一化的香农熵、键盘行走和序列模式检测、字符级TF-IDF n-gram特征来识别泄露密码数据集中常用的子字符串。

Result: 随机森林模型表现最佳，在测试集上达到99.12%的准确率。模型的可解释性允许进行特征重要性分析，为开发提供具体可操作反馈的安全工具提供了清晰路径。

Conclusion: 该研究在预测准确性和实际可用性之间架起了桥梁，开发出了一个高性能的评分系统，不仅减少了基于密码的漏洞，还使用户能够做出更明智的安全决策。

Abstract: Password security plays a crucial role in cybersecurity, yet traditional password strength meters, which rely on static rules like character-type requirements, often fail. Such methods are easily bypassed by common password patterns (e.g., 'P@ssw0rd1!'), giving users a false sense of security. To address this, we implement and evaluate a password strength scoring system by comparing four machine learning models: Random Forest (RF), Support Vector Machine (SVM), a Convolutional Neural Network (CNN), and Logistic Regression with a dataset of over 660,000 real-world passwords. Our primary contribution is a novel hybrid feature engineering approach that captures nuanced vulnerabilities missed by standard metrics. We introduce features like leetspeak-normalized Shannon entropy to assess true randomness, pattern detection for keyboard walks and sequences, and character-level TF-IDF n-grams to identify frequently reused substrings from breached password datasets. our RF model achieved superior performance, achieving 99.12% accuracy on a held-out test set. Crucially, the interpretability of the Random Forest model allows for feature importance analysis, providing a clear pathway to developing security tools that offer specific, actionable feedback to users. This study bridges the gap between predictive accuracy and practical usability, resulting in a high-performance scoring system that not only reduces password-based vulnerabilities but also empowers users to make more informed security decisions.

</details>


### [17] [Intelligent Carrier Allocation: A Cross-Modal Reasoning Framework for Adaptive Multimodal Steganography](https://arxiv.org/abs/2511.09552)
*Abhirup Das,Pranav Dudani,Shruti Sharma,Ravi Kumar C.*

Main category: cs.CR

TL;DR: 提出了一种基于跨模态推理引擎的智能载体分配框架，用于多模态隐写术，通过动态评估不同载体媒体的可靠性来优化秘密数据的分配。


<details>
  <summary>Details</summary>
Motivation: 传统隐写方法固定且仅适用于单一载体类型，无法适应多种媒体类型，导致系统安全性不足和隐蔽性降低。

Method: 使用跨模态推理引擎分析图像、音频和文本等多种载体，通过熵、信号复杂度和词汇丰富度等指标计算可靠性分数，智能分配秘密比特流。

Result: 该自适应分配策略使系统更难被检测，相比静态多模态技术具有更高的安全性和数据保护能力。

Conclusion: 基于推理的方法能够构建更强大和智能的秘密通信系统，在隐写术领域具有显著优势。

Abstract: In today's digital world, which has many different types of media, steganography, the art of secret communication, has a lot of problems to deal with. Traditional methods are often fixed and only work with one type of carrier media. This means they don't work well with all the different types of media that are out there. This system doesn't send data to "weak" or easily detectable carriers because it can't adapt. This makes the system less safe and less secret in general. This paper proposes a novel Intelligent Carrier Allocation framework founded on a Cross-Modal Reasoning (CMR) Engine. This engine looks at a wide range of carriers, such as images, audio, and text, to see if they are good for steganography. It uses important measurements like entropy, signal complexity, and vocabulary richness to come up with a single reliability score for each modality. The framework uses these scores to fairly and intelligently share the secret bitstream, giving more data to carriers that are thought to be stronger and more complex. This adaptive allocation strategy makes the system as hard to find as possible and as strong as possible against steganalysis. We demonstrate that this reasoning-based approach is more secure and superior in data protection compared to static, non-adaptive multimodal techniques. This makes it possible to build stronger and smarter secret communication systems.

</details>
