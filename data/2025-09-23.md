<div id=toc></div>

# Table of Contents

- [cs.CR](#cs.CR) [Total: 45]


<div id='cs.CR'></div>

# cs.CR [[Back]](#toc)

### [1] [Reconnecting Citizens to Politics via Blockchain - Starting the Debate](https://arxiv.org/abs/2509.16274)
*Uwe Serdült*

Main category: cs.CR

TL;DR: 本文探讨了利用区块链技术解决选举竞选资金问题的可能性，提出创建专门用于政治竞选和广告费用的加密货币。


<details>
  <summary>Details</summary>
Motivation: 选举是自由民主国家的重要支柱，但全球范围内的证据表明，以自由公平的方式举行选举并非易事。竞选资金问题频繁引发丑闻，现有方法难以有效解决这一难题。

Method: 通过引入区块链技术，设计一种专门用于支付政治竞选和广告成本的加密货币，为竞选资金管理提供新的技术解决方案。

Result: 虽然目前仍存在许多未解决的问题，但在区块链技术将持续存在的假设下，这一想法值得进一步探索。

Conclusion: 区块链技术可能为解决选举竞选资金问题提供前进的一步，尽管实施过程中面临挑战，但这一创新思路具有研究价值。

Abstract: Elections are not the only but arguably one of the most important pillars for
the proper functioning of liberal democracies. Recent evidence across the globe
shows that it is not straightforward to conduct them in a free and fair manner.
One constant concern is the role of money in politics, more specifically,
election campaign financing. Frequent scandals are proof of the difficulties
encountered with current approaches to tackle the issue. Suggestions on how to
overcome the problem exist but seem difficult to implement. With the help of
blockchain technology we might be able to make a step forward. A separate
crypto currency specifically designed to pay for costs of political campaigning
and advertising could be introduced. Admittedly, at this stage, there are many
open questions. However, under the assumption that blockchain technology is
here to stay, it is an idea that deserves further exploration.

</details>


### [2] [SecureFixAgent: A Hybrid LLM Agent for Automated Python Static Vulnerability Repair](https://arxiv.org/abs/2509.16275)
*Jugal Gajjar,Kamalasankari Subramaniakuppusamy,Relsy Puthal,Kaustik Ranaware*

Main category: cs.CR

TL;DR: SecureFixAgent是一个混合修复框架，将静态分析工具Bandit与轻量级本地LLMs结合，通过迭代的检测-修复-验证循环来减少误报并提高修复准确性。


<details>
  <summary>Details</summary>
Motivation: 现代软件开发面临大型代码库安全挑战，静态分析工具误报率高且缺乏修复能力，而LLMs能建议修复但容易产生幻觉变化且缺乏自我验证。

Method: 集成Bandit与轻量级本地LLMs（<8B参数），采用参数高效的LoRA微调，在多样化Python项目数据集上进行训练，通过迭代的检测-修复-验证循环工作。

Result: 相比静态分析减少误报10.8%，修复准确率提高13.51%，相比预训练LLMs误报降低5.46%，通常在3次迭代内收敛。开发者对解释质量评分4.5/5。

Conclusion: SecureFixAgent通过结合可验证的安全改进和透明解释，在资源高效的本地框架中推进了可信赖的自动化漏洞修复。

Abstract: Modern software development pipelines face growing challenges in securing
large codebases with extensive dependencies. Static analysis tools like Bandit
are effective at vulnerability detection but suffer from high false positives
and lack repair capabilities. Large Language Models (LLMs), in contrast, can
suggest fixes but often hallucinate changes and lack self-validation. We
present SecureFixAgent, a hybrid repair framework integrating Bandit with
lightweight local LLMs (<8B parameters) in an iterative detect-repair-validate
loop. To improve precision, we apply parameter-efficient LoRA-based fine-tuning
on a diverse, curated dataset spanning multiple Python project domains,
mitigating dataset bias and reducing unnecessary edits. SecureFixAgent uses
Bandit for detection, the LLM for candidate fixes with explanations, and Bandit
re-validation for verification, all executed locally to preserve privacy and
reduce cloud reliance. Experiments show SecureFixAgent reduces false positives
by 10.8% over static analysis, improves fix accuracy by 13.51%, and lowers
false positives by 5.46% compared to pre-trained LLMs, typically converging
within three iterations. Beyond metrics, developer studies rate explanation
quality 4.5/5, highlighting its value for human trust and adoption. By
combining verifiable security improvements with transparent rationale in a
resource-efficient local framework, SecureFixAgent advances trustworthy,
automated vulnerability remediation for modern pipelines.

</details>


### [3] [Decoding TRON: A Comprehensive Framework for Large-Scale Blockchain Data Extraction and Exploration](https://arxiv.org/abs/2509.16292)
*Qian'ang Mao,Jiaxin Wang,Zhiqi Feng,Yi Zhang,Jiaqi Yan*

Main category: cs.CR

TL;DR: 本文提出了一个针对TRON区块链的全面数据提取和探索框架，通过高性能ETL系统提取原始链上数据并建立研究数据集，深入分析TRON生态系统的特征和模式。


<details>
  <summary>Details</summary>
Motivation: 尽管TRON在稳定币支付和结算等领域很受欢迎，但对其链上数据的分析研究却非常稀缺，需要填补这一空白。

Method: 开发创新的高性能ETL系统，高效提取TRON的原始链上数据（包括区块、交易、智能合约和收据），建立研究数据集。

Result: 分析揭示了TRON的区块生成、交易趋势、交易所主导地位、资源委托市场、智能合约使用模式以及USDT稳定币的核心作用，强调了赌博应用和与USDT相关的潜在非法活动的突出地位。

Conclusion: 这项工作增强了区块链数据管理能力，加深了对快速发展的TRON生态系统的理解，并为未来研究提供了机会，包括委托服务分析、赌博场景、稳定币活动和非法交易检测等。

Abstract: Cryptocurrencies and Web3 applications based on blockchain technology have
flourished in the blockchain research field. Unlike Bitcoin and Ethereum, due
to its unique architectural designs in consensus mechanisms, resource
management, and throughput, TRON has developed a more distinctive ecosystem and
application scenarios centered around stablecoins. Although it is popular in
areas like stablecoin payments and settlement, research on analyzing on-chain
data from the TRON blockchain is remarkably scarce. To fill this gap, this
paper proposes a comprehensive data extraction and exploration framework for
the TRON blockchain. An innovative high-performance ETL system aims to
efficiently extract raw on-chain data from TRON, including blocks,
transactions, smart contracts, and receipts, establishing a research dataset.
An in-depth analysis of the extracted dataset reveals insights into TRON's
block generation, transaction trends, the dominance of exchanges, the resource
delegation market, smart contract usage patterns, and the central role of the
USDT stablecoin. The prominence of gambling applications and potential illicit
activities related to USDT is emphasized. The paper discusses opportunities for
future research leveraging this dataset, including analysis of delegate
services, gambling scenarios, stablecoin activities, and illicit transaction
detection. These contributions enhance blockchain data management capabilities
and understanding of the rapidly evolving TRON ecosystem.

</details>


### [4] [To Unpack or Not to Unpack: Living with Packers to Enable Dynamic Analysis of Android Apps](https://arxiv.org/abs/2509.16340)
*Mohammad Hossein Asghari,Lianying Zhao*

Main category: cs.CR

TL;DR: 本文提出了Purifire，一种基于eBPF的规避引擎，用于绕过Android打包器的反分析技术，在不进行解包的情况下对打包应用进行动态分析。


<details>
  <summary>Details</summary>
Motivation: Android打包器通过反分析技术阻碍安全分析，现有解包器对新兴商业打包器无效且解包后应用无法运行，需要新的解决方案。

Method: 基于eBPF内核特性构建Purifire引擎，提供对用户空间应用的观察性和隐身性，强制执行定义的规避规则。

Result: Purifire能够成功绕过打包器的反分析检查，显著提升检测效果（如检测到更多设备指纹等）。

Conclusion: Purifire为打包Android应用的动态分析提供了有效解决方案，显著改善了现有研究受打包器影响的问题。

Abstract: Android apps have become a valuable target for app modifiers and imitators
due to its popularity and being trusted with highly sensitive data. Packers, on
the other hand, protect apps from tampering with various anti-analysis
techniques embedded in the app. Meanwhile, packers also conceal certain
behavior potentially against the interest of the users, aside from being abused
by malware for stealth. Security practitioners typically try to capture
undesired behavior at runtime with hooking (e.g., Frida) or debugging
techniques, which are heavily affected by packers. Unpackers have been the
community's continuous effort to address this, but due to the emerging
commercial packers, our study shows that none of the unpackers remain
effective, and they are unfit for this purpose as unpacked apps can no longer
run. We first perform a large-scale prevalence analysis of Android packers with
a real-world dataset of 12,341 apps, the first of its kind, to find out what
percentage of Android apps are actually packed and to what extent dynamic
analysis is hindered. We then propose Purifire, an evasion engine to bypass
packers' anti-analysis techniques and enable dynamic analysis on packed apps
without unpacking them. Purifire is based on eBPF, a low-level kernel feature,
which provides observability and invisibility to userspace apps to enforce
defined evasion rules while staying low-profile. Our evaluation shows that
Purifire is able to bypass packers' anti-analysis checks and more importantly,
for previous research works suffering from packers, we observe a significant
improvement (e.g., a much higher number of detected items such as device
fingerprints).

</details>


### [5] [Secure Confidential Business Information When Sharing Machine Learning Models](https://arxiv.org/abs/2509.16352)
*Yunfan Yang,Jiarong Xu,Hongzhe Zhang,Xiao Fang*

Main category: cs.CR

TL;DR: 提出一种新的防御方法，通过模拟现实世界中对手的响应性行为，构建攻击-防御军备竞赛框架，有效抵御模型共享中的机密属性推理攻击。


<details>
  <summary>Details</summary>
Motivation: 模型共享具有重要商业价值，但机密属性推理攻击会泄露模型提供者的私有训练数据机密属性。现有防御方法假设攻击是非自适应的，忽略了现实对手的响应性特征。

Method: 提出响应性CPI攻击模拟真实对手行为，构建攻击-防御军备竞赛框架迭代增强目标模型和攻击模型，并引入近似策略解决计算瓶颈。

Result: 通过多种现实模型共享场景的实证评估，该方法在防御CPI攻击、保持模型效用和降低计算开销方面优于现有防御方法。

Conclusion: 该方法通过明确考虑现实对手的响应性特征，提供了一种更有效的模型共享安全防御方案。

Abstract: Model-sharing offers significant business value by enabling firms with
well-established Machine Learning (ML) models to monetize and share their
models with others who lack the resources to develop ML models from scratch.
However, concerns over data confidentiality remain a significant barrier to
model-sharing adoption, as Confidential Property Inference (CPI) attacks can
exploit shared ML models to uncover confidential properties of the model
provider's private model training data. Existing defenses often assume that CPI
attacks are non-adaptive to the specific ML model they are targeting. This
assumption overlooks a key characteristic of real-world adversaries: their
responsiveness, i.e., adversaries' ability to dynamically adjust their attack
models based on the information of the target and its defenses. To overcome
this limitation, we propose a novel defense method that explicitly accounts for
the responsive nature of real-world adversaries via two methodological
innovations: a novel Responsive CPI attack and an attack-defense arms race
framework. The former emulates the responsive behaviors of adversaries in the
real world, and the latter iteratively enhances both the target and attack
models, ultimately producing a secure ML model that is robust against
responsive CPI attacks. Furthermore, we propose and integrate a novel
approximate strategy into our defense, which addresses a critical computational
bottleneck of defense methods and improves defense efficiency. Through
extensive empirical evaluations across various realistic model-sharing
scenarios, we demonstrate that our method outperforms existing defenses by more
effectively defending against CPI attacks, preserving ML model utility, and
reducing computational overhead.

</details>


### [6] [LiteRSan: Lightweight Memory Safety Via Rust-specific Program Analysis and Selective Instrumentation](https://arxiv.org/abs/2509.16389)
*Tianrou Xia,Kaiming Huang,Dongyeon Yu,Yuseok Jeon,Jie Zhou,Dinghao Wu,Taegyu Kim*

Main category: cs.CR

TL;DR: LiteRSan是一个针对Rust语言的新型内存安全检测器，通过利用Rust的所有权模型进行静态分析，选择性检测有风险的指针，显著降低了运行时和内存开销。


<details>
  <summary>Details</summary>
Motivation: Rust允许使用unsafe代码绕过编译器安全检查，现有基于ASan的检测工具存在性能开销大且无法检测某些内存安全漏洞的局限性。

Method: 利用Rust独特的ownership模型进行静态分析，识别有风险的指针，然后选择性进行空间或时间内存安全检查。

Result: 相比现有ASan-based检测器，运行时开销降低至18.84%（对比152.05%和183.50%），内存开销仅为0.81%（对比739.27%和861.98%）。

Conclusion: LiteRSan在显著降低性能开销的同时，能够检测到现有技术遗漏的内存安全漏洞。

Abstract: Rust is a memory-safe language, and its strong safety guarantees combined
with high performance have been attracting widespread adoption in systems
programming and security-critical applications. However, Rust permits the use
of unsafe code, which bypasses compiler-enforced safety checks and can
introduce memory vulnerabilities. A widely adopted approach for detecting
memory safety bugs in Rust is Address Sanitizer (ASan). Optimized versions,
such as ERASan and RustSan, have been proposed to selectively apply security
checks in order to reduce performance overhead. However, these tools still
incur significant performance and memory overhead and fail to detect many
classes of memory safety vulnerabilities due to the inherent limitations of
ASan. In this paper, we present LiteRSan, a novel memory safety sanitizer that
addresses the limitations of prior approaches. By leveraging Rust's unique
ownership model, LiteRSan performs Rust-specific static analysis that is aware
of pointer lifetimes to identify risky pointers. It then selectively
instruments risky pointers to enforce only the necessary spatial or temporal
memory safety checks. Consequently, LiteRSan introduces significantly lower
runtime overhead (18.84% versus 152.05% and 183.50%) and negligible memory
overhead (0.81% versus 739.27% and 861.98%) compared with existing ASan-based
sanitizers while being capable of detecting memory safety bugs that prior
techniques miss.

</details>


### [7] [B5GRoam: A Zero Trust Framework for Secure and Efficient On-Chain B5G Roaming](https://arxiv.org/abs/2509.16390)
*Mohamed Abdessamed Rezazi,Mouhamed Amine Bouchiha,Ahmed Mounsf Rafik Bendada,Yacine Ghamri-Doudane*

Main category: cs.CR

TL;DR: B5GRoam是一个基于区块链的5G漫游结算框架，通过零知识证明和Layer 2技术解决现有方案的隐私、信任和可扩展性问题


<details>
  <summary>Details</summary>
Motivation: 5G及未来网络中的漫游结算需要安全、高效、可信的计费对账机制。现有区块链方案存在数据隐私风险、互信假设和可扩展性瓶颈等关键限制

Method: 引入密码学可验证的呼叫详细记录提交协议，集成非交互式零知识证明实现链上验证而不暴露敏感数据，利用Layer 2 zk-Rollups技术满足高吞吐量需求

Result: 实验结果显示达到7200+ tx/s的吞吐量，具有强隐私保护和显著的成本节约

Conclusion: B5GRoam通过消除中间方和增强可验证性，为未来移动网络的去中心化漫游提供了实用且安全的基础

Abstract: Roaming settlement in 5G and beyond networks demands secure, efficient, and
trustworthy mechanisms for billing reconciliation between mobile operators.
While blockchain promises decentralization and auditability, existing solutions
suffer from critical limitations-namely, data privacy risks, assumptions of
mutual trust, and scalability bottlenecks. To address these challenges, we
present B5GRoam, a novel on-chain and zero-trust framework for secure,
privacy-preserving, and scalable roaming settlements. B5GRoam introduces a
cryptographically verifiable call detail record (CDR) submission protocol,
enabling smart contracts to authenticate usage claims without exposing
sensitive data. To preserve privacy, we integrate non-interactive
zero-knowledge proofs (zkSNARKs) that allow on-chain verification of roaming
activity without revealing user or network details. To meet the high-throughput
demands of 5G environments, B5GRoam leverages Layer 2 zk-Rollups, significantly
reducing gas costs while maintaining the security guarantees of Layer 1.
Experimental results demonstrate a throughput of over 7,200 tx/s with strong
privacy and substantial cost savings. By eliminating intermediaries and
enhancing verifiability, B5GRoam offers a practical and secure foundation for
decentralized roaming in future mobile networks.

</details>


### [8] [LenslessMic: Audio Encryption and Authentication via Lensless Computational Imaging](https://arxiv.org/abs/2509.16418)
*Petr Grinberg,Eric Bezzam,Paolo Prandoni,Martin Vetterli*

Main category: cs.CR

TL;DR: LenslessMic是一种基于光学硬件的混合加密方法，使用无镜头相机作为物理安全层，适用于多种音频类型，提供强大的认证和加密能力。


<details>
  <summary>Details</summary>
Motivation: 随着社会对数字数据共享的依赖增加，保护敏感信息变得至关重要。现有的音频加密主要依赖信号处理或软件方法，需要更安全的硬件级解决方案。

Method: 利用无镜头相机作为物理安全层，开发混合光学硬件加密方法，通过低成本Raspberry Pi原型进行验证。

Result: LenslessMic能够实现音频记录的鲁棒认证，加密强度可与256位数字标准相媲美，同时保持高质量信号和最小内容信息损失。

Conclusion: 该方法通过低成本原型验证有效，并开源数据集以促进该领域研究，为音频安全提供了创新的硬件级解决方案。

Abstract: With society's increasing reliance on digital data sharing, the protection of
sensitive information has become critical. Encryption serves as one of the
privacy-preserving methods; however, its realization in the audio domain
predominantly relies on signal processing or software methods embedded into
hardware. In this paper, we introduce LenslessMic, a hybrid optical
hardware-based encryption method that utilizes a lensless camera as a physical
layer of security applicable to multiple types of audio. We show that
LenslessMic enables (1) robust authentication of audio recordings and (2)
encryption strength that can rival the search space of 256-bit digital
standards, while maintaining high-quality signals and minimal loss of content
information. The approach is validated with a low-cost Raspberry Pi prototype
and is open-sourced together with datasets to facilitate research in the area.

</details>


### [9] [End-to-End Co-Simulation Testbed for Cybersecurity Research and Development in Intelligent Transportation Systems](https://arxiv.org/abs/2509.16489)
*Minhaj Uddin Ahmad,Akid Abrar,Sagar Dasgupta,Mizanur Rahman*

Main category: cs.CR

TL;DR: 本章介绍了一个集成协同仿真测试平台，结合CARLA、SUMO和OMNeT++来评估智能交通系统的网络安全漏洞和缓解措施，并通过案例研究展示了其在提升ITS安全性和韧性方面的能力。


<details>
  <summary>Details</summary>
Motivation: 智能交通系统(ITS)的广泛部署扩大了攻击面，暴露出关键基础设施面临网络安全威胁，但全面的漏洞评估和缓解验证在大规模异构系统中成本高昂且耗时。

Method: 开发了一个集成协同仿真测试平台，将CARLA用于3D环境和传感器建模，SUMO用于微观交通仿真和控制，OMNeT++用于V2X通信仿真。

Result: 该测试平台能够进行端到端实验、漏洞识别和缓解基准测试，为开发安全高效的ITS基础设施提供实用见解。

Conclusion: 通过C-V2X主动安全预警系统增强后量子密码学的案例研究，证明了该测试平台在推进安全韧性ITS基础设施方面的重要作用。

Abstract: Intelligent Transportation Systems (ITS) have been widely deployed across
major metropolitan regions worldwide to improve roadway safety, optimize
traffic flow, and reduce environmental impacts. These systems integrate
advanced sensors, communication networks, and data analytics to enable
real-time traffic monitoring, adaptive signal control, and predictive
maintenance. However, such integration significantly broadens the ITS attack
surface, exposing critical infrastructures to cyber threats that jeopardize
safety, data integrity, and operational resilience. Ensuring robust
cybersecurity is therefore essential, yet comprehensive vulnerability
assessments, threat modeling, and mitigation validations are often
cost-prohibitive and time-intensive when applied to large-scale, heterogeneous
transportation systems. Simulation platforms offer a cost-effective and
repeatable means for cybersecurity evaluation, and the simulation platform
should encompass the full range of ITS dimensions - mobility, sensing,
networking, and applications. This chapter discusses an integrated
co-simulation testbed that links CARLA for 3D environment and sensor modeling,
SUMO for microscopic traffic simulation and control, and OMNeT++ for V2X
communication simulation. The co-simulation testbed enables end-to-end
experimentation, vulnerability identification, and mitigation benchmarking,
providing practical insights for developing secure, efficient, and resilient
ITS infrastructures. To illustrate its capabilities, the chapter incorporates a
case study on a C-V2X proactive safety alert system enhanced with post-quantum
cryptography, highlighting the role of the testbed in advancing secure and
resilient ITS infrastructures.

</details>


### [10] [Train to Defend: First Defense Against Cryptanalytic Neural Network Parameter Extraction Attacks](https://arxiv.org/abs/2509.16546)
*Ashley Kurian,Aydin Aysu*

Main category: cs.CR

TL;DR: 本文提出首个针对密码分析参数提取攻击的防御机制，通过消除神经元独特性来防止攻击成功，在推理时实现零面积延迟开销。


<details>
  <summary>Details</summary>
Motivation: 神经网络是重要的知识产权，保护其参数对于保持竞争优势和增强模型安全性至关重要。现有研究表明密码分析攻击已能扩展到更深层模型。

Method: 提出一种新颖的提取感知训练方法，在标准损失函数基础上增加正则化项，最小化层内神经元权重之间的距离。

Result: 防御机制在重新训练相同模型架构时，准确率变化小于1%。在持续提取测试中，受保护网络成功抵御攻击，而未保护网络在14分钟到4小时内被提取。

Conclusion: 该方法有效缓解了参数提取攻击，同时保持模型性能，为神经网络知识产权保护提供了实用解决方案。

Abstract: Neural networks are valuable intellectual property due to the significant
computational cost, expert labor, and proprietary data involved in their
development. Consequently, protecting their parameters is critical not only for
maintaining a competitive advantage but also for enhancing the model's security
and privacy. Prior works have demonstrated the growing capability of
cryptanalytic attacks to scale to deeper models. In this paper, we present the
first defense mechanism against cryptanalytic parameter extraction attacks. Our
key insight is to eliminate the neuron uniqueness necessary for these attacks
to succeed. We achieve this by a novel, extraction-aware training method.
Specifically, we augment the standard loss function with an additional
regularization term that minimizes the distance between neuron weights within a
layer. Therefore, the proposed defense has zero area-delay overhead during
inference. We evaluate the effectiveness of our approach in mitigating
extraction attacks while analyzing the model accuracy across different
architectures and datasets. When re-trained with the same model architecture,
the results show that our defense incurs a marginal accuracy change of less
than 1% with the modified loss function. Moreover, we present a theoretical
framework to quantify the success probability of the attack. When tested
comprehensively with prior attack settings, our defense demonstrated empirical
success for sustained periods of extraction, whereas unprotected networks are
extracted between 14 minutes to 4 hours.

</details>


### [11] [MoPE: A Mixture of Password Experts for Improving Password Guessing](https://arxiv.org/abs/2509.16558)
*Mingjian Duan,Ming Xu,Shenghao Zhang,Jiaheng Zhang,Weili Han*

Main category: cs.CR

TL;DR: MoPE是一个基于密码结构模式的混合专家框架，通过识别密码的结构特征并将其路由到专门的专家模型，显著提高了密码猜测性能。


<details>
  <summary>Details</summary>
Motivation: 现有密码强度评估模型通常将密码统一处理，忽略了密码之间的结构差异，导致训练偏向于频繁出现的密码结构模式。

Method: 提出MoPE框架，包括：(1)基于密码结构模式生成专门专家模型的方法；(2)轻量级门控方法选择适当的专家模型输出可靠猜测。

Result: MoPE在离线和在线猜测场景中显著优于现有最先进基线，破解率分别提升38.80%和9.27%，并实现了基于MoPE的实时密码强度计。

Conclusion: MoPE能够有效利用数据驱动模型的能力进行密码猜测，通过结构感知处理方式改善了密码强度评估的准确性。

Abstract: Textual passwords remain a predominant authentication mechanism in web
security. To evaluate their strength, existing research has proposed several
data-driven models across various scenarios. However, these models generally
treat passwords uniformly, neglecting the structural differences among
passwords. This typically results in biased training that favors frequent
password structural patterns. To mitigate the biased training, we argue that
passwords, as a type of complex short textual data, should be processed in a
structure-aware manner by identifying their structural patterns and routing
them to specialized models accordingly. In this paper, we propose MoPE, a
Mixture of Password Experts framework, specifically designed to leverage the
structural patterns in passwords to improveguessing performance. Motivated by
the observation that passwords with similar structural patterns (e.g.,
fixed-length numeric strings) tend to cluster in high-density regions within
the latent space, our MoPE introduces: (1) a novel structure-based method for
generating specialized expert models; (2) a lightweight gate method to select
appropriate expert models to output reliable guesses, better aligned with the
high computational frequency of password guessing tasks. Our evaluation shows
that MoPE significantly outperforms existing state-of-the-art baselines in both
offline and online guessing scenarios, achieving up to 38.80% and 9.27%
improvement in cracking rate, respectively, showcasing that MoPE can
effectively exploit the capabilities of data-driven models for password
guessing. Additionally, we implement a real-time Password Strength Meter (PSM)
based on offline MoPE, assisting users in choosing stronger passwords more
precisely with millisecond-level response latency.

</details>


### [12] [Towards Cost-Effective ZK-Rollups: Modeling and Optimization of Proving Infrastructure](https://arxiv.org/abs/2509.16581)
*Mohsen Ahmadvand,Pedro Souto*

Main category: cs.CR

TL;DR: 本文提出了一种参数化成本模型，用于优化零知识rollup证明系统的经济可行性，通过Z3 SMT求解器找到成本最优配置，可实现高达70%的成本降低。


<details>
  <summary>Details</summary>
Motivation: 零知识rollup面临吞吐量增长、快速最终性需求、波动gas价格和动态资源需求等挑战，导致经济可行性日益困难。

Method: 基于Halo2证明系统，构建参数化成本模型，将其表述为约束系统，并使用Z3 SMT求解器寻找成本最优配置，同时实现模拟器进行验证。

Result: 提出的方法显示出高达70%的成本降低潜力，能够有效应对rollup扩展带来的经济挑战。

Conclusion: 该参数化成本模型为rollup证明系统提供了经济可行的解决方案，有助于在保持性能的同时显著降低运营成本。

Abstract: Zero-knowledge rollups rely on provers to generate multi-step state
transition proofs under strict finality and availability constraints. These
steps require expensive hardware (e.g., GPUs), and finality is reached only
once all stages complete and results are posted on-chain. As rollups scale,
staying economically viable becomes increasingly difficult due to rising
throughput, fast finality demands, volatile gas prices, and dynamic resource
needs. We base our study on Halo2-based proving systems and identify
transactions per second (TPS), average gas usage, and finality time as key cost
drivers. To address this, we propose a parametric cost model that captures
rollup-specific constraints and ensures provers can keep up with incoming
transaction load. We formulate this model as a constraint system and solve it
using the Z3 SMT solver to find cost-optimal configurations. To validate our
approach, we implement a simulator that detects lag and estimates operational
costs. Our method shows a potential cost reduction of up to 70\%.

</details>


### [13] [Reproducing a Security Risk Assessment Using Computer Aided Design](https://arxiv.org/abs/2509.16593)
*Avi Shaked*

Main category: cs.CR

TL;DR: 本文应用基于模型的安全设计工具重现先前报告的安全评估，比较计算机辅助应用与传统非计算机辅助应用的优势。


<details>
  <summary>Details</summary>
Motivation: 当前安全风险评估主要依赖"纸笔"实现，容易出错且不一致。计算机辅助设计方法可以使安全风险评估更加严谨和可持续。

Method: 使用基于模型的安全设计工具来重现先前报告的安全评估，并进行比较分析。

Result: 展示了计算机辅助设计方法在分析报告和评估系统方面的潜在优势，为从业者和研究人员提供了实用价值。

Conclusion: 计算机辅助设计方法能够提高安全风险评估的严谨性和可持续性，对工业实践和学术研究都具有重要意义。

Abstract: Security risk assessment is essential in establishing the trustworthiness and
reliability of modern systems. While various security risk assessment
approaches exist, prevalent applications are "pen and paper" implementations
that -- even if performed digitally using computers -- remain prone to
authoring mistakes and inconsistencies. Computer-aided design approaches can
transform security risk assessments into more rigorous and sustainable efforts.
This is of value to both industrial practitioners and researchers, who practice
security risk assessments to reflect on systems' designs and to contribute to
the discipline's state-of-the-art. In this article, we report the application
of a model-based security design tool to reproduce a previously reported
security assessment. The main contributions are: 1) an independent attempt to
reproduce a refereed article describing a real security risk assessment of a
system; 2) comparison of a new computer-aided application with a previous
non-computer-aided application, based on a published, real-world case study; 3)
a showcase for the potential advantages -- for both practitioners and
researchers -- of using computer-aided design approaches to analyze reports and
to assess systems.

</details>


### [14] [Delving into Cryptanalytic Extraction of PReLU Neural Networks](https://arxiv.org/abs/2509.16620)
*Yi Chen,Xiaoyang Dong,Ruijie Ma,Yantian Shen,Anyu Wang,Hongbo Yu,Xiaoyun Wang*

Main category: cs.CR

TL;DR: 本文首次实现了PReLU神经网络的密码分析提取攻击，提出了基于原始输出的参数恢复攻击，并扩展到仅能访问top-m概率分数的限制场景。


<details>
  <summary>Details</summary>
Motivation: 过去30多年模型提取研究主要关注ReLU神经网络，而PReLU网络使用更复杂的非线性激活函数，其提取问题尚未得到充分研究。

Method: 提出基于原始输出的参数恢复攻击方法，并扩展到仅能访问top-m概率分数的限制场景，在MNIST数据集上对多种PReLU神经网络进行端到端实验验证。

Result: 首次在实际中成功演示了PReLU神经网络在三种不同攻击场景下的提取，证明了攻击方法的有效性。

Conclusion: 这是PReLU神经网络提取领域的首个实际演示，为更复杂激活函数的神经网络安全性研究开辟了新方向。

Abstract: The machine learning problem of model extraction was first introduced in 1991
and gained prominence as a cryptanalytic challenge starting with Crypto 2020.
For over three decades, research in this field has primarily focused on
ReLU-based neural networks. In this work, we take the first step towards the
cryptanalytic extraction of PReLU neural networks, which employ more complex
nonlinear activation functions than their ReLU counterparts. We propose a raw
output-based parameter recovery attack for PReLU networks and extend it to more
restrictive scenarios where only the top-m probability scores are accessible.
Our attacks are rigorously evaluated through end-to-end experiments on diverse
PReLU neural networks, including models trained on the MNIST dataset. To the
best of our knowledge, this is the first practical demonstration of PReLU
neural network extraction across three distinct attack scenarios.

</details>


### [15] ["Digital Camouflage": The LLVM Challenge in LLM-Based Malware Detection](https://arxiv.org/abs/2509.16671)
*Ekin Böke,Simon Torka*

Main category: cs.CR

TL;DR: 该研究评估了ChatGPT-4o、Gemini Flash 2.5和Claude Sonnet 4三种先进LLM在编译器级混淆技术下的鲁棒性，发现这些模型在面对控制流平坦化、虚假控制流注入等混淆技术时性能显著下降。


<details>
  <summary>Details</summary>
Motivation: 虽然LLM在恶意软件检测方面表现出潜力，但其在对抗性编译器级混淆下的可靠性尚未被充分研究，需要评估这些模型在实际对抗环境中的表现。

Method: 使用LLVM基础设施实现四种编译器级混淆技术（控制流平坦化、虚假控制流注入、指令替换和基本块分割），在Devign数据集的40个C函数上进行结构化评估。

Result: 结果显示这些模型在混淆后代码分类上经常失败，精确率、召回率和F1分数显著下降，表明LLM容易被基于编译器的混淆策略误导。

Conclusion: 研究揭示了LLM在对抗编译器混淆方面的关键局限性，提出了软件水印、编译器感知防御和混淆弹性模型设计等未来研究方向。

Abstract: Large Language Models (LLMs) have emerged as promising tools for malware
detection by analyzing code semantics, identifying vulnerabilities, and
adapting to evolving threats. However, their reliability under adversarial
compiler-level obfuscation is yet to be discovered. In this study, we
empirically evaluate the robustness of three state-of-the-art LLMs: ChatGPT-4o,
Gemini Flash 2.5, and Claude Sonnet 4 against compiler-level obfuscation
techniques implemented via the LLVM infrastructure. These include control flow
flattening, bogus control flow injection, instruction substitution, and split
basic blocks, which are widely used to evade detection while preserving
malicious behavior. We perform a structured evaluation on 40~C functions (20
vulnerable, 20 secure) sourced from the Devign dataset and obfuscated using
LLVM passes. Our results show that these models often fail to correctly
classify obfuscated code, with precision, recall, and F1-score dropping
significantly after transformation. This reveals a critical limitation: LLMs,
despite their language understanding capabilities, can be easily misled by
compiler-based obfuscation strategies. To promote reproducibility, we release
all evaluation scripts, prompts, and obfuscated code samples in a public
repository. We also discuss the implications of these findings for adversarial
threat modeling, and outline future directions such as software watermarking,
compiler-aware defenses, and obfuscation-resilient model design.

</details>


### [16] [Design and Development of an Intelligent LLM-based LDAP Honeypot](https://arxiv.org/abs/2509.16682)
*Javier Jiménez-Román,Florina Almenares-Mendoza,Alfonso Sánchez-Macián*

Main category: cs.CR

TL;DR: 本文提出了一种基于大语言模型（LLM）的LDAP服务器蜜罐设计，旨在解决传统蜜罐在动态场景中的适应性问题，通过AI技术提升网络欺骗工具的灵活性和真实性。


<details>
  <summary>Details</summary>
Motivation: 网络安全威胁日益增长，传统蜜罐存在配置复杂和适应性差的局限性。大语言模型的发展为创建更灵活、易用的欺骗工具提供了新机遇，特别是在模拟LDAP这种关键身份管理协议方面。

Method: 设计并实现基于LLM的蜜罐来模拟LDAP服务器，利用大语言模型的自然语言处理能力与攻击者进行逼真交互，收集攻击者战术信息。

Result: 提出的解决方案能够提供灵活且真实的交互体验，有效欺骗攻击者，有助于早期威胁检测和分析。

Conclusion: LLM-based honeypot技术显著提升了网络防御能力，特别是在保护关键身份管理服务方面具有重要价值，为未来网络安全欺骗工具的发展指明了方向。

Abstract: Cybersecurity threats continue to increase, with a growing number of
previously unknown attacks each year targeting both large corporations and
smaller entities. This scenario demands the implementation of advanced security
measures, not only to mitigate damage but also to anticipate emerging attack
trends. In this context, deception tools have become a key strategy, enabling
the detection, deterrence, and deception of potential attackers while
facilitating the collection of information about their tactics and methods.
Among these tools, honeypots have proven their value, although they have
traditionally been limited by rigidity and configuration complexity, hindering
their adaptability to dynamic scenarios. The rise of artificial intelligence,
and particularly general-purpose Large Language Models (LLMs), is driving the
development of new deception solutions capable of offering greater adaptability
and ease of use. This work proposes the design and implementation of an
LLM-based honeypot to simulate an LDAP server, a critical protocol present in
most organizations due to its central role in identity and access management.
The proposed solution aims to provide a flexible and realistic tool capable of
convincingly interacting with attackers, thereby contributing to early
detection and threat analysis while enhancing the defensive capabilities of
infrastructures against intrusions targeting this service.

</details>


### [17] [Evaluating LLM Generated Detection Rules in Cybersecurity](https://arxiv.org/abs/2509.16749)
*Anna Bertiger,Bobby Filar,Aryan Luthra,Stefano Meschiari,Aiden Mitchell,Sam Scholten,Vivek Sharath*

Main category: cs.CR

TL;DR: 提出了一个开源评估框架和基准指标，用于评估LLM生成的网络安全规则的有效性。


<details>
  <summary>Details</summary>
Motivation: LLM在安全环境中应用日益广泛，但缺乏有效的评估方法，限制了安全从业者对LLM的信任和实用性。

Method: 采用保留集方法，将LLM生成的安全规则与人工生成的规则语料库进行比较，提供三个关键指标来多维度评估LLM安全规则生成器的有效性。

Result: 使用Sublime Security检测团队的规则和其自动化检测工程师(ADE)编写的规则进行了方法验证，并对ADE的能力进行了深入分析。

Conclusion: 该框架为评估LLM生成安全规则提供了现实、多方面的评估方法，有助于提高LLM在安全领域的可信度和实用性。

Abstract: LLMs are increasingly pervasive in the security environment, with limited
measures of their effectiveness, which limits trust and usefulness to security
practitioners. Here, we present an open-source evaluation framework and
benchmark metrics for evaluating LLM-generated cybersecurity rules. The
benchmark employs a holdout set-based methodology to measure the effectiveness
of LLM-generated security rules in comparison to a human-generated corpus of
rules. It provides three key metrics inspired by the way experts evaluate
security rules, offering a realistic, multifaceted evaluation of the
effectiveness of an LLM-based security rule generator. This methodology is
illustrated using rules from Sublime Security's detection team and those
written by Sublime Security's Automated Detection Engineer (ADE), with a
thorough analysis of ADE's skills presented in the results section.

</details>


### [18] [AdaptiveGuard: Towards Adaptive Runtime Safety for LLM-Powered Software](https://arxiv.org/abs/2509.16861)
*Rui Yang,Michael Fu,Chakkrit Tantithamthavorn,Chetan Arora,Gunel Gulmammadova,Joey Chua*

Main category: cs.CR

TL;DR: 提出AdaptiveGuard自适应防护栏系统，通过持续学习框架检测新型越狱攻击并动态适应，解决现有防护栏对未知攻击性能急剧下降的问题。


<details>
  <summary>Details</summary>
Motivation: 现有LLM防护栏在对抗新型越狱攻击时性能会从95%急剧下降到12%，需要构建能够动态适应新兴威胁的部署后防护系统。

Method: 使用离群分布检测技术识别新型越狱攻击作为OOD输入，通过持续学习框架学习防御这些攻击。

Result: AdaptiveGuard达到96%的OOD检测准确率，仅需两次更新即可适应新攻击，适应后对分布内数据保持85%以上的F1分数。

Conclusion: AdaptiveGuard是首个能够在部署后持续演化以应对新兴越狱策略的防护栏系统，显著优于现有基线方法。

Abstract: Guardrails are critical for the safe deployment of Large Language Models
(LLMs)-powered software. Unlike traditional rule-based systems with limited,
predefined input-output spaces that inherently constrain unsafe behavior, LLMs
enable open-ended, intelligent interactions--opening the door to jailbreak
attacks through user inputs. Guardrails serve as a protective layer, filtering
unsafe prompts before they reach the LLM. However, prior research shows that
jailbreak attacks can still succeed over 70% of the time, even against advanced
models like GPT-4o. While guardrails such as LlamaGuard report up to 95%
accuracy, our preliminary analysis shows their performance can drop sharply--to
as low as 12%--when confronted with unseen attacks. This highlights a growing
software engineering challenge: how to build a post-deployment guardrail that
adapts dynamically to emerging threats? To address this, we propose
AdaptiveGuard, an adaptive guardrail that detects novel jailbreak attacks as
out-of-distribution (OOD) inputs and learns to defend against them through a
continual learning framework. Through empirical evaluation, AdaptiveGuard
achieves 96% OOD detection accuracy, adapts to new attacks in just two update
steps, and retains over 85% F1-score on in-distribution data post-adaptation,
outperforming other baselines. These results demonstrate that AdaptiveGuard is
a guardrail capable of evolving in response to emerging jailbreak strategies
post deployment. We release our AdaptiveGuard and studied datasets at
https://github.com/awsm-research/AdaptiveGuard to support further research.

</details>


### [19] [Security Vulnerabilities in Software Supply Chain for Autonomous Vehicles](https://arxiv.org/abs/2509.16899)
*Md Wasiul Haque,Md Erfan,Sagar Dasgupta,Md Rayhanur Rahman,Mizanur Rahman*

Main category: cs.CR

TL;DR: 本文分析了自动驾驶车辆（AVs）开源软件组件中的安全漏洞，通过静态分析工具对主流开源AV软件进行检测，旨在揭示常见安全缺陷并强调在软件开发早期实施安全最佳实践的重要性。


<details>
  <summary>Details</summary>
Motivation: 随着自动驾驶车辆在关键任务中的广泛应用，其软件系统安全风险日益突出。特别是在依赖开源软件供应链的背景下，安全实践往往被忽视，导致严重的安全隐患。2024年汽车网络安全报告显示，49.5%的汽车网络攻击与软件系统安全漏洞相关。

Method: 使用静态分析工具对流行的开源自动驾驶软件（如Autoware、Apollo和openpilot）进行安全漏洞检测，分析不同开源AV仓库的静态分析器输出结果。

Result: 识别了自动驾驶车辆中普遍存在的软件安全漏洞，并对不同开源AV仓库的安全状况进行了比较分析。

Conclusion: 研究结果强调了在软件开发生命周期早期实施安全最佳实践的必要性，以降低网络安全风险，确保系统可靠性，保护用户数据，并在日益自动化的世界中维护公众信任。

Abstract: The interest in autonomous vehicles (AVs) for critical missions, including
transportation, rescue, surveillance, reconnaissance, and mapping, is growing
rapidly due to their significant safety and mobility benefits. AVs consist of
complex software systems that leverage artificial intelligence (AI), sensor
fusion algorithms, and real-time data processing. Additionally, AVs are
becoming increasingly reliant on open-source software supply chains, such as
open-source packages, third-party software components, AI models, and
third-party datasets. Software security best practices in the automotive sector
are often an afterthought for developers. Thus, significant cybersecurity risks
exist in the software supply chain of AVs, particularly when secure software
development practices are not rigorously implemented. For example, Upstream's
2024 Automotive Cybersecurity Report states that 49.5% of cyberattacks in the
automotive sector are related to exploiting security vulnerabilities in
software systems. In this chapter, we analyze security vulnerabilities in
open-source software components in AVs. We utilize static analyzers on popular
open-source AV software, such as Autoware, Apollo, and openpilot. Specifically,
this chapter covers: (1) prevalent software security vulnerabilities of AVs;
and (2) a comparison of static analyzer outputs for different open-source AV
repositories. The goal is to inform researchers, practitioners, and
policymakers about the existing security flaws in the commonplace open-source
software ecosystem in the AV domain. The findings would emphasize the necessity
of security best practices earlier in the software development lifecycle to
reduce cybersecurity risks, thereby ensuring system reliability, safeguarding
user data, and maintaining public trust in an increasingly automated world.

</details>


### [20] [Temporal Logic-Based Multi-Vehicle Backdoor Attacks against Offline RL Agents in End-to-end Autonomous Driving](https://arxiv.org/abs/2509.16950)
*Xuan Chen,Shiwei Feng,Zikang Xiong,Shengwei An,Yunshu Mao,Lu Yan,Guanhong Tao,Wenbo Guo,Xiangyu Zhang*

Main category: cs.CR

TL;DR: 本文提出了一种针对端到端自动驾驶系统的新型后门攻击，使用其他车辆的轨迹作为触发器，而非不切实际的像素级触发器。通过时间逻辑规范定义攻击车辆行为，并采用负训练策略提高攻击隐蔽性。


<details>
  <summary>Details</summary>
Motivation: 现有后门攻击主要关注像素级触发器，这在现实世界中部署不切实际。本文旨在填补这一空白，研究基于轨迹的后门攻击对自动驾驶系统的威胁。

Method: 1. 使用时间逻辑规范定义攻击车辆行为；2. 通过可配置行为模型生成精确触发轨迹；3. 开发负训练策略，引入与触发器相似但不激活后门的补丁轨迹；4. 在5个离线强化学习驾驶代理上进行实验验证。

Result: 实验结果表明，该方法在6种触发模式和目标动作组合下均表现出灵活性和有效性，揭示了现有端到端自动驾驶系统对基于轨迹的后门攻击的脆弱性。

Conclusion: 本文证明了基于轨迹的后门攻击对自动驾驶系统的实际威胁，强调了此类攻击在现实场景中的可行性，为自动驾驶安全研究提供了新的方向。

Abstract: Assessing the safety of autonomous driving (AD) systems against security
threats, particularly backdoor attacks, is a stepping stone for real-world
deployment. However, existing works mainly focus on pixel-level triggers that
are impractical to deploy in the real world. We address this gap by introducing
a novel backdoor attack against the end-to-end AD systems that leverage one or
more other vehicles' trajectories as triggers. To generate precise trigger
trajectories, we first use temporal logic (TL) specifications to define the
behaviors of attacker vehicles. Configurable behavior models are then used to
generate these trajectories, which are quantitatively evaluated and iteratively
refined based on the TL specifications. We further develop a negative training
strategy by incorporating patch trajectories that are similar to triggers but
are designated not to activate the backdoor. It enhances the stealthiness of
the attack and refines the system's responses to trigger scenarios. Through
extensive experiments on 5 offline reinforcement learning (RL) driving agents
with 6 trigger patterns and target action combinations, we demonstrate the
flexibility and effectiveness of our proposed attack, showing the
under-exploration of existing end-to-end AD systems' vulnerabilities to such
trajectory-based backdoor attacks.

</details>


### [21] [In Numeris Veritas: An Empirical Measurement of Wi-Fi Integration in Industry](https://arxiv.org/abs/2509.16987)
*Vyron Kampourakis,Christos Smiliotopoulos,Vasileios Gkioulos,Sokratis Katsikas*

Main category: cs.CR

TL;DR: 该研究通过分析全球WiGLE数据库，首次创建了包含1,087个高置信度工业Wi-Fi网络的公开数据集，揭示了工业环境中Wi-Fi安全配置的严重缺陷。


<details>
  <summary>Details</summary>
Motivation: 随着IT技术渗透到OT领域，工业系统中的传统物理隔离正在消失，新一代Wi-Fi标准的引入带来了严重的安全隐患，但缺乏对现实工业环境中Wi-Fi安全配置的实证研究。

Method: 挖掘全球众包WiGLE数据库，创建首个公开的工业Wi-Fi网络数据集，分析SSID模式、加密方法、供应商类型和全球分布等关键属性。

Result: 研究发现工业部门Wi-Fi采用率不断增长，但存在严重安全缺陷，包括持续使用弱或过时的安全配置，直接暴露关键基础设施。

Conclusion: 这项研究为工业环境中的无线安全提供了关键参考点，提供了独特的数据集和实用见解，指导未来的安全调查。

Abstract: Traditional air gaps in industrial systems are disappearing as IT
technologies permeate the OT domain, accelerating the integration of wireless
solutions like Wi-Fi. Next-generation Wi-Fi standards (IEEE 802.11ax/be) meet
performance demands for industrial use cases, yet their introduction raises
significant security concerns. A critical knowledge gap exists regarding the
empirical prevalence and security configuration of Wi-Fi in real-world
industrial settings. This work addresses this by mining the global crowdsourced
WiGLE database to provide a data-driven understanding. We create the first
publicly available dataset of 1,087 high-confidence industrial Wi-Fi networks,
examining key attributes such as SSID patterns, encryption methods, vendor
types, and global distribution. Our findings reveal a growing adoption of Wi-Fi
across industrial sectors but underscore alarming security deficiencies,
including the continued use of weak or outdated security configurations that
directly expose critical infrastructure. This research serves as a pivotal
reference point, offering both a unique dataset and practical insights to guide
future investigations into wireless security within industrial environments.

</details>


### [22] [Electronic Reporting Using SM2-Based Ring Signcryption](https://arxiv.org/abs/2509.17048)
*Huifang Yu,Jiaxing Jie,Lei Li*

Main category: cs.CR

TL;DR: 提出了一种基于SM2可追踪环签密方案的电子举报系统，该方案结合SM2椭圆曲线公钥密码算法和环签名算法，在保护举报人身份隐私的同时能够追踪恶意举报，并确保举报信息的机密性。


<details>
  <summary>Details</summary>
Motivation: 电子举报系统需要解决举报人身份隐私保护、防止恶意举报以及举报信息保密性等关键问题。现有方案在效率和安全性方面存在不足，需要设计更高效的密码学方案。

Method: 将SM2椭圆曲线公钥密码算法与环签名算法相结合，设计可追踪的环签密方案。该方案在签名阶段具有较高效率，同时满足机密性、不可伪造性、可追踪性、可链接性和可否认性等安全特性。

Result: 安全性分析表明该方案满足所有设计的安全要求。效率分析显示，与现有环签名方案相比，在签名阶段具有显著效率优势。基于该方案设计的电子举报系统能有效保护用户身份隐私并追踪恶意举报者。

Conclusion: 所提出的SM2可追踪环签密方案为电子举报系统提供了一种高效安全的解决方案，实现了身份隐私保护与恶意行为追踪的平衡，具有实际应用价值。

Abstract: Electronic whistleblowing systems are widely used due to their efficiency and
convenience. The key to designing such systems lies in protecting the identity
privacy of whistleblowers, preventing malicious whistleblowing, and ensuring
the confidentiality of whistleblowing information. To address these issues, a
SM2 traceable ring signcryption scheme for electronic voting is proposed. This
scheme combines the SM2 elliptic curve public key cryptography algorithm with
the ring signature algorithm, enhancing the overall efficiency of the scheme
while ensuring the autonomy and controllability of the core cryptographic
algorithms. Security analysis demonstrates that the proposed scheme satisfies
confidentiality, unforgeability, traceability, linkability, and deniability.
Efficiency analysis shows that, compared to existing ring signature schemes,
the proposed scheme exhibits significant efficiency advantages during the
signature phase. The electronic whistleblowing system designed using the
proposed scheme can track malicious whistleblowers while protecting user
identity privacy, and ensures that the content of whistleblowing remains
unknown to third parties.

</details>


### [23] [Localizing Malicious Outputs from CodeLLM](https://arxiv.org/abs/2509.17070)
*Mayukh Borana,Junyi Liang,Sai Sathiesh Rajan,Sudipta Chattopadhyay*

Main category: cs.CR

TL;DR: FreqRank是一种基于突变的防御方法，用于定位LLM输出中的恶意组件及其对应的后门触发器，通过频率排名系统识别恶意子字符串并定位输入中的后门触发器。


<details>
  <summary>Details</summary>
Motivation: 当前LLM在代码相关任务中容易受到后门攻击，需要有效的防御方法来检测和定位恶意组件。

Method: 使用频率排名系统，假设恶意子字符串在触发输入中一致出现，通过突变生成多个变体并分析频率来识别恶意组件。

Result: 在9个恶意模型上测试，平均攻击成功率为86.6%，FreqRank在98%的情况下将恶意输出列为前5建议，比其他防御方法有效35-50%。

Conclusion: FreqRank是一种有效的后门防御方法，能够准确定位恶意输出和触发器，且随着突变数量增加效果更好。

Abstract: We introduce FreqRank, a mutation-based defense to localize malicious
components in LLM outputs and their corresponding backdoor triggers. FreqRank
assumes that the malicious sub-string(s) consistently appear in outputs for
triggered inputs and uses a frequency-based ranking system to identify them.
Our ranking system then leverages this knowledge to localize the backdoor
triggers present in the inputs. We create nine malicious models through
fine-tuning or custom instructions for three downstream tasks, namely, code
completion (CC), code generation (CG), and code summarization (CS), and show
that they have an average attack success rate (ASR) of 86.6%. Furthermore,
FreqRank's ranking system highlights the malicious outputs as one of the top
five suggestions in 98% of cases. We also demonstrate that FreqRank's
effectiveness scales as the number of mutants increases and show that FreqRank
is capable of localizing the backdoor trigger effectively even with a limited
number of triggered samples. Finally, we show that our approach is 35-50% more
effective than other defense methods.

</details>


### [24] [Unaligned Incentives: Pricing Attacks Against Blockchain Rollups](https://arxiv.org/abs/2509.17126)
*Stefanos Chaliasos,Conner Swann,Sina Pilehchiha,Nicolas Mohnblatt,Benjamin Livshits,Assimakis Kattis*

Main category: cs.CR

TL;DR: 本文识别了现有Rollup交易费机制中的关键错误定价问题，揭示了两种攻击向量：L2 DoS攻击和证明杀手交易攻击，导致最终性延迟和经济损失。


<details>
  <summary>Details</summary>
Motivation: Rollup已成为以太坊的主要扩容方案，管理着超过550亿美元资产。其费用机制需要同时反映L2成本、L1数据可用性和L1 gas成本，但现有机制存在错误定价问题。

Method: 分析主要以太坊Rollup的攻击向量，量化攻击成本和协议损失，包括DoS攻击持续时间和证明延迟增加倍数。

Result: 发现DoS攻击成本低于2 ETH，可使Rollup瘫痪30分钟；证明杀手攻击导致最终性延迟增加约94倍；三种Rollup面临无限期DoS攻击，成本为0.8-2.7 ETH/小时。

Conclusion: 提出了全面的缓解措施，建议通过多维Rollup交易费机制来纠正识别出的错误定价攻击。

Abstract: Rollups have become the de facto scalability solution for Ethereum, securing
more than $55B in assets. They achieve scale by executing transactions on a
Layer 2 ledger, while periodically posting data and finalizing state on the
Layer 1, either optimistically or via validity proofs. Their fees must
simultaneously reflect the pricing of three resources: L2 costs (e.g.,
execution), L1 DA, and underlying L1 gas costs for batch settlement and proof
verification. In this work, we identify critical mis-pricings in existing
rollup transaction fee mechanisms (TFMs) that allow for two powerful attacks.
Firstly, an adversary can saturate the L2's DA batch capacity with
compute-light data-heavy transactions, forcing low-gas transaction batches that
enable both L2 DoS attacks, and finality-delay attacks. Secondly, by crafting
prover killer transactions that maximize proving cycles relative to the gas
charges, an adversary can effectively stall proof generation, delaying finality
by hours and inflicting prover-side economic losses to the rollup at a minimal
cost.
  We analyze the above attack vectors across the major Ethereum rollups,
quantifying adversarial costs and protocol losses. We find that the first
attack enables periodic DoS on rollups, lasting up to 30 minutes, at a cost
below 2 ETH for most rollups. Moreover, we identify three rollups that are
exposed to indefinite DoS at a cost of approximately 0.8 to 2.7 ETH per hour.
The attack can be further modified to increase finalization delays by a factor
of about 1.45x to 2.73x, compared to direct L1 blob-stuffing, depending on the
rollup's parameters. Furthermore, we find that the prover killer attack induces
a finalization latency increase of about 94x. Finally, we propose comprehensive
mitigations to prevent these attacks and suggest how some practical uses of
multi-dimensional rollup TFMs can rectify the identified mis-pricing attacks.

</details>


### [25] [Bribers, Bribers on The Chain, Is Resisting All in Vain? Trustless Consensus Manipulation Through Bribing Contracts](https://arxiv.org/abs/2509.17185)
*Bence Soóki-Tóth,István András Seres,Kamilla Kara,Ábel Nagy,Balázs Pejó,Gergely Biczók*

Main category: cs.CR

TL;DR: 本文介绍了三种针对以太坊验证者的新型高效贿赂合约，分析了它们对区块链共识机制的威胁，并进行了初步的博弈论分析。


<details>
  <summary>Details</summary>
Motivation: 加密货币的长期成功依赖于验证者的激励兼容性，而通过智能合约实现的贿赂攻击威胁着这一基础。

Method: 设计并实现了三种贿赂合约：1）通过购买投票来分叉区块链；2）激励验证者自愿退出共识协议；3）建立信任缺失的贿赂市场来操纵RANDAO随机数信标。

Result: 成功展示了这些贿赂合约的有效性，并揭示了以太坊共识机制中存在的潜在漏洞。

Conclusion: 这些新型贿赂攻击对以太坊等权益证明区块链构成严重威胁，需要加强共识机制的安全性和抗攻击能力。

Abstract: The long-term success of cryptocurrencies largely depends on the incentive
compatibility provided to the validators. Bribery attacks, facilitated
trustlessly via smart contracts, threaten this foundation. This work
introduces, implements, and evaluates three novel and efficient bribery
contracts targeting Ethereum validators. The first bribery contract enables a
briber to fork the blockchain by buying votes on their proposed blocks. The
second contract incentivizes validators to voluntarily exit the consensus
protocol, thus increasing the adversary's relative staking power. The third
contract builds a trustless bribery market that enables the briber to auction
off their manipulative power over the RANDAO, Ethereum's distributed randomness
beacon. Finally, we provide an initial game-theoretical analysis of one of the
described bribery markets.

</details>


### [26] [Seeing is Deceiving: Mirror-Based LiDAR Spoofing for Autonomous Vehicle Deception](https://arxiv.org/abs/2509.17253)
*Selma Yahia,Ildi Alla,Girija Bangalore Mohan,Daniel Rau,Mridula Singh,Valeria Loscri*

Main category: cs.CR

TL;DR: 本文提出了一种利用镜面反射的低成本、被动式LiDAR欺骗攻击方法，可以在自动驾驶车辆感知系统中注入或移除物体，导致虚假检测和不安全行为。


<details>
  <summary>Details</summary>
Motivation: 自动驾驶车辆严重依赖LiDAR进行3D感知，但现有研究主要关注主动式攻击。本文旨在探索利用镜面反射的被动式攻击方法，这种攻击成本低、易于部署且难以检测。

Method: 使用平面镜重定向LiDAR光束，定义物体添加攻击（OAA）和物体移除攻击（ORA）。开发几何光学模型，通过室外实验和CARLA仿真进行验证。

Result: 实验表明镜面攻击能够破坏占用网格，诱发虚假检测，并触发不安全的规划和控制行为。攻击在真实环境中有效且难以防御。

Conclusion: 镜面反射攻击对自动驾驶系统构成严重威胁，现有防御方法（热传感、多传感器融合、光指纹识别）存在局限性，需要开发更有效的防护机制。

Abstract: Autonomous vehicles (AVs) rely heavily on LiDAR sensors for accurate 3D
perception. We show a novel class of low-cost, passive LiDAR spoofing attacks
that exploit mirror-like surfaces to inject or remove objects from an AV's
perception. Using planar mirrors to redirect LiDAR beams, these attacks require
no electronics or custom fabrication and can be deployed in real settings. We
define two adversarial goals: Object Addition Attacks (OAA), which create
phantom obstacles, and Object Removal Attacks (ORA), which conceal real
hazards. We develop geometric optics models, validate them with controlled
outdoor experiments using a commercial LiDAR and an Autoware-equipped vehicle,
and implement a CARLA-based simulation for scalable testing. Experiments show
mirror attacks corrupt occupancy grids, induce false detections, and trigger
unsafe planning and control behaviors. We discuss potential defenses (thermal
sensing, multi-sensor fusion, light-fingerprinting) and their limitations.

</details>


### [27] [Bridging Cybersecurity Practice and Law: a Hands-on, Scenario-Based Curriculum Using the NICE Framework to Foster Skill Development](https://arxiv.org/abs/2509.17263)
*Colman McGuan,Aadithyan V. Raghavan,Komala M. Mandapati,Chansu Yu,Brian E. Ray,Debbie K. Jackson,Sathish Kumar*

Main category: cs.CR

TL;DR: 本文针对中小企业难以实施NICE网络安全框架的问题，提出了基于常见攻击向量的实用模型和情景式课程，帮助中小企业评估和培养网络安全人才。


<details>
  <summary>Details</summary>
Motivation: 中小企业难以导航和实施NICE等网络安全框架，需要更实用的指导来应对网络威胁。

Method: 识别中小企业常见攻击向量，从NICE框架提取相关技术与非技术任务知识技能，开发情景式课程，整合实践经验。

Result: 建立了实用的TKSA模型和情景学习模块，可用于人才评估和培训。

Conclusion: 该模型为中小企业提供了实用的网络安全人才培养指南，教育机构可基于此开发有效培训课程。

Abstract: In an increasingly interconnected world, cybersecurity professionals play a
pivotal role in safeguarding organizations from cyber threats. To secure their
cyberspace, organizations are forced to adopt a cybersecurity framework such as
the NIST National Initiative for Cybersecurity Education Workforce Framework
for Cybersecurity (NICE Framework). Although these frameworks are a good
starting point for businesses and offer critical information to identify,
prevent, and respond to cyber incidents, they can be difficult to navigate and
implement, particularly for small-medium businesses (SMB). To help overcome
this issue, this paper identifies the most frequent attack vectors to SMBs
(Objective 1) and proposes a practical model of both technical and
non-technical tasks, knowledge, skills, abilities (TKSA) from the NICE
Framework for those attacks (Objective 2). The research develops a
scenario-based curriculum. By immersing learners in realistic cyber threat
scenarios, their practical understanding and preparedness in responding to
cybersecurity incidents is enhanced (Objective 3). Finally, this work
integrates practical experience and real-life skill development into the
curriculum (Objective 4). SMBs can use the model as a guide to evaluate, equip
their existing workforce, or assist in hiring new employees. In addition,
educational institutions can use the model to develop scenario-based learning
modules to adequately equip the emerging cybersecurity workforce for SMBs.
Trainees will have the opportunity to practice both technical and legal issues
in a simulated environment, thereby strengthening their ability to identify,
mitigate, and respond to cyber threats effectively.

</details>


### [28] [Privacy-Preserving State Estimation with Crowd Sensors: An Information-Theoretic Respective](https://arxiv.org/abs/2509.17266)
*Farhad Farokhi*

Main category: cs.CR

TL;DR: 该论文提出了一种用于线性时不变动态系统的隐私保护状态估计方法，通过添加隐私保护噪声来控制传感器身份信息泄漏，实现隐私与效用之间的可调权衡。


<details>
  <summary>Details</summary>
Motivation: 在众包传感器环境中进行状态估计时，需要保护传感器身份隐私，防止被强大对手通过状态估计推断出具体使用了哪个传感器。

Method: 使用Luenberger类观测器融合传感器测量值和系统模型，递归生成状态估计，并添加加性隐私保护噪声来约束信息泄漏。信息泄漏通过互信息度量。

Result: 研究表明，通过适当选择隐私保护噪声的方差，可以实现任何预设的信息泄漏水平，从而精确调节隐私与效用之间的权衡关系。

Conclusion: 该方法为线性时不变动态系统的隐私保护状态估计提供了一种有效的解决方案，能够在不牺牲估计精度的前提下保护传感器身份隐私。

Abstract: Privacy-preserving state estimation for linear time-invariant dynamical
systems with crowd sensors is considered. At any time step, the estimator has
access to measurements from a randomly selected sensor from a pool of sensors
with pre-specified models and noise profiles. A Luenberger-like observer is
used to fuse the measurements with the underlying model of the system to
recursively generate the state estimates. An additive privacy-preserving noise
is used to constrain information leakage. Information leakage is measured via
mutual information between the identity of the sensors and the state estimate
conditioned on the actual state of the system. This captures an omnipotent
adversary that not only can access state estimates but can also gather direct
high-quality state measurements. Any prescribed level of information leakage is
shown to be achievable by appropriately selecting the variance of the
privacy-preserving noise. Therefore, privacy-utility trade-off can be
fine-tuned.

</details>


### [29] [TextCrafter: Optimization-Calibrated Noise for Defending Against Text Embedding Inversion](https://arxiv.org/abs/2509.17302)
*Duoxun Tang,Xinhang Jiang,Jiajun Niu*

Main category: cs.CR

TL;DR: TextCrafter是一种基于优化的对抗扰动机制，通过RL学习、几何感知噪声注入结合聚类先验和PII信号指导，在保护任务效用的同时抑制文本嵌入反转攻击。


<details>
  <summary>Details</summary>
Motivation: 文本嵌入反转攻击能够从潜在表示重构原始句子，在协同推理和边缘计算中构成严重隐私威胁，需要有效的防御机制。

Method: 结合强化学习学习的几何感知噪声注入（与用户嵌入正交）、聚类先验和PII信号指导的优化对抗扰动机制。

Result: 在强隐私设置下，TextCrafter在四个数据集上保持70%的分类准确率，在较低隐私预算下始终优于高斯/LDP基线方法。

Conclusion: TextCrafter提供了一种方向性保护策略，在隐私和效用之间实现了优越的平衡。

Abstract: Text embedding inversion attacks reconstruct original sentences from latent
representations, posing severe privacy threats in collaborative inference and
edge computing. We propose TextCrafter, an optimization-based adversarial
perturbation mechanism that combines RL learned, geometry aware noise injection
orthogonal to user embeddings with cluster priors and PII signal guidance to
suppress inversion while preserving task utility. Unlike prior defenses either
non learnable or agnostic to perturbation direction, TextCrafter provides a
directional protective policy that balances privacy and utility. Under strong
privacy setting, TextCrafter maintains 70 percentage classification accuracy on
four datasets and consistently outperforms Gaussian/LDP baselines across lower
privacy budgets, demonstrating a superior privacy utility trade off.

</details>


### [30] [SilentStriker:Toward Stealthy Bit-Flip Attacks on Large Language Models](https://arxiv.org/abs/2509.17371)
*Haotian Xu,Qingsong Peng,Jie Shi,Huadi Zheng,Yu Li,Cheng Zhuo*

Main category: cs.CR

TL;DR: 本文提出了SilentStriker，首个针对大语言模型的隐蔽位翻转攻击方法，能在降低任务性能的同时保持输出自然性。


<details>
  <summary>Details</summary>
Motivation: 现有位翻转攻击方法在性能降低和输出自然性之间难以平衡，容易被发现。大语言模型输出长度可变且输出空间巨大，设计有效的损失函数具有挑战性。

Method: 通过利用关键输出标记作为抑制目标重新制定攻击目标，采用迭代渐进搜索策略最大化攻击效果，避免使用输出困惑度来保持自然性。

Result: 实验表明SilentStriker显著优于现有基线方法，能够成功实施攻击而不影响生成文本的自然性。

Conclusion: SilentStriker解决了LLM位翻转攻击中效果与隐蔽性的平衡问题，为模型安全研究提供了新视角。

Abstract: The rapid adoption of large language models (LLMs) in critical domains has
spurred extensive research into their security issues. While input manipulation
attacks (e.g., prompt injection) have been well studied, Bit-Flip Attacks
(BFAs) -- which exploit hardware vulnerabilities to corrupt model parameters
and cause severe performance degradation -- have received far less attention.
Existing BFA methods suffer from key limitations: they fail to balance
performance degradation and output naturalness, making them prone to discovery.
In this paper, we introduce SilentStriker, the first stealthy bit-flip attack
against LLMs that effectively degrades task performance while maintaining
output naturalness. Our core contribution lies in addressing the challenge of
designing effective loss functions for LLMs with variable output length and the
vast output space. Unlike prior approaches that rely on output perplexity for
attack loss formulation, which inevitably degrade output naturalness, we
reformulate the attack objective by leveraging key output tokens as targets for
suppression, enabling effective joint optimization of attack effectiveness and
stealthiness. Additionally, we employ an iterative, progressive search strategy
to maximize attack efficacy. Experiments show that SilentStriker significantly
outperforms existing baselines, achieving successful attacks without
compromising the naturalness of generated text.

</details>


### [31] [A Lightweight Authentication and Key Agreement Protocol Design for FANET](https://arxiv.org/abs/2509.17409)
*Yao Wu,Ziye Jia,Qihui Wu,Yian Zhu*

Main category: cs.CR

TL;DR: 本文提出了一种轻量级的FANETs认证和密钥协商协议，结合物理不可克隆功能与动态凭证管理，降低计算和通信开销同时提升安全性。


<details>
  <summary>Details</summary>
Motivation: 低空智能网络中无人机通过FANETs互联具有灵活性和去中心化协调优势，但资源约束、动态拓扑和开放环境操作带来了显著的安全和通信挑战。现有基于存储敏感信息的多因素和公钥密码协议存在暴露和泄露风险。

Method: 提出了一种轻量级认证和密钥协商协议，集成物理不可克隆功能、动态凭证管理和轻量级密码原语。

Result: 安全分析确认协议能抵抗各种攻击，比较评估显示其在安全性、通信效率和计算成本方面具有优越性。

Conclusion: 该协议有效解决了FANETs中的安全挑战，在保证安全性的同时显著降低了资源开销。

Abstract: The advancement of low-altitude intelligent networks enables unmanned aerial
vehicle (UAV) interconnection via flying ad-hoc networks (FANETs), offering
flexibility and decentralized coordination. However, resource constraints,
dynamic topologies, and UAV operations in open environments present significant
security and communication challenges. Existing multi-factor and public-key
cryptography protocols are vulnerable due to their reliance on stored sensitive
information, increasing the risk of exposure and compromise. This paper
proposes a lightweight authentication and key agreement protocol for FANETs,
integrating physical unclonable functions with dynamic credential management
and lightweight cryptographic primitives. The protocol reduces computational
and communication overhead while enhancing security. Security analysis confirms
its resilience against various attacks, and comparative evaluations demonstrate
its superiority in security, communication efficiency, and computational cost.

</details>


### [32] [DINVMark: A Deep Invertible Network for Video Watermarking](https://arxiv.org/abs/2509.17416)
*Jianbin Ji,Dawen Xu,Li Dong,Lin Yang,Songhan He*

Main category: cs.CR

TL;DR: 本文提出了一种基于深度可逆网络的视频水印方法DINVMark，通过设计专门针对HEVC压缩的噪声层，提高了水印容量和鲁棒性。


<details>
  <summary>Details</summary>
Motivation: 现有视频水印方法在水印容量和鲁棒性方面存在不足，且缺乏专门针对HEVC压缩的噪声层设计。

Method: 使用可逆神经网络(INN)，编码器和解码器共享相同网络结构，设计专门模拟HEVC压缩的噪声层。

Result: 实验结果表明该方法显著增强了水印鲁棒性，保持了视频质量，并大幅提高了水印嵌入容量。

Conclusion: DINVMark方法有效解决了视频水印在容量和鲁棒性方面的挑战，为HEVC压缩环境下的视频版权保护提供了有效解决方案。

Abstract: With the wide spread of video, video watermarking has become increasingly
crucial for copyright protection and content authentication. However, video
watermarking still faces numerous challenges. For example, existing methods
typically have shortcomings in terms of watermarking capacity and robustness,
and there is a lack of specialized noise layer for High Efficiency Video
Coding(HEVC) compression. To address these issues, this paper introduces a Deep
Invertible Network for Video watermarking (DINVMark) and designs a noise layer
to simulate HEVC compression. This approach not only in creases watermarking
capacity but also enhances robustness. DINVMark employs an Invertible Neural
Network (INN), where the encoder and decoder share the same network structure
for both watermark embedding and extraction. This shared architecture ensures
close coupling between the encoder and decoder, thereby improving the accuracy
of the watermark extraction process. Experimental results demonstrate that the
proposed scheme significantly enhances watermark robustness, preserves video
quality, and substantially increases watermark embedding capacity.

</details>


### [33] [Privacy in Action: Towards Realistic Privacy Mitigation and Evaluation for LLM-Powered Agents](https://arxiv.org/abs/2509.17488)
*Shouju Wang,Fenglin Yu,Xirui Liu,Xiaoting Qin,Jue Zhang,Qingwei Lin,Dongmei Zhang,Saravan Rajmohan*

Main category: cs.CR

TL;DR: 提出PrivacyChecker方法，通过基于情境完整性的缓解方法显著降低LLM代理的隐私泄露风险，同时保持任务有效性，并引入PrivacyLens-Live将静态基准转化为动态环境来评估实际隐私风险。


<details>
  <summary>Details</summary>
Motivation: LLM代理在处理敏感通信时自主性增强，但现有隐私基准仅限于静态简化场景，无法反映实际代理环境中的隐私风险。

Method: 开发了模型无关的、基于情境完整性的PrivacyChecker缓解方法，以及PrivacyLens-Live动态评估框架，将静态基准转化为MCP和A2A环境。

Result: PrivacyChecker将DeepSeek-R1的隐私泄露从36.08%降至7.30%，GPT-4o从33.06%降至8.32%，同时保持任务有效性。

Conclusion: 该方法通过三种部署策略无缝集成到代理协议中，为新兴的代理生态系统提供实用的隐私保护方案。

Abstract: The increasing autonomy of LLM agents in handling sensitive communications,
accelerated by Model Context Protocol (MCP) and Agent-to-Agent (A2A)
frameworks, creates urgent privacy challenges. While recent work reveals
significant gaps between LLMs' privacy Q&A performance and their agent
behavior, existing benchmarks remain limited to static, simplified scenarios.
We present PrivacyChecker, a model-agnostic, contextual integrity based
mitigation approach that effectively reduces privacy leakage from 36.08% to
7.30% on DeepSeek-R1 and from 33.06% to 8.32% on GPT-4o, all while preserving
task helpfulness. We also introduce PrivacyLens-Live, transforming static
benchmarks into dynamic MCP and A2A environments that reveal substantially
higher privacy risks in practical. Our modular mitigation approach integrates
seamlessly into agent protocols through three deployment strategies, providing
practical privacy protection for the emerging agentic ecosystem. Our data and
code will be made available at https://aka.ms/privacy_in_action.

</details>


### [34] [Community Covert Communication - Dynamic Mass Covert Communication Through Social Media](https://arxiv.org/abs/2509.17508)
*Eric Filiol*

Main category: cs.CR

TL;DR: 本文研究如何利用社交媒体网络中的傀儡大师技术来传播加密信息，重新定义通信概念，使传统监听和干扰手段失效。


<details>
  <summary>Details</summary>
Motivation: 随着社交网络影响力技术的快速发展，出现了利用大量虚拟账号进行影响力操作的技术。本研究旨在探索这些社区管理技术如何被用于向有限参与者传播大量加密信息。

Method: 采用傀儡大师活动技术，创建数百至数千个虚拟化身，组织成社区，使用专门软件（如Ripon、AIMS）自动化操作，实现多层级加密信息传播。

Result: 研究表明这种技术能够有效传播数十MB量级的加密信息，具有比暗帖功能更强大的潜力，彻底改变了通信方式。

Conclusion: 社交媒体影响力技术可以重新定义通信概念，使传统监听、拦截和干扰操作失去意义，为安全通信提供了新的可能性。

Abstract: Since the early 2010s, social network-based influence technologies have grown
almost exponentially. Initiated by the U.S. Army's early OEV system in 2011, a
number of companies specializing in this field have emerged. The most
(in)famous cases are Bell Pottinger, Cambridge Analytica, Aggregate-IQ and,
more recently, Team Jorge.
  In this paper, we consider the use-case of sock puppet master activities,
which consist in creating hundreds or even thousands of avatars, in organizing
them into communities and implement influence operations. On-purpose software
is used to automate these operations (e.g. Ripon software, AIMS) and organize
these avatar populations into communities. The aim is to organize targeted and
directed influence communication to rather large communities (influence
targets).
  The goal of the present research work is to show how these community
management techniques (social networks) can also be used to
communicate/disseminate relatively large volumes (up to a few tens of Mb) of
multi-level encrypted information to a limited number of actors. To a certain
extent, this can be compared to a Dark Post-type function, with a number of
much more powerful potentialities. As a consequence, the concept of
communication has been totally redefined and disrupted, so that eavesdropping,
interception and jamming operations no longer make sense.

</details>


### [35] [Impossibility Results of Card-Based Protocols via Mathematical Optimization](https://arxiv.org/abs/2509.17595)
*Shunnosuke Ikeda,Kazumasa Shinagawa*

Main category: cs.CR

TL;DR: 本文提出了一种使用数学优化方法证明卡基密码学中不可能性证明的新框架，特别针对单次切牌全公开协议，证明了对于任何三变量布尔函数，在附加卡颜色相同的条件下，不存在超出已知协议的新SCFO协议。


<details>
  <summary>Details</summary>
Motivation: 传统的不可能性证明方法通常只能处理少量卡片的情况，需要一种能够处理大量卡片的新方法来扩展卡基密码学的不可能性证明范围。

Method: 采用数学优化方法，重点研究单次切牌全公开协议，通过建立适用于任意数量卡片的证明框架，分析三变量布尔函数的可实现性。

Result: 证明在附加卡颜色相同的条件下，对于任何三变量布尔函数，不存在超出已知协议的新SCFO协议，该结果适用于任意数量的卡片。

Conclusion: 数学优化方法为卡基密码学的不可能性证明提供了新的有效框架，能够处理大规模卡片情况，填补了传统方法的局限性。

Abstract: This paper introduces mathematical optimization as a new method for proving
impossibility proofs in the field of card-based cryptography. While previous
impossibility proofs were often limited to cases involving a small number of
cards, this new approach establishes results that hold for a large number of
cards. The research focuses on single-cut full-open (SCFO) protocols, which
consist of performing one random cut and then revealing all cards. The main
contribution is that for any three-variable Boolean function, no new SCFO
protocols exist beyond those already known, under the condition that all
additional cards have the same color. The significance of this work is that it
provides a new framework for impossibility proofs and delivers a proof that is
valid for any number of cards, as long as all additional cards have the same
color.

</details>


### [36] [Ordered Multi-Signatures with Public-Key Aggregation from SXDH Assumption](https://arxiv.org/abs/2509.17709)
*Masayuki Tezuka,Keisuke Tanaka*

Main category: cs.CR

TL;DR: 本文提出了一种有序多重签名方案，通过修改Chatterjee和Kabaleeshwaran的顺序聚合签名方案，实现了紧凑的公共参数大小和公钥聚合特性。


<details>
  <summary>Details</summary>
Motivation: 有序多重签名方案允许多个签名者按顺序对共同消息进行签名，并允许任何人通过公钥列表验证签名者的签名顺序。现有方案在公共参数大小和公钥聚合方面存在改进空间。

Method: 通过修改Chatterjee和Kabaleeshwaran的顺序聚合签名方案，引入公钥聚合特性，将公钥列表压缩为短聚合密钥。

Result: 提出的方案具有紧凑的公共参数大小和公钥聚合特性，能够在对称外部Diffie-Hellman（SXDH）假设下证明安全性，无需随机预言模型。

Conclusion: 该有序多重签名方案在保持安全性的同时，优化了参数大小和公钥管理效率，为实际应用提供了更高效的解决方案。

Abstract: An ordered multi-signature scheme allows multiple signers to sign a common
message in a sequential manner and allows anyone to verify the signing order of
signers with a public-key list. In this work, we propose an ordered
multi-signature scheme by modifying the sequential aggregate signature scheme
by Chatterjee and Kabaleeshwaran (ACISP 2020). Our scheme offers compact public
parameter size and the public-key aggregation property. This property allows us
to compress a public-key list into a short aggregated key. We prove the
security of our scheme under the symmetric external Diffie-Hellman (SXDH)
assumption without the random oracle model.

</details>


### [37] [Public Key Encryption with Equality Test from Tag-Based Encryption](https://arxiv.org/abs/2509.17722)
*Masayuki Tezuka,Keisuke Tanaka*

Main category: cs.CR

TL;DR: 本文提出了一种基于标签加密的PKEET通用构造方案，无需随机预言模型，解决了现有通用构造依赖随机预言模型或身份基加密的缺点。


<details>
  <summary>Details</summary>
Motivation: 现有的PKEET通用构造方案存在依赖随机预言模型或（分层）身份基加密的缺点，需要一种更基础、更安全的构造方法。

Method: 基于标签加密这一比身份基加密更弱的原语，提出通用构造方案，并通过Kiltz的无配对标签加密方案和基于LPN假设的标签加密方案进行实例化。

Result: 成功构建了无需随机预言模型的PKEET方案，获得了无配对的PKEET方案和基于LPN假设的PKEET方案。

Conclusion: 该通用构造为PKEET方案提供了新的构建途径，避免了随机预言模型的依赖，具有更好的安全性和实用性。

Abstract: Public key encryption with equality test (PKEET), proposed by Yang et al.
(CT-RSA 2010), is a variant of public key encryption that enables an equality
test to determine whether two ciphertexts correspond to the same plaintext.
This test applies not only for ciphertexts generated under the same encryption
key but also for those generated under different encryption keys. To date,
several generic constructions of PKEET have been proposed. However, these
generic constructions have the drawback of reliance on the random oracle model
or a (hierarchical) identity-based encryption scheme. In this paper, we propose
a generic construction of a PKEET scheme based on tag-based encryption without
the random oracle model. Tag-based encryption is a weaker primitive than
identity-based encryption. Our scheme allows to derive new PKEET schemes
without the random oracle model. By instantiating our construction with the
pairing-free tag-based encryption scheme by Kiltz (TCC 2006), we obtain a
pairing-free PKEET scheme without the random oracle model. Moreover, by
instantiating our construction with a tag-based encryption scheme based on the
learning parity with noise (LPN) assumption, we obtain a PKEET scheme based on
the LPN assumption without the random oracle model.

</details>


### [38] [AEAS: Actionable Exploit Assessment System](https://arxiv.org/abs/2509.17832)
*Xiangmin Shen,Wenyuan Cheng,Yan Chen,Zhenyuan Li,Yuqiao Gu,Lingzhi Wang,Wencheng Zhao,Dawei Sun,Jiashui Wang*

Main category: cs.CR

TL;DR: AEAS是一个自动化系统，通过静态分析评估和优先处理可操作的漏洞利用代码，解决现有评分系统在评估实际可用漏洞利用方面的不足。


<details>
  <summary>Details</summary>
Motivation: 安全从业者在漏洞评估中面临挑战，因为公共漏洞库中存在不一致和低质量的漏洞利用代码。现有评分系统如CVSS和EPSS对此任务支持有限，安全团队通常需要手动筛选漏洞库，这既耗时又容易出错。

Method: AEAS通过静态分析漏洞利用代码和相关文档，提取反映漏洞利用可用性、功能性和设置复杂性的结构化特征集，然后计算每个漏洞利用的可操作性分数并生成排名建议。

Result: 在包含5,000多个漏洞的数据集上评估，AEAS在推荐功能性漏洞利用方面实现了100%的前3成功率，并与专家验证的排名高度一致。

Conclusion: AEAS在支持基于漏洞利用的漏洞优先级排序方面表现出有效性，能够帮助安全团队更高效地识别和优先处理实际可用的漏洞利用。

Abstract: Security practitioners face growing challenges in exploit assessment, as
public vulnerability repositories are increasingly populated with inconsistent
and low-quality exploit artifacts. Existing scoring systems, such as CVSS and
EPSS, offer limited support for this task. They either rely on theoretical
metrics or produce opaque probability estimates without assessing whether
usable exploit code exists. In practice, security teams often resort to manual
triage of exploit repositories, which is time-consuming, error-prone, and
difficult to scale. We present AEAS, an automated system designed to assess and
prioritize actionable exploits through static analysis. AEAS analyzes both
exploit code and associated documentation to extract a structured set of
features reflecting exploit availability, functionality, and setup complexity.
It then computes an actionability score for each exploit and produces ranked
exploit recommendations. We evaluate AEAS on a dataset of over 5,000
vulnerabilities derived from 600+ real-world applications frequently
encountered by red teams. Manual validation and expert review on representative
subsets show that AEAS achieves a 100% top-3 success rate in recommending
functional exploits and shows strong alignment with expert-validated rankings.
These results demonstrate the effectiveness of AEAS in supporting
exploit-driven vulnerability prioritization.

</details>


### [39] [Federated Learning in the Wild: A Comparative Study for Cybersecurity under Non-IID and Unbalanced Settings](https://arxiv.org/abs/2509.17836)
*Roberto Doriguzzi-Corin,Petr Sabel,Silvio Cretti,Silvio Ranise*

Main category: cs.CR

TL;DR: 本文系统评估了联邦学习（FL）方法在网络入侵检测中的应用，特别是在非独立同分布（non-i.i.d.）和不平衡数据环境下的性能表现。


<details>
  <summary>Details</summary>
Motivation: 机器学习在网络流量分析中具有潜力，但受限于隐私和数据共享限制。联邦学习可以在保护数据隐私的同时实现协作训练，但传统的FedAvg算法在异构环境中收敛效果差。

Method: 使用Kubernetes测试平台中的网络攻击数据集，系统评估多种FL方法的收敛效率、计算开销、带宽消耗和模型准确性。

Result: 这是首个在真实非i.i.d.和不平衡设置下对FL算法进行入侵检测的比较分析，为设计鲁棒的隐私保护网络安全解决方案提供了新见解。

Conclusion: 该研究填补了FL算法在网络安全应用中的研究空白，为实际部署提供了重要参考价值。

Abstract: Machine Learning (ML) techniques have shown strong potential for network
traffic analysis; however, their effectiveness depends on access to
representative, up-to-date datasets, which is limited in cybersecurity due to
privacy and data-sharing restrictions. To address this challenge, Federated
Learning (FL) has recently emerged as a novel paradigm that enables
collaborative training of ML models across multiple clients while ensuring that
sensitive data remains local. Nevertheless, Federated Averaging (FedAvg), the
canonical FL algorithm, has proven poor convergence in heterogeneous
environments where data distributions are non-independent and identically
distributed (i.i.d.) and client datasets are unbalanced, conditions frequently
observed in cybersecurity contexts. To overcome these challenges, several
alternative FL strategies have been developed, yet their applicability to
network intrusion detection remains insufficiently explored. This study
systematically reviews and evaluates a range of FL methods in the context of
intrusion detection for DDoS attacks. Using a dataset of network attacks within
a Kubernetes-based testbed, we assess convergence efficiency, computational
overhead, bandwidth consumption, and model accuracy. To the best of our
knowledge, this is the first comparative analysis of FL algorithms for
intrusion detection under realistic non-i.i.d. and unbalanced settings,
providing new insights for the design of robust, privacypreserving network
security solutions.

</details>


### [40] [B-Privacy: Defining and Enforcing Privacy in Weighted Voting](https://arxiv.org/abs/2509.17871)
*Samuel Breckenridge,Dani Vilardell,Andrés Fábrega,Amy Zhao,Patrick McCorry,Rafael Solari,Ari Juels*

Main category: cs.CR

TL;DR: 该论文研究了加权投票系统中的隐私问题，提出了基于贿赂成本的B隐私概念，并通过噪声机制在隐私和透明度之间进行权衡，发现在投票权重不集中的情况下能有效提升隐私保护。


<details>
  <summary>Details</summary>
Motivation: 传统投票系统中隐私等同于选票保密，但加权投票系统（如加密货币和web3系统）颠覆了这一概念，即使采用秘密投票，公布原始投票结果也会泄露投票者选择，因此需要新的隐私框架。

Method: 提出了B隐私概念，基于贿赂成本来衡量隐私保护效果；设计了通过给投票结果添加噪声来增强B隐私的机制；分析了3,582个DAO提案的投票数据，评估机制在不同投票权重分布下的有效性。

Result: 研究发现大投票者（鲸鱼）的存在限制了B隐私增强技术的效果；但在需要≥5个投票者联盟才能改变结果的提案中，该机制将B隐私提高了4.1倍的几何平均数。

Conclusion: 这项工作为加权投票系统提供了首个关于透明度-隐私权衡的原则性指导，揭示了投票权重集中对隐私机制的基本约束，补充了现有专注于选票保密的方法。

Abstract: In traditional, one-vote-per-person voting systems, privacy equates with
ballot secrecy: voting tallies are published, but individual voters' choices
are concealed.
  Voting systems that weight votes in proportion to token holdings, though, are
now prevalent in cryptocurrency and web3 systems. We show that these
weighted-voting systems overturn existing notions of voter privacy. Our
experiments demonstrate that even with secret ballots, publishing raw tallies
often reveals voters' choices.
  Weighted voting thus requires a new framework for privacy. We introduce a
notion called B-privacy whose basis is bribery, a key problem in voting systems
today. B-privacy captures the economic cost to an adversary of bribing voters
based on revealed voting tallies.
  We propose a mechanism to boost B-privacy by noising voting tallies. We prove
bounds on its tradeoff between B-privacy and transparency, meaning
reported-tally accuracy. Analyzing 3,582 proposals across 30 Decentralized
Autonomous Organizations (DAOs), we find that the prevalence of large voters
("whales") limits the effectiveness of any B-Privacy-enhancing technique.
However, our mechanism proves to be effective in cases without extreme voting
weight concentration: among proposals requiring coalitions of $\geq5$ voters to
flip outcomes, our mechanism raises B-privacy by a geometric mean factor of
$4.1\times$.
  Our work offers the first principled guidance on transparency-privacy
tradeoffs in weighted-voting systems, complementing existing approaches that
focus on ballot secrecy and revealing fundamental constraints that voting
weight concentration imposes on privacy mechanisms.

</details>


### [41] [What if we could hot swap our Biometrics?](https://arxiv.org/abs/2509.17962)
*Jon Crowcroft,Anil Madhavapeddy,Chris Hicks,Richard Mortier,Vasilios Mavroudis*

Main category: cs.CR

TL;DR: 本文探讨了通过生物技术实时改写生物特征来撤销和更换身份的可能性，分析了这种技术的潜在积极用途和负面后果，特别是当生物特征变得容易伪造时对用户带来的风险。


<details>
  <summary>Details</summary>
Motivation: 研究动机是探索生物特征身份的可撤销性和可更换性，因为当前生物特征被认为是不可伪造的，但如果技术发展使其易于伪造，可能会对用户造成不利影响。

Method: 提出了基于新型生物技术的热交换身份机制，讨论了如果这种技术变得可用和负担得起的潜在用例和后果。

Result: 分析表明，如果生物特征变得更容易伪造，伪造他人生物特征的成本可能远低于更换自己生物特征的成本，这可能使生物特征对用户来说是一个不利的选择。

Conclusion: 尽管目前这种威胁是高度推测性的，但作者认为值得提出并考虑其潜在后果，以提前应对可能的技术发展带来的挑战。

Abstract: What if you could really revoke your actual biometric identity, and install a
new one, by live rewriting your biological self? We propose some novel
mechanisms for hot swapping identity based in novel biotechnology. We discuss
the potential positive use cases, and negative consequences if such technology
was to become available and affordable. Biometrics are selected on the basis
that they are supposed to be unfakeable, or at least not at reasonable cost. If
they become easier to fake, it may be much cheaper to fake someone else's
biometrics than it is for you to change your own biometrics if someone does
copy yours. This potentially makes biometrics a bad trade-off for the user. At
the time of writing, this threat is highly speculative, but we believe it is
worth raising and considering the potential consequences.

</details>


### [42] [The Reverse File System: Towards open cost-effective secure WORM storage devices for logging](https://arxiv.org/abs/2509.17969)
*Gorka Guardiola Múzquiz,Juan González-Gómez,Enrique Soriano-Salvador*

Main category: cs.CR

TL;DR: Socarrat是一种新型、经济高效的本地WORM存储解决方案，利用外部USB设备实现数据不可变性，无需专用硬件或软件。


<details>
  <summary>Details</summary>
Motivation: 传统WORM存储解决方案依赖昂贵的专用硬件，分布式方法存在拒绝服务漏洞和操作复杂性。需要一种安全、兼容且成本低廉的本地WORM存储方案。

Method: 采用基于反向文件系统的新方法，通过推断主机计算机高层文件系统操作，将WORM执行机制隔离在专用USB硬件模块中。使用单板计算机运行Linux并支持USB On-The-Go。

Result: 开发了Socarrat原型系统，用Go语言实现并作为自由/开源软件提供。在不同单板计算机上进行了完整的日志性能评估。

Conclusion: Socarrat显著减少了攻击面，即使特权攻击者也无法修改或删除存储数据，同时具备防篡改能力，为安全日志记录、合规存储等应用提供了可行的解决方案。

Abstract: Write Once Read Many (WORM) properties for storage devices are desirable to
ensure data immutability for applications such as secure logging, regulatory
compliance, archival storage, and other types of backup systems. WORM devices
guarantee that data, once written, cannot be altered or deleted. However,
implementing secure and compatible WORM storage remains a challenge.
Traditional solutions often rely on specialized hardware, which is either
costly, closed, or inaccessible to the general public. Distributed approaches,
while promising, introduce additional risks such as denial-of-service
vulnerabilities and operational complexity. We introduce Socarrat, a novel,
cost-effective, and local WORM storage solution that leverages a simple
external USB device (specifically, a single-board computer running Linux with
USB On-The-Go support). The resulting device can be connected via USB,
appearing as an ordinary external disk formatted with an ext4 or exFAT file
system, without requiring any specialized software or drivers. By isolating the
WORM enforcement mechanism in a dedicated USB hardware module, Socarrat
significantly reduces the attack surface and ensures that even privileged
attackers cannot modify or erase stored data. In addition to the WORM capacity,
the system is designed to be tamper-evident, becoming resilient against
advanced attacks. This work describes a novel approach, the Reverse File
System, based on inferring the file system operations occurring at higher
layers in the host computer where Socarrat is mounted. The paper also describes
the current Socarrat prototype, implemented in Go and available as free/libre
software. Finally, it provides a complete evaluation of the logging performance
on different single-board computers.

</details>


### [43] [Synth-MIA: A Testbed for Auditing Privacy Leakage in Tabular Data Synthesis](https://arxiv.org/abs/2509.18014)
*Joshua Ward,Xiaofeng Lin,Chi-Hua Wang,Guang Cheng*

Main category: cs.CR

TL;DR: 提出了Synth-MIA框架和开源库，用于系统评估表格生成模型的隐私泄露风险，通过集成13种成员推理攻击方法来统一审计隐私泄露。


<details>
  <summary>Details</summary>
Motivation: 现有的表格生成模型隐私评估方法存在挑战，相似性度量无法有效表征隐私风险，而成员推理攻击方法多样且难以一致应用，导致隐私风险被低估。

Method: 开发了统一的模型无关威胁框架Synth-MIA，通过集成13种攻击方法的开源Python库，提供Scikit-Learn风格的API来系统评估隐私泄露。

Result: 在最大的表格合成隐私基准测试中显示：更高的合成数据质量对应更大的隐私泄露；基于相似性的隐私指标与MIA结果相关性弱；差分隐私生成器PATEGAN在攻击下可能失效。

Conclusion: 在设计和使用表格生成模型时，基于MIA的隐私审计是必要的，Synth-MIA框架为实践者和研究者提供了系统化的隐私风险评估工具。

Abstract: Tabular Generative Models are often argued to preserve privacy by creating
synthetic datasets that resemble training data. However, auditing their
empirical privacy remains challenging, as commonly used similarity metrics fail
to effectively characterize privacy risk. Membership Inference Attacks (MIAs)
have recently emerged as a method for evaluating privacy leakage in synthetic
data, but their practical effectiveness is limited. Numerous attacks exist
across different threat models, each with distinct implementations targeting
various sources of privacy leakage, making them difficult to apply
consistently. Moreover, no single attack consistently outperforms the others,
leading to a routine underestimation of privacy risk.
  To address these issues, we propose a unified, model-agnostic threat
framework that deploys a collection of attacks to estimate the maximum
empirical privacy leakage in synthetic datasets. We introduce Synth-MIA, an
open-source Python library that streamlines this auditing process through a
novel testbed that integrates seamlessly into existing synthetic data
evaluation pipelines through a Scikit-Learn-like API. Our software implements
13 attack methods through a Scikit-Learn-like API, designed to enable fast
systematic estimation of privacy leakage for practitioners as well as
facilitate the development of new attacks and experiments for researchers.
  We demonstrate our framework's utility in the largest tabular synthesis
privacy benchmark to date, revealing that higher synthetic data quality
corresponds to greater privacy leakage, that similarity-based privacy metrics
show weak correlation with MIA results, and that the differentially private
generator PATEGAN can fail to preserve privacy under such attacks. This
underscores the necessity of MIA-based auditing when designing and deploying
Tabular Generative Models.

</details>


### [44] [STAFF: Stateful Taint-Assisted Full-system Firmware Fuzzing](https://arxiv.org/abs/2509.18039)
*Alessio Izzillo,Riccardo Lazzeretti,Emilio Coppa*

Main category: cs.CR

TL;DR: STAFF是一个嵌入式Linux固件模糊测试框架，通过用户驱动的多请求记录、进程间依赖检测和协议感知的污点引导模糊测试，发现涉及多个网络请求和不同固件守护程序的漏洞。


<details>
  <summary>Details</summary>
Motivation: 现代嵌入式Linux设备使用复杂的软件栈，但现有模糊测试方案主要测试单个进程，忽略了守护程序之间的深度依赖关系和持久内部状态，导致安全测试不充分。

Method: STAFF采用三个关键技术：(a)用户驱动的多请求记录，监控用户与仿真固件的交互；(b)进程内和进程间依赖检测，使用全系统污点分析跟踪输入字节对用户空间状态的影响；(c)协议感知的污点引导模糊测试，基于识别的依赖关系对请求序列进行变异。

Result: 在15个基于Linux的固件目标上评估，STAFF发现了42个涉及多个网络请求和不同固件守护程序的漏洞，在发现漏洞的数量和可复现性方面显著优于现有最先进的模糊测试方案。

Conclusion: STAFF框架能够有效发现嵌入式Linux固件中涉及复杂交互的漏洞，填补了现有模糊测试方案在测试深度依赖关系方面的空白。

Abstract: Modern embedded Linux devices, such as routers, IP cameras, and IoT gateways,
rely on complex software stacks where numerous daemons interact to provide
services. Testing these devices is crucial from a security perspective since
vendors often use custom closed- or open-source software without documenting
releases and patches. Recent coverage-guided fuzzing solutions primarily test
individual processes, ignoring deep dependencies between daemons and their
persistent internal state. This article presents STAFF, a firmware fuzzing
framework for discovering bugs in Linux-based firmware built around three key
ideas: (a) user-driven multi-request recording, which monitors user
interactions with emulated firmware to capture request sequences involving
application-layer protocols (e.g., HTTP); (b) intra- and inter-process
dependency detection, which uses whole-system taint analysis to track how input
bytes influence user-space states, including files, sockets, and memory areas;
(c) protocol-aware taint-guided fuzzing, which applies mutations to request
sequences based on identified dependencies, exploiting multi-staged forkservers
to efficiently checkpoint protocol states. When evaluating STAFF on 15
Linux-based firmware targets, it identifies 42 bugs involving multiple network
requests and different firmware daemons, significantly outperforming existing
state-of-the-art fuzzing solutions in both the number and reproducibility of
discovered bugs.

</details>


### [45] [Hybrid Reputation Aggregation: A Robust Defense Mechanism for Adversarial Federated Learning in 5G and Edge Network Environments](https://arxiv.org/abs/2509.18044)
*Saeid Sheikhi,Panos Kostakos,Lauri Loven*

Main category: cs.CR

TL;DR: 本文提出了混合信誉聚合(HRA)机制，用于防御5G和边缘网络中联邦学习面临的各种对抗性攻击，无需预先知道攻击类型。HRA结合几何异常检测和基于动量的信誉跟踪，在多个数据集上表现出优于现有聚合方法的性能。


<details>
  <summary>Details</summary>
Motivation: 5G和边缘网络环境中的联邦学习面临严重的安全威胁，恶意参与者可以进行标签翻转、注入后门触发器或发起Sybil攻击来破坏全局模型。现有方法通常针对特定攻击类型设计，缺乏通用性。

Method: HRA采用混合方法：1）通过基于距离的几何分析检测异常模型更新；2）基于历史行为持续更新每个客户端的信任评分。这种双重机制能够自适应过滤可疑更新并对不可靠客户端进行长期惩罚。

Result: 在大型专有5G网络数据集(300万+记录)和NF-CSE-CIC-IDS2018基准测试中，HRA实现了高达98.66%和96.60%的鲁棒全局模型准确率，显著优于Krum、Trimmed Mean和Bulyan等最先进聚合器。消融研究显示完整混合系统的准确率为98.66%，而仅异常检测和仅信誉跟踪的变体分别降至84.77%和78.52%。

Conclusion: HRA在5G/边缘联邦学习部署中展现出增强的韧性和鲁棒性，即使在严重的对抗条件下也能保持高性能，验证了双重机制方法的协同价值。

Abstract: Federated Learning (FL) in 5G and edge network environments face severe
security threats from adversarial clients. Malicious participants can perform
label flipping, inject backdoor triggers, or launch Sybil attacks to corrupt
the global model. This paper introduces Hybrid Reputation Aggregation (HRA), a
novel robust aggregation mechanism designed to defend against diverse
adversarial behaviors in FL without prior knowledge of the attack type. HRA
combines geometric anomaly detection with momentum-based reputation tracking of
clients. In each round, it detects outlier model updates via distance-based
geometric analysis while continuously updating a trust score for each client
based on historical behavior. This hybrid approach enables adaptive filtering
of suspicious updates and long-term penalization of unreliable clients,
countering attacks ranging from backdoor insertions to random noise Byzantine
failures. We evaluate HRA on a large-scale proprietary 5G network dataset (3M+
records) and the widely used NF-CSE-CIC-IDS2018 benchmark under diverse
adversarial attack scenarios. Experimental results reveal that HRA achieves
robust global model accuracy of up to 98.66% on the 5G dataset and 96.60% on
NF-CSE-CIC-IDS2018, outperforming state-of-the-art aggregators such as Krum,
Trimmed Mean, and Bulyan by significant margins. Our ablation studies further
demonstrate that the full hybrid system achieves 98.66% accuracy, while the
anomaly-only and reputation-only variants drop to 84.77% and 78.52%,
respectively, validating the synergistic value of our dual-mechanism approach.
This demonstrates HRA's enhanced resilience and robustness in 5G/edge federated
learning deployments, even under significant adversarial conditions.

</details>
