{"id": "2601.05293", "categories": ["cs.CR", "cs.AI"], "pdf": "https://arxiv.org/pdf/2601.05293", "abs": "https://arxiv.org/abs/2601.05293", "authors": ["Sahaya Jestus Lazer", "Kshitiz Aryal", "Maanak Gupta", "Elisa Bertino"], "title": "A Survey of Agentic AI and Cybersecurity: Challenges, Opportunities and Use-case Prototypes", "comment": null, "summary": "Agentic AI marks an important transition from single-step generative models to systems capable of reasoning, planning, acting, and adapting over long-lasting tasks. By integrating memory, tool use, and iterative decision cycles, these systems enable continuous, autonomous workflows in real-world environments. This survey examines the implications of agentic AI for cybersecurity. On the defensive side, agentic capabilities enable continuous monitoring, autonomous incident response, adaptive threat hunting, and fraud detection at scale. Conversely, the same properties amplify adversarial power by accelerating reconnaissance, exploitation, coordination, and social-engineering attacks. These dual-use dynamics expose fundamental gaps in existing governance, assurance, and accountability mechanisms, which were largely designed for non-autonomous and short-lived AI systems. To address these challenges, we survey emerging threat models, security frameworks, and evaluation pipelines tailored to agentic systems, and analyze systemic risks including agent collusion, cascading failures, oversight evasion, and memory poisoning. Finally, we present three representative use-case implementations that illustrate how agentic AI behaves in practical cybersecurity workflows, and how design choices shape reliability, safety, and operational effectiveness.", "AI": {"tldr": "\u8be5\u8c03\u67e5\u5206\u6790\u4e86\u667a\u80fd\u4f53AI\u5bf9\u7f51\u7edc\u5b89\u5168\u7684\u5f71\u54cd\uff0c\u63a2\u8ba8\u4e86\u5176\u5728\u9632\u5fa1\u548c\u653b\u51fb\u65b9\u9762\u7684\u53cc\u91cd\u7528\u9014\uff0c\u4ee5\u53ca\u7531\u6b64\u4ea7\u751f\u7684\u6cbb\u7406\u6311\u6218\u548c\u7cfb\u7edf\u6027\u98ce\u9669\u3002", "motivation": "\u667a\u80fd\u4f53AI\u4ece\u5355\u6b65\u751f\u6210\u6a21\u578b\u8f6c\u5411\u80fd\u591f\u63a8\u7406\u3001\u89c4\u5212\u3001\u884c\u52a8\u548c\u9002\u5e94\u7684\u7cfb\u7edf\uff0c\u8fd9\u79cd\u8f6c\u53d8\u5bf9\u7f51\u7edc\u5b89\u5168\u4ea7\u751f\u4e86\u6df1\u8fdc\u5f71\u54cd\u3002\u9700\u8981\u7814\u7a76\u667a\u80fd\u4f53AI\u5728\u7f51\u7edc\u5b89\u5168\u4e2d\u7684\u53cc\u91cd\u7528\u9014\u7279\u6027\uff0c\u4ee5\u53ca\u73b0\u6709\u6cbb\u7406\u673a\u5236\u5982\u4f55\u5e94\u5bf9\u8fd9\u4e9b\u65b0\u578b\u81ea\u4e3b\u7cfb\u7edf\u7684\u6311\u6218\u3002", "method": "\u901a\u8fc7\u8c03\u67e5\u65b0\u5174\u5a01\u80c1\u6a21\u578b\u3001\u5b89\u5168\u6846\u67b6\u548c\u8bc4\u4f30\u6d41\u7a0b\uff0c\u5206\u6790\u667a\u80fd\u4f53\u7cfb\u7edf\u7279\u6709\u7684\u7cfb\u7edf\u6027\u98ce\u9669\uff0c\u5e76\u5c55\u793a\u4e09\u4e2a\u4ee3\u8868\u6027\u7528\u4f8b\u5b9e\u73b0\uff0c\u8bf4\u660e\u667a\u80fd\u4f53AI\u5728\u5b9e\u9645\u7f51\u7edc\u5b89\u5168\u5de5\u4f5c\u6d41\u7a0b\u4e2d\u7684\u884c\u4e3a\u3002", "result": "\u667a\u80fd\u4f53AI\u5728\u9632\u5fa1\u65b9\u9762\u80fd\u591f\u5b9e\u73b0\u6301\u7eed\u76d1\u63a7\u3001\u81ea\u4e3b\u4e8b\u4ef6\u54cd\u5e94\u3001\u81ea\u9002\u5e94\u5a01\u80c1\u72e9\u730e\u548c\u5927\u89c4\u6a21\u6b3a\u8bc8\u68c0\u6d4b\uff1b\u5728\u653b\u51fb\u65b9\u9762\u5219\u589e\u5f3a\u4e86\u4fa6\u5bdf\u3001\u5229\u7528\u3001\u534f\u8c03\u548c\u793e\u4f1a\u5de5\u7a0b\u653b\u51fb\u80fd\u529b\u3002\u73b0\u6709\u6cbb\u7406\u3001\u4fdd\u8bc1\u548c\u95ee\u8d23\u673a\u5236\u5b58\u5728\u6839\u672c\u6027\u5dee\u8ddd\uff0c\u65e0\u6cd5\u6709\u6548\u5e94\u5bf9\u81ea\u4e3b\u7cfb\u7edf\u7684\u6311\u6218\u3002", "conclusion": "\u667a\u80fd\u4f53AI\u5728\u7f51\u7edc\u5b89\u5168\u9886\u57df\u5177\u6709\u53cc\u91cd\u7528\u9014\u7279\u6027\uff0c\u9700\u8981\u4e13\u95e8\u7684\u5b89\u5168\u6846\u67b6\u548c\u8bc4\u4f30\u6d41\u7a0b\u6765\u5e94\u5bf9\u7cfb\u7edf\u6027\u98ce\u9669\u3002\u8bbe\u8ba1\u9009\u62e9\u76f4\u63a5\u5f71\u54cd\u667a\u80fd\u4f53AI\u7684\u53ef\u9760\u6027\u3001\u5b89\u5168\u6027\u548c\u64cd\u4f5c\u6709\u6548\u6027\uff0c\u5fc5\u987b\u5efa\u7acb\u9002\u5e94\u81ea\u4e3b\u7cfb\u7edf\u7279\u6027\u7684\u6cbb\u7406\u673a\u5236\u3002"}}
{"id": "2601.05339", "categories": ["cs.CR", "cs.AI"], "pdf": "https://arxiv.org/pdf/2601.05339", "abs": "https://arxiv.org/abs/2601.05339", "authors": ["Badhan Chandra Das", "Md Tasnim Jawad", "Joaquin Molto", "M. Hadi Amini", "Yanzhao Wu"], "title": "Multi-turn Jailbreaking Attack in Multi-Modal Large Language Models", "comment": null, "summary": "In recent years, the security vulnerabilities of Multi-modal Large Language Models (MLLMs) have become a serious concern in the Generative Artificial Intelligence (GenAI) research. These highly intelligent models, capable of performing multi-modal tasks with high accuracy, are also severely susceptible to carefully launched security attacks, such as jailbreaking attacks, which can manipulate model behavior and bypass safety constraints. This paper introduces MJAD-MLLMs, a holistic framework that systematically analyzes the proposed Multi-turn Jailbreaking Attacks and multi-LLM-based defense techniques for MLLMs. In this paper, we make three original contributions. First, we introduce a novel multi-turn jailbreaking attack to exploit the vulnerabilities of the MLLMs under multi-turn prompting. Second, we propose a novel fragment-optimized and multi-LLM defense mechanism, called FragGuard, to effectively mitigate jailbreaking attacks in the MLLMs. Third, we evaluate the efficacy of the proposed attacks and defenses through extensive experiments on several state-of-the-art (SOTA) open-source and closed-source MLLMs and benchmark datasets, and compare their performance with the existing techniques.", "AI": {"tldr": "MJAD-MLLMs\u6846\u67b6\u7cfb\u7edf\u5206\u6790\u591a\u6a21\u6001\u5927\u8bed\u8a00\u6a21\u578b\u7684\u591a\u8f6e\u8d8a\u72f1\u653b\u51fb\u4e0e\u9632\u5fa1\u6280\u672f\uff0c\u63d0\u51fa\u65b0\u578b\u591a\u8f6e\u653b\u51fb\u65b9\u6cd5\u548c\u57fa\u4e8e\u591aLLM\u7684\u9632\u5fa1\u673a\u5236FragGuard\u3002", "motivation": "\u591a\u6a21\u6001\u5927\u8bed\u8a00\u6a21\u578b\u867d\u7136\u667a\u80fd\u4e14\u51c6\u786e\uff0c\u4f46\u5b58\u5728\u4e25\u91cd\u5b89\u5168\u6f0f\u6d1e\uff0c\u7279\u522b\u662f\u5bb9\u6613\u53d7\u5230\u7cbe\u5fc3\u8bbe\u8ba1\u7684\u8d8a\u72f1\u653b\u51fb\uff0c\u8fd9\u4e9b\u653b\u51fb\u80fd\u64cd\u7eb5\u6a21\u578b\u884c\u4e3a\u5e76\u7ed5\u8fc7\u5b89\u5168\u7ea6\u675f\uff0c\u9700\u8981\u7cfb\u7edf\u6027\u7684\u5b89\u5168\u5206\u6790\u6846\u67b6\u3002", "method": "\u63d0\u51faMJAD-MLLMs\u6574\u4f53\u6846\u67b6\uff0c\u5305\u542b\u4e09\u4e2a\u4e3b\u8981\u8d21\u732e\uff1a1) \u65b0\u578b\u591a\u8f6e\u8d8a\u72f1\u653b\u51fb\u65b9\u6cd5\uff0c\u5229\u7528\u591a\u8f6e\u63d0\u793a\u5229\u7528MLLM\u6f0f\u6d1e\uff1b2) \u57fa\u4e8e\u591aLLM\u7684\u9632\u5fa1\u673a\u5236FragGuard\uff0c\u91c7\u7528\u7247\u6bb5\u4f18\u5316\u7b56\u7565\uff1b3) \u5728\u591a\u4e2aSOTA\u5f00\u6e90\u548c\u95ed\u6e90MLLM\u53ca\u57fa\u51c6\u6570\u636e\u96c6\u4e0a\u8fdb\u884c\u5e7f\u6cdb\u5b9e\u9a8c\u8bc4\u4f30\u3002", "result": "\u901a\u8fc7\u5b9e\u9a8c\u8bc4\u4f30\u9a8c\u8bc1\u4e86\u6240\u63d0\u653b\u51fb\u548c\u9632\u5fa1\u65b9\u6cd5\u7684\u6709\u6548\u6027\uff0c\u5e76\u4e0e\u73b0\u6709\u6280\u672f\u8fdb\u884c\u4e86\u6027\u80fd\u6bd4\u8f83\uff0c\u5c55\u793a\u4e86MJAD-MLLMs\u6846\u67b6\u5728\u5206\u6790MLLM\u5b89\u5168\u6f0f\u6d1e\u548c\u9632\u5fa1\u8d8a\u72f1\u653b\u51fb\u65b9\u9762\u7684\u80fd\u529b\u3002", "conclusion": "MJAD-MLLMs\u4e3aMLLM\u5b89\u5168\u7814\u7a76\u63d0\u4f9b\u4e86\u7cfb\u7edf\u6027\u5206\u6790\u6846\u67b6\uff0c\u63d0\u51fa\u7684\u591a\u8f6e\u8d8a\u72f1\u653b\u51fb\u548cFragGuard\u9632\u5fa1\u673a\u5236\u4e3a\u89e3\u51b3MLLM\u5b89\u5168\u6f0f\u6d1e\u95ee\u9898\u63d0\u4f9b\u4e86\u6709\u6548\u65b9\u6848\uff0c\u5bf9\u63d0\u5347\u751f\u6210\u5f0fAI\u5b89\u5168\u6027\u5177\u6709\u91cd\u8981\u610f\u4e49\u3002"}}
{"id": "2601.05445", "categories": ["cs.CR", "cs.LG"], "pdf": "https://arxiv.org/pdf/2601.05445", "abs": "https://arxiv.org/abs/2601.05445", "authors": ["Songze Li", "Ruishi He", "Xiaojun Jia", "Jun Wang", "Zhihui Fu"], "title": "Knowledge-Driven Multi-Turn Jailbreaking on Large Language Models", "comment": null, "summary": "Large Language Models (LLMs) face a significant threat from multi-turn jailbreak attacks, where adversaries progressively steer conversations to elicit harmful outputs. However, the practical effectiveness of existing attacks is undermined by several critical limitations: they struggle to maintain a coherent progression over long interactions, often losing track of what has been accomplished and what remains to be done; they rely on rigid or pre-defined patterns, and fail to adapt to the LLM's dynamic and unpredictable conversational state. To address these shortcomings, we introduce Mastermind, a multi-turn jailbreak framework that adopts a dynamic and self-improving approach. Mastermind operates in a closed loop of planning, execution, and reflection, enabling it to autonomously build and refine its knowledge of model vulnerabilities through interaction. It employs a hierarchical planning architecture that decouples high-level attack objectives from low-level tactical execution, ensuring long-term focus and coherence. This planning is guided by a knowledge repository that autonomously discovers and refines effective attack patterns by reflecting on interactive experiences. Mastermind leverages this accumulated knowledge to dynamically recombine and adapt attack vectors, dramatically improving both effectiveness and resilience. We conduct comprehensive experiments against state-of-the-art models, including GPT-5 and Claude 3.7 Sonnet. The results demonstrate that Mastermind significantly outperforms existing baselines, achieving substantially higher attack success rates and harmfulness ratings. Moreover, our framework exhibits notable resilience against multiple advanced defense mechanisms.", "AI": {"tldr": "Mastermind\u662f\u4e00\u4e2a\u591a\u8f6e\u8d8a\u72f1\u653b\u51fb\u6846\u67b6\uff0c\u91c7\u7528\u52a8\u6001\u81ea\u6539\u8fdb\u65b9\u6cd5\uff0c\u901a\u8fc7\u89c4\u5212-\u6267\u884c-\u53cd\u601d\u7684\u95ed\u73af\u7cfb\u7edf\uff0c\u663e\u8457\u63d0\u5347\u4e86\u5bf9\u5927\u578b\u8bed\u8a00\u6a21\u578b\u7684\u653b\u51fb\u6210\u529f\u7387\u3002", "motivation": "\u73b0\u6709\u591a\u8f6e\u8d8a\u72f1\u653b\u51fb\u5b58\u5728\u5173\u952e\u5c40\u9650\u6027\uff1a\u96be\u4ee5\u5728\u957f\u5bf9\u8bdd\u4e2d\u4fdd\u6301\u8fde\u8d2f\u8fdb\u5c55\uff0c\u4f9d\u8d56\u50f5\u5316\u9884\u5b9a\u4e49\u6a21\u5f0f\uff0c\u65e0\u6cd5\u9002\u5e94LLM\u52a8\u6001\u4e0d\u53ef\u9884\u6d4b\u7684\u5bf9\u8bdd\u72b6\u6001\u3002", "method": "\u91c7\u7528\u52a8\u6001\u81ea\u6539\u8fdb\u7684\u95ed\u73af\u6846\u67b6\uff0c\u5305\u542b\u89c4\u5212\u3001\u6267\u884c\u3001\u53cd\u601d\u4e09\u4e2a\u73af\u8282\u3002\u4f7f\u7528\u5206\u5c42\u89c4\u5212\u67b6\u6784\u5c06\u9ad8\u5c42\u653b\u51fb\u76ee\u6807\u4e0e\u4f4e\u5c42\u6218\u672f\u6267\u884c\u89e3\u8026\uff0c\u901a\u8fc7\u77e5\u8bc6\u5e93\u81ea\u4e3b\u53d1\u73b0\u548c\u4f18\u5316\u653b\u51fb\u6a21\u5f0f\uff0c\u52a8\u6001\u91cd\u7ec4\u548c\u9002\u5e94\u653b\u51fb\u5411\u91cf\u3002", "result": "\u5728GPT-5\u548cClaude 3.7 Sonnet\u7b49\u6700\u5148\u8fdb\u6a21\u578b\u4e0a\u7684\u5b9e\u9a8c\u8868\u660e\uff0cMastermind\u663e\u8457\u4f18\u4e8e\u73b0\u6709\u57fa\u7ebf\uff0c\u5b9e\u73b0\u4e86\u66f4\u9ad8\u7684\u653b\u51fb\u6210\u529f\u7387\u548c\u5371\u5bb3\u6027\u8bc4\u5206\uff0c\u5e76\u5bf9\u591a\u79cd\u9ad8\u7ea7\u9632\u5fa1\u673a\u5236\u8868\u73b0\u51fa\u663e\u8457\u97e7\u6027\u3002", "conclusion": "Mastermind\u901a\u8fc7\u52a8\u6001\u81ea\u6539\u8fdb\u7684\u95ed\u73af\u6846\u67b6\u6709\u6548\u89e3\u51b3\u4e86\u73b0\u6709\u591a\u8f6e\u8d8a\u72f1\u653b\u51fb\u7684\u5c40\u9650\u6027\uff0c\u663e\u8457\u63d0\u5347\u4e86\u653b\u51fb\u6548\u679c\u548c\u97e7\u6027\uff0c\u4e3aLLM\u5b89\u5168\u7814\u7a76\u63d0\u4f9b\u4e86\u91cd\u8981\u53c2\u8003\u3002"}}
{"id": "2601.05466", "categories": ["cs.CR", "cs.AI"], "pdf": "https://arxiv.org/pdf/2601.05466", "abs": "https://arxiv.org/abs/2601.05466", "authors": ["Zhaoqi Wang", "Zijian Zhang", "Daqing He", "Pengtao Kou", "Xin Li", "Jiamou Liu", "Jincheng An", "Yong Liu"], "title": "Jailbreaking Large Language Models through Iterative Tool-Disguised Attacks via Reinforcement Learning", "comment": null, "summary": "Large language models (LLMs) have demonstrated remarkable capabilities across diverse applications, however, they remain critically vulnerable to jailbreak attacks that elicit harmful responses violating human values and safety guidelines. Despite extensive research on defense mechanisms, existing safeguards prove insufficient against sophisticated adversarial strategies. In this work, we propose iMIST (\\underline{i}nteractive \\underline{M}ulti-step \\underline{P}rogre\\underline{s}sive \\underline{T}ool-disguised Jailbreak Attack), a novel adaptive jailbreak method that synergistically exploits vulnerabilities in current defense mechanisms. iMIST disguises malicious queries as normal tool invocations to bypass content filters, while simultaneously introducing an interactive progressive optimization algorithm that dynamically escalates response harmfulness through multi-turn dialogues guided by real-time harmfulness assessment. Our experiments on widely-used models demonstrate that iMIST achieves higher attack effectiveness, while maintaining low rejection rates. These results reveal critical vulnerabilities in current LLM safety mechanisms and underscore the urgent need for more robust defense strategies.", "AI": {"tldr": "iMIST\u662f\u4e00\u79cd\u65b0\u578b\u81ea\u9002\u5e94\u8d8a\u72f1\u653b\u51fb\u65b9\u6cd5\uff0c\u901a\u8fc7\u5c06\u6076\u610f\u67e5\u8be2\u4f2a\u88c5\u6210\u6b63\u5e38\u5de5\u5177\u8c03\u7528\u6765\u7ed5\u8fc7\u5185\u5bb9\u8fc7\u6ee4\u5668\uff0c\u540c\u65f6\u91c7\u7528\u4ea4\u4e92\u5f0f\u6e10\u8fdb\u4f18\u5316\u7b97\u6cd5\u52a8\u6001\u63d0\u5347\u54cd\u5e94\u5371\u5bb3\u6027\u3002", "motivation": "\u5c3d\u7ba1\u5927\u8bed\u8a00\u6a21\u578b\u5728\u5404\u79cd\u5e94\u7528\u4e2d\u8868\u73b0\u51fa\u8272\uff0c\u4f46\u5b83\u4eec\u4ecd\u7136\u6781\u6613\u53d7\u5230\u8d8a\u72f1\u653b\u51fb\uff0c\u8fd9\u4e9b\u653b\u51fb\u4f1a\u5f15\u53d1\u8fdd\u53cd\u4eba\u7c7b\u4ef7\u503c\u89c2\u548c\u5b89\u5168\u51c6\u5219\u7684\u6709\u5bb3\u54cd\u5e94\u3002\u73b0\u6709\u9632\u5fa1\u673a\u5236\u5bf9\u590d\u6742\u5bf9\u6297\u7b56\u7565\u7684\u9632\u62a4\u4e0d\u8db3\u3002", "method": "iMIST\u5c06\u6076\u610f\u67e5\u8be2\u4f2a\u88c5\u6210\u6b63\u5e38\u5de5\u5177\u8c03\u7528\u6765\u7ed5\u8fc7\u5185\u5bb9\u8fc7\u6ee4\u5668\uff0c\u540c\u65f6\u5f15\u5165\u4ea4\u4e92\u5f0f\u6e10\u8fdb\u4f18\u5316\u7b97\u6cd5\uff0c\u901a\u8fc7\u57fa\u4e8e\u5b9e\u65f6\u5371\u5bb3\u6027\u8bc4\u4f30\u7684\u591a\u8f6e\u5bf9\u8bdd\u52a8\u6001\u63d0\u5347\u54cd\u5e94\u5371\u5bb3\u6027\u3002", "result": "\u5b9e\u9a8c\u8868\u660eiMIST\u5728\u5e7f\u6cdb\u4f7f\u7528\u7684\u6a21\u578b\u4e0a\u5b9e\u73b0\u4e86\u66f4\u9ad8\u7684\u653b\u51fb\u6709\u6548\u6027\uff0c\u540c\u65f6\u4fdd\u6301\u8f83\u4f4e\u7684\u62d2\u7edd\u7387\u3002", "conclusion": "\u8fd9\u4e9b\u7ed3\u679c\u63ed\u793a\u4e86\u5f53\u524dLLM\u5b89\u5168\u673a\u5236\u7684\u5173\u952e\u6f0f\u6d1e\uff0c\u5e76\u5f3a\u8c03\u4e86\u5f00\u53d1\u66f4\u5f3a\u5927\u9632\u5fa1\u7b56\u7565\u7684\u7d27\u8feb\u6027\u3002"}}
{"id": "2601.05504", "categories": ["cs.CR", "cs.MA"], "pdf": "https://arxiv.org/pdf/2601.05504", "abs": "https://arxiv.org/abs/2601.05504", "authors": ["Balachandra Devarangadi Sunil", "Isheeta Sinha", "Piyush Maheshwari", "Shantanu Todmal", "Shreyan Malik", "Shuchi Mishra"], "title": "Memory Poisoning Attack and Defense on Memory Based LLM-Agents", "comment": null, "summary": "Large language model agents equipped with persistent memory are vulnerable to memory poisoning attacks, where adversaries inject malicious instructions through query only interactions that corrupt the agents long term memory and influence future responses. Recent work demonstrated that the MINJA (Memory Injection Attack) achieves over 95 % injection success rate and 70 % attack success rate under idealized conditions. However, the robustness of these attacks in realistic deployments and effective defensive mechanisms remain understudied. This work addresses these gaps through systematic empirical evaluation of memory poisoning attacks and defenses in Electronic Health Record (EHR) agents. We investigate attack robustness by varying three critical dimensions: initial memory state, number of indication prompts, and retrieval parameters. Our experiments on GPT-4o-mini, Gemini-2.0-Flash and Llama-3.1-8B-Instruct models using MIMIC-III clinical data reveal that realistic conditions with pre-existing legitimate memories dramatically reduce attack effectiveness. We then propose and evaluate two novel defense mechanisms: (1) Input/Output Moderation using composite trust scoring across multiple orthogonal signals, and (2) Memory Sanitization with trust-aware retrieval employing temporal decay and pattern-based filtering. Our defense evaluation reveals that effective memory sanitization requires careful trust threshold calibration to prevent both overly conservative rejection (blocking all entries) and insufficient filtering (missing subtle attacks), establishing important baselines for future adaptive defense mechanisms. These findings provide crucial insights for securing memory-augmented LLM agents in production environments.", "AI": {"tldr": "\u8be5\u8bba\u6587\u7cfb\u7edf\u8bc4\u4f30\u4e86LLM\u667a\u80fd\u4f53\u5728\u7535\u5b50\u5065\u5eb7\u8bb0\u5f55\u573a\u666f\u4e2d\u7684\u8bb0\u5fc6\u4e2d\u6bd2\u653b\u51fb\u4e0e\u9632\u5fa1\u673a\u5236\uff0c\u53d1\u73b0\u73b0\u5b9e\u6761\u4ef6\u4e0b\u653b\u51fb\u6548\u679c\u663e\u8457\u964d\u4f4e\uff0c\u5e76\u63d0\u51fa\u4e86\u57fa\u4e8e\u4fe1\u4efb\u8bc4\u5206\u7684\u8f93\u5165\u8f93\u51fa\u5ba1\u6838\u4e0e\u8bb0\u5fc6\u51c0\u5316\u4e24\u79cd\u9632\u5fa1\u65b9\u6cd5\u3002", "motivation": "\u73b0\u6709\u7814\u7a76\u8868\u660e\u8bb0\u5fc6\u4e2d\u6bd2\u653b\u51fb\u5728\u7406\u60f3\u6761\u4ef6\u4e0b\u6210\u529f\u7387\u5f88\u9ad8\uff0c\u4f46\u7f3a\u4e4f\u5bf9\u73b0\u5b9e\u90e8\u7f72\u4e2d\u653b\u51fb\u9c81\u68d2\u6027\u7684\u7814\u7a76\uff0c\u4ee5\u53ca\u5728\u7535\u5b50\u5065\u5eb7\u8bb0\u5f55\u7b49\u654f\u611f\u5e94\u7528\u573a\u666f\u4e2d\u7684\u6709\u6548\u9632\u5fa1\u673a\u5236\u3002", "method": "\u901a\u8fc7\u7cfb\u7edf\u5b9e\u8bc1\u8bc4\u4f30\uff0c\u7814\u7a76\u653b\u51fb\u9c81\u68d2\u6027\u7684\u4e09\u4e2a\u5173\u952e\u7ef4\u5ea6\uff1a\u521d\u59cb\u8bb0\u5fc6\u72b6\u6001\u3001\u63d0\u793a\u6570\u91cf\u548c\u68c0\u7d22\u53c2\u6570\u3002\u5728GPT-4o-mini\u3001Gemini-2.0-Flash\u548cLlama-3.1-8B-Instruct\u6a21\u578b\u4e0a\u4f7f\u7528MIMIC-III\u4e34\u5e8a\u6570\u636e\u8fdb\u884c\u5b9e\u9a8c\uff0c\u5e76\u63d0\u51fa\u4e86\u4e24\u79cd\u9632\u5fa1\u673a\u5236\uff1a\u57fa\u4e8e\u591a\u6b63\u4ea4\u4fe1\u53f7\u7684\u8f93\u5165\u8f93\u51fa\u5ba1\u6838\u548c\u57fa\u4e8e\u65f6\u95f4\u8870\u51cf\u4e0e\u6a21\u5f0f\u8fc7\u6ee4\u7684\u4fe1\u4efb\u611f\u77e5\u8bb0\u5fc6\u51c0\u5316\u3002", "result": "\u73b0\u5b9e\u6761\u4ef6\u4e0b\uff08\u5b58\u5728\u9884\u5148\u5408\u6cd5\u8bb0\u5fc6\uff09\u653b\u51fb\u6548\u679c\u663e\u8457\u964d\u4f4e\u3002\u9632\u5fa1\u8bc4\u4f30\u663e\u793a\u6709\u6548\u7684\u8bb0\u5fc6\u51c0\u5316\u9700\u8981\u7cbe\u7ec6\u7684\u4fe1\u4efb\u9608\u503c\u6821\u51c6\uff0c\u4ee5\u907f\u514d\u8fc7\u5ea6\u4fdd\u5b88\uff08\u62d2\u7edd\u6240\u6709\u6761\u76ee\uff09\u6216\u8fc7\u6ee4\u4e0d\u8db3\uff08\u9057\u6f0f\u5fae\u5999\u653b\u51fb\uff09\u3002", "conclusion": "\u7814\u7a76\u4e3a\u751f\u4ea7\u73af\u5883\u4e2d\u8bb0\u5fc6\u589e\u5f3a\u578bLLM\u667a\u80fd\u4f53\u7684\u5b89\u5168\u9632\u62a4\u63d0\u4f9b\u4e86\u91cd\u8981\u57fa\u51c6\u548c\u89c1\u89e3\uff0c\u5f3a\u8c03\u4e86\u5728\u73b0\u5b9e\u6761\u4ef6\u4e0b\u653b\u51fb\u9c81\u68d2\u6027\u7684\u5c40\u9650\u6027\u4ee5\u53ca\u9632\u5fa1\u673a\u5236\u9700\u8981\u7cbe\u7ec6\u8c03\u6821\u7684\u91cd\u8981\u6027\u3002"}}
{"id": "2601.05534", "categories": ["cs.CR"], "pdf": "https://arxiv.org/pdf/2601.05534", "abs": "https://arxiv.org/abs/2601.05534", "authors": ["Nicholas Papadopoulos"], "title": "Blockchain Verifiable Proof of Quantum Supremacy as a Trigger for Quantum-Secure Signatures", "comment": "12 pages, 2 figures, 1 table", "summary": "Blockchain is a decentralized, distributed ledger technology that ensures transparency, security, and immutability through cryptographic techniques. However, advancements in quantum computing threaten the security of classical cryptographic schemes, jeopardizing blockchain integrity once cryptographic quantum supremacy is achieved. This milestone, defined here as the realization of quantum computers to solve practical cryptographic problems, would render existing security standards vulnerable, exposing blockchain assets (currency, data, etc.) to fraud and theft. To address this risk, we propose and implement a smart contract deployable on the Ethereum blockchain, having the ability to run applications on its blockchain, that generates classically intractable puzzles by probabilistically generating large, hard-to-factor numbers without requiring secret information. This contract then serves two purposes: to establish a mechanism (1) for a trustless, unbiased proof of cryptographic quantum supremacy by verifying solutions to these puzzles, and (2) to protect user funds on Ethereum by triggering quantum-secure fallback protocols upon detecting cryptographic quantum supremacy, since it is desirable to wait as long as possible to fall back to a quantum-secure scheme because of its inherent additional cost and complexity. These mechanisms demonstrate the ability to identify cryptographic vulnerabilities and ensure a smooth transition to quantum-secure standards, safeguarding blockchain assets in a post-quantum era.", "AI": {"tldr": "\u8bba\u6587\u63d0\u51fa\u5e76\u5b9e\u73b0\u4e86\u4e00\u4e2a\u90e8\u7f72\u5728\u4ee5\u592a\u574a\u4e0a\u7684\u667a\u80fd\u5408\u7ea6\uff0c\u901a\u8fc7\u751f\u6210\u96be\u4ee5\u5206\u89e3\u7684\u5927\u6570\u96be\u9898\u6765\u68c0\u6d4b\u91cf\u5b50\u8ba1\u7b97\u4f18\u52bf\uff0c\u5e76\u89e6\u53d1\u91cf\u5b50\u5b89\u5168\u56de\u9000\u534f\u8bae\u4ee5\u4fdd\u62a4\u533a\u5757\u94fe\u8d44\u4ea7\u3002", "motivation": "\u91cf\u5b50\u8ba1\u7b97\u7684\u8fdb\u6b65\u5a01\u80c1\u5230\u7ecf\u5178\u5bc6\u7801\u5b66\u65b9\u6848\u7684\u5b89\u5168\u6027\uff0c\u4e00\u65e6\u5b9e\u73b0\u5bc6\u7801\u5b66\u91cf\u5b50\u4f18\u52bf\uff0c\u73b0\u6709\u533a\u5757\u94fe\u5b89\u5168\u6807\u51c6\u5c06\u53d8\u5f97\u8106\u5f31\uff0c\u53ef\u80fd\u5bfc\u81f4\u8d44\u4ea7\u88ab\u76d7\u6216\u6b3a\u8bc8\u3002\u9700\u8981\u4e00\u79cd\u673a\u5236\u6765\u68c0\u6d4b\u91cf\u5b50\u4f18\u52bf\u5e76\u5e73\u6ed1\u8fc7\u6e21\u5230\u91cf\u5b50\u5b89\u5168\u6807\u51c6\u3002", "method": "\u8bbe\u8ba1\u5e76\u5b9e\u73b0\u4e86\u4e00\u4e2a\u4ee5\u592a\u574a\u667a\u80fd\u5408\u7ea6\uff0c\u8be5\u5408\u7ea6\u80fd\u591f\u6982\u7387\u6027\u5730\u751f\u6210\u96be\u4ee5\u5206\u89e3\u7684\u5927\u6570\uff08\u65e0\u9700\u79d8\u5bc6\u4fe1\u606f\uff09\uff0c\u521b\u5efa\u7ecf\u5178\u8ba1\u7b97\u96be\u4ee5\u89e3\u51b3\u7684\u96be\u9898\u3002\u8be5\u5408\u7ea6\u6709\u4e24\u4e2a\u529f\u80fd\uff1a(1) \u901a\u8fc7\u9a8c\u8bc1\u8fd9\u4e9b\u96be\u9898\u7684\u89e3\u51b3\u65b9\u6848\u6765\u5efa\u7acb\u65e0\u4fe1\u4efb\u3001\u65e0\u504f\u89c1\u7684\u5bc6\u7801\u5b66\u91cf\u5b50\u4f18\u52bf\u8bc1\u660e\u673a\u5236\uff1b(2) \u5728\u68c0\u6d4b\u5230\u5bc6\u7801\u5b66\u91cf\u5b50\u4f18\u52bf\u65f6\u89e6\u53d1\u91cf\u5b50\u5b89\u5168\u56de\u9000\u534f\u8bae\u6765\u4fdd\u62a4\u7528\u6237\u8d44\u91d1\u3002", "result": "\u6210\u529f\u5b9e\u73b0\u4e86\u80fd\u591f\u751f\u6210\u7ecf\u5178\u8ba1\u7b97\u96be\u4ee5\u5206\u89e3\u7684\u5927\u6570\u96be\u9898\u7684\u667a\u80fd\u5408\u7ea6\uff0c\u5efa\u7acb\u4e86\u91cf\u5b50\u4f18\u52bf\u68c0\u6d4b\u673a\u5236\uff0c\u5e76\u8bbe\u8ba1\u4e86\u91cf\u5b50\u5b89\u5168\u56de\u9000\u534f\u8bae\u89e6\u53d1\u7cfb\u7edf\uff0c\u4e3a\u533a\u5757\u94fe\u5411\u91cf\u5b50\u5b89\u5168\u6807\u51c6\u8fc7\u6e21\u63d0\u4f9b\u4e86\u53ef\u884c\u65b9\u6848\u3002", "conclusion": "\u8be5\u667a\u80fd\u5408\u7ea6\u7cfb\u7edf\u80fd\u591f\u8bc6\u522b\u5bc6\u7801\u5b66\u6f0f\u6d1e\uff0c\u786e\u4fdd\u533a\u5757\u94fe\u8d44\u4ea7\u5728\u540e\u91cf\u5b50\u65f6\u4ee3\u7684\u5b89\u5168\uff0c\u4e3a\u533a\u5757\u94fe\u5411\u91cf\u5b50\u5b89\u5168\u6807\u51c6\u7684\u5e73\u6ed1\u8fc7\u6e21\u63d0\u4f9b\u4e86\u5b9e\u7528\u89e3\u51b3\u65b9\u6848\uff0c\u540c\u65f6\u907f\u514d\u4e86\u8fc7\u65e9\u91c7\u7528\u91cf\u5b50\u5b89\u5168\u65b9\u6848\u5e26\u6765\u7684\u989d\u5916\u6210\u672c\u548c\u590d\u6742\u6027\u3002"}}
{"id": "2601.05587", "categories": ["cs.CR", "cs.AI"], "pdf": "https://arxiv.org/pdf/2601.05587", "abs": "https://arxiv.org/abs/2601.05587", "authors": ["Jingxiao Yang", "Ping He", "Tianyu Du", "Sun Bing", "Xuhong Zhang"], "title": "HogVul: Black-box Adversarial Code Generation Framework Against LM-based Vulnerability Detectors", "comment": "AAAI26", "summary": "Recent advances in software vulnerability detection have been driven by Language Model (LM)-based approaches. However, these models remain vulnerable to adversarial attacks that exploit lexical and syntax perturbations, allowing critical flaws to evade detection. Existing black-box attacks on LM-based vulnerability detectors primarily rely on isolated perturbation strategies, limiting their ability to efficiently explore the adversarial code space for optimal perturbations. To bridge this gap, we propose HogVul, a black-box adversarial code generation framework that integrates both lexical and syntax perturbations under a unified dual-channel optimization strategy driven by Particle Swarm Optimization (PSO). By systematically coordinating two-level perturbations, HogVul effectively expands the search space for adversarial examples, enhancing the attack efficacy. Extensive experiments on four benchmark datasets demonstrate that HogVul achieves an average attack success rate improvement of 26.05\\% over state-of-the-art baseline methods. These findings highlight the potential of hybrid optimization strategies in exposing model vulnerabilities.", "AI": {"tldr": "HogVul\u662f\u4e00\u4e2a\u57fa\u4e8e\u7c92\u5b50\u7fa4\u4f18\u5316\u7684\u9ed1\u76d2\u5bf9\u6297\u4ee3\u7801\u751f\u6210\u6846\u67b6\uff0c\u901a\u8fc7\u7edf\u4e00\u7684\u53cc\u901a\u9053\u4f18\u5316\u7b56\u7565\u6574\u5408\u8bcd\u6c47\u548c\u8bed\u6cd5\u6270\u52a8\uff0c\u663e\u8457\u63d0\u9ad8\u4e86\u5bf9\u57fa\u4e8e\u8bed\u8a00\u6a21\u578b\u7684\u6f0f\u6d1e\u68c0\u6d4b\u5668\u7684\u653b\u51fb\u6210\u529f\u7387\u3002", "motivation": "\u5f53\u524d\u57fa\u4e8e\u8bed\u8a00\u6a21\u578b\u7684\u6f0f\u6d1e\u68c0\u6d4b\u5668\u5bb9\u6613\u53d7\u5230\u5229\u7528\u8bcd\u6c47\u548c\u8bed\u6cd5\u6270\u52a8\u7684\u5bf9\u6297\u653b\u51fb\uff0c\u73b0\u6709\u9ed1\u76d2\u653b\u51fb\u65b9\u6cd5\u4e3b\u8981\u4f9d\u8d56\u5b64\u7acb\u7684\u6270\u52a8\u7b56\u7565\uff0c\u9650\u5236\u4e86\u5728\u5bf9\u6297\u4ee3\u7801\u7a7a\u95f4\u4e2d\u9ad8\u6548\u63a2\u7d22\u6700\u4f18\u6270\u52a8\u7684\u80fd\u529b\u3002", "method": "\u63d0\u51faHogVul\u6846\u67b6\uff0c\u91c7\u7528\u57fa\u4e8e\u7c92\u5b50\u7fa4\u4f18\u5316\u7684\u7edf\u4e00\u53cc\u901a\u9053\u4f18\u5316\u7b56\u7565\uff0c\u7cfb\u7edf\u534f\u8c03\u8bcd\u6c47\u548c\u8bed\u6cd5\u4e24\u4e2a\u5c42\u9762\u7684\u6270\u52a8\uff0c\u6709\u6548\u6269\u5c55\u5bf9\u6297\u6837\u672c\u7684\u641c\u7d22\u7a7a\u95f4\u3002", "result": "\u5728\u56db\u4e2a\u57fa\u51c6\u6570\u636e\u96c6\u4e0a\u7684\u5b9e\u9a8c\u8868\u660e\uff0cHogVul\u76f8\u6bd4\u6700\u5148\u8fdb\u7684\u57fa\u7ebf\u65b9\u6cd5\u5e73\u5747\u653b\u51fb\u6210\u529f\u7387\u63d0\u9ad8\u4e8626.05%\u3002", "conclusion": "\u6df7\u5408\u4f18\u5316\u7b56\u7565\u5728\u66b4\u9732\u6a21\u578b\u6f0f\u6d1e\u65b9\u9762\u5177\u6709\u5de8\u5927\u6f5c\u529b\uff0cHogVul\u6846\u67b6\u4e3a\u8bc4\u4f30\u548c\u6539\u8fdb\u57fa\u4e8e\u8bed\u8a00\u6a21\u578b\u7684\u6f0f\u6d1e\u68c0\u6d4b\u5668\u7684\u9c81\u68d2\u6027\u63d0\u4f9b\u4e86\u6709\u6548\u5de5\u5177\u3002"}}
{"id": "2601.05635", "categories": ["cs.CR", "cs.CL"], "pdf": "https://arxiv.org/pdf/2601.05635", "abs": "https://arxiv.org/abs/2601.05635", "authors": ["Honghao Liu", "Xuhui Jiang", "Chengjin Xu", "Cehao Yang", "Yiran Cheng", "Lionel Ni", "Jian Guo"], "title": "Continual Pretraining on Encrypted Synthetic Data for Privacy-Preserving LLMs", "comment": null, "summary": "Preserving privacy in sensitive data while pretraining large language models on small, domain-specific corpora presents a significant challenge. In this work, we take an exploratory step toward privacy-preserving continual pretraining by proposing an entity-based framework that synthesizes encrypted training data to protect personally identifiable information (PII). Our approach constructs a weighted entity graph to guide data synthesis and applies deterministic encryption to PII entities, enabling LLMs to encode new knowledge through continual pretraining while granting authorized access to sensitive data through decryption keys. Our results on limited-scale datasets demonstrate that our pretrained models outperform base models and ensure PII security, while exhibiting a modest performance gap compared to models trained on unencrypted synthetic data. We further show that increasing the number of entities and leveraging graph-based synthesis improves model performance, and that encrypted models retain instruction-following capabilities with long retrieved contexts. We discuss the security implications and limitations of deterministic encryption, positioning this work as an initial investigation into the design space of encrypted data pretraining for privacy-preserving LLMs. Our code is available at https://github.com/DataArcTech/SoE.", "AI": {"tldr": "\u63d0\u51fa\u57fa\u65bc\u5be6\u9ad4\u7684\u52a0\u5bc6\u6578\u64da\u5408\u6210\u6846\u67b6\uff0c\u7528\u65bc\u4fdd\u8b77\u96b1\u79c1\u7684\u6301\u7e8c\u9810\u8a13\u7df4LLM\uff0c\u901a\u904e\u78ba\u5b9a\u6027\u52a0\u5bc6\u4fdd\u8b77PII\uff0c\u5728\u4fdd\u6301\u6a21\u578b\u6027\u80fd\u7684\u540c\u6642\u78ba\u4fdd\u654f\u611f\u6578\u64da\u5b89\u5168\u3002", "motivation": "\u5728\u5c0f\u578b\u9818\u57df\u7279\u5b9a\u8a9e\u6599\u5eab\u4e0a\u9810\u8a13\u7df4\u5927\u578b\u8a9e\u8a00\u6a21\u578b\u6642\uff0c\u4fdd\u8b77\u654f\u611f\u6578\u64da\u4e2d\u7684\u96b1\u79c1\u662f\u4e00\u5927\u6311\u6230\u3002\u9700\u8981\u63a2\u7d22\u5982\u4f55\u5728\u6301\u7e8c\u9810\u8a13\u7df4\u4e2d\u4fdd\u8b77\u500b\u4eba\u53ef\u8b58\u5225\u4fe1\u606f(PII)\u3002", "method": "\u63d0\u51fa\u57fa\u65bc\u5be6\u9ad4\u7684\u6846\u67b6\uff1a1)\u69cb\u5efa\u52a0\u6b0a\u5be6\u9ad4\u5716\u6307\u5c0e\u6578\u64da\u5408\u6210\uff1b2)\u5c0dPII\u5be6\u9ad4\u61c9\u7528\u78ba\u5b9a\u6027\u52a0\u5bc6\uff1b3)\u901a\u904e\u89e3\u5bc6\u5bc6\u9470\u6388\u6b0a\u8a2a\u554f\u654f\u611f\u6578\u64da\uff0c\u4f7fLLM\u80fd\u5920\u901a\u904e\u6301\u7e8c\u9810\u8a13\u7df4\u7de8\u78bc\u65b0\u77e5\u8b58\u3002", "result": "\u5728\u6709\u9650\u898f\u6a21\u6578\u64da\u96c6\u4e0a\uff0c\u9810\u8a13\u7df4\u6a21\u578b\u512a\u65bc\u57fa\u790e\u6a21\u578b\u4e26\u78ba\u4fddPII\u5b89\u5168\uff0c\u8207\u672a\u52a0\u5bc6\u5408\u6210\u6578\u64da\u8a13\u7df4\u7684\u6a21\u578b\u76f8\u6bd4\u5b58\u5728\u9069\u5ea6\u6027\u80fd\u5dee\u8ddd\u3002\u589e\u52a0\u5be6\u9ad4\u6578\u91cf\u548c\u57fa\u65bc\u5716\u7684\u5408\u6210\u53ef\u63d0\u5347\u6027\u80fd\uff0c\u52a0\u5bc6\u6a21\u578b\u4fdd\u6301\u6307\u4ee4\u8ddf\u96a8\u80fd\u529b\u3002", "conclusion": "\u9019\u9805\u5de5\u4f5c\u4f5c\u70ba\u52a0\u5bc6\u6578\u64da\u9810\u8a13\u7df4\u8a2d\u8a08\u7a7a\u9593\u7684\u521d\u6b65\u63a2\u7d22\uff0c\u8a0e\u8ad6\u4e86\u78ba\u5b9a\u6027\u52a0\u5bc6\u7684\u5b89\u5168\u5f71\u97ff\u548c\u9650\u5236\uff0c\u70ba\u96b1\u79c1\u4fdd\u8b77LLM\u63d0\u4f9b\u4e86\u6709\u524d\u666f\u7684\u65b9\u5411\u3002"}}
{"id": "2601.05742", "categories": ["cs.CR", "cs.AI"], "pdf": "https://arxiv.org/pdf/2601.05742", "abs": "https://arxiv.org/abs/2601.05742", "authors": ["Ahmad Alobaid", "Mart\u00ed Jord\u00e0 Roca", "Carlos Castillo", "Joan Vendrell"], "title": "The Echo Chamber Multi-Turn LLM Jailbreak", "comment": null, "summary": "The availability of Large Language Models (LLMs) has led to a new generation of powerful chatbots that can be developed at relatively low cost. As companies deploy these tools, security challenges need to be addressed to prevent financial loss and reputational damage. A key security challenge is jailbreaking, the malicious manipulation of prompts and inputs to bypass a chatbot's safety guardrails. Multi-turn attacks are a relatively new form of jailbreaking involving a carefully crafted chain of interactions with a chatbot. We introduce Echo Chamber, a new multi-turn attack using a gradual escalation method. We describe this attack in detail, compare it to other multi-turn attacks, and demonstrate its performance against multiple state-of-the-art models through extensive evaluation.", "AI": {"tldr": "Echo Chamber\u662f\u4e00\u79cd\u65b0\u578b\u7684\u591a\u8f6e\u8d8a\u72f1\u653b\u51fb\u65b9\u6cd5\uff0c\u901a\u8fc7\u9010\u6b65\u5347\u7ea7\u7684\u65b9\u5f0f\u7ed5\u8fc7\u804a\u5929\u673a\u5668\u4eba\u7684\u5b89\u5168\u9632\u62a4\u673a\u5236", "motivation": "\u968f\u7740LLM\u804a\u5929\u673a\u5668\u4eba\u7684\u666e\u53ca\uff0c\u5b89\u5168\u6311\u6218\u65e5\u76ca\u7a81\u51fa\uff0c\u7279\u522b\u662f\u8d8a\u72f1\u653b\u51fb\u53ef\u80fd\u5bfc\u81f4\u8d22\u52a1\u635f\u5931\u548c\u58f0\u8a89\u635f\u5bb3\u3002\u591a\u8f6e\u653b\u51fb\u4f5c\u4e3a\u4e00\u79cd\u65b0\u578b\u8d8a\u72f1\u65b9\u5f0f\u9700\u8981\u88ab\u6df1\u5165\u7814\u7a76\u3002", "method": "\u63d0\u51faEcho Chamber\u653b\u51fb\u65b9\u6cd5\uff0c\u91c7\u7528\u9010\u6b65\u5347\u7ea7\u7b56\u7565\uff0c\u901a\u8fc7\u7cbe\u5fc3\u8bbe\u8ba1\u7684\u4ea4\u4e92\u94fe\u6765\u7ed5\u8fc7\u804a\u5929\u673a\u5668\u4eba\u7684\u5b89\u5168\u9632\u62a4\u673a\u5236\u3002", "result": "\u901a\u8fc7\u5e7f\u6cdb\u8bc4\u4f30\uff0cEcho Chamber\u653b\u51fb\u5728\u591a\u4e2a\u6700\u5148\u8fdb\u6a21\u578b\u4e0a\u8868\u73b0\u51fa\u8272\uff0c\u8bc1\u660e\u4e86\u5176\u6709\u6548\u6027\u3002", "conclusion": "Echo Chamber\u4f5c\u4e3a\u4e00\u79cd\u65b0\u578b\u591a\u8f6e\u8d8a\u72f1\u653b\u51fb\u65b9\u6cd5\uff0c\u7a81\u663e\u4e86\u5f53\u524d\u804a\u5929\u673a\u5668\u4eba\u5b89\u5168\u9632\u62a4\u7684\u8106\u5f31\u6027\uff0c\u9700\u8981\u52a0\u5f3a\u9632\u5fa1\u63aa\u65bd\u3002"}}
{"id": "2601.05755", "categories": ["cs.CR", "cs.AI"], "pdf": "https://arxiv.org/pdf/2601.05755", "abs": "https://arxiv.org/abs/2601.05755", "authors": ["Junda Lin", "Zhaomeng Zhou", "Zhi Zheng", "Shuochen Liu", "Tong Xu", "Yong Chen", "Enhong Chen"], "title": "VIGIL: Defending LLM Agents Against Tool Stream Injection via Verify-Before-Commit", "comment": null, "summary": "LLM agents operating in open environments face escalating risks from indirect prompt injection, particularly within the tool stream where manipulated metadata and runtime feedback hijack execution flow. Existing defenses encounter a critical dilemma as advanced models prioritize injected rules due to strict alignment while static protection mechanisms sever the feedback loop required for adaptive reasoning. To reconcile this conflict, we propose \\textbf{VIGIL}, a framework that shifts the paradigm from restrictive isolation to a verify-before-commit protocol. By facilitating speculative hypothesis generation and enforcing safety through intent-grounded verification, \\textbf{VIGIL} preserves reasoning flexibility while ensuring robust control. We further introduce \\textbf{SIREN}, a benchmark comprising 959 tool stream injection cases designed to simulate pervasive threats characterized by dynamic dependencies. Extensive experiments demonstrate that \\textbf{VIGIL} outperforms state-of-the-art dynamic defenses by reducing the attack success rate by over 22\\% while more than doubling the utility under attack compared to static baselines, thereby achieving an optimal balance between security and utility. Code is available at https://anonymous.4open.science/r/VIGIL-378B/.", "AI": {"tldr": "VIGIL\u6846\u67b6\u901a\u8fc7\u9a8c\u8bc1\u524d\u63d0\u4ea4\u534f\u8bae\u89e3\u51b3LLM\u4ee3\u7406\u5728\u5f00\u653e\u73af\u5883\u4e2d\u7684\u95f4\u63a5\u63d0\u793a\u6ce8\u5165\u653b\u51fb\uff0c\u5728\u4fdd\u6301\u63a8\u7406\u7075\u6d3b\u6027\u7684\u540c\u65f6\u786e\u4fdd\u5b89\u5168\u63a7\u5236\uff0c\u663e\u8457\u964d\u4f4e\u653b\u51fb\u6210\u529f\u7387\u5e76\u63d0\u9ad8\u5b9e\u7528\u6027\u3002", "motivation": "LLM\u4ee3\u7406\u5728\u5f00\u653e\u73af\u5883\u4e2d\u9762\u4e34\u95f4\u63a5\u63d0\u793a\u6ce8\u5165\u653b\u51fb\u7684\u5347\u7ea7\u98ce\u9669\uff0c\u7279\u522b\u662f\u5728\u5de5\u5177\u6d41\u4e2d\uff0c\u88ab\u64cd\u7eb5\u7684\u5143\u6570\u636e\u548c\u8fd0\u884c\u65f6\u53cd\u9988\u4f1a\u52ab\u6301\u6267\u884c\u6d41\u7a0b\u3002\u73b0\u6709\u9632\u5fa1\u65b9\u6cd5\u9762\u4e34\u5173\u952e\u56f0\u5883\uff1a\u9ad8\u7ea7\u6a21\u578b\u56e0\u4e25\u683c\u5bf9\u9f50\u800c\u4f18\u5148\u6267\u884c\u6ce8\u5165\u89c4\u5219\uff0c\u800c\u9759\u6001\u4fdd\u62a4\u673a\u5236\u5219\u5207\u65ad\u4e86\u81ea\u9002\u5e94\u63a8\u7406\u6240\u9700\u7684\u53cd\u9988\u5faa\u73af\u3002", "method": "\u63d0\u51faVIGIL\u6846\u67b6\uff0c\u5c06\u8303\u5f0f\u4ece\u9650\u5236\u6027\u9694\u79bb\u8f6c\u5411\u9a8c\u8bc1\u524d\u63d0\u4ea4\u534f\u8bae\u3002\u901a\u8fc7\u4fc3\u8fdb\u63a8\u6d4b\u6027\u5047\u8bbe\u751f\u6210\u548c\u6267\u884c\u57fa\u4e8e\u610f\u56fe\u7684\u9a8c\u8bc1\u6765\u786e\u4fdd\u5b89\u5168\uff0c\u5728\u4fdd\u6301\u63a8\u7406\u7075\u6d3b\u6027\u7684\u540c\u65f6\u5b9e\u73b0\u7a33\u5065\u63a7\u5236\u3002\u8fd8\u5f15\u5165\u4e86SIREN\u57fa\u51c6\u6d4b\u8bd5\uff0c\u5305\u542b959\u4e2a\u5de5\u5177\u6d41\u6ce8\u5165\u6848\u4f8b\uff0c\u7528\u4e8e\u6a21\u62df\u5177\u6709\u52a8\u6001\u4f9d\u8d56\u6027\u7684\u666e\u904d\u5a01\u80c1\u3002", "result": "\u5e7f\u6cdb\u5b9e\u9a8c\u8868\u660e\uff0cVIGIL\u4f18\u4e8e\u6700\u5148\u8fdb\u7684\u52a8\u6001\u9632\u5fa1\u65b9\u6cd5\uff0c\u5c06\u653b\u51fb\u6210\u529f\u7387\u964d\u4f4e\u4e86\u8d85\u8fc722%\uff0c\u540c\u65f6\u4e0e\u9759\u6001\u57fa\u7ebf\u76f8\u6bd4\uff0c\u5728\u653b\u51fb\u4e0b\u7684\u5b9e\u7528\u6027\u63d0\u9ad8\u4e86\u4e00\u500d\u4ee5\u4e0a\uff0c\u5b9e\u73b0\u4e86\u5b89\u5168\u6027\u548c\u5b9e\u7528\u6027\u7684\u6700\u4f73\u5e73\u8861\u3002", "conclusion": "VIGIL\u6846\u67b6\u6210\u529f\u89e3\u51b3\u4e86LLM\u4ee3\u7406\u5728\u5f00\u653e\u73af\u5883\u4e2d\u9762\u4e34\u7684\u5b89\u5168\u4e0e\u5b9e\u7528\u6027\u4e4b\u95f4\u7684\u6743\u8861\u95ee\u9898\uff0c\u901a\u8fc7\u9a8c\u8bc1\u524d\u63d0\u4ea4\u534f\u8bae\u5728\u4fdd\u6301\u63a8\u7406\u7075\u6d3b\u6027\u7684\u540c\u65f6\u786e\u4fdd\u5b89\u5168\u63a7\u5236\uff0c\u4e3a\u95f4\u63a5\u63d0\u793a\u6ce8\u5165\u653b\u51fb\u63d0\u4f9b\u4e86\u6709\u6548\u7684\u9632\u5fa1\u89e3\u51b3\u65b9\u6848\u3002"}}
{"id": "2601.05828", "categories": ["cs.CR", "cs.AI", "cs.IR"], "pdf": "https://arxiv.org/pdf/2601.05828", "abs": "https://arxiv.org/abs/2601.05828", "authors": ["Manuel Brosch", "Matthias Probst", "Stefan K\u00f6gler", "Georg Sigl"], "title": "Influence of Parallelism in Vector-Multiplication Units on Correlation Power Analysis", "comment": null, "summary": "The use of neural networks in edge devices is increasing, which introduces new security challenges related to the neural networks' confidentiality. As edge devices often offer physical access, attacks targeting the hardware, such as side-channel analysis, must be considered. To enhance the performance of neural network inference, hardware accelerators are commonly employed. This work investigates the influence of parallel processing within such accelerators on correlation-based side-channel attacks that exploit power consumption. The focus is on neurons that are part of the same fully-connected layer, which run parallel and simultaneously process the same input value. The theoretical impact of concurrent multiply-and-accumulate operations on overall power consumption is evaluated, as well as the success rate of correlation power analysis. Based on the observed behavior, equations are derived that describe how the correlation decreases with increasing levels of parallelism. The applicability of these equations is validated using a vector-multiplication unit implemented on an FPGA.", "AI": {"tldr": "\u7814\u7a76\u795e\u7ecf\u7f51\u7edc\u786c\u4ef6\u52a0\u901f\u5668\u4e2d\u5e76\u884c\u5904\u7406\u5bf9\u57fa\u4e8e\u76f8\u5173\u6027\u7684\u529f\u8017\u4fa7\u4fe1\u9053\u653b\u51fb\u7684\u5f71\u54cd\uff0c\u53d1\u73b0\u5e76\u884c\u5ea6\u589e\u52a0\u4f1a\u964d\u4f4e\u653b\u51fb\u6210\u529f\u7387", "motivation": "\u968f\u7740\u795e\u7ecf\u7f51\u7edc\u5728\u8fb9\u7f18\u8bbe\u5907\u4e2d\u5e94\u7528\u589e\u52a0\uff0c\u8bbe\u5907\u7269\u7406\u53ef\u8bbf\u95ee\u6027\u5e26\u6765\u4e86\u4fa7\u4fe1\u9053\u653b\u51fb\u7684\u5b89\u5168\u6311\u6218\u3002\u786c\u4ef6\u52a0\u901f\u5668\u867d\u7136\u63d0\u5347\u63a8\u7406\u6027\u80fd\uff0c\u4f46\u5176\u5e76\u884c\u5904\u7406\u7279\u6027\u53ef\u80fd\u5f71\u54cd\u529f\u8017\u4fa7\u4fe1\u9053\u653b\u51fb\u7684\u6548\u679c\uff0c\u9700\u8981\u7814\u7a76\u8fd9\u79cd\u5f71\u54cd", "method": "\u7814\u7a76\u5168\u8fde\u63a5\u5c42\u4e2d\u5e76\u884c\u8fd0\u884c\u7684\u795e\u7ecf\u5143\u5bf9\u529f\u8017\u4fa7\u4fe1\u9053\u653b\u51fb\u7684\u5f71\u54cd\uff0c\u5206\u6790\u5e76\u53d1\u4e58\u52a0\u8fd0\u7b97\u5bf9\u603b\u4f53\u529f\u8017\u7684\u7406\u8bba\u5f71\u54cd\u548c\u76f8\u5173\u529f\u8017\u5206\u6790\u7684\u6210\u529f\u7387\u3002\u63a8\u5bfc\u63cf\u8ff0\u76f8\u5173\u6027\u968f\u5e76\u884c\u5ea6\u589e\u52a0\u800c\u964d\u4f4e\u7684\u65b9\u7a0b\uff0c\u5e76\u5728FPGA\u4e0a\u5b9e\u73b0\u7684\u5411\u91cf\u4e58\u6cd5\u5355\u5143\u8fdb\u884c\u9a8c\u8bc1", "result": "\u5efa\u7acb\u4e86\u63cf\u8ff0\u76f8\u5173\u6027\u968f\u5e76\u884c\u5ea6\u589e\u52a0\u800c\u964d\u4f4e\u7684\u6570\u5b66\u65b9\u7a0b\uff0c\u901a\u8fc7FPGA\u5b9e\u9a8c\u9a8c\u8bc1\u4e86\u8fd9\u4e9b\u65b9\u7a0b\u7684\u9002\u7528\u6027\uff0c\u8bc1\u660e\u4e86\u5e76\u884c\u5904\u7406\u786e\u5b9e\u4f1a\u964d\u4f4e\u57fa\u4e8e\u76f8\u5173\u6027\u7684\u529f\u8017\u4fa7\u4fe1\u9053\u653b\u51fb\u7684\u6210\u529f\u7387", "conclusion": "\u795e\u7ecf\u7f51\u7edc\u786c\u4ef6\u52a0\u901f\u5668\u7684\u5e76\u884c\u5904\u7406\u7279\u6027\u4f1a\u964d\u4f4e\u57fa\u4e8e\u76f8\u5173\u6027\u7684\u529f\u8017\u4fa7\u4fe1\u9053\u653b\u51fb\u7684\u6709\u6548\u6027\uff0c\u8fd9\u4e3a\u8bbe\u8ba1\u66f4\u5b89\u5168\u7684\u795e\u7ecf\u7f51\u7edc\u786c\u4ef6\u5b9e\u73b0\u63d0\u4f9b\u4e86\u7406\u8bba\u4f9d\u636e\uff0c\u6709\u52a9\u4e8e\u5728\u6027\u80fd\u548c\u5b89\u5168\u6027\u4e4b\u95f4\u53d6\u5f97\u5e73\u8861"}}
{"id": "2601.05865", "categories": ["cs.CR"], "pdf": "https://arxiv.org/pdf/2601.05865", "abs": "https://arxiv.org/abs/2601.05865", "authors": ["Federico Mazzone", "Giorgio Micali", "Massimiliano Pronesti"], "title": "Secure Change-Point Detection for Time Series under Homomorphic Encryption", "comment": "To appear at PETs 2026", "summary": "We introduce the first method for change-point detection on encrypted time series. Our approach employs the CKKS homomorphic encryption scheme to detect shifts in statistical properties (e.g., mean, variance, frequency) without ever decrypting the data. Unlike solutions based on differential privacy, which degrade accuracy through noise injection, our solution preserves utility comparable to plaintext baselines. We assess its performance through experiments on both synthetic datasets and real-world time series from healthcare and network monitoring. Notably, our approach can process one million points within 3 minutes.", "AI": {"tldr": "\u9996\u4e2a\u5728\u52a0\u5bc6\u65f6\u95f4\u5e8f\u5217\u4e0a\u8fdb\u884c\u53d8\u70b9\u68c0\u6d4b\u7684\u65b9\u6cd5\uff0c\u4f7f\u7528CKKS\u540c\u6001\u52a0\u5bc6\u65b9\u6848\uff0c\u65e0\u9700\u89e3\u5bc6\u6570\u636e\u5373\u53ef\u68c0\u6d4b\u7edf\u8ba1\u7279\u6027\u53d8\u5316\uff0c\u4fdd\u6301\u4e0e\u660e\u6587\u76f8\u5f53\u7684\u51c6\u786e\u6027\uff0c\u5904\u7406\u767e\u4e07\u70b9\u6570\u636e\u4ec5\u97003\u5206\u949f\u3002", "motivation": "\u73b0\u6709\u57fa\u4e8e\u5dee\u5206\u9690\u79c1\u7684\u89e3\u51b3\u65b9\u6848\u901a\u8fc7\u566a\u58f0\u6ce8\u5165\u4f1a\u964d\u4f4e\u51c6\u786e\u6027\uff0c\u800c\u52a0\u5bc6\u65f6\u95f4\u5e8f\u5217\u4e0a\u7684\u53d8\u70b9\u68c0\u6d4b\u9700\u6c42\u65e5\u76ca\u589e\u957f\uff0c\u7279\u522b\u662f\u5728\u533b\u7597\u548c\u7f51\u7edc\u76d1\u63a7\u7b49\u9690\u79c1\u654f\u611f\u9886\u57df\u3002", "method": "\u91c7\u7528CKKS\u540c\u6001\u52a0\u5bc6\u65b9\u6848\uff0c\u5728\u52a0\u5bc6\u72b6\u6001\u4e0b\u68c0\u6d4b\u7edf\u8ba1\u7279\u6027\uff08\u5982\u5747\u503c\u3001\u65b9\u5dee\u3001\u9891\u7387\uff09\u7684\u53d8\u5316\u70b9\uff0c\u65e0\u9700\u89e3\u5bc6\u539f\u59cb\u6570\u636e\u3002", "result": "\u5728\u5408\u6210\u6570\u636e\u96c6\u548c\u771f\u5b9e\u4e16\u754c\u65f6\u95f4\u5e8f\u5217\uff08\u533b\u7597\u548c\u7f51\u7edc\u76d1\u63a7\uff09\u4e0a\u8bc4\u4f30\u6027\u80fd\uff0c\u4fdd\u6301\u4e0e\u660e\u6587\u57fa\u51c6\u76f8\u5f53\u7684\u5b9e\u7528\u6027\uff0c\u5904\u7406\u767e\u4e07\u70b9\u6570\u636e\u4ec5\u97003\u5206\u949f\u3002", "conclusion": "\u8be5\u65b9\u6cd5\u9996\u6b21\u5b9e\u73b0\u4e86\u52a0\u5bc6\u65f6\u95f4\u5e8f\u5217\u4e0a\u7684\u9ad8\u6548\u53d8\u70b9\u68c0\u6d4b\uff0c\u5728\u4fdd\u62a4\u9690\u79c1\u7684\u540c\u65f6\u4fdd\u6301\u4e86\u5b9e\u7528\u6027\uff0c\u4e3a\u9690\u79c1\u654f\u611f\u5e94\u7528\u63d0\u4f9b\u4e86\u53ef\u884c\u7684\u89e3\u51b3\u65b9\u6848\u3002"}}
{"id": "2601.05887", "categories": ["cs.CR"], "pdf": "https://arxiv.org/pdf/2601.05887", "abs": "https://arxiv.org/abs/2601.05887", "authors": ["V\u00edctor Mayoral-Vilches", "Mar\u00eda Sanz-G\u00f3mez", "Francesco Balassone", "Stefan Rass", "Lidia Salas-Espejo", "Benjamin Jablonski", "Luis Javier Navarrete-Lozano", "Maite del Mundo de Torres", "Crist\u00f3bal R. J. Veas Chavez"], "title": "Cybersecurity AI: A Game-Theoretic AI for Guiding Attack and Defense", "comment": null, "summary": "AI-driven penetration testing now executes thousands of actions per hour but still lacks the strategic intuition humans apply in competitive security. To build cybersecurity superintelligence --Cybersecurity AI exceeding best human capability-such strategic intuition must be embedded into agentic reasoning processes. We present Generative Cut-the-Rope (G-CTR), a game-theoretic guidance layer that extracts attack graphs from agent's context, computes Nash equilibria with effort-aware scoring, and feeds a concise digest back into the LLM loop \\emph{guiding} the agent's actions. Across five real-world exercises, G-CTR matches 70--90% of expert graph structure while running 60--245x faster and over 140x cheaper than manual analysis. In a 44-run cyber-range, adding the digest lifts success from 20.0% to 42.9%, cuts cost-per-success by 2.7x, and reduces behavioral variance by 5.2x. In Attack-and-Defense exercises, a shared digest produces the Purple agent, winning roughly 2:1 over the LLM-only baseline and 3.7:1 over independently guided teams. This closed-loop guidance is what produces the breakthrough: it reduces ambiguity, collapses the LLM's search space, suppresses hallucinations, and keeps the model anchored to the most relevant parts of the problem, yielding large gains in success rate, consistency, and reliability.", "AI": {"tldr": "G-CTR\u662f\u4e00\u4e2a\u6e38\u620f\u8bba\u6307\u5bfc\u5c42\uff0c\u901a\u8fc7\u63d0\u53d6\u653b\u51fb\u56fe\u3001\u8ba1\u7b97\u7eb3\u4ec0\u5747\u8861\u5e76\u63d0\u4f9b\u7b80\u660e\u6458\u8981\u6765\u6307\u5bfcLLM\u4ee3\u7406\uff0c\u663e\u8457\u63d0\u5347AI\u6e17\u900f\u6d4b\u8bd5\u7684\u6210\u529f\u7387\u3001\u4e00\u81f4\u6027\u548c\u6210\u672c\u6548\u76ca\u3002", "motivation": "\u5f53\u524dAI\u9a71\u52a8\u7684\u6e17\u900f\u6d4b\u8bd5\u867d\u7136\u80fd\u6267\u884c\u5927\u91cf\u64cd\u4f5c\uff0c\u4f46\u7f3a\u4e4f\u4eba\u7c7b\u5728\u7ade\u4e89\u6027\u5b89\u5168\u4e2d\u7684\u6218\u7565\u76f4\u89c9\u3002\u4e3a\u4e86\u6784\u5efa\u8d85\u8d8a\u4eba\u7c7b\u6700\u4f73\u80fd\u529b\u7684\u7f51\u7edc\u5b89\u5168\u8d85\u7ea7\u667a\u80fd\uff0c\u9700\u8981\u5c06\u8fd9\u79cd\u6218\u7565\u76f4\u89c9\u5d4c\u5165\u5230\u4ee3\u7406\u63a8\u7406\u8fc7\u7a0b\u4e2d\u3002", "method": "\u63d0\u51faGenerative Cut-the-Rope (G-CTR)\u65b9\u6cd5\uff1a\u4ece\u4ee3\u7406\u4e0a\u4e0b\u6587\u4e2d\u63d0\u53d6\u653b\u51fb\u56fe\uff0c\u4f7f\u7528\u52aa\u529b\u611f\u77e5\u8bc4\u5206\u8ba1\u7b97\u7eb3\u4ec0\u5747\u8861\uff0c\u5e76\u5c06\u7b80\u660e\u6458\u8981\u53cd\u9988\u5230LLM\u5faa\u73af\u4e2d\u6307\u5bfc\u4ee3\u7406\u884c\u52a8\u3002", "result": "\u5728\u4e94\u4e2a\u771f\u5b9e\u4e16\u754c\u7ec3\u4e60\u4e2d\uff0cG-CTR\u5339\u914d\u4e8670-90%\u7684\u4e13\u5bb6\u56fe\u7ed3\u6784\uff0c\u8fd0\u884c\u901f\u5ea6\u6bd4\u624b\u52a8\u5206\u6790\u5feb60-245\u500d\uff0c\u6210\u672c\u964d\u4f4e140\u500d\u4ee5\u4e0a\u3002\u572844\u6b21\u7f51\u7edc\u9776\u573a\u6d4b\u8bd5\u4e2d\uff0c\u6210\u529f\u7387\u4ece20.0%\u63d0\u5347\u523042.9%\uff0c\u6bcf\u6b21\u6210\u529f\u6210\u672c\u964d\u4f4e2.7\u500d\uff0c\u884c\u4e3a\u65b9\u5dee\u51cf\u5c115.2\u500d\u3002\u5728\u653b\u9632\u6f14\u7ec3\u4e2d\uff0c\u5171\u4eab\u6458\u8981\u7684\u7d2b\u8272\u4ee3\u7406\u4ee5\u7ea62:1\u6218\u80dc\u4ec5\u4f7f\u7528LLM\u7684\u57fa\u7ebf\uff0c\u4ee53.7:1\u6218\u80dc\u72ec\u7acb\u6307\u5bfc\u7684\u56e2\u961f\u3002", "conclusion": "\u95ed\u73af\u6307\u5bfc\u901a\u8fc7\u51cf\u5c11\u6b67\u4e49\u3001\u538b\u7f29LLM\u641c\u7d22\u7a7a\u95f4\u3001\u6291\u5236\u5e7b\u89c9\u5e76\u5c06\u6a21\u578b\u951a\u5b9a\u5230\u95ee\u9898\u6700\u76f8\u5173\u90e8\u5206\uff0c\u5b9e\u73b0\u4e86\u5728\u6210\u529f\u7387\u3001\u4e00\u81f4\u6027\u548c\u53ef\u9760\u6027\u65b9\u9762\u7684\u91cd\u5927\u7a81\u7834\u3002"}}
{"id": "2601.05918", "categories": ["cs.CR", "cs.AI", "cs.CY"], "pdf": "https://arxiv.org/pdf/2601.05918", "abs": "https://arxiv.org/abs/2601.05918", "authors": ["Tianshi Li"], "title": "Agentic LLMs as Powerful Deanonymizers: Re-identification of Participants in the Anthropic Interviewer Dataset", "comment": "4 pages", "summary": "On December 4, 2025, Anthropic released Anthropic Interviewer, an AI tool for running qualitative interviews at scale, along with a public dataset of 1,250 interviews with professionals, including 125 scientists, about their use of AI for research. Focusing on the scientist subset, I show that widely available LLMs with web search and agentic capabilities can link six out of twenty-four interviews to specific scientific works, recovering associated authors and, in some cases, uniquely identifying the interviewees. My contribution is to show that modern LLM-based agents make such re-identification attacks easy and low-effort: off-the-shelf tools can, with a few natural-language prompts, search the web, cross-reference details, and propose likely matches, effectively lowering the technical barrier. Existing safeguards can be bypassed by breaking down the re-identification into benign tasks. I outline the attack at a high level, discuss implications for releasing rich qualitative data in the age of LLM agents, and propose mitigation recommendations and open problems. I have notified Anthropic of my findings.", "AI": {"tldr": "LLM\u667a\u80fd\u4f53\u901a\u8fc7\u7f51\u9875\u641c\u7d22\u548c\u4ea4\u53c9\u5f15\u7528\uff0c\u80fd\u591f\u4eceAnthropic\u53d1\u5e03\u7684\u79d1\u5b66\u5bb6\u8bbf\u8c08\u6570\u636e\u96c6\u4e2d\u91cd\u65b0\u8bc6\u522b\u51fa\u53d7\u8bbf\u8005\u8eab\u4efd\uff0c\u66b4\u9732\u51fa\u5f53\u524d\u5b9a\u6027\u6570\u636e\u53d1\u5e03\u7684\u5b89\u5168\u98ce\u9669\u3002", "motivation": "\u968f\u7740Anthropic\u53d1\u5e03\u5305\u542b125\u540d\u79d1\u5b66\u5bb6\u8bbf\u8c08\u7684\u516c\u5f00\u6570\u636e\u96c6\uff0c\u7814\u7a76\u65e8\u5728\u8bc4\u4f30\u73b0\u4ee3LLM\u667a\u80fd\u4f53\u662f\u5426\u80fd\u591f\u901a\u8fc7\u8fd9\u4e9b\u8bbf\u8c08\u5185\u5bb9\u91cd\u65b0\u8bc6\u522b\u51fa\u79d1\u5b66\u5bb6\u7684\u5177\u4f53\u8eab\u4efd\uff0c\u63ed\u793a\u5f53\u524d\u6570\u636e\u53d1\u5e03\u5728AI\u65f6\u4ee3\u7684\u5b89\u5168\u9690\u60a3\u3002", "method": "\u4f7f\u7528\u73b0\u6210\u7684LLM\u5de5\u5177\uff08\u5177\u5907\u7f51\u9875\u641c\u7d22\u548c\u667a\u80fd\u4f53\u80fd\u529b\uff09\uff0c\u901a\u8fc7\u81ea\u7136\u8bed\u8a00\u63d0\u793a\u5c06\u91cd\u65b0\u8bc6\u522b\u653b\u51fb\u5206\u89e3\u4e3a\u591a\u4e2a\u826f\u6027\u4efb\u52a1\uff0c\u5305\u62ec\u641c\u7d22\u7f51\u7edc\u3001\u4ea4\u53c9\u5f15\u7528\u7ec6\u8282\u548c\u63d0\u51fa\u53ef\u80fd\u7684\u5339\u914d\u9879\u3002", "result": "\u572824\u4e2a\u79d1\u5b66\u5bb6\u8bbf\u8c08\u4e2d\uff0c\u6210\u529f\u91cd\u65b0\u8bc6\u522b\u51fa6\u4e2a\u8bbf\u8c08\u5bf9\u5e94\u7684\u5177\u4f53\u79d1\u5b66\u5de5\u4f5c\u3001\u76f8\u5173\u4f5c\u8005\uff0c\u5728\u67d0\u4e9b\u60c5\u51b5\u4e0b\u751a\u81f3\u80fd\u552f\u4e00\u786e\u5b9a\u53d7\u8bbf\u8005\u8eab\u4efd\uff0c\u8bc1\u660e\u73b0\u4ee3LLM\u667a\u80fd\u4f53\u4f7f\u6b64\u7c7b\u91cd\u65b0\u8bc6\u522b\u653b\u51fb\u53d8\u5f97\u5bb9\u6613\u4e14\u4f4e\u95e8\u69db\u3002", "conclusion": "LLM\u667a\u80fd\u4f53\u65f6\u4ee3\u4e0b\uff0c\u53d1\u5e03\u4e30\u5bcc\u7684\u5b9a\u6027\u6570\u636e\u5b58\u5728\u4e25\u91cd\u7684\u9690\u79c1\u98ce\u9669\uff0c\u73b0\u6709\u5b89\u5168\u63aa\u65bd\u53ef\u80fd\u88ab\u7ed5\u8fc7\uff0c\u9700\u8981\u5236\u5b9a\u65b0\u7684\u7f13\u89e3\u5efa\u8bae\u5e76\u89e3\u51b3\u76f8\u5173\u5f00\u653e\u6027\u95ee\u9898\u3002"}}
{"id": "2601.05988", "categories": ["cs.CR", "cs.LG"], "pdf": "https://arxiv.org/pdf/2601.05988", "abs": "https://arxiv.org/abs/2601.05988", "authors": ["Isaiah J. King", "Bernardo Trindade", "Benjamin Bowman", "H. Howie Huang"], "title": "CyberGFM: Graph Foundation Models for Lateral Movement Detection in Enterprise Networks", "comment": "17 pages; 11 figures; 8 tables", "summary": "Representing networks as a graph and training a link prediction model using benign connections is an effective method of anomaly-based intrusion detection. Existing works using this technique have shown great success using temporal graph neural networks and skip-gram-based approaches on random walks. However, random walk-based approaches are unable to incorporate rich edge data, while the GNN-based approaches require large amounts of memory to train. In this work, we propose extending the original insight from random walk-based skip-grams--that random walks through a graph are analogous to sentences in a corpus--to the more modern transformer-based foundation models. Using language models that take advantage of GPU optimizations, we can quickly train a graph foundation model to predict missing tokens in random walks through a network of computers. The graph foundation model is then finetuned for link prediction and used as a network anomaly detector. This new approach allows us to combine the efficiency of random walk-based methods and the rich semantic representation of deep learning methods. This system, which we call CyberGFM, achieved state-of-the-art results on three widely used network anomaly detection datasets, delivering a up to 2$\\times$ improvement in average precision. We found that CyberGFM outperforms all prior works in unsupervised link prediction for network anomaly detection, using the same number of parameters, and with equal or better efficiency than the previous best approaches.", "AI": {"tldr": "\u63d0\u51faCyberGFM\u7cfb\u7edf\uff0c\u5c06\u968f\u673a\u6e38\u8d70\u4e0eTransformer\u57fa\u7840\u6a21\u578b\u7ed3\u5408\uff0c\u7528\u4e8e\u7f51\u7edc\u5f02\u5e38\u68c0\u6d4b\uff0c\u5728\u4e09\u4e2a\u6570\u636e\u96c6\u4e0a\u8fbe\u5230SOTA\uff0cAP\u63d0\u5347\u6700\u9ad8\u8fbe2\u500d\u3002", "motivation": "\u73b0\u6709\u65b9\u6cd5\u5b58\u5728\u5c40\u9650\u6027\uff1a\u57fa\u4e8e\u968f\u673a\u6e38\u8d70\u7684\u65b9\u6cd5\u65e0\u6cd5\u5229\u7528\u4e30\u5bcc\u7684\u8fb9\u6570\u636e\uff0c\u800c\u57fa\u4e8eGNN\u7684\u65b9\u6cd5\u9700\u8981\u5927\u91cf\u5185\u5b58\u8bad\u7ec3\u3002\u9700\u8981\u7ed3\u5408\u968f\u673a\u6e38\u8d70\u7684\u9ad8\u6548\u6027\u548c\u6df1\u5ea6\u5b66\u4e60\u7684\u4e30\u5bcc\u8bed\u4e49\u8868\u793a\u80fd\u529b\u3002", "method": "\u5c06\u968f\u673a\u6e38\u8d70\u7c7b\u6bd4\u4e3a\u8bed\u6599\u5e93\u4e2d\u7684\u53e5\u5b50\uff0c\u4f7f\u7528GPU\u4f18\u5316\u7684\u8bed\u8a00\u6a21\u578b\u8bad\u7ec3\u56fe\u57fa\u7840\u6a21\u578b\u6765\u9884\u6d4b\u968f\u673a\u6e38\u8d70\u4e2d\u7684\u7f3a\u5931\u6807\u8bb0\uff0c\u7136\u540e\u5fae\u8c03\u7528\u4e8e\u94fe\u8def\u9884\u6d4b\uff0c\u4f5c\u4e3a\u7f51\u7edc\u5f02\u5e38\u68c0\u6d4b\u5668\u3002", "result": "\u5728\u4e09\u4e2a\u5e7f\u6cdb\u4f7f\u7528\u7684\u7f51\u7edc\u5f02\u5e38\u68c0\u6d4b\u6570\u636e\u96c6\u4e0a\u8fbe\u5230\u6700\u5148\u8fdb\u7ed3\u679c\uff0c\u5e73\u5747\u7cbe\u5ea6\u6700\u9ad8\u63d0\u53472\u500d\uff0c\u5728\u65e0\u76d1\u7763\u94fe\u8def\u9884\u6d4b\u4e2d\u4f18\u4e8e\u6240\u6709\u5148\u524d\u5de5\u4f5c\uff0c\u53c2\u6570\u6570\u91cf\u76f8\u540c\uff0c\u6548\u7387\u76f8\u5f53\u6216\u66f4\u597d\u3002", "conclusion": "CyberGFM\u6210\u529f\u7ed3\u5408\u4e86\u968f\u673a\u6e38\u8d70\u65b9\u6cd5\u7684\u6548\u7387\u548c\u6df1\u5ea6\u5b66\u4e60\u65b9\u6cd5\u7684\u4e30\u5bcc\u8bed\u4e49\u8868\u793a\u80fd\u529b\uff0c\u4e3a\u7f51\u7edc\u5f02\u5e38\u68c0\u6d4b\u63d0\u4f9b\u4e86\u9ad8\u6548\u6709\u6548\u7684\u89e3\u51b3\u65b9\u6848\u3002"}}
