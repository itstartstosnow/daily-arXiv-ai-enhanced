<div id=toc></div>

# Table of Contents

- [cs.CR](#cs.CR) [Total: 22]


<div id='cs.CR'></div>

# cs.CR [[Back]](#toc)

### [1] [Reflection-Driven Control for Trustworthy Code Agents](https://arxiv.org/abs/2512.21354)
*Bin Wang,Jiazheng Quan,Xingrui Yu,Hansen Hu,Yuhao,Ivor Tsang*

Main category: cs.CR

TL;DR: 提出Reflection-Driven Control方法，将自我反思作为LLM代理推理过程的显式步骤，通过持续监控决策路径、检测风险并注入安全约束，提升代码生成的安全性和合规性。


<details>
  <summary>Details</summary>
Motivation: 当前大型语言模型代理虽然能力强大，但缺乏可靠的安全控制机制，可能产生不受约束、不可预测甚至有害的输出，特别是在安全关键的代码生成场景中。

Method: 提出Reflection-Driven Control模块，将自我反思从后处理提升为代理推理过程的显式步骤。代理在生成过程中持续运行内部反思循环，监控评估决策路径，检测到风险时从演进式反思记忆中检索相关修复示例和安全编码指南，并将这些基于证据的约束直接注入后续推理步骤。

Result: 在安全代码生成场景中，对八类安全关键编程任务进行系统评估。实验结果显示，Reflection-Driven Control显著提高了生成代码的安全性和策略合规性，同时基本保持了功能正确性，且运行时和token开销最小。

Conclusion: Reflection-Driven Control是实现可信AI编码代理的实用路径，能够同时实现自主性、构建时更安全且可审计的设计。

Abstract: Contemporary large language model (LLM) agents are remarkably capable, but they still lack reliable safety controls and can produce unconstrained, unpredictable, and even actively harmful outputs. To address this, we introduce Reflection-Driven Control, a standardized and pluggable control module that can be seamlessly integrated into general agent architectures. Reflection-Driven Control elevates "self-reflection" from a post hoc patch into an explicit step in the agent's own reasoning process: during generation, the agent continuously runs an internal reflection loop that monitors and evaluates its own decision path. When potential risks are detected, the system retrieves relevant repair examples and secure coding guidelines from an evolving reflective memory, injecting these evidence-based constraints directly into subsequent reasoning steps. We instantiate Reflection-Driven Control in the setting of secure code generation and systematically evaluate it across eight classes of security-critical programming tasks. Empirical results show that Reflection-Driven Control substantially improves the security and policy compliance of generated code while largely preserving functional correctness, with minimal runtime and token overhead. Taken together, these findings indicate that Reflection-Driven Control is a practical path toward trustworthy AI coding agents: it enables designs that are simultaneously autonomous, safer by construction, and auditable.

</details>


### [2] [Composition Theorems for f-Differential Privacy](https://arxiv.org/abs/2512.21358)
*Natasha Fernandes,Annabelle McIver,Parastoo Sadeghi*

Main category: cs.CR

TL;DR: 论文展示了f差分隐私与定量信息流的信道模型之间的等价性，通过Galois连接建立联系，并推导出新的组合定理


<details>
  <summary>Details</summary>
Motivation: fDP作为新的隐私定义能提供更好的隐私损失预测，但需要更深入的理论基础来支持复杂隐私设计的分析

Method: 通过统计假设检验的基础，建立fDP与定量信息流信道模型的等价性，使用两个偏序集之间的Galois连接来证明

Result: 证明了fDP与定量信息流信道模型的等价性，并推导出新的通用组合定理

Conclusion: fDP与定量信息流信道模型的等价性为复杂隐私设计提供了改进的分析框架，支持更好的隐私机制组合分析

Abstract: "f differential privacy" (fDP) is a recent definition for privacy privacy which can offer improved predictions of "privacy loss". It has been used to analyse specific privacy mechanisms, such as the popular Gaussian mechanism. In this paper we show how fDP's foundation in statistical hypothesis testing implies equivalence to the channel model of Quantitative Information Flow. We demonstrate this equivalence by a Galois connection between two partially ordered sets. This equivalence enables novel general composition theorems for fDP, supporting improved analysis for complex privacy designs.

</details>


### [3] [Power Side-Channel Analysis of the CVA6 RISC-V Core at the RTL Level Using VeriSide](https://arxiv.org/abs/2512.21362)
*Behnam Farnaghinejad,Antonio Porsia,Annachiara Ruospo,Alessandro Savino,Stefano Di Carlo,Ernesto Sanchez*

Main category: cs.CR

TL;DR: 评估CVA6 RISC-V核心侧信道漏洞，通过VeriSide框架分析AES加密，发现CPA攻击可恢复密钥，强调RTL早期评估对安全设计的重要性。


<details>
  <summary>Details</summary>
Motivation: 现代RISC-V处理器不仅需要功能正确性，还需要抵抗侧信道攻击。当前缺乏对CVA6 RISC-V核心侧信道漏洞的系统评估，需要早期RTL级别的安全分析来指导未来安全设计。

Method: 使用VeriSide RTL级功耗分析框架，对CVA6 RISC-V核心进行侧信道分析。通过软件实现的AES加密作为测试用例，采用相关性功耗分析（CPA）技术来评估密钥泄露情况。

Result: CPA分析显示CVA6设计存在显著的信息泄露，能够成功恢复AES加密密钥。这表明该RISC-V核心在侧信道攻击面前存在严重安全漏洞。

Conclusion: RISC-V处理器设计需要在早期RTL阶段就考虑侧信道安全性，VeriSide框架为早期安全评估提供了有效工具，未来RISC-V设计应集成更强的侧信道防护机制。

Abstract: Security in modern RISC-V processors demands more than functional correctness: It requires resilience to side-channel attacks. This paper evaluates the vulnerability of the side channel of the CVA6 RISC-V core by analyzing software-based AES encryption uses an RTL-level power profiling framework called VeriSide. This work represents that this design's Correlation Power Analysis (CPA) reveals significant leakage, enabling key recovery. These findings underscore the importance of early-stage RTL assessments in shaping future secure RISC-V designs.

</details>


### [4] [Satellite Cybersecurity Across Orbital Altitudes: Analyzing Ground-Based Threats to LEO, MEO, and GEO](https://arxiv.org/abs/2512.21367)
*Mark Ballard,Guanqun Song,Ting Zhu*

Main category: cs.CR

TL;DR: 该论文比较分析了LEO、MEO和GEO轨道的卫星网络安全，发现轨道高度决定攻击可行性和影响，弱加密和指令路径异常是跨轨道最一致的攻击成功预测因素。


<details>
  <summary>Details</summary>
Motivation: 随着卫星星座的快速扩张，特别是低地球轨道（LEO）卫星，空间基础设施的风险格局已从单纯的物理碰撞转变为复杂的网络物理威胁。传统安全框架主要关注碎片减缓，但地面攻击者越来越多地利用射频链路、供应链漏洞和软件更新路径来破坏空间资产。需要理解不同轨道高度的网络安全差异。

Method: 对LEO、MEO和GEO轨道卫星网络安全进行对比分析。综合分析了60个公开记录的安全事件数据，结合遥测、跟踪和指令（TT&C）异常、加密弱点和环境压力等关键漏洞指标，研究轨道高度如何决定攻击可行性和影响。

Result: 研究发现不同轨道具有明显不同的威胁特征：GEO系统主要通过高频上行链路暴露被攻击，而LEO星座面临独特的风险，包括有限的功率预算、硬件限制以及对热和辐射诱导故障的敏感性。弱加密和指令路径异常是所有轨道中最一致的攻击成功预测因素。

Conclusion: 未缓解的网络漏洞会加速硬件过时和碎片积累，破坏碳中和空间运营的努力。需要弥合安全与可持续性之间的差距，因为网络安全问题直接影响空间环境的长期可持续性。

Abstract: The rapid proliferation of satellite constellations, particularly in Low Earth Orbit (LEO), has fundamentally altered the global space infrastructure, shifting the risk landscape from purely kinetic collisions to complex cyber-physical threats. While traditional safety frameworks focus on debris mitigation, ground-based adversaries increasingly exploit radio-frequency links, supply chain vulnerabilities, and software update pathways to degrade space assets. This paper presents a comparative analysis of satellite cybersecurity across LEO, Medium Earth Orbit (MEO), and Geostationary Earth Orbit (GEO) regimes. By synthesizing data from 60 publicly documented security incidents with key vulnerability proxies--including Telemetry, Tracking, and Command (TT&C) anomalies, encryption weaknesses, and environmental stressors--we characterize how orbital altitude dictates attack feasibility and impact. Our evaluation reveals distinct threat profiles: GEO systems are predominantly targeted via high-frequency uplink exposure, whereas LEO constellations face unique risks stemming from limited power budgets, hardware constraints, and susceptibility to thermal and radiation-induced faults. We further bridge the gap between security and sustainability, arguing that unmitigated cyber vulnerabilities accelerate hardware obsolescence and debris accumulation, undermining efforts toward carbon-neutral space operations. The results demonstrate that weak encryption and command path irregularities are the most consistent predictors of adversarial success across all orbits.

</details>


### [5] [Key Length-Oriented Classification of Lightweight Cryptographic Algorithms for IoT Security](https://arxiv.org/abs/2512.21368)
*Arsalan Vahi*

Main category: cs.CR

TL;DR: 该论文对物联网中使用的对称轻量级密码进行安全评估调查，提出基于应用特性和密钥大小的分类法，发现密钥大小是轻量级密码安全的关键参数


<details>
  <summary>Details</summary>
Motivation: 现有调查主要从硬件/软件实现或性能评估角度研究轻量级密码技术，缺乏针对物联网环境特定安全方面的全面分析。物联网应用的安全部署依赖轻量级密码，需要填补这一研究空白

Method: 对物联网系统中常用的对称轻量级密码进行全面的安全评估调查，提出两种分类法：1) 基于物联网应用固有特性的分类；2) 基于密钥大小的安全等级评估分类

Result: 研究发现密钥大小是轻量级密码安全的关键参数，使用少于128位密钥的密码被认为安全性较低，甚至不足以保护敏感数据

Conclusion: 该研究填补了物联网轻量级密码安全评估的空白，提供了全面的安全视角，强调密钥大小对物联网应用安全的重要性，为资源受限的实时应用选择合适的密码提供了指导

Abstract: The successful deployment of the Internet of Things (IoT) applications relies heavily on their robust security, and lightweight cryptography is considered an emerging solution in this context. While existing surveys have been examining lightweight cryptographic techniques from the perspective of hardware and software implementations or performance evaluation, there is a significant gap in addressing different security aspects specific to the IoT environment. This study aims to bridge this gap. This research presents a thorough survey focused on the security evaluation of symmetric lightweight ciphers commonly used in IoT systems. The objective of this study is to provide a holistic understanding of lightweight ciphers, emphasizing their security strength, which is an essential consideration for real-time and resource-constrained applications. Furthermore, we propose two taxonomies: one for classifying IoT applications based on their inherent characteristics, and another for evaluating security levels based on key size. Our findings indicate that key size is a critical parameter in the security of lightweight ciphers. Ciphers employing keys shorter than 128 bits are considered less secure or even insecure for protecting sensitive data

</details>


### [6] [The Imitation Game: Using Large Language Models as Chatbots to Combat Chat-Based Cybercrimes](https://arxiv.org/abs/2512.21371)
*Yifan Yao,Baojuan Wang,Jinhao Duan,Kaidi Xu,ChuanKai Guo,Zhibo Eric Sun,Yue Zhang*

Main category: cs.CR

TL;DR: LURE系统利用大语言模型主动模仿人类受害者与网络犯罪分子聊天，成功识别并分析诈骗行为模式


<details>
  <summary>Details</summary>
Motivation: 传统基于静态规则或浅层内容过滤的防御机制难以识别基于聊天平台的网络犯罪，特别是当攻击者使用多媒体混淆和上下文感知对话时

Method: LURE系统结合自动发现、对抗性交互和基于OCR的图像嵌入支付数据分析，将LLM作为主动代理而非被动分类器嵌入对抗性聊天环境

Result: 在Telegram的98个群组中与53名犯罪分子互动，超过56%的交互中LLM保持多轮对话未被识别为机器人，成功揭示了支付流程、追加销售策略和平台迁移等诈骗行为模式

Conclusion: LLM可以有效地模仿人类受害者来对抗网络犯罪分子，为检测和打击聊天式网络犯罪提供了新的主动防御方法

Abstract: Chat-based cybercrime has emerged as a pervasive threat, with attackers leveraging real-time messaging platforms to conduct scams that rely on trust-building, deception, and psychological manipulation. Traditional defense mechanisms, which operate on static rules or shallow content filters, struggle to identify these conversational threats, especially when attackers use multimedia obfuscation and context-aware dialogue.
  In this work, we ask a provocative question inspired by the classic Imitation Game: Can machines convincingly pose as human victims to turn deception against cybercriminals? We present LURE (LLM-based User Response Engagement), the first system to deploy Large Language Models (LLMs) as active agents, not as passive classifiers, embedded within adversarial chat environments.
  LURE combines automated discovery, adversarial interaction, and OCR-based analysis of image-embedded payment data. Applied to the setting of illicit video chat scams on Telegram, our system engaged 53 actors across 98 groups. In over 56 percent of interactions, the LLM maintained multi-round conversations without being noticed as a bot, effectively "winning" the imitation game. Our findings reveal key behavioral patterns in scam operations, such as payment flows, upselling strategies, and platform migration tactics.

</details>


### [7] [Security Risks Introduced by Weak Authentication in Smart Home IoT Systems](https://arxiv.org/abs/2512.21374)
*Daniyal Ganiuly,Nurzhau Bolatbek,Assel Smaiyl*

Main category: cs.CR

TL;DR: 智能家居物联网设备认证机制存在安全漏洞：认证状态长期有效、可跨网络事件持续使用，且可被同一局域网内其他主机重放攻击


<details>
  <summary>Details</summary>
Motivation: 智能家居物联网系统需要在安全性和可用性之间取得平衡，但实际部署中往往倾向于持久连接和最小用户交互。需要实证分析实际部署设备的认证执行情况，了解认证状态如何建立、重用和验证。

Method: 在受控住宅环境中，对广泛部署的消费设备（智能插座、照明设备、摄像头、基于集线器的生态系统）进行评估。使用被动网络测量和通过官方移动应用的受控交互，检查认证行为：初始配对、长期运行、常见网络变化后、以及从不同本地网络主机进行重放尝试。

Result: 配对期间建立的认证状态在控制操作中持续重用，长时间有效且无明确过期；在网络重新连接、地址重新分配和路由器重启等事件后仍然有效。重放实验显示，先前观察到的认证凭证通常可被同一局域网内其他主机重用，成功率高。这些行为在多个设备类别和生态系统中普遍存在。

Conclusion: 当前智能家居物联网认证机制依赖于长期信任关系，缺乏对会话新鲜度、网络上下文或控制器身份的充分绑定，存在安全风险。

Abstract: Smart home IoT systems rely on authentication mechanisms to ensure that only authorized entities can control devices and access sensitive functionality. In practice, these mechanisms must balance security with usability, often favoring persistent connectivity and minimal user interaction. This paper presents an empirical analysis of authentication enforcement in deployed smart home IoT devices, focusing on how authentication state is established, reused, and validated during normal operation and under routine network conditions. A set of widely deployed consumer devices, including smart plugs, lighting devices, cameras, and a hub based ecosystem, was evaluated in a controlled residential environment using passive network measurement and controlled interaction through official mobile applications. Authentication behavior was examined during initial pairing, over extended periods of operation, after common network changes, and under replay attempts from a different local network host. The results show that authentication state established during pairing is consistently reused across control actions, persists for extended periods without explicit expiration, and remains valid after network events such as reconnection, address reassignment, and router reboot. Replay experiments demonstrate that previously observed authentication artifacts can often be reused to issue control commands from another host on the same local network with high success rates. These behaviors were observed across multiple device categories and ecosystems. The findings indicate that current smart home IoT authentication mechanisms rely on long lived trust relationships with limited binding to session freshness, network context, or controller identity.

</details>


### [8] [A Systematic Review of Technical Defenses Against Software-Based Cheating in Online Multiplayer Games](https://arxiv.org/abs/2512.21377)
*Adwa Alangari,Ohoud Alharbi*

Main category: cs.CR

TL;DR: 本文对在线多人游戏中软件作弊的技术防御措施进行了系统性文献综述，将现有方法分为服务器端检测、客户端反篡改、内核级反作弊驱动和硬件辅助TEE四类，并评估了检测效果、性能开销、隐私影响和可扩展性等指标。


<details>
  <summary>Details</summary>
Motivation: 在线多人游戏中软件作弊问题日益严重，破坏了游戏公平性和玩家体验，需要系统性地分析现有反作弊技术的优缺点，为设计更有效的防御方案提供指导。

Method: 采用系统性文献综述方法，对现有反作弊技术进行分类（服务器端检测、客户端反篡改、内核级反作弊驱动、硬件辅助TEE），并从检测效果、性能开销、隐私影响、可扩展性四个维度进行评估分析。

Result: 分析揭示了不同技术方案之间的关键权衡：内核级解决方案具有高可见性但存在隐私和稳定性风险，服务器端方法侵入性低但洞察力有限。硬件辅助TEE提供了较好的平衡，但部署成本较高。

Conclusion: 反作弊是一场持续的军备竞赛，需要设计健壮、抗攻击的反作弊系统。未来应关注隐私保护、性能优化和可扩展性的平衡，同时考虑硬件辅助方案的实际部署可行性。

Abstract: This systematic literature review surveys technical defenses against software-based cheating in online multiplayer games. Categorizing existing approach-es into server-side detection, client-side anti-tamper, kernel-level anti-cheat drivers, and hardware-assisted TEEs. Each category is evaluated in terms of detection effectiveness, perfor-mance overhead, privacy im-pact, and scalability. The analy-sis highlights key trade-offs, particularly between the high visibility of kernel-level solutions and their privacy and stability risks, versus the low intrusive-ness but limited insight of server-side methods. Overall, the re-view emphasizes the ongoing arms race with cheaters and the need for robust, adversary-resistant anti-cheat designs.

</details>


### [9] [LLM-Driven Feature-Level Adversarial Attacks on Android Malware Detectors](https://arxiv.org/abs/2512.21404)
*Tianwei Lan,Farid Naït-Abdesselam*

Main category: cs.CR

TL;DR: LAMLAD是一个利用大语言模型（LLMs）生成对抗性样本来绕过Android恶意软件检测器的攻击框架，通过双智能体架构实现高效、隐蔽的攻击，攻击成功率高达97%，并提出相应的防御策略。


<details>
  <summary>Details</summary>
Motivation: 尽管机器学习技术已广泛应用于Android恶意软件检测，但这些模型仍然容易受到对抗性攻击。现有攻击方法可能不够高效或隐蔽，因此需要开发更先进的攻击框架来评估和改进检测系统的鲁棒性。

Method: LAMLAD采用双智能体架构：1）LLM manipulator生成保持恶意功能性的特征扰动；2）LLM analyzer指导扰动过程实现成功规避。框架集成了检索增强生成（RAG）以提高效率和上下文感知能力，专注于Drebin风格的特征表示。

Result: 在三个代表性ML-based Android恶意软件检测器上的实验表明，LAMLAD攻击成功率高达97%，平均每个对抗样本仅需3次尝试。与两种最先进的对抗攻击方法相比，LAMLAD在效果、效率和适应性方面表现更优。

Conclusion: LAMLAD证明了LLMs在生成对抗性Android恶意软件样本方面的强大能力，对现有检测系统构成严重威胁。同时提出的基于对抗训练的防御策略能将攻击成功率平均降低30%以上，显著增强了模型对LAMLAD式攻击的鲁棒性。

Abstract: The rapid growth in both the scale and complexity of Android malware has driven the widespread adoption of machine learning (ML) techniques for scalable and accurate malware detection. Despite their effectiveness, these models remain vulnerable to adversarial attacks that introduce carefully crafted feature-level perturbations to evade detection while preserving malicious functionality. In this paper, we present LAMLAD, a novel adversarial attack framework that exploits the generative and reasoning capabilities of large language models (LLMs) to bypass ML-based Android malware classifiers. LAMLAD employs a dual-agent architecture composed of an LLM manipulator, which generates realistic and functionality-preserving feature perturbations, and an LLM analyzer, which guides the perturbation process toward successful evasion. To improve efficiency and contextual awareness, LAMLAD integrates retrieval-augmented generation (RAG) into the LLM pipeline. Focusing on Drebin-style feature representations, LAMLAD enables stealthy and high-confidence attacks against widely deployed Android malware detection systems. We evaluate LAMLAD against three representative ML-based Android malware detectors and compare its performance with two state-of-the-art adversarial attack methods. Experimental results demonstrate that LAMLAD achieves an attack success rate (ASR) of up to 97%, requiring on average only three attempts per adversarial sample, highlighting its effectiveness, efficiency, and adaptability in practical adversarial settings. Furthermore, we propose an adversarial training-based defense strategy that reduces the ASR by more than 30% on average, significantly enhancing model robustness against LAMLAD-style attacks.

</details>


### [10] [GoldenFuzz: Generative Golden Reference Hardware Fuzzing](https://arxiv.org/abs/2512.21524)
*Lichao Wu,Mohamadreza Rostami,Huimin Li,Nikhilesh Singh,Ahmad-Reza Sadeghi*

Main category: cs.CR

TL;DR: GoldenFuzz是一个两阶段硬件模糊测试框架，使用快速黄金参考模型作为被测设备的数字孪生，通过解耦测试用例优化与覆盖探索，显著提升硬件漏洞发现效率和覆盖率。


<details>
  <summary>Details</summary>
Motivation: 现代硬件系统日益复杂，存在大量bug和安全漏洞。现有硬件模糊测试工具存在语义感知有限、测试优化效率低、计算开销大（依赖慢速设备模拟）等问题，需要更高效的解决方案。

Method: 采用两阶段框架：1) 使用快速ISA兼容的黄金参考模型作为数字孪生进行模糊测试，实现低成本测试用例优化；2) 通过精心选择的指令块拼接构建测试用例，平衡指令间和指令内质量；3) 利用高覆盖率和低覆盖率样本的反馈驱动机制增强硬件状态探索能力。

Result: 在RocketChip、BOOM和CVA6三个RISC-V处理器上的评估显示，GoldenFuzz在最小测试用例长度和计算开销下达到最高覆盖率，发现所有已知漏洞和5个新漏洞（其中4个CVSS v3严重性评分超过7/10），并在商业BA51-H核心扩展中发现2个先前未知漏洞。

Conclusion: GoldenFuzz通过部分解耦测试用例优化与覆盖探索，利用快速黄金参考模型作为数字孪生，显著提升了硬件模糊测试的效率和效果，能够高效发现严重硬件漏洞。

Abstract: Modern hardware systems, driven by demands for high performance and application-specific functionality, have grown increasingly complex, introducing large surfaces for bugs and security-critical vulnerabilities. Fuzzing has emerged as a scalable solution for discovering such flaws. Yet, existing hardware fuzzers suffer from limited semantic awareness, inefficient test refinement, and high computational overhead due to reliance on slow device simulation.
  In this paper, we present GoldenFuzz, a novel two-stage hardware fuzzing framework that partially decouples test case refinement from coverage and vulnerability exploration. GoldenFuzz leverages a fast, ISA-compliant Golden Reference Model (GRM) as a ``digital twin'' of the Device Under Test (DUT). It fuzzes the GRM first, enabling rapid, low-cost test case refinement, accelerating deep architectural exploration and vulnerability discovery on DUT. During the fuzzing pipeline, GoldenFuzz iteratively constructs test cases by concatenating carefully chosen instruction blocks that balance the subtle inter- and intra-instructions quality. A feedback-driven mechanism leveraging insights from both high- and low-coverage samples further enhances GoldenFuzz's capability in hardware state exploration. Our evaluation of three RISC-V processors, RocketChip, BOOM, and CVA6, demonstrates that GoldenFuzz significantly outperforms existing fuzzers in achieving the highest coverage with minimal test case length and computational overhead. GoldenFuzz uncovers all known vulnerabilities and discovers five new ones, four of which are classified as highly severe with CVSS v3 severity scores exceeding seven out of ten. It also identifies two previously unknown vulnerabilities in the commercial BA51-H core extension.

</details>


### [11] [Enhancing Distributed Authorization With Lagrange Interpolation And Attribute-Based Encryption](https://arxiv.org/abs/2512.21525)
*Keshav Sinha,Sumitra,Richa Kumari,Akashdeep Bhardwaj,Shawon Rahman*

Main category: cs.CR

TL;DR: 提出一种结合流密码加密和秘密共享的多方执行方案，通过减少服务器计算开销和响应时间来提升安全数据访问效率。


<details>
  <summary>Details</summary>
Motivation: 当前安全环境中，用户需要访问大量机密数据，现有技术使用访问控制列表进行认证授权，但多个步骤增加了服务器计算开销和响应时间。

Method: 采用两种方法：1) 使用基于对合函数的流密码加密文件数据；2) 使用Shamir秘密共享方案分发对称密钥给用户。解密时通过二阶拉格朗日插值从隐藏点重构密钥。

Result: 评估了加密解密时间、吞吐量、计算开销和安全性分析，证明能有效减少服务器计算开销。

Conclusion: 提出的机制未来可用于组织内大规模安全数据共享，通过多方执行降低服务器负担。

Abstract: In todays security landscape, every user wants to access large amounts of data with confidentiality and authorization. To maintain confidentiality, various researchers have proposed several techniques. However, to access secure data, researchers use access control lists to grant authentication and provide authorization. The above several steps will increase the server's computation overhead and response time. To cope with these two problems, we proposed multiparty execution on the server. In this paper, we introduce two different approaches. The first approach is encryption, utilizing the Involution Function Based Stream Cipher to encrypt the file data. The second approach is key distribution, using the Shamir secret sharing scheme to divide and distribute the symmetric key to every user. The decryption process required key reconstruction, which used second order Lagrange interpolation to reconstruct the secret keys from the hidden points. The process will reduce the server's computational overhead. The results are evaluated based on the encryption and decryption time, throughput, computational overhead, and security analysis. In the future, the proposed mechanism will be used to share large-scale, secure data within the organization.

</details>


### [12] [Security Boundaries of Quantum Key Reuse: A Quantitative Evaluation Method for QKD Key Rotation Interval and Security Benefits Combined with Block Ciphers](https://arxiv.org/abs/2512.21561)
*Xiaoming Chen,Haoze Chen,Fei Xu,Meifeng Gao,Jianguo Xie,Cheng Ye,An Hua,Jiao Zhao,Minghan Li,Feilong Li,Yajun Miao,Wei Qi*

Main category: cs.CR

TL;DR: 该研究量化了量子密钥分发(QKD)与经典分组密码(如SM4)结合使用时，单密钥加密多个文件的安全强度下降问题，提出了密钥轮换间隔的精确计算模型和安全效益评估方法。


<details>
  <summary>Details</summary>
Motivation: 量子计算快速发展威胁经典密码系统安全，QKD虽提供信息论安全但带宽有限，需与AES、SM4等分组密码结合使用。然而，单密钥加密多个多块文件导致的安全强度降低尚未被系统量化。

Method: 构建密钥轮换间隔的精确计算模型，提出QKD密钥用于分组密码的安全效益量化方法。基于具体安全模型和不同分组密码模式(CTR、CBC、ECBC-MAC)的安全特性，推导单密钥下可安全加密的最大文件数Q*，量化密钥轮换间隔对安全水平的提升效益。

Result: 以SM4为例，在80位安全目标下，均匀执行k次密钥轮换可使安全强度提升log2(k)到2log2(k)位。研究提供了QKD密钥与经典密码算法集成应用的理论支持和参数优化基础。

Conclusion: 该研究系统量化了QKD与分组密码结合时单密钥多文件加密的安全风险，提出了密钥轮换的量化评估方法，为量子安全密码系统的工程部署提供了理论依据和参数优化基础。

Abstract: With the rapid development of quantum computing, classical cryptography systems are facing increasing security threats, making it urgent to build architectures resilient to quantum attacks. Although Quantum Key Distribution (QKD) technology provides information-theoretic security, its limited bandwidth requires it to be combined with classical cryptography-particularly block ciphers such as AES and SM4-in practical deployments.However, when a single key is used to process multiple multi-block files, the resulting reduction in security strength has not yet been systematically quantified.In this work, we focus on the use of both QKD keys and block ciphers, and construct a precise calculation model for the key rotation interval. We further propose a quantitative method to evaluate the security benefit of using QKD keys for block cipher. Building on concrete security models and the security properties of various block cipher modes (CTR, CBC, and ECBC-MAC), we derive the maximum number of files that can be safely encrypted under a single key, denoted Q*, and quantify the benefits of key rotation interval in enhancing security levels. Using SM4 as a case study, our results show that, under an 80-bit security target, uniformly performing k key rotations can increase the security strength by log2(k) to 2log2(k) bits. This study provides theoretical support and a basis for parameter optimization for the integrated application of QKD keys with classical cryptographic algorithms and the engineering deployment of cryptographic systems.

</details>


### [13] [Verifiable Passkey: The Decentralized Authentication Standard](https://arxiv.org/abs/2512.21663)
*Aditya Mitra,Sibi Chakkaravarthy Sethuraman*

Main category: cs.CR

TL;DR: 提出"可验证通行密钥"新标准，解决FIDO2通行密钥存储限制和联合认证隐私风险问题


<details>
  <summary>Details</summary>
Motivation: FIDO2通行密钥虽然提供防钓鱼认证，但存在两个主要问题：1) 安全存储模块（如TPM或物理安全密钥）存储空间有限，限制了用户可创建的通行密钥数量；2) 使用联合认证和单点登录虽然能解决存储问题，但身份提供商可以跨服务追踪用户，带来隐私风险

Method: 提出"可验证通行密钥"新标准，允许用户将可验证凭证发行者创建的通行密钥安全地用于任何平台，同时保护隐私和防止用户追踪

Result: 通过可验证通行密钥标准，用户可以在不牺牲隐私的情况下，使用有限的通行密钥跨多个平台进行认证，解决了存储限制和隐私追踪的双重问题

Conclusion: 可验证通行密钥为密码认证提供了一个既安全又隐私保护的解决方案，克服了现有FIDO2通行密钥在存储限制和联合认证隐私风险方面的局限性

Abstract: Passwordless authentication has revolutionized the way we authenticate across various websites and services. FIDO2 Passkeys, is one of the most-widely adopted standards of passwordless authentication that promises phishing-resistance. However, like any other authentication system, passkeys require the user details to be saved on a centralized server, also known as Relying Party (RP) Server. This has led users to create a new passkey for every new online account. While this just works for a limited number of online accounts, the limited storage space of secure storage modules like TPM or a physical security key limits the number of passkeys a user can have. For example, Yubico Yubikey 5 (firmware 5.0 - 5.6) offers to store only 25 passkeys, while firmware 5.7+ allows to store upto 100 [1]. To overcome this problem, one of the widely adopted approaches is to use Federated Authentication with Single Sign On (SSO). This allows the user to create a passkey for the Identity Provider (IdP) and use the IdP to authenticate to all service providers. This proves to be a significant privacy risk since the IdP can potentially track users across different services. To overcome these limitations, this paper introduces a novel standard 'Verifiable Passkey' that allows the user to use Passkeys created for a Verifiable Credential issuer across any platform without risking privacy or user tracking.

</details>


### [14] [Exploring the Security Threats of Retriever Backdoors in Retrieval-Augmented Code Generation](https://arxiv.org/abs/2512.21681)
*Tian Li,Bo Lin,Shangwen Wang,Yusong Tan*

Main category: cs.CR

TL;DR: 本文首次系统性地研究了RACG系统中检索器后门攻击的安全威胁，开发了难以检测的VenomRACG攻击方法，发现仅需污染0.05%知识库即可在51.29%情况下使检索器将漏洞代码排在前5，导致GPT-4o等模型在40%以上目标场景生成漏洞代码。


<details>
  <summary>Details</summary>
Motivation: 检索增强代码生成(RACG)系统在软件开发中日益普及，但其安全影响严重缺乏研究。现有攻击方法要么效果太差不构成真实威胁，要么容易被现有防御机制检测到，无法进行现实威胁评估。需要开发更隐蔽有效的攻击方法来揭示真实风险。

Method: 开发了VenomRACG攻击方法，使中毒样本在统计上与良性代码无法区分，从而在所有防御机制下保持低检测率。利用该方法评估攻击效果，通过仅注入相当于知识库总量0.05%的漏洞代码，测试检索器将漏洞代码排在前5结果的成功率。

Result: 攻击成功率高：仅污染0.05%知识库，检索器在51.29%情况下将漏洞代码排在前5结果。下游危害严重：导致GPT-4o等模型在超过40%的目标场景中生成漏洞代码，同时系统整体性能不受影响。现有防御机制完全无法检测这种攻击。

Conclusion: 检索器后门攻击不是理论威胁而是实际存在的供应链漏洞，现有防御机制对此完全失效。研究揭示了RACG系统的严重安全风险，强调了开发鲁棒安全措施的紧迫性。

Abstract: Retrieval-Augmented Code Generation (RACG) is increasingly adopted to enhance Large Language Models for software development, yet its security implications remain dangerously underexplored. This paper conducts the first systematic exploration of a critical and stealthy threat: backdoor attacks targeting the retriever component, which represents a significant supply-chain vulnerability. It is infeasible to assess this threat realistically, as existing attack methods are either too ineffective to pose a real danger or are easily detected by state-of-the-art defense mechanisms spanning both latent-space analysis and token-level inspection, which achieve consistently high detection rates. To overcome this barrier and enable a realistic analysis, we first developed VenomRACG, a new class of potent and stealthy attack that serves as a vehicle for our investigation. Its design makes poisoned samples statistically indistinguishable from benign code, allowing the attack to consistently maintain low detectability across all evaluated defense mechanisms. Armed with this capability, our exploration reveals a severe vulnerability: by injecting vulnerable code equivalent to only 0.05% of the entire knowledge base size, an attacker can successfully manipulate the backdoored retriever to rank the vulnerable code in its top-5 results in 51.29% of cases. This translates to severe downstream harm, causing models like GPT-4o to generate vulnerable code in over 40% of targeted scenarios, while leaving the system's general performance intact. Our findings establish that retriever backdooring is not a theoretical concern but a practical threat to the software development ecosystem that current defenses are blind to, highlighting the urgent need for robust security measures.

</details>


### [15] [Raster Domain Text Steganography: A Unified Framework for Multimodal Secure Embedding](https://arxiv.org/abs/2512.21698)
*A V Uday Kiran Kandala*

Main category: cs.CR

TL;DR: 提出GPC框架，通过修改文本字形渲染后的像素来嵌入多种类型数据（文本、图像、音频、视频），每个字形作为编码单元，通过扰动内部墨像素的数量表示有效载荷值。


<details>
  <summary>Details</summary>
Motivation: 现有文本隐写方法多基于语言或结构层面，本文提出在字体栅格化后直接在像素空间操作的方法，使普通文本能够作为视觉隐蔽的多模态数据嵌入媒介。

Method: GPC框架在确定性文本渲染管线后操作，每个字形作为编码单元，通过最小化扰动内部墨像素的基数来表示有效载荷值。将多模态输入（图像强度、音频特征、视频帧值）归一化为有界整数序列，分布在多个字形中。

Result: 该方法计算轻量，基于确定性栅格行为，视觉上不可感知，能够稳定解码。演示了文本到文本嵌入，并推广到多模态输入。

Conclusion: GPC框架为多模态数据嵌入提供了一种统一、视觉隐蔽且计算高效的方法，使普通文本能够作为隐蔽通信媒介。

Abstract: This work introduces a unified raster domain steganographic framework, termed as the Glyph Perturbation Cardinality (GPC) framework, capable of embedding heterogeneous data such as text, images, audio, and video directly into the pixel space of rendered textual glyphs. Unlike linguistic or structural text based steganography, the proposed method operates exclusively after font rasterization, modifying only the bitmap produced by a deterministic text rendering pipeline. Each glyph functions as a covert encoding unit, where a payload value is expressed through the cardinality of minimally perturbed interior ink pixels. These minimal intensity increments remain visually imperceptible while forming a stable and decodable signal. The framework is demonstrated for text to text embedding and generalized to multimodal inputs by normalizing image intensities, audio derived scalar features, and video frame values into bounded integer sequences distributed across glyphs. Decoding is achieved by re-rasterizing the cover text, subtracting canonical glyph rasters, and recovering payload values via pixel count analysis. The approach is computationally lightweight, and grounded in deterministic raster behavior, enabling ordinary text to serve as a visually covert medium for multimodal data embedding.

</details>


### [16] [Machine Learning Power Side-Channel Attack on SNOW-V](https://arxiv.org/abs/2512.21737)
*Deepak,Rahul Balout,Anupam Golder,Suparna Kundu,Angshuman Karmakar,Debayan Das*

Main category: cs.CR

TL;DR: 本文展示了针对5G移动通信安全标准候选算法SNOW-V的功耗分析侧信道攻击，使用机器学习方法实现了比传统CPA攻击更高效的密钥恢复。


<details>
  <summary>Details</summary>
Motivation: SNOW-V是5G移动通信安全标准候选算法，评估其侧信道攻击脆弱性对于实际部署安全至关重要。传统功耗分析方法效率有限，需要探索机器学习方法是否能更有效地攻击该算法。

Method: 在STM32微控制器上实现SNOW-V算法，使用ChipWhisperer板捕获功耗轨迹。通过测试向量泄漏评估(TVLA)确认可利用的泄漏。采用线性判别分析(LDA)和全连接神经网络(FCN)进行特征分析攻击，并与传统的相关性功耗分析(CPA)结合LDA的方法进行比较。

Result: TVLA确认存在可利用的泄漏。FCN攻击实现了比最先进的CPA结合LDA方法低5倍以上的最小轨迹泄露(MTD)，表明机器学习方法在SNOW-V侧信道攻击中具有显著优势。

Conclusion: SNOW-V对基于机器学习的侧信道攻击存在脆弱性，需要采取更强大的防护措施来确保其在5G移动通信中的安全性。

Abstract: This paper demonstrates a power analysis-based Side-Channel Analysis (SCA) attack on the SNOW-V encryption algorithm, which is a 5G mobile communication security standard candidate. Implemented on an STM32 microcontroller, power traces captured with a ChipWhisperer board were analyzed, with Test Vector Leakage Assessment (TVLA) confirming exploitable leakage. Profiling attacks using Linear Discriminant Analysis (LDA) and Fully Connected Neural Networks (FCN) achieved efficient key recovery, with FCN achieving > 5X lower minimum traces to disclosure (MTD) compared to the state-of-the-art Correlational Power Analysis (CPA) assisted with LDA. The results highlight the vulnerability of SNOW-V to machine learning-based SCA and the need for robust countermeasures.

</details>


### [17] [Assessing the Effectiveness of Membership Inference on Generative Music](https://arxiv.org/abs/2512.21762)
*Kurtis Chow,Omar Samiullah,Vinesh Sridhar,Hewen Zhang*

Main category: cs.CR

TL;DR: 该论文研究了成员推理攻击在生成式音乐模型上的有效性，发现现有攻击方法对音乐数据的识别效果有限


<details>
  <summary>Details</summary>
Motivation: 生成式AI快速发展引发隐私和版权担忧，成员推理攻击可检测训练数据使用情况，但音乐领域尚未被研究。音乐产业价值巨大，艺术家需要确定作品是否被未经授权使用。

Method: 使用现有成员推理攻击方法对流行的生成式音乐模型MuseGAN进行实验研究

Result: 研究发现音乐数据对已知成员推理技术具有较强抵抗力，攻击效果有限

Conclusion: 生成式音乐对当前成员推理攻击具有韧性，需要进一步研究更有效的检测方法

Abstract: Generative AI systems are quickly improving, now able to produce believable output in several modalities including images, text, and audio. However, this fast development has prompted increased scrutiny concerning user privacy and the use of copyrighted works in training. A recent attack on machine-learning models called membership inference lies at the crossroads of these two concerns. The attack is given as input a set of records and a trained model and seeks to identify which of those records may have been used to train the model. On one hand, this attack can be used to identify user data used to train a model, which may violate their privacy especially in sensitive applications such as models trained on medical data. On the other hand, this attack can be used by rights-holders as evidence that a company used their works without permission to train a model.
  Remarkably, it appears that no work has studied the effect of membership inference attacks (MIA) on generative music. Given that the music industry is worth billions of dollars and artists would stand to gain from being able to determine if their works were being used without permission, we believe this is a pressing issue to study. As such, in this work we begin a preliminary study into whether MIAs are effective on generative music. We study the effect of several existing attacks on MuseGAN, a popular and influential generative music model. Similar to prior work on generative audio MIAs, our findings suggest that music data is fairly resilient to known membership inference techniques.

</details>


### [18] [Organizational Learning in Industry 4.0: Applying Crossan's 4I Framework with Double Loop Learning](https://arxiv.org/abs/2512.21813)
*Nimra Akram,Atif Ahmad,Sean B Maynard*

Main category: cs.CR

TL;DR: 提出结合双循环学习理论与4I组织学习框架的工业4.0网络安全事件响应架构，通过前馈和反馈学习循环提升组织网络安全成熟度。


<details>
  <summary>Details</summary>
Motivation: 65%的工业企业每年遭受勒索软件攻击，许多企业缺乏网络安全意识，随着物联网设备预计达到188亿台，网络安全威胁日益严峻，需要系统性解决方案。

Method: 结合Argyris和Schön的双循环学习理论与Crossan的4I组织学习框架，构建高级动态安全学习过程模型，通过文献综述和定性研究提出可扩展的系统性方法。

Result: 提出一个能够弥合运营障碍、促进系统韧性的网络安全成熟度方法，帮助工业4.0组织适应日益增长的安全挑战。

Conclusion: DSL模型为复杂网络物理系统提供了主动和反思性的网络安全治理架构，通过战略转型和持续成长机制增强组织应对网络安全威胁的能力。

Abstract: The Advanced Dynamic Security Learning (DSL) Process Model is an Industry 4.0 cybersecurity incident response architecture proposed in this paper. This model addresses proactive and reflective cybersecurity governance across complex cyber-physical systems by combining Argyris and Schön's double-loop learning theory with Crossan's 4I organizational learning framework. Given that 65% of industrial companies suffer ransomware attacks annually and many of them lack cybersecurity awareness, this reveals the gravity of cyber threats. Feedforward and feedback learning loops in this paradigm help promote strategic transformation and ongoing growth. The DSL model helps Industry 4.0 organizations adapt to growing challenges posed by the projected 18.8 billion IoT devices by bridging operational obstacles and promoting systemic resilience. This research presents a scalable, methodical cybersecurity maturity approach based on a comprehensive analysis of the literature and a qualitative study.

</details>


### [19] [Securing Cross-Domain Internet of Drones: An RFF-PUF Allied Authenticated Key Exchange Protocol With Over-the-Air Enrollment](https://arxiv.org/abs/2512.21827)
*Xuanyu Chen,Yue Zheng,Junqing Zhang,Guanxiong Shen,Chip-Hong Chang*

Main category: cs.CR

TL;DR: 提出一种轻量级无人机物联网认证机制，结合射频指纹和物理不可克隆函数技术，实现安全的无人机间及无人机与地面站通信，无需第三方参与和秘密存储。


<details>
  <summary>Details</summary>
Motivation: 无人机物联网在异构不信任域中面临访问控制和敏感数据传输的安全挑战。现有方案存在计算开销大、依赖第三方、需在资源受限无人机中存储秘密、需要严格受控注册环境等问题，难以适用于动态跨域部署。

Method: 集成射频指纹和物理不可克隆函数技术：RFF用于实现空中注册的设备识别，PUF作为信任根建立通信方之间的相互认证。PUF的即时密钥生成能力与一次性密码本加密协同设计，实现临时密钥生成并消除无人机内秘密存储需求。

Result: 非正式安全分析和基于ProVerif的形式化安全验证全面证明协议对常见安全攻击的抵抗能力。协议在安全特性、计算开销、通信开销和存储开销方面均优于现有无人机物联网认证方案。

Conclusion: 提出的轻量级相互认证机制有效解决了无人机物联网在动态跨域环境中的安全挑战，通过RFF和PUF技术的集成，实现了无需第三方参与、无需秘密存储的安全通信方案。

Abstract: The Internet of Drones (IoD) is an emerging and crucial paradigm enabling advanced applications that require seamless, secure communication across heterogeneous and untrusted domains. In such environments, access control and the transmission of sensitive data pose significant security challenges for IoD systems, necessitating the design of lightweight mutual authentication and key exchange protocols. Existing solutions are often hampered by high computation overhead, reliance on third parties, the requirement for secret storage in resource-constrained drones, and the need for a strictly controlled enrollment environment. These limitations make them impractical for dynamic cross-domain deployment. To address these limitations, we propose a lightweight mutual authentication mechanism that integrates Radio Frequency Fingerprint (RFF) and Physical Unclonable Function (PUF) technologies for secure drone-to-drone (D2D) and drone-to-ground station server (D2G) communication. RFF-based device identification is used to achieve over-the-air (OTA) enrollment, while the PUF serves as the root of trust for establishing mutual authentication among communication parties. Additionally, the on-the-fly key generation capability of the PUF is co-designed with One-Time-Pad (OTP) encryption to realize ephemeral keying and eliminate the need for storing secrets within drones. Both informal security analysis and ProVerif-based formal security verification comprehensively demonstrate the resilience of our protocol against common security attacks. The proposed protocol also outperforms existing IoD authentication schemes in terms of security features, as well as computation, communication, and storage overhead.

</details>


### [20] [Toward Secure and Compliant AI: Organizational Standards and Protocols for NLP Model Lifecycle Management](https://arxiv.org/abs/2512.22060)
*Sunil Arora,John Hastings*

Main category: cs.CR

TL;DR: 本文提出了一个安全合规的NLP生命周期管理框架（SC-NLP-LMF），用于高风险环境中NLP系统的开发、部署和维护，确保安全性和合规性。


<details>
  <summary>Details</summary>
Motivation: NLP系统在医疗、金融和政府等敏感领域广泛应用，处理大量个人和受监管数据，但现有AI治理框架未能充分解决这些系统带来的安全、隐私和合规风险。

Method: 通过系统性的PRISMA方法回顾45篇同行评审和监管文献，开发了一个六阶段生命周期管理框架，整合了偏见检测、隐私保护（差分隐私、联邦学习）、安全部署、可解释性和安全模型退役等方法。

Result: 提出了SC-NLP-LMF框架，与NIST AI RMF、ISO/IEC 42001:2023、欧盟AI法案和MITRE ATLAS等标准对齐，并通过医疗案例研究展示了框架如何检测术语漂移并指导合规模型更新。

Conclusion: SC-NLP-LMF为组织提供了一个实用的、覆盖整个生命周期的框架，用于在高风险环境中开发、部署和维护安全且可问责的NLP系统。

Abstract: Natural Language Processing (NLP) systems are increasingly used in sensitive domains such as healthcare, finance, and government, where they handle large volumes of personal and regulated data. However, these systems introduce distinct risks related to security, privacy, and regulatory compliance that are not fully addressed by existing AI governance frameworks. This paper introduces the Secure and Compliant NLP Lifecycle Management Framework (SC-NLP-LMF), a comprehensive six-phase model designed to ensure the secure operation of NLP systems from development to retirement. The framework, developed through a systematic PRISMA-based review of 45 peer-reviewed and regulatory sources, aligns with leading standards, including NIST AI RMF, ISO/IEC 42001:2023, the EU AI Act, and MITRE ATLAS. It integrates established methods for bias detection, privacy protection (differential privacy, federated learning), secure deployment, explainability, and secure model decommissioning. A healthcare case study illustrates how SC-NLP-LMF detects emerging terminology drift (e.g., COVID-related language) and guides compliant model updates. The framework offers organizations a practical, lifecycle-wide structure for developing, deploying, and maintaining secure and accountable NLP systems in high-risk environments.

</details>


### [21] [ReSMT: An SMT-Based Tool for Reverse Engineering](https://arxiv.org/abs/2512.22076)
*Nir Somech,Guy Katz*

Main category: cs.CR

TL;DR: ReSMT：一种基于SMT求解的自动化工具，用于逆向工程混淆代码，将汇编代码转换为逻辑断言系统进行分析


<details>
  <summary>Details</summary>
Motivation: 恶意软件作者使用代码混淆技术来避免检测，而现有的逆向工程工具处理分层或定制化混淆技术时过程复杂且缓慢，需要高度专业化的去混淆技能

Method: ReSMT工具将混淆的汇编代码转换为表示代码功能的复杂逻辑断言系统，然后应用SMT求解和仿真工具来检查混淆代码的执行

Result: 在精心设计的案例研究中，ReSMT成功处理了复杂的混淆代码，并能够解决相关的逆向工程查询问题

Conclusion: 该方法展示了基于SMT求解的自动化逆向工程方法的潜力和实用性，能够减轻对高度专业化去混淆技能的依赖

Abstract: Software obfuscation techniques make code more difficult
  to understand, without changing its functionality. Such techniques
  are often used by authors of malicious software to avoid
  detection. Reverse Engineering
  of obfuscated code, i.e., the process of overcoming obfuscation and
  answering questions about the functionality of the code, is
  notoriously difficult; and while various tools and methods exist for
  this purpose, the process remains complex and slow, especially when
  dealing with layered or customized obfuscation techniques.
  Here, we present a novel, automated tool for addressing some of the
  challenges in reverse engineering of obfuscated code. Our tool,
  called ReSMT, converts the obfuscated assembly code into a complex
  system of logical assertions that represent the code functionality,
  and then applies SMT solving and simulation tools to inspect the
  obfuscated code's execution. The approach is mostly automatic,
  alleviating the need for highly specialized deobfuscation skills.
  In an elaborate case study that we conducted, ReSMT successfully
  tackled complex obfuscated code, and was able to solve reverse-engineering
  queries about it. We believe that these results showcase the potential
  and usefulness of our proposed approach.

</details>


### [22] [Abstraction of Trusted Execution Environments as the Missing Layer for Broad Confidential Computing Adoption: A Systematization of Knowledge](https://arxiv.org/abs/2512.22090)
*Quentin Michaud,Sara Ramezanian,Dhouha Ayed,Olivier Levillain,Joaquin Garcia-Alfaro*

Main category: cs.CR

TL;DR: 该论文系统化分析了可信执行环境(TEEs)技术，对现有TEE解决方案进行分类，研究抽象层设计，并指出WebAssembly是最有前景的抽象层方案。


<details>
  <summary>Details</summary>
Motivation: 当前存在多种不同的TEE技术解决方案，每种都有不同的特性。需要抽象层来统一生态系统，让应用开发者和系统管理员能够尽可能广泛和高效地利用机密计算。

Method: 首先概述代表性的TEE技术，描述和总结每个TEE生态系统，根据主要设计选择进行分类。然后提出知识系统化方法，围绕每个设计选择分析不同的抽象层，描述每个设计的基础技术以及每个抽象层的内部工作原理和特性。

Result: 研究发现改进现有抽象层解决方案的机会，并指出WebAssembly是支持最多特性的有前景方法。研究揭示了不同抽象层的优缺点。

Conclusion: 论文最后讨论了未来研究方向，如未来抽象层如何演变以及与机密计算生态系统的集成。WebAssembly被认为是支持最大特性集的promising approach。

Abstract: Trusted Execution Environments (TEEs) protect sensitive code and data from the operating system, hypervisor, or other untrusted software. Different solutions exist, each proposing different features. Abstraction layers aim to unify the ecosystem, allowing application developers and system administrators to leverage confidential computing as broadly and efficiently as possible. We start with an overview of representative available TEE technologies. We describe and summarize each TEE ecosystem, classifying them in different categories depending on their main design choices. Then, we propose a systematization of knowledge focusing on different abstraction layers around each design choice. We describe the underlying technologies of each design, as well as the inner workings and features of each abstraction layer. Our study reveals opportunities for improving existing abstraction layer solutions. It also highlights WebAssembly, a promising approach that supports the largest set of features. We close with a discussion on future directions for research, such as how future abstraction layers may evolve and integrate with the confidential computing ecosystem.

</details>
