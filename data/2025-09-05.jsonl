{"id": "2509.03711", "categories": ["cs.CR", "cs.SE"], "pdf": "https://arxiv.org/pdf/2509.03711", "abs": "https://arxiv.org/abs/2509.03711", "authors": ["Siddharth Muralee", "Sourag Cherupattamoolayil", "James C. Davis", "Antonio Bianchi", "Aravind Machiry"], "title": "Reactive Bottom-Up Testing", "comment": null, "summary": "Modern computing systems remain rife with software vulnerabilities. Engineers\napply many means to detect them, of which dynamic testing is one of the most\ncommon and effective. However, most dynamic testing techniques follow a\ntop-down paradigm, and struggle to reach and exercise functions deep within the\ncall graph. While recent works have proposed Bottom-Up approaches to address\nthese limitations, they face challenges with false positives and generating\nvalid inputs that adhere to the context of the entire program.\n  In this work, we introduce a new paradigm that we call Reactive Bottom-Up\nTesting. Our insight is that function-level testing is necessary but not\nsufficient for the validation of vulnerabilities in functions. What we need is\na systematic approach that not only tests functions in isolation but also\nvalidates their behavior within the broader program context, ensuring that\ndetected vulnerabilities are both reachable and triggerable. We develop a\nthree-stage bottom-up testing scheme: (1) identify likely-vulnerable functions\nand generate type- and context-aware harnesses; (2) fuzz to find crashes and\nextract input constraints via symbolic execution; (3) verify crashes by\ncombining constraints to remove false positives. We implemented an automated\nprototype, which we call Griller. We evaluated Griller in a controlled setting\nusing a benchmark of 48 known vulnerabilities across 5 open-source projects,\nwhere we successfully detected 28 known vulnerabilities. Additionally, we\nevaluated Griller on several real-world applications such as Pacman, and it\ndiscovered 6 previously unknown vulnerabilities. Our findings suggest that\nReactive Bottom-Up Testing can significantly enhance the detection of\nvulnerabilities in complex systems, paving the way for more robust security\npractices."}
{"id": "2509.03744", "categories": ["cs.CR"], "pdf": "https://arxiv.org/pdf/2509.03744", "abs": "https://arxiv.org/abs/2509.03744", "authors": ["Hamid Barati"], "title": "A Quantum Genetic Algorithm-Enhanced Self-Supervised Intrusion Detection System for Wireless Sensor Networks in the Internet of Things", "comment": null, "summary": "The rapid expansion of the Internet of Things (IoT) and Wireless Sensor\nNetworks (WSNs) has significantly increased the attack surface of such systems,\nmaking them vulnerable to a wide range of cyber threats. Traditional Intrusion\nDetection Systems (IDS) often fail to meet the stringent requirements of\nresource-constrained IoT environments due to their high computational cost and\nreliance on large labeled datasets. To address these challenges, this paper\nproposes a novel hybrid Intrusion Detection System that integrates a Quantum\nGenetic Algorithm (QGA) with Self-Supervised Learning (SSL). The QGA leverages\nquantum-inspired evolutionary operators to optimize feature selection and\nfine-tune model parameters, ensuring lightweight yet efficient detection in\nresource-limited networks. Meanwhile, SSL enables the system to learn robust\nrepresentations from unlabeled data, thereby reducing dependency on manually\nlabeled training sets. The proposed framework is evaluated on benchmark IoT\nintrusion datasets, demonstrating superior performance in terms of detection\naccuracy, false positive rate, and computational efficiency compared to\nconventional evolutionary and deep learning-based IDS models. The results\nhighlight the potential of combining quantum-inspired optimization with\nself-supervised paradigms to design next-generation intrusion detection\nsolutions for IoT and WSN environments."}
{"id": "2509.03806", "categories": ["cs.CR"], "pdf": "https://arxiv.org/pdf/2509.03806", "abs": "https://arxiv.org/abs/2509.03806", "authors": ["Hao Nie", "Wei Wang", "Peng Xu", "Wei Chen", "Laurence T. Yang", "Mauro Conti", "Kaitai Liang"], "title": "Peekaboo, I See Your Queries: Passive Attacks Against DSSE Via Intermittent Observations", "comment": null, "summary": "Dynamic Searchable Symmetric Encryption (DSSE) allows secure searches over a\ndynamic encrypted database but suffers from inherent information leakage.\nExisting passive attacks against DSSE rely on persistent leakage monitoring to\ninfer leakage patterns, whereas this work targets intermittent observation - a\nmore practical threat model. We propose Peekaboo - a new universal attack\nframework - and the core design relies on inferring the search pattern and\nfurther combining it with auxiliary knowledge and other leakage. We instantiate\nPeekaboo over the SOTA attacks, Sap (USENIX' 21) and Jigsaw (USENIX' 24), to\nderive their \"+\" variants (Sap+ and Jigsaw+). Extensive experiments demonstrate\nthat our design achieves >0.9 adjusted rand index for search pattern recovery\nand 90% query accuracy vs. FMA's 30% (CCS' 23). Peekaboo's accuracy scales with\nobservation rounds and the number of observed queries but also it resists SOTA\ncountermeasures, with >40% accuracy against file size padding and >80% against\nobfuscation."}
{"id": "2509.03807", "categories": ["cs.CR", "cs.SE"], "pdf": "https://arxiv.org/pdf/2509.03807", "abs": "https://arxiv.org/abs/2509.03807", "authors": ["Junhui Li", "Chengbin Feng", "Zhiwei Yang", "Qi Mo", "Wei Wang"], "title": "BIDO: A Unified Approach to Address Obfuscation and Concept Drift Challenges in Image-based Malware Detection", "comment": null, "summary": "To identify malicious Android applications, various malware detection\ntechniques have been proposed. Among them, image-based approaches are\nconsidered potential alternatives due to their efficiency and scalability.\nRecent studies have reported that these approaches suffer significant\nperformance declines when confronted with obfuscation or concept drift.\nHowever, existing solutions often treat these two challenges as different\nproblems, offering independent solutions. These techniques overlook the fact\nthat both challenges share a common statistical root, out-of-distribution, and\nresearch from this perspective remains limited. In response, we propose BIDO, a\nhybrid image-based malware detector designed to enhance robustness against both\nobfuscation and concept drift simultaneously. Specifically, to improve the\ndiscriminative power of image features, we introduce a local feature selection\nmodule that identifies informative subregions within malware images. Second, to\nenhance feature robustness, we model pairwise cross-modal dependencies in an\nouter product space, enabling the extraction of stable co-occurrence patterns.\nThird, to ensure feature compactness, we design a learnable metric that pulls\nsamples with identical labels closer while pushing apart those with different\nlabels, regardless of obfuscation or concept drift. Extensive experiments on\nthe real-world datasets demonstrate that BIDO significantly outperforms\nexisting baselines, achieving higher robustness against both concept drift and\nobfuscation. The source code is available at:\nhttps://github.com/whatishope/BIDO/."}
{"id": "2509.03821", "categories": ["cs.CR"], "pdf": "https://arxiv.org/pdf/2509.03821", "abs": "https://arxiv.org/abs/2509.03821", "authors": ["Rui Zhao", "Muhammad Shoaib", "Viet Tung Hoang", "Wajih Ul Hassan"], "title": "Rethinking Tamper-Evident Logging: A High-Performance, Co-Designed Auditing System", "comment": "This paper has been accepted to the ACM Conference on Computer and\n  Communications Security (CCS) 2025", "summary": "Existing tamper-evident logging systems suffer from high overhead and severe\ndata loss in high-load settings, yet only provide coarse-grained tamper\ndetection. Moreover, installing such systems requires recompiling kernel code.\nTo address these challenges, we present Nitro, a high-performance,\ntamper-evident audit logging system that supports fine-grained detection of log\ntampering. Even better, our system avoids kernel recompilation by using the\neBPF technology. To formally justify the security of Nitro, we provide a new\ndefinitional framework for logging systems, and give a practical cryptographic\nconstruction meeting this new goal. Unlike prior work that focus only on the\ncryptographic processing, we codesign the cryptographic part with the pre- and\npost-processing of the logs to exploit all system-level optimizations. Our\nevaluations demonstrate Nitro's superior performance, achieving 10X-25X\nimprovements in high-stress conditions and 2X-10X in real-world scenarios while\nmaintaining near-zero data loss. We also provide an advanced variant, Nitro-R\nthat introduces in-kernel log reduction techniques to reduce runtime overhead\neven further."}
{"id": "2509.03860", "categories": ["cs.CR"], "pdf": "https://arxiv.org/pdf/2509.03860", "abs": "https://arxiv.org/abs/2509.03860", "authors": ["Yifan Jia", "Ye Tian", "Liguo Zhang", "Yanbin Wang", "Jianguo Sun", "Liangliang Song"], "title": "KGBERT4Eth: A Feature-Complete Transformer Powered by Knowledge Graph for Multi-Task Ethereum Fraud Detection", "comment": "This work has been submitted to the IEEE for possible publication", "summary": "Ethereum's rapid ecosystem expansion and transaction anonymity have triggered\na surge in malicious activity. Detection mechanisms currently bifurcate into\nthree technical strands: expert-defined features, graph embeddings, and\nsequential transaction patterns, collectively spanning the complete feature\nsets of Ethereum's native data layer. Yet the absence of cross-paradigm\nintegration mechanisms forces practitioners to choose between sacrificing\nsequential context awareness, structured fund-flow patterns, or human-curated\nfeature insights in their solutions. To bridge this gap, we propose KGBERT4Eth,\na feature-complete pre-training encoder that synergistically combines two key\ncomponents: (1) a Transaction Semantic Extractor, where we train an enhanced\nTransaction Language Model (TLM) to learn contextual semantic representations\nfrom conceptualized transaction records, and (2) a Transaction Knowledge Graph\n(TKG) that incorporates expert-curated domain knowledge into graph node\nembeddings to capture fund flow patterns and human-curated feature insights. We\njointly optimize pre-training objectives for both components to fuse these\ncomplementary features, generating feature-complete embeddings. To emphasize\nrare anomalous transactions, we design a biased masking prediction task for TLM\nto focus on statistical outliers, while the Transaction TKG employs link\nprediction to learn latent transaction relationships and aggregate knowledge.\nFurthermore, we propose a mask-invariant attention coordination module to\nensure stable dynamic information exchange between TLM and TKG during\npre-training. KGBERT4Eth significantly outperforms state-of-the-art baselines\nin both phishing account detection and de-anonymization tasks, achieving\nabsolute F1-score improvements of 8-16% on three phishing detection benchmarks\nand 6-26% on four de-anonymization datasets."}
{"id": "2509.03879", "categories": ["cs.CR", "cs.SY", "eess.SY"], "pdf": "https://arxiv.org/pdf/2509.03879", "abs": "https://arxiv.org/abs/2509.03879", "authors": ["Gang Liu", "Ningjie Li", "Cen Chen"], "title": "ShieldMMU: Detecting and Defending against Controlled-Channel Attacks in Shielding Memory System", "comment": null, "summary": "Intel SGX and hypervisors isolate non-privileged programs from other\nsoftware, ensuring confidentiality and integrity. However, side-channel attacks\ncontinue to threaten Intel SGX's security, enabling malicious OS to manipulate\nPTE present bits, induce page faults, and steal memory access traces. Despite\nextensive research, existing defenses focus on detection or rely on impractical\nsolutions. This paper presents ShieldMMU, a comprehensive solution for\nmitigating controlled channel attacks, balancing compatibility, performance,\nand usability. Leveraging a Merkle Tree-inspired Defense Tree (DD-Tree),\nShieldMMU protects PTE integrity by detecting, locating, and restoring attacked\nPTEs. It identifies MMU page table lookup events and side-channel attacks,\npromptly restoring PTE parameters to prevent page fault traps and ensure secure\nnon-privileged application operation within SGX. Our experiments confirm\nShieldMMU's enhanced security and acceptable latency performance."}
{"id": "2509.03939", "categories": ["cs.CR", "cs.LG"], "pdf": "https://arxiv.org/pdf/2509.03939", "abs": "https://arxiv.org/abs/2509.03939", "authors": ["Yifan Jia", "Yanbin Wang", "Jianguo Sun", "Ye Tian", "Peng Qian"], "title": "LMAE4Eth: Generalizable and Robust Ethereum Fraud Detection by Exploring Transaction Semantics and Masked Graph Embedding", "comment": "This work has been submitted to the IEEE for possible publication", "summary": "Current Ethereum fraud detection methods rely on context-independent,\nnumerical transaction sequences, failing to capture semantic of account\ntransactions. Furthermore, the pervasive homogeneity in Ethereum transaction\nrecords renders it challenging to learn discriminative account embeddings.\nMoreover, current self-supervised graph learning methods primarily learn node\nrepresentations through graph reconstruction, resulting in suboptimal\nperformance for node-level tasks like fraud account detection, while these\nmethods also encounter scalability challenges. To tackle these challenges, we\npropose LMAE4Eth, a multi-view learning framework that fuses transaction\nsemantics, masked graph embedding, and expert knowledge. We first propose a\ntransaction-token contrastive language model (TxCLM) that transforms\ncontext-independent numerical transaction records into logically cohesive\nlinguistic representations. To clearly characterize the semantic differences\nbetween accounts, we also use a token-aware contrastive learning pre-training\nobjective together with the masked transaction model pre-training objective,\nlearns high-expressive account representations. We then propose a masked\naccount graph autoencoder (MAGAE) using generative self-supervised learning,\nwhich achieves superior node-level account detection by focusing on\nreconstructing account node features. To enable MAGAE to scale for large-scale\ntraining, we propose to integrate layer-neighbor sampling into the graph, which\nreduces the number of sampled vertices by several times without compromising\ntraining quality. Finally, using a cross-attention fusion network, we unify the\nembeddings of TxCLM and MAGAE to leverage the benefits of both. We evaluate our\nmethod against 21 baseline approaches on three datasets. Experimental results\nshow that our method outperforms the best baseline by over 10% in F1-score on\ntwo of the datasets."}
{"id": "2509.03985", "categories": ["cs.CR", "cs.AI"], "pdf": "https://arxiv.org/pdf/2509.03985", "abs": "https://arxiv.org/abs/2509.03985", "authors": ["Chuhan Zhang", "Ye Zhang", "Bowen Shi", "Yuyou Gan", "Tianyu Du", "Shouling Ji", "Dazhan Deng", "Yingcai Wu"], "title": "NeuroBreak: Unveil Internal Jailbreak Mechanisms in Large Language Models", "comment": "12 pages, 9 figures", "summary": "In deployment and application, large language models (LLMs) typically undergo\nsafety alignment to prevent illegal and unethical outputs. However, the\ncontinuous advancement of jailbreak attack techniques, designed to bypass\nsafety mechanisms with adversarial prompts, has placed increasing pressure on\nthe security defenses of LLMs. Strengthening resistance to jailbreak attacks\nrequires an in-depth understanding of the security mechanisms and\nvulnerabilities of LLMs. However, the vast number of parameters and complex\nstructure of LLMs make analyzing security weaknesses from an internal\nperspective a challenging task. This paper presents NeuroBreak, a top-down\njailbreak analysis system designed to analyze neuron-level safety mechanisms\nand mitigate vulnerabilities. We carefully design system requirements through\ncollaboration with three experts in the field of AI security. The system\nprovides a comprehensive analysis of various jailbreak attack methods. By\nincorporating layer-wise representation probing analysis, NeuroBreak offers a\nnovel perspective on the model's decision-making process throughout its\ngeneration steps. Furthermore, the system supports the analysis of critical\nneurons from both semantic and functional perspectives, facilitating a deeper\nexploration of security mechanisms. We conduct quantitative evaluations and\ncase studies to verify the effectiveness of our system, offering mechanistic\ninsights for developing next-generation defense strategies against evolving\njailbreak attacks."}
{"id": "2509.04010", "categories": ["cs.CR"], "pdf": "https://arxiv.org/pdf/2509.04010", "abs": "https://arxiv.org/abs/2509.04010", "authors": ["Olivier Adjonyo", "Sebastien Bardin", "Emanuele Bellini", "Gilbert Ndollane Dione", "Mahmudul Faisal Al Ameen", "Robert Merget", "Frederic Recoules", "Yanis Sellami"], "title": "Systematic Timing Leakage Analysis of NIST PQDSS Candidates: Tooling and Lessons Learned", "comment": "20 pages, 1 figure, to be published and presented at Sixth PQC\n  Standardization Conference by NIST, partially supported by the \"France 2030\"\n  government investment plan managed by the French National Research Agency,\n  under the reference ANR-22-PECY-0005", "summary": "The PQDSS standardization process requires cryptographic primitives to be\nfree from vulnerabilities, including timing and cache side-channels. Resistance\nto timing leakage is therefore an essential property, and achieving this\ntypically relies on software implementations that follow constant-time\nprinciples. Moreover, ensuring that all implementations are constant-time is\ncrucial for fair performance comparisons, as secure implementations often incur\nadditional overhead. Such analysis also helps identify scheme proposals that\nare inherently difficult to implement in constant time. Because constant-time\nproperties can be broken during compilation, it is often necessary to analyze\nthe compiled binary directly. Since manual binary analysis is extremely\nchallenging, automated analysis becomes highly important. Although several\ntools exist to assist with such analysis, they often have usability limitations\nand are difficult to set up correctly. To support the developers besides the\nNIST committee in verifying candidates, we developed a toolchain that automates\nconfiguration, execution, and result analysis for several widely used\nconstant-time analysis tools. We selected TIMECOP and Binsec/Rel2 to verify\nconstant-time policy compliance at the binary level, and dudect and RTLF to\ndetect side-channel vulnerabilities through statistical analysis of execution\ntime behavior. We demonstrate its effectiveness and practicability by\nevaluating the NIST PQDSS round 1 and round 2 implementations. We reported 26\nissues in total to the respective developers, and 5 of them have already been\nfixed. We also discuss our different findings, as well as the benefits of\nshortcomings of the different tools."}
{"id": "2509.04070", "categories": ["cs.CR", "cs.AR"], "pdf": "https://arxiv.org/pdf/2509.04070", "abs": "https://arxiv.org/abs/2509.04070", "authors": ["Paresh Baidya", "Rourab Paul", "Vikas Srivastava", "Sumit Kumar Debnath"], "title": "Error Detection Schemes for Barrett Reduction of CT-BU on FPGA in Post Quantum Cryptography", "comment": null, "summary": "A fault can occur naturally or intentionally. However, intentionally\ninjecting faults into hardware accelerators of Post-Quantum Cryptographic (PQC)\nalgorithms may leak sensitive information. This intentional fault injection in\nside-channel attacks compromises the reliability of PQC implementations. The\nrecently NIST-standardized key encapsulation mechanism (KEM), Kyber may also\nleak information at the hardware implementation level. This work proposes three\nefficient and lightweight recomputation-based fault detection methods for\nBarrett Reduction in the Cooley-Tukey Butterfly Unit (CT-BU) of Kyber on a\nField Programmable Gate Array (FPGA). The CT-BU and Barrett Reduction are\nfundamental components in structured lattice-based PQC algorithms, including\nKyber, NTRU, Falcon, CRYSTALS-Dilithium, etc. This paper introduces a new\nalgorithm, Recomputation with Swapped Operand (RESWO), for fault detection.\nWhile Recomputation with Negated Operand (RENO) and Recomputation with Shifted\nOperand (RESO) are existing methods used in other PQC hardware algorithms. To\nthe best of our knowledge, RENO and RESO have never been used in Barrett\nReduction before. The proposed RESWO method consumes a similar number of slices\ncompared to RENO and RESO. However, RESWO shows lesser delay compared to both\nRENO and RESO. The fault detection efficiency of RESWO, RENO, and RESO is\nnearly 100%."}
{"id": "2509.04080", "categories": ["cs.CR"], "pdf": "https://arxiv.org/pdf/2509.04080", "abs": "https://arxiv.org/abs/2509.04080", "authors": ["Francesco Aurelio Pironti", "Angelo Furfaro", "Francesco Blefari", "Carmelo Felicetti", "Matteo Lupinacci", "Francesco Romeo"], "title": "ICSLure: A Very High Interaction Honeynet for PLC-based Industrial Control Systems", "comment": null, "summary": "The security of Industrial Control Systems (ICSs) is critical to ensuring the\nsafety of industrial processes and personnel. The rapid adoption of Industrial\nInternet of Things (IIoT) technologies has expanded system functionality but\nalso increased the attack surface, exposing ICSs to a growing range of cyber\nthreats. Honeypots provide a means to detect and analyze such threats by\nemulating target systems and capturing attacker behavior. However, traditional\nICS honeypots, often limited to software-based simulations of a single\nProgrammable Logic Controller (PLC), lack the realism required to engage\nsophisticated adversaries. In this work, we introduce a modular honeynet\nframework named ICSLure. The framework has been designed to emulate realistic\nICS environments. Our approach integrates physical PLCs interacting with live\ndata sources via industrial protocols such as Modbus and Profinet RTU, along\nwith virtualized network components including routers, switches, and Remote\nTerminal Units (RTUs). The system incorporates comprehensive monitoring\ncapabilities to collect detailed logs of attacker interactions. We demonstrate\nthat our framework enables coherent and high-fidelity emulation of real-world\nindustrial plants. This high-interaction environment significantly enhances the\nquality of threat data collected and supports advanced analysis of ICS-specific\nattack strategies, contributing to more effective detection and mitigation\ntechniques."}
{"id": "2509.04091", "categories": ["cs.CR", "68M25", "K.6.5; D.2.7"], "pdf": "https://arxiv.org/pdf/2509.04091", "abs": "https://arxiv.org/abs/2509.04091", "authors": ["Jintao Gu", "Haolang Lu", "Guoshun Nan", "Yihan Lin", "Kun Wang", "Yuchun Guo", "Yigui Cao", "Yang Liu"], "title": "Revisiting Third-Party Library Detection: A Ground Truth Dataset and Its Implications Across Security Tasks", "comment": "20pages, 7figures", "summary": "Accurate detection of third-party libraries (TPLs) is fundamental to Android\nsecurity, supporting vulnerability tracking, malware detection, and supply\nchain auditing. Despite many proposed tools, their real-world effectiveness\nremains unclear.We present the first large-scale empirical study of ten\nstate-of-the-art TPL detection techniques across over 6,000 apps, enabled by a\nnew ground truth dataset with precise version-level annotations for both remote\nand local dependencies.Our evaluation exposes tool fragility to R8-era\ntransformations, weak version discrimination, inaccurate correspondence of\ncandidate libraries, difficulty in generalizing similarity thresholds, and\nprohibitive runtime/memory overheads at scale.Beyond tool assessment, we\nfurther analyze how TPLs shape downstream tasks, including vulnerability\nanalysis, malware detection, secret leakage assessment, and LLM-based\nevaluation. From this perspective, our study provides concrete insights into\nhow TPL characteristics affect these tasks and informs future improvements in\nsecurity analysis."}
{"id": "2509.04097", "categories": ["cs.CR"], "pdf": "https://arxiv.org/pdf/2509.04097", "abs": "https://arxiv.org/abs/2509.04097", "authors": ["Víctor Duarte Melo", "William J. Buchanan"], "title": "ECCFROG522PP: An Enhanced 522-bit Weierstrass Elliptic Curve", "comment": null, "summary": "Whilst many key exchange and digital signature systems still rely on NIST\nP-256 (secp256r1) and secp256k1, offering around 128-bit security, there is an\nincreasing demand for transparent and reproducible curves at the 256-bit\nsecurity level. Standard higher-security options include NIST P-521, Curve448,\nand Brainpool-P512. This paper presents ECCFROG522PP (\"Presunto Powered\"), a\n522-bit prime-field elliptic curve that delivers security in the same classical\napprox 260-bit ballpark as NIST P-521, but with a fundamentally different\ndesign philosophy. All of the curve parameters are deterministically derived\nfrom a fixed public seed via BLAKE3, with zero hidden choices. The curve has\nprime order (cofactor = 1), a verified twist with a proven approx 505-bit prime\nfactor, safe embedding degree (greater than or equal to 14), and passes\nanti-MOV checks up to k less than or equal to 200 and CM discriminant sanity up\nto 100k. Unlike prior opaque or ad-hoc constructions, ECCFROG522PP is fully\nreproducible: anyone can regenerate and verify it byte-for-byte using the\npublished scripts. The intent is not to outperform NIST P-521 in raw speed, but\nto maximise trust, verifiability, and long-term auditability in a practical\ncurve of equivalent security level"}
{"id": "2509.04191", "categories": ["cs.CR", "cs.LG"], "pdf": "https://arxiv.org/pdf/2509.04191", "abs": "https://arxiv.org/abs/2509.04191", "authors": ["Omri Sgan Cohen", "Ehud Malul", "Yair Meidan", "Dudu Mimran", "Yuval Elovici", "Asaf Shabtai"], "title": "KubeGuard: LLM-Assisted Kubernetes Hardening via Configuration Files and Runtime Logs Analysis", "comment": null, "summary": "The widespread adoption of Kubernetes (K8s) for orchestrating cloud-native\napplications has introduced significant security challenges, such as\nmisconfigured resources and overly permissive configurations. Failing to\naddress these issues can result in unauthorized access, privilege escalation,\nand lateral movement within clusters. Most existing K8s security solutions\nfocus on detecting misconfigurations, typically through static analysis or\nanomaly detection. In contrast, this paper presents KubeGuard, a novel runtime\nlog-driven recommender framework aimed at mitigating risks by addressing overly\npermissive configurations. KubeGuard is designed to harden K8s environments\nthrough two complementary tasks: Resource Creation and Resource Refinement. It\nleverages large language models (LLMs) to analyze manifests and runtime logs\nreflecting actual system behavior, using modular prompt-chaining workflows.\nThis approach enables KubeGuard to create least-privilege configurations for\nnew resources and refine existing manifests to reduce the attack surface.\nKubeGuard's output manifests are presented as recommendations that users (e.g.,\ndevelopers and operators) can review and adopt to enhance cluster security. Our\nevaluation demonstrates that KubeGuard effectively generates and refines K8s\nmanifests for Roles, NetworkPolicies, and Deployments, leveraging both\nproprietary and open-source LLMs. The high precision, recall, and F1-scores\naffirm KubeGuard's practicality as a framework that translates runtime\nobservability into actionable, least-privilege configuration guidance."}
{"id": "2509.04214", "categories": ["cs.CR"], "pdf": "https://arxiv.org/pdf/2509.04214", "abs": "https://arxiv.org/abs/2509.04214", "authors": ["Tyler Shumaker", "Jessica Carpenter", "David Saranchak", "Nathaniel D. Bastian"], "title": "An Automated, Scalable Machine Learning Model Inversion Assessment Pipeline", "comment": null, "summary": "Machine learning (ML) models have the potential to transform military\nbattlefields, presenting a large external pressure to rapidly incorporate them\ninto operational settings. However, it is well-established that these ML models\nare vulnerable to a number of adversarial attacks throughout the model\ndeployment pipeline that threaten to negate battlefield advantage. One broad\ncategory is privacy attacks (such as model inversion) where an adversary can\nreverse engineer information from the model, such as the sensitive data used in\nits training. The ability to quantify the risk of model inversion attacks\n(MIAs) is not well studied, and there is a lack of automated developmental test\nand evaluation (DT&E) tools and metrics to quantify the effectiveness of\nprivacy loss of the MIA. The current DT&E process is difficult because ML model\ninversions can be hard for a human to interpret, subjective when they are\ninterpretable, and difficult to quantify in terms of inversion quality.\nAdditionally, scaling the DT&E process is challenging due to many ML model\narchitectures and data modalities that need to be assessed. In this work, we\npresent a novel DT&E tool that quantifies the risk of data privacy loss from\nMIAs and introduces four adversarial risk dimensions to quantify privacy loss.\nOur DT&E pipeline combines inversion with vision language models (VLMs) to\nimprove effectiveness while enabling scalable analysis. We demonstrate\neffectiveness using multiple MIA techniques and VLMs configured for zero-shot\nclassification and image captioning. We benchmark the pipeline using several\nstate-of-the-art MIAs in the computer vision domain with an image\nclassification task that is typical in military applications. In general, our\ninnovative pipeline extends the current model inversion DT&E capabilities by\nimproving the effectiveness and scalability of the privacy loss analysis in an\nautomated fashion."}
