<div id=toc></div>

# Table of Contents

- [cs.CR](#cs.CR) [Total: 18]


<div id='cs.CR'></div>

# cs.CR [[Back]](#toc)

### [1] [Energy-Efficient Multi-LLM Reasoning for Binary-Free Zero-Day Detection in IoT Firmware](https://arxiv.org/abs/2512.19945)
*Saeid Jamshidi,Omar Abdul-Wahab,Martine Bellaïche,Foutse Khomh*

Main category: cs.CR

TL;DR: 提出一种无需二进制代码、架构无关的IoT固件零日漏洞评估方法，通过多LLM推理架构和高层描述符预测漏洞可能性。


<details>
  <summary>Details</summary>
Motivation: IoT固件安全分析面临挑战：专有二进制、符号剥离、异构架构、代码访问受限。现有方法依赖二进制可见性和功能仿真，当固件加密或不可访问时不可靠。

Method: 1. 基于高层描述符的架构无关解决方案；2. 三LLM推理架构：LLaMA配置解释器、DeepSeek结构抽象分析器、GPT-4o语义融合模型；3. 集成LLM计算签名（延迟模式、不确定性标记、推理深度指标）和能量感知符号负载模型；4. 建立推理管道的数学基础，证明单调性、发散性和能量-风险耦合特性。

Result: 模拟评估显示：高暴露条件下，预测的零日漏洞可能性增加20-35%；GPT-4o表现出最强的跨层相关性和最高敏感性；能量和发散性指标显著预测风险升高(p<0.01)。

Conclusion: 提出的推理框架有效解决了传统二进制分析方法的局限性，为加密或不可访问的IoT固件提供了一种可行的零日漏洞评估方法，理论分析和实验结果验证了其有效性。

Abstract: Securing Internet of Things (IoT) firmware remains difficult due to proprietary binaries, stripped symbols, heterogeneous architectures, and limited access to executable code. Existing analysis methods, such as static analysis, symbolic execution, and fuzzing, depend on binary visibility and functional emulation, making them unreliable when firmware is encrypted or inaccessible. To address this limitation, we propose a binary-free, architecture-agnostic solution that estimates the likelihood of conceptual zero-day vulnerabilities using only high-level descriptors. The approach integrates a tri-LLM reasoning architecture combining a LLaMA-based configuration interpreter, a DeepSeek-based structural abstraction analyzer, and a GPT-4o semantic fusion model. The solution also incorporates LLM computational signatures, including latency patterns, uncertainty markers, and reasoning depth indicators, as well as an energy-aware symbolic load model, to enhance interpretability and operational feasibility. In addition, we formally derive the mathematical foundations of the reasoning pipeline, establishing monotonicity, divergence, and energy-risk coupling properties that theoretically justify the model's behavior. Simulation-based evaluation reveals that high exposure conditions increase the predicted zero-day likelihood by 20 to 35 percent across models, with GPT-4o demonstrating the strongest cross-layer correlations and the highest sensitivity. Energy and divergence metrics significantly predict elevated risk (p < 0.01), reinforcing the effectiveness of the proposed reasoning framework.

</details>


### [2] [Efficient Mod Approximation and Its Applications to CKKS Ciphertexts](https://arxiv.org/abs/2512.19951)
*Yufei Zhou*

Main category: cs.CR

TL;DR: 提出基于多项式插值和切比雪夫级数的新方法，在CKKS同态加密中准确近似模函数，并设计BitStack和CRTStack数据打包方案，实现高效密文上传和完整输入范围的模运算。


<details>
  <summary>Details</summary>
Motivation: 模函数在数据编码和密码学中至关重要，但CKKS同态加密方案仅支持算术运算，难以在加密数据上执行模计算。现有方法只能在有限子范围内提供准确结果，无法实现完整输入范围的准确近似。

Method: 基于多项式插值和切比雪夫级数近似模函数，设计BitStack和CRTStack两种针对CKKS小整数输入的数据打包方案，提高明文空间利用率，支持高效密文上传。

Result: 实验结果显示达到高达1e-8的近似精度，实现了准确的密文舍入操作和从加法秘密共享到CKKS密文的完整转换。

Conclusion: 为CKKS中的模运算提供了实用且通用的解决方案，扩展了隐私保护计算的应用范围，实现了完整输入范围的准确模函数近似。

Abstract: The mod function plays a critical role in numerous data encoding and cryptographic primitives. However, the widely used CKKS homomorphic encryption (HE) scheme supports only arithmetic operations, making it difficult to perform mod computations on encrypted data. Approximating the mod function with polynomials has therefore become an important yet challenging problem. The discontinuous and periodic characteristics of the mod function make it particularly difficult to approximate accurately under HE. Existing homomorphic mod constructions provide accurate results only within limited subranges of the input range, leaving the problem of achieving accurate approximation across the full input range unresolved. In this work, we propose a novel method based on polynomial interpolation and Chebyshev series to accurately approximate the mod function. Building upon this, we design two efficient data packing schemes, BitStack and CRTStack, tailored for small-integer inputs in CKKS. These schemes significantly improve the utilization of the CKKS plaintext space and enable efficient ciphertext uploads. Furthermore, we apply the proposed HE mod function to implement a homomorphic rounding operation and a general transformation from additive secret sharing to CKKS ciphertexts, achieving accurate ciphertext rounding and complete secret-share-to-CKKS conversion. Experimental results demonstrate that our approach achieves high approximation accuracy (up to 1e-8). Overall, our work provides a practical and general solution for performing mod operations under CKKS, extending its applicability to a broader range of privacy-preserving computations.

</details>


### [3] [Fast Deterministically Safe Proof-of-Work Consensus](https://arxiv.org/abs/2512.19968)
*Ali Farahbakhsh,Giuliano Losa,Youer Pu,Lorenzo Alvisi,Ittay Eyal*

Main category: cs.CR

TL;DR: Sieve-MMR是首个具有确定性安全性和恒定预期延迟的完全无许可协议，不依赖外部机制，通过将PoS协议MMR移植到PoW设置中实现。


<details>
  <summary>Details</summary>
Motivation: 现有无许可区块链（PoW和PoS）都存在安全漏洞：PoS易受长程攻击，PoW易受算力攻击。PoS依赖外部社会共识，PoW要么依赖概率保证，要么速度慢。需要一种既安全又高效的解决方案。

Method: 将PoS协议MMR移植到PoW设置中，提出Sieve算法实现时间旅行弹性广播（TTRB）。Sieve使用黑盒确定性PoW原语实现TTRB，作为MMR的消息传递层。

Result: Sieve-MMR继承了MMR的恒定预期延迟和确定性安全性，同时通过PoW获得对长程攻击的抵抗力。解决了时间旅行攻击问题。

Conclusion: Sieve-MMR是首个实现确定性安全性和恒定延迟的无许可协议，不依赖外部机制，为区块链共识提供了新的安全高效解决方案。

Abstract: Permissionless blockchains achieve consensus while allowing unknown nodes to join and leave the system at any time. They typically come in two flavors: proof of work (PoW) and proof of stake (PoS), and both are vulnerable to attacks. PoS protocols suffer from long-range attacks, wherein attackers alter execution history at little cost, and PoW protocols are vulnerable to attackers with enough computational power to subvert execution history. PoS protocols respond by relying on external mechanisms like social consensus; PoW protocols either fall back to probabilistic guarantees, or are slow.
  We present Sieve-MMR, the first fully-permissionless protocol with deterministic security and constant expected latency that does not rely on external mechanisms. We obtain Sieve-MMR by porting a PoS protocol (MMR) to the PoW setting. From MMR we inherit constant expected latency and deterministic security, and proof-of-work gives us resilience against long-range attacks. The main challenge to porting MMR to the PoW setting is what we call time-travel attacks, where attackers use PoWs generated in the distant past to increase their perceived PoW power in the present. We respond by proposing Sieve, a novel algorithm that implements a new broadcast primitive we dub time-travel-resilient broadcast (TTRB). Sieve relies on a black-box, deterministic PoW primitive to implement TTRB, which we use as the messaging layer for MMR.

</details>


### [4] [BacAlarm: Mining and Simulating Composite API Traffic to Prevent Broken Access Control Violations](https://arxiv.org/abs/2512.19997)
*Yanjing Yang,He Zhang,Bohan Liu,Jinwei Xu,Jinghao Hu,Liming Dong,Zhewen Mao,Dongxue Pan*

Main category: cs.CR

TL;DR: BAC是一种通过生成API流量数据来检测Broken Access Control违规的方法，包含API流量生成器和BAC检测器，在F1和MCC指标上比现有方法提升超过20%


<details>
  <summary>Details</summary>
Motivation: BAC违规是OWASP API安全十大风险之一，但现有学习方法面临两大挑战：1) RESTful API设计下训练数据严重短缺；2) BAC违规由多个看似正常的关联请求组成，而非单个异常请求

Method: 提出BAC方法，包含API流量生成器（生成训练数据）和BAC检测器（检测违规）。通过生成API流量数据解决数据短缺问题，并设计检测器处理多个关联请求的模式

Result: 实验结果显示BAC在F1和MCC指标上分别比现有最先进的基于不变式和基于学习的方法提升21.2%和24.1%

Conclusion: BAC方法有效解决了BAC违规检测中的数据短缺和模式识别挑战，显著提升了检测性能，为API安全提供了实用解决方案

Abstract: Broken Access Control (BAC) violations, which consistently rank among the top five security risks in the OWASP API Security Top 10, refer to unauthorized access attempts arising from BAC vulnerabilities, whose successful exploitation can impose significant risks on exposed application programming interfaces (APIs). In recent years, learning-based methods have demonstrated promising prospects in detecting various types of malicious activities. However, in real-network operation and maintenance scenarios, leveraging learning-based methods for BAC detection faces two critical challenges. Firstly, under the RESTful API design principles, most systems omit recording composite traffic for performance, and together with ethical and legal bans on directly testing real-world systems, this leads to a critical shortage of training data for detecting BAC violations. Secondly, common malicious behaviors such as SQL injection typically generate individual access traffic that is inherently anomalous. In contrast, BAC is usually composed of multiple correlated access requests that appear normal when examined in isolation. To tackle these problems, we introduce \BAC, an approach for establishing a BAC violation detection model by generating and utilizing API traffic data. The \BAC consists of an API Traffic Generator and a BAC Detector. Experimental results show that \BAC outperforms current state-of-the-art invariant-based and learning-based methods with the $\text{F}_1$ and MCC improving by 21.2\% and 24.1\%.

</details>


### [5] [IoT-based Android Malware Detection Using Graph Neural Network With Adversarial Defense](https://arxiv.org/abs/2512.20004)
*Rahul Yumlembam,Biju Issac,Seibu Mary Jacob,Longzhi Yang*

Main category: cs.CR

TL;DR: 该论文提出基于GNN的Android恶意软件检测方法，并针对其脆弱性设计了VGAE-MalGAN对抗攻击算法，通过对抗训练提升模型鲁棒性。


<details>
  <summary>Details</summary>
Motivation: 随着Android应用在IoT中的广泛应用，恶意软件检测变得至关重要。现有基于图的深度学习方法虽然有效，但容易受到对抗攻击，攻击者可以通过添加虚假关系来逃避检测。

Method: 1. 使用GNN分类器从API图中生成图嵌入，结合权限和Intent特征训练多种机器学习模型进行恶意软件检测。2. 提出VGAE-MalGAN对抗攻击算法，生成对抗性恶意API图来攻击GNN分类器，并通过对抗训练提升模型鲁棒性。

Result: 提出的分类方法在CICMaldroid数据集上达到98.33%准确率，在Drebin数据集上达到98.68%准确率。VGAE-MalGAN能显著降低GNN分类器的检测率，但通过对抗训练可以恢复检测能力并提升鲁棒性。

Conclusion: 基于图的GNN方法在Android恶意软件检测中表现优异，但存在对抗攻击脆弱性。提出的VGAE-MalGAN攻击算法揭示了这种脆弱性，而对抗训练是提升模型鲁棒性的有效方法。

Abstract: Since the Internet of Things (IoT) is widely adopted using Android applications, detecting malicious Android apps is essential. In recent years, Android graph-based deep learning research has proposed many approaches to extract relationships from applications as graphs to generate graph embeddings. First, we demonstrate the effectiveness of graph-based classification using a Graph Neural Network (GNN)-based classifier to generate API graph embeddings. The graph embeddings are combined with Permission and Intent features to train multiple machine learning and deep learning models for Android malware detection. The proposed classification approach achieves an accuracy of 98.33 percent on the CICMaldroid dataset and 98.68 percent on the Drebin dataset. However, graph-based deep learning models are vulnerable, as attackers can add fake relationships to evade detection by the classifier. Second, we propose a Generative Adversarial Network (GAN)-based attack algorithm named VGAE-MalGAN targeting graph-based GNN Android malware classifiers. The VGAE-MalGAN generator produces adversarial malware API graphs, while the VGAE-MalGAN substitute detector attempts to mimic the target detector. Experimental results show that VGAE-MalGAN can significantly reduce the detection rate of GNN-based malware classifiers. Although the model initially fails to detect adversarial malware, retraining with generated adversarial samples improves robustness and helps mitigate adversarial attacks.

</details>


### [6] [On the Effectiveness of Instruction-Tuning Local LLMs for Identifying Software Vulnerabilities](https://arxiv.org/abs/2512.20062)
*Sangryu Park,Gihyuk Ko,Homook Cho*

Main category: cs.CR

TL;DR: 该论文提出将软件漏洞分析重新定义为漏洞识别任务，使用本地指令调优的小型LLM替代在线API大模型，在保护代码隐私的同时提升CWE类型识别的性能。


<details>
  <summary>Details</summary>
Motivation: 当前LLM在软件漏洞分析中存在两个主要问题：1）依赖在线API服务需要公开源代码，存在隐私风险；2）仅进行二元分类（有漏洞/无漏洞），实用性有限。需要更安全、更实用的解决方案。

Method: 将问题重新定义为软件漏洞识别（SVI），要求LLM输出CWE弱点类型ID而非简单二元判断。采用指令调优（instruct-tuning）本地可部署的小型LLM，替代大型在线API模型。

Result: 指令调优的本地LLM在整体性能和成本权衡方面优于在线API大模型，能够更准确地识别CWE漏洞类型，同时保护源代码隐私。

Conclusion: 指令调优的本地模型为实际漏洞管理工作流提供了更有效、安全、实用的LLM应用方案，解决了现有方法的隐私限制和功能局限性。

Abstract: Large Language Models (LLMs) show significant promise in automating software vulnerability analysis, a critical task given the impact of security failure of modern software systems. However, current approaches in using LLMs to automate vulnerability analysis mostly rely on using online API-based LLM services, requiring the user to disclose the source code in development. Moreover, they predominantly frame the task as a binary classification(vulnerable or not vulnerable), limiting potential practical utility. This paper addresses these limitations by reformulating the problem as Software Vulnerability Identification (SVI), where LLMs are asked to output the type of weakness in Common Weakness Enumeration (CWE) IDs rather than simply indicating the presence or absence of a vulnerability. We also tackle the reliance on large, API-based LLMs by demonstrating that instruction-tuning smaller, locally deployable LLMs can achieve superior identification performance. In our analysis, instruct-tuning a local LLM showed better overall performance and cost trade-off than online API-based LLMs. Our findings indicate that instruct-tuned local models represent a more effective, secure, and practical approach for leveraging LLMs in real-world vulnerability management workflows.

</details>


### [7] [Odysseus: Jailbreaking Commercial Multimodal LLM-integrated Systems via Dual Steganography](https://arxiv.org/abs/2512.20168)
*Songze Li,Jiameng Cheng,Yiming Li,Xiaojun Jia,Dacheng Tao*

Main category: cs.CR

TL;DR: 本文提出Odysseus攻击方法，通过双隐写术在多模态大语言模型系统中隐藏恶意内容，成功绕过现有安全过滤器，攻击成功率高达99%。


<details>
  <summary>Details</summary>
Motivation: 现有MLLM系统的安全过滤器基于一个关键假设：恶意内容必须在输入或输出中明确可见。然而在多模态系统中，攻击者可以利用多个模态隐藏恶意意图，导致现有防御存在盲区。

Method: 提出Odysseus攻击范式，采用双隐写术技术，将恶意查询和响应隐蔽地嵌入看似良性的图像中，从而绕过基于文本内容检测的安全过滤器。

Result: 在基准数据集上的广泛实验表明，Odysseus成功攻击了多个领先的实用MLLM系统，攻击成功率高达99%，暴露了现有防御的根本盲点。

Conclusion: 该研究揭示了MLLM集成系统中跨模态安全的根本缺陷，挑战了现有安全过滤器的核心假设，呼吁重新思考多模态系统的安全防御机制。

Abstract: By integrating language understanding with perceptual modalities such as images, multimodal large language models (MLLMs) constitute a critical substrate for modern AI systems, particularly intelligent agents operating in open and interactive environments. However, their increasing accessibility also raises heightened risks of misuse, such as generating harmful or unsafe content. To mitigate these risks, alignment techniques are commonly applied to align model behavior with human values. Despite these efforts, recent studies have shown that jailbreak attacks can circumvent alignment and elicit unsafe outputs. Currently, most existing jailbreak methods are tailored for open-source models and exhibit limited effectiveness against commercial MLLM-integrated systems, which often employ additional filters. These filters can detect and prevent malicious input and output content, significantly reducing jailbreak threats. In this paper, we reveal that the success of these safety filters heavily relies on a critical assumption that malicious content must be explicitly visible in either the input or the output. This assumption, while often valid for traditional LLM-integrated systems, breaks down in MLLM-integrated systems, where attackers can leverage multiple modalities to conceal adversarial intent, leading to a false sense of security in existing MLLM-integrated systems. To challenge this assumption, we propose Odysseus, a novel jailbreak paradigm that introduces dual steganography to covertly embed malicious queries and responses into benign-looking images. Extensive experiments on benchmark datasets demonstrate that our Odysseus successfully jailbreaks several pioneering and realistic MLLM-integrated systems, achieving up to 99% attack success rate. It exposes a fundamental blind spot in existing defenses, and calls for rethinking cross-modal security in MLLM-integrated systems.

</details>


### [8] [Optimistic TEE-Rollups: A Hybrid Architecture for Scalable and Verifiable Generative AI Inference on Blockchain](https://arxiv.org/abs/2512.20176)
*Aaron Chan,Alex Ding,Frank Chen,Alan Wu,Bruce Zhang,Arther Tian*

Main category: cs.CR

TL;DR: OTR协议结合TEE可信执行环境和乐观欺诈证明，解决去中心化AI推理中的验证三难问题，实现高完整性、低延迟和低成本


<details>
  <summary>Details</summary>
Motivation: 当前LLM集成到DePIN网络面临验证三难问题：无法同时实现高计算完整性、低延迟和低成本。现有方案如ZKML证明开销过大，乐观方法争议窗口过长，PoQ牺牲完整性存在安全风险

Method: 提出乐观TEE-Rollups协议，结合NVIDIA H100机密计算TEE提供亚秒级临时最终性，采用乐观欺诈证明机制和随机零知识抽查来缓解硬件侧信道风险，定义高效归属证明共识机制

Result: 模拟显示OTR达到集中式基线99%的吞吐量，每次查询边际成本仅0.07美元，即使在存在瞬时硬件漏洞的情况下也能保持对理性对手的拜占庭容错

Conclusion: OTR协议成功调和了验证三难问题的约束，为去中心化AI推理提供了可行的解决方案，平衡了完整性、延迟和成本的需求

Abstract: The rapid integration of Large Language Models (LLMs) into decentralized physical infrastructure networks (DePIN) is currently bottlenecked by the Verifiability Trilemma, which posits that a decentralized inference system cannot simultaneously achieve high computational integrity, low latency, and low cost. Existing cryptographic solutions, such as Zero-Knowledge Machine Learning (ZKML), suffer from superlinear proving overheads (O(k NlogN)) that render them infeasible for billionparameter models. Conversely, optimistic approaches (opML) impose prohibitive dispute windows, preventing real-time interactivity, while recent "Proof of Quality" (PoQ) paradigms sacrifice cryptographic integrity for subjective semantic evaluation, leaving networks vulnerable to model downgrade attacks and reward hacking. In this paper, we introduce Optimistic TEE-Rollups (OTR), a hybrid verification protocol that harmonizes these constraints. OTR leverages NVIDIA H100 Confidential Computing Trusted Execution Environments (TEEs) to provide sub-second Provisional Finality, underpinned by an optimistic fraud-proof mechanism and stochastic Zero-Knowledge spot-checks to mitigate hardware side-channel risks. We formally define Proof of Efficient Attribution (PoEA), a consensus mechanism that cryptographically binds execution traces to hardware attestations, thereby guaranteeing model authenticity. Extensive simulations demonstrate that OTR achieves 99% of the throughput of centralized baselines with a marginal cost overhead of $0.07 per query, maintaining Byzantine fault tolerance against rational adversaries even in the presence of transient hardware vulnerabilities.

</details>


### [9] [Achieving Flexible and Secure Authentication with Strong Privacy in Decentralized Networks](https://arxiv.org/abs/2512.20234)
*Bin Xie,Rui Song,Xuyuan Cai*

Main category: cs.CR

TL;DR: IRAC是一种新型的匿名凭证方案，解决了现有方案在去中心化环境中的三个主要限制：不灵活的凭证模型、有缺陷的撤销机制和弱属性隐藏，实现了更实用的隐私保护认证。


<details>
  <summary>Details</summary>
Motivation: 现有匿名凭证方案在去中心化环境中存在实际限制：1) 凭证模型不灵活，限制了发行者和持有者的自主权；2) 撤销机制存在安全缺陷；3) 属性隐藏不足，无法满足数据最小化原则。这些问题阻碍了隐私保护认证在去中心化网络中的实际部署。

Method: IRAC方案采用三种关键技术：1) 使用向量承诺和填充策略的统一凭证模型，支持异构发行者；2) 基于排序撤销列表间隙的分散式撤销机制，持有者证明其凭证哈希不在撤销列表中；3) 结合zk-SNARKs和向量承诺的强属性隐藏，允许在不泄露属性或凭证结构的情况下证明属性声明。

Result: IRAC在安全分析和性能评估中表现出实际可行性，在去中心化网络中呈现凭证可在1秒内完成，同时解决了现有方案在灵活性、撤销安全和属性隐私方面的关键问题。

Conclusion: IRAC为去中心化环境中的隐私保护认证提供了一个实用的解决方案，通过灵活的凭证模型、安全的撤销机制和强属性隐藏，克服了现有匿名凭证方案的主要限制，实现了发行者隐藏和真正的数据最小化。

Abstract: Anonymous credentials (ACs) are a crucial cryptographic tool for privacy-preserving authentication in decentralized networks, allowing holders to prove eligibility without revealing their identity. However, a major limitation of standard ACs is the disclosure of the issuer's identity, which can leak sensitive contextual information about the holder. Issuer-hiding ACs address this by making a credential's origin indistinguishable among a set of approved issuers. Despite this advancement, existing solutions suffer from practical limitations that hinder their deployment in decentralized environments: unflexible credential models that restrict issuer and holder autonomy, flawed revocation mechanisms that compromise security, and weak attribute hiding that fails to meet data minimization principles. This paper introduces a new scheme called IRAC to overcome these challenges. We propose a flexible credential model that employs vector commitments with a padding strategy to unify credentials from heterogeneous issuers, enabling privacy-preserving authentication without enforcing a global static attribute set or verifier-defined policies. Furthermore, we design a secure decentralized revocation mechanism where holders prove non-revocation by demonstrating their credential's hash lies within a gap in the issuer's sorted revocation list, effectively decoupling revocation checks from verifier policies while maintaining issuer anonymity. IRAC also strengthens attribute hiding by utilizing zk-SNARKs and vector commitments, allowing holders to prove statements about their attributes without disclosing the attributes themselves or the credential structure. Security analysis and performance evaluations demonstrate its practical feasibility for decentralized networks, where presenting a credential can be finished in 1s.

</details>


### [10] [Post-Quantum Cryptography in the 5G Core](https://arxiv.org/abs/2512.20243)
*Thomas Attema,Bor de Kock,Sandesh Manganahalli Jayaprakash,Dimitrios Schoinianakis,Thom Sijpesteijn,Rintse van de Vlasakker*

Main category: cs.CR

TL;DR: 5G核心网采用后量子密码算法替换传统密码算法，实验表明性能影响较小，不影响网络可用性和功能效率


<details>
  <summary>Details</summary>
Motivation: 评估在5G核心网中用后量子密码算法替代传统密码算法的实际影响，验证其技术可行性

Method: 使用仿真环境模拟不同数量用户设备的注册和注销过程，测量带宽消耗和延迟变化

Result: 后量子密码算法部署对性能有可测量的影响，但影响较小；额外的计算和带宽开销对网络可用性和功能效率没有实质性影响

Conclusion: 5G核心网技术上能够支持后量子密码学，增加的计算开销和消息大小不会带来固有问题

Abstract: In this work, the conventional cryptographic algorithms used in the 5G Core are replaced with post-quantum alternatives and the practical impact of this transition is evaluated. Using a simulation environment, we model the registration and deregistration of varying numbers of user equipments (UEs) and measure the resulting effects on bandwidth consumption and latency.
  Our results show that the deployment of post-quantum cryptographic algorithms has a measurable effect on performance, but that this effect is small, and perhaps more crucially, that the extra overhead needed in terms of computation and bandwidth does not have any substantial impact on the usability of the network and the efficiency of its network functions.
  Overall the experimental results in this work corroborate earlier research: the 5G Core is technically able to support post-quantum cryptography without any inherent issues connected to the increased computational overhead or larger message size.

</details>


### [11] [From the Two-Capacitor Paradox to Electromagnetic Side-Channel Mitigation in Digital Circuits](https://arxiv.org/abs/2512.20303)
*Raghvendra Pratap Singh,Baibhab Chatterjee,Shreyas Sen,Debayan Das*

Main category: cs.CR

TL;DR: 该论文从电子电路安全角度重新审视经典的两电容悖论，将电容器充电过程中的能量损耗与电磁侧信道分析联系起来，并提出绝热充电作为减少电磁泄漏的解决方案。


<details>
  <summary>Details</summary>
Motivation: 经典的两电容悖论中"丢失的能量"问题已有多种解释，主要归因于热量和辐射。随着资源受限的物联网设备增长，电磁侧信道分析在电子系统安全中变得日益重要。本文旨在将电容器充电的能量损耗与电磁侧信道泄漏联系起来。

Method: 对标准RC和RLC电路模型进行解析证明，将电容器充电过程中的能量损耗与电磁辐射联系起来。通过实验展示如何利用这种能量损耗进行电磁侧信道分析，从而恢复设备中的加密密钥。最后提出绝热充电作为减少电磁泄漏的解决方案。

Result: 解析证明了电容器充电过程中的能量损耗确实会产生电磁辐射。这种辐射可以被用于电磁侧信道分析，成功恢复嵌入式设备中的秘密加密密钥。绝热充电被证明能有效减少电磁泄漏。

Conclusion: 电容器充电过程中的能量损耗与电磁侧信道泄漏直接相关。通过采用绝热充电技术，可以显著减少电磁辐射，为低开销的电磁侧信道分析防护提供有效途径，对物联网设备安全具有重要意义。

Abstract: The classical two-capacitor paradox of the lost energy is revisited from an electronic circuit security stand-point. The paradox has been solved previously by various researchers, and the energy lost during the charging of capacitors has been primarily attributed to the heat and radiation. We analytically prove this for various standard resistor-capacitor (RC) and resistor-inductor-capacitor (RLC) circuit models. From the perspective of electronic system security, electromagnetic (EM) side-channel analysis (SCA) has recently gained significant prominence with the growth of resource-constrained, internet connected devices. This article connects the energy lost due to capacitor charging to the EM SCA leakage in electronic devices, leading to the recovery of the secret encryption key embedded within the device. Finally, with an understanding of how lost energy relates to EM radiation, we propose adiabatic charging as a solution to minimize EM leakage, thereby paving the way towards low-overhead EM SCA resilience.

</details>


### [12] [Differentially Private Feature Release for Wireless Sensing: Adaptive Privacy Budget Allocation on CSI Spectrograms](https://arxiv.org/abs/2512.20323)
*Ipek Sena Yilmaz,Onur G. Tuncer,Zeynep E. Aksoy,Zeynep Yağmur Baydemir*

Main category: cs.CR

TL;DR: 提出一种针对Wi-Fi/RF感知的差分隐私特征发布方法，通过自适应隐私预算分配机制，在CSI时频表示上实现更好的隐私-效用平衡。


<details>
  <summary>Details</summary>
Motivation: Wi-Fi/RF感知在深度学习推动下取得显著进展，但实际部署需要特征共享用于云分析、协同训练或基准评估。发布中间表示（如CSI频谱图）可能无意中暴露敏感信息（用户身份、位置、成员关系），因此需要正式的隐私保证。

Method: 提出自适应隐私预算分配机制，针对CSI时频表示的高度非均匀结构进行优化。流程包括：将CSI转换为有界频谱图特征，通过裁剪进行敏感性控制，估计时频平面上任务相关的重要性，在注入校准高斯噪声前将全局隐私预算分配到频谱图块。

Result: 在多用户活动感知（WiMANS）、多人3D姿态估计（Person-in-WiFi 3D）和呼吸监测（Resp-CSI）实验中，自适应分配在相同隐私预算下始终比均匀扰动提供更好的隐私-效用边界。该方法获得更高准确率、更低错误率，并显著减少身份和成员推理攻击中的经验泄漏。

Conclusion: 针对无线感知的差分隐私特征发布需要适应CSI时频表示的非均匀结构，自适应隐私预算分配机制能有效提升隐私保护效果同时保持感知任务的实用性。

Abstract: Wi-Fi/RF-based human sensing has achieved remarkable progress with deep learning, yet practical deployments increasingly require feature sharing for cloud analytics, collaborative training, or benchmark evaluation. Releasing intermediate representations such as CSI spectrograms can inadvertently expose sensitive information, including user identity, location, and membership, motivating formal privacy guarantees. In this paper, we study differentially private (DP) feature release for wireless sensing and propose an adaptive privacy budget allocation mechanism tailored to the highly non-uniform structure of CSI time-frequency representations. Our pipeline converts CSI to bounded spectrogram features, applies sensitivity control via clipping, estimates task-relevant importance over the time-frequency plane, and allocates a global privacy budget across spectrogram blocks before injecting calibrated Gaussian noise. Experiments on multi-user activity sensing (WiMANS), multi-person 3D pose estimation (Person-in-WiFi 3D), and respiration monitoring (Resp-CSI) show that adaptive allocation consistently improves the privacy-utility frontier over uniform perturbation under the same privacy budget. Our method yields higher accuracy and lower error while substantially reducing empirical leakage in identity and membership inference attacks.

</details>


### [13] [Symmaries: Automatic Inference of Formal Security Summaries for Java Programs](https://arxiv.org/abs/2512.20396)
*Narges Khakpour,Nicolas Berthier*

Main category: cs.CR

TL;DR: Symmaries工具：为Java字节码程序自动构建形式化安全规范（方法摘要）的模块化、可扩展且可靠的方法


<details>
  <summary>Details</summary>
Motivation: 需要自动化生成Java程序的安全规范，帮助静态代码分析工具和开发者理解代码（特别是库）的安全行为，评估在应用中重用时的安全影响

Method: 开发Symmaries工具，自动生成安全摘要，包含方法安全调用条件、信息流和别名更新的抽象表示。该方法具有可扩展性、模块化和可靠性

Result: Symmaries成功扩展到分析数十万行代码的应用程序，根据使用的堆模型实现有前景的精度。工具应用于Java API库提取安全规范

Conclusion: 该方法在保证终止不敏感非干扰性方面是可靠的，为Java程序安全分析提供了有效的自动化规范生成方案

Abstract: We introduce a scalable, modular, and sound approach for automatically constructing formal security specifications for Java bytecode programs in the form of method summaries. A summary provides an abstract representation of a method's security behavior, consisting of the conditions under which the method can be securely invoked, together with specifications of information flows and aliasing updates. Such summaries can be consumed by static code analysis tools and also help developers understand the behavior of code segments, such as libraries, in order to evaluate their security implications when reused in applications. Our approach is implemented in a tool called Symmaries, which automates the generation of security summaries. We applied Symmaries to Java API libraries to extract their security specifications and to large real-world applications to evaluate its scalability. Our results show that the tool successfully scales to analyze applications with hundreds of thousands of lines of code, and that Symmaries achieves a promising precision depending on the heap model used. We prove the soundness of our approach in terms of guaranteeing termination-insensitive non-interference.

</details>


### [14] [iblock: Accurate and Scalable Bitcoin Simulations with OMNeT++](https://arxiv.org/abs/2512.20402)
*Niccolò Scatena,Pericle Perazzo,Giovanni Nardini*

Main category: cs.CR

TL;DR: iblock是一个用于OMNeT++的比特币模拟C++库，相比现有模拟器具有更高效率和可扩展性，支持详细模拟并与理论预期一致


<details>
  <summary>Details</summary>
Motivation: 现有比特币模拟器通常使用高级语言编写，效率和可扩展性有限，需要更高效、可扩展且能与OMNeT++生态集成的模拟解决方案

Method: 开发iblock作为OMNeT++的C++库，利用C++的高性能特性，支持与OMNeT++其他库集成实现高度详细模拟

Result: iblock在相同模拟细节水平下比现有区块链模拟器更高效，模拟比特币正常运行和自私挖矿攻击等场景的结果与理论预期一致

Conclusion: iblock是一个高效、可扩展的比特币模拟C++库，适用于OMNeT++平台，能够提供准确可靠的比特币网络模拟

Abstract: This paper proposes iblock, a comprehensive C++ library for Bitcoin simulation, designed for OMNeT++. iblock offers superior efficiency and scalability with respect to state-of-the-art simulators, which are typically written in high-level languages. Moreover, the possible integration with other OMNeT++ libraries allows highly detailed simulations. We measure iblock's performance against a state-of-the-art blockchain simulator, proving that it is more efficient at the same level of simulation detail. We also validate iblock by using it to simulate different scenarios such as the normal Bitcoin operation and the selfish mine attack, showing that simulation results are coherent with theoretical expectations.

</details>


### [15] [ChatGPT: Excellent Paper! Accept It. Editor: Imposter Found! Review Rejected](https://arxiv.org/abs/2512.20405)
*Kanchon Gharami,Sanjiv Kumar Sarkar,Yongxin Liu,Shafika Showkat Moni*

Main category: cs.CR

TL;DR: 论文探讨LLM在科研写作与评审中的风险，提出攻击方法（PDF隐藏提示引导LLM评审）和防御策略（注入-检测法识别LLM生成评审），旨在暴露同行评审脆弱性并恢复科学评估可信度。


<details>
  <summary>Details</summary>
Motivation: LLM在科研写作和评审中的广泛应用加速了发表速度但带来了严重风险：缺乏真正创新性、包含捏造或偏见结果、误导下游研究，可能损害声誉、浪费资源，甚至在医疗或安全关键系统中危及生命。需要研究如何应对这一威胁。

Method: 研究采用攻防双重视角：攻击方面展示作者如何在PDF中注入隐藏提示来"越狱"LLM评审者，使其给出过度积极和有偏见的接受意见；防御方面提出"注入-检测"策略，编辑在论文中嵌入不可见触发提示，如果评审重复或响应这些提示，则表明评审由LLM生成而非人类。

Result: 该方法将提示注入从漏洞转化为验证工具，能够有效检测LLM生成的评审。研究还设计了预期模型行为和部署的伦理保障措施。

Conclusion: 研究揭示了当前同行评审过程在LLM影响下的脆弱性，通过编辑意识提升可以帮助恢复科学评估的可信度。将提示注入技术从攻击手段转变为防御工具，为识别LLM参与的科学评审提供了实用方法。

Abstract: Large Language Models (LLMs) like ChatGPT are now widely used in writing and reviewing scientific papers. While this trend accelerates publication growth and reduces human workload, it also introduces serious risks. Papers written or reviewed by LLMs may lack real novelty, contain fabricated or biased results, or mislead downstream research that others depend on. Such issues can damage reputations, waste resources, and even endanger lives when flawed studies influence medical or safety-critical systems. This research explores both the offensive and defensive sides of this growing threat. On the attack side, we demonstrate how an author can inject hidden prompts inside a PDF that secretly guide or "jailbreak" LLM reviewers into giving overly positive feedback and biased acceptance. On the defense side, we propose an "inject-and-detect" strategy for editors, where invisible trigger prompts are embedded into papers; if a review repeats or reacts to these triggers, it reveals that the review was generated by an LLM, not a human. This method turns prompt injections from vulnerability into a verification tool. We outline our design, expected model behaviors, and ethical safeguards for deployment. The goal is to expose how fragile today's peer-review process becomes under LLM influence and how editorial awareness can help restore trust in scientific evaluation.

</details>


### [16] [Evasion-Resilient Detection of DNS-over-HTTPS Data Exfiltration: A Practical Evaluation and Toolkit](https://arxiv.org/abs/2512.20423)
*Adam Elaoumari*

Main category: cs.CR

TL;DR: 开发容器化工具包评估DNS-over-HTTPS文件外泄检测效果，比较机器学习与阈值检测方法，并分析攻击者规避策略


<details>
  <summary>Details</summary>
Motivation: 评估防御者检测DNS-over-HTTPS文件外泄的能力，分析攻击者可用的规避策略，提供可复现的研究工具包

Method: 构建端到端容器化流水线，生成可配置的DoH外泄流量（支持分块、编码、填充、解析器轮换），使用DoHLyzer分支提取流级特征，训练随机森林、梯度提升和逻辑回归模型，并与阈值检测方法对比

Result: 开发了完整的工具包，封装在多个Docker容器中，实现流量生成、文件捕获、特征提取、模型训练和分析的自动化，为DoH外泄检测提供可复现评估框架

Conclusion: 该研究为DoH文件外泄检测提供了系统评估工具，未来将验证企业混合流量结果，扩展到HTTP/3/QUIC协议，增加良性流量生成，并实现实时流量评估，目标是量化隐蔽性约束何时使DoH外泄对攻击者不经济

Abstract: The purpose of this project is to assess how well defenders can detect DNS-over-HTTPS (DoH) file exfiltration, and which evasion strategies can be used by attackers. While providing a reproducible toolkit to generate, intercept and analyze DoH exfiltration, and comparing Machine Learning vs threshold-based detection under adversarial scenarios. The originality of this project is the introduction of an end-to-end, containerized pipeline that generates configurable file exfiltration over DoH using several parameters (e.g., chunking, encoding, padding, resolver rotation). It allows for file reconstruction at the resolver side, while extracting flow-level features using a fork of DoHLyzer. The pipeline contains a prediction side, which allows the training of machine learning models based on public labelled datasets and then evaluates them side-by-side with threshold-based detection methods against malicious and evasive DNS-Over-HTTPS traffic. We train Random Forest, Gradient Boosting and Logistic Regression classifiers on a public DoH dataset and benchmark them against evasive DoH exfiltration scenarios. The toolkit orchestrates traffic generation, file capture, feature extraction, model training and analysis. The toolkit is then encapsulated into several Docker containers for easy setup and full reproducibility regardless of the platform it is run on. Future research regarding this project is directed at validating the results on mixed enterprise traffic, extending the protocol coverage to HTTP/3/QUIC request, adding a benign traffic generation, and working on real-time traffic evaluation. A key objective is to quantify when stealth constraints make DoH exfiltration uneconomical and unworthy for the attacker.

</details>


### [17] [ARBITER: AI-Driven Filtering for Role-Based Access Control](https://arxiv.org/abs/2512.20535)
*Michele Lorenzo,Idilio Drago,Dario Salvadori,Fabio Romolo Vayr*

Main category: cs.CR

TL;DR: 论文提出OUR系统，为RAG系统实现基于角色的访问控制，通过分层验证、角色感知检索和后生成事实检查解决传统RBAC在动态企业环境中的适应性问题。


<details>
  <summary>Details</summary>
Motivation: 传统RBAC难以适应动态企业环境，特别是当文档包含敏感信息且被LLM驱动的RAG系统使用时，LLM可能因提示截断、分类错误或上下文丢失而泄露敏感数据。

Method: 提出OUR系统，采用分层输入/输出验证、角色感知检索和后生成事实检查。不同于依赖微调分类器的传统方法，OUR使用LLM在少样本设置下通过提示引导实现快速部署和角色更新。

Result: 在389个查询的合成数据集上评估，结果显示查询过滤准确率达到85%，F1分数89%，接近传统RBAC解决方案的性能水平。

Conclusion: 结果表明，在RAG系统上部署实用的RBAC正接近动态企业环境所需的成熟度水平。

Abstract: Role-Based Access Control (RBAC) struggles to adapt to dynamic enterprise environments with documents that contain information that cannot be disclosed to specific user groups. As these documents are used by LLM-driven systems (e.g., in RAG) the problem is exacerbated as LLMs can leak sensitive data due to prompt truncation, classification errors, or loss of system context. We introduce \our, a system designed to provide RBAC in RAG systems. \our implements layered input/output validation, role-aware retrieval, and post-generation fact-checking. Unlike traditional RBAC approaches that rely on fine-tuned classifiers, \our uses LLMs operating in few-shot settings with prompt-based steering for rapid deployment and role updates. We evaluate the approach on 389 queries using a synthetic dataset. Experimental results show 85\% accuracy and 89\% F1-score in query filtering, close to traditional RBAC solutions. Results suggest that practical RBAC deployment on RAG systems is approaching the maturity level needed for dynamic enterprise environments.

</details>


### [18] [Making Sense of Private Advertising: A Principled Approach to a Complex Ecosystem](https://arxiv.org/abs/2512.20583)
*Kyle Hogan,Alishah Chator,Gabriel Kaptchuk,Mayank Varia,Srinivas Devadas*

Main category: cs.CR

TL;DR: 论文分析当前隐私广告提案的两个主要问题：1）现有工作孤立考虑广告定向和参与度指标，导致隐私概念无法组合成完整的生态系统隐私；2）证明任何有用的广告生态系统都无法实现完美隐私。作者提出需要基于敏感数据概念重新定义广告隐私。


<details>
  <summary>Details</summary>
Motivation: 当前隐私广告提案存在系统性缺陷，虽然单个协议看起来合理，但在整个广告生态系统中组合时无法提供真正的隐私保护，允许广告商提取新的受众信息。需要重新思考广告隐私的实际含义。

Method: 1）建模广告生态系统的端到端流程；2）识别现有隐私广告提案的两个主要问题；3）证明完美隐私在有用广告生态系统中不可能实现；4）基于敏感数据概念重新定义广告隐私。

Result: 发现现有隐私广告提案存在组合性问题，证明完美隐私在广告生态系统中不可能实现，提出需要基于敏感数据概念重新思考广告隐私设计。

Conclusion: 广告生态系统中的隐私泄露是固有的，需要从根本上重新设计隐私保护广告子系统，确保端到端系统的隐私属性与用户的隐私期望保持一致。

Abstract: In this work, we model the end-to-end pipeline of the advertising ecosystem, allowing us to identify two main issues with the current trajectory of private advertising proposals. First, prior work has largely considered ad targeting and engagement metrics individually rather than in composition. This has resulted in privacy notions that, while reasonable for each protocol in isolation, fail to compose to a natural notion of privacy for the ecosystem as a whole, permitting advertisers to extract new information about the audience of their advertisements. The second issue serves to explain the first: we prove that \textit{perfect} privacy is impossible for any, even minimally, useful advertising ecosystem, due to the advertisers' expectation of conducting market research on the results.
  Having demonstrated that leakage is inherent in advertising, we re-examine what privacy could realistically mean in advertising, building on the well-established notion of \textit{sensitive} data in a specific context. We identify that fundamentally new approaches are needed when designing privacy-preserving advertising subsystems in order to ensure that the privacy properties of the end-to-end advertising system are well aligned with people's privacy desires.

</details>
