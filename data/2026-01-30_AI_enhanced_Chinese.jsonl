{"id": "2601.20885", "categories": ["cs.CR"], "pdf": "https://arxiv.org/pdf/2601.20885", "abs": "https://arxiv.org/abs/2601.20885", "authors": ["Md Tasnim Jawad", "Mingyan Xiao", "Yanzhao Wu"], "title": "What Hard Tokens Reveal: Exploiting Low-confidence Tokens for Membership Inference Attacks against Large Language Models", "comment": null, "summary": "With the widespread adoption of Large Language Models (LLMs) and increasingly stringent privacy regulations, protecting data privacy in LLMs has become essential, especially for privacy-sensitive applications. Membership Inference Attacks (MIAs) attempt to determine whether a specific data sample was included in the model training/fine-tuning dataset, posing serious privacy risks. However, most existing MIA techniques against LLMs rely on sequence-level aggregated prediction statistics, which fail to distinguish prediction improvements caused by generalization from those caused by memorization, leading to low attack effectiveness. To address this limitation, we propose a novel membership inference approach that captures the token-level probabilities for low-confidence (hard) tokens, where membership signals are more pronounced. By comparing token-level probability improvements at hard tokens between a fine-tuned target model and a pre-trained reference model, HT-MIA isolates strong and robust membership signals that are obscured by prior MIA approaches. Extensive experiments on both domain-specific medical datasets and general-purpose benchmarks demonstrate that HT-MIA consistently outperforms seven state-of-the-art MIA baselines. We further investigate differentially private training as an effective defense mechanism against MIAs in LLMs. Overall, our HT-MIA framework establishes hard-token based analysis as a state-of-the-art foundation for advancing membership inference attacks and defenses for LLMs.", "AI": {"tldr": "HT-MIA\u662f\u4e00\u79cd\u9488\u5bf9\u5927\u8bed\u8a00\u6a21\u578b\u7684\u6210\u5458\u63a8\u7406\u653b\u51fb\u65b9\u6cd5\uff0c\u901a\u8fc7\u5206\u6790\u4f4e\u7f6e\u4fe1\u5ea6\uff08hard\uff09token\u7ea7\u522b\u7684\u6982\u7387\u6539\u8fdb\u6765\u533a\u5206\u6cdb\u5316\u548c\u8bb0\u5fc6\uff0c\u663e\u8457\u63d0\u5347\u4e86\u653b\u51fb\u6548\u679c\u3002", "motivation": "\u968f\u7740\u5927\u8bed\u8a00\u6a21\u578b\u7684\u5e7f\u6cdb\u5e94\u7528\u548c\u9690\u79c1\u6cd5\u89c4\u65e5\u76ca\u4e25\u683c\uff0c\u4fdd\u62a4LLMs\u4e2d\u7684\u6570\u636e\u9690\u79c1\u53d8\u5f97\u81f3\u5173\u91cd\u8981\u3002\u73b0\u6709\u7684\u6210\u5458\u63a8\u7406\u653b\u51fb\u65b9\u6cd5\u4e3b\u8981\u4f9d\u8d56\u5e8f\u5217\u7ea7\u522b\u7684\u805a\u5408\u9884\u6d4b\u7edf\u8ba1\uff0c\u65e0\u6cd5\u533a\u5206\u6cdb\u5316\u6539\u8fdb\u548c\u8bb0\u5fc6\u6539\u8fdb\uff0c\u5bfc\u81f4\u653b\u51fb\u6548\u679c\u4e0d\u4f73\u3002", "method": "\u63d0\u51faHT-MIA\u65b9\u6cd5\uff0c\u4e13\u6ce8\u4e8e\u6355\u83b7\u4f4e\u7f6e\u4fe1\u5ea6\uff08hard\uff09token\u7ea7\u522b\u7684\u6982\u7387\u3002\u901a\u8fc7\u6bd4\u8f83\u5fae\u8c03\u76ee\u6807\u6a21\u578b\u548c\u9884\u8bad\u7ec3\u53c2\u8003\u6a21\u578b\u5728hard token\u4e0a\u7684token\u7ea7\u522b\u6982\u7387\u6539\u8fdb\uff0c\u5206\u79bb\u51fa\u88ab\u5148\u524dMIA\u65b9\u6cd5\u63a9\u76d6\u7684\u5f3a\u5927\u4e14\u9c81\u68d2\u7684\u6210\u5458\u4fe1\u53f7\u3002", "result": "\u5728\u9886\u57df\u7279\u5b9a\u7684\u533b\u7597\u6570\u636e\u96c6\u548c\u901a\u7528\u57fa\u51c6\u6d4b\u8bd5\u4e0a\u7684\u5e7f\u6cdb\u5b9e\u9a8c\u8868\u660e\uff0cHT-MIA\u5728\u4e03\u4e2a\u6700\u5148\u8fdb\u7684MIA\u57fa\u7ebf\u65b9\u6cd5\u4e2d\u8868\u73b0\u4e00\u81f4\u66f4\u4f18\u3002\u540c\u65f6\u7814\u7a76\u4e86\u5dee\u5206\u9690\u79c1\u8bad\u7ec3\u4f5c\u4e3a\u5bf9\u6297LLMs\u4e2dMIA\u7684\u6709\u6548\u9632\u5fa1\u673a\u5236\u3002", "conclusion": "HT-MIA\u6846\u67b6\u786e\u7acb\u4e86\u57fa\u4e8ehard token\u7684\u5206\u6790\u4f5c\u4e3a\u63a8\u8fdbLLMs\u6210\u5458\u63a8\u7406\u653b\u51fb\u548c\u9632\u5fa1\u7684\u6700\u5148\u8fdb\u57fa\u7840\uff0c\u4e3a\u9690\u79c1\u4fdd\u62a4\u63d0\u4f9b\u4e86\u91cd\u8981\u5de5\u5177\u3002"}}
{"id": "2601.20901", "categories": ["cs.CR"], "pdf": "https://arxiv.org/pdf/2601.20901", "abs": "https://arxiv.org/abs/2601.20901", "authors": ["Dren Fazlija", "Iyiola E. Olatunji", "Daniel Kudenko", "Sandipan Sikdar"], "title": "Towards Sensitivity-Aware Language Models", "comment": "11 pages, 3 figures, 2 tables, AISTATS 2026; Project Page: https://drenfazlija.github.io/towards-sa-llms/", "summary": "With LLMs increasingly deployed in corporate data management, it is crucial to ensure that these models do not leak sensitive information. In the context of corporate data management, the concept of sensitivity awareness has been introduced, enabling LLMs to adhere to predefined access rights rules. However, it remains unclear how sensitivity awareness relates to established notions of privacy, such as differential privacy (DP), thereby making it difficult to deploy meaningfully in real-world applications. In this work, we formalize the notion of sensitivity awareness and theoretically establish its connection to DP. Additionally, we develop a supervised fine-tuning recipe to make existing, four-bit quantized LLMs more sensitivity-aware. With a performance boost of up to 21.7%, the finetuned LLMs not only substantially improve over their baseline but also outperform other full-precision open-source and commercial models of similar size in achieving sensitivity awareness, demonstrating the effectiveness of our proposed approach. At the same time, our method also largely preserves the models' performance on other tasks, such as general instruction-following, mathematical, and common-sense reasoning.", "AI": {"tldr": "\u672c\u6587\u5f62\u5f0f\u5316\u4e86LLM\u7684\u654f\u611f\u6027\u611f\u77e5\u6982\u5ff5\uff0c\u5efa\u7acb\u4e86\u5176\u4e0e\u5dee\u5206\u9690\u79c1\u7684\u7406\u8bba\u8054\u7cfb\uff0c\u5e76\u63d0\u51fa\u4e86\u4e00\u79cd\u76d1\u7763\u5fae\u8c03\u65b9\u6cd5\uff0c\u4f7f\u91cf\u5316LLM\u5728\u4fdd\u6301\u654f\u611f\u4fe1\u606f\u7684\u540c\u65f6\u63d0\u5347\u6027\u80fd\u8fbe21.7%\u3002", "motivation": "\u968f\u7740LLM\u5728\u4f01\u4e1a\u6570\u636e\u7ba1\u7406\u4e2d\u7684\u90e8\u7f72\uff0c\u786e\u4fdd\u6a21\u578b\u4e0d\u6cc4\u9732\u654f\u611f\u4fe1\u606f\u53d8\u5f97\u81f3\u5173\u91cd\u8981\u3002\u867d\u7136\u5df2\u6709\u654f\u611f\u6027\u611f\u77e5\u6982\u5ff5\u4f7fLLM\u80fd\u9075\u5faa\u8bbf\u95ee\u6743\u9650\u89c4\u5219\uff0c\u4f46\u5176\u4e0e\u5dee\u5206\u9690\u79c1\u7b49\u9690\u79c1\u6982\u5ff5\u7684\u5173\u7cfb\u5c1a\u4e0d\u660e\u786e\uff0c\u963b\u788d\u4e86\u5b9e\u9645\u5e94\u7528\u3002", "method": "1. \u5f62\u5f0f\u5316\u654f\u611f\u6027\u611f\u77e5\u6982\u5ff5\uff1b2. \u7406\u8bba\u5efa\u7acb\u5176\u4e0e\u5dee\u5206\u9690\u79c1\u7684\u8054\u7cfb\uff1b3. \u5f00\u53d1\u76d1\u7763\u5fae\u8c03\u65b9\u6cd5\uff0c\u4f7f4\u4f4d\u91cf\u5316LLM\u66f4\u5177\u654f\u611f\u6027\u611f\u77e5\u80fd\u529b\u3002", "result": "\u5fae\u8c03\u540e\u7684LLM\u6027\u80fd\u63d0\u5347\u9ad8\u8fbe21.7%\uff0c\u4e0d\u4ec5\u663e\u8457\u8d85\u8d8a\u57fa\u7ebf\u6a21\u578b\uff0c\u8fd8\u5728\u654f\u611f\u6027\u611f\u77e5\u65b9\u9762\u4f18\u4e8e\u7c7b\u4f3c\u89c4\u6a21\u7684\u5168\u7cbe\u5ea6\u5f00\u6e90\u548c\u5546\u4e1a\u6a21\u578b\u3002\u540c\u65f6\uff0c\u6a21\u578b\u5728\u901a\u7528\u6307\u4ee4\u9075\u5faa\u3001\u6570\u5b66\u63a8\u7406\u548c\u5e38\u8bc6\u63a8\u7406\u7b49\u4efb\u52a1\u4e0a\u7684\u6027\u80fd\u4e5f\u5f97\u5230\u4fdd\u7559\u3002", "conclusion": "\u672c\u6587\u4e3aLLM\u5728\u4f01\u4e1a\u6570\u636e\u7ba1\u7406\u4e2d\u7684\u5b89\u5168\u90e8\u7f72\u63d0\u4f9b\u4e86\u7406\u8bba\u57fa\u7840\u548c\u5b9e\u7528\u65b9\u6cd5\uff0c\u901a\u8fc7\u5f62\u5f0f\u5316\u654f\u611f\u6027\u611f\u77e5\u6982\u5ff5\u5e76\u5efa\u7acb\u5176\u4e0e\u5dee\u5206\u9690\u79c1\u7684\u8054\u7cfb\uff0c\u540c\u65f6\u5f00\u53d1\u51fa\u6709\u6548\u7684\u5fae\u8c03\u65b9\u6cd5\uff0c\u4f7f\u91cf\u5316LLM\u5728\u4fdd\u62a4\u654f\u611f\u4fe1\u606f\u7684\u540c\u65f6\u4fdd\u6301\u826f\u597d\u6027\u80fd\u3002"}}
{"id": "2601.20903", "categories": ["cs.CR", "cs.AI"], "pdf": "https://arxiv.org/pdf/2601.20903", "abs": "https://arxiv.org/abs/2601.20903", "authors": ["Xingwei Lin", "Wenhao Lin", "Sicong Cao", "Jiahao Yu", "Renke Huang", "Lei Xue", "Chunming Wu"], "title": "ICON: Intent-Context Coupling for Efficient Multi-Turn Jailbreak Attack", "comment": null, "summary": "Multi-turn jailbreak attacks have emerged as a critical threat to Large Language Models (LLMs), bypassing safety mechanisms by progressively constructing adversarial contexts from scratch and incrementally refining prompts. However, existing methods suffer from the inefficiency of incremental context construction that requires step-by-step LLM interaction, and often stagnate in suboptimal regions due to surface-level optimization. In this paper, we characterize the Intent-Context Coupling phenomenon, revealing that LLM safety constraints are significantly relaxed when a malicious intent is coupled with a semantically congruent context pattern. Driven by this insight, we propose ICON, an automated multi-turn jailbreak framework that efficiently constructs an authoritative-style context via prior-guided semantic routing. Specifically, ICON first routes the malicious intent to a congruent context pattern (e.g., Scientific Research) and instantiates it into an attack prompt sequence. This sequence progressively builds the authoritative-style context and ultimately elicits prohibited content. In addition, ICON incorporates a Hierarchical Optimization Strategy that combines local prompt refinement with global context switching, preventing the attack from stagnating in ineffective contexts. Experimental results across eight SOTA LLMs demonstrate the effectiveness of ICON, achieving a state-of-the-art average Attack Success Rate (ASR) of 97.1\\%. Code is available at https://github.com/xwlin-roy/ICON.", "AI": {"tldr": "ICON\u662f\u4e00\u4e2a\u81ea\u52a8\u5316\u591a\u8f6e\u8d8a\u72f1\u6846\u67b6\uff0c\u901a\u8fc7\u610f\u56fe-\u4e0a\u4e0b\u6587\u8026\u5408\u73b0\u8c61\uff0c\u5229\u7528\u5148\u9a8c\u5f15\u5bfc\u7684\u8bed\u4e49\u8def\u7531\u6784\u5efa\u6743\u5a01\u98ce\u683c\u4e0a\u4e0b\u6587\uff0c\u7ed3\u5408\u5206\u5c42\u4f18\u5316\u7b56\u7565\uff0c\u57288\u4e2aSOTA LLMs\u4e0a\u8fbe\u523097.1%\u7684\u5e73\u5747\u653b\u51fb\u6210\u529f\u7387\u3002", "motivation": "\u73b0\u6709\u591a\u8f6e\u8d8a\u72f1\u653b\u51fb\u65b9\u6cd5\u5b58\u5728\u6548\u7387\u4f4e\u4e0b\u95ee\u9898\uff0c\u9700\u8981\u9010\u6b65\u6784\u5efa\u4e0a\u4e0b\u6587\uff0c\u4e14\u5bb9\u6613\u9677\u5165\u6b21\u4f18\u533a\u57df\u3002\u7814\u7a76\u53d1\u73b0\u610f\u56fe-\u4e0a\u4e0b\u6587\u8026\u5408\u73b0\u8c61\uff1a\u5f53\u6076\u610f\u610f\u56fe\u4e0e\u8bed\u4e49\u4e00\u81f4\u7684\u4e0a\u4e0b\u6587\u6a21\u5f0f\u8026\u5408\u65f6\uff0cLLM\u7684\u5b89\u5168\u7ea6\u675f\u4f1a\u663e\u8457\u653e\u677e\u3002", "method": "ICON\u6846\u67b6\uff1a1\uff09\u901a\u8fc7\u5148\u9a8c\u5f15\u5bfc\u7684\u8bed\u4e49\u8def\u7531\u5c06\u6076\u610f\u610f\u56fe\u8def\u7531\u5230\u4e00\u81f4\u7684\u4e0a\u4e0b\u6587\u6a21\u5f0f\uff08\u5982\u79d1\u5b66\u7814\u7a76\uff09\uff1b2\uff09\u5b9e\u4f8b\u5316\u4e3a\u653b\u51fb\u63d0\u793a\u5e8f\u5217\uff0c\u9010\u6b65\u6784\u5efa\u6743\u5a01\u98ce\u683c\u4e0a\u4e0b\u6587\uff1b3\uff09\u91c7\u7528\u5206\u5c42\u4f18\u5316\u7b56\u7565\uff0c\u7ed3\u5408\u5c40\u90e8\u63d0\u793a\u7ec6\u5316\u548c\u5168\u5c40\u4e0a\u4e0b\u6587\u5207\u6362\uff0c\u907f\u514d\u9677\u5165\u65e0\u6548\u4e0a\u4e0b\u6587\u3002", "result": "\u57288\u4e2a\u6700\u5148\u8fdb\u7684LLMs\u4e0a\u8fdb\u884c\u5b9e\u9a8c\uff0cICON\u5b9e\u73b0\u4e8697.1%\u7684\u5e73\u5747\u653b\u51fb\u6210\u529f\u7387\uff08ASR\uff09\uff0c\u8fbe\u5230\u6700\u5148\u8fdb\u6c34\u5e73\u3002", "conclusion": "ICON\u901a\u8fc7\u5229\u7528\u610f\u56fe-\u4e0a\u4e0b\u6587\u8026\u5408\u73b0\u8c61\u548c\u5206\u5c42\u4f18\u5316\u7b56\u7565\uff0c\u6709\u6548\u89e3\u51b3\u4e86\u73b0\u6709\u591a\u8f6e\u8d8a\u72f1\u653b\u51fb\u7684\u6548\u7387\u95ee\u9898\uff0c\u663e\u8457\u63d0\u9ad8\u4e86\u653b\u51fb\u6210\u529f\u7387\uff0c\u63ed\u793a\u4e86LLM\u5b89\u5168\u673a\u5236\u4e2d\u7684\u5173\u952e\u6f0f\u6d1e\u3002"}}
{"id": "2601.20915", "categories": ["cs.CR"], "pdf": "https://arxiv.org/pdf/2601.20915", "abs": "https://arxiv.org/abs/2601.20915", "authors": ["Deepthy K Bhaskar", "Minimol B", "Binu V P"], "title": "Robust Federated Learning for Malicious Clients using Loss Trend Deviation Detection", "comment": null, "summary": "Federated Learning (FL) facilitates collaborative model training among distributed clients while ensuring that raw data remains on local devices.Despite this advantage, FL systems are still exposed to risks from malicious or unreliable participants. Such clients can interfere with the training process by sending misleading updates, which can negatively affect the performance and reliability of the global model. Many existing defense mechanisms rely on gradient inspection, complex similarity computations, or cryptographic operations, which introduce additional overhead and may become unstable under non-IID data distributions. In this paper, we propose the Federated Learning with Loss Trend Detection (FL-LTD), a lightweight and privacy-preserving defense framework that detects and mitigates malicious behavior by monitoring temporal loss dynamics rather than model gradients. The proposed approach identifies anomalous clients by detecting abnormal loss stagnation or abrupt loss fluctuations across communication rounds. To counter adaptive attackers, a short-term memory mechanism is incorporated to sustain mitigation for clients previously flagged as anomalous, while enabling trust recovery for stable participants. We evaluate FL-LTD on a non-IID federated MNIST setup under loss manipulation attacks. Experimental results demonstrate that the proposed method significantly enhances robustness, achieving a final test accuracy of 0.84, compared to 0.41 for standard FedAvg under attack. FL-LTD incurs negligible computational and communication overhead, maintains stable convergence, and avoids client exclusion or access to sensitive data, highlighting the effectiveness of loss-based monitoring for secure federated learning.", "AI": {"tldr": "\u63d0\u51faFL-LTD\u6846\u67b6\uff0c\u901a\u8fc7\u76d1\u63a7\u635f\u5931\u8d8b\u52bf\u800c\u975e\u68af\u5ea6\u6765\u68c0\u6d4b\u6076\u610f\u5ba2\u6237\u7aef\uff0c\u5728\u975eIID\u6570\u636e\u4e0b\u5b9e\u73b0\u8f7b\u91cf\u7ea7\u3001\u9690\u79c1\u4fdd\u62a4\u7684\u8054\u90a6\u5b66\u4e60\u9632\u5fa1", "motivation": "\u8054\u90a6\u5b66\u4e60\u9762\u4e34\u6076\u610f\u5ba2\u6237\u7aef\u53d1\u9001\u8bef\u5bfc\u6027\u66f4\u65b0\u7684\u98ce\u9669\uff0c\u73b0\u6709\u9632\u5fa1\u673a\u5236\u4f9d\u8d56\u68af\u5ea6\u68c0\u67e5\u3001\u590d\u6742\u76f8\u4f3c\u6027\u8ba1\u7b97\u6216\u5bc6\u7801\u64cd\u4f5c\uff0c\u5728\u975eIID\u6570\u636e\u4e0b\u5f15\u5165\u989d\u5916\u5f00\u9500\u4e14\u4e0d\u7a33\u5b9a", "method": "\u63d0\u51faFL-LTD\u6846\u67b6\uff0c\u901a\u8fc7\u76d1\u63a7\u65f6\u95f4\u635f\u5931\u52a8\u6001\u68c0\u6d4b\u5f02\u5e38\u5ba2\u6237\u7aef\uff0c\u8bc6\u522b\u635f\u5931\u505c\u6ede\u6216\u7a81\u53d8\uff0c\u7ed3\u5408\u77ed\u671f\u8bb0\u5fc6\u673a\u5236\u6301\u7eed\u7f13\u89e3\u5148\u524d\u6807\u8bb0\u7684\u5f02\u5e38\u5ba2\u6237\u7aef\uff0c\u540c\u65f6\u5141\u8bb8\u7a33\u5b9a\u53c2\u4e0e\u8005\u6062\u590d\u4fe1\u4efb", "result": "\u5728\u975eIID\u8054\u90a6MNIST\u8bbe\u7f6e\u4e0b\uff0cFL-LTD\u663e\u8457\u589e\u5f3a\u9c81\u68d2\u6027\uff0c\u6700\u7ec8\u6d4b\u8bd5\u51c6\u786e\u7387\u8fbe\u52300.84\uff0c\u800c\u6807\u51c6FedAvg\u5728\u653b\u51fb\u4e0b\u4ec5\u4e3a0.41\uff0c\u8ba1\u7b97\u548c\u901a\u4fe1\u5f00\u9500\u53ef\u5ffd\u7565\uff0c\u4fdd\u6301\u7a33\u5b9a\u6536\u655b", "conclusion": "FL-LTD\u5c55\u793a\u4e86\u57fa\u4e8e\u635f\u5931\u76d1\u63a7\u5728\u5b89\u5168\u8054\u90a6\u5b66\u4e60\u4e2d\u7684\u6709\u6548\u6027\uff0c\u65e0\u9700\u5ba2\u6237\u7aef\u6392\u9664\u6216\u8bbf\u95ee\u654f\u611f\u6570\u636e\uff0c\u63d0\u4f9b\u8f7b\u91cf\u7ea7\u3001\u9690\u79c1\u4fdd\u62a4\u7684\u9632\u5fa1\u65b9\u6848"}}
{"id": "2601.20917", "categories": ["cs.CR"], "pdf": "https://arxiv.org/pdf/2601.20917", "abs": "https://arxiv.org/abs/2601.20917", "authors": ["Leo Kao"], "title": "FIPS 204-Compatible Threshold ML-DSA via Masked Lagrange Reconstruction", "comment": "50 pages, 10 tables", "summary": "We present masked Lagrange reconstruction, a technique that enables threshold ML-DSA (FIPS 204) with arbitrary thresholds $T$ while producing standard 3.3 KB signatures verifiable by unmodified FIPS 204 implementations. Concurrent approaches have limitations: Bienstock et al. (ePrint 2025/1163) achieve arbitrary $T$ but require honest-majority and 37--136 rounds; Celi et al. (ePrint 2026/013) achieve dishonest-majority but are limited to $T \\leq 6$. Our technique addresses the barrier that Lagrange coefficients grow as $\u0398(q)$ for moderate $T$, making individual contributions too large for ML-DSA's rejection sampling.\n  Unlike ECDSA threshold schemes where pairwise masks suffice for correctness, ML-DSA requires solving three additional challenges absent in prior work: (1) rejection sampling on $\\|z\\|_\\infty$ must still pass after masking, (2) the $r_0$-check exposes $c s_2$ enabling key recovery if unprotected, and (3) the resulting Irwin-Hall nonce distribution must preserve EUF-CMA security. We solve all three.\n  We instantiate this technique in three deployment profiles with full security proofs. Profile P1 (TEE-assisted) achieves 3-round signing with a trusted coordinator, with EUF-CMA security under Module-SIS. Profile P2 (fully distributed) eliminates hardware trust via MPC in 8 rounds, achieving UC security against malicious adversaries corrupting up to $n-1$ parties. Profile P3 (2PC-assisted) uses lightweight 2PC for the $r_0$-check in 3--5 rounds, achieving UC security under a 1-of-2 CP honest assumption with the best empirical performance (249ms).\n  Our scheme requires $|S| \\geq T+1$ signers and achieves success rates of 23--32\\%, matching single-signer ML-DSA.", "AI": {"tldr": "\u63d0\u51fa\u63a9\u7801\u62c9\u683c\u6717\u65e5\u91cd\u6784\u6280\u672f\uff0c\u5b9e\u73b0\u4efb\u610f\u9608\u503cT\u7684ML-DSA\u9608\u503c\u7b7e\u540d\uff0c\u4ea7\u751f\u6807\u51c63.3KB\u7b7e\u540d\uff0c\u517c\u5bb9\u672a\u4fee\u6539\u7684FIPS 204\u9a8c\u8bc1\u5b9e\u73b0\u3002", "motivation": "\u73b0\u6709\u9608\u503cML-DSA\u65b9\u6848\u5b58\u5728\u9650\u5236\uff1aBienstock\u7b49\u4eba\u65b9\u6848\u9700\u8981\u8bda\u5b9e\u591a\u6570\u548c37-136\u8f6e\u901a\u4fe1\uff1bCeli\u7b49\u4eba\u65b9\u6848\u652f\u6301\u6076\u610f\u591a\u6570\u4f46\u4ec5\u9650\u4e8eT\u22646\u3002\u9700\u8981\u89e3\u51b3\u62c9\u683c\u6717\u65e5\u7cfb\u6570\u968fq\u589e\u957f\u5bfc\u81f4\u62d2\u7edd\u91c7\u6837\u5931\u8d25\u7684\u95ee\u9898\u3002", "method": "\u4f7f\u7528\u63a9\u7801\u62c9\u683c\u6717\u65e5\u91cd\u6784\u6280\u672f\uff0c\u89e3\u51b3ML-DSA\u9608\u503c\u7b7e\u540d\u7684\u4e09\u4e2a\u5173\u952e\u6311\u6218\uff1a1) \u63a9\u7801\u540e\u4ecd\u9700\u901a\u8fc7\u62d2\u7edd\u91c7\u6837\uff1b2) \u4fdd\u62a4r0-check\u9632\u6b62\u5bc6\u94a5\u6062\u590d\uff1b3) \u4fdd\u6301Irwin-Hall\u975ece\u5206\u5e03\u7684\u5b89\u5168\u6027\u3002\u8bbe\u8ba1\u4e86\u4e09\u79cd\u90e8\u7f72\u65b9\u6848\uff1aP1\uff08TEE\u8f85\u52a9\uff09\u3001P2\uff08\u5b8c\u5168\u5206\u5e03\u5f0fMPC\uff09\u3001P3\uff082PC\u8f85\u52a9\uff09\u3002", "result": "\u5b9e\u73b0\u4e86\u4efb\u610f\u9608\u503cT\u7684ML-DSA\u9608\u503c\u7b7e\u540d\uff0c\u4ea7\u751f\u6807\u51c63.3KB\u7b7e\u540d\u3002P1\u65b9\u68483\u8f6e\u7b7e\u540d\uff0cP2\u65b9\u68488\u8f6e\u5b8c\u5168\u5206\u5e03\u5f0f\uff0cP3\u65b9\u68483-5\u8f6e\u4e14\u6027\u80fd\u6700\u4f73\uff08249ms\uff09\u3002\u6210\u529f\u738723-32%\uff0c\u5339\u914d\u5355\u7b7e\u540d\u8005ML-DSA\u3002", "conclusion": "\u63a9\u7801\u62c9\u683c\u6717\u65e5\u91cd\u6784\u6280\u672f\u6210\u529f\u89e3\u51b3\u4e86ML-DSA\u9608\u503c\u7b7e\u540d\u7684\u5173\u952e\u6311\u6218\uff0c\u63d0\u4f9b\u4e86\u4e09\u79cd\u5b89\u5168\u90e8\u7f72\u65b9\u6848\uff0c\u5728\u4fdd\u6301FIPS 204\u517c\u5bb9\u6027\u7684\u540c\u65f6\u5b9e\u73b0\u4e86\u7075\u6d3b\u7684\u9608\u503c\u8bbe\u7f6e\u3002"}}
{"id": "2601.20999", "categories": ["cs.CR", "cs.HC"], "pdf": "https://arxiv.org/pdf/2601.20999", "abs": "https://arxiv.org/abs/2601.20999", "authors": ["Dev Vikesh Doshi", "Mehjabeen Tasnim", "Fernando Landeros", "Chinthagumpala Muni Venkatesh", "Daniel Timko", "Muhammad Lutfor Rahman"], "title": "What Are Brands Telling You About Smishing? A Cross-Industry Evaluation of Customer Guidance", "comment": null, "summary": "Phishing attacks through text, also known as smishing, are a prevalent type of social engineering tactic in which attackers impersonate brands to deceive victims into providing personal information and/or money. While smishing awareness and cyber education are a key method by which organizations communicate this awareness, the guidance itself varies widely. In this paper, we investigate the state of practice of how 149 well-known brands across 25 categories educate their customers about smishing and what smishing prevention and reporting advice they provide. After conducting a comprehensive content analysis of the brands, we identified significant gaps in the smishing-related information provided: only 46\\% of the 149 brands mentioned the definition of smishing, less than 1\\% had a video tutorial on smishing, and only 50\\% of brands provided instructions on how to report. Our study highlights variation in terminology, prevention advice, and reporting mechanisms across industries, with some brands recommending potentially ineffective strategies such as \"ignoring suspicious messages.\" These findings establish a baseline for understanding the current state of industry smishing awareness advice and provide specific areas where standardization improvements are needed. From our evaluation, we provide recommendations for brands on how to offer streamlined education to their respective customers on smishing for better awareness and protection against increasing smishing attacks.", "AI": {"tldr": "\u5bf9149\u4e2a\u77e5\u540d\u54c1\u724c\u7684\u9493\u9c7c\u77ed\u4fe1\uff08smishing\uff09\u9632\u8303\u6559\u80b2\u73b0\u72b6\u5206\u6790\u663e\u793a\uff0c\u54c1\u724c\u5728\u5b9a\u4e49\u8bf4\u660e\u3001\u89c6\u9891\u6559\u7a0b\u548c\u62a5\u544a\u673a\u5236\u65b9\u9762\u5b58\u5728\u663e\u8457\u4e0d\u8db3\uff0c\u884c\u4e1a\u95f4\u672f\u8bed\u548c\u9884\u9632\u5efa\u8bae\u5dee\u5f02\u5927\uff0c\u9700\u6807\u51c6\u5316\u6539\u8fdb\u3002", "motivation": "\u9493\u9c7c\u77ed\u4fe1\u653b\u51fb\u65e5\u76ca\u666e\u904d\uff0c\u54c1\u724c\u901a\u8fc7\u7f51\u7edc\u5b89\u5168\u6559\u80b2\u5411\u5ba2\u6237\u4f20\u8fbe\u9632\u8303\u610f\u8bc6\uff0c\u4f46\u73b0\u6709\u6307\u5bfc\u5185\u5bb9\u5dee\u5f02\u5f88\u5927\u3002\u672c\u7814\u7a76\u65e8\u5728\u8c03\u67e5\u77e5\u540d\u54c1\u724c\u5982\u4f55\u6559\u80b2\u5ba2\u6237\u9632\u8303\u9493\u9c7c\u77ed\u4fe1\uff0c\u4ee5\u53ca\u5b83\u4eec\u63d0\u4f9b\u7684\u9884\u9632\u548c\u62a5\u544a\u5efa\u8bae\u7684\u5b9e\u9645\u72b6\u51b5\u3002", "method": "\u5bf925\u4e2a\u884c\u4e1a\u7684149\u4e2a\u77e5\u540d\u54c1\u724c\u8fdb\u884c\u5168\u9762\u7684\u5185\u5bb9\u5206\u6790\uff0c\u7814\u7a76\u5b83\u4eec\u5982\u4f55\u6559\u80b2\u5ba2\u6237\u9632\u8303\u9493\u9c7c\u77ed\u4fe1\uff0c\u5305\u62ec\u63d0\u4f9b\u7684\u5b9a\u4e49\u3001\u9884\u9632\u5efa\u8bae\u3001\u62a5\u544a\u673a\u5236\u548c\u89c6\u9891\u6559\u7a0b\u7b49\u5185\u5bb9\u3002", "result": "\u7814\u7a76\u53d1\u73b0\u663e\u8457\u7684\u4fe1\u606f\u7f3a\u53e3\uff1a\u4ec546%\u7684\u54c1\u724c\u63d0\u53ca\u9493\u9c7c\u77ed\u4fe1\u5b9a\u4e49\uff0c\u4e0d\u52301%\u63d0\u4f9b\u89c6\u9891\u6559\u7a0b\uff0c\u4ec550%\u63d0\u4f9b\u62a5\u544a\u6307\u5bfc\u3002\u884c\u4e1a\u95f4\u672f\u8bed\u3001\u9884\u9632\u5efa\u8bae\u548c\u62a5\u544a\u673a\u5236\u5dee\u5f02\u660e\u663e\uff0c\u90e8\u5206\u54c1\u724c\u63a8\u8350\"\u5ffd\u7565\u53ef\u7591\u6d88\u606f\"\u7b49\u53ef\u80fd\u65e0\u6548\u7684\u7b56\u7565\u3002", "conclusion": "\u7814\u7a76\u4e3a\u884c\u4e1a\u9493\u9c7c\u77ed\u4fe1\u9632\u8303\u6559\u80b2\u73b0\u72b6\u5efa\u7acb\u4e86\u57fa\u51c6\uff0c\u6307\u51fa\u4e86\u9700\u8981\u6807\u51c6\u5316\u7684\u5177\u4f53\u9886\u57df\u3002\u5efa\u8bae\u54c1\u724c\u63d0\u4f9b\u66f4\u7cfb\u7edf\u5316\u7684\u6559\u80b2\u5185\u5bb9\uff0c\u4ee5\u589e\u5f3a\u5ba2\u6237\u5bf9\u65e5\u76ca\u589e\u957f\u7684\u9493\u9c7c\u77ed\u4fe1\u653b\u51fb\u7684\u9632\u8303\u610f\u8bc6\u548c\u4fdd\u62a4\u80fd\u529b\u3002"}}
{"id": "2601.21189", "categories": ["cs.CR", "cs.AI"], "pdf": "https://arxiv.org/pdf/2601.21189", "abs": "https://arxiv.org/abs/2601.21189", "authors": ["Arther Tian", "Alex Ding", "Frank Chen", "Simon Wu", "Aaron Chan"], "title": "Adaptive and Robust Cost-Aware Proof of Quality for Decentralized LLM Inference Networks", "comment": null, "summary": "Decentralized large language model inference networks require lightweight mechanisms to reward high quality outputs under heterogeneous latency and cost. Proof of Quality provides scalable verification by sampling evaluator nodes that score candidate outputs, then aggregating their scores into a consensus signal that determines rewards. However, evaluator heterogeneity and malicious score manipulation can distort consensus and inflate payouts, which weakens incentive alignment in open participation settings.\n  This paper extends a cost-aware Proof of Quality mechanism by adding adversary-resilient consensus formation. We study robust aggregation rules, including median and trimmed mean, and an adaptive trust-weighted consensus that updates evaluator weights from deviation signals. Using question answering and summarization workloads with a ground truth proxy for offline analysis, we quantify evaluator reliability and show strong variance across evaluators, including task-dependent misalignment that can invert correlations. We then evaluate robustness under four adversarial strategies, including noise injection, boosting, sabotage, and intermittent manipulation, across a sweep of malicious ratios and evaluator sample sizes. Our results show that robust aggregation improves consensus alignment with the ground truth proxy and reduces sensitivity to noisy and strategic attacks compared with simple averaging. We further characterize the operational trade-off introduced by evaluator sampling, where larger evaluator sets reduce evaluator rewards and increase payoff variance while inference rewards remain relatively stable in our configuration. These findings motivate robust consensus as a default component for cost-aware Proof of Quality and provide practical guidance for selecting evaluator sampling parameters under adversarial risk and resource constraints.", "AI": {"tldr": "\u672c\u6587\u6269\u5c55\u4e86\u6210\u672c\u611f\u77e5\u7684Proof of Quality\u673a\u5236\uff0c\u901a\u8fc7\u6dfb\u52a0\u6297\u5bf9\u6297\u7684\u5171\u8bc6\u5f62\u6210\u65b9\u6cd5\u6765\u62b5\u5fa1\u8bc4\u4f30\u8005\u5f02\u8d28\u6027\u548c\u6076\u610f\u8bc4\u5206\u64cd\u7eb5\uff0c\u63d0\u9ad8\u4e86\u53bb\u4e2d\u5fc3\u5316LLM\u63a8\u7406\u7f51\u7edc\u7684\u6fc0\u52b1\u5bf9\u9f50\u3002", "motivation": "\u53bb\u4e2d\u5fc3\u5316\u5927\u8bed\u8a00\u6a21\u578b\u63a8\u7406\u7f51\u7edc\u9700\u8981\u8f7b\u91cf\u7ea7\u673a\u5236\u6765\u5956\u52b1\u9ad8\u8d28\u91cf\u8f93\u51fa\uff0c\u4f46\u8bc4\u4f30\u8005\u5f02\u8d28\u6027\u548c\u6076\u610f\u8bc4\u5206\u64cd\u7eb5\u4f1a\u626d\u66f2\u5171\u8bc6\u5e76\u524a\u5f31\u6fc0\u52b1\u5bf9\u9f50\uff0c\u7279\u522b\u662f\u5728\u5f00\u653e\u53c2\u4e0e\u73af\u5883\u4e2d\u3002", "method": "\u6269\u5c55\u6210\u672c\u611f\u77e5Proof of Quality\u673a\u5236\uff0c\u6dfb\u52a0\u6297\u5bf9\u6297\u5171\u8bc6\u5f62\u6210\u65b9\u6cd5\uff0c\u5305\u62ec\u4e2d\u4f4d\u6570\u3001\u4fee\u526a\u5747\u503c\u7b49\u9c81\u68d2\u805a\u5408\u89c4\u5219\uff0c\u4ee5\u53ca\u57fa\u4e8e\u504f\u5dee\u4fe1\u53f7\u66f4\u65b0\u8bc4\u4f30\u8005\u6743\u91cd\u7684\u81ea\u9002\u5e94\u4fe1\u4efb\u52a0\u6743\u5171\u8bc6\u3002", "result": "\u9c81\u68d2\u805a\u5408\u63d0\u9ad8\u4e86\u5171\u8bc6\u4e0e\u5730\u9762\u771f\u503c\u4ee3\u7406\u7684\u5bf9\u9f50\u5ea6\uff0c\u964d\u4f4e\u4e86\u5bf9\u566a\u58f0\u548c\u7b56\u7565\u653b\u51fb\u7684\u654f\u611f\u6027\uff1b\u8bc4\u4f30\u8005\u91c7\u6837\u5b58\u5728\u64cd\u4f5c\u6743\u8861\uff0c\u66f4\u5927\u7684\u8bc4\u4f30\u8005\u96c6\u5408\u4f1a\u51cf\u5c11\u8bc4\u4f30\u8005\u5956\u52b1\u5e76\u589e\u52a0\u652f\u4ed8\u65b9\u5dee\u3002", "conclusion": "\u9c81\u68d2\u5171\u8bc6\u5e94\u4f5c\u4e3a\u6210\u672c\u611f\u77e5Proof of Quality\u7684\u9ed8\u8ba4\u7ec4\u4ef6\uff0c\u7814\u7a76\u7ed3\u679c\u4e3a\u5728\u5bf9\u6297\u98ce\u9669\u548c\u8d44\u6e90\u7ea6\u675f\u4e0b\u9009\u62e9\u8bc4\u4f30\u8005\u91c7\u6837\u53c2\u6570\u63d0\u4f9b\u4e86\u5b9e\u7528\u6307\u5bfc\u3002"}}
{"id": "2601.21211", "categories": ["cs.CR"], "pdf": "https://arxiv.org/pdf/2601.21211", "abs": "https://arxiv.org/abs/2601.21211", "authors": ["Gayathri Subramanian", "Girinath P", "Nitya Ranganathan", "Kamakoti Veezhinathan", "Gopalakrishnan Srinivasan"], "title": "SPOILER-GUARD: Gating Latency Effects of Memory Accesses through Randomized Dependency Prediction", "comment": "3 pages, 3 figures, to appear in DATE 2026 Conference Proceedings", "summary": "Modern microprocessors depend on speculative execution, creating vulnerabilities that enable transient execution attacks. Prior defenses target speculative data leakage but overlook false dependencies from partial address aliasing, where repeated squash and reissue events increase the load-store latency, which is exploited by the SPOILER attack. We present SPOILER-GUARD, a hardware defense that obfuscates speculative dependency resolution by dynamically randomizing the physical address bits used for load-store comparisons and tagging store entries to prevent latency-amplifying misspeculations. Implemented in gem5 and evaluated with SPEC 2017, SPOILER-GUARD reduces misspeculation to 0.0004 percent and improves integer and floating-point performance by 2.12 and 2.87 percent. HDL synthesis with Synopsys Design Compiler at 14 nm node demonstrates minimal overheads - 69 ps latency in critical path, 0.064 square millimeter in area, and 5.863 mW in power.", "AI": {"tldr": "SPOILER-GUARD\uff1a\u4e00\u79cd\u786c\u4ef6\u9632\u5fa1\u673a\u5236\uff0c\u901a\u8fc7\u52a8\u6001\u968f\u673a\u5316\u7269\u7406\u5730\u5740\u4f4d\u548c\u6807\u8bb0\u5b58\u50a8\u6761\u76ee\u6765\u9632\u6b62SPOILER\u653b\u51fb\uff0c\u51cf\u5c11\u8bef\u9884\u6d4b\u81f30.0004%\uff0c\u6027\u80fd\u63d0\u53472-3%\uff0c\u786c\u4ef6\u5f00\u9500\u6781\u5c0f\u3002", "motivation": "\u73b0\u4ee3\u5fae\u5904\u7406\u5668\u4f9d\u8d56\u63a8\u6d4b\u6267\u884c\uff0c\u5b58\u5728\u77ac\u6001\u6267\u884c\u653b\u51fb\u6f0f\u6d1e\u3002\u73b0\u6709\u9632\u5fa1\u4e3b\u8981\u9488\u5bf9\u63a8\u6d4b\u6570\u636e\u6cc4\u6f0f\uff0c\u4f46\u5ffd\u7565\u4e86\u90e8\u5206\u5730\u5740\u522b\u540d\u5bfc\u81f4\u7684\u865a\u5047\u4f9d\u8d56\u95ee\u9898\uff0c\u8fd9\u79cd\u4f9d\u8d56\u901a\u8fc7\u91cd\u590d\u7684squash\u548creissue\u4e8b\u4ef6\u589e\u52a0\u52a0\u8f7d-\u5b58\u50a8\u5ef6\u8fdf\uff0c\u88abSPOILER\u653b\u51fb\u5229\u7528\u3002", "method": "\u63d0\u51faSPOILER-GUARD\u786c\u4ef6\u9632\u5fa1\u673a\u5236\uff1a1\uff09\u52a8\u6001\u968f\u673a\u5316\u7528\u4e8e\u52a0\u8f7d-\u5b58\u50a8\u6bd4\u8f83\u7684\u7269\u7406\u5730\u5740\u4f4d\uff0c\u6df7\u6dc6\u63a8\u6d4b\u4f9d\u8d56\u89e3\u6790\uff1b2\uff09\u6807\u8bb0\u5b58\u50a8\u6761\u76ee\u4ee5\u9632\u6b62\u5ef6\u8fdf\u653e\u5927\u7684\u8bef\u9884\u6d4b\u3002\u5728gem5\u4e2d\u5b9e\u73b0\uff0c\u4f7f\u7528SPEC 2017\u8fdb\u884c\u8bc4\u4f30\u3002", "result": "1\uff09\u8bef\u9884\u6d4b\u7387\u964d\u81f30.0004%\uff1b2\uff09\u6574\u6570\u548c\u6d6e\u70b9\u6027\u80fd\u5206\u522b\u63d0\u53472.12%\u548c2.87%\uff1b3\uff09\u572814nm\u8282\u70b9\u5408\u6210\u663e\u793a\u6781\u5c0f\u5f00\u9500\uff1a\u5173\u952e\u8def\u5f84\u5ef6\u8fdf69ps\uff0c\u9762\u79ef0.064mm\u00b2\uff0c\u529f\u80175.863mW\u3002", "conclusion": "SPOILER-GUARD\u6709\u6548\u9632\u5fa1\u4e86SPOILER\u653b\u51fb\uff0c\u901a\u8fc7\u786c\u4ef6\u673a\u5236\u89e3\u51b3\u4e86\u90e8\u5206\u5730\u5740\u522b\u540d\u5bfc\u81f4\u7684\u865a\u5047\u4f9d\u8d56\u95ee\u9898\uff0c\u5728\u6781\u5c0f\u7684\u786c\u4ef6\u5f00\u9500\u4e0b\u663e\u8457\u964d\u4f4e\u4e86\u8bef\u9884\u6d4b\u5e76\u63d0\u5347\u4e86\u6027\u80fd\u3002"}}
{"id": "2601.21252", "categories": ["cs.CR", "cs.CV"], "pdf": "https://arxiv.org/pdf/2601.21252", "abs": "https://arxiv.org/abs/2601.21252", "authors": ["Lingxiao Chen", "Liqin Wang", "Wei Lu", "Xiangyang Luo"], "title": "Lossless Copyright Protection via Intrinsic Model Fingerprinting", "comment": null, "summary": "The exceptional performance of diffusion models establishes them as high-value intellectual property but exposes them to unauthorized replication. Existing protection methods either modify the model to embed watermarks, which impairs performance, or extract model fingerprints by manipulating the denoising process, rendering them incompatible with black-box APIs. In this paper, we propose TrajPrint, a completely lossless and training-free framework that verifies model copyright by extracting unique manifold fingerprints formed during deterministic generation. Specifically, we first utilize a watermarked image as an anchor and exactly trace the path back to its trajectory origin, effectively locking the model fingerprint mapped by this path. Subsequently, we implement a joint optimization strategy that employs dual-end anchoring to synthesize a specific fingerprint noise, which strictly adheres to the target manifold for robust watermark recovery. As input, it enables the protected target model to recover the watermarked image, while failing on non-target models. Finally, we achieved verification via atomic inference and statistical hypothesis testing. Extensive experiments demonstrate that TrajPrint achieves lossless verification in black-box API scenarios with superior robustness against model modifications.", "AI": {"tldr": "TrajPrint\u662f\u4e00\u79cd\u65e0\u635f\u3001\u514d\u8bad\u7ec3\u7684\u6269\u6563\u6a21\u578b\u7248\u6743\u4fdd\u62a4\u6846\u67b6\uff0c\u901a\u8fc7\u63d0\u53d6\u786e\u5b9a\u6027\u751f\u6210\u8fc7\u7a0b\u4e2d\u5f62\u6210\u7684\u72ec\u7279\u6d41\u5f62\u6307\u7eb9\u6765\u9a8c\u8bc1\u6a21\u578b\u7248\u6743\uff0c\u652f\u6301\u9ed1\u76d2API\u573a\u666f\u3002", "motivation": "\u6269\u6563\u6a21\u578b\u7684\u5353\u8d8a\u6027\u80fd\u4f7f\u5176\u6210\u4e3a\u9ad8\u4ef7\u503c\u77e5\u8bc6\u4ea7\u6743\uff0c\u4f46\u4e5f\u9762\u4e34\u672a\u7ecf\u6388\u6743\u590d\u5236\u7684\u98ce\u9669\u3002\u73b0\u6709\u4fdd\u62a4\u65b9\u6cd5\u8981\u4e48\u901a\u8fc7\u4fee\u6539\u6a21\u578b\u5d4c\u5165\u6c34\u5370\uff08\u635f\u5bb3\u6027\u80fd\uff09\uff0c\u8981\u4e48\u901a\u8fc7\u64cd\u7eb5\u53bb\u566a\u8fc7\u7a0b\u63d0\u53d6\u6a21\u578b\u6307\u7eb9\uff08\u4e0e\u9ed1\u76d2API\u4e0d\u517c\u5bb9\uff09\u3002", "method": "1) \u4f7f\u7528\u6c34\u5370\u56fe\u50cf\u4f5c\u4e3a\u951a\u70b9\uff0c\u7cbe\u786e\u56de\u6eaf\u5230\u5176\u8f68\u8ff9\u539f\u70b9\uff0c\u9501\u5b9a\u8be5\u8def\u5f84\u6620\u5c04\u7684\u6a21\u578b\u6307\u7eb9\uff1b2) \u91c7\u7528\u53cc\u7aef\u951a\u5b9a\u7684\u8054\u5408\u4f18\u5316\u7b56\u7565\u5408\u6210\u7279\u5b9a\u6307\u7eb9\u566a\u58f0\uff0c\u4e25\u683c\u9075\u5faa\u76ee\u6807\u6d41\u5f62\u4ee5\u5b9e\u73b0\u9c81\u68d2\u6c34\u5370\u6062\u590d\uff1b3) \u901a\u8fc7\u539f\u5b50\u63a8\u7406\u548c\u7edf\u8ba1\u5047\u8bbe\u68c0\u9a8c\u8fdb\u884c\u9a8c\u8bc1\u3002", "result": "TrajPrint\u5728\u9ed1\u76d2API\u573a\u666f\u4e2d\u5b9e\u73b0\u4e86\u65e0\u635f\u9a8c\u8bc1\uff0c\u5bf9\u6a21\u578b\u4fee\u6539\u5177\u6709\u4f18\u8d8a\u7684\u9c81\u68d2\u6027\u3002\u76ee\u6807\u6a21\u578b\u80fd\u591f\u6062\u590d\u6c34\u5370\u56fe\u50cf\uff0c\u800c\u975e\u76ee\u6807\u6a21\u578b\u5219\u65e0\u6cd5\u6062\u590d\u3002", "conclusion": "TrajPrint\u63d0\u51fa\u4e86\u4e00\u79cd\u5b8c\u5168\u65e0\u635f\u4e14\u514d\u8bad\u7ec3\u7684\u6846\u67b6\uff0c\u901a\u8fc7\u63d0\u53d6\u6269\u6563\u6a21\u578b\u786e\u5b9a\u6027\u751f\u6210\u8fc7\u7a0b\u4e2d\u5f62\u6210\u7684\u72ec\u7279\u6d41\u5f62\u6307\u7eb9\u6765\u9a8c\u8bc1\u7248\u6743\uff0c\u89e3\u51b3\u4e86\u73b0\u6709\u65b9\u6cd5\u635f\u5bb3\u6027\u80fd\u6216\u4e0e\u9ed1\u76d2API\u4e0d\u517c\u5bb9\u7684\u95ee\u9898\u3002"}}
{"id": "2601.21258", "categories": ["cs.CR", "cs.SE"], "pdf": "https://arxiv.org/pdf/2601.21258", "abs": "https://arxiv.org/abs/2601.21258", "authors": ["Wei Minn", "Phong Phan", "Vikas K. Malviya", "Benjamin Adolphi", "Yan Naing Tun", "Henning Benzon Treichl", "Albert Ching", "Lwin Khin Shar", "David Lo"], "title": "Virtualization-based Penetration Testing Study for Detecting Accessibility Abuse Vulnerabilities in Banking Apps in East and Southeast Asia", "comment": "Accepted at APSEC 2025 Software Engineering in Practices (SEIP)", "summary": "Android banking applications have revolutionized financial management by allowing users to perform various financial activities through mobile devices. However, this convenience has attracted cybercriminals who exploit security vulnerabilities to access sensitive financial data. FjordPhantom, a malware identified by our industry collaborator, uses virtualization and hooking to bypass the detection of malicious accessibility services, allowing it to conduct keylogging, screen scraping, and unauthorized data access. This malware primarily affects banking and finance apps across East and Southeast Asia region where our industry partner's clients are primarily based in. It requires users to be deceived into installing a secondary malicious component and activating a malicious accessibility service. In our study, we conducted an empirical study on the susceptibility of banking apps in the region to FjordPhantom, analyzed the effectiveness of protective measures currently implemented in those apps, and discussed ways to detect and prevent such attacks by identifying and mitigating the vulnerabilities exploited by this malware.", "AI": {"tldr": "\u8be5\u7814\u7a76\u5206\u6790\u4e86FjordPhantom\u6076\u610f\u8f6f\u4ef6\u5982\u4f55\u5229\u7528\u865a\u62df\u5316\u548c\u94a9\u5b50\u6280\u672f\u7ed5\u8fc7\u5b89\u5353\u94f6\u884c\u5e94\u7528\u7684\u5b89\u5168\u68c0\u6d4b\uff0c\u901a\u8fc7\u5b9e\u8bc1\u7814\u7a76\u8bc4\u4f30\u4e86\u4e1c\u4e9a\u548c\u4e1c\u5357\u4e9a\u5730\u533a\u94f6\u884c\u5e94\u7528\u7684\u6613\u53d7\u653b\u51fb\u6027\uff0c\u5e76\u63d0\u51fa\u4e86\u68c0\u6d4b\u548c\u9632\u5fa1\u65b9\u6cd5\u3002", "motivation": "\u5b89\u5353\u94f6\u884c\u5e94\u7528\u867d\u7136\u65b9\u4fbf\u4e86\u91d1\u878d\u7ba1\u7406\uff0c\u4f46\u4e5f\u5438\u5f15\u4e86\u7f51\u7edc\u72af\u7f6a\u5206\u5b50\u5229\u7528\u5b89\u5168\u6f0f\u6d1e\u7a83\u53d6\u654f\u611f\u8d22\u52a1\u6570\u636e\u3002FjordPhantom\u6076\u610f\u8f6f\u4ef6\u901a\u8fc7\u865a\u62df\u5316\u548c\u94a9\u5b50\u6280\u672f\u7ed5\u8fc7\u6076\u610f\u65e0\u969c\u788d\u670d\u52a1\u7684\u68c0\u6d4b\uff0c\u5bf9\u4e1c\u4e9a\u548c\u4e1c\u5357\u4e9a\u5730\u533a\u7684\u94f6\u884c\u5e94\u7528\u6784\u6210\u4e25\u91cd\u5a01\u80c1\uff0c\u9700\u8981\u7814\u7a76\u5176\u653b\u51fb\u673a\u5236\u548c\u9632\u5fa1\u65b9\u6cd5\u3002", "method": "\u7814\u7a76\u8fdb\u884c\u4e86\u5b9e\u8bc1\u7814\u7a76\uff0c\u5206\u6790\u8be5\u5730\u533a\u94f6\u884c\u5e94\u7528\u5bf9FjordPhantom\u7684\u6613\u53d7\u653b\u51fb\u6027\uff1b\u8bc4\u4f30\u4e86\u8fd9\u4e9b\u5e94\u7528\u4e2d\u73b0\u6709\u4fdd\u62a4\u63aa\u65bd\u7684\u6709\u6548\u6027\uff1b\u901a\u8fc7\u8bc6\u522b\u548c\u7f13\u89e3\u8be5\u6076\u610f\u8f6f\u4ef6\u5229\u7528\u7684\u6f0f\u6d1e\uff0c\u8ba8\u8bba\u4e86\u68c0\u6d4b\u548c\u9884\u9632\u6b64\u7c7b\u653b\u51fb\u7684\u65b9\u6cd5\u3002", "result": "\u7814\u7a76\u53d1\u73b0FjordPhantom\u80fd\u591f\u901a\u8fc7\u6b3a\u9a97\u7528\u6237\u5b89\u88c5\u6076\u610f\u7ec4\u4ef6\u5e76\u6fc0\u6d3b\u6076\u610f\u65e0\u969c\u788d\u670d\u52a1\uff0c\u6210\u529f\u7ed5\u8fc7\u5b89\u5168\u68c0\u6d4b\uff0c\u8fdb\u884c\u952e\u76d8\u8bb0\u5f55\u3001\u5c4f\u5e55\u6293\u53d6\u548c\u672a\u7ecf\u6388\u6743\u7684\u6570\u636e\u8bbf\u95ee\u3002\u8be5\u6076\u610f\u8f6f\u4ef6\u4e3b\u8981\u5f71\u54cd\u4e1c\u4e9a\u548c\u4e1c\u5357\u4e9a\u5730\u533a\u7684\u94f6\u884c\u548c\u91d1\u878d\u5e94\u7528\u3002", "conclusion": "\u7814\u7a76\u5f3a\u8c03\u4e86\u5b89\u5353\u94f6\u884c\u5e94\u7528\u9762\u4e34\u7684\u65b0\u578b\u5a01\u80c1\uff0c\u63d0\u51fa\u4e86\u901a\u8fc7\u8bc6\u522b\u6f0f\u6d1e\u548c\u52a0\u5f3a\u5b89\u5168\u63aa\u65bd\u6765\u68c0\u6d4b\u548c\u9884\u9632FjordPhantom\u7c7b\u653b\u51fb\u7684\u65b9\u6cd5\uff0c\u4e3a\u94f6\u884c\u5e94\u7528\u5f00\u53d1\u8005\u63d0\u4f9b\u4e86\u5b89\u5168\u6539\u8fdb\u7684\u65b9\u5411\u3002"}}
{"id": "2601.21261", "categories": ["cs.CR"], "pdf": "https://arxiv.org/pdf/2601.21261", "abs": "https://arxiv.org/abs/2601.21261", "authors": ["Abrar Hamed Al Barwani", "Abdelaziz Amara Korba", "Raja Waseem Anwar"], "title": "User-Centric Phishing Detection: A RAG and LLM-Based Approach", "comment": null, "summary": "The escalating sophistication of phishing emails necessitates a shift beyond traditional rule-based and conventional machine-learning-based detectors. Although large language models (LLMs) offer strong natural language understanding, using them as standalone classifiers often yields elevated falsepositive (FP) rates, which mislabel legitimate emails as phishing and create significant operational burden. This paper presents a personalized phishing detection framework that integrates LLMs with retrieval-augmented generation (RAG). For each message, the system constructs user-specific context by retrieving a compact set of the user's historical legitimate emails and enriching it with real-time domain and URL reputation from a cyber-threat intelligence platform, then conditions the LLM's decision on this evidence. We evaluate four open-source LLMs (Llama4-Scout, DeepSeek-R1, Mistral-Saba, and Gemma2) on an email dataset collected from public and institutional sources. Results show high performance; for example, Llama4-Scout attains an F1-score of 0.9703 and achieves a 66.7% reduction in FPs with RAG. These findings validate that a RAG-based, user-profiling approach is both feasible and effective for building high-precision, low-friction email security systems that adapt to individual communication patterns.", "AI": {"tldr": "\u63d0\u51fa\u4e00\u4e2a\u7ed3\u5408LLM\u4e0e\u68c0\u7d22\u589e\u5f3a\u751f\u6210(RAG)\u7684\u4e2a\u6027\u5316\u9493\u9c7c\u90ae\u4ef6\u68c0\u6d4b\u6846\u67b6\uff0c\u901a\u8fc7\u68c0\u7d22\u7528\u6237\u5386\u53f2\u90ae\u4ef6\u548c\u5b9e\u65f6\u5a01\u80c1\u60c5\u62a5\u6765\u63d0\u5347\u68c0\u6d4b\u7cbe\u5ea6\uff0c\u663e\u8457\u964d\u4f4e\u8bef\u62a5\u7387\u3002", "motivation": "\u4f20\u7edf\u89c4\u5219\u548c\u673a\u5668\u5b66\u4e60\u65b9\u6cd5\u96be\u4ee5\u5e94\u5bf9\u65e5\u76ca\u590d\u6742\u7684\u9493\u9c7c\u90ae\u4ef6\uff0c\u800c\u5355\u72ec\u4f7f\u7528LLM\u4f5c\u4e3a\u5206\u7c7b\u5668\u4f1a\u4ea7\u751f\u9ad8\u8bef\u62a5\u7387\uff0c\u7ed9\u8fd0\u8425\u5e26\u6765\u8d1f\u62c5\uff0c\u9700\u8981\u66f4\u7cbe\u51c6\u7684\u4e2a\u6027\u5316\u68c0\u6d4b\u65b9\u6848\u3002", "method": "\u6784\u5efa\u4e2a\u6027\u5316\u9493\u9c7c\u68c0\u6d4b\u6846\u67b6\uff1a\u4e3a\u6bcf\u6761\u6d88\u606f\u68c0\u7d22\u7528\u6237\u5386\u53f2\u5408\u6cd5\u90ae\u4ef6\u5f62\u6210\u7528\u6237\u7279\u5b9a\u4e0a\u4e0b\u6587\uff0c\u7ed3\u5408\u5b9e\u65f6\u57df\u540d\u548cURL\u4fe1\u8a89\u5a01\u80c1\u60c5\u62a5\uff0c\u4f7f\u7528RAG\u589e\u5f3aLLM\u51b3\u7b56\u3002\u8bc4\u4f30\u4e86Llama4-Scout\u7b49\u56db\u79cd\u5f00\u6e90LLM\u3002", "result": "\u5728\u516c\u5f00\u548c\u673a\u6784\u90ae\u4ef6\u6570\u636e\u96c6\u4e0a\u8bc4\u4f30\u663e\u793a\u9ad8\u6027\u80fd\uff0cLlama4-Scout\u8fbe\u5230F1\u5206\u65700.9703\uff0cRAG\u4f7f\u8bef\u62a5\u7387\u964d\u4f4e66.7%\uff0c\u9a8c\u8bc1\u4e86RAG\u7528\u6237\u753b\u50cf\u65b9\u6cd5\u7684\u6709\u6548\u6027\u3002", "conclusion": "\u57fa\u4e8eRAG\u7684\u7528\u6237\u753b\u50cf\u65b9\u6cd5\u53ef\u884c\u4e14\u6709\u6548\uff0c\u80fd\u591f\u6784\u5efa\u9ad8\u7cbe\u5ea6\u3001\u4f4e\u6469\u64e6\u7684\u90ae\u4ef6\u5b89\u5168\u7cfb\u7edf\uff0c\u9002\u5e94\u4e2a\u4eba\u901a\u4fe1\u6a21\u5f0f\uff0c\u663e\u8457\u964d\u4f4e\u8bef\u62a5\u7387\u3002"}}
{"id": "2601.21287", "categories": ["cs.CR"], "pdf": "https://arxiv.org/pdf/2601.21287", "abs": "https://arxiv.org/abs/2601.21287", "authors": ["Yifei Cai", "Yizhou Feng", "Qiao Zhang", "Chunsheng Xin", "Hongyi Wu"], "title": "Towards Zero Rotation and Beyond: Architecting Neural Networks for Fast Secure Inference with Homomorphic Encryption", "comment": "the IEEE Conference on Secure and Trustworthy Machine Learning (SaTML)", "summary": "Privacy-preserving deep learning addresses privacy concerns in Machine Learning as a Service (MLaaS) by using Homomorphic Encryption (HE) for linear computations. However, the computational overhead remains a major challenge. While prior work has improved efficiency, most approaches build on models originally designed for plaintext inference. Such models incur architectural inefficiencies when adapted to HE. We argue that substantial gains require networks tailored to HE rather than retrofitting plaintext architectures. Our design has two components: the building block and the overall architecture. First, StriaBlock targets the most expensive HE operation, rotation. It integrates ExRot-Free Convolution and a novel Cross Kernel, eliminating external rotations and requiring only 19% of the internal rotations used by plaintext models. Second, our architectural principles include (i) the Focused Constraint Principle, which limits cost-sensitive factors while preserving flexibility elsewhere, and (ii) the Channel Packing-Aware Scaling Principle, which adapts bottleneck ratios to ciphertext channel capacity that varies with depth. Together, these strategies control both local and end-to-end HE cost, enabling a balanced HE-tailored network. We evaluate the resulting StriaNet across datasets of varying scales, including ImageNet, Tiny ImageNet, and CIFAR-10. At comparable accuracy, StriaNet achieves speedups of 9.78x, 6.01x, and 9.24x on ImageNet, Tiny ImageNet, and CIFAR-10, respectively.", "AI": {"tldr": "StriaNet\uff1a\u9488\u5bf9\u540c\u6001\u52a0\u5bc6\u4f18\u5316\u7684\u795e\u7ecf\u7f51\u7edc\u67b6\u6784\uff0c\u901a\u8fc7\u6d88\u9664\u5916\u90e8\u65cb\u8f6c\u548c\u51cf\u5c11\u5185\u90e8\u65cb\u8f6c\uff0c\u5728\u4fdd\u6301\u7cbe\u5ea6\u7684\u540c\u65f6\u5b9e\u73b06-10\u500d\u52a0\u901f\u3002", "motivation": "\u73b0\u6709\u9690\u79c1\u4fdd\u62a4\u6df1\u5ea6\u5b66\u4e60\u4f7f\u7528\u540c\u6001\u52a0\u5bc6\uff08HE\uff09\u8fdb\u884c\u7ebf\u6027\u8ba1\u7b97\uff0c\u4f46\u8ba1\u7b97\u5f00\u9500\u5de8\u5927\u3002\u5927\u591a\u6570\u65b9\u6cd5\u57fa\u4e8e\u660e\u6587\u63a8\u7406\u8bbe\u8ba1\u7684\u6a21\u578b\uff0c\u8fd9\u4e9b\u6a21\u578b\u5728\u9002\u5e94HE\u65f6\u5b58\u5728\u67b6\u6784\u4f4e\u6548\u95ee\u9898\u3002\u9700\u8981\u4e13\u95e8\u4e3aHE\u8bbe\u8ba1\u7684\u7f51\u7edc\u800c\u975e\u6539\u9020\u660e\u6587\u67b6\u6784\u3002", "method": "\u63d0\u51fa\u4e24\u4e2a\u6838\u5fc3\u7ec4\u4ef6\uff1a1) StriaBlock\uff1a\u9488\u5bf9\u6700\u6602\u8d35\u7684HE\u64cd\u4f5c\uff08\u65cb\u8f6c\uff09\uff0c\u96c6\u6210ExRot-Free\u5377\u79ef\u548c\u65b0\u578bCross Kernel\uff0c\u6d88\u9664\u5916\u90e8\u65cb\u8f6c\uff0c\u5185\u90e8\u65cb\u8f6c\u4ec5\u9700\u660e\u6587\u6a21\u578b\u768419%\uff1b2) \u67b6\u6784\u539f\u5219\uff1a\u805a\u7126\u7ea6\u675f\u539f\u5219\uff08\u9650\u5236\u6210\u672c\u654f\u611f\u56e0\u7d20\uff09\u548c\u901a\u9053\u6253\u5305\u611f\u77e5\u7f29\u653e\u539f\u5219\uff08\u6839\u636e\u6df1\u5ea6\u8c03\u6574\u74f6\u9888\u6bd4\u4ee5\u9002\u5e94\u5bc6\u6587\u901a\u9053\u5bb9\u91cf\uff09\u3002", "result": "\u5728ImageNet\u3001Tiny ImageNet\u548cCIFAR-10\u6570\u636e\u96c6\u4e0a\uff0cStriaNet\u5728\u4fdd\u6301\u76f8\u5f53\u7cbe\u5ea6\u7684\u60c5\u51b5\u4e0b\uff0c\u5206\u522b\u5b9e\u73b0\u4e869.78\u500d\u30016.01\u500d\u548c9.24\u500d\u7684\u52a0\u901f\u3002", "conclusion": "\u901a\u8fc7\u4e13\u95e8\u4e3a\u540c\u6001\u52a0\u5bc6\u8bbe\u8ba1\u7684\u7f51\u7edc\u67b6\u6784\uff0c\u800c\u975e\u6539\u9020\u660e\u6587\u6a21\u578b\uff0c\u53ef\u4ee5\u663e\u8457\u63d0\u5347\u9690\u79c1\u4fdd\u62a4\u6df1\u5ea6\u5b66\u4e60\u7684\u6548\u7387\u3002StriaNet\u5c55\u793a\u4e86\u901a\u8fc7\u4f18\u5316HE\u7279\u5b9a\u64cd\u4f5c\u548c\u67b6\u6784\u539f\u5219\uff0c\u5728\u4fdd\u6301\u7cbe\u5ea6\u7684\u540c\u65f6\u5b9e\u73b0\u6570\u91cf\u7ea7\u52a0\u901f\u7684\u53ef\u884c\u6027\u3002"}}
{"id": "2601.21353", "categories": ["cs.CR"], "pdf": "https://arxiv.org/pdf/2601.21353", "abs": "https://arxiv.org/abs/2601.21353", "authors": ["Qinhan Tan", "Akash Gaonkar", "Yu-Wei Fan", "Aarti Gupta", "Sharad Malik"], "title": "SecIC3: Customizing IC3 for Hardware Security Verification", "comment": "Accepted by DATE 2026", "summary": "Recent years have seen significant advances in using formal verification to check hardware security properties. Of particular practical interest are checking confidentiality and integrity of secrets, by checking that there is no information flow between the secrets and observable outputs. A standard method for checking information flow is to translate the corresponding non-interference hyperproperty into a safety property on a self-composition of the design, which has two copies of the design composed together. Although prior efforts have aimed to reduce the size of the self-composed design, there are no state-of-the-art model checkers that exploit their special structure for hardware security verification. In this paper, we propose SecIC3, a hardware model checking algorithm based on IC3 that is customized to exploit this self-composition structure. SecIC3 utilizes this structure in two complementary techniques: symmetric state exploration and adding equivalence predicates. We implement SecIC3 on top of two open-source IC3 implementations and evaluate it on a non-interference checking benchmark consisting of 10 designs. The experiment results show that SecIC3 significantly reduces the time for finding security proofs, with up to 49.3x proof speedup compared to baseline implementations.", "AI": {"tldr": "SecIC3\uff1a\u4e00\u79cd\u5229\u7528\u81ea\u7ec4\u5408\u7ed3\u6784\u8fdb\u884c\u786c\u4ef6\u5b89\u5168\u9a8c\u8bc1\u7684IC3\u6a21\u578b\u68c0\u67e5\u7b97\u6cd5\uff0c\u901a\u8fc7\u5bf9\u79f0\u72b6\u6001\u63a2\u7d22\u548c\u7b49\u4ef7\u8c13\u8bcd\u6280\u672f\u663e\u8457\u63d0\u5347\u975e\u5e72\u6270\u6027\u68c0\u67e5\u6548\u7387", "motivation": "\u73b0\u6709\u786c\u4ef6\u5b89\u5168\u9a8c\u8bc1\u65b9\u6cd5\u5c06\u975e\u5e72\u6270\u8d85\u5c5e\u6027\u8f6c\u6362\u4e3a\u81ea\u7ec4\u5408\u8bbe\u8ba1\u7684\u5b89\u5168\u5c5e\u6027\u68c0\u67e5\uff0c\u4f46\u7f3a\u4e4f\u9488\u5bf9\u8fd9\u79cd\u7279\u6b8a\u7ed3\u6784\u7684\u4f18\u5316\u6a21\u578b\u68c0\u67e5\u5668\uff0c\u5bfc\u81f4\u9a8c\u8bc1\u6548\u7387\u4e0d\u9ad8", "method": "\u57fa\u4e8eIC3\u7b97\u6cd5\u5f00\u53d1SecIC3\uff0c\u5229\u7528\u81ea\u7ec4\u5408\u7ed3\u6784\u7279\u70b9\uff0c\u91c7\u7528\u5bf9\u79f0\u72b6\u6001\u63a2\u7d22\u548c\u6dfb\u52a0\u7b49\u4ef7\u8c13\u8bcd\u4e24\u79cd\u4e92\u8865\u6280\u672f\u6765\u4f18\u5316\u9a8c\u8bc1\u8fc7\u7a0b", "result": "\u572810\u4e2a\u8bbe\u8ba1\u7684\u975e\u5e72\u6270\u68c0\u67e5\u57fa\u51c6\u6d4b\u8bd5\u4e2d\uff0cSecIC3\u663e\u8457\u51cf\u5c11\u4e86\u5b89\u5168\u8bc1\u660e\u65f6\u95f4\uff0c\u76f8\u6bd4\u57fa\u7ebf\u5b9e\u73b0\u6700\u9ad8\u8fbe\u523049.3\u500d\u7684\u8bc1\u660e\u52a0\u901f", "conclusion": "SecIC3\u901a\u8fc7\u4e13\u95e8\u9488\u5bf9\u81ea\u7ec4\u5408\u7ed3\u6784\u4f18\u5316\u7684IC3\u7b97\u6cd5\uff0c\u6709\u6548\u63d0\u5347\u4e86\u786c\u4ef6\u5b89\u5168\u9a8c\u8bc1\u7684\u6548\u7387\uff0c\u4e3a\u786c\u4ef6\u4fe1\u606f\u6d41\u5b89\u5168\u9a8c\u8bc1\u63d0\u4f9b\u4e86\u66f4\u9ad8\u6548\u7684\u89e3\u51b3\u65b9\u6848"}}
{"id": "2601.21380", "categories": ["cs.CR"], "pdf": "https://arxiv.org/pdf/2601.21380", "abs": "https://arxiv.org/abs/2601.21380", "authors": ["Wenhui Zhang", "Huiyu Xu", "Zhibo Wang", "Zhichao Li", "Zeqing He", "Xuelin Wei", "Kui Ren"], "title": "RerouteGuard: Understanding and Mitigating Adversarial Risks for LLM Routing", "comment": "15 pages, 13 figures", "summary": "Recent advancements in multi-model AI systems have leveraged LLM routers to reduce computational cost while maintaining response quality by assigning queries to the most appropriate model. However, as classifiers, LLM routers are vulnerable to novel adversarial attacks in the form of LLM rerouting, where adversaries prepend specially crafted triggers to user queries to manipulate routing decisions. Such attacks can lead to increased computational cost, degraded response quality, and even bypass safety guardrails, yet their security implications remain largely underexplored. In this work, we bridge this gap by systematizing LLM rerouting threats based on the adversary's objectives (i.e., cost escalation, quality hijacking, and safety bypass) and knowledge. Based on the threat taxonomy, we conduct a measurement study of real-world LLM routing systems against existing LLM rerouting attacks. The results reveal that existing routing systems are vulnerable to rerouting attacks, especially in the cost escalation scenario. We then characterize existing rerouting attacks using interpretability techniques, revealing that they exploit router decision boundaries through confounder gadgets that prepend queries to force misrouting. To mitigate these risks, we introduce RerouteGuard, a flexible and scalable guardrail framework for LLM rerouting. RerouteGuard filters adversarial rerouting prompts via dynamic embedding-based detection and adaptive thresholding. Extensive evaluations in three attack settings and four benchmarks demonstrate that RerouteGuard achieves over 99% detection accuracy against state-of-the-art rerouting attacks, while maintaining negligible impact on legitimate queries. The experimental results indicate that RerouteGuard offers a principled and practical solution for safeguarding multi-model AI systems against adversarial rerouting.", "AI": {"tldr": "\u672c\u6587\u7cfb\u7edf\u7814\u7a76\u4e86LLM\u8def\u7531\u7cfb\u7edf\u4e2d\u7684\u5bf9\u6297\u6027\u91cd\u8def\u7531\u653b\u51fb\uff0c\u63d0\u51fa\u4e86\u5a01\u80c1\u5206\u7c7b\u3001\u6d4b\u91cf\u7814\u7a76\uff0c\u5e76\u5f00\u53d1\u4e86RerouteGuard\u9632\u5fa1\u6846\u67b6\uff0c\u80fd\u6709\u6548\u68c0\u6d4b\u548c\u9632\u5fa1\u6b64\u7c7b\u653b\u51fb\u3002", "motivation": "\u591a\u6a21\u578bAI\u7cfb\u7edf\u4e2d\u7684LLM\u8def\u7531\u5668\u867d\u7136\u80fd\u964d\u4f4e\u8ba1\u7b97\u6210\u672c\uff0c\u4f46\u4f5c\u4e3a\u5206\u7c7b\u5668\u5bb9\u6613\u53d7\u5230\u5bf9\u6297\u6027\u653b\u51fb\u3002\u653b\u51fb\u8005\u53ef\u4ee5\u901a\u8fc7\u5728\u67e5\u8be2\u524d\u6dfb\u52a0\u7279\u5236\u89e6\u53d1\u5668\u6765\u64cd\u7eb5\u8def\u7531\u51b3\u7b56\uff0c\u5bfc\u81f4\u8ba1\u7b97\u6210\u672c\u589e\u52a0\u3001\u54cd\u5e94\u8d28\u91cf\u4e0b\u964d\u751a\u81f3\u7ed5\u8fc7\u5b89\u5168\u9632\u62a4\uff0c\u4f46\u8fd9\u4e9b\u5b89\u5168\u5f71\u54cd\u5c1a\u672a\u5f97\u5230\u5145\u5206\u7814\u7a76\u3002", "method": "1) \u57fa\u4e8e\u653b\u51fb\u8005\u76ee\u6807\uff08\u6210\u672c\u63d0\u5347\u3001\u8d28\u91cf\u52ab\u6301\u3001\u5b89\u5168\u7ed5\u8fc7\uff09\u548c\u77e5\u8bc6\u5bf9LLM\u91cd\u8def\u7531\u5a01\u80c1\u8fdb\u884c\u7cfb\u7edf\u5206\u7c7b\uff1b2) \u5bf9\u73b0\u6709LLM\u8def\u7531\u7cfb\u7edf\u8fdb\u884c\u6d4b\u91cf\u7814\u7a76\uff1b3) \u4f7f\u7528\u53ef\u89e3\u91ca\u6027\u6280\u672f\u5206\u6790\u73b0\u6709\u653b\u51fb\u65b9\u6cd5\uff1b4) \u63d0\u51faRerouteGuard\u9632\u5fa1\u6846\u67b6\uff0c\u91c7\u7528\u52a8\u6001\u5d4c\u5165\u68c0\u6d4b\u548c\u81ea\u9002\u5e94\u9608\u503c\u6765\u8fc7\u6ee4\u5bf9\u6297\u6027\u91cd\u8def\u7531\u63d0\u793a\u3002", "result": "\u6d4b\u91cf\u7814\u7a76\u53d1\u73b0\u73b0\u6709\u8def\u7531\u7cfb\u7edf\u5bb9\u6613\u53d7\u5230\u91cd\u8def\u7531\u653b\u51fb\uff0c\u7279\u522b\u662f\u5728\u6210\u672c\u63d0\u5347\u573a\u666f\u4e2d\u3002RerouteGuard\u5728\u4e09\u79cd\u653b\u51fb\u8bbe\u7f6e\u548c\u56db\u4e2a\u57fa\u51c6\u6d4b\u8bd5\u4e2d\u5b9e\u73b0\u4e86\u8d85\u8fc799%\u7684\u68c0\u6d4b\u51c6\u786e\u7387\uff0c\u540c\u65f6\u5bf9\u5408\u6cd5\u67e5\u8be2\u5f71\u54cd\u6781\u5c0f\u3002", "conclusion": "LLM\u91cd\u8def\u7531\u653b\u51fb\u5bf9\u591a\u6a21\u578bAI\u7cfb\u7edf\u6784\u6210\u4e25\u91cd\u5a01\u80c1\uff0c\u4f46\u901a\u8fc7RerouteGuard\u8fd9\u6837\u7684\u9632\u5fa1\u6846\u67b6\u53ef\u4ee5\u6709\u6548\u7f13\u89e3\u8fd9\u4e9b\u98ce\u9669\u3002\u8be5\u7814\u7a76\u4e3a\u4fdd\u62a4\u591a\u6a21\u578bAI\u7cfb\u7edf\u514d\u53d7\u5bf9\u6297\u6027\u91cd\u8def\u7531\u653b\u51fb\u63d0\u4f9b\u4e86\u539f\u5219\u6027\u548c\u5b9e\u7528\u7684\u89e3\u51b3\u65b9\u6848\u3002"}}
{"id": "2601.21531", "categories": ["cs.CR", "cs.AI", "cs.CV"], "pdf": "https://arxiv.org/pdf/2601.21531", "abs": "https://arxiv.org/abs/2601.21531", "authors": ["Xinwei Zhang", "Hangcheng Liu", "Li Bai", "Hao Wang", "Qingqing Ye", "Tianwei Zhang", "Haibo Hu"], "title": "On the Adversarial Robustness of Large Vision-Language Models under Visual Token Compression", "comment": "Under Review, 20 pages", "summary": "Visual token compression is widely used to accelerate large vision-language models (LVLMs) by pruning or merging visual tokens, yet its adversarial robustness remains unexplored. We show that existing encoder-based attacks can substantially overestimate the robustness of compressed LVLMs, due to an optimization-inference mismatch: perturbations are optimized on the full-token representation, while inference is performed through a token-compression bottleneck. To address this gap, we propose the Compression-AliGnEd attack (CAGE), which aligns perturbation optimization with compression inference without assuming access to the deployed compression mechanism or its token budget. CAGE combines (i) expected feature disruption, which concentrates distortion on tokens likely to survive across plausible budgets, and (ii) rank distortion alignment, which actively aligns token distortions with rank scores to promote the retention of highly distorted evidence. Across diverse representative plug-and-play compression mechanisms and datasets, our results show that CAGE consistently achieves lower robust accuracy than the baseline. This work highlights that robustness assessments ignoring compression can be overly optimistic, calling for compression-aware security evaluation and defenses for efficient LVLMs.", "AI": {"tldr": "\u672c\u6587\u63d0\u51faCAGE\u653b\u51fb\u65b9\u6cd5\uff0c\u9488\u5bf9\u89c6\u89c9\u8bed\u8a00\u6a21\u578b\u4e2d\u7684\u89c6\u89c9\u4ee4\u724c\u538b\u7f29\u673a\u5236\uff0c\u901a\u8fc7\u5bf9\u9f50\u6270\u52a8\u4f18\u5316\u4e0e\u538b\u7f29\u63a8\u7406\uff0c\u63ed\u793a\u4e86\u73b0\u6709\u653b\u51fb\u65b9\u6cd5\u9ad8\u4f30\u538b\u7f29\u6a21\u578b\u9c81\u68d2\u6027\u7684\u95ee\u9898\u3002", "motivation": "\u73b0\u6709\u57fa\u4e8e\u7f16\u7801\u5668\u7684\u653b\u51fb\u65b9\u6cd5\u5728\u8bc4\u4f30\u538b\u7f29\u89c6\u89c9\u8bed\u8a00\u6a21\u578b\u7684\u5bf9\u6297\u9c81\u68d2\u6027\u65f6\u5b58\u5728\u4e25\u91cd\u9ad8\u4f30\uff0c\u539f\u56e0\u662f\u5b58\u5728\u4f18\u5316-\u63a8\u7406\u4e0d\u5339\u914d\uff1a\u6270\u52a8\u5728\u5b8c\u6574\u4ee4\u724c\u8868\u793a\u4e0a\u4f18\u5316\uff0c\u800c\u63a8\u7406\u901a\u8fc7\u4ee4\u724c\u538b\u7f29\u74f6\u9888\u8fdb\u884c\u3002", "method": "\u63d0\u51faCAGE\u653b\u51fb\u65b9\u6cd5\uff0c\u5305\u542b\u4e24\u4e2a\u6838\u5fc3\u7ec4\u4ef6\uff1a(1) \u9884\u671f\u7279\u5f81\u7834\u574f\uff1a\u5c06\u5931\u771f\u96c6\u4e2d\u5728\u53ef\u80fd\u5728\u4e0d\u540c\u9884\u7b97\u4e0b\u5b58\u6d3b\u7684\u4ee4\u724c\u4e0a\uff1b(2) \u79e9\u5931\u771f\u5bf9\u9f50\uff1a\u4e3b\u52a8\u5c06\u4ee4\u724c\u5931\u771f\u4e0e\u79e9\u5206\u6570\u5bf9\u9f50\uff0c\u4ee5\u4fc3\u8fdb\u9ad8\u5ea6\u5931\u771f\u8bc1\u636e\u7684\u4fdd\u7559\u3002", "result": "\u5728\u591a\u79cd\u4ee3\u8868\u6027\u7684\u5373\u63d2\u5373\u7528\u538b\u7f29\u673a\u5236\u548c\u6570\u636e\u96c6\u4e0a\uff0cCAGE\u59cb\u7ec8\u6bd4\u57fa\u7ebf\u65b9\u6cd5\u83b7\u5f97\u66f4\u4f4e\u7684\u9c81\u68d2\u51c6\u786e\u7387\uff0c\u8bc1\u660e\u4e86\u73b0\u6709\u9c81\u68d2\u6027\u8bc4\u4f30\u5ffd\u7565\u538b\u7f29\u673a\u5236\u4f1a\u8fc7\u4e8e\u4e50\u89c2\u3002", "conclusion": "\u672c\u6587\u63ed\u793a\u4e86\u5ffd\u7565\u538b\u7f29\u673a\u5236\u7684\u9c81\u68d2\u6027\u8bc4\u4f30\u5b58\u5728\u4e25\u91cd\u7f3a\u9677\uff0c\u547c\u5401\u5bf9\u9ad8\u6548\u89c6\u89c9\u8bed\u8a00\u6a21\u578b\u8fdb\u884c\u538b\u7f29\u611f\u77e5\u7684\u5b89\u5168\u8bc4\u4f30\u548c\u9632\u5fa1\u8bbe\u8ba1\u3002"}}
{"id": "2601.21586", "categories": ["cs.CR"], "pdf": "https://arxiv.org/pdf/2601.21586", "abs": "https://arxiv.org/abs/2601.21586", "authors": ["Ningyuan He", "Ronghong Huang", "Qianqian Tang", "Hongyu Wang", "Xianghang Mi", "Shanqing Guo"], "title": "ICL-EVADER: Zero-Query Black-Box Evasion Attacks on In-Context Learning and Their Defenses", "comment": "32 pages, Accepted by The Web Conference 2026 (WWW '26)", "summary": "In-context learning (ICL) has become a powerful, data-efficient paradigm for text classification using large language models. However, its robustness against realistic adversarial threats remains largely unexplored. We introduce ICL-Evader, a novel black-box evasion attack framework that operates under a highly practical zero-query threat model, requiring no access to model parameters, gradients, or query-based feedback during attack generation. We design three novel attacks, Fake Claim, Template, and Needle-in-a-Haystack, that exploit inherent limitations of LLMs in processing in-context prompts. Evaluated across sentiment analysis, toxicity, and illicit promotion tasks, our attacks significantly degrade classifier performance (e.g., achieving up to 95.3% attack success rate), drastically outperforming traditional NLP attacks which prove ineffective under the same constraints. To counter these vulnerabilities, we systematically investigate defense strategies and identify a joint defense recipe that effectively mitigates all attacks with minimal utility loss (<5% accuracy degradation). Finally, we translate our defensive insights into an automated tool that proactively fortifies standard ICL prompts against adversarial evasion. This work provides a comprehensive security assessment of ICL, revealing critical vulnerabilities and offering practical solutions for building more robust systems. Our source code and evaluation datasets are publicly available at: https://github.com/ChaseSecurity/ICL-Evader .", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86ICL-Evader\uff0c\u4e00\u79cd\u9488\u5bf9\u5927\u8bed\u8a00\u6a21\u578b\u4e0a\u4e0b\u6587\u5b66\u4e60\u7684\u9ed1\u76d2\u89c4\u907f\u653b\u51fb\u6846\u67b6\uff0c\u5728\u96f6\u67e5\u8be2\u5a01\u80c1\u6a21\u578b\u4e0b\u663e\u8457\u964d\u4f4e\u5206\u7c7b\u5668\u6027\u80fd\uff0c\u5e76\u63d0\u51fa\u4e86\u6709\u6548\u7684\u9632\u5fa1\u65b9\u6848\u3002", "motivation": "\u4e0a\u4e0b\u6587\u5b66\u4e60\u5df2\u6210\u4e3a\u6587\u672c\u5206\u7c7b\u7684\u5f3a\u5927\u6570\u636e\u9ad8\u6548\u8303\u5f0f\uff0c\u4f46\u5176\u5bf9\u73b0\u5b9e\u5bf9\u6297\u5a01\u80c1\u7684\u9c81\u68d2\u6027\u5c1a\u672a\u5145\u5206\u63a2\u7d22\u3002\u4f5c\u8005\u65e8\u5728\u63ed\u793aICL\u7684\u6f5c\u5728\u5b89\u5168\u6f0f\u6d1e\uff0c\u5e76\u5728\u9ad8\u5ea6\u5b9e\u7528\u7684\u5a01\u80c1\u6a21\u578b\u4e0b\u8bc4\u4f30\u5176\u8106\u5f31\u6027\u3002", "method": "\u63d0\u51fa\u4e86ICL-Evader\u653b\u51fb\u6846\u67b6\uff0c\u5305\u542b\u4e09\u79cd\u65b0\u578b\u653b\u51fb\uff1aFake Claim\u3001Template\u548cNeedle-in-a-Haystack\uff0c\u5229\u7528LLM\u5904\u7406\u4e0a\u4e0b\u6587\u63d0\u793a\u7684\u56fa\u6709\u5c40\u9650\u6027\u3002\u5728\u60c5\u611f\u5206\u6790\u3001\u6bd2\u6027\u548c\u975e\u6cd5\u63a8\u5e7f\u4efb\u52a1\u4e0a\u8fdb\u884c\u8bc4\u4f30\uff0c\u5e76\u7cfb\u7edf\u7814\u7a76\u9632\u5fa1\u7b56\u7565\u3002", "result": "\u653b\u51fb\u663e\u8457\u964d\u4f4e\u4e86\u5206\u7c7b\u5668\u6027\u80fd\uff08\u653b\u51fb\u6210\u529f\u7387\u9ad8\u8fbe95.3%\uff09\uff0c\u8fdc\u8d85\u4f20\u7edfNLP\u653b\u51fb\u3002\u540c\u65f6\u53d1\u73b0\u4e86\u8054\u5408\u9632\u5fa1\u65b9\u6848\uff0c\u80fd\u6709\u6548\u7f13\u89e3\u6240\u6709\u653b\u51fb\u4e14\u6548\u7528\u635f\u5931\u6700\u5c0f\uff08\u51c6\u786e\u7387\u4e0b\u964d<5%\uff09\u3002", "conclusion": "\u8fd9\u9879\u5de5\u4f5c\u5168\u9762\u8bc4\u4f30\u4e86ICL\u7684\u5b89\u5168\u6027\uff0c\u63ed\u793a\u4e86\u5173\u952e\u6f0f\u6d1e\uff0c\u5e76\u4e3a\u6784\u5efa\u66f4\u9c81\u68d2\u7684\u7cfb\u7edf\u63d0\u4f9b\u4e86\u5b9e\u7528\u89e3\u51b3\u65b9\u6848\u3002\u5f00\u53d1\u4e86\u81ea\u52a8\u5316\u5de5\u5177\u6765\u4e3b\u52a8\u52a0\u56fa\u6807\u51c6ICL\u63d0\u793a\uff0c\u5bf9\u6297\u5bf9\u6297\u6027\u89c4\u907f\u3002"}}
{"id": "2601.21628", "categories": ["cs.CR", "cs.LG"], "pdf": "https://arxiv.org/pdf/2601.21628", "abs": "https://arxiv.org/abs/2601.21628", "authors": ["Puwei Lian", "Yujun Cai", "Songze Li", "Bingkun Bao"], "title": "Noise as a Probe: Membership Inference Attacks on Diffusion Models Leveraging Initial Noise", "comment": null, "summary": "Diffusion models have achieved remarkable progress in image generation, but their increasing deployment raises serious concerns about privacy. In particular, fine-tuned models are highly vulnerable, as they are often fine-tuned on small and private datasets. Membership inference attacks (MIAs) are used to assess privacy risks by determining whether a specific sample was part of a model's training data. Existing MIAs against diffusion models either assume obtaining the intermediate results or require auxiliary datasets for training the shadow model. In this work, we utilized a critical yet overlooked vulnerability: the widely used noise schedules fail to fully eliminate semantic information in the images, resulting in residual semantic signals even at the maximum noise step. We empirically demonstrate that the fine-tuned diffusion model captures hidden correlations between the residual semantics in initial noise and the original images. Building on this insight, we propose a simple yet effective membership inference attack, which injects semantic information into the initial noise and infers membership by analyzing the model's generation result. Extensive experiments demonstrate that the semantic initial noise can strongly reveal membership information, highlighting the vulnerability of diffusion models to MIAs.", "AI": {"tldr": "\u8be5\u8bba\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u9488\u5bf9\u5fae\u8c03\u6269\u6563\u6a21\u578b\u7684\u6210\u5458\u63a8\u7406\u653b\u51fb\u65b9\u6cd5\uff0c\u5229\u7528\u566a\u58f0\u8c03\u5ea6\u4e2d\u6b8b\u7559\u7684\u8bed\u4e49\u4fe1\u606f\u6765\u63a8\u65ad\u6837\u672c\u662f\u5426\u5c5e\u4e8e\u8bad\u7ec3\u6570\u636e\u3002", "motivation": "\u6269\u6563\u6a21\u578b\u5728\u56fe\u50cf\u751f\u6210\u65b9\u9762\u53d6\u5f97\u663e\u8457\u8fdb\u5c55\uff0c\u4f46\u5176\u90e8\u7f72\u5f15\u53d1\u4e86\u9690\u79c1\u62c5\u5fe7\u3002\u5fae\u8c03\u6a21\u578b\u5c24\u5176\u8106\u5f31\uff0c\u56e0\u4e3a\u5b83\u4eec\u901a\u5e38\u5728\u5c0f\u578b\u79c1\u6709\u6570\u636e\u96c6\u4e0a\u5fae\u8c03\u3002\u73b0\u6709\u6210\u5458\u63a8\u7406\u653b\u51fb\u8981\u4e48\u9700\u8981\u83b7\u53d6\u4e2d\u95f4\u7ed3\u679c\uff0c\u8981\u4e48\u9700\u8981\u8f85\u52a9\u6570\u636e\u96c6\u8bad\u7ec3\u5f71\u5b50\u6a21\u578b\uff0c\u5b58\u5728\u5c40\u9650\u6027\u3002", "method": "\u5229\u7528\u566a\u58f0\u8c03\u5ea6\u4e2d\u6b8b\u7559\u8bed\u4e49\u4fe1\u606f\u7684\u6f0f\u6d1e\uff1a\u5373\u4f7f\u6700\u5927\u566a\u58f0\u6b65\u957f\u4e0b\uff0c\u56fe\u50cf\u4e2d\u4ecd\u5b58\u5728\u6b8b\u7559\u8bed\u4e49\u4fe1\u53f7\u3002\u5c06\u8bed\u4e49\u4fe1\u606f\u6ce8\u5165\u521d\u59cb\u566a\u58f0\uff0c\u901a\u8fc7\u5206\u6790\u6a21\u578b\u751f\u6210\u7ed3\u679c\u6765\u63a8\u65ad\u6210\u5458\u5173\u7cfb\u3002", "result": "\u5b9e\u9a8c\u8bc1\u660e\uff0c\u8bed\u4e49\u521d\u59cb\u566a\u58f0\u80fd\u5f3a\u70c8\u63ed\u793a\u6210\u5458\u4fe1\u606f\uff0c\u7a81\u663e\u6269\u6563\u6a21\u578b\u5bf9\u6210\u5458\u63a8\u7406\u653b\u51fb\u7684\u8106\u5f31\u6027\u3002", "conclusion": "\u6269\u6563\u6a21\u578b\u5b58\u5728\u4e25\u91cd\u9690\u79c1\u98ce\u9669\uff0c\u5f53\u524d\u566a\u58f0\u8c03\u5ea6\u672a\u80fd\u5b8c\u5168\u6d88\u9664\u8bed\u4e49\u4fe1\u606f\uff0c\u5bfc\u81f4\u6b8b\u7559\u8bed\u4e49\u4fe1\u53f7\u53ef\u88ab\u7528\u4e8e\u6210\u5458\u63a8\u7406\u653b\u51fb\u3002\u8fd9\u4e3a\u6269\u6563\u6a21\u578b\u7684\u9690\u79c1\u4fdd\u62a4\u63d0\u51fa\u4e86\u91cd\u8981\u8b66\u793a\u3002"}}
{"id": "2601.21657", "categories": ["cs.CR", "cs.NI", "eess.SY"], "pdf": "https://arxiv.org/pdf/2601.21657", "abs": "https://arxiv.org/abs/2601.21657", "authors": ["Andrew Savchenko"], "title": "Authenticated encryption for space telemetry", "comment": "11 pages. In proceedings of the 76th International Astronautical Congress (IAC 2025). Sydney, Australia, September 2025", "summary": "We explore how command stack protection requirements outlined in NASA-STD-1006A can be satisfied within the context of emergency space telemetry. Proposed implementation of lightweight authenticated encryption offers strong security without sacrificing performance in resource-constrained environments. It produces fixed-length messages, maintaining compatibility with the underlying data transport protocols. By focusing on predictable properties and robust authentication, we create a scheme that protects the confidentiality, integrity and authenticity of telemetry data in emergency communications while balancing security requirements with the operational constraints.", "AI": {"tldr": "\u8be5\u8bba\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u8f7b\u91cf\u7ea7\u8ba4\u8bc1\u52a0\u5bc6\u65b9\u6848\uff0c\u7528\u4e8e\u6ee1\u8db3NASA-STD-1006A\u6807\u51c6\u4e2d\u5e94\u6025\u7a7a\u95f4\u9065\u6d4b\u7684\u547d\u4ee4\u6808\u4fdd\u62a4\u8981\u6c42\uff0c\u5728\u8d44\u6e90\u53d7\u9650\u73af\u5883\u4e2d\u63d0\u4f9b\u5f3a\u5b89\u5168\u6027\u800c\u4e0d\u727a\u7272\u6027\u80fd\u3002", "motivation": "\u6ee1\u8db3NASA-STD-1006A\u6807\u51c6\u5bf9\u5e94\u6025\u7a7a\u95f4\u9065\u6d4b\u547d\u4ee4\u6808\u4fdd\u62a4\u7684\u8981\u6c42\uff0c\u5728\u8d44\u6e90\u53d7\u9650\u7684\u822a\u5929\u73af\u5883\u4e2d\u5e73\u8861\u5b89\u5168\u9700\u6c42\u4e0e\u64cd\u4f5c\u7ea6\u675f\uff0c\u4fdd\u62a4\u9065\u6d4b\u6570\u636e\u7684\u673a\u5bc6\u6027\u3001\u5b8c\u6574\u6027\u548c\u771f\u5b9e\u6027\u3002", "method": "\u63d0\u51fa\u8f7b\u91cf\u7ea7\u8ba4\u8bc1\u52a0\u5bc6\u5b9e\u73b0\u65b9\u6848\uff0c\u8be5\u65b9\u6848\u4ea7\u751f\u56fa\u5b9a\u957f\u5ea6\u6d88\u606f\u4ee5\u4fdd\u6301\u4e0e\u5e95\u5c42\u6570\u636e\u4f20\u8f93\u534f\u8bae\u7684\u517c\u5bb9\u6027\uff0c\u4e13\u6ce8\u4e8e\u53ef\u9884\u6d4b\u5c5e\u6027\u548c\u5f3a\u5065\u8ba4\u8bc1\u673a\u5236\u3002", "result": "\u8be5\u65b9\u6848\u80fd\u591f\u5728\u8d44\u6e90\u53d7\u9650\u73af\u5883\u4e2d\u63d0\u4f9b\u5f3a\u5b89\u5168\u6027\u800c\u4e0d\u727a\u7272\u6027\u80fd\uff0c\u4fdd\u62a4\u5e94\u6025\u901a\u4fe1\u4e2d\u9065\u6d4b\u6570\u636e\u7684\u673a\u5bc6\u6027\u3001\u5b8c\u6574\u6027\u548c\u771f\u5b9e\u6027\uff0c\u540c\u65f6\u4fdd\u6301\u4e0e\u73b0\u6709\u534f\u8bae\u7684\u517c\u5bb9\u6027\u3002", "conclusion": "\u8f7b\u91cf\u7ea7\u8ba4\u8bc1\u52a0\u5bc6\u65b9\u6848\u80fd\u591f\u6709\u6548\u6ee1\u8db3NASA-STD-1006A\u6807\u51c6\u5bf9\u5e94\u6025\u7a7a\u95f4\u9065\u6d4b\u7684\u4fdd\u62a4\u8981\u6c42\uff0c\u5728\u5b89\u5168\u6027\u548c\u64cd\u4f5c\u7ea6\u675f\u4e4b\u95f4\u53d6\u5f97\u826f\u597d\u5e73\u8861\uff0c\u9002\u7528\u4e8e\u8d44\u6e90\u53d7\u9650\u7684\u822a\u5929\u901a\u4fe1\u73af\u5883\u3002"}}
{"id": "2601.21680", "categories": ["cs.CR", "cs.LO"], "pdf": "https://arxiv.org/pdf/2601.21680", "abs": "https://arxiv.org/abs/2601.21680", "authors": ["Loes Kruger", "Paul Kobialka", "Andrea Pferscher", "Einar Broch Johnsen", "Sebastian Junges", "Jurriaan Rot"], "title": "Incremental Fingerprinting in an Open World", "comment": "Extended version of a CSF 2026 paper", "summary": "Network protocol fingerprinting is used to identify a protocol implementation by analyzing its input-output behavior. Traditionally, fingerprinting operates under a closed-world assumption, where models of all implementations are assumed to be available. However, this assumption is unrealistic in practice. When this assumption does not hold, fingerprinting results in numerous misclassifications without indicating that a model for an implementation is missing. Therefore, we introduce an open-world variant of the fingerprinting problem, where not all models are known in advance. We propose an incremental fingerprinting approach to solve the problem by combining active automata learning with closed-world fingerprinting. Our approach quickly determines whether the implementation under consideration matches an available model using fingerprinting and conformance checking. If no match is found, it learns a new model by exploiting the structure of available models. We prove the correctness of our approach and improvements in asymptotic complexity compared to naive baselines. Moreover, experimental results on a variety of protocols demonstrate a significant reduction in misclassifications and interactions with these black-boxes.", "AI": {"tldr": "\u63d0\u51fa\u5f00\u653e\u4e16\u754c\u7f51\u7edc\u534f\u8bae\u6307\u7eb9\u8bc6\u522b\u65b9\u6cd5\uff0c\u7ed3\u5408\u4e3b\u52a8\u81ea\u52a8\u673a\u5b66\u4e60\u548c\u95ed\u4e16\u754c\u6307\u7eb9\u8bc6\u522b\uff0c\u89e3\u51b3\u4f20\u7edf\u65b9\u6cd5\u5728\u672a\u77e5\u5b9e\u73b0\u6a21\u578b\u65f6\u7684\u8bef\u5206\u7c7b\u95ee\u9898\u3002", "motivation": "\u4f20\u7edf\u534f\u8bae\u6307\u7eb9\u8bc6\u522b\u57fa\u4e8e\u95ed\u4e16\u754c\u5047\u8bbe\uff0c\u8981\u6c42\u6240\u6709\u5b9e\u73b0\u6a21\u578b\u90fd\u5df2\u77e5\uff0c\u8fd9\u5728\u5b9e\u8df5\u4e2d\u4e0d\u73b0\u5b9e\u3002\u5f53\u5047\u8bbe\u4e0d\u6210\u7acb\u65f6\uff0c\u4f1a\u5bfc\u81f4\u5927\u91cf\u8bef\u5206\u7c7b\u4e14\u65e0\u6cd5\u6307\u793a\u7f3a\u5931\u6a21\u578b\u3002", "method": "\u63d0\u51fa\u589e\u91cf\u6307\u7eb9\u8bc6\u522b\u65b9\u6cd5\uff1a1) \u4f7f\u7528\u6307\u7eb9\u8bc6\u522b\u548c\u4e00\u81f4\u6027\u68c0\u67e5\u5feb\u901f\u5224\u65ad\u5b9e\u73b0\u662f\u5426\u5339\u914d\u73b0\u6709\u6a21\u578b\uff1b2) \u82e5\u65e0\u5339\u914d\uff0c\u5229\u7528\u73b0\u6709\u6a21\u578b\u7ed3\u6784\u5b66\u4e60\u65b0\u6a21\u578b\uff1b3) \u7ed3\u5408\u4e3b\u52a8\u81ea\u52a8\u673a\u5b66\u4e60\u4e0e\u95ed\u4e16\u754c\u6307\u7eb9\u8bc6\u522b\u3002", "result": "\u8bc1\u660e\u4e86\u65b9\u6cd5\u7684\u6b63\u786e\u6027\uff0c\u76f8\u6bd4\u6734\u7d20\u57fa\u7ebf\u5728\u6e10\u8fd1\u590d\u6742\u5ea6\u4e0a\u6709\u6539\u8fdb\u3002\u5b9e\u9a8c\u7ed3\u679c\u663e\u793a\u5728\u5404\u79cd\u534f\u8bae\u4e0a\u663e\u8457\u51cf\u5c11\u4e86\u8bef\u5206\u7c7b\u548c\u4e0e\u9ed1\u76d2\u7cfb\u7edf\u7684\u4ea4\u4e92\u6b21\u6570\u3002", "conclusion": "\u63d0\u51fa\u7684\u5f00\u653e\u4e16\u754c\u6307\u7eb9\u8bc6\u522b\u65b9\u6cd5\u6709\u6548\u89e3\u51b3\u4e86\u4f20\u7edf\u95ed\u4e16\u754c\u5047\u8bbe\u7684\u5c40\u9650\u6027\uff0c\u51cf\u5c11\u4e86\u8bef\u5206\u7c7b\uff0c\u63d0\u9ad8\u4e86\u5b9e\u9645\u5e94\u7528\u4e2d\u7684\u53ef\u884c\u6027\u3002"}}
{"id": "2601.21893", "categories": ["cs.CR"], "pdf": "https://arxiv.org/pdf/2601.21893", "abs": "https://arxiv.org/abs/2601.21893", "authors": ["Kangqiang Luo", "Yi Xie", "Shiqian Zhao", "Jing Pan"], "title": "WADBERT: Dual-channel Web Attack Detection Based on BERT Models", "comment": null, "summary": "Web attack detection is the first line of defense for securing web applications, designed to preemptively identify malicious activities. Deep learning-based approaches are increasingly popular for their advantages: automatically learning complex patterns and extracting semantic features from HTTP requests to achieve superior detection performance. However, existing methods are less effective in embedding irregular HTTP requests, even failing to model unordered parameters and achieve attack traceability. In this paper, we propose an effective web attack detection model, named WADBERT. It achieves high detection accuracy while enabling the precise identification of malicious parameters. To this end, we first employ Hybrid Granularity Embedding (HGE) to generate fine-grained embeddings for URL and payload parameters. Then, URLBERT and SecBERT are respectively utilized to extract their semantic features. Further, parameter-level features (extracted by SecBERT) are fused through a multi-head attention mechanism, resulting in a comprehensive payload feature. Finally, by feeding the concatenated URL and payload features into a linear classifier, a final detection result is obtained. The experimental results on CSIC2010 and SR-BH2020 datasets validate the efficacy of WADBERT, which respectively achieves F1-scores of 99.63% and 99.50%, and significantly outperforms state-of-the-art methods.", "AI": {"tldr": "WADBERT\u662f\u4e00\u4e2a\u57fa\u4e8e\u6df1\u5ea6\u5b66\u4e60\u7684Web\u653b\u51fb\u68c0\u6d4b\u6a21\u578b\uff0c\u901a\u8fc7\u6df7\u5408\u7c92\u5ea6\u5d4c\u5165\u548cBERT\u67b6\u6784\u5b9e\u73b0\u9ad8\u7cbe\u5ea6\u68c0\u6d4b\uff0c\u5e76\u80fd\u7cbe\u786e\u5b9a\u4f4d\u6076\u610f\u53c2\u6570\u3002", "motivation": "\u73b0\u6709\u57fa\u4e8e\u6df1\u5ea6\u5b66\u4e60\u7684Web\u653b\u51fb\u68c0\u6d4b\u65b9\u6cd5\u5728\u5904\u7406\u4e0d\u89c4\u5219HTTP\u8bf7\u6c42\u65f6\u6548\u679c\u4e0d\u4f73\uff0c\u96be\u4ee5\u5efa\u6a21\u65e0\u5e8f\u53c2\u6570\u548c\u5b9e\u73b0\u653b\u51fb\u6eaf\u6e90\u3002\u9700\u8981\u4e00\u79cd\u65e2\u80fd\u9ad8\u7cbe\u5ea6\u68c0\u6d4b\u653b\u51fb\uff0c\u53c8\u80fd\u7cbe\u786e\u5b9a\u4f4d\u6076\u610f\u53c2\u6570\u7684\u65b9\u6cd5\u3002", "method": "1. \u4f7f\u7528\u6df7\u5408\u7c92\u5ea6\u5d4c\u5165\uff08HGE\uff09\u4e3aURL\u548cpayload\u53c2\u6570\u751f\u6210\u7ec6\u7c92\u5ea6\u5d4c\u5165\uff1b2. \u5206\u522b\u4f7f\u7528URLBERT\u548cSecBERT\u63d0\u53d6\u8bed\u4e49\u7279\u5f81\uff1b3. \u901a\u8fc7\u591a\u5934\u6ce8\u610f\u529b\u673a\u5236\u878d\u5408\u53c2\u6570\u7ea7\u7279\u5f81\uff1b4. \u5c06\u62fc\u63a5\u7684URL\u548cpayload\u7279\u5f81\u8f93\u5165\u7ebf\u6027\u5206\u7c7b\u5668\u5f97\u5230\u6700\u7ec8\u68c0\u6d4b\u7ed3\u679c\u3002", "result": "\u5728CSIC2010\u548cSR-BH2020\u6570\u636e\u96c6\u4e0a\u5206\u522b\u8fbe\u523099.63%\u548c99.50%\u7684F1\u5206\u6570\uff0c\u663e\u8457\u4f18\u4e8e\u73b0\u6709\u6700\u5148\u8fdb\u65b9\u6cd5\u3002", "conclusion": "WADBERT\u6a21\u578b\u4e0d\u4ec5\u5b9e\u73b0\u4e86\u9ad8\u7cbe\u5ea6\u7684Web\u653b\u51fb\u68c0\u6d4b\uff0c\u8fd8\u80fd\u7cbe\u786e\u5b9a\u4f4d\u6076\u610f\u53c2\u6570\uff0c\u89e3\u51b3\u4e86\u73b0\u6709\u65b9\u6cd5\u5728\u5904\u7406\u4e0d\u89c4\u5219HTTP\u8bf7\u6c42\u548c\u653b\u51fb\u6eaf\u6e90\u65b9\u9762\u7684\u4e0d\u8db3\u3002"}}
{"id": "2601.21910", "categories": ["cs.CR"], "pdf": "https://arxiv.org/pdf/2601.21910", "abs": "https://arxiv.org/abs/2601.21910", "authors": ["Sofia Giampietro", "Ralf Sasse", "David Basin"], "title": "Beyond the Finite Variant Property: Extending Symbolic Diffie-Hellman Group Models (Extended Version)", "comment": "Extended version of conference paper", "summary": "Diffie-Hellman groups are commonly used in cryptographic protocols. While most state-of-the-art, symbolic protocol verifiers support them to some degree, they do not support all mathematical operations possible in these groups. In particular, they lack support for exponent addition, as these tools reason about terms using unification, which is undecidable in the theory describing all Diffie-Hellman operators. In this paper we approximate such a theory and propose a semi-decision procedure to determine whether a protocol, which may use all operations in such groups, satisfies user-defined properties. We implement this approach by extending the Tamarin prover to support the full Diffie-Hellman theory, including group element multiplication and hence addition of exponents. This is the first time a state-of-the-art tool can model and reason about such protocols. We illustrate our approach's effectiveness with different case studies: ElGamal encryption and MQV. Using Tamarin, we prove security properties of ElGamal, and we rediscover known attacks on MQV.", "AI": {"tldr": "\u8be5\u8bba\u6587\u6269\u5c55\u4e86Tamarin\u9a8c\u8bc1\u5668\u4ee5\u652f\u6301\u5b8c\u6574\u7684Diffie-Hellman\u7fa4\u7406\u8bba\uff0c\u5305\u62ec\u7fa4\u5143\u7d20\u4e58\u6cd5\u548c\u6307\u6570\u52a0\u6cd5\uff0c\u4f7f\u534f\u8bae\u9a8c\u8bc1\u5de5\u5177\u80fd\u591f\u5904\u7406\u4f7f\u7528\u6240\u6709DH\u64cd\u4f5c\u7684\u534f\u8bae\u3002", "motivation": "\u5f53\u524d\u7b26\u53f7\u534f\u8bae\u9a8c\u8bc1\u5668\u867d\u7136\u652f\u6301Diffie-Hellman\u7fa4\uff0c\u4f46\u7f3a\u4e4f\u5bf9\u6307\u6570\u52a0\u6cd5\u7b49\u6570\u5b66\u64cd\u4f5c\u7684\u652f\u6301\uff0c\u56e0\u4e3a\u8fd9\u4e9b\u5de5\u5177\u4f7f\u7528\u5408\u4e00\u63a8\u7406\uff0c\u800c\u5b8c\u6574DH\u7406\u8bba\u7684\u5408\u4e00\u662f\u4e0d\u53ef\u5224\u5b9a\u7684\u3002", "method": "\u63d0\u51fa\u4e86\u4e00\u79cd\u8fd1\u4f3c\u7406\u8bba\u5e76\u8bbe\u8ba1\u4e86\u534a\u51b3\u7b56\u8fc7\u7a0b\uff0c\u901a\u8fc7\u6269\u5c55Tamarin\u9a8c\u8bc1\u5668\u6765\u652f\u6301\u5b8c\u6574\u7684Diffie-Hellman\u7406\u8bba\uff0c\u5305\u62ec\u7fa4\u5143\u7d20\u4e58\u6cd5\u548c\u6307\u6570\u52a0\u6cd5\u3002", "result": "\u6210\u529f\u5b9e\u73b0\u4e86\u9996\u4e2a\u80fd\u591f\u5efa\u6a21\u548c\u63a8\u7406\u4f7f\u7528\u5b8c\u6574DH\u64cd\u4f5c\u534f\u8bae\u7684\u6700\u5148\u8fdb\u5de5\u5177\uff0c\u901a\u8fc7ElGamal\u52a0\u5bc6\u548cMQV\u6848\u4f8b\u7814\u7a76\u9a8c\u8bc1\u4e86\u65b9\u6cd5\u7684\u6709\u6548\u6027\u3002", "conclusion": "\u8be5\u7814\u7a76\u4f7f\u534f\u8bae\u9a8c\u8bc1\u5de5\u5177\u80fd\u591f\u5904\u7406\u66f4\u5e7f\u6cdb\u7684\u5bc6\u7801\u534f\u8bae\uff0c\u586b\u8865\u4e86\u73b0\u6709\u5de5\u5177\u5728\u652f\u6301\u5b8c\u6574DH\u64cd\u4f5c\u65b9\u9762\u7684\u7a7a\u767d\uff0c\u4e3a\u534f\u8bae\u5b89\u5168\u6027\u5206\u6790\u63d0\u4f9b\u4e86\u65b0\u80fd\u529b\u3002"}}
{"id": "2601.21966", "categories": ["cs.CR"], "pdf": "https://arxiv.org/pdf/2601.21966", "abs": "https://arxiv.org/abs/2601.21966", "authors": ["Sebastian N. Peters", "Lukas Lautenschlager", "David Emeis", "Jason Lochert"], "title": "Secure Group Key Agreement on Cyber-Physical System Buses", "comment": null, "summary": "Cyber-Physical Systems (CPSs) rely on distributed embedded devices that often must communicate securely over buses. Ensuring message integrity and authenticity on these buses typically requires group-shared keys for Message Authentication Codes (MACs). To avoid insecure fixed pre-shared keys and trust-on-first-use concepts, a Group Key Agreement (GKA) protocol is needed to dynamically agree on a key amongst the devices. Yet existing GKA protocols lack adaptability to constrained CPS buses. This paper targets authenticated, fully distributed GKA suitable for bus topologies under constraints of industrial and cyber-physical systems, including broadcast-only links, half-duplex operation, resource limits, dynamic membership (including unannounced leaves), a long device lifetime, and a strong Dolev-Yao adversary capable of partitioning the bus. We first systematise existing protocols, then derive the requirements necessary for an authenticated and fully distributed GKA on bus systems. Finally, we design, implement, and evaluate a custom GKA protocol based on TreeKEM.", "AI": {"tldr": "\u672c\u6587\u9488\u5bf9\u5de5\u4e1a\u4e0e\u4fe1\u606f\u7269\u7406\u7cfb\u7edf\u4e2d\u7684\u603b\u7ebf\u62d3\u6251\u7ed3\u6784\uff0c\u8bbe\u8ba1\u4e86\u4e00\u79cd\u9002\u7528\u4e8e\u53d7\u9650\u73af\u5883\u7684\u8ba4\u8bc1\u5f0f\u5b8c\u5168\u5206\u5e03\u5f0f\u7fa4\u7ec4\u5bc6\u94a5\u534f\u5546\u534f\u8bae\uff0c\u57fa\u4e8eTreeKEM\u5b9e\u73b0\uff0c\u89e3\u51b3\u4e86\u73b0\u6709\u534f\u8bae\u5728\u5e7f\u64ad\u94fe\u8def\u3001\u534a\u53cc\u5de5\u64cd\u4f5c\u7b49\u7ea6\u675f\u4e0b\u7684\u9002\u5e94\u6027\u95ee\u9898\u3002", "motivation": "\u4fe1\u606f\u7269\u7406\u7cfb\u7edf\u4f9d\u8d56\u5206\u5e03\u5f0f\u5d4c\u5165\u5f0f\u8bbe\u5907\u901a\u8fc7\u603b\u7ebf\u8fdb\u884c\u5b89\u5168\u901a\u4fe1\uff0c\u9700\u8981\u7fa4\u7ec4\u5171\u4eab\u5bc6\u94a5\u7528\u4e8e\u6d88\u606f\u8ba4\u8bc1\u7801\u3002\u4e3a\u907f\u514d\u4e0d\u5b89\u5168\u7684\u56fa\u5b9a\u9884\u5171\u4eab\u5bc6\u94a5\u548c\u9996\u6b21\u4f7f\u7528\u4fe1\u4efb\u673a\u5236\uff0c\u9700\u8981\u52a8\u6001\u534f\u5546\u7fa4\u7ec4\u5bc6\u94a5\u7684\u534f\u8bae\uff0c\u4f46\u73b0\u6709\u7fa4\u7ec4\u5bc6\u94a5\u534f\u5546\u534f\u8bae\u65e0\u6cd5\u9002\u5e94\u53d7\u9650\u7684\u4fe1\u606f\u7269\u7406\u7cfb\u7edf\u603b\u7ebf\u7ea6\u675f\u3002", "method": "\u9996\u5148\u7cfb\u7edf\u5316\u5206\u6790\u73b0\u6709\u534f\u8bae\uff0c\u7136\u540e\u63a8\u5bfc\u603b\u7ebf\u7cfb\u7edf\u4e0a\u8ba4\u8bc1\u5f0f\u5b8c\u5168\u5206\u5e03\u5f0f\u7fa4\u7ec4\u5bc6\u94a5\u534f\u5546\u7684\u9700\u6c42\uff0c\u6700\u540e\u57fa\u4e8eTreeKEM\u8bbe\u8ba1\u3001\u5b9e\u73b0\u5e76\u8bc4\u4f30\u5b9a\u5236\u5316\u7684\u7fa4\u7ec4\u5bc6\u94a5\u534f\u5546\u534f\u8bae\u3002", "result": "\u8bbe\u8ba1\u51fa\u9002\u7528\u4e8e\u603b\u7ebf\u62d3\u6251\u7684\u8ba4\u8bc1\u5f0f\u5b8c\u5168\u5206\u5e03\u5f0f\u7fa4\u7ec4\u5bc6\u94a5\u534f\u5546\u534f\u8bae\uff0c\u80fd\u591f\u5e94\u5bf9\u5de5\u4e1a\u4e0e\u4fe1\u606f\u7269\u7406\u7cfb\u7edf\u7684\u591a\u79cd\u7ea6\u675f\u6761\u4ef6\uff0c\u5305\u62ec\u5e7f\u64ad\u94fe\u8def\u3001\u534a\u53cc\u5de5\u64cd\u4f5c\u3001\u8d44\u6e90\u9650\u5236\u3001\u52a8\u6001\u6210\u5458\u53d8\u66f4\u3001\u957f\u8bbe\u5907\u5bff\u547d\u4ee5\u53ca\u80fd\u591f\u5206\u533a\u603b\u7ebf\u7684\u5f3aDolev-Yao\u654c\u624b\u3002", "conclusion": "\u901a\u8fc7\u57fa\u4e8eTreeKEM\u7684\u5b9a\u5236\u5316\u534f\u8bae\u8bbe\u8ba1\uff0c\u5b9e\u73b0\u4e86\u9002\u5408\u53d7\u9650\u603b\u7ebf\u73af\u5883\u7684\u8ba4\u8bc1\u5f0f\u5b8c\u5168\u5206\u5e03\u5f0f\u7fa4\u7ec4\u5bc6\u94a5\u534f\u5546\uff0c\u89e3\u51b3\u4e86\u73b0\u6709\u534f\u8bae\u5728\u4fe1\u606f\u7269\u7406\u7cfb\u7edf\u603b\u7ebf\u62d3\u6251\u4e2d\u7684\u9002\u5e94\u6027\u95ee\u9898\u3002"}}
{"id": "2601.22159", "categories": ["cs.CR", "cs.AI", "cs.CL"], "pdf": "https://arxiv.org/pdf/2601.22159", "abs": "https://arxiv.org/abs/2601.22159", "authors": ["Naufal Suryanto", "Muzammal Naseer", "Pengfei Li", "Syed Talal Wasim", "Jinhui Yi", "Juergen Gall", "Paolo Ceravolo", "Ernesto Damiani"], "title": "RedSage: A Cybersecurity Generalist LLM", "comment": "Accepted on ICLR 2026; Project page: https://risys-lab.github.io/RedSage/", "summary": "Cybersecurity operations demand assistant LLMs that support diverse workflows without exposing sensitive data. Existing solutions either rely on proprietary APIs with privacy risks or on open models lacking domain adaptation. To bridge this gap, we curate 11.8B tokens of cybersecurity-focused continual pretraining data via large-scale web filtering and manual collection of high-quality resources, spanning 28.6K documents across frameworks, offensive techniques, and security tools. Building on this, we design an agentic augmentation pipeline that simulates expert workflows to generate 266K multi-turn cybersecurity samples for supervised fine-tuning. Combined with general open-source LLM data, these resources enable the training of RedSage, an open-source, locally deployable cybersecurity assistant with domain-aware pretraining and post-training. To rigorously evaluate the models, we introduce RedSage-Bench, a benchmark with 30K multiple-choice and 240 open-ended Q&A items covering cybersecurity knowledge, skills, and tool expertise. RedSage is further evaluated on established cybersecurity benchmarks (e.g., CTI-Bench, CyberMetric, SECURE) and general LLM benchmarks to assess broader generalization. At the 8B scale, RedSage achieves consistently better results, surpassing the baseline models by up to +5.59 points on cybersecurity benchmarks and +5.05 points on Open LLM Leaderboard tasks. These findings demonstrate that domain-aware agentic augmentation and pre/post-training can not only enhance cybersecurity-specific expertise but also help to improve general reasoning and instruction-following. All models, datasets, and code are publicly available.", "AI": {"tldr": "RedSage\u662f\u4e00\u4e2a\u5f00\u6e90\u7684\u3001\u53ef\u672c\u5730\u90e8\u7f72\u7684\u7f51\u7edc\u5b89\u5168\u52a9\u624bLLM\uff0c\u901a\u8fc7\u9886\u57df\u611f\u77e5\u7684\u6301\u7eed\u9884\u8bad\u7ec3\u548c\u57fa\u4e8e\u4e13\u5bb6\u5de5\u4f5c\u6d41\u7a0b\u7684\u667a\u80fd\u589e\u5f3a\u5fae\u8c03\uff0c\u5728\u7f51\u7edc\u5b89\u5168\u4efb\u52a1\u4e0a\u663e\u8457\u8d85\u8d8a\u57fa\u7ebf\u6a21\u578b\uff0c\u540c\u65f6\u63d0\u5347\u901a\u7528\u63a8\u7406\u80fd\u529b\u3002", "motivation": "\u7f51\u7edc\u5b89\u5168\u64cd\u4f5c\u9700\u8981\u65e2\u80fd\u652f\u6301\u591a\u6837\u5316\u5de5\u4f5c\u6d41\u7a0b\u53c8\u4e0d\u66b4\u9732\u654f\u611f\u6570\u636e\u7684\u52a9\u624bLLM\u3002\u73b0\u6709\u89e3\u51b3\u65b9\u6848\u8981\u4e48\u4f9d\u8d56\u6709\u9690\u79c1\u98ce\u9669\u7684\u4e13\u6709API\uff0c\u8981\u4e48\u4f7f\u7528\u7f3a\u4e4f\u9886\u57df\u9002\u5e94\u7684\u5f00\u6e90\u6a21\u578b\uff0c\u9700\u8981\u586b\u8865\u8fd9\u4e00\u7a7a\u767d\u3002", "method": "1) \u901a\u8fc7\u5927\u89c4\u6a21\u7f51\u9875\u8fc7\u6ee4\u548c\u624b\u52a8\u6536\u96c6\u9ad8\u8d28\u91cf\u8d44\u6e90\uff0c\u6574\u740611.8B tokens\u7684\u7f51\u7edc\u5b89\u5168\u6301\u7eed\u9884\u8bad\u7ec3\u6570\u636e\uff1b2) \u8bbe\u8ba1\u667a\u80fd\u589e\u5f3a\u7ba1\u9053\uff0c\u6a21\u62df\u4e13\u5bb6\u5de5\u4f5c\u6d41\u7a0b\u751f\u6210266K\u591a\u8f6e\u7f51\u7edc\u5b89\u5168\u6837\u672c\u7528\u4e8e\u76d1\u7763\u5fae\u8c03\uff1b3) \u7ed3\u5408\u901a\u7528\u5f00\u6e90LLM\u6570\u636e\u8bad\u7ec3RedSage\u6a21\u578b\uff1b4) \u5f15\u5165RedSage-Bench\u57fa\u51c6\u8fdb\u884c\u8bc4\u4f30\u3002", "result": "\u57288B\u89c4\u6a21\u4e0a\uff0cRedSage\u5728\u7f51\u7edc\u5b89\u5168\u57fa\u51c6\u4e0a\u6bd4\u57fa\u7ebf\u6a21\u578b\u63d0\u5347\u9ad8\u8fbe+5.59\u5206\uff0c\u5728Open LLM Leaderboard\u4efb\u52a1\u4e0a\u63d0\u5347+5.05\u5206\u3002\u6a21\u578b\u5728CTI-Bench\u3001CyberMetric\u3001SECURE\u7b49\u57fa\u51c6\u4e0a\u4e5f\u8868\u73b0\u4f18\u5f02\u3002", "conclusion": "\u9886\u57df\u611f\u77e5\u7684\u667a\u80fd\u589e\u5f3a\u548c\u9884/\u540e\u8bad\u7ec3\u4e0d\u4ec5\u80fd\u589e\u5f3a\u7f51\u7edc\u5b89\u5168\u4e13\u4e1a\u77e5\u8bc6\uff0c\u8fd8\u80fd\u6539\u5584\u901a\u7528\u63a8\u7406\u548c\u6307\u4ee4\u8ddf\u968f\u80fd\u529b\u3002\u6240\u6709\u6a21\u578b\u3001\u6570\u636e\u96c6\u548c\u4ee3\u7801\u5747\u5df2\u516c\u5f00\u3002"}}
