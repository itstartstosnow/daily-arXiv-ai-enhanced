<div id=toc></div>

# Table of Contents

- [cs.CR](#cs.CR) [Total: 11]


<div id='cs.CR'></div>

# cs.CR [[Back]](#toc)

### [1] [Secrecy and Verifiability: An Introduction to Electronic Voting](https://arxiv.org/abs/2602.12398)
*Paul Keeler,Ben Smyth*

Main category: cs.CR

TL;DR: 这篇教程论文向非电子投票领域的读者介绍了电子投票系统的基本概念，重点阐述了如何通过现代密码学工具实现投票保密性和可验证性这两个看似矛盾但至关重要的属性。


<details>
  <summary>Details</summary>
Motivation: 电子投票系统旨在替代传统的纸质投票，但现有方案存在各种缺陷。作者认为任何电子投票系统都需要两个基本属性：投票保密性和可验证性。然而这两个属性看似相互矛盾——完全黑盒系统能保证保密性但无法验证结果。本文旨在通过现代密码学工具解决这一矛盾，使非专业读者也能理解这些概念。

Method: 论文采用教程形式，首先介绍非对称加密和同态加密等基本密码学概念，用最小化的数学形式描述通用电子选举方案。然后概述基于博弈的密码学这一现代密码学标准方法，引入将选举形式化为博弈的符号表示。最后在基于博弈的密码学框架内给出投票保密性和可验证性的精确定义。

Result: 论文成功构建了一个教学框架，使非电子投票领域的读者能够理解现代电子投票研究的基本概念和方法。通过将复杂的密码学概念简化为可理解的形式，展示了如何利用现代密码学工具在保证投票保密性的同时实现结果的可验证性。

Conclusion: 电子投票系统需要在保密性和可验证性之间取得平衡，现代密码学提供了实现这一平衡的工具。通过基于博弈的密码学框架，可以形式化地定义和验证电子投票系统的安全性属性。本文为读者提供了理解现代电子投票研究方法的入门途径。

Abstract: Democracies are built upon secure and reliable voting systems. Electronic voting systems seek to replace ballot papers and boxes with computer hardware and software. Proposed electronic election schemes have been subjected to scrutiny, with researchers spotting inherent faults and weaknesses. Inspired by physical voting systems, we argue that any electronic voting system needs two essential properties: ballot secrecy and verifiability. These properties seemingly work against each other. An election scheme that is a complete black box offers ballot secrecy, but verification of the outcome is impossible. This challenge can be tackled using standard tools from modern cryptography, reaching a balance that delivers both properties.
  This tutorial makes these ideas accessible to readers outside electronic voting. We introduce fundamental concepts such as asymmetric and homomorphic encryption, which we use to describe a general electronic election scheme while keeping mathematical formalism minimal. We outline game-based cryptography, a standard approach in modern cryptography, and introduce notation for formulating elections as games. We then give precise definitions of ballot secrecy and verifiability in the framework of game-based cryptography. A principal aim is introducing modern research approaches to electronic voting.

</details>


### [2] [Sparse Autoencoders are Capable LLM Jailbreak Mitigators](https://arxiv.org/abs/2602.12418)
*Yannick Assogba,Jacopo Cortellazzi,Javier Abad,Pau Rodriguez,Xavier Suau,Arno Blaas*

Main category: cs.CR

TL;DR: CC-Delta是一种基于稀疏自编码器的防御方法，通过比较有害请求在有/无越狱上下文时的token级表示来识别越狱相关稀疏特征，并在推理时进行均值漂移引导，有效提升模型安全性。


<details>
  <summary>Details</summary>
Motivation: 越狱攻击持续威胁大语言模型安全，现有防御方法存在局限性。作者希望利用稀疏自编码器（SAE）的可解释性特征，开发一种无需任务特定训练的实际越狱防御方法。

Method: 提出上下文条件化Delta引导（CC-Delta）：1）使用配对的有害/越狱提示，通过统计测试选择越狱相关稀疏特征；2）在SAE潜在空间中进行推理时均值漂移引导；3）利用现成的SAE，无需特定任务训练。

Result: 在4个对齐指令调优模型和12种越狱攻击上测试，CC-Delta在安全-效用权衡方面达到或优于在密集潜在空间操作的基线防御方法。特别是在所有模型上都明显优于密集均值漂移引导，对分布外攻击效果尤其显著。

Conclusion: 稀疏SAE特征空间引导比密集激活空间引导在越狱缓解方面具有优势，现成的SAE可重新用作实际越狱防御，无需任务特定训练。

Abstract: Jailbreak attacks remain a persistent threat to large language model safety. We propose Context-Conditioned Delta Steering (CC-Delta), an SAE-based defense that identifies jailbreak-relevant sparse features by comparing token-level representations of the same harmful request with and without jailbreak context. Using paired harmful/jailbreak prompts, CC-Delta selects features via statistical testing and applies inference-time mean-shift steering in SAE latent space. Across four aligned instruction-tuned models and twelve jailbreak attacks, CC-Delta achieves comparable or better safety-utility tradeoffs than baseline defenses operating in dense latent space. In particular, our method clearly outperforms dense mean-shift steering on all four models, and particularly against out-of-distribution attacks, showing that steering in sparse SAE feature space offers advantages over steering in dense activation space for jailbreak mitigation. Our results suggest off-the-shelf SAEs trained for interpretability can be repurposed as practical jailbreak defenses without task-specific training.

</details>


### [3] [DRAMatic Speedup: Accelerating HE Operations on a Processing-in-Memory System](https://arxiv.org/abs/2602.12433)
*Niklas Klinger,Jonas Sander,Peterson Yuhala,Pascal Felber,Thomas Eisenbarth*

Main category: cs.CR

TL;DR: DRAMatic在UPMEM PIM系统上实现同态加密基础操作，通过算术优化显著缩小了与Microsoft SEAL的性能差距，但受限于乘法性能和数据传输开销。


<details>
  <summary>Details</summary>
Motivation: 同态加密（HE）是机密云计算的有前景技术，但计算成本高且在传统架构上受内存限制。内存内处理（PIM）架构具有更高内存带宽，可能适合加速HE。

Method: 在UPMEM的可编程通用PIM系统上实现DRAMatic，采用余数系统和数论变换等算术优化技术，支持安全同态评估所需的大参数。

Result: DRAMatic显著缩小了UPMEM PIM与Microsoft SEAL之间的性能差距，但受限于UPMEM PIM的乘法性能和数据传输开销。

Conclusion: PIM架构有潜力加速同态加密，但需要硬件扩展来改善乘法性能和减少数据传输开销。

Abstract: Homomorphic encryption (HE) is a promising technology for confidential cloud computing, as it allows computations on encrypted data. However, HE is computationally expensive and often memory-bound on conventional computer architectures. Processing-in-Memory (PIM) is an alternative hardware architecture that integrates processing units and memory on the same chip or memory module. PIM enables higher memory bandwidth than conventional architectures and could thus be suitable for accelerating HE. In this work, we present DRAMatic, which implements operations foundational to HE on UPMEM's programmable, general-purpose PIM system, and evaluate its performance. DRAMatic incorporates many arithmetic optimizations, including residue number system and number-theoretic transform techniques, and can support the large parameters required for secure homomorphic evaluations. To compare performance, we evaluate DRAMatic against Microsoft SEAL, a popular open-source HE library, regarding both runtime and energy efficiency. The results show that DRAMatic significantly closes the gap between UPMEM PIM and Microsoft SEAL. However, we also show that DRAMatic is currently constrained by UPMEM PIM's multiplication performance and data transfer overhead. Finally, we discuss potential hardware extensions to UPMEM PIM.

</details>


### [4] [RADAR: Exposing Unlogged NoSQL Operations](https://arxiv.org/abs/2602.12600)
*Mahfuzul I. Nissan,James Wagner*

Main category: cs.CR

TL;DR: RADAR是一个日志对抗感知的取证框架，通过交叉比对低级存储痕迹和高级应用日志来获取取证真相，在10种NoSQL数据库上验证有效。


<details>
  <summary>Details</summary>
Motivation: NoSQL数据库的广泛采用使得数字取证变得困难，因为存储格式多样且不透明，当特权内部人员可以禁用、抑制或操纵日志时，审计日志不可信。

Method: RADAR框架使用ANOC从原始磁盘字节推断布局并提取记录，绕过数据库API和管理系统，然后将提取的痕迹与审计日志进行比对，识别未记录的插入、静默删除和字段级更新等差异痕迹。

Result: 在10种NoSQL引擎上评估，包括BerkeleyDB、LMDB、MDBX等，涵盖键值存储和文档存储，在日志规避场景下，RADAR始终能暴露未归属的操作，同时保持31.7-397 MB/min的处理吞吐量。

Conclusion: RADAR证明了不依赖日志的可信NoSQL取证的可行性，能够检测特权内部人员试图通过操纵日志来隐藏的活动。

Abstract: The widespread adoption of NoSQL databases has made digital forensics increasingly difficult as storage formats are diverse and often opaque, and audit logs cannot be assumed trustworthy when privileged insiders, such as DevOps or administrators, can disable, suppress, or manipulate logging to conceal activity. We present RADAR (Record & Artifact Detection, Alignment & Reporting), a log-adversary-aware framework that derives forensic ground truth by cross-referencing low-level storage artifacts against high-level application logs. RADAR analyzes artifacts reconstructed by the Automated NoSQL Carver (ANOC), which infers layouts and carves records directly from raw disk bytes, bypassing database APIs and the management system entirely, thereby treating physical storage as the independent evidence source. RADAR then reconciles carved artifacts with the audit log to identify delta artifacts such as unlogged insertions, silent deletions, and field-level updates that exist on disk but are absent from the logical history. We evaluate RADAR across ten NoSQL engines, including BerkeleyDB, LMDB, MDBX, etcd, ZODB, Durus, LiteDB, Realm, RavenDB, and NitriteDB, spanning key-value and document stores and multiple storage designs, e.g., copy-on-write/MVCC, B/B+ tree, and append-only. Under log-evasion scenarios, such as log suppression and post-maintenance attacks, including cases where historical bytes are pruned, RADAR consistently exposes unattributed operations while sustaining 31.7-397 MB/min processing throughput, demonstrating the feasibility of log-independent, trustworthy NoSQL forensics.

</details>


### [5] [TensorCommitments: A Lightweight Verifiable Inference for Language Models](https://arxiv.org/abs/2602.12630)
*Oguzhan Baser,Elahe Sadeghi,Eric Wang,David Ribeiro Alves,Sam Kazemian,Hong Kang,Sandeep P. Chinchali,Sriram Vishwanath*

Main category: cs.CR

TL;DR: TensorCommitments (TCs) 是一种用于验证大语言模型推理正确性的方案，通过张量承诺和多元Terkle树结构，在几乎不影响推理速度的情况下提供可验证性。


<details>
  <summary>Details</summary>
Motivation: 当前大多数LLM在外部云上运行，用户需要信任远程GPU正确执行推理而不被篡改。现有密码学方法在大规模LLM上太慢，而非密码学方法需要强大的验证者GPU。需要一种高效的可验证推理方案。

Method: 提出TensorCommitments (TCs)，一种张量原生的推理证明方案。TC将LLM推理绑定到一个承诺上，这是一个不可逆的标签，如果被篡改就会失效。使用多元Terkle树组织承诺结构。

Result: 对于LLaMA2模型，TC仅增加0.97%的证明者时间和0.12%的验证者时间，同时针对定制化LLM攻击的鲁棒性比之前最佳方案（需要验证者GPU）提高了48%。

Conclusion: TensorCommitments提供了一种高效、轻量级的可验证LLM推理方案，在几乎不影响性能的情况下显著提高了安全性和可验证性。

Abstract: Most large language models (LLMs) run on external clouds: users send a prompt, pay for inference, and must trust that the remote GPU executes the LLM without any adversarial tampering. We critically ask how to achieve verifiable LLM inference, where a prover (the service) must convince a verifier (the client) that an inference was run correctly without rerunning the LLM. Existing cryptographic works are too slow at the LLM scale, while non-cryptographic ones require a strong verifier GPU. We propose TensorCommitments (TCs), a tensor-native proof-of-inference scheme. TC binds the LLM inference to a commitment, an irreversible tag that breaks under tampering, organized in our multivariate Terkle Trees. For LLaMA2, TC adds only 0.97% prover and 0.12% verifier time over inference while improving robustness to tailored LLM attacks by up to 48% over the best prior work requiring a verifier GPU.

</details>


### [6] [Fool Me If You Can: On the Robustness of Binary Code Similarity Detection Models against Semantics-preserving Transformations](https://arxiv.org/abs/2602.12681)
*Jiyong Uhm,Minseok Kim,Michalis Polychronakis,Hyungjoon Koo*

Main category: cs.CR

TL;DR: 该论文提出了asmFooler系统，用于评估二进制代码相似性检测模型在语义保持变换下的鲁棒性，发现模型对对抗性代码变换脆弱，且微小扰动即可有效误导模型决策。


<details>
  <summary>Details</summary>
Motivation: 尽管深度学习在二进制代码分析中展现出潜力，但现有模型对二进制级别的对抗性代码变换的鲁棒性研究不足。二进制指令的特殊性使其与常规输入扰动不同，需要专门评估模型在语义保持变换下的脆弱性。

Method: 提出asmFooler系统，使用八种语义保持变换生成对抗性二进制变体，构建包含9,565个变体的数据集，在六个代表性BCSD模型上进行评估，分析模型处理流程、变换预算和扰动效果。

Result: 发现：1) 模型鲁棒性依赖于代码预处理、架构和特征选择；2) 对抗变换效果受模型特定约束（如输入大小和指令表达能力）形成的预算限制；3) 精心设计的变换只需最小扰动即可高效；4) 通过针对语义重要指令的变换可有效误导模型决策。

Conclusion: 二进制代码相似性检测模型对语义保持的对抗性变换脆弱，需要改进模型鲁棒性。asmFooler为评估和增强BCSD模型安全性提供了系统化框架，揭示了二进制分析中对抗性攻击的独特挑战。

Abstract: Binary code analysis plays an essential role in cybersecurity, facilitating reverse engineering to reveal the inner workings of programs in the absence of source code. Traditional approaches, such as static and dynamic analysis, extract valuable insights from stripped binaries, but often demand substantial expertise and manual effort. Recent advances in deep learning have opened promising opportunities to enhance binary analysis by capturing latent features and disclosing underlying code semantics. Despite the growing number of binary analysis models based on machine learning, their robustness to adversarial code transformations at the binary level remains underexplored. We evaluate the robustness of deep learning models for the task of binary code similarity detection (BCSD) under semantics-preserving transformations. The unique nature of machine instructions presents distinct challenges compared to the typical input perturbations found in other domains. We introduce asmFooler, a system that evaluates the resilience of BCSD models using a diverse set of adversarial code transformations that preserve functional semantics. We construct a dataset of 9,565 binary variants from 620 baseline samples by applying eight semantics-preserving transformations across six representative BCSD models. Our major findings highlight several key insights: i) model robustness relies on the processing pipeline, including code pre-processing, architecture, and feature selection; ii) adversarial transformation effectiveness is bounded by a budget shaped by model-specific constraints like input size and instruction expressive capacity; iii) well-crafted transformations can be highly effective with minimal perturbations; and iv) such transformations efficiently disrupt model decisions (e.g., misleading to false positives or false negatives) by focusing on semantically significant instructions.

</details>


### [7] [Reliable Hierarchical Operating System Fingerprinting via Conformal Prediction](https://arxiv.org/abs/2602.12825)
*Rubén Pérez-Jove,Osvaldo Simeone,Alejandro Pazos,Jose Vázquez-Naya*

Main category: cs.CR

TL;DR: 本文提出两种结构化共形预测方法（L-CP和P-CP）用于操作系统指纹识别，在保证覆盖率的同时解决了传统方法忽略OS分类层次结构的问题。


<details>
  <summary>Details</summary>
Motivation: 传统操作系统指纹识别方法缺乏形式化的不确定性量化机制，且将OS识别视为扁平分类问题，忽略了OS的自然分类层次结构，导致预测结果脆弱。

Method: 提出了两种结构化共形预测策略：1) 层级独立校准的L-CP方法；2) 通过向上投影确保结构一致性的P-CP方法。两种方法都利用共形预测为预测集提供覆盖率保证。

Result: 两种方法都满足有效性保证，但揭示了层级效率与结构一致性之间的权衡：L-CP产生更紧凑的预测集但存在分类不一致性；P-CP保证层次一致性的嵌套集但粗粒度层级效率较低。

Conclusion: 结构化共形预测方法为操作系统指纹识别提供了形式化的不确定性量化，L-CP适合人工取证分析，P-CP适合自动化策略执行，两者在效率与一致性间存在权衡。

Abstract: Operating System (OS) fingerprinting is critical for network security, but conventional methods do not provide formal uncertainty quantification mechanisms. Conformal Prediction (CP) could be directly wrapped around existing methods to obtain prediction sets with guaranteed coverage. However, a direct application of CP would treat OS identification as a flat classification problem, ignoring the natural taxonomic structure of OSs and providing brittle point predictions. This work addresses these limitations by introducing and evaluating two distinct structured CP strategies: level-wise CP (L-CP), which calibrates each hierarchy level independently, and projection-based CP (P-CP), which ensures structural consistency by projecting leaf-level sets upwards. Our results demonstrate that, while both methods satisfy validity guarantees, they expose a fundamental trade-off between level-wise efficiency and structural consistency. L-CP yields tighter prediction sets suitable for human forensic analysis but suffers from taxonomic inconsistencies. Conversely, P-CP guarantees hierarchically consistent, nested sets ideal for automated policy enforcement, albeit at the cost of reduced efficiency at coarser levels.

</details>


### [8] [Neighborhood Blending: A Lightweight Inference-Time Defense Against Membership Inference Attacks](https://arxiv.org/abs/2602.12943)
*Osama Zafar,Shaojie Zhan,Tianxi Ji,Erman Ayday*

Main category: cs.CR

TL;DR: 提出Neighborhood Blending方法，在推理时通过差分隐私采样选择相似训练样本平滑模型置信度输出，有效防御成员推理攻击，同时保持高模型效用和零标签损失。


<details>
  <summary>Details</summary>
Motivation: MLaaS在敏感环境中的广泛应用引发隐私担忧，特别是成员推理攻击(MIAs)通过利用训练数据与非训练数据的行为差异判断特定记录是否在训练集中，现有防御方法如对抗正则化、DP-SGD、MemGuard等存在效用损失、计算开销大或保护不一致等权衡问题。

Method: 提出Neighborhood Blending推理时防御机制：1) 后训练操作，无需重新训练模型；2) 基于查询样本的邻域平滑模型置信度输出；3) 使用差分隐私采样选择相似训练样本进行预测平均；4) 建立一致的置信度模式，使成员和非成员对攻击者不可区分；5) 采用自适应"按需付费"失真策略保持高效用。

Result: 通过多个数据集和模型的广泛实验表明：1) 显著降低MIA成功率；2) 保持模型性能；3) 在效用保持方面优于MemGuard等后处理防御和DP-SGD等训练时技术；4) 保持标签完整性(零标签损失)；5) 提供实用轻量级解决方案。

Conclusion: Neighborhood Blending是一种模型无关的推理时防御方法，通过差分隐私采样和邻域混合有效缓解成员推理攻击，在保持高模型效用的同时增强隐私保护，相比现有方法具有更好的实用性和性能平衡。

Abstract: In recent years, the widespread adoption of Machine Learning as a Service (MLaaS), particularly in sensitive environments, has raised considerable privacy concerns. Of particular importance are membership inference attacks (MIAs), which exploit behavioral discrepancies between training and non-training data to determine whether a specific record was included in the model's training set, thereby presenting significant privacy risks. Although existing defenses, such as adversarial regularization, DP-SGD, and MemGuard, assist in mitigating these threats, they often entail trade-offs such as compromising utility, increased computational requirements, or inconsistent protection against diverse attack vectors.
  In this paper, we introduce a novel inference-time defense mechanism called Neighborhood Blending, which mitigates MIAs without retraining the model or incurring significant computational overhead. Our approach operates post-training by smoothing the model's confidence outputs based on the neighborhood of a queried sample. By averaging predictions from similar training samples selected using differentially private sampling, our method establishes a consistent confidence pattern, rendering members and non-members indistinguishable to an adversary while maintaining high utility. Significantly, Neighborhood Blending maintains label integrity (zero label loss) and ensures high utility through an adaptive, "pay-as-you-go" distortion strategy. It is a model-agnostic approach that offers a practical, lightweight solution that enhances privacy without sacrificing model utility. Through extensive experiments across diverse datasets and models, we demonstrate that our defense significantly reduces MIA success rates while preserving model performance, outperforming existing post-hoc defenses like MemGuard and training-time techniques like DP-SGD in terms of utility retention.

</details>


### [9] [Cryptographic Choreographies](https://arxiv.org/abs/2602.12967)
*Sebastian Mödersheim,Simon Lund,Alessandro Bruni,Marco Carbone,Rosario Giustolisi*

Main category: cs.CR

TL;DR: CryptoChoreo是一种用于规范密码协议编排的语言，扩展了Alice-and-Bob表示法，支持非确定性选择、条件分支和可变长期记忆，通过翻译到进程演算定义语义，并与ProVerif连接实现实际可行性验证。


<details>
  <summary>Details</summary>
Motivation: 传统密码协议规范通常孤立指定每个协议角色，缺乏对协议整体的直观高层视图。Alice-and-Bob表示法虽然直观但表达能力有限，需要扩展以支持更复杂的协议特性。

Method: 提出CryptoChoreo编排语言，扩展Alice-and-Bob表示法，添加非确定性选择、条件分支和可变长期记忆。通过翻译到进程演算定义形式语义，实现与ProVerif的连接，并在代表性代数理论下提供实现。

Result: 成功定义了CryptoChoreo的形式语义，解决了在任意代数理论和非确定性选择下代理如何解析、检查传入消息和构造传出消息的问题。通过多个案例研究表明该方法在实际中是可行的。

Conclusion: CryptoChoreo为密码协议规范提供了直观的高层视图，扩展了传统表示法的表达能力，通过形式语义和与ProVerif的连接实现了实际可行性验证，为复杂密码协议的分析提供了有效工具。

Abstract: We present CryptoChoreo, a choreography language for the specification of cryptographic protocols. Choreographies can be regarded as an extension of Alice-and-Bob notation, providing an intuitive high-level view of the protocol as a whole (rather than specifying each protocol role in isolation). The extensions over standard Alice-and-Bob notation that we consider are non-deterministic choice, conditional branching, and mutable long-term memory. We define the semantics of CryptoChoreo by translation to a process calculus. This semantics entails an understanding of the protocol: it determines how agents parse and check incoming messages and how they construct outgoing messages, in the presence of an arbitrary algebraic theory and non-deterministic choices made by other agents. While this semantics entails algebraic problems that are in general undecidable, we give an implementation for a representative theory. We connect this translation to ProVerif and show on a number of case studies that the approach is practically feasible.

</details>


### [10] [TrustMee: Self-Verifying Remote Attestation Evidence](https://arxiv.org/abs/2602.13148)
*Parsa Sadri Sinaki,Zainab Ahmad,Wentao Xie,Merlijn Sebrechts,Jimmy Kjällman,Lachlan J. Gunn*

Main category: cs.CR

TL;DR: 论文提出自验证远程证明证据概念，将证据验证转化为标准代码签名问题，无需平台特定知识


<details>
  <summary>Details</summary>
Motivation: 硬件安全远程证明对建立机密虚拟机完整性信任至关重要，但实际使用困难，因为验证证明证据需要硬件特定加密逻辑，增加了维护成本和验证者的可信计算基

Method: 引入自验证远程证明证据概念，每个证明包包含由可信方签名的WebAssembly组件作为验证逻辑，将证据验证转化为标准代码签名问题

Result: 实现TrustMee平台无关验证驱动程序，支持AMD SEV-SNP和Intel TDX证明的自验证证据，生成标准EAT证明结果格式

Conclusion: 自验证远程证明证据方法使验证者无需平台特定知识即可验证证明证据，降低了维护成本和可信计算基要求

Abstract: Hardware-secured remote attestation is essential to establishing trust in the integrity of confidential virtual machines (cVMs), but is difficult to use in practice because verifying attestation evidence requires the use of hardware-specific cryptographic logic. This increases both maintenance costs and the verifiers' trusted computing base. We introduce the concept of self-verifying remote attestation evidence. Each attestation bundle includes verification logic as a WebAssembly component signed by a trusted party. This approach transforms evidence verification into a standard code-signing problem: the verifier checks the signature on the embedded logic and then executes it to validate the evidence. As a result, verifiers can validate attestation evidence without any platform-specific knowledge. We implement this concept as TrustMee, a platform-agnostic verification driver for the Trustee framework. We demonstrate its functionality with self-verifying evidence for AMD SEV-SNP and Intel TDX attestations, producing attestation claims in the standard EAT Attestation Result (EAR) format.

</details>


### [11] [In-Context Autonomous Network Incident Response: An End-to-End Large Language Model Agent Approach](https://arxiv.org/abs/2602.13156)
*Yiran Gao,Kim Hammar,Tao Li*

Main category: cs.CR

TL;DR: 提出基于大型语言模型（LLM）的端到端自主事件响应代理，通过感知、推理、规划和行动四个功能集成，无需手动建模模拟器，在商品硬件上实现快速恢复。


<details>
  <summary>Details</summary>
Motivation: 现有基于强化学习的事件响应系统需要手动建模模拟器，且抑制了原始系统日志和警报中的有用语义信息，无法快速适应不断演变的网络攻击。

Method: 利用LLM预训练的安全知识和上下文学习能力，构建轻量级LLM代理（14B模型），通过微调和思维链推理，集成感知、推理、规划和行动四个功能，实现端到端的事件响应规划。

Result: 在文献报道的事件日志评估中，该代理比前沿LLM实现恢复速度快23%，且无需建模，可在商品硬件上运行。

Conclusion: 基于LLM的代理方法为自主事件响应提供了无建模的端到端解决方案，能够有效处理原始系统日志，通过上下文学习适应不断变化的网络威胁。

Abstract: Rapidly evolving cyberattacks demand incident response systems that can autonomously learn and adapt to changing threats. Prior work has extensively explored the reinforcement learning approach, which involves learning response strategies through extensive simulation of the incident. While this approach can be effective, it requires handcrafted modeling of the simulator and suppresses useful semantics from raw system logs and alerts. To address these limitations, we propose to leverage large language models' (LLM) pre-trained security knowledge and in-context learning to create an end-to-end agentic solution for incident response planning. Specifically, our agent integrates four functionalities, perception, reasoning, planning, and action, into one lightweight LLM (14b model). Through fine-tuning and chain-of-thought reasoning, our LLM agent is capable of processing system logs and inferring the underlying network state (perception), updating its conjecture of attack models (reasoning), simulating consequences under different response strategies (planning), and generating an effective response (action). By comparing LLM-simulated outcomes with actual observations, the LLM agent repeatedly refines its attack conjecture and corresponding response, thereby demonstrating in-context adaptation. Our agentic approach is free of modeling and can run on commodity hardware. When evaluated on incident logs reported in the literature, our agent achieves recovery up to 23% faster than those of frontier LLMs.

</details>
