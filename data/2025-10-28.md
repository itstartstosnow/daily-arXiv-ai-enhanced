<div id=toc></div>

# Table of Contents

- [cs.CR](#cs.CR) [Total: 37]


<div id='cs.CR'></div>

# cs.CR [[Back]](#toc)

### [1] [$δ$-STEAL: LLM Stealing Attack with Local Differential Privacy](https://arxiv.org/abs/2510.21946)
*Kieu Dang,Phung Lai,NhatHai Phan,Yelong Shen,Ruoming Jin,Abdallah Khreishah*

Main category: cs.CR

TL;DR: 提出了一种名为δ-STEAL的新型模型窃取攻击方法，通过在对手模型的token嵌入中注入满足局部差分隐私(LDP)保证的噪声，能够绕过服务提供商的水印检测器，同时保持对手模型的实用性。


<details>
  <summary>Details</summary>
Motivation: 大型语言模型(LLMs)的部署带来了知识产权风险，特别是模型窃取攻击。水印解决方案虽然能提供模型可追溯性和知识产权验证，但现有攻击方法容易被检测。需要开发能够绕过水印检测的模型窃取方法。

Method: δ-STEAL攻击方法：1) 对手查询服务提供商的模型收集输出，形成输入-输出训练对；2) 在对手模型微调过程中，对token嵌入注入满足LDP保证的噪声；3) 通过LDP保护噪声模糊水印信号，使服务提供商难以确定其输出是否被使用。

Result: 实验显示，δ-STEAL经过轻量级修改后攻击成功率高达96.95%，且不会显著损害对手模型的实用性。LDP中的噪声规模控制攻击效果与模型实用性之间的权衡。

Conclusion: δ-STEAL攻击对现有知识产权保护方法构成重大风险，即使强大的水印也能被绕过，使对手能够欺骗水印检测器，削弱当前的知识产权保护机制。

Abstract: Large language models (LLMs) demonstrate remarkable capabilities across
various tasks. However, their deployment introduces significant risks related
to intellectual property. In this context, we focus on model stealing attacks,
where adversaries replicate the behaviors of these models to steal services.
These attacks are highly relevant to proprietary LLMs and pose serious threats
to revenue and financial stability. To mitigate these risks, the watermarking
solution embeds imperceptible patterns in LLM outputs, enabling model
traceability and intellectual property verification. In this paper, we study
the vulnerability of LLM service providers by introducing $\delta$-STEAL, a
novel model stealing attack that bypasses the service provider's watermark
detectors while preserving the adversary's model utility. $\delta$-STEAL
injects noise into the token embeddings of the adversary's model during
fine-tuning in a way that satisfies local differential privacy (LDP)
guarantees. The adversary queries the service provider's model to collect
outputs and form input-output training pairs. By applying LDP-preserving noise
to these pairs, $\delta$-STEAL obfuscates watermark signals, making it
difficult for the service provider to determine whether its outputs were used,
thereby preventing claims of model theft. Our experiments show that
$\delta$-STEAL with lightweight modifications achieves attack success rates of
up to $96.95\%$ without significantly compromising the adversary's model
utility. The noise scale in LDP controls the trade-off between attack
effectiveness and model utility. This poses a significant risk, as even robust
watermarks can be bypassed, allowing adversaries to deceive watermark detectors
and undermine current intellectual property protection methods.

</details>


### [2] [Towards Low-Latency and Adaptive Ransomware Detection Using Contrastive Learning](https://arxiv.org/abs/2510.21957)
*Zhixin Pan,Ziyu Shu,Amberbir Alemayoh*

Main category: cs.CR

TL;DR: 提出结合自监督对比学习和神经架构搜索的勒索软件检测框架，使用硬件性能计数器分析运行时行为，实现早期检测和自适应架构。


<details>
  <summary>Details</summary>
Motivation: 传统勒索软件检测方法面临特征依赖、响应延迟和适应性不足三大挑战，AI方法也存在类似局限。

Method: 1) 基于HPC的对比学习框架分析运行时行为；2) 定制损失函数实现早期检测；3) NAS自动构建自适应模型架构。

Result: 检测准确率提升16.1%，响应时间加快6倍，在规避攻击下保持鲁棒性。

Conclusion: 该框架有效解决了勒索软件检测的关键挑战，在准确性和响应速度上显著优于现有方法。

Abstract: Ransomware has become a critical threat to cybersecurity due to its rapid
evolution, the necessity for early detection, and growing diversity, posing
significant challenges to traditional detection methods. While AI-based
approaches had been proposed by prior works to assist ransomware detection,
existing methods suffer from three major limitations, ad-hoc feature
dependencies, delayed response, and limited adaptability to unseen variants. In
this paper, we propose a framework that integrates self-supervised contrastive
learning with neural architecture search (NAS) to address these challenges.
Specifically, this paper offers three important contributions. (1) We design a
contrastive learning framework that incorporates hardware performance counters
(HPC) to analyze the runtime behavior of target ransomware. (2) We introduce a
customized loss function that encourages early-stage detection of malicious
activity, and significantly reduces the detection latency. (3) We deploy a
neural architecture search (NAS) framework to automatically construct adaptive
model architectures, allowing the detector to flexibly align with unseen
ransomware variants. Experimental results show that our proposed method
achieves significant improvements in both detection accuracy (up to 16.1%) and
response time (up to 6x) compared to existing approaches while maintaining
robustness under evasive attacks.

</details>


### [3] [Security Analysis of LTE Connectivity in Connected Cars: A Case Study of Tesla](https://arxiv.org/abs/2510.22024)
*Evangelos Bitsikas,Jason Veara,Aanjhan Ranganathan*

Main category: cs.CR

TL;DR: 对特斯拉车辆LTE连接的安全分析揭示了系统性的协议弱点和架构配置错误，包括IMSI捕获、伪基站劫持和不安全的回退机制，这些漏洞挑战了汽车网络安全监管框架的核心假设。


<details>
  <summary>Details</summary>
Motivation: 虽然移动网络漏洞在智能手机生态系统中已有充分记录，但在安全关键的汽车环境中其影响尚未得到充分研究。现代联网车辆依赖持久LTE连接实现远程诊断、OTA更新和关键安全服务，需要评估这些连接在汽车环境中的安全性。

Method: 采用黑盒、非侵入式安全分析方法，对特斯拉车辆（包括Model 3和Cybertruck）的LTE连接进行测试，重点关注协议弱点和架构配置问题。

Result: 发现特斯拉的远程信息处理堆栈易受IMSI捕获、伪基站劫持和不安全回退机制的攻击，可能导致服务可用性静默降级。此外，遗留的控制平面配置允许静默SMS注入和广播消息欺骗，且驾驶员无法察觉。

Conclusion: 这些漏洞不仅影响单个供应商，还挑战了ISO/SAE 21434和UN R155/R156等监管框架的核心假设，这些框架要求现代车辆的类型认证必须具备安全、可追踪和有弹性的远程信息处理能力。

Abstract: Modern connected vehicles rely on persistent LTE connectivity to enable
remote diagnostics, over-the-air (OTA) updates, and critical safety services.
While mobile network vulnerabilities are well documented in the smartphone
ecosystem, their impact in safety-critical automotive settings remains
insufficiently examined. In this work, we conduct a black-box, non-invasive
security analysis of LTE connectivity in Tesla vehicles, including the Model 3
and Cybertruck, revealing systemic protocol weaknesses and architectural
misconfigurations. We find that Tesla's telematics stack is susceptible to IMSI
catching, rogue base station hijacking, and insecure fallback mechanisms that
may silently degrade service availability. Furthermore, legacy control-plane
configurations allow for silent SMS injection and broadcast message spoofing
without driver awareness. These vulnerabilities have implications beyond a
single vendor as they challenge core assumptions in regulatory frameworks like
ISO/SAE 21434 and UN R155/R156, which require secure, traceable, and resilient
telematics for type approval of modern vehicles.

</details>


### [4] [Jailbreak Mimicry: Automated Discovery of Narrative-Based Jailbreaks for Large Language Models](https://arxiv.org/abs/2510.22085)
*Pavlos Ntais*

Main category: cs.CR

TL;DR: 提出Jailbreak Mimicry方法，通过参数高效微调训练小型攻击模型，自动生成基于叙事的越狱提示，在GPT-OSS-20B上实现81.0%攻击成功率，比直接提示提升54倍。


<details>
  <summary>Details</summary>
Motivation: 大型语言模型容易受到复杂提示工程攻击，利用上下文框架绕过安全机制，对网络安全应用构成重大风险。

Method: 使用参数高效微调(LoRA)在Mistral-7B上，基于AdvBench的精选数据集训练攻击模型，实现一次性自动生成叙事型越狱提示。

Result: 在GPT-OSS-20B测试集上达到81.0%攻击成功率，跨模型评估显示GPT-4为66.5%、Llama-3为79.5%、Gemini 2.5 Flash为33.0%。技术领域(网络安全:93%)和欺骗攻击(欺诈:87.8%)最脆弱。

Conclusion: 当前安全对齐方法存在系统性漏洞，技术领域和欺骗类攻击特别易受攻击，需开发防御策略来缓解AI网络安全中的这些漏洞。

Abstract: Large language models (LLMs) remain vulnerable to sophisticated prompt
engineering attacks that exploit contextual framing to bypass safety
mechanisms, posing significant risks in cybersecurity applications. We
introduce Jailbreak Mimicry, a systematic methodology for training compact
attacker models to automatically generate narrative-based jailbreak prompts in
a one-shot manner. Our approach transforms adversarial prompt discovery from
manual craftsmanship into a reproducible scientific process, enabling proactive
vulnerability assessment in AI-driven security systems. Developed for the
OpenAI GPT-OSS-20B Red-Teaming Challenge, we use parameter-efficient
fine-tuning (LoRA) on Mistral-7B with a curated dataset derived from AdvBench,
achieving an 81.0% Attack Success Rate (ASR) against GPT-OSS-20B on a held-out
test set of 200 items. Cross-model evaluation reveals significant variation in
vulnerability patterns: our attacks achieve 66.5% ASR against GPT-4, 79.5% on
Llama-3 and 33.0% against Gemini 2.5 Flash, demonstrating both broad
applicability and model-specific defensive strengths in cybersecurity contexts.
This represents a 54x improvement over direct prompting (1.5% ASR) and
demonstrates systematic vulnerabilities in current safety alignment approaches.
Our analysis reveals that technical domains (Cybersecurity: 93% ASR) and
deception-based attacks (Fraud: 87.8% ASR) are particularly vulnerable,
highlighting threats to AI-integrated threat detection, malware analysis, and
secure systems, while physical harm categories show greater resistance (55.6%
ASR). We employ automated harmfulness evaluation using Claude Sonnet 4,
cross-validated with human expert assessment, ensuring reliable and scalable
evaluation for cybersecurity red-teaming. Finally, we analyze failure
mechanisms and discuss defensive strategies to mitigate these vulnerabilities
in AI for cybersecurity.

</details>


### [5] [Lightweight and Breach-Resilient Authenticated Encryption Framework for Internet of Things](https://arxiv.org/abs/2510.22100)
*Saif E. Nouma,Attila A. Yavuz*

Main category: cs.CR

TL;DR: 提出了Graphene，首个对称前向安全和聚合认证加密框架，专为低端物联网设备设计，结合密钥演进策略和离线-在线加密处理，提供突破恢复能力、近最优在线延迟和紧凑性。


<details>
  <summary>Details</summary>
Motivation: 当前物联网中部署的轻量级认证加密标准缺乏关键特性，如密钥泄露恢复能力和紧凑认证标签，以及性能增强如离线-在线加密。需要为资源受限的物联网设备设计更安全高效的解决方案。

Method: 结合密钥演进策略和离线-在线加密处理与通用消息认证码(UMACs)，开发了前向安全和聚合认证加密框架。通过两种不同的实例化展示效率，每种都在性能权衡与可扩展性之间取得平衡。

Result: 在商用硬件和32位ARM Cortex-M4微控制器上的实验评估显示，Graphene相比现有方案有显著性能提升，同时保持与标准兼容加密实现的向后兼容性。

Conclusion: Graphene为低端物联网基础设施提供了突破恢复能力、近最优在线延迟和紧凑性的安全解决方案，已作为开源实现发布供公共测试和适配。

Abstract: The Internet of Things (IoT) relies heavily on resource-limited devices to
communicate critical (e.g., military data) information under low-energy
adversarial environments and low-latency wireless channels. Authenticated
Encryption (AE) guarantees confidentiality, authenticity, and integrity, making
it a vital security service for IoT. However, current deployed (lightweight) AE
standards lack essential features like key compromise resiliency and compact
authentication tags, as well as performance enhancements such as offline-online
cryptography. To address these gaps, we propose Graphene, the first (to our
knowledge) symmetric Forward-secure and Aggregate Authenticated Encryption
(FAAE) framework designed for the performance and security demands of low-end
IoT infrastructures. Graphene innovates by synergizing key evolution strategies
and offline-online cryptographic processing with Universal Message
Authentication Codes (UMACs) to guarantee breach-resiliency, near-optimal
online latency, and compactness. We demonstrate Graphene efficiency through two
distinct instantiations, each balancing unique performance trade-offs with
extensibility for diverse MACs. Our experimental evaluation on commodity
hardware and 32-bit ARM Cortex-M4 microcontroller shows Graphene significant
performance gains over existing alternatives. Graphene is also backward
compatible with standard-compliant cryptographic implementations. We release
our implementation as open source for public testing and adaptation.

</details>


### [6] [TPPR: APT Tactic / Technique Pattern Guided Attack Path Reasoning for Attack Investigation](https://arxiv.org/abs/2510.22191)
*Qi Sheng*

Main category: cs.CR

TL;DR: 提出了TPPR框架，通过异常节点检测、TTP标注和图剪枝提取异常子图，使用挖掘的TTP序列模式进行攻击路径推理，最后通过基于置信度的路径评分和合并重建攻击场景。


<details>
  <summary>Details</summary>
Motivation: 现有的溯源图路径推理技术无法建立有效的攻击上下文关联，往往将良性系统操作与真实攻击实体混淆，无法准确表征真实APT行为。

Method: TPPR框架：1) 异常节点检测、TTP标注和图剪枝提取异常子图；2) 使用挖掘的TTP序列模式进行攻击路径推理；3) 基于置信度的路径评分和合并重建攻击场景。

Result: 在真实企业日志（超过1亿事件）和DARPA TC数据集上的评估显示，TPPR实现了99.9%的图简化（70万到20条边），同时保留了91%的关键攻击节点，在重建精度上比现有最佳解决方案（SPARSE、DepImpact）分别高出63.1%和67.9%。

Conclusion: TPPR框架能够有效识别和重建APT攻击场景，在保持攻击场景完整性的同时显著提高推理精度和效率。

Abstract: Provenance analysis based on system audit data has emerged as a fundamental
approach for investigating Advanced Persistent Threat (APT) attacks. Due to the
high concealment and long-term persistence of APT attacks, they are only
represented as a minimal part of the critical path in the provenance graph.
While existing techniques employ behavioral pattern matching and data flow
feature matching to uncover latent associations in attack sequences through
provenance graph path reasoning, their inability to establish effective attack
context associations often leads to the conflation of benign system operations
with real attack entities, that fail to accurately characterize real APT
behaviors. We observe that while the causality of entities in the provenance
graph exhibit substantial complexity, attackers often follow specific attack
patterns-specifically, clear combinations of tactics and techniques to achieve
their goals. Based on these insights, we propose TPPR, a novel framework that
first extracts anomaly subgraphs through abnormal node detection,
TTP-annotation and graph pruning, then performs attack path reasoning using
mined TTP sequential pattern, and finally reconstructs attack scenarios through
confidence-based path scoring and merging. Extensive evaluation on real
enterprise logs (more than 100 million events) and DARPA TC dataset
demonstrates TPPR's capability to achieve 99.9% graph simplification (700,000
to 20 edges) while preserving 91% of critical attack nodes, outperforming
state-of-the-art solutions (SPARSE, DepImpact) by 63.1% and 67.9% in
reconstruction precision while maintaining attack scenario integrity.

</details>


### [7] [SecureLearn -- An Attack-agnostic Defense for Multiclass Machine Learning Against Data Poisoning Attacks](https://arxiv.org/abs/2510.22274)
*Anum Paracha,Junaid Arshad,Mohamed Ben Farah,Khalid Ismail*

Main category: cs.CR

TL;DR: SecureLearn是一个两层的攻击不可知防御框架，用于保护多分类模型免受数据投毒攻击，包含数据净化和特征导向对抗训练两个组件。


<details>
  <summary>Details</summary>
Motivation: 现有防御主要针对特定投毒攻击或特定ML算法，且多集中于深度神经网络或二分类器，而传统多分类器在多模态应用中很重要但缺乏安全保护。

Method: 提出SecureLearn防御框架，包含数据净化和新的特征导向对抗训练两个组件，采用3D评估矩阵进行有效性验证。

Result: SecureLearn在10%-20%投毒水平下保持90%以上准确率，75%以上召回率和F1分数，对神经网络达到97%的召回率和F1分数。

Conclusion: SecureLearn有效增强了传统多分类模型和神经网络的抗攻击能力和对抗鲁棒性，证明了其在算法特定防御之外的泛化能力。

Abstract: Data poisoning attacks are a potential threat to machine learning (ML)
models, aiming to manipulate training datasets to disrupt their performance.
Existing defenses are mostly designed to mitigate specific poisoning attacks or
are aligned with particular ML algorithms. Furthermore, most defenses are
developed to secure deep neural networks or binary classifiers. However,
traditional multiclass classifiers need attention to be secure from data
poisoning attacks, as these models are significant in developing multi-modal
applications. Therefore, this paper proposes SecureLearn, a two-layer
attack-agnostic defense to defend multiclass models from poisoning attacks. It
comprises two components of data sanitization and a new feature-oriented
adversarial training. To ascertain the effectiveness of SecureLearn, we
proposed a 3D evaluation matrix with three orthogonal dimensions: data
poisoning attack, data sanitization and adversarial training. Benchmarking
SecureLearn in a 3D matrix, a detailed analysis is conducted at different
poisoning levels (10%-20%), particularly analysing accuracy, recall, F1-score,
detection and correction rates, and false discovery rate. The experimentation
is conducted for four ML algorithms, namely Random Forest (RF), Decision Tree
(DT), Gaussian Naive Bayes (GNB) and Multilayer Perceptron (MLP), trained with
three public datasets, against three poisoning attacks and compared with two
existing mitigations. Our results highlight that SecureLearn is effective
against the provided attacks. SecureLearn has strengthened resilience and
adversarial robustness of traditional multiclass models and neural networks,
confirming its generalization beyond algorithm-specific defenses. It
consistently maintained accuracy above 90%, recall and F1-score above 75%. For
neural networks, SecureLearn achieved 97% recall and F1-score against all
selected poisoning attacks.

</details>


### [8] [Adapting Noise-Driven PUF and AI for Secure WBG ICS: A Proof-of-Concept Study](https://arxiv.org/abs/2510.22283)
*Devon A. Kelly,Christiana Chamon*

Main category: cs.CR

TL;DR: 该研究提出了一种利用宽禁带技术开关噪声作为物理不可克隆函数源和实时威胁指示器的双重用途安全框架，结合机器学习实现工业控制系统的硬件级认证和异常检测。


<details>
  <summary>Details</summary>
Motivation: 宽禁带技术虽然提升了电力系统效率，但也带来了独特的传感器损坏和网络安全风险，特别是在高频噪声和复杂网络物理威胁方面。需要开发能够适应这种严苛环境的安全解决方案。

Method: 通过提取宽禁带开关噪声（高达100kHz）作为PUF熵源，同时利用该噪声作为实时威胁指示器，结合混合机器学习模型和自适应贝叶斯滤波，实现硬件级认证和异常检测。

Result: 在良性场景和攻击场景（包括EMI注入、信号篡改和节点冒充）的详细模拟中，实现了95%的检测准确率和亚毫秒级的处理延迟。

Conclusion: 证明了物理驱动的双重用途噪声利用作为可扩展ICS防御原语的可行性，为利用固有设备特性、连接硬件和人工智能的下一代安全策略奠定了基础。

Abstract: Wide-bandgap (WBG) technologies offer unprecedented improvements in power
system efficiency, size, and performance, but also introduce unique sensor
corruption and cybersecurity risks in industrial control systems (ICS),
particularly due to high-frequency noise and sophisticated cyber-physical
threats. This proof-of-concept (PoC) study demonstrates the adaptation of a
noise-driven physically unclonable function (PUF) and machine learning
(ML)-assisted anomaly detection framework to the demanding environment of
WBG-based ICS sensor pathways. By extracting entropy from unavoidable WBG
switching noise (up to 100 kHz) as a PUF source, and simultaneously using this
noise as a real-time threat indicator, the proposed system unites
hardware-level authentication and anomaly detection. Our approach integrates
hybrid machine learning (ML) models with adaptive Bayesian filtering, providing
robust and low-latency detection capabilities resilient to both natural
electromagnetic interference (EMI) and active adversarial manipulation. Through
detailed simulations of WBG modules under benign and attack
scenarios--including EMI injection, signal tampering, and node
impersonation--we achieve 95% detection accuracy and sub-millisecond processing
latency. These results demonstrate the feasibility of physics-driven, dual-use
noise exploitation as a scalable ICS defense primitive. Our findings lay the
groundwork for next-generation security strategies that leverage inherent
device characteristics, bridging hardware and artificial intelligence (AI) for
enhanced protection of critical ICS infrastructure.

</details>


### [9] [T2I-RiskyPrompt: A Benchmark for Safety Evaluation, Attack, and Defense on Text-to-Image Model](https://arxiv.org/abs/2510.22300)
*Chenyu Zhang,Tairen Zhang,Lanjun Wang,Ruidong Chen,Wenhui Li,Anan Liu*

Main category: cs.CR

TL;DR: 提出了T2I-RiskyPrompt基准，包含6,432个有效风险提示，采用分层风险分类法（6个主类别和14个子类别），并基于此评估了8个T2I模型、9种防御方法、5个安全过滤器和5种攻击策略。


<details>
  <summary>Details</summary>
Motivation: 现有风险提示数据集存在三个主要局限：风险类别有限、标注粒度粗糙、有效性低，需要更全面的基准来评估文本到图像模型的安全性。

Method: 开发了分层风险分类法，构建了收集和标注风险提示的流程，提出了基于原因的风险图像检测方法，将MLLM与安全标注对齐。

Result: 获得了6,432个有效风险提示，每个提示都有分层类别标签和详细风险原因。评估揭示了T2I模型安全性的9个关键见解。

Conclusion: T2I-RiskyPrompt为评估T2I模型安全性提供了全面基准，并讨论了其在多个研究领域的潜在应用价值。

Abstract: Using risky text prompts, such as pornography and violent prompts, to test
the safety of text-to-image (T2I) models is a critical task. However, existing
risky prompt datasets are limited in three key areas: 1) limited risky
categories, 2) coarse-grained annotation, and 3) low effectiveness. To address
these limitations, we introduce T2I-RiskyPrompt, a comprehensive benchmark
designed for evaluating safety-related tasks in T2I models. Specifically, we
first develop a hierarchical risk taxonomy, which consists of 6 primary
categories and 14 fine-grained subcategories. Building upon this taxonomy, we
construct a pipeline to collect and annotate risky prompts. Finally, we obtain
6,432 effective risky prompts, where each prompt is annotated with both
hierarchical category labels and detailed risk reasons. Moreover, to facilitate
the evaluation, we propose a reason-driven risky image detection method that
explicitly aligns the MLLM with safety annotations. Based on T2I-RiskyPrompt,
we conduct a comprehensive evaluation of eight T2I models, nine defense
methods, five safety filters, and five attack strategies, offering nine key
insights into the strengths and limitations of T2I model safety. Finally, we
discuss potential applications of T2I-RiskyPrompt across various research
fields. The dataset and code are provided in
https://github.com/datar001/T2I-RiskyPrompt.

</details>


### [10] [Privacy-Aware Federated nnU-Net for ECG Page Digitization](https://arxiv.org/abs/2510.22387)
*Nader Nemati*

Main category: cs.CR

TL;DR: 提出了一种跨机构的联邦学习框架，用于将ECG页面图像转换为可分析波形，在保护隐私的同时实现高效训练。


<details>
  <summary>Details</summary>
Motivation: 集中式训练与跨机构隐私和部署约束存在冲突，需要一种能在保护数据隐私的前提下进行模型训练的方法。

Method: 使用nnU-Net分割主干进行全模型联邦训练，集成FedAvg、FedProx和FedAdam三种聚合器，结合安全聚合和中心差分隐私保护。

Result: 在PTB-XL数据集上，FedAdam相比FedAvg和FedProx收敛更快且达到更高性能，接近集中式训练效果，同时保持隐私保护。

Conclusion: 该框架在保护原始图像和客户端更新隐私的同时，实现了可部署、可审计的多机构ECG数字化解决方案。

Abstract: Deep neural networks can convert ECG page images into analyzable waveforms,
yet centralized training often conflicts with cross-institutional privacy and
deployment constraints. A cross-silo federated digitization framework is
presented that trains a full-model nnU-Net segmentation backbone without
sharing images and aggregates updates across sites under realistic non-IID
heterogeneity (layout, grid style, scanner profile, noise).
  The protocol integrates three standard server-side aggregators--FedAvg,
FedProx, and FedAdam--and couples secure aggregation with central, user-level
differential privacy to align utility with formal guarantees. Key features
include: (i) end-to-end full-model training and synchronization across clients;
(ii) secure aggregation so the server only observes a clipped, weighted sum
once a participation threshold is met; (iii) central Gaussian DP with Renyi
accounting applied post-aggregation for auditable user-level privacy; and (iv)
a calibration-aware digitization pipeline comprising page normalization, trace
segmentation, grid-leakage suppression, and vectorization to twelve-lead
signals.
  Experiments on ECG pages rendered from PTB-XL show consistently faster
convergence and higher late-round plateaus with adaptive server updates
(FedAdam) relative to FedAvg and FedProx, while approaching centralized
performance. The privacy mechanism maintains competitive accuracy while
preventing exposure of raw images or per-client updates, yielding deployable,
auditable guarantees suitable for multi-institution settings.

</details>


### [11] [PortGPT: Towards Automated Backporting Using Large Language Models](https://arxiv.org/abs/2510.22396)
*Zhaoyang Li,Zheng Yu,Jingyi Song,Meng Xu,Yuxuan Luo,Dongliang Mu*

Main category: cs.CR

TL;DR: PORTGPT是一个基于LLM的智能代理，用于自动化补丁回移植过程，通过工具访问代码、总结Git历史并自主修订补丁，在真实场景中实现了高成功率的补丁回移植。


<details>
  <summary>Details</summary>
Motivation: 手动回移植补丁工作量大，现有自动化方法依赖预定义规则，对复杂补丁缺乏灵活性。

Method: PORTGPT增强LLM能力，使其能够按需访问代码、总结Git历史，并根据编译器反馈自主修订补丁，模拟人类推理和验证过程。

Result: 在现有数据集上达到89.15%成功率（1815个案例），在复杂案例数据集上达到62.33%成功率（146个案例），均优于现有最佳回移植工具。向Linux内核社区贡献了9个回移植补丁并全部被合并。

Conclusion: PORTGPT证明了LLM代理在复杂软件维护任务中的有效性，能够自动化处理真实世界的补丁回移植工作。

Abstract: Patch backporting, the process of migrating mainline security patches to
older branches, is an essential task in maintaining popular open-source
projects (e.g., Linux kernel). However, manual backporting can be
labor-intensive, while existing automated methods, which heavily rely on
predefined syntax or semantic rules, often lack agility for complex patches.
  In this paper, we introduce PORTGPT, an LLM-agent for end-to-end automation
of patch backporting in real-world scenarios. PORTGPT enhances an LLM with
tools to access code on-demand, summarize Git history, and revise patches
autonomously based on feedback (e.g., from compilers), hence, simulating
human-like reasoning and verification. PORTGPT achieved an 89.15% success rate
on existing datasets (1815 cases), and 62.33% on our own dataset of 146 complex
cases, both outperforms state-of-the-art of backporting tools. We contributed 9
backported patches from PORTGPT to the Linux kernel community and all patches
are now merged.

</details>


### [12] [ProGQL: A Provenance Graph Query System for Cyber Attack Investigation](https://arxiv.org/abs/2510.22400)
*Fei Shao,Jia Zou,Zhichao Cao,Xusheng Xiao*

Main category: cs.CR

TL;DR: 提出了PROGQL框架，这是一个用于网络攻击溯源分析的图查询语言和引擎，解决了现有溯源分析技术灵活性不足和内存效率低的问题。


<details>
  <summary>Details</summary>
Motivation: 现有溯源分析技术存在两个关键挑战：(1) 不灵活且不可扩展，难以融入分析专家知识；(2) 内存效率低，通常需要>100GB内存来存储完整事件流，限制了实际环境中的可扩展性和部署。

Method: 提出了PROGQL框架，包括一个领域特定的图搜索语言和优化的查询引擎。引入了约束图遍历、边权重计算、加权边值传播和图合并等新语言构造。查询引擎针对异构数据库后端的高效增量图搜索进行了优化。

Result: 在真实攻击上的评估表明，PROGQL语言在表达复杂攻击方面比最先进的图查询语言Cypher更有效，与最先进的PA技术DEPIMPACT相比，PROGQL框架的设计显著提高了可扩展性。

Conclusion: PROGQL框架通过提供灵活的图查询语言和内存高效的查询引擎，有效解决了现有溯源分析技术的局限性，为复杂网络攻击调查提供了有力支持。

Abstract: Provenance analysis (PA) has recently emerged as an important solution for
cyber attack investigation. PA leverages system monitoring to monitor system
activities as a series of system audit events and organizes these events as a
provenance graph to show the dependencies among system activities, which can
reveal steps of cyber attacks. Despite their potential, existing PA techniques
face two critical challenges: (1) they are inflexible and non-extensible,
making it difficult to incorporate analyst expertise, and (2) they are memory
inefficient, often requiring>100GB of RAM to hold entire event streams, which
fundamentally limits scalability and deployment in real-world environments. To
address these limitations, we propose the PROGQL framework, which provides a
domain-specific graph search language with a well-engineered query engine,
allowing PA over system audit events and expert knowledge to be jointly
expressed as a graph search query and thereby facilitating the investigation of
complex cyberattacks. In particular, to support dependency searches from a
starting edge required in PA, PROGQL introduces new language constructs for
constrained graph traversal, edge weight computation, value propagation along
weighted edges, and graph merging to integrate multiple searches. Moreover, the
PROGQL query engine is optimized for efficient incremental graph search across
heterogeneous database backends, eliminating the need for full in-memory
materialization and reducing memory overhead. Our evaluations on real attacks
demonstrate the effectiveness of the PROGQL language in expressing a diverse
set of complex attacks compared with the state-of-the-art graph query language
Cypher, and the comparison with the SOTA PA technique DEPIMPACT further
demonstrates the significant improvement of the scalability brought by our
PROGQL framework's design.

</details>


### [13] [ZK Coprocessor Bridge: Replay-Safe Private Execution from Solana to Aztec via Wormhole](https://arxiv.org/abs/2510.22536)
*Jotaro Yano*

Main category: cs.CR

TL;DR: 该论文提出了一个跨域的ZK协处理器桥接系统，允许Solana程序通过Wormhole VAAs在Aztec L2上请求私有执行，包含Solana程序、EVM门户、Aztec合约和链下中继器四个组件。


<details>
  <summary>Details</summary>
Motivation: 构建一个安全的跨域系统，使Solana程序能够通过以太坊在Aztec L2上执行私有计算，同时确保消息认证、重放安全和隐私保护。

Method: 使用Wormhole VAAs作为认证传输机制，包含四个主要组件：Solana程序发布消息、EVM门户验证VAAs、Aztec合约消费私有消息、链下中继器传输VAAs。

Result: 设计了状态机、消息格式，并提供了重放安全、来源认证、最终性对齐、参数绑定、隐私、幂等性和活跃性的证明草图。

Conclusion: 成功构建了一个可复现的跨域ZK协处理器桥接系统，支持Solana到Aztec的私有执行请求，并提供了完整的迁移指南和测试网运行验证。

Abstract: We formalize a cross-domain "ZK coprocessor bridge" that lets Solana programs
request private execution on Aztec L2 (via Ethereum) using Wormhole Verifiable
Action Approvals (VAAs) as authenticated transport. The system comprises: (i) a
Solana program that posts messages to Wormhole Core with explicit finality;
(ii) an EVM Portal that verifies VAAs, enforces a replay lock, parses a bound
payload secretHash||m from the attested VAA, derives a domain-separated field
commitment, and enqueues an L1->L2 message into the Aztec Inbox (our reference
implementation v0.1.0 currently uses consumeWithSecret(vaa, secretHash); we
provide migration guidance to the payload-bound interface); (iii) a minimal
Aztec contract that consumes the message privately; and (iv) an off-chain
relayer that ferries VAAs and can record receipts on Solana. We present state
machines, message formats, and proof sketches for replay-safety, origin
authenticity, finality alignment, parameter binding (no relayer front-running
of Aztec parameters), privacy, idempotence, and liveness. Finally, we include a
concise Reproducibility note with pinned versions and artifacts to replicate a
public testnet run.

</details>


### [14] [Cross-Paradigm Graph Backdoor Attacks with Promptable Subgraph Triggers](https://arxiv.org/abs/2510.22555)
*Dongyi Liu,Jiangtong Li,Dawei Cheng,Changjun Jiang*

Main category: cs.CR

TL;DR: 提出CP-GBA方法，使用图提示学习训练通用子图触发器，实现跨图学习范式的可迁移后门攻击


<details>
  <summary>Details</summary>
Motivation: 现有图神经网络后门攻击方法触发器结构简单、依赖特定特征，仅适用于单一图学习范式，在其他范式中迁移性差

Method: 使用图提示学习训练通用子图触发器，通过类感知、特征丰富性和结构保真度约束，构建可查询的触发器库

Result: 在多个真实数据集和防御场景下，CP-GBA实现了最先进的攻击成功率

Conclusion: CP-GBA方法通过图提示学习训练通用触发器，有效解决了图后门攻击的跨范式迁移性问题

Abstract: Graph Neural Networks(GNNs) are vulnerable to backdoor attacks, where
adversaries implant malicious triggers to manipulate model predictions.
  Existing trigger generators are often simplistic in structure and overly
reliant on specific features, confining them to a single graph learning
paradigm, such as graph supervised learning, graph contrastive learning, or
graph prompt learning.
  This specialized design, which aligns the trigger with one learning
objective, results in poor transferability when applied to other learning
paradigms.
  For instance, triggers generated for the graph supervised learning paradigm
perform poorly when tested within graph contrastive learning or graph prompt
learning environments.
  Furthermore, these simple generators often fail to utilize complex structural
information or node diversity within the graph data.
  These constraints limit the attack success rates of such methods in general
testing scenarios.
  Therefore, to address these limitations, we propose Cross-Paradigm Graph
Backdoor Attacks with Promptable Subgraph Triggers(CP-GBA), a new transferable
graph backdoor attack that employs graph prompt learning(GPL) to train a set of
universal subgraph triggers.
  First, we distill a compact yet expressive trigger set from target graphs,
which is structured as a queryable repository, by jointly enforcing
class-awareness, feature richness, and structural fidelity.
  Second, we conduct the first exploration of the theoretical transferability
of GPL to train these triggers under prompt-based objectives, enabling
effective generalization to diverse and unseen test-time paradigms.
  Extensive experiments across multiple real-world datasets and defense
scenarios show that CP-GBA achieves state-of-the-art attack success rates.

</details>


### [15] [Blockchain Signatures to Ensure Information Integrity and Non-Repudiation in the Digital Era: A comprehensive study](https://arxiv.org/abs/2510.22561)
*Kaveri Banerjee,Sajal Saha*

Main category: cs.CR

TL;DR: 该论文综述了区块链系统中使用的数字签名方案，分析了它们如何提供不可否认性并增强系统安全性，比较了不同签名方案在共识协议、智能合约约束和资源限制下的适用性。


<details>
  <summary>Details</summary>
Motivation: 区块链系统依赖去中心化账本和强安全保证，其中不可否认性是防止交易作者否认和支持数据完整性的关键要求。

Method: 通过检查代表性签名方案家族及其密码学基础、安全假设和相关属性（如不可伪造性、抗延展性、聚合支持等），使用标准比较不同设计在区块链环境中的适用性。

Result: 研究强调了不同签名方案在吞吐量、存储、可扩展性和攻击面方面的实际权衡，总结了每种方案在区块链环境中的优势和局限性。

Conclusion: 精心选择的数字签名对于实现不可否认性和保持信息完整性至关重要，研究还概述了实施考虑因素和开放方向，如互操作性和后量子准备。

Abstract: Blockchain systems rely on decentralized ledgers and strong security
guarantees. A key requirement is non-repudiation, which prevents denial of
transaction authorship and supports integrity of recorded data. This work
surveys digital signature schemes used in blockchain platforms and analyzes how
they deliver non-repudiation and contribute to overall system security. We
examine representative scheme families and their cryptographic foundations,
security assumptions, and properties relevant to deployment, including
unforgeability, resistance to malleability, support for aggregation and
multisignature or threshold settings, key and signature sizes, and verification
cost. Using these criteria, we compare the suitability of different designs for
consensus protocols, smart contract constraints, and resource limits. We
highlight practical tradeoffs that affect throughput, storage, scalability, and
attack surfaces, and summarize benefits and limitations of each scheme in
blockchain contexts. The study underscores that carefully chosen digital
signatures are central to achieving non-repudiation and preserving information
integrity, and it outlines implementation considerations and open directions
such as interoperability and post-quantum readiness.

</details>


### [16] [FAARM: Firmware Attestation and Authentication Framework for Mali GPUs](https://arxiv.org/abs/2510.22566)
*Md. Mehedi Hasan*

Main category: cs.CR

TL;DR: FAARM是一个轻量级固件认证和验证框架，通过数字签名验证防止GPU TEE中的恶意固件注入攻击，在启动时验证固件完整性并锁定固件区域，仅产生1.34ms的延迟开销。


<details>
  <summary>Details</summary>
Motivation: 针对MOLE攻击暴露的GPU可信执行环境固件级信任缺口，需要解决固件初始化阶段缺乏加密验证的问题，防止恶意固件注入导致的数据泄露和推理结果篡改。

Method: 在EL3安全监控器中集成数字签名验证，使用供应商签名的固件包和设备内公钥锚点，在启动时验证固件完整性和真实性，强制执行版本检查并锁定固件区域。

Result: FAARM可靠地检测并阻止恶意固件注入，在验证阶段拒绝篡改的镜像，并在认证后阻止覆盖尝试，平均固件验证延迟仅为1.34ms。

Conclusion: FAARM填补了基于shim的GPU TEE的基本安全缺口，为移动和云GPU部署提供了实用且可部署的防御方案，显著提升了安全基线。

Abstract: Recent work has revealed MOLE, the first practical attack to compromise GPU
Trusted Execution Environments (TEEs), by injecting malicious firmware into the
embedded Microcontroller Unit (MCU) of Arm Mali GPUs. By exploiting the absence
of cryptographic verification during initialization, adversaries with kernel
privileges can bypass memory protections, exfiltrate sensitive data at over 40
MB/s, and tamper with inference results, all with negligible runtime overhead.
This attack surface affects commodity mobile SoCs and cloud accelerators,
exposing a critical firmware-level trust gap in existing GPU TEE designs. To
address this gap, this paper presents FAARM, a lightweight Firmware Attestation
and Authentication framework that prevents MOLE-style firmware subversion.
FAARM integrates digital signature verification at the EL3 secure monitor using
vendor-signed firmware bundles and an on-device public key anchor. At boot, EL3
verifies firmware integrity and authenticity, enforces version checks, and
locks the firmware region, eliminating both pre-verification and
time-of-check-to-time-of-use (TOCTOU) attack vectors. We implement FAARM as a
software-only prototype on a Mali GPU testbed, using a Google Colab-based
emulation framework that models the firmware signing process, the EL1 to EL3
load path, and secure memory configuration. FAARM reliably detects and blocks
malicious firmware injections, rejecting tampered images before use and denying
overwrite attempts after attestation. Firmware verification incurs only 1.34 ms
latency on average, demonstrating that strong security can be achieved with
negligible overhead. FAARM thus closes a fundamental gap in shim-based GPU
TEEs, providing a practical, deployable defense that raises the security
baseline for both mobile and cloud GPU deployments.

</details>


### [17] [Breaking Agent Backbones: Evaluating the Security of Backbone LLMs in AI Agents](https://arxiv.org/abs/2510.22620)
*Julia Bazinska,Max Mathys,Francesco Casucci,Mateo Rojas-Carulla,Xander Davies,Alexandra Souly,Niklas Pfister*

Main category: cs.CR

TL;DR: 提出了威胁快照框架来系统分析LLM对AI代理安全性的影响，创建了包含194331个对抗攻击的安全基准b³，评估31个流行LLM后发现推理能力增强可提升安全性，而模型大小与安全性无关。


<details>
  <summary>Details</summary>
Motivation: AI代理大规模部署但缺乏对骨干LLM选择如何影响代理安全的系统理解，现有框架要么只捕获特定漏洞，要么需要完整代理建模。

Method: 引入威胁快照框架，隔离代理执行流程中LLM漏洞显现的特定状态，构建基于194331个众包对抗攻击的b³安全基准，评估31个流行LLM。

Result: 评估显示增强的推理能力可提高安全性，而模型大小与安全性无相关性。

Conclusion: 发布基准、数据集和评估代码以促进广泛应用，为代理开发者提供指导并激励模型开发者优先考虑骨干安全性改进。

Abstract: AI agents powered by large language models (LLMs) are being deployed at
scale, yet we lack a systematic understanding of how the choice of backbone LLM
affects agent security. The non-deterministic sequential nature of AI agents
complicates security modeling, while the integration of traditional software
with AI components entangles novel LLM vulnerabilities with conventional
security risks. Existing frameworks only partially address these challenges as
they either capture specific vulnerabilities only or require modeling of
complete agents. To address these limitations, we introduce threat snapshots: a
framework that isolates specific states in an agent's execution flow where LLM
vulnerabilities manifest, enabling the systematic identification and
categorization of security risks that propagate from the LLM to the agent
level. We apply this framework to construct the $\operatorname{b}^3$ benchmark,
a security benchmark based on 194331 unique crowdsourced adversarial attacks.
We then evaluate 31 popular LLMs with it, revealing, among other insights, that
enhanced reasoning capabilities improve security, while model size does not
correlate with security. We release our benchmark, dataset, and evaluation code
to facilitate widespread adoption by LLM providers and practitioners, offering
guidance for agent developers and incentivizing model developers to prioritize
backbone security improvements.

</details>


### [18] [DeepfakeBench-MM: A Comprehensive Benchmark for Multimodal Deepfake Detection](https://arxiv.org/abs/2510.22622)
*Kangran Zhao,Yupeng Chen,Xiaoyu Zhang,Yize Chen,Weinan Guan,Baicheng Chen,Chengzhe Sun,Soumyya Kanti Datta,Qingshan Liu,Siwei Lyu,Baoyuan Wu*

Main category: cs.CR

TL;DR: 构建了大规模多模态深度伪造数据集Mega-MMDF和统一基准DeepfakeBench-MM，以解决多模态深度伪造检测中数据不足和标准缺失的问题。


<details>
  <summary>Details</summary>
Motivation: 高级生成AI模型的滥用导致伪造数据泛滥，特别是伪造的人类中心视听内容，带来了严重的金融欺诈和社会不稳定风险。现有研究缺乏足够的多样化训练数据和标准化基准。

Method: 通过组合10种音频伪造方法、12种视觉伪造方法和6种音频驱动面部重演方法，构建了21种伪造流程的Mega-MMDF数据集，包含10万真实样本和110万伪造样本。在此基础上建立了DeepfakeBench-MM基准平台。

Result: 创建了当前最大且最多样化的多模态深度伪造数据集，支持5个数据集和11种多模态深度伪造检测器。通过全面评估发现了多个关键发现（如数据增强、堆叠伪造等）。

Conclusion: DeepfakeBench-MM基准和Mega-MMDF数据集将作为推进多模态深度伪造检测的基础设施，为未来研究提供标准化平台和大规模数据支持。

Abstract: The misuse of advanced generative AI models has resulted in the widespread
proliferation of falsified data, particularly forged human-centric audiovisual
content, which poses substantial societal risks (e.g., financial fraud and
social instability). In response to this growing threat, several works have
preliminarily explored countermeasures. However, the lack of sufficient and
diverse training data, along with the absence of a standardized benchmark,
hinder deeper exploration. To address this challenge, we first build Mega-MMDF,
a large-scale, diverse, and high-quality dataset for multimodal deepfake
detection. Specifically, we employ 21 forgery pipelines through the combination
of 10 audio forgery methods, 12 visual forgery methods, and 6 audio-driven face
reenactment methods. Mega-MMDF currently contains 0.1 million real samples and
1.1 million forged samples, making it one of the largest and most diverse
multimodal deepfake datasets, with plans for continuous expansion. Building on
it, we present DeepfakeBench-MM, the first unified benchmark for multimodal
deepfake detection. It establishes standardized protocols across the entire
detection pipeline and serves as a versatile platform for evaluating existing
methods as well as exploring novel approaches. DeepfakeBench-MM currently
supports 5 datasets and 11 multimodal deepfake detectors. Furthermore, our
comprehensive evaluations and in-depth analyses uncover several key findings
from multiple perspectives (e.g., augmentation, stacked forgery). We believe
that DeepfakeBench-MM, together with our large-scale Mega-MMDF, will serve as
foundational infrastructures for advancing multimodal deepfake detection.

</details>


### [19] [Sentra-Guard: A Multilingual Human-AI Framework for Real-Time Defense Against Adversarial LLM Jailbreaks](https://arxiv.org/abs/2510.22628)
*Md. Mehedi Hasan,Ziaur Rahman,Rafid Mostafiz,Md. Abir Hossain*

Main category: cs.CR

TL;DR: Sentra-Guard是一个实时模块化防御系统，使用混合架构检测和缓解针对大语言模型的越狱和提示注入攻击，通过语义分析和分类器实现99.96%的检测率。


<details>
  <summary>Details</summary>
Motivation: 随着大语言模型的广泛应用，越狱和提示注入攻击日益增多，需要开发有效的防御系统来保护LLM免受恶意攻击。

Method: 采用混合架构，结合FAISS索引的SBERT嵌入表示和微调transformer分类器，通过分类器-检索器融合模块动态计算风险评分，支持多语言预处理和人工反馈循环。

Result: 检测率达到99.96%（AUC=1.00，F1=1.00），攻击成功率仅为0.004%，优于LlamaGuard-2（1.3%）和OpenAI Moderation（3.7%）。

Conclusion: Sentra-Guard在对抗性LLM防御方面达到了新的最先进水平，具有透明、可微调和模块化设计，适用于商业和开源环境。

Abstract: This paper presents a real-time modular defense system named Sentra-Guard.
The system detects and mitigates jailbreak and prompt injection attacks
targeting large language models (LLMs). The framework uses a hybrid
architecture with FAISS-indexed SBERT embedding representations that capture
the semantic meaning of prompts, combined with fine-tuned transformer
classifiers, which are machine learning models specialized for distinguishing
between benign and adversarial language inputs. It identifies adversarial
prompts in both direct and obfuscated attack vectors. A core innovation is the
classifier-retriever fusion module, which dynamically computes context-aware
risk scores that estimate how likely a prompt is to be adversarial based on its
content and context. The framework ensures multilingual resilience with a
language-agnostic preprocessing layer. This component automatically translates
non-English prompts into English for semantic evaluation, enabling consistent
detection across over 100 languages. The system includes a HITL feedback loop,
where decisions made by the automated system are reviewed by human experts for
continual learning and rapid adaptation under adversarial pressure.
Sentra-Guard maintains an evolving dual-labeled knowledge base of benign and
malicious prompts, enhancing detection reliability and reducing false
positives. Evaluation results show a 99.96% detection rate (AUC = 1.00, F1 =
1.00) and an attack success rate (ASR) of only 0.004%. This outperforms leading
baselines such as LlamaGuard-2 (1.3%) and OpenAI Moderation (3.7%). Unlike
black-box approaches, Sentra-Guard is transparent, fine-tunable, and compatible
with diverse LLM backends. Its modular design supports scalable deployment in
both commercial and open-source environments. The system establishes a new
state-of-the-art in adversarial LLM defense.

</details>


### [20] [RejSCore: Rejection Sampling Core for Multivariate-based Public key Cryptography](https://arxiv.org/abs/2510.22661)
*Malik Imran,Safiullah Khan,Zain Ul Abideen,Ciara Rafferty,Ayesha Khalid,Muhammad Rashid,Maire O'Neill*

Main category: cs.CR

TL;DR: RejSCore是一个针对后量子密码学中拒绝采样的轻量级硬件加速器，专门为QR-UOV方案设计，在资源受限设备上实现高效运行。


<details>
  <summary>Details</summary>
Motivation: 后量子多元公钥密码学方案需要大量计算操作如拒绝采样，这对资源受限设备构成挑战，而现有硬件设计尚未充分解决拒绝采样问题。

Method: 采用AES-CTR-128伪随机数生成器和轻量级迭代方法进行拒绝采样，在Artix-7 FPGA和65nm CMOS技术上实现，使用面积-延迟乘积和功耗-延迟乘积进行评估。

Result: 在Artix-7和65nm CMOS上分别实现222MHz和565MHz工作频率，占用2042个slice和464,866μm²面积，使用QR-UOV安全级别I参数时完成操作需要8525个时钟周期。

Conclusion: ADP和PDP评估证实RejSCore适合部署在资源受限和安全关键的环境中。

Abstract: Post-quantum multivariate public key cryptography (MPKC) schemes resist
quantum threats but require heavy operations, such as rejection sampling, which
challenge resource-limited devices. Prior hardware designs have addressed
various aspects of MPKC signature generation. However, rejection sampling
remains largely unexplored in such contexts. This paper presents RejSCore, a
lightweight hardware accelerator for rejection sampling in post-quantum
cryptography. It specifically targets the QR-UOV scheme, which is a prominent
candidate under the second-round of the National Institute of Standards and
Technology (NIST) additional digital signature standardization process. The
architecture includes an AES-CTR-128-based pseudorandom number generator.
Moreover, a lightweight iterative method is employed in rejection sampling,
offering reduced resource consumption and area overhead while slightly
increasing latency. The performance of RejSCore is comprehensively evaluated on
Artix-7 FPGAs and 65 nm CMOS technology using the Area-Delay Product (ADP) and
Power-Delay Product (PDP). On Artix-7 and 65 nm CMOS, RejSCore achieves an area
of 2042 slices and 464,866~$\mu m^2$, with operating frequencies of 222 MHz and
565 MHz, respectively. Using the QR-UOV parameters for security level I ($q =
127$, $v = 156$, $m = 54$, $l = 3$), the core completes its operation in 8525
clock cycles. The ADP and PDP evaluations confirm RejSCore's suitability for
deployment in resource-constrained and security-critical environments.

</details>


### [21] [SpoofTrackBench: Interpretable AI for Spoof-Aware UAV Tracking and Benchmarking](https://arxiv.org/abs/2510.22726)
*Van Le,Tan Le*

Main category: cs.CR

TL;DR: SpoofTrackBench是一个可复现的模块化基准测试，用于评估实时定位跟踪系统在雷达欺骗攻击下的对抗鲁棒性，支持多种欺骗类型和跟踪架构的分析比较。


<details>
  <summary>Details</summary>
Motivation: 现有的实时定位跟踪系统缺乏标准化的对抗鲁棒性评估基准，难以系统评估不同跟踪架构在雷达欺骗攻击下的表现。

Method: 基于Hampton大学Skyler雷达传感器数据集，模拟漂移、幽灵和镜像类型欺骗攻击，使用JPDA和GNN跟踪架构，通过分离干净和欺骗检测流、可视化轨迹偏差和量化分配误差进行评估。

Result: 开发了包含聚类叠加、注入感知时间线和场景自适应可视化的可解释框架，自动导出评估图表和日志，实现了跨架构的可复现比较。

Conclusion: SpoofTrackBench为欺骗感知跟踪管道设立了开放、伦理的基准测试新标准，支持严格的跨架构分析和社区验证。

Abstract: SpoofTrackBench is a reproducible, modular benchmark for evaluating
adversarial robustness in real-time localization and tracking (RTLS) systems
under radar spoofing. Leveraging the Hampton University Skyler Radar Sensor
dataset, we simulate drift, ghost, and mirror-type spoofing attacks and
evaluate tracker performance using both Joint Probabilistic Data Association
(JPDA) and Global Nearest Neighbor (GNN) architectures. Our framework separates
clean and spoofed detection streams, visualizes spoof-induced trajectory
divergence, and quantifies assignment errors via direct drift-from-truth
metrics. Clustering overlays, injection-aware timelines, and scenario-adaptive
visualizations enable interpretability across spoof types and configurations.
Evaluation figures and logs are auto-exported for reproducible comparison.
SpoofTrackBench sets a new standard for open, ethical benchmarking of
spoof-aware tracking pipelines, enabling rigorous cross-architecture analysis
and community validation.

</details>


### [22] [Is Your Prompt Poisoning Code? Defect Induction Rates and Security Mitigation Strategies](https://arxiv.org/abs/2510.22944)
*Bin Wang,YiLu Zhong,MiDi Wan,WenJie Yu,YuanBing Ouyang,Yenan Huang,Hui Li*

Main category: cs.CR

TL;DR: 论文研究了提示质量对LLM生成代码安全性的影响，发现提示规范性降低会显著增加生成不安全代码的风险，而高级提示技术可以有效缓解这种风险。


<details>
  <summary>Details</summary>
Motivation: 现有研究主要关注对抗性攻击或模型固有缺陷，但忽略了良性但表述不佳的提示对生成代码安全性的影响，这是一个普遍但未被充分探索的问题。

Method: 提出了包含目标清晰度、信息完整性和逻辑一致性的提示质量评估框架，构建了包含四个规范性级别(L0-L3)的大规模基准数据集CWE-BENCH-PYTHON，并在多个最先进LLM上进行实验。

Result: 实验显示提示规范性降低与生成不安全代码的可能性呈明显正相关，而Chain-of-Thought和Self-Correction等高级提示技术能有效减轻低质量提示带来的安全风险。

Conclusion: 提高用户提示质量是增强AI生成代码安全性的关键有效策略。

Abstract: Large language models (LLMs) have become indispensable for automated code
generation, yet the quality and security of their outputs remain a critical
concern. Existing studies predominantly concentrate on adversarial attacks or
inherent flaws within the models. However, a more prevalent yet underexplored
issue concerns how the quality of a benign but poorly formulated prompt affects
the security of the generated code. To investigate this, we first propose an
evaluation framework for prompt quality encompassing three key dimensions: goal
clarity, information completeness, and logical consistency. Based on this
framework, we construct and publicly release CWE-BENCH-PYTHON, a large-scale
benchmark dataset containing tasks with prompts categorized into four distinct
levels of normativity (L0-L3). Extensive experiments on multiple
state-of-the-art LLMs reveal a clear correlation: as prompt normativity
decreases, the likelihood of generating insecure code consistently and markedly
increases. Furthermore, we demonstrate that advanced prompting techniques, such
as Chain-of-Thought and Self-Correction, effectively mitigate the security
risks introduced by low-quality prompts, substantially improving code safety.
Our findings highlight that enhancing the quality of user prompts constitutes a
critical and effective strategy for strengthening the security of AI-generated
code.

</details>


### [23] [QuantumShield: Multilayer Fortification for Quantum Federated Learning](https://arxiv.org/abs/2510.22945)
*Dev Gurung,Shiva Raj Pokhrel*

Main category: cs.CR

TL;DR: 提出了一种量子安全的联邦学习框架，通过整合量子密钥分发、量子隐形传态、密钥封装机制和后量子密码学等先进协议，保护分布式学习系统免受量子攻击威胁。


<details>
  <summary>Details</summary>
Motivation: 随着经典密码方法在量子攻击面前日益脆弱，需要建立一个在量子攻击者存在时仍然稳健的安全架构，为下一代联邦学习系统提供量子时代的内在安全保障。

Method: 整合并严格评估量子密钥分发、量子隐形传态、密钥封装机制和后量子密码学等协议，在安全可扩展的量子安全联邦学习生态系统中实现无缝互操作性。

Result: 通过全面的理论建模和实验验证，提供了所提出框架的详细安全和性能评估，证明了其在量子攻击下的稳健性。

Conclusion: 这项工作为下一代联邦学习系统奠定了坚实基础，使其在量子时代具有内在安全性，能够抵御量子攻击威胁。

Abstract: In this paper, we propose a groundbreaking quantum-secure federated learning
(QFL) framework designed to safeguard distributed learning systems against the
emerging threat of quantum-enabled adversaries. As classical cryptographic
methods become increasingly vulnerable to quantum attacks, our framework
establishes a resilient security architecture that remains robust even in the
presence of quantum-capable attackers. We integrate and rigorously evaluate
advanced quantum and post-quantum protocols including Quantum Key Distribution
(QKD), Quantum Teleportation, Key Encapsulation Mechanisms (KEM) and
Post-Quantum Cryptography (PQC) to fortify the QFL process against both
classical and quantum threats. These mechanisms are systematically analyzed and
implemented to demonstrate their seamless interoperability within a secure and
scalable QFL ecosystem. Through comprehensive theoretical modeling and
experimental validation, this work provides a detailed security and performance
assessment of the proposed framework. Our findings lay a strong foundation for
next-generation federated learning systems that are inherently secure in the
quantum era.

</details>


### [24] [CompressionAttack: Exploiting Prompt Compression as a New Attack Surface in LLM-Powered Agents](https://arxiv.org/abs/2510.22963)
*Zesen Liu,Zhixiang Zhang,Yuchong Xie,Dongdong She*

Main category: cs.CR

TL;DR: 本文提出了CompressionAttack框架，首次利用提示压缩作为攻击面，通过硬压缩和软压缩两种策略操纵LLM行为，攻击成功率高达80%，现有防御措施无效。


<details>
  <summary>Details</summary>
Motivation: LLM驱动的代理常使用提示压缩来降低推理成本，但这引入了新的安全风险。压缩模块为效率而非安全优化，可能被对抗性输入操纵，导致语义漂移和LLM行为改变。

Method: 提出CompressionAttack框架，包含两种策略：HardCom使用离散对抗性编辑进行硬压缩，SoftCom在潜在空间进行扰动实现软压缩。

Result: 在多个LLM上的实验显示攻击成功率高达80%，偏好翻转率达98%，同时具有高度隐蔽性和可转移性。VSCode Cline和Ollama的案例研究证实了实际影响。

Conclusion: 当前防御措施被证明无效，突显了需要更强的保护机制来应对提示压缩带来的安全风险。

Abstract: LLM-powered agents often use prompt compression to reduce inference costs,
but this introduces a new security risk. Compression modules, which are
optimized for efficiency rather than safety, can be manipulated by adversarial
inputs, causing semantic drift and altering LLM behavior. This work identifies
prompt compression as a novel attack surface and presents CompressionAttack,
the first framework to exploit it. CompressionAttack includes two strategies:
HardCom, which uses discrete adversarial edits for hard compression, and
SoftCom, which performs latent-space perturbations for soft compression.
Experiments on multiple LLMs show up to 80% attack success and 98% preference
flips, while remaining highly stealthy and transferable. Case studies in VSCode
Cline and Ollama confirm real-world impact, and current defenses prove
ineffective, highlighting the need for stronger protections.

</details>


### [25] [Advancing Honeywords for Real-World Authentication Security](https://arxiv.org/abs/2510.22971)
*Sudiksha Das,Ashish Kundu*

Main category: cs.CR

TL;DR: 本文认为蜜词技术有潜力但需要解决平坦性、集成性和可靠性等问题才能实际部署，提出了一个可部署框架建议。


<details>
  <summary>Details</summary>
Motivation: 尽管蜜词技术已研究十多年，但主要认证平台仍未采用。本文旨在分析阻碍其广泛使用的技术问题，并提出改进方案。

Method: 通过分析现有蜜词生成、攻击者建模和蜜检查器架构的研究，识别已解决的问题和持续存在的障碍。

Result: 识别出平坦性、集成性和可靠性是阻碍蜜词技术部署的主要问题，需要技术突破与安全简单架构的结合。

Conclusion: 蜜词技术要从学术概念转变为实用安全工具，需要技术进展与安全简单架构、自适应响应处理和详细配置检查的结合。

Abstract: Introduced by Juels and Rivest in 2013, Honeywords, which are decoy passwords
stored alongside a real password, appear to be a proactive method to help
detect password credentials misuse. However, despite over a decade of research,
this technique has not been adopted by major authentication platforms. This
position paper argues that the core concept of Honeywords has potential but
requires more research on issues such as flatness, integration, and
reliability, in order to be a practical deployable solution. This paper
examines the current work on Honeyword generation, attacker modeling, and
honeychecker architecture, analyzing the subproblems that have been addressed
and ongoing issues that prevent this system from being more widely used. The
paper then suggests a deployable framework that combines the
attacker-resilient, context-aware decoy creation that Honeywords provide with
easy integration into existing systems. Honeywords will only move from an
academic idea to a practical security tool if technical advances are paired
with secure and straightforward architectures, along with adaptive response
handling and detailed configuration checks.

</details>


### [26] [A Multi-Store Privacy Measurement of Virtual Reality App Ecosystem](https://arxiv.org/abs/2510.23024)
*Chuan Yan,Zeng Li,Kunlin Cai,Liuhuo Wan,Ruomai Ren,Yiran Shen,Guangdong Bai*

Main category: cs.CR

TL;DR: 对VR应用商店中6,565个应用的隐私实践进行首次全面多商店研究，发现VR生态系统存在严重的隐私合规问题，包括三分之一应用未声明敏感数据使用，21.5%应用未提供有效隐私政策。


<details>
  <summary>Details</summary>
Motivation: VR应用收集用户生物特征、行为和环境等敏感数据，但缺乏领域特定监管，导致各应用商店隐私实践差异显著，需要系统评估当前隐私保护状况。

Method: 使用自然语言处理、逆向工程和静态分析的多方面方法，评估VR应用的声明性和行为性隐私实践。

Result: 所有商店都存在显著的隐私合规问题，三分之一应用未声明敏感数据使用，21.5%应用未提供有效隐私政策，显示VR生态系统隐私保护处于不成熟状态。

Conclusion: 研究首次揭示了VR应用生态系统的隐私保护现状，应向VR应用开发者和用户发出警示，并鼓励商店运营商对VR应用的隐私合规实施严格监管。

Abstract: Virtual Reality (VR) has gained increasing traction among various domains in
recent years, with major companies such as Meta, Pico, and Microsoft launching
their application stores to support third-party developers in releasing their
applications (or simply apps). These apps offer rich functionality but
inherently collect privacy-sensitive data, such as user biometrics, behaviors,
and the surrounding environment. Nevertheless, there is still a lack of
domain-specific regulations to govern the data handling of VR apps, resulting
in significant variations in their privacy practices among app stores.
  In this work, we present the first comprehensive multi-store study of privacy
practices in the current VR app ecosystem, covering a large-scale dataset
involving 6,565 apps collected from five major app stores. We assess both
declarative and behavioral privacy practices of VR apps, using a multi-faceted
approach based on natural language processing, reverse engineering, and static
analysis. Our assessment reveals significant privacy compliance issues across
all stores, underscoring the premature status of privacy protection in this
rapidly growing ecosystem. For instance, one third of apps fail to declare
their use of sensitive data, and 21.5\% of apps neglect to provide valid
privacy policies. Our work sheds light on the status quo of privacy protection
within the VR app ecosystem for the first time. Our findings should raise an
alert to VR app developers and users, and encourage store operators to
implement stringent regulations on privacy compliance among VR apps.

</details>


### [27] [Efficient and Encrypted Inference using Binarized Neural Networks within In-Memory Computing Architectures](https://arxiv.org/abs/2510.23034)
*Gokulnath Rajendran,Suman Deb,Anupam Chattopadhyay*

Main category: cs.CR

TL;DR: 提出了一种保护内存计算中二值化神经网络模型参数的方法，使用物理不可克隆函数生成密钥对权重进行加密，在加密状态下执行推理，实现高效的安全保护。


<details>
  <summary>Details</summary>
Motivation: 传统方法在内存计算框架中保护BNN模型参数时，需要存储加密参数并在运行时解密，这会带来显著的计算开销，违背了内存计算集成计算与存储的核心原则。

Method: 利用物理不可克隆函数生成密钥，在存储到交叉阵列前对模型参数进行转换，然后在加密权重上直接执行推理操作，实现了一种特殊的全同态加密。

Result: 分析表明，在没有密钥的情况下进行推理会导致性能急剧下降，准确率低于15%，验证了保护策略的有效性。

Conclusion: 该方法能够在保护内存计算架构中BNN安全的同时，保持计算效率，为安全的内存计算提供了可行的解决方案。

Abstract: Binarized Neural Networks (BNNs) are a class of deep neural networks designed
to utilize minimal computational resources, which drives their popularity
across various applications. Recent studies highlight the potential of mapping
BNN model parameters onto emerging non-volatile memory technologies,
specifically using crossbar architectures, resulting in improved inference
performance compared to traditional CMOS implementations. However, the common
practice of protecting model parameters from theft attacks by storing them in
an encrypted format and decrypting them at runtime introduces significant
computational overhead, thus undermining the core principles of in-memory
computing, which aim to integrate computation and storage. This paper presents
a robust strategy for protecting BNN model parameters, particularly within
in-memory computing frameworks. Our method utilizes a secret key derived from a
physical unclonable function to transform model parameters prior to storage in
the crossbar. Subsequently, the inference operations are performed on the
encrypted weights, achieving a very special case of Fully Homomorphic
Encryption (FHE) with minimal runtime overhead. Our analysis reveals that
inference conducted without the secret key results in drastically diminished
performance, with accuracy falling below 15%. These results validate the
effectiveness of our protection strategy in securing BNNs within in-memory
computing architectures while preserving computational efficiency.

</details>


### [28] [A high-capacity linguistic steganography based on entropy-driven rank-token mapping](https://arxiv.org/abs/2510.23035)
*Jun Jiang,Weiming Zhang,Nenghai Yu,Kejiang Chen*

Main category: cs.CR

TL;DR: 提出RTMStega框架，通过基于排名的自适应编码和上下文感知解压缩，显著提升语言隐写术的载荷容量和安全性。


<details>
  <summary>Details</summary>
Motivation: 当前语言隐写术方法在载荷容量和安全性方面存在严重限制：传统修改方法会产生可检测异常，检索策略容量低，生成式方法受限于标记预测的有限熵。

Method: RTMStega整合基于排名的自适应编码和上下文感知解压缩，通过将秘密消息映射到标记概率排名，并基于上下文感知的熵调整动态调整采样。

Result: 实验表明RTMStega将主流生成式隐写术的载荷容量提升三倍，处理时间减少50%以上，同时保持高文本质量。

Conclusion: RTMStega在载荷容量和不可感知性之间取得平衡，为安全高效的隐蔽通信提供了可信解决方案。

Abstract: Linguistic steganography enables covert communication through embedding
secret messages into innocuous texts; however, current methods face critical
limitations in payload capacity and security. Traditional modification-based
methods introduce detectable anomalies, while retrieval-based strategies suffer
from low embedding capacity. Modern generative steganography leverages language
models to generate natural stego text but struggles with limited entropy in
token predictions, further constraining capacity. To address these issues, we
propose an entropy-driven framework called RTMStega that integrates rank-based
adaptive coding and context-aware decompression with normalized entropy. By
mapping secret messages to token probability ranks and dynamically adjusting
sampling via context-aware entropy-based adjustments, RTMStega achieves a
balance between payload capacity and imperceptibility. Experiments across
diverse datasets and models demonstrate that RTMStega triples the payload
capacity of mainstream generative steganography, reduces processing time by
over 50%, and maintains high text quality, offering a trustworthy solution for
secure and efficient covert communication.

</details>


### [29] [KAPG: Adaptive Password Guessing via Knowledge-Augmented Generation](https://arxiv.org/abs/2510.23036)
*Xudong Yang,Jincheng Li,Kaiwen Xing,Zhenjia Xiao,Mingjian Duan,Weili Han,Hu Xiong*

Main category: cs.CR

TL;DR: KAPG是一个知识增强的密码猜测框架，通过将外部词汇知识融入猜测过程，显著提升了密码猜测的准确性和适应性。


<details>
  <summary>Details</summary>
Motivation: 现有密码猜测模型主要依赖泄露密码的统计模式，忽视了社会背景、文化趋势等外部因素对密码选择的影响，导致模型难以适应新兴密码趋势。

Method: KAPG将内部统计知识与反映现实趋势的外部信息相结合，使用密码前缀作为知识查找的锚点，在生成过程中动态注入相关外部线索，同时保持真实密码的结构规律性。

Result: 在12个泄露数据集上的实验表明，KAPG在站内和跨站场景下分别比最先进模型平均提升了36.5%和74.7%的性能，并展现出良好的鲁棒性和计算效率。

Conclusion: KAPG通过整合外部知识有效解决了传统密码猜测模型的局限性，同时开发的KAPSM密码强度计在各种评估设置中都显著优于现有工具。

Abstract: As the primary mechanism of digital authentication, user-created passwords
exhibit common patterns and regularities that can be learned from leaked
datasets. Password choices are profoundly shaped by external factors, including
social contexts, cultural trends, and popular vocabulary. Prevailing password
guessing models primarily emphasize patterns derived from leaked passwords,
while neglecting these external influences -- a limitation that hampers their
adaptability to emerging password trends and erodes their effectiveness over
time.
  To address these challenges, we propose KAPG, a knowledge-augmented password
guessing framework that adaptively integrates external lexical knowledge into
the guessing process. KAPG couples internal statistical knowledge learned from
leaked passwords with external information that reflects real-world trends. By
using password prefixes as anchors for knowledge lookup, it dynamically injects
relevant external cues during generation while preserving the structural
regularities of authentic passwords. Experiments on twelve leaked datasets show
that KnowGuess achieves average improvements of 36.5\% and 74.7\% over
state-of-the-art models in intra-site and cross-site scenarios, respectively.
Further analyses of password overlap and model efficiency highlight its
robustness and computational efficiency. To counter these attacks, we further
develop KAPSM, a trend-aware and site-specific password strength meter.
Experiments demonstrate that KAPSM significantly outperforms existing tools in
accuracy across diverse evaluation settings.

</details>


### [30] [zkSTAR: A zero knowledge system for time series attack detection enforcing regulatory compliance in critical infrastructure networks](https://arxiv.org/abs/2510.23060)
*Paritosh Ramanan,H. M. Mohaimanul Islam,Abhiram Reddy Alugula*

Main category: cs.CR

TL;DR: zkSTAR是一个基于zk-SNARKs的工业控制系统网络攻击检测框架，能够在保护数据机密性的同时提供可验证的检测保证


<details>
  <summary>Details</summary>
Motivation: 工业控制系统面临日益增长的网络安全威胁，监管机构需要验证检测机制的有效性，但公用事业公司不愿披露敏感操作数据

Method: 采用基于残差的统计假设检验方法，构建双管齐下的zk-SNARK架构，强制执行状态空间动态的时间一致性和检测测试的统计一致性

Result: 通过形式化分析框架的可靠性和零知识属性，并在真实ICS数据集上进行计算实验验证了实际可行性

Conclusion: zkSTAR为工业控制系统驱动的关键基础设施网络提供了一种可扩展的、保护隐私的监管合规替代方案

Abstract: Industrial control systems (ICS) form the operational backbone of critical
infrastructure networks (CIN) such as power grids, water supply systems, and
gas pipelines. As cyber threats to these systems escalate, regulatory agencies
are imposing stricter compliance requirements to ensure system-wide security
and reliability. A central challenge, however, is enabling regulators to verify
the effectiveness of detection mechanisms without requiring utilities to
disclose sensitive operational data. In this paper, we introduce zkSTAR, a
cyberattack detection framework that leverages zk-SNARKs to reconcile these
requirements and enable provable detection guarantees while preserving data
confidentiality. Our approach builds on established residual-based statistical
hypothesis testing methods applied to state-space detection models.
Specifically, we design a two-pronged zk-SNARK architecture that enforces
temporal consistency of the state-space dynamics and statistical consistency of
the detection tests, allowing regulators to temporally verify alarm correctness
without visibility into utility-level data. We formally analyze the soundness
and zero knowledge properties of our framework and validate its practical
feasibility through computational experiments on real-world ICS datasets. As a
result, our work demonstrates a scalable, privacy-preserving alternative for
regulatory compliance for ICS driven critical infrastructure networks.

</details>


### [31] [Fast-MIA: Efficient and Scalable Membership Inference for LLMs](https://arxiv.org/abs/2510.23074)
*Hiromu Takahashi,Shotaro Ishihara*

Main category: cs.CR

TL;DR: Fast-MIA是一个用于高效评估大型语言模型成员推理攻击的Python库，解决了高计算成本和缺乏标准化实现的问题。


<details>
  <summary>Details</summary>
Motivation: 由于对版权、安全和数据隐私的日益关注，针对LLM的成员推理攻击研究面临高计算成本和缺乏标准化实现的障碍。

Method: 提供快速批量推理，并在统一评估框架下实现了代表性MIA方法，支持简单配置和可扩展性。

Result: 开发了开源工具Fast-MIA，支持可扩展和透明的LLM研究。

Conclusion: Fast-MIA通过提供高效、标准化的MIA评估框架，促进了LLM成员推理攻击研究的进展。

Abstract: We propose Fast-MIA (https://github.com/Nikkei/fast-mia), a Python library
for efficiently evaluating membership inference attacks (MIA) against Large
Language Models (LLMs). MIA against LLMs has emerged as a crucial challenge due
to growing concerns over copyright, security, and data privacy, and has
attracted increasing research attention. However, the progress of this research
is significantly hindered by two main obstacles: (1) the high computational
cost of inference in LLMs, and (2) the lack of standardized and maintained
implementations of MIA methods, which makes large-scale empirical comparison
difficult. To address these challenges, our library provides fast batch
inference and includes implementations of representative MIA methods under a
unified evaluation framework. This library supports easy implementation of
reproducible benchmarks with simple configuration and extensibility. We release
Fast-MIA as an open-source (Apache License 2.0) tool to support scalable and
transparent research on LLMs.

</details>


### [32] [Beyond Imprecise Distance Metrics: LLM-Predicted Target Call Stacks for Directed Greybox Fuzzing](https://arxiv.org/abs/2510.23101)
*Yifan Zhang,Xin Zhang*

Main category: cs.CR

TL;DR: 提出了一种基于大语言模型预测调用栈的定向灰盒模糊测试方法，替代传统的静态分析距离度量，显著提高了漏洞触发效率


<details>
  <summary>Details</summary>
Motivation: 现有定向模糊测试方法依赖静态分析的距离度量，存在过度近似问题，导致大量无关执行路径被误判为可能触发目标漏洞，降低了模糊测试效率

Method: 使用大语言模型预测漏洞触发调用栈来指导种子优先级排序。首先通过静态分析构建调用图识别可能到达目标位置的方法，然后利用LLM预测最可能触发漏洞的调用栈序列，优先选择执行路径与预测调用栈重叠度高的种子进行变异

Result: 在真实世界程序套件上，该方法触发漏洞速度比基线快1.86倍到3.09倍。通过定向补丁测试发现了10个新漏洞和2个不完整修复，其中10个获得了CVE编号

Conclusion: 这是首个将大语言模型集成到定向灰盒模糊测试核心种子优先级排序机制的工作，证明了基于精确调用栈表示的方法比传统静态分析距离度量更有效

Abstract: Directed greybox fuzzing (DGF) aims to efficiently trigger bugs at specific
target locations by prioritizing seeds whose execution paths are more likely to
mutate into triggering target bugs. However, existing DGF approaches suffer
from imprecise probability calculations due to their reliance on complex
distance metrics derived from static analysis. The over-approximations inherent
in static analysis cause a large number of irrelevant execution paths to be
mistakenly considered to potentially mutate into triggering target bugs,
significantly reducing fuzzing efficiency. We propose to replace static
analysis-based distance metrics with precise call stack representations. Call
stacks represent precise control flows, thereby avoiding false information in
static analysis. We leverage large language models (LLMs) to predict
vulnerability-triggering call stacks for guiding seed prioritization. Our
approach constructs call graphs through static analysis to identify methods
that can potentially reach target locations, then utilizes LLMs to predict the
most likely call stack sequence that triggers the vulnerability. Seeds whose
execution paths have higher overlap with the predicted call stack are
prioritized for mutation. This is the first work to integrate LLMs into the
core seed prioritization mechanism of DGF. We implement our approach and
evaluate it against several state-of-the-art fuzzers. On a suite of real-world
programs, our approach triggers vulnerabilities $1.86\times$ to $3.09\times$
faster compared to baselines. In addition, our approach identifies 10 new
vulnerabilities and 2 incomplete fixes in the latest versions of programs used
in our controlled experiments through directed patch testing, with 10 assigned
CVE IDs.

</details>


### [33] [Optimizing Optimism: Up to 6.5x Faster zkVM Validty Proofs via Sparse Derivation](https://arxiv.org/abs/2510.23172)
*Mohsen Ahmadvand,Pedro Souto*

Main category: cs.CR

TL;DR: 该论文针对Optimism派生管道在zkVM中实现时的高开销问题，提出了针对零知识证明优化的重新设计，实现了6.5倍的派生速度提升。


<details>
  <summary>Details</summary>
Motivation: 当前的Optimism派生管道设计主要关注正确性和活跃性，而非简洁有效性证明。直接移植到zkVM会产生显著开销，使有效性证明成本远高于必要水平。

Method: 系统识别当前设计中的低效问题，分析其对证明成本的影响，并提供保持安全性的重新设计，专门针对零知识证明进行优化。

Result: 重新设计在zkVM中实现了高达6.5倍的派生速度提升（整体速度提升3.5倍），同时保持完全相同的安全保证。

Conclusion: 通过专门针对零知识证明环境进行优化设计，可以显著降低有效性证明的成本，同时不牺牲安全性。

Abstract: The Optimism derivation pipeline is engineered for correctness and liveness,
not for succinct validity proofs. A straightforward port to a zkVM imposes
significant overheads, making validity proofs significantly more costly than
necessary. We systematically identify inefficiencies in the current design,
analyze their impact on proving costs, and provide a soundness-preserving
redesign tailored to zk proving. Our redesign achieves up to 6.5x faster
derivation inside zkVMs (3.5x overall speedup) while maintaining identical
safety guarantees.

</details>


### [34] [Privacy-Preserving Semantic Communication over Wiretap Channels with Learnable Differential Privacy](https://arxiv.org/abs/2510.23274)
*Weixuan Chen,Qianqian Yang,Shuo Shao,Shunpu Tang,Zhiguo Shi,Shui Yu*

Main category: cs.CR

TL;DR: 提出了一种基于差分隐私的安全语义通信框架，通过可学习模式的DP噪声保护图像传输中的隐私信息，在保持合法用户任务性能的同时显著降低窃听者的重建质量。


<details>
  <summary>Details</summary>
Motivation: 现有安全语义通信方法存在限制性假设，如需要有利信道条件或窃听者模型先验知识。语义通信虽然提高了传输效率，但也带来了严重的隐私问题。

Method: 使用GAN反演方法从源图像中提取解耦的语义表示，然后选择性地用近似DP噪声扰动私有语义表示。与传统DP方法不同，引入通过神经网络对抗训练生成的可学习模式DP噪声。

Result: 与之前的DP方法和直接传输相比，该方法显著降低了窃听者的重建质量，同时对任务性能只有轻微影响。在可比安全级别下，相比之前的DP方法，合法用户在LPIPS和FPPSR指标上分别有0.06-0.29和0.10-0.86的优势。

Conclusion: 所提出的方法通过可学习模式的DP噪声有效保护私有信息，同时通过调整隐私预算实现明确可控的安全级别，解决了现有安全语义通信方法的局限性。

Abstract: While semantic communication (SemCom) improves transmission efficiency by
focusing on task-relevant information, it also raises critical privacy
concerns. Many existing secure SemCom approaches rely on restrictive or
impractical assumptions, such as favorable channel conditions for the
legitimate user or prior knowledge of the eavesdropper's model. To address
these limitations, this paper proposes a novel secure SemCom framework for
image transmission over wiretap channels, leveraging differential privacy (DP)
to provide approximate privacy guarantees. Specifically, our approach first
extracts disentangled semantic representations from source images using
generative adversarial network (GAN) inversion method, and then selectively
perturbs private semantic representations with approximate DP noise. Distinct
from conventional DP-based protection methods, we introduce DP noise with
learnable pattern, instead of traditional white Gaussian or Laplace noise,
achieved through adversarial training of neural networks (NNs). This design
mitigates the inherent non-invertibility of DP while effectively protecting
private information. Moreover, it enables explicitly controllable security
levels by adjusting the privacy budget according to specific security
requirements, which is not achieved in most existing secure SemCom approaches.
Experimental results demonstrate that, compared with the previous DP-based
method and direct transmission, the proposed method significantly degrades the
reconstruction quality for the eavesdropper, while introducing only slight
degradation in task performance. Under comparable security levels, our approach
achieves an LPIPS advantage of 0.06-0.29 and an FPPSR advantage of 0.10-0.86
for the legitimate user compared with the previous DP-based method.

</details>


### [35] [Network Intrusion Detection: Evolution from Conventional Approaches to LLM Collaboration and Emerging Risks](https://arxiv.org/abs/2510.23313)
*Yaokai Feng,Kouichi Sakurai*

Main category: cs.CR

TL;DR: 这篇综述系统梳理了网络入侵检测系统(NIDS)的演进历程，从传统的基于签名和神经网络的方法到最近与大型语言模型(LLM)的集成，总结了当前技术现状、优势和局限。


<details>
  <summary>Details</summary>
Motivation: 随着网络攻击日益复杂，传统NIDS方法面临挑战，需要探索LLM等新技术在网络安全领域的应用潜力，同时评估其实际部署的可行性和风险。

Method: 通过系统文献综述方法，分析比较不同NIDS技术路线：签名检测、神经网络检测和LLM集成方法，涵盖传统网络、自动驾驶车辆和物联网等多样化环境。

Result: 研究发现：1)基于签名的IDS仍在现代系统中发挥重要作用；2)神经网络检测虽发展20多年但实际部署仍面临挑战；3)LLM在NIDS中有用但面临实际应用挑战，甚至可能被用作攻击工具；4)构建领域特定LLM的策略已被提出。

Conclusion: NIDS技术持续演进，LLM集成带来新机遇但也伴随新风险，需要平衡技术创新与实际部署可行性，领域特定LLM策略为解决LLM在网络安全应用中的挑战提供了方向。

Abstract: This survey systematizes the evolution of network intrusion detection systems
(NIDS), from conventional methods such as signature-based and neural network
(NN)-based approaches to recent integrations with large language models (LLMs).
It clearly and concisely summarizes the current status, strengths, and
limitations of conventional techniques, and explores the practical benefits of
integrating LLMs into NIDS. Recent research on the application of LLMs to NIDS
in diverse environments is reviewed, including conventional network
infrastructures, autonomous vehicle environments and IoT environments.
  From this survey, readers will learn that: 1) the earliest methods,
signature-based IDSs, continue to make significant contributions to modern
systems, despite their well-known weaknesses; 2) NN-based detection, although
considered promising and under development for more than two decades, and
despite numerous related approaches, still faces significant challenges in
practical deployment; 3) LLMs are useful for NIDS in many cases, and a number
of related approaches have been proposed; however, they still face significant
challenges in practical applications. Moreover, they can even be exploited as
offensive tools, such as for generating malware, crafting phishing messages, or
launching cyberattacks. Recently, several studies have been proposed to address
these challenges, which are also reviewed in this survey; and 4) strategies for
constructing domain-specific LLMs have been proposed and are outlined in this
survey, as it is nearly impossible to train a NIDS-specific LLM from scratch.

</details>


### [36] [Authentication Against Insecure Bootstrapping for 5G Networks: Feasibility, Resiliency, and Transitional Solutions in Post-Quantum Era](https://arxiv.org/abs/2510.23457)
*Saleh Darzi,Mirza Masfiqur Rahman,Imtiaz Karim,Rouzbeh Behnia,Attila A Yavuz,Elisa Bertino*

Main category: cs.CR

TL;DR: 该论文分析了5G基站认证在量子计算威胁下的安全性问题，发现直接采用NIST后量子密码标准存在可行性问题，并提出了一种基于分层身份基阈值签名的过渡解决方案BORG。


<details>
  <summary>Details</summary>
Motivation: 5G协议在初始引导阶段缺乏强大的基站认证机制，容易受到假基站攻击。传统基于PKI的数字签名和身份基签名方案无法抵御量子攻击，而直接集成NIST后量子密码标准在5G基站认证中的适用性尚未探索。

Method: 对NIST后量子密码标准和传统数字签名方案（包括阈值和身份基方案）在5G基站认证中的网络级性能进行全面表征分析，并提出基于分层身份基阈值签名方案的BORG解决方案，具有故障停止特性。

Result: 研究发现直接采用后量子密码受到协议约束和大签名尺寸的限制，传统方法因证书链开销存在性能限制。BORG方案通过阈值签名和紧凑签名提供分布式信任，适合5G的严格要求。

Conclusion: 直接集成后量子密码在5G认证中不可行，BORG作为有效的过渡解决方案，为未来量子弹性5G认证提供了可行路径。

Abstract: The 5G protocol lacks a robust base station authentication mechanism during
the initial bootstrapping phase, leaving it susceptible to threats such as fake
base station attacks. Conventional solutions, including digital signatures
based on Public Key Infrastructures (PKIs) and identity-based signatures, are
inadequate against quantum-capable adversaries. While integrating NIST's
Post-Quantum Cryptography (PQC) standards is a leading approach for quantum
resistance, their suitability for 5G base station authentication remains
unexplored. Moreover, current solutions are predominantly centralized and lack
security features such as distributed authentication. This work presents, to
our knowledge, the first comprehensive network-level performance
characterization of integrating NIST-PQC standards and conventional digital
signatures (including threshold and identity-based schemes) into 5G base
station authentication. Our findings reveal significant feasibility concerns,
with direct PQC adoption hindered by protocol constraints and large signature
sizes. We also highlight the performance limitations of conventional methods
due to the overhead of certificate chains. To mitigate these challenges, we
propose BORG, a transitional authentication solution based on a Hierarchical
Identity-Based Threshold Signature scheme with a Fail-Stop property. BORG
offers post-mortem post-quantum forgery detection and distributed trust via
threshold and compact signatures, well-suited for 5G's stringent requirements.
Our performance analysis underscores an important warning on the infeasibility
of direct PQC integration and positions BORG as an effective transitional
solution toward future quantum-resilient 5G authentication.

</details>


### [37] [Towards a Functionally Complete and Parameterizable TFHE Processor](https://arxiv.org/abs/2510.23483)
*Valentin Reyes Häusler,Gabriel Ott,Aruna Jayasena,Andreas Peter*

Main category: cs.CR

TL;DR: 提出基于FPGA的TFHE全同态加密硬件加速器，通过改进的可编程自举模块将性能提升240%-480%，解决TFHE计算开销高的问题


<details>
  <summary>Details</summary>
Motivation: TFHE全同态加密虽然自举操作快，但同态电路评估计算开销大，比未加密计算慢几个数量级，阻碍了其广泛应用。现有实现受限于高内存带宽成本，需要硬件加速方案

Method: 设计基于FPGA的TFHE处理器，实现完全在FPGA上处理数据的指令执行，特别改进了可编程自举模块以提升吞吐量

Result: 改进的自举模块比现有最优方案每秒能处理240%-480%更多的自举操作，实现了高效、紧凑且可扩展的设计

Conclusion: 该FPGA加速器为构建完整的TFHE处理器架构奠定了基础，解决了TFHE计算性能瓶颈问题

Abstract: Fully homomorphic encryption allows the evaluation of arbitrary functions on
encrypted data. It can be leveraged to secure outsourced and multiparty
computation. TFHE is a fast torus-based fully homomorphic encryption scheme
that allows both linear operations, as well as the evaluation of arbitrary
non-linear functions. It currently provides the fastest bootstrapping operation
performance of any other FHE scheme. Despite its fast performance, TFHE suffers
from a considerably higher computational overhead for the evaluation of
homomorphic circuits. Computations in the encrypted domain are orders of
magnitude slower than their unencrypted equivalents. This bottleneck hinders
the widespread adoption of (T)FHE for the protection of sensitive data. While
state-of-the-art implementations focused on accelerating and outsourcing single
operations, their scalability and practicality are constrained by high memory
bandwidth costs. In order to overcome this, we propose an FPGA-based hardware
accelerator for the evaluation of homomorphic circuits. Specifically, we design
a functionally complete TFHE processor for FPGA hardware capable of processing
instructions on the data completely on the FPGA. In order to achieve a higher
throughput from our TFHE processor, we implement an improved programmable
bootstrapping module which outperforms the current state-of-the-art by 240\% to
480\% more bootstrappings per second. Our efficient, compact, and scalable
design lays the foundation for implementing complete FPGA-based TFHE processor
architectures.

</details>
