{"id": "2509.08083", "categories": ["cs.CR"], "pdf": "https://arxiv.org/pdf/2509.08083", "abs": "https://arxiv.org/abs/2509.08083", "authors": ["Laurie Williams", "Sammy Migues"], "title": "Establishing a Baseline of Software Supply Chain Security Task Adoption by Software Organizations", "comment": null, "summary": "Software supply chain attacks have increased exponentially since 2020. The\nprimary attack vectors for supply chain attacks are through: (1) software\ncomponents; (2) the build infrastructure; and (3) humans (a.k.a software\npractitioners). Software supply chain risk management frameworks provide a list\nof tasks that an organization can adopt to reduce software supply chain risk.\nExhaustively adopting all the tasks of these frameworks is infeasible,\nnecessitating the prioritized adoption of tasks. Software organizations can\nbenefit from being guided in this prioritization by learning what tasks other\nteams have adopted. The goal of this study is to aid software development\norganizations in understanding the adoption of security tasks that reduce\nsoftware supply chain risk through an interview study of software practitioners\nengaged in software supply chain risk management efforts. An interview study\nwas conducted with 61 practitioners at nine software development organizations\nthat have focused efforts on reducing software supply chain risk. The results\nof the interviews indicate that organizations had implemented the most adopted\nsoftware tasks before the focus on software supply chain security. Therefore,\ntheir implementation in organizations is more mature. The tasks that mitigate\nthe novel attack vectors through software components and the build\ninfrastructure are in the early stages of adoption. Adoption of these tasks\nshould be prioritized."}
{"id": "2509.08091", "categories": ["cs.CR"], "pdf": "https://arxiv.org/pdf/2509.08091", "abs": "https://arxiv.org/abs/2509.08091", "authors": ["Jing Chen", "Onat Gungor", "Zhengli Shang", "Tajana Rosing"], "title": "SAGE: Sample-Aware Guarding Engine for Robust Intrusion Detection Against Adversarial Attacks", "comment": "Under review at IEEE TIFS", "summary": "The rapid proliferation of the Internet of Things (IoT) continues to expose\ncritical security vulnerabilities, necessitating the development of efficient\nand robust intrusion detection systems (IDS). Machine learning-based intrusion\ndetection systems (ML-IDS) have significantly improved threat detection\ncapabilities; however, they remain highly susceptible to adversarial attacks.\nWhile numerous defense mechanisms have been proposed to enhance ML-IDS\nresilience, a systematic approach for selecting the most effective defense\nagainst a specific adversarial attack remains absent. To address this\nchallenge, we previously proposed DYNAMITE, a dynamic defense selection\napproach that identifies the most suitable defense against adversarial attacks\nthrough an ML-driven selection mechanism. Building on this foundation, we\npropose SAGE (Sample-Aware Guarding Engine), a substantially improved defense\nalgorithm that integrates active learning with targeted data reduction. It\nemploys an active learning mechanism to selectively identify the most\ninformative input samples and their corresponding optimal defense labels, which\nare then used to train a second-level learner responsible for selecting the\nmost effective defense. This targeted sampling improves computational\nefficiency, exposes the model to diverse adversarial strategies during\ntraining, and enhances robustness, stability, and generalizability. As a\nresult, SAGE demonstrates strong predictive performance across multiple\nintrusion detection datasets, achieving an average F1-score improvement of 201%\nover the state-of-the-art defenses. Notably, SAGE narrows the performance gap\nto the Oracle to just 3.8%, while reducing computational overhead by up to 29x."}
{"id": "2509.08200", "categories": ["cs.CR", "cs.AI", "cs.CY"], "pdf": "https://arxiv.org/pdf/2509.08200", "abs": "https://arxiv.org/abs/2509.08200", "authors": ["William Cashman", "Chasen Milner", "Michael Houle", "Michael Jones", "Hayden Jananthan", "Jeremy Kepner", "Peter Michaleas", "Alex Pentland"], "title": "Accelerating AI Development with Cyber Arenas", "comment": "2 pages, 1 figure, 7 references, accepted to IEEE HPEC 2025", "summary": "AI development requires high fidelity testing environments to effectively\ntransition from the laboratory to operations. The flexibility offered by cyber\narenas presents a novel opportunity to test new artificial intelligence (AI)\ncapabilities with users. Cyber arenas are designed to expose end-users to\nreal-world situations and must rapidly incorporate evolving capabilities to\nmeet their core objectives. To explore this concept the MIT/IEEE/Amazon Graph\nChallenge Anonymized Network Sensor was deployed in a cyber arena during a\nNational Guard exercise."}
{"id": "2509.08204", "categories": ["cs.CR", "cs.SE"], "pdf": "https://arxiv.org/pdf/2509.08204", "abs": "https://arxiv.org/abs/2509.08204", "authors": ["Behnaz Hassanshahi", "Trong Nhan Mai", "Benjamin Selwyn Smith", "Nicholas Allen"], "title": "Unlocking Reproducibility: Automating re-Build Process for Open-Source Software", "comment": null, "summary": "Software ecosystems like Maven Central play a crucial role in modern software\nsupply chains by providing repositories for libraries and build plugins.\nHowever, the separation between binaries and their corresponding source code in\nMaven Central presents a significant challenge, particularly when it comes to\nlinking binaries back to their original build environment. This lack of\ntransparency poses security risks, as approximately 84% of the top 1200\ncommonly used artifacts are not built using a transparent CI/CD pipeline.\nConsequently, users must place a significant amount of trust not only in the\nsource code but also in the environment in which these artifacts are built.\n  Rebuilding software artifacts from source provides a robust solution to\nimprove supply chain security. This approach allows for a deeper review of\ncode, verification of binary-source equivalence, and control over dependencies.\nHowever, challenges arise due to variations in build environments, such as JDK\nversions and build commands, which can lead to build failures. Additionally,\nensuring that all dependencies are rebuilt from source across large and complex\ndependency graphs further complicates the process. In this paper, we introduce\nan extension to Macaron, an industry-grade open-source supply chain security\nframework, to automate the rebuilding of Maven artifacts from source. Our\napproach improves upon existing tools, by offering better performance in source\ncode detection and automating the extraction of build specifications from\nGitHub Actions workflows. We also present a comprehensive root cause analysis\nof build failures in Java projects and propose a scalable solution to automate\nthe rebuilding of artifacts, ultimately enhancing security and transparency in\nthe open-source supply chain."}
{"id": "2509.08248", "categories": ["cs.CR", "cs.NI"], "pdf": "https://arxiv.org/pdf/2509.08248", "abs": "https://arxiv.org/abs/2509.08248", "authors": ["Arin Upadhyay"], "title": "EFPIX: A zero-trust encrypted flood protocol", "comment": null, "summary": "We propose a flood-based relay communication protocol that achieves\nend-to-end encryption, plausible deniability for users, and untraceable\nmessages. It is resistant to changes in topology and infrastructure failures.\nIt is also designed to hide metadata, such as sender and receiver, from those\nnot involved."}
{"id": "2509.08364", "categories": ["cs.CR"], "pdf": "https://arxiv.org/pdf/2509.08364", "abs": "https://arxiv.org/abs/2509.08364", "authors": ["Aduma Rishith", "Aditya Kulkarni", "Tamal Das", "Vivek Balachandran"], "title": "Overcoming DNSSEC Islands of Security: A TLS and IP-Based Certificate Solution", "comment": null, "summary": "The Domain Name System (DNS) serves as the backbone of the Internet,\nprimarily translating domain names to IP addresses. Over time, various\nenhancements have been introduced to strengthen the integrity of DNS. Among\nthese, DNSSEC stands out as a leading cryptographic solution. It protects\nagainst attacks (such as DNS spoofing) by establishing a chain of trust\nthroughout the DNS nameserver hierarchy. However, DNSSEC's effectiveness is\ncompromised when there is a break in this chain, resulting in \"Islands of\nSecurity\", where domains can authenticate locally but not across hierarchical\nlevels, leading to a loss of trust and validation between them. Leading\napproaches to addressing these issues were centralized, with a single authority\nmaintaining some kind of bulletin board. This approach requires significantly\nmore infrastructure and places excessive trust in the entity responsible for\nmanaging it properly. In this paper, we propose a decentralized approach to\naddressing gaps in DNSSEC's chain of trust, commonly referred to as \"Islands of\nSecurity\". We leverage TLS and IP-based certificates to enable end-to-end\nauthentication between hierarchical levels, eliminating the need for uniform\nDNSSEC deployment across every level of the DNS hierarchy. This approach\nenhances the overall integrity of DNSSEC, while reducing dependence on\nregistrars for maintaining signature records to verify the child nameserver's\nauthenticity. By offering a more flexible and efficient solution, our method\nstrengthens DNS security and streamlines deployment across diverse\nenvironments."}
{"id": "2509.08375", "categories": ["cs.CR"], "pdf": "https://arxiv.org/pdf/2509.08375", "abs": "https://arxiv.org/abs/2509.08375", "authors": ["Duddu Hriday", "Aditya Kulkarni", "Vivek Balachandran", "Tamal Das"], "title": "Phish-Blitz: Advancing Phishing Detection with Comprehensive Webpage Resource Collection and Visual Integrity Preservation", "comment": null, "summary": "Phishing attacks are increasingly prevalent, with adversaries creating\ndeceptive webpages to steal sensitive information. Despite advancements in\nmachine learning and deep learning for phishing detection, attackers constantly\ndevelop new tactics to bypass detection models. As a result, phishing webpages\ncontinue to reach users, particularly those unable to recognize phishing\nindicators. To improve detection accuracy, models must be trained on large\ndatasets containing both phishing and legitimate webpages, including URLs,\nwebpage content, screenshots, and logos. However, existing tools struggle to\ncollect the required resources, especially given the short lifespan of phishing\nwebpages, limiting dataset comprehensiveness. In response, we introduce\nPhish-Blitz, a tool that downloads phishing and legitimate webpages along with\ntheir associated resources, such as screenshots. Unlike existing tools,\nPhish-Blitz captures live webpage screenshots and updates resource file paths\nto maintain the original visual integrity of the webpage. We provide a dataset\ncontaining 8,809 legitimate and 5,000 phishing webpages, including all\nassociated resources. Our dataset and tool are publicly available on GitHub,\ncontributing to the research community by offering a more complete dataset for\nphishing detection."}
{"id": "2509.08399", "categories": ["cs.CR"], "pdf": "https://arxiv.org/pdf/2509.08399", "abs": "https://arxiv.org/abs/2509.08399", "authors": ["Abdou-Essamad Jabri", "Mostafa Azizi", "Cyril Drocourt", "Gil Utard"], "title": "MIoT-Driven Comparison of Open Blockchain Platforms", "comment": null, "summary": "Being propelled by the fourth industrial revolution (Industry 4.0), IoT\ndevices and solutions are well adopted everywhere, ranging from home\napplications to industrial use, crossing through transportation, healthcare,\nenergy, and so on. This wide use of IoT has not gone unnoticed, hackers are\ntracking the weakness of such a technology and threatening them continuously.\nTheir security at various levels has become an important concern of\nprofessionals and researchers. This issue takes more risk, especially with the\nIoT variants, IIoT (Industrial IoT) and MIoT (Medical IoT). Many existing\nsecurity solutions are adapted and proposed for addressing IoT security. In\nthis paper, we are interested in exploring blockchain technology and we make a\ncomparison of three free Blockchain platforms towards their applicability for\nMIoT context, namely Ethereum, Hyperledger Fabric and Corda. In general,\nBlockchain technology provides a decentralized, autonomous, trustless, and\ndistributed environment. It is challenging to find a Blockchain platform that\nfits the MIoT context and performs well in terms of security. The retained\nplatform should be deployed smartly to avoid its practical drawbacks related to\nenergy-consuming and excessive computing."}
{"id": "2509.08402", "categories": ["cs.CR"], "pdf": "https://arxiv.org/pdf/2509.08402", "abs": "https://arxiv.org/abs/2509.08402", "authors": ["Abdou-Essamad Jabri", "C. Drocourt", "Mostafa Azizi", "Gil Utard"], "title": "Leveraging Blockchain and Proxy Re-Encryption to secure Medical IoT Records", "comment": null, "summary": "The integration of the Internet of Things (IoT) in healthcare has\nrevolutionized patient monitoring and data collection, allowing real-time\ntracking of vital signs, remote diagnostics, and automated medical responses.\nHowever, the transmission and storage of sensitive medical data introduce\nsignificant security and privacy challenges. To address these concerns,\nblockchain technology provides a decentralized and immutable ledger that\nensures data integrity, , and transparency. Unlike public blockchains, private\nblockchains are permissioned; the access is granted only to authorized\nparticipants; they are more suitable for handling confidential healthcare data.\nAlthough blockchain ensures security and trust, it lacks built-in mechanisms to\nsupport flexible and controlled data sharing; This is where Proxy Re-Encryption\n(PRE) comes into play. PRE is a cryptographic technique that allows encrypted\ndata to be re-encrypted for a new recipient without exposing it to\nintermediaries. We propose an architecture integrating private blockchain and\nPRE to enable secure, traceable, and privacy-preserving data sharing in\nIoT-based healthcare systems. Blockchain guarantees tamper proof\nrecord-keeping, while PRE enables fine-grained access control, allowing medical\nprofessionals to securely share patient data without compromising\nconfidentiality. This combination creates a robust security framework that\nenhances trust and efficiency in digital healthcare ecosystems."}
{"id": "2509.08424", "categories": ["cs.CR"], "pdf": "https://arxiv.org/pdf/2509.08424", "abs": "https://arxiv.org/abs/2509.08424", "authors": ["Aditya Kulkarni", "Vivek Balachandran", "Tamal Das"], "title": "Phishing Webpage Detection: Unveiling the Threat Landscape and Investigating Detection Techniques", "comment": null, "summary": "In the realm of cybersecurity, phishing stands as a prevalent cyber attack,\nwhere attackers employ various tactics to deceive users into gathering their\nsensitive information, potentially leading to identity theft or financial gain.\nResearchers have been actively working on advancing phishing webpage detection\napproaches to detect new phishing URLs, bolstering user protection.\nNonetheless, the ever-evolving strategies employed by attackers, aimed at\ncircumventing existing detection approaches and tools, present an ongoing\nchallenge to the research community. This survey presents a systematic\ncategorization of diverse phishing webpage detection approaches, encompassing\nURL-based, webpage content-based, and visual techniques. Through a\ncomprehensive review of these approaches and an in-depth analysis of existing\nliterature, our study underscores current research gaps in phishing webpage\ndetection. Furthermore, we suggest potential solutions to address some of these\ngaps, contributing valuable insights to the ongoing efforts to combat phishing\nattacks."}
{"id": "2509.08449", "categories": ["cs.CR", "cs.AI", "cs.DC"], "pdf": "https://arxiv.org/pdf/2509.08449", "abs": "https://arxiv.org/abs/2509.08449", "authors": ["Charuka Herath", "Yogachandran Rahulamathavan", "Varuna De Silva", "Sangarapillai Lambotharan"], "title": "DSFL: A Dual-Server Byzantine-Resilient Federated Learning Framework via Group-Based Secure Aggregation", "comment": null, "summary": "Federated Learning (FL) enables decentralized model training without sharing\nraw data, offering strong privacy guarantees. However, existing FL protocols\nstruggle to defend against Byzantine participants, maintain model utility under\nnon-independent and identically distributed (non-IID) data, and remain\nlightweight for edge devices. Prior work either assumes trusted hardware, uses\nexpensive cryptographic tools, or fails to address privacy and robustness\nsimultaneously. We propose DSFL, a Dual-Server Byzantine-Resilient Federated\nLearning framework that addresses these limitations using a group-based secure\naggregation approach. Unlike LSFL, which assumes non-colluding semi-honest\nservers, DSFL removes this dependency by revealing a key vulnerability: privacy\nleakage through client-server collusion. DSFL introduces three key innovations:\n(1) a dual-server secure aggregation protocol that protects updates without\nencryption or key exchange, (2) a group-wise credit-based filtering mechanism\nto isolate Byzantine clients based on deviation scores, and (3) a dynamic\nreward-penalty system for enforcing fair participation. DSFL is evaluated on\nMNIST, CIFAR-10, and CIFAR-100 under up to 30 percent Byzantine participants in\nboth IID and non-IID settings. It consistently outperforms existing baselines,\nincluding LSFL, homomorphic encryption methods, and differential privacy\napproaches. For example, DSFL achieves 97.15 percent accuracy on CIFAR-10 and\n68.60 percent on CIFAR-100, while FedAvg drops to 9.39 percent under similar\nthreats. DSFL remains lightweight, requiring only 55.9 ms runtime and 1088 KB\ncommunication per round."}
{"id": "2509.08485", "categories": ["cs.CR"], "pdf": "https://arxiv.org/pdf/2509.08485", "abs": "https://arxiv.org/abs/2509.08485", "authors": ["Priyanka Rushikesh Chaudhary", "Rajib Ranjan Maiti"], "title": "Flow-Based Detection and Identification of Zero-Day IoT Cameras", "comment": null, "summary": "The majority of consumer IoT devices lack mechanisms for administrators to\nmonitor and control them, hindering tailored security policies. A key challenge\nis identifying whether a new device, especially a streaming IoT camera, has\njoined the network. We present zCamInspector, a system for identifying known\nIoT cameras with supervised classifiers (zCamClassifier) and detecting zero-day\ncameras with one-class classifiers (zCamDetector). We analyzed ~40GB of traffic\nacross three datasets: Set I (six commercial IoT cameras), Set II (five\nopen-source IoT cameras, ~1.5GB), and Set III (four conferencing and two\nvideo-sharing applications as non-IoT traffic). From each, 62 flow-based\nfeatures were extracted using CICFlowmeter. zCamInspector employs seven\nsupervised models (ET, DT, RF, KNN, XGB, LKSVM, GNB) and four one-class models\n(OCSVM, SGDOCSVM, IF, DeepSVDD). Results show that XGB identifies IoT cameras\nwith >99% accuracy and false negatives as low as 0.3%, outperforming\nstate-of-the-art methods. For zero-day detection, accuracies reached 93.20%\n(OCSVM), 96.55% (SGDOCSVM), 78.65% (IF), and 92.16% (DeepSVDD). When all\ndevices were treated as zero-day, DeepSVDD performed best with mean\ntraining/testing accuracies of 96.03%/74.51%. zCamInspector also achieved >95%\naccuracy for specific devices, such as Spy Clock cameras, demonstrating its\nrobustness for identifying and detecting zero-day IoT cameras in diverse\nnetwork environments."}
{"id": "2509.08493", "categories": ["cs.CR", "cs.AI", "K.6.5; I.2.7"], "pdf": "https://arxiv.org/pdf/2509.08493", "abs": "https://arxiv.org/abs/2509.08493", "authors": ["Hossein Siadati", "Haadi Jafarian", "Sima Jafarikhah"], "title": "Send to which account? Evaluation of an LLM-based Scambaiting System", "comment": null, "summary": "Scammers are increasingly harnessing generative AI(GenAI) technologies to\nproduce convincing phishing content at scale, amplifying financial fraud and\nundermining public trust. While conventional defenses, such as detection\nalgorithms, user training, and reactive takedown efforts remain important, they\noften fall short in dismantling the infrastructure scammers depend on,\nincluding mule bank accounts and cryptocurrency wallets. To bridge this gap, a\nproactive and emerging strategy involves using conversational honeypots to\nengage scammers and extract actionable threat intelligence. This paper presents\nthe first large-scale, real-world evaluation of a scambaiting system powered by\nlarge language models (LLMs). Over a five-month deployment, the system\ninitiated over 2,600 engagements with actual scammers, resulting in a dataset\nof more than 18,700 messages. It achieved an Information Disclosure Rate (IDR)\nof approximately 32%, successfully extracting sensitive financial information\nsuch as mule accounts. Additionally, the system maintained a Human Acceptance\nRate (HAR) of around 70%, indicating strong alignment between LLM-generated\nresponses and human operator preferences. Alongside these successes, our\nanalysis reveals key operational challenges. In particular, the system\nstruggled with engagement takeoff: only 48.7% of scammers responded to the\ninitial seed message sent by defenders. These findings highlight the need for\nfurther refinement and provide actionable insights for advancing the design of\nautomated scambaiting systems."}
{"id": "2509.08646", "categories": ["cs.CR", "cs.AI", "cs.SY", "eess.SY"], "pdf": "https://arxiv.org/pdf/2509.08646", "abs": "https://arxiv.org/abs/2509.08646", "authors": ["Ron F. Del Rosario", "Klaudia Krawiecka", "Christian Schroeder de Witt"], "title": "Architecting Resilient LLM Agents: A Guide to Secure Plan-then-Execute Implementations", "comment": null, "summary": "As Large Language Model (LLM) agents become increasingly capable of\nautomating complex, multi-step tasks, the need for robust, secure, and\npredictable architectural patterns is paramount. This paper provides a\ncomprehensive guide to the ``Plan-then-Execute'' (P-t-E) pattern, an agentic\ndesign that separates strategic planning from tactical execution. We explore\nthe foundational principles of P-t-E, detailing its core components - the\nPlanner and the Executor - and its architectural advantages in predictability,\ncost-efficiency, and reasoning quality over reactive patterns like ReAct\n(Reason + Act). A central focus is placed on the security implications of this\ndesign, particularly its inherent resilience to indirect prompt injection\nattacks by establishing control-flow integrity. We argue that while P-t-E\nprovides a strong foundation, a defense-in-depth strategy is necessary, and we\ndetail essential complementary controls such as the Principle of Least\nPrivilege, task-scoped tool access, and sandboxed code execution. To make these\nprinciples actionable, this guide provides detailed implementation blueprints\nand working code references for three leading agentic frameworks: LangChain\n(via LangGraph), CrewAI, and AutoGen. Each framework's approach to implementing\nthe P-t-E pattern is analyzed, highlighting unique features like LangGraph's\nstateful graphs for re-planning, CrewAI's declarative tool scoping for\nsecurity, and AutoGen's built-in Docker sandboxing. Finally, we discuss\nadvanced patterns, including dynamic re-planning loops, parallel execution with\nDirected Acyclic Graphs (DAGs), and the critical role of Human-in-the-Loop\n(HITL) verification, to offer a complete strategic blueprint for architects,\ndevelopers, and security engineers aiming to build production-grade, resilient,\nand trustworthy LLM agents."}
{"id": "2509.08704", "categories": ["cs.CR"], "pdf": "https://arxiv.org/pdf/2509.08704", "abs": "https://arxiv.org/abs/2509.08704", "authors": ["Zihang Xiang", "Tianhao Wang", "Hanshen Xiao", "Yuan Tian", "Di Wang"], "title": "Tight Privacy Audit in One Run", "comment": null, "summary": "In this paper, we study the problem of privacy audit in one run and show that\nour method achieves tight audit results for various differentially private\nprotocols. This includes obtaining tight results for auditing\n$(\\varepsilon,\\delta)$-DP algorithms where all previous work fails to achieve\nin any parameter setups. We first formulate a framework for privacy audit\n\\textit{in one run} with refinement compared with previous work. Then, based on\nmodeling privacy by the $f$-DP formulation, we study the implications of our\nframework to obtain a theoretically justified lower bound for privacy audit. In\nthe experiment, we compare with previous work and show that our audit method\noutperforms the rest in auditing various differentially private algorithms. We\nalso provide experiments that give contrasting conclusions to previous work on\nthe parameter settings for privacy audits in one run."}
{"id": "2509.08720", "categories": ["cs.CR"], "pdf": "https://arxiv.org/pdf/2509.08720", "abs": "https://arxiv.org/abs/2509.08720", "authors": ["Ruiyao Liu", "Chenxi Qiu"], "title": "PAnDA: Rethinking Metric Differential Privacy Optimization at Scale with Anchor-Based Approximation", "comment": "In Proceedings of the 32nd ACM Conference on Computer and\n  Communications Security (CCS 2025)", "summary": "Metric Differential Privacy (mDP) extends the local differential privacy\n(LDP) framework to metric spaces, enabling more nuanced privacy protection for\ndata such as geo-locations. However, existing mDP optimization methods,\nparticularly those based on linear programming (LP), face scalability\nchallenges due to the quadratic growth in decision variables. In this paper, we\npropose Perturbation via Anchor-based Distributed Approximation (PAnDA), a\nscalable two-phase framework for optimizing metric differential privacy (mDP).\nTo reduce computational overhead, PAnDA allows each user to select a small set\nof anchor records, enabling the server to solve a compact linear program over a\nreduced domain. We introduce three anchor selection strategies, exponential\ndecay (PAnDA-e), power-law decay (PAnDA-p), and logistic decay (PAnDA-l), and\nestablish theoretical guarantees under a relaxed privacy notion called\nprobabilistic mDP (PmDP). Experiments on real-world geo-location datasets\ndemonstrate that PAnDA scales to secret domains with up to 5,000 records, two\ntimes larger than prior LP-based methods, while providing theoretical\nguarantees for both privacy and utility."}
{"id": "2509.08722", "categories": ["cs.CR"], "pdf": "https://arxiv.org/pdf/2509.08722", "abs": "https://arxiv.org/abs/2509.08722", "authors": ["Zihan Liu", "Xiaohu Wang", "Chao Lin", "Minghui Xu", "Debiao He", "Xinyi Huang"], "title": "SilentLedger: Privacy-Preserving Auditing for Blockchains with Complete Non-Interactivity", "comment": null, "summary": "Privacy-preserving blockchain systems are essential for protecting\ntransaction data, yet they must also provide auditability that enables auditors\nto recover participant identities and transaction amounts when warranted.\nExisting designs often compromise the independence of auditing and\ntransactions, introducing extra interactions that undermine usability and\nscalability. Moreover, many auditable solutions depend on auditors serving as\nvalidators or recording nodes, which introduces risks to both data security and\nsystem reliability.\n  To overcome these challenges, we propose SilentLedger, a privacy-preserving\ntransaction system with auditing and complete non-interactivity. To support\npublic verification of authorization, we introduce a renewable anonymous\ncertificate scheme with formal semantics and a rigorous security model.\nSilentLedger further employs traceable transaction mechanisms constructed from\nestablished cryptographic primitives, enabling users to transact without\ninteraction while allowing auditors to audit solely from on-chain data. We\nformally prove security properties including authenticity, anonymity,\nconfidentiality, and soundness, provide a concrete instantiation, and evaluate\nperformance under a standard 2-2 transaction model. Our implementation and\nbenchmarks demonstrate that SilentLedger achieves superior performance compared\nwith state-of-the-art solutions."}
{"id": "2509.08727", "categories": ["cs.CR", "cs.AR", "cs.PL"], "pdf": "https://arxiv.org/pdf/2509.08727", "abs": "https://arxiv.org/abs/2509.08727", "authors": ["Shixin Song", "Tingzhen Dong", "Kosi Nwabueze", "Julian Zanders", "Andres Erbsen", "Adam Chlipala", "Mengjia Yan"], "title": "Securing Cryptographic Software via Typed Assembly Language (Extended Version)", "comment": null, "summary": "Authors of cryptographic software are well aware that their code should not\nleak secrets through its timing behavior, and, until 2018, they believed that\nfollowing industry-standard constant-time coding guidelines was sufficient.\nHowever, the revelation of the Spectre family of speculative execution attacks\ninjected new complexities.\n  To block speculative attacks, prior work has proposed annotating the\nprogram's source code to mark secret data, with hardware using this information\nto decide when to speculate (i.e., when only public values are involved) or not\n(when secrets are in play). While these solutions are able to track secret\ninformation stored on the heap, they suffer from limitations that prevent them\nfrom correctly tracking secrets on the stack, at a cost in performance.\n  This paper introduces SecSep, a transformation framework that rewrites\nassembly programs so that they partition secret and public data on the stack.\nBy moving from the source-code level to assembly rewriting, SecSep is able to\naddress limitations of prior work. The key challenge in performing this\nassembly rewriting stems from the loss of semantic information through the\nlengthy compilation process. The key innovation of our methodology is a new\nvariant of typed assembly language (TAL), Octal, which allows us to address\nthis challenge. Assembly rewriting is driven by compile-time inference within\nOctal. We apply our technique to cryptographic programs and demonstrate that it\nenables secure speculation efficiently, incurring a low average overhead of\n$1.2\\%$."}
{"id": "2509.08740", "categories": ["cs.CR", "cs.DB"], "pdf": "https://arxiv.org/pdf/2509.08740", "abs": "https://arxiv.org/abs/2509.08740", "authors": ["Sam Kumar", "Samyukta Yagati", "Conor Power", "David E. Culler", "Raluca Ada Popa"], "title": "Membrane: A Cryptographic Access Control System for Data Lakes", "comment": "28 pages, 25 figures", "summary": "Organizations use data lakes to store and analyze sensitive data. But hackers\nmay compromise data lake storage to bypass access controls and access sensitive\ndata. To address this, we propose Membrane, a system that (1) cryptographically\nenforces data-dependent access control views over a data lake, (2) without\nrestricting the analytical queries data scientists can run. We observe that\ndata lakes, unlike DBMSes, disaggregate computation and storage into separate\ntrust domains, making at-rest encryption sufficient to defend against remote\nattackers targeting data lake storage, even when running analytical queries in\nplaintext. This leads to a new system design for Membrane that combines\nencryption at rest with SQL-aware encryption. Using block ciphers, a fast\nsymmetric-key primitive with hardware acceleration in CPUs, we develop a new\nSQL-aware encryption protocol well-suited to at-rest encryption. Membrane adds\noverhead only at the start of an interactive session due to decrypting views,\ndelaying the first query result by up to $\\approx 20\\times$; subsequent queries\nprocess decrypted data in plaintext, resulting in low amortized overhead."}
{"id": "2509.08746", "categories": ["cs.CR"], "pdf": "https://arxiv.org/pdf/2509.08746", "abs": "https://arxiv.org/abs/2509.08746", "authors": ["Ryan McGaughey", "Jesus Martinez del Rincon", "Ihsen Alouani"], "title": "Stealth by Conformity: Evading Robust Aggregation through Adaptive Poisoning", "comment": "16 pages, 12 figures", "summary": "Federated Learning (FL) is a distributed learning paradigm designed to\naddress privacy concerns. However, FL is vulnerable to poisoning attacks, where\nByzantine clients compromise the integrity of the global model by submitting\nmalicious updates. Robust aggregation methods have been widely adopted to\nmitigate such threats, relying on the core assumption that malicious updates\nare inherently out-of-distribution and can therefore be identified and excluded\nbefore aggregating client updates. In this paper, we challenge this underlying\nassumption by showing that a model can be poisoned while keeping malicious\nupdates within the main distribution. We propose Chameleon Poisoning (CHAMP),\nan adaptive and evasive poisoning strategy that exploits side-channel feedback\nfrom the aggregation process to guide the attack. Specifically, the adversary\ncontinuously infers whether its malicious contribution has been incorporated\ninto the global model and adapts accordingly. This enables a dynamic adjustment\nof the local loss function, balancing a malicious component with a camouflaging\ncomponent, thereby increasing the effectiveness of the poisoning while evading\nrobust aggregation defenses. CHAMP enables more effective and evasive\npoisoning, highlighting a fundamental limitation of existing robust aggregation\ndefenses and underscoring the need for new strategies to secure federated\nlearning against sophisticated adversaries. Our approach is evaluated in two\ndatasets reaching an average increase of 47.07% in attack success rate against\nnine robust aggregation defenses."}
{"id": "2509.08747", "categories": ["cs.CR"], "pdf": "https://arxiv.org/pdf/2509.08747", "abs": "https://arxiv.org/abs/2509.08747", "authors": ["Wei Guo", "Maura Pintor", "Ambra Demontis", "Battista Biggio"], "title": "Silent Until Sparse: Backdoor Attacks on Semi-Structured Sparsity", "comment": null, "summary": "In the deployment phase, semi-structured sparsity accelerates the execution\nof deep neural networks on modern GPUs via sparse matrix multiplication. In\nthis paper, targeting the semi-structured sparsity, we introduce a Silent Until\nSparse (SUS) backdoor attack, where the released full model remains silent\n(benign), but becomes a backdoored model after sparsification. The attack\noperates in two phases: (i) in the backdoor training phase, the backdoor\nfunctionality is injected into specific weights that will be retained during\nthe pruning process; (ii) in the backdoor hiding phase, the malicious behavior\nis concealed by fine-tuning elements that will be pruned away. This dual-phase\napproach ensures that the attack remains undetectable in the released model,\nbut activates properly once the model is pruned with the semi-structured\nsparsity. Through extensive experiments, we show that our attack successfully\nthreatens the semi-structured sparsity algorithms from both NVIDIA and PyTorch.\nOur empirical results show that, regardless of model architecture, the attack\nsuccess rate of the released model remains below 10% prior to sparsification\nbut exceeds 99% afterward. Moreover, we demonstrate that SUS attack is robust\nagainst state-of-the-art backdoor defenses and finetuning, highlighting a\ncritical vulnerability in current model compression and deployment pipelines."}
{"id": "2509.08748", "categories": ["cs.CR"], "pdf": "https://arxiv.org/pdf/2509.08748", "abs": "https://arxiv.org/abs/2509.08748", "authors": ["Wei Guo", "Maura Pintor", "Ambra Demontis", "Battista Biggio"], "title": "Prototype-Guided Robust Learning against Backdoor Attacks", "comment": null, "summary": "Backdoor attacks poison the training data to embed a backdoor in the model,\ncausing it to behave normally on legitimate inputs but maliciously when\nspecific trigger signals appear. Training a benign model from a dataset\npoisoned by backdoor attacks is challenging. Existing works rely on various\nassumptions and can only defend against backdoor attacks with specific trigger\nsignals, high poisoning ratios, or when the defender possesses a large,\nuntainted, validation dataset. In this paper, we propose a defense called\nPrototype-Guided Robust Learning (PGRL), which overcomes all the aforementioned\nlimitations, being robust against diverse backdoor attacks. Leveraging a tiny\nset of benign samples, PGRL generates prototype vectors to guide the training\nprocess. We compare our PGRL with 8 existing defenses, showing that it achieves\nsuperior robustness. We also demonstrate that PGRL generalizes well across\nvarious architectures, datasets, and advanced attacks. Finally, to evaluate our\nPGRL in the worst-case scenario, we perform an adaptive attack, where the\nattackers fully know the details of the defense."}
{"id": "2509.08758", "categories": ["cs.CR"], "pdf": "https://arxiv.org/pdf/2509.08758", "abs": "https://arxiv.org/abs/2509.08758", "authors": ["Markus Scherer", "Jeppe Fredsgaard Blaabjerg", "Alexander Sj√∂sten", "Matteo Maffei"], "title": "Wanilla: Sound Noninterference Analysis for WebAssembly", "comment": null, "summary": "WebAssembly (Wasm) is rapidly gaining popularity as a distribution format for\nsoftware components embedded in various security-critical domains.\nUnfortunately, despite its prudent design, WebAssembly's primary use case as a\ncompilation target for memory-unsafe languages leaves some possibilities for\nmemory corruption. Independently of that, Wasm is an inherently interesting\ntarget for information flow analysis due to its interfacing role.\n  Both the information flows between a Wasm module and its embedding context,\nas well as the memory integrity within a module, can be described by the\nhyperproperty noninterference. So far, no sound, fully static noninterference\nanalysis for Wasm has been presented, but sound reachability analyses were.\nThis work presents a novel and general approach to lift reachability analyses\nto noninterference by tracking taints on values and using value-sensitive,\nrelational reasoning to remove them when appropriate. We implement this\napproach in Wanilla, the first automatic, sound, and fully static\nnoninterference analysis for WebAssembly, and demonstrate its performance and\nprecision by verifying memory integrity and other noninterference properties\nwith several synthetic and real-world benchmarks."}
{"id": "2509.08804", "categories": ["cs.CR", "cs.PL", "D.2.5; F.4.1"], "pdf": "https://arxiv.org/pdf/2509.08804", "abs": "https://arxiv.org/abs/2509.08804", "authors": ["Bishnu Bhusal", "Rohit Chadha", "A. Prasad Sistla", "Mahesh Viswanathan"], "title": "Approximate Algorithms for Verifying Differential Privacy with Gaussian Distributions", "comment": "An extended abstract appears in CCS 2025", "summary": "The verification of differential privacy algorithms that employ Gaussian\ndistributions is little understood. This paper tackles the challenge of\nverifying such programs by introducing a novel approach to approximating\nprobability distributions of loop-free programs that sample from both discrete\nand continuous distributions with computable probability density functions,\nincluding Gaussian and Laplace. We establish that verifying\n$(\\epsilon,\\delta)$-differential privacy for these programs is \\emph{almost\ndecidable}, meaning the problem is decidable for all values of $\\delta$ except\nthose in a finite set. Our verification algorithm is based on computing\nprobabilities to any desired precision by combining integral approximations,\nand tail probability bounds. The proposed methods are implemented in the tool,\nDipApprox, using the FLINT library for high-precision integral computations,\nand incorporate optimizations to enhance scalability. We validate {\\ourtool} on\nfundamental privacy-preserving algorithms, such as Gaussian variants of the\nSparse Vector Technique and Noisy Max, demonstrating its effectiveness in both\nconfirming privacy guarantees and detecting violations."}
