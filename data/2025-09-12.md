<div id=toc></div>

# Table of Contents

- [cs.CR](#cs.CR) [Total: 20]


<div id='cs.CR'></div>

# cs.CR [[Back]](#toc)

### [1] [Cross-Service Token: Finding Attacks in 5G Core Networks](https://arxiv.org/abs/2509.08992)
*Anqi Chen,Riccardo Preatoni,Alessandro Brighente,Mauro Conti,Cristina Nita-Rotaru*

Main category: cs.CR

TL;DR: FivGeeFuzz是一个基于语法的模糊测试框架，用于发现5G核心网络中服务化接口的安全漏洞，在free5GC中发现了8个未知漏洞


<details>
  <summary>Details</summary>
Motivation: 5G核心网络采用服务化架构，网络功能通过HTTP API通信，云环境易受内部攻击，需要研究安全漏洞以防止攻击者利用受损网络功能获取未授权资源访问

Method: 从3GPP API规范自动推导语法生成畸形、意外或语义不一致的输入，集成自动化bug检测与手动验证和根因分析

Result: 在free5GC中发现8个未知漏洞，包括运行时崩溃、错误处理不当和未授权资源访问，其中7个已修复，1个正在修复

Conclusion: FivGeeFuzz能有效发现5G核心网络服务化接口的安全漏洞，证明了基于语法的模糊测试在5G安全评估中的有效性

Abstract: 5G marks a major departure from previous cellular architectures, by
transitioning from a monolithic design of the core network to a Service-Based
Architecture (SBA) where services are modularized as Network Functions (NFs)
which communicate with each other via standard-defined HTTP-based APIs called
Service-Based Interfaces (SBIs). These NFs are deployed in private and public
cloud infrastructure, and an access control framework based on OAuth restricts
how they communicate with each other and obtain access to resources. Given the
increased vulnerabilities of clouds to insiders, it is important to study the
security of the 5G Core services for vulnerabilities that allow attackers to
use compromised NFs to obtain unauthorized access to resources.
  We present FivGeeFuzz, a grammar-based fuzzing framework designed to uncover
security flaws in 5G core SBIs. FivGeeFuzz automatically derives grammars from
3GPP API specifications to generate malformed, unexpected, or semantically
inconsistent inputs, and it integrates automated bug detection with manual
validation and root-cause analysis. We evaluate our approach on free5GC, the
only open-source 5G core implementing Release 17-compliant SBIs with an access
control mechanism. Using FivGeeFuzz, we discovered 8 previously unknown
vulnerabilities in free5GC, leading to runtime crashes, improper error
handling, and unauthorized access to resources, including a very severe attack
we call Cross-Service Token Attack. All bugs were confirmed by the free5GC
team, 7 have already been patched, and the remaining one has a patch under
development.

</details>


### [2] [When FinTech Meets Privacy: Securing Financial LLMs with Differential Private Fine-Tuning](https://arxiv.org/abs/2509.08995)
*Sichen Zhu,Hoyeung Leung,Xiaoyi Wang,Jia Wei,Honghui Xu*

Main category: cs.CR

TL;DR: DPFinLLM是一个专为金融应用设计的轻量级隐私保护大语言模型，结合差分隐私机制，可在边缘设备上安全高效处理敏感金融数据。


<details>
  <summary>Details</summary>
Motivation: 随着AI模型在金融边缘设备部署的增加，保护敏感金融数据的隐私成为重要挑战，需要开发既能保护隐私又保持高性能的解决方案。

Method: 提出DPFinLLM模型，结合强大的差分隐私机制和基于最先进模型的精简架构，专门为设备端金融应用设计。

Result: 在多个金融情感数据集上的广泛实验验证了DPFinLLM的有效性，即使在严格隐私约束下也能达到与完全微调模型相当的性能。

Conclusion: DPFinLLM能够有效保护用户数据隐私，同时在各种金融任务中保持高性能，为边缘设备金融AI应用提供了可行的隐私保护解决方案。

Abstract: The integration of Large Language Models (LLMs) into financial technology
(FinTech) has revolutionized the analysis and processing of complex financial
data, driving advancements in real-time decision-making and analytics. With the
growing trend of deploying AI models on edge devices for financial
applications, ensuring the privacy of sensitive financial data has become a
significant challenge. To address this, we propose DPFinLLM, a
privacy-enhanced, lightweight LLM specifically designed for on-device financial
applications. DPFinLLM combines a robust differential privacy mechanism with a
streamlined architecture inspired by state-of-the-art models, enabling secure
and efficient processing of financial data. This proposed DPFinLLM can not only
safeguard user data from privacy breaches but also ensure high performance
across diverse financial tasks. Extensive experiments on multiple financial
sentiment datasets validate the effectiveness of DPFinLLM, demonstrating its
ability to achieve performance comparable to fully fine-tuned models, even
under strict privacy constraints.

</details>


### [3] [Beyond Tag Collision: Cluster-based Memory Management for Tag-based Sanitizers](https://arxiv.org/abs/2509.09089)
*Mengfei Xie,Yan Lin,Hongtao Wu,Jianming Fu,Chenke Luo,Guojun Peng*

Main category: cs.CR

TL;DR: ClusterTag是一种基于集群的内存分配器，通过将内存对象分组到独立集群中并采用集群级堆随机化，有效缓解标签冲突问题，在保持低性能开销的同时提供确定性安全检测结果。


<details>
  <summary>Details</summary>
Motivation: 现有标签消毒器由于标签编码空间有限，在时间和空间维度上难以分配唯一标签，导致标签冲突和潜在的内存违规检测失败。

Method: 将内存对象划分为多个独立集群，限制标签冲突范围；设计集群级堆随机化方案，在集群间引入随机地址间隔，打破标签空间熵限制。

Result: 在Juliet数据集上实现确定性检测结果（500次重复测试一致），性能开销仅1%；在最小、平均和不可预测性三个冲突距离指标上均取得平衡改进。

Conclusion: ClusterTag通过集群化设计和堆随机化有效解决了标签冲突问题，为标签消毒器提供了更可靠的安全保障，且性能开销极小。

Abstract: Tag-based sanitizers attach a small "key" to each pointer and a matching
"lock" tag to its target memory object, enabling runtime verification of
pointer-object consistency and helping developers to detect potential memory
violations. However, the limited tag encoding space challenges existing studies
in assigning distinct tags to memory objects across temporal and spatial
dimensions, leading to potential tag collisions. In this paper, we present
ClusterTag, a novel cluster-based memory allocator aimed at simultaneously
mitigating tag collisions in both temporal and spatial dimensions. The core
design of ClusterTag effectively balances the significant mismatch between tag
encoding space and memory objects: it divides memory objects into multiple
independent clusters, thereby limiting tag collisions to finite chunks within
each cluster. To mitigate tag collisions across clusters, we design a
cluster-grained heap randomization scheme. This approach introduces random
address intervals between clusters and further breaks the entropy limitation of
the tag space. ClusterTag has been implemented as an independent memory
allocator that seamlessly integrates with tag-based sanitizers such as HWASan,
and maintains comparable performance overhead (within 1%) at various
randomization densities. Security evaluations on the Juliet dataset indicate
that ClusterTag exhibits deterministic results across 500 repeated tests (5,652
reported and 1,530 missed), while the existing three types of tag assignment
strategies all exhibit probabilistic false negatives due to tag collisions.
Quantitative analysis across three tag collision distance metrics-minimum,
average, and unpredictability-demonstrates that ClusterTag achieves balanced
improvements across all three, whereas prior tag assignment schemes (random,
staggered, fixed) show significant trade-offs in at least one metric.

</details>


### [4] [Towards Confidential and Efficient LLM Inference with Dual Privacy Protection](https://arxiv.org/abs/2509.09091)
*Honglan Yu,Yibin Wang,Feifei Dai,Dong Liu,Haihui Fan,Xiaoyan Gu*

Main category: cs.CR

TL;DR: CMIF是一个保护隐私的高效模型推理框架，通过在客户端TEE部署嵌入层、在GPU服务器运行后续层，并优化Report-Noisy-Max机制，在保证数据隐私的同时减少推理开销。


<details>
  <summary>Details</summary>
Motivation: 解决TEE中推理延迟高和DP方法损害LLM性能的问题，传统分区方法在LLM密集非线性层存在显著通信开销，DP噪声会降低模型语义理解能力。

Method: 1) 在客户端TEE部署嵌入层，GPU服务器运行后续层；2) 优化Report-Noisy-Max机制保护敏感输入；3) 减少TEE与GPU间的通信开销。

Result: 在Llama系列模型上的实验表明，CMIF显著降低了TEE中的额外推理开销，同时有效保护了用户数据隐私。

Conclusion: CMIF框架成功解决了TEE高延迟和DP性能下降的问题，实现了隐私保护与推理效率的平衡，适用于大语言模型的机密推理场景。

Abstract: CPU-based trusted execution environments (TEEs) and differential privacy (DP)
have gained wide applications for private inference. Due to high inference
latency in TEEs, researchers use partition-based approaches that offload linear
model components to GPUs. However, dense nonlinear layers of large language
models (LLMs) result in significant communication overhead between TEEs and
GPUs. DP-based approaches apply random noise to protect data privacy, but this
compromises LLM performance and semantic understanding. To overcome the above
drawbacks, this paper proposes CMIF, a Confidential and efficient Model
Inference Framework. CMIF confidentially deploys the embedding layer in the
client-side TEE and subsequent layers on GPU servers. Meanwhile, it optimizes
the Report-Noisy-Max mechanism to protect sensitive inputs with a slight
decrease in model performance. Extensive experiments on Llama-series models
demonstrate that CMIF reduces additional inference overhead in TEEs while
preserving user data privacy.

</details>


### [5] [DP-FedLoRA: Privacy-Enhanced Federated Fine-Tuning for On-Device Large Language Models](https://arxiv.org/abs/2509.09097)
*Honghui Xu,Shiva Shrestha,Wei Chen,Zhiyuan Li,Zhipeng Cai*

Main category: cs.CR

TL;DR: DP-FedLoRA是一个隐私增强的联邦微调框架，将LoRA适配与差分隐私结合，在通信高效的环境中保护用户敏感数据。


<details>
  <summary>Details</summary>
Motivation: 随着设备端大语言模型系统的普及，联邦微调虽然能在边缘设备上实现高级语言理解，但涉及处理敏感的用户特定数据，在联邦学习框架中存在显著的隐私问题。

Method: 每个客户端使用高斯噪声对LoRA矩阵进行本地裁剪和扰动，以满足(ε, δ)-差分隐私。提供理论分析证明更新的无偏性，并推导噪声引入的方差界限。

Result: 在主流基准测试中，DP-FedLoRA在提供强大隐私保证的同时展现出有竞争力的性能表现。

Conclusion: 该框架为设备端环境中可扩展且保护隐私的LLM部署铺平了道路。

Abstract: As on-device large language model (LLM) systems become increasingly
prevalent, federated fine-tuning enables advanced language understanding and
generation directly on edge devices; however, it also involves processing
sensitive, user-specific data, raising significant privacy concerns within the
federated learning framework. To address these challenges, we propose
DP-FedLoRA, a privacy-enhanced federated fine-tuning framework that integrates
LoRA-based adaptation with differential privacy in a communication-efficient
setting. Each client locally clips and perturbs its LoRA matrices using
Gaussian noise to satisfy ($\epsilon$, $\delta$)-differential privacy. We
further provide a theoretical analysis demonstrating the unbiased nature of the
updates and deriving bounds on the variance introduced by noise, offering
practical guidance for privacy-budget calibration. Experimental results across
mainstream benchmarks show that DP-FedLoRA delivers competitive performance
while offering strong privacy guarantees, paving the way for scalable and
privacy-preserving LLM deployment in on-device environments.

</details>


### [6] [AgriSentinel: Privacy-Enhanced Embedded-LLM Crop Disease Alerting System](https://arxiv.org/abs/2509.09103)
*Chanti Raju Mylay,Bobin Deng,Zhipeng Cai,Honghui Xu*

Main category: cs.CR

TL;DR: AgriSentinel是一个基于嵌入式大语言模型的隐私增强型作物病害预警系统，通过差分隐私保护、轻量级深度学习模型和本地化LLM，为农民提供安全的病害检测和可操作的管理建议。


<details>
  <summary>Details</summary>
Motivation: 现有作物病害预警系统忽视数据隐私、市场定价权和农民可用性等问题，使农民面临隐私泄露和经济剥削风险，需要开发更全面的解决方案。

Method: 采用差分隐私机制保护作物图像数据，开发轻量级深度学习分类模型优化移动设备部署，并利用本地化大语言模型结合知识库提供具体管理建议。

Result: 实验验证了系统在保护数据隐私的同时保持高分类性能，能够提供实用的病害管理策略。

Conclusion: AgriSentinel为农民提供了强大、友好的作物病害预警和管理自动化解决方案，有助于改善农业决策和提高作物生产力。

Abstract: Crop diseases pose significant threats to global food security, agricultural
productivity, and sustainable farming practices, directly affecting farmers'
livelihoods and economic stability. To address the growing need for effective
crop disease management, AI-based disease alerting systems have emerged as
promising tools by providing early detection and actionable insights for timely
intervention. However, existing systems often overlook critical aspects such as
data privacy, market pricing power, and farmer-friendly usability, leaving
farmers vulnerable to privacy breaches and economic exploitation. To bridge
these gaps, we propose AgriSentinel, the first Privacy-Enhanced Embedded-LLM
Crop Disease Alerting System. AgriSentinel incorporates a differential privacy
mechanism to protect sensitive crop image data while maintaining classification
accuracy. Its lightweight deep learning-based crop disease classification model
is optimized for mobile devices, ensuring accessibility and usability for
farmers. Additionally, the system includes a fine-tuned, on-device large
language model (LLM) that leverages a curated knowledge pool to provide farmers
with specific, actionable suggestions for managing crop diseases, going beyond
simple alerting. Comprehensive experiments validate the effectiveness of
AgriSentinel, demonstrating its ability to safeguard data privacy, maintain
high classification performance, and deliver practical, actionable disease
management strategies. AgriSentinel offers a robust, farmer-friendly solution
for automating crop disease alerting and management, ultimately contributing to
improved agricultural decision-making and enhanced crop productivity.

</details>


### [7] [CryptGNN: Enabling Secure Inference for Graph Neural Networks](https://arxiv.org/abs/2509.09107)
*Pritam Sen,Yao Ma,Cristian Borcea*

Main category: cs.CR

TL;DR: CryptGNN是一个安全的图神经网络推理解决方案，使用安全多方计算技术保护客户端数据和模型参数隐私


<details>
  <summary>Details</summary>
Motivation: 解决云环境中第三方GNN模型推理时的隐私保护问题，防止云服务提供商和模型所有者获取客户端数据和图结构信息

Method: 采用分布式安全多方计算(SMPC)技术实现安全消息传递和特征变换层，支持任意数量的SMPC参与方，无需可信服务器

Result: 理论分析和实验验证表明CryptGNN具有安全性和高效性，即使P-1个云参与方合谋也能保证安全性

Conclusion: CryptGNN为MLaaS场景下的GNN推理提供了有效的隐私保护解决方案，具有实际应用价值

Abstract: We present CryptGNN, a secure and effective inference solution for
third-party graph neural network (GNN) models in the cloud, which are accessed
by clients as ML as a service (MLaaS). The main novelty of CryptGNN is its
secure message passing and feature transformation layers using distributed
secure multi-party computation (SMPC) techniques. CryptGNN protects the
client's input data and graph structure from the cloud provider and the
third-party model owner, and it protects the model parameters from the cloud
provider and the clients. CryptGNN works with any number of SMPC parties, does
not require a trusted server, and is provably secure even if P-1 out of P
parties in the cloud collude. Theoretical analysis and empirical experiments
demonstrate the security and efficiency of CryptGNN.

</details>


### [8] [Character-Level Perturbations Disrupt LLM Watermarks](https://arxiv.org/abs/2509.09112)
*Zhaoxi Zhang,Xiaomei Zhang,Yanjun Zhang,He Zhang,Shirui Pan,Bo Liu,Asif Qumer Gill,Leo Yu Zhang*

Main category: cs.CR

TL;DR: 这篇论文提出字符级水印移除攻击方法，通过打乱分词过程来同时影响多个标记，在限制性威胁模型下显示出更高效的水印移除能力，曝露了现有LLM水印方案的漏洞。


<details>
  <summary>Details</summary>
Motivation: 先前的水印移除攻击方法通常需要大规模干扰或强大攻击者，导致人们误解为有效移除需要这些条件。论文希望找到更有效的移除方法，并揭示现有水印方案的实际弱点。

Method: 首先形式化LLM水印系统模型，定义了两种现实威胁模型。分析了不同类型干扰的攻击范围，发现字符级干扰通过打乱分词过程可以同时影响多个标记。提出了基于遗传算法的导向移除攻击，以及适应性复合字符级攻击。

Result: 实验结果证明字符级干扰在最严格的威胁模型下具有显著更高的水印移除效果。在限制性黑盒查询条件下，遗传算法方法显示出强大的移除性能。适应性复合攻击能够有效突破防御措施。

Conclusion: 研究结果显著揭示了现有LLM水印方案的漏洞，字符级攻击通过打乱分词过程实现了高效移除。这为开发更稳健的水印机制指明了方向，并展现了安全性分析的重要性。

Abstract: Large Language Model (LLM) watermarking embeds detectable signals into
generated text for copyright protection, misuse prevention, and content
detection. While prior studies evaluate robustness using watermark removal
attacks, these methods are often suboptimal, creating the misconception that
effective removal requires large perturbations or powerful adversaries.
  To bridge the gap, we first formalize the system model for LLM watermark, and
characterize two realistic threat models constrained on limited access to the
watermark detector. We then analyze how different types of perturbation vary in
their attack range, i.e., the number of tokens they can affect with a single
edit. We observe that character-level perturbations (e.g., typos, swaps,
deletions, homoglyphs) can influence multiple tokens simultaneously by
disrupting the tokenization process. We demonstrate that character-level
perturbations are significantly more effective for watermark removal under the
most restrictive threat model. We further propose guided removal attacks based
on the Genetic Algorithm (GA) that uses a reference detector for optimization.
Under a practical threat model with limited black-box queries to the watermark
detector, our method demonstrates strong removal performance. Experiments
confirm the superiority of character-level perturbations and the effectiveness
of the GA in removing watermarks under realistic constraints. Additionally, we
argue there is an adversarial dilemma when considering potential defenses: any
fixed defense can be bypassed by a suitable perturbation strategy. Motivated by
this principle, we propose an adaptive compound character-level attack.
Experimental results show that this approach can effectively defeat the
defenses. Our findings highlight significant vulnerabilities in existing LLM
watermark schemes and underline the urgency for the development of new robust
mechanisms.

</details>


### [9] [IoTFuzzSentry: A Protocol Guided Mutation Based Fuzzer for Automatic Vulnerability Testing in Commercial IoT Devices](https://arxiv.org/abs/2509.09158)
*Priyanka Rushikesh Chaudhary,Rajib Ranjan Maiti*

Main category: cs.CR

TL;DR: IoTFuzzSentry是一个基于变异的协议模糊测试工具，用于发现商用IoT设备中的安全漏洞，已成功识别出4类漏洞并发布2个CVE编号


<details>
  <summary>Details</summary>
Motivation: IoT设备在运行阶段常运行轻量级服务器处理用户交互，传输层或应用层安全机制的实现缺陷可能导致未经授权访问和数据泄露等威胁

Method: 开发了名为IoTFuzzSentry的变异模糊测试工具，集成到Cotopaxi测试工具中，通过向IoT通信注入精心构造的传输层和应用层数据包来发现漏洞

Result: 在商用IoT设备（IP摄像头和智能插座）中发现了4类漏洞：IoT访问凭证泄露、窃取IoT实时视频流、窥探IoT实时图像、IoT命令注入，并展示了实际利用场景，已发布2个CVE编号

Conclusion: IoTFuzzSentry有潜力发现非常规安全威胁，能够以可忽略的开销自动帮助IoT厂商加强其商用设备的安全性，对6个额外IoT设备的流量分析表明类似协议存在相似漏洞

Abstract: Protocol fuzzing is a scalable and cost-effective technique for identifying
security vulnerabilities in deployed Internet of Things devices. During their
operational phase, IoT devices often run lightweight servers to handle user
interactions, such as video streaming or image capture in smart cameras.
Implementation flaws in transport or application-layer security mechanisms can
expose IoT devices to a range of threats, including unauthorized access and
data leakage. This paper addresses the challenge of uncovering such
vulnerabilities by leveraging protocol fuzzing techniques that inject crafted
transport and application-layer packets into IoT communications. We present a
mutation-based fuzzing tool, named IoTFuzzSentry, to identify specific
non-trivial vulnerabilities in commercial IoT devices. We further demonstrate
how these vulnerabilities can be exploited in real-world scenarios. We
integrated our fuzzing tool into a well-known testing tool Cotopaxi and
evaluated it with commercial-off-the-shelf IoT devices such as IP cameras and
Smart Plug. Our evaluation revealed vulnerabilities categorized into 4 types
(IoT Access Credential Leakage, Sneak IoT Live Video Stream, Creep IoT Live
Image, IoT Command Injection) and we show their exploits using three IoT
devices. We have responsibly disclosed all these vulnerabilities to the
respective vendors. So far, we have published two CVEs, CVE-2024-41623 and
CVE-2024-42531, and one is awaiting. To extend the applicability, we have
investigated the traffic of six additional IoT devices and our analysis shows
that these devices can have similar vulnerabilities, due to the presence of a
similar set of application protocols. We believe that IoTFuzzSentry has the
potential to discover unconventional security threats and allow IoT vendors to
strengthen the security of their commercialized IoT devices automatically with
negligible overhead.

</details>


### [10] [Enhancing Cyber Threat Hunting -- A Visual Approach with the Forensic Visualization Toolkit](https://arxiv.org/abs/2509.09185)
*Jihane Najar,Marinos Tsantekidis,Aris Sotiropoulos,Vassilis Prevelakis*

Main category: cs.CR

TL;DR: 提出了Forensic Visualization Toolkit (FVT)工具，用于数字取证调查和网络安全威胁狩猎，通过先进的可视化技术增强安全分析师的能力。


<details>
  <summary>Details</summary>
Motivation: 面对动态网络威胁环境，传统安全措施可能无法检测到高级威胁，需要主动的威胁狩猎方法来识别和缓解潜在风险。

Method: 开发Forensic Visualization Toolkit工具，提供数字证据分析和高级可视化功能，支持交互式网络安全态势感知和风险管理。

Result: FVT工具已成功集成到多个欧盟资助的研究项目中，通过实际场景验证了其能够显著增强网络安全专业人员识别、分析和响应威胁的能力。

Conclusion: FVT作为一个强大的数字取证和可视化工具，有效支持了主动网络安全威胁狩猎，提升了组织应对高级网络威胁的防御能力。

Abstract: In today's dynamic cyber threat landscape, organizations must take proactive
steps to bolster their cybersecurity defenses. Cyber threat hunting is a
proactive and iterative process aimed at identifying and mitigating advanced
threats that may go undetected by traditional security measures. Rather than
waiting for automated security systems to flag potential threats, threat
hunting involves actively searching for signs of malicious activity within an
organization's network. In this paper, we present the Forensic Visualization
Toolkit, a powerful tool designed for digital forensics investigations,
analysis of digital evidence, and advanced visualizations to enhance
cybersecurity situational awareness and risk management and empower security
analysts with an intuitive and interactive tool. Through practical, real-world
scenarios, we demonstrate how FVT significantly amplifies the capabilities of
cybersecurity professionals, enabling them to effectively identify, analyze,
and respond to threats. Furthermore, it is important to highlight that FVT has
been integrated into, utilized, and continually enhanced within various
EU-funded research projects over recent years.

</details>


### [11] [Shell or Nothing: Real-World Benchmarks and Memory-Activated Agents for Automated Penetration Testing](https://arxiv.org/abs/2509.09207)
*Wuyuao Mai,Geng Hong,Qi Liu,Jinsong Chen,Jiarun Dai,Xudong Pan,Yuan Zhang,Min Yang*

Main category: cs.CR

TL;DR: 提出了第一个真实世界渗透测试基准TermiBench和新型多代理框架TermiAgent，解决了现有AI渗透测试系统在简化CTF环境中表现良好但在真实场景中效果差的问题。


<details>
  <summary>Details</summary>
Motivation: 传统渗透测试成本高、耗时长且依赖专家人工，现有AI驱动的渗透测试代理在简化的CTF环境中评估，性能估计远离真实世界实践。

Method: 提出TermiBench基准（510个主机、25种服务、30个CVE）和TermiAgent多代理框架，采用定位记忆激活机制缓解长上下文遗忘，通过结构化代码理解构建可靠的漏洞利用库。

Result: TermiAgent在评估中优于最先进代理，展现出更强的渗透测试能力，减少执行时间和财务成本，甚至在笔记本电脑规模部署中也具有实用性。

Conclusion: 这项工作提供了第一个开源的真实世界自主渗透测试基准和一个新型代理框架，为AI驱动的渗透测试建立了里程碑。

Abstract: Penetration testing is critical for identifying and mitigating security
vulnerabilities, yet traditional approaches remain expensive, time-consuming,
and dependent on expert human labor. Recent work has explored AI-driven
pentesting agents, but their evaluation relies on oversimplified
capture-the-flag (CTF) settings that embed prior knowledge and reduce
complexity, leading to performance estimates far from real-world practice. We
close this gap by introducing the first real-world, agent-oriented pentesting
benchmark, TermiBench, which shifts the goal from 'flag finding' to achieving
full system control. The benchmark spans 510 hosts across 25 services and 30
CVEs, with realistic environments that require autonomous reconnaissance,
discrimination between benign and exploitable services, and robust exploit
execution. Using this benchmark, we find that existing systems can hardly
obtain system shells under realistic conditions.
  To address these challenges, we propose TermiAgent, a multi-agent penetration
testing framework. TermiAgent mitigates long-context forgetting with a Located
Memory Activation mechanism and builds a reliable exploit arsenal via
structured code understanding rather than naive retrieval. In evaluations, our
work outperforms state-of-the-art agents, exhibiting stronger penetration
testing capability, reducing execution time and financial cost, and
demonstrating practicality even on laptop-scale deployments. Our work delivers
both the first open-source benchmark for real-world autonomous pentesting and a
novel agent framework that establishes a milestone for AI-driven penetration
testing.

</details>


### [12] [A Cyber-Twin Based Honeypot for Gathering Threat Intelligence](https://arxiv.org/abs/2509.09222)
*Muhammad Azmi Umer,Zhan Xuna,Yan Lin Aung,Aditya P. Mathur,Jianying Zhou*

Main category: cs.CR

TL;DR: 基于水处理厂组织双生的蜘蛛网，用于吸引和分析网络攻击，为关键基础设施提供威胁情报


<details>
  <summary>Details</summary>
Motivation: 关键基础设施（CI）容易受到网络攻击，需要有效的防护技术来应对这些威胁

Method: 开发了一种基于水处理厂组织双生的蜘蛛网，作为实际水处理厂的实际复制品，用于吸引潜在攻击者

Result: 该蜘蛛网已经运行并多次受到攻击，包括详细描述的劫持磁盘病毒攻击，攻击行为被记录和分析

Conclusion: 通过蜘蛛网收集的威胁情报可以与水处理厂管理方分享，帮助他们改善厂区保护系统

Abstract: Critical Infrastructure (CI) is prone to cyberattacks. Several techniques
have been developed to protect CI against such attacks. In this work, we
describe a honeypot based on a cyber twin for a water treatment plant. The
honeypot is intended to serve as a realistic replica of a water treatment plant
that attracts potential attackers. The attacks launched on the honeypot are
recorded and analyzed for threat intelligence. The intelligence so obtained is
shared with the management of water treatment plants, who in turn may use it to
improve plant protection systems. The honeypot used here is operational and has
been attacked on several occasions using, for example, a ransomware attack that
is described in detail.

</details>


### [13] [What You Code Is What We Prove: Translating BLE App Logic into Formal Models with LLMs for Vulnerability Detection](https://arxiv.org/abs/2509.09291)
*Biwei Yan,Yue Zhang,Minghui Xu,Runyu Pan,Jinku Li,Xiuzhen Cheng*

Main category: cs.CR

TL;DR: VerifiaBLE系统利用LLM将BLE应用代码转换为形式化模型进行验证，发现大多数Android BLE应用存在严重安全漏洞，只有10.2%的应用实现了完整的安全保护。


<details>
  <summary>Details</summary>
Motivation: BLE应用层安全漏洞日益严重，开发者经常忽略加密、认证和新鲜性等关键保护措施，而传统形式化验证需要大量人工建模工作，难以进行大规模分析。

Method: 将BLE安全分析重构为语义翻译问题，使用LLM作为翻译器将BLE特定代码转换为可由ProVerif等工具验证的过程模型，结合静态分析、提示引导的LLM翻译和符号验证来检查加密、随机性和认证三个核心安全特性。

Result: 在1,050个Android BLE应用的分析中，只有10.2%的应用实现了所有三种保护措施，53.9%的应用完全忽略了这些保护，揭示了系统性的安全弱点。

Conclusion: 使用LLM作为结构化翻译器可以降低形式化方法的门槛，为安全关键领域的大规模验证开辟了新途径。

Abstract: The application layer of Bluetooth Low Energy (BLE) is a growing source of
security vulnerabilities, as developers often neglect to implement critical
protections such as encryption, authentication, and freshness. While formal
verification offers a principled way to check these properties, the manual
effort of constructing formal models makes it impractical for large-scale
analysis. This paper introduces a key insight: BLE application security
analysis can be reframed as a semantic translation problem, i.e., from
real-world code to formal models. We leverage large language models (LLMs) not
to directly detect vulnerabilities, but to serve as translators that convert
BLE-specific code into process models verifiable by tools like ProVerif. We
implement this idea in VerifiaBLE, a system that combines static analysis,
prompt-guided LLM translation, and symbolic verification to check three core
security features: encryption, randomness, and authentication. Applied to 1,050
Android BLE apps, VerifiaBLE uncovers systemic weaknesses: only 10.2\% of apps
implement all three protections, while 53.9\% omit them entirely. Our work
demonstrates that using LLMs as structured translators can lower the barrier to
formal methods, unlocking scalable verification across security-critical
domains.

</details>


### [14] [On the Security of SSH Client Signatures](https://arxiv.org/abs/2509.09331)
*Fabian Bäumer,Marcus Brinkmann,Maximilian Radoy,Jörg Schwenk,Juraj Somorovsky*

Main category: cs.CR

TL;DR: 这篇论文研究SSH客户端密钥安全性，通过收集公开密钥和分析SSH客户端签名算法实现，发现了包括弱随机性和确定性nonce在内的多个安全漏洞。


<details>
  <summary>Details</summary>
Motivation: 补充SSH客户端密钥安全性的研究空白，因为不像服务器可以通过互联网扫描进行测量。

Method: 分两步进行：1) 从GitHub等开发平台收集310万+个SSH客户公钥并进行安全测试；2) 在黑盒实验中分析24款流行SSH客户端的签名算法实现。

Result: 发现98个短密钥、139个弱随机性生成的密钥、149个共享小因子的密钥。首次证明ECDSA中确定性nonce的使用可能泄露私钥，PuTTY客户端仅需58个有效签名即可恢复私钥。

Conclusion: 虽然大多数SSH客户密钥没有安全问题，但ECDSA签名中的确定性nonce生成算法存在严重安全风险，PuTTY已修复此漏洞(CVE-2024-31497)。

Abstract: Administrators and developers use SSH client keys and signatures for
authentication, for example, to access internet backbone servers or to commit
new code on platforms like GitHub. However, unlike servers, SSH clients cannot
be measured through internet scans. We close this gap in two steps. First, we
collect SSH client public keys. Such keys are regularly published by their
owners on open development platforms like GitHub and GitLab. We systematize
previous non-academic work by subjecting these keys to various security tests
in a longitudinal study. Second, in a series of black-box lab experiments, we
analyze the implementations of algorithms for SSH client signatures in 24
popular SSH clients for Linux, Windows, and macOS.
  We extracted 31,622,338 keys from three public sources in two scans. Compared
to previous work, we see a clear tendency to abandon RSA signatures in favor of
EdDSA signatures. Still, in January 2025, we found 98 broken short keys, 139
keys generated from weak randomness, and 149 keys with common or small
factors-the large majority of the retrieved keys exposed no weakness.
  Weak randomness can not only compromise a secret key through its public key,
but also through signatures. It is well-known that a bias in random nonces in
ECDSA can reveal the secret key through public signatures. For the first time,
we show that the use of deterministic nonces in ECDSA can also be dangerous:
The private signing key of a PuTTY client can be recovered from just 58 valid
signatures if ECDSA with NIST curve P-521 is used. PuTTY acknowledged our
finding in CVE-2024-31497, and they subsequently replaced the nonce generation
algorithm.

</details>


### [15] [[Extended] Ethics in Computer Security Research: A Data-Driven Assessment of the Past, the Present, and the Possible Future](https://arxiv.org/abs/2509.09351)
*Harshini Sri Ramulu,Helen Schmitt,Bogdan Rerich,Rachel Gonzalez Rodriguez,Tadayoshi Kohno,Yasemin Acar*

Main category: cs.CR

TL;DR: 这篇论文分析了计算机安全领域的论理问题状况，通过对2024年1154篇顶级论文的审查和24位研究人员的访谈，发现了论理报告不一致、缺乏统一价值观和案例研究等问题，并提出改善建议。


<details>
  <summary>Details</summary>
Motivation: 计算机安全领域经常讨论论理问题，但研究人员缺乏明确指导来做出、记录和评估论理决定，特别是在道德上不明确的情况下。

Method: 分析了2024年发表的1154篇顶级安全论文中的论理报告情况，并进行了半结构化访谈研究，访谈24位计算机安全和隐私研究人员（包括评审人、论理委员会成员和程序主席）。

Result: 发现论理报告水平不一致，重点集中在机构批准、人体保护和责任暴露上，缺乏对害处与改善平衡的讨论。研究人员希望进行论理研究但价值观、论理框架、决策过程和结果都缺乏一致性。

Conclusion: 提供了当前计算机安全研究论理讨论状况和实际标准的概览，并提出改善计算机安全研究论理状况的建议。

Abstract: Ethical questions are discussed regularly in computer security. Still,
researchers in computer security lack clear guidance on how to make, document,
and assess ethical decisions in research when what is morally right or
acceptable is not clear-cut. In this work, we give an overview of the
discussion of ethical implications in current published work in computer
security by reviewing all 1154 top-tier security papers published in 2024,
finding inconsistent levels of ethics reporting with a strong focus of
reporting institutional or ethics board approval, human subjects protection,
and responsible disclosure, and a lack of discussion of balancing harms and
benefits. We further report on the results of a semi-structured interview study
with 24 computer security and privacy researchers (among whom were also:
reviewers, ethics committee members, and/or program chairs) and their ethical
decision-making both as authors and during peer review, finding a strong desire
for ethical research, but a lack of consistency in considered values, ethical
frameworks (if articulated), decision-making, and outcomes. We present an
overview of the current state of the discussion of ethics and current de-facto
standards in computer security research, and contribute suggestions to improve
the state of ethics in computer security research.

</details>


### [16] [ENSI: Efficient Non-Interactive Secure Inference for Large Language Models](https://arxiv.org/abs/2509.09424)
*Zhiyu He,Maojiang Wang,Xinwen Gao,Yuchuan Luo,Lin Liu,Shaojing Fu*

Main category: cs.CR

TL;DR: ENSI是一个新颖的非交互式安全推理框架，通过密码协议与LLM架构的协同设计，显著提升大语言模型加密推理效率，实现矩阵乘法8倍加速和softmax推理2.6倍加速。


<details>
  <summary>Details</summary>
Motivation: 将密码协议与大规模语言模型集成面临巨大挑战，协议复杂性和LLM庞大的参数规模严重限制了实际可用性，需要新的解决方案来实现高效的安全推理。

Method: 采用密码协议与LLM架构协同设计原则，使用优化的编码策略将CKKS方案与轻量级BitNet集成，引入sigmoid注意力机制替代softmax，并将Bootstrapping操作嵌入RMSNorm过程。

Result: 实验评估显示ENSI在矩阵乘法上实现约8倍加速，CPU上softmax推理速度提升2.6倍，bootstrapping操作比例降至仅1%。

Conclusion: ENSI框架通过创新的协同设计和优化策略，成功解决了LLM安全推理中的计算效率瓶颈，为隐私保护机器学习提供了实用的解决方案。

Abstract: Secure inference enables privacy-preserving machine learning by leveraging
cryptographic protocols that support computations on sensitive user data
without exposing it. However, integrating cryptographic protocols with large
language models (LLMs) presents significant challenges, as the inherent
complexity of these protocols, together with LLMs' massive parameter scale and
sophisticated architectures, severely limits practical usability. In this work,
we propose ENSI, a novel non-interactive secure inference framework for LLMs,
based on the principle of co-designing the cryptographic protocols and LLM
architecture. ENSI employs an optimized encoding strategy that seamlessly
integrates CKKS scheme with a lightweight LLM variant, BitNet, significantly
reducing the computational complexity of encrypted matrix multiplications. In
response to the prohibitive computational demands of softmax under homomorphic
encryption (HE), we pioneer the integration of the sigmoid attention mechanism
with HE as a seamless, retraining-free alternative. Furthermore, by embedding
the Bootstrapping operation within the RMSNorm process, we efficiently refresh
ciphertexts while markedly decreasing the frequency of costly bootstrapping
invocations. Experimental evaluations demonstrate that ENSI achieves
approximately an 8x acceleration in matrix multiplications and a 2.6x speedup
in softmax inference on CPU compared to state-of-the-art method, with the
proportion of bootstrapping is reduced to just 1%.

</details>


### [17] [Prompt Pirates Need a Map: Stealing Seeds helps Stealing Prompts](https://arxiv.org/abs/2509.09488)
*Felix Mächtle,Ashwath Shetty,Jonas Sander,Nils Loose,Sören Pirk,Thomas Eisenbarth*

Main category: cs.CR

TL;DR: 本文揭示了扩散模型中种子值可被暴力破解的安全漏洞，提出了基于遗传算法的PromptPirate方法实现提示词窃取，并提出了有效的防御措施。


<details>
  <summary>Details</summary>
Motivation: 扩散模型生成的图像包含有价值的文本提示词，提示词窃取成为重要的安全和隐私问题。现有基于数值优化的提示词恢复方法存在根本性限制，无法考虑图像生成时的初始随机噪声。

Method: 1) 发现并利用噪声生成漏洞(CWE-339)，该漏洞源于PyTorch在CPU上生成初始随机噪声时将种子值限制在2^32范围内；2) 开发SeedSnitch工具进行种子值暴力破解；3) 提出基于遗传算法的PromptPirate方法进行提示词窃取。

Result: 在CivitAI平台的大规模实证分析显示，约95%图像的种子值可在140分钟内被破解。PromptPirate相比现有方法(PromptStealer、P2HP、CLIP-Interrogator)在LPIPS相似度上提升8-11%。

Conclusion: 本文揭示了扩散模型中的重要安全漏洞，提出了有效的攻击和防御方法。已负责任地披露发现并与开发者合作进行协调缓解工作。

Abstract: Diffusion models have significantly advanced text-to-image generation,
enabling the creation of highly realistic images conditioned on textual prompts
and seeds. Given the considerable intellectual and economic value embedded in
such prompts, prompt theft poses a critical security and privacy concern. In
this paper, we investigate prompt-stealing attacks targeting diffusion models.
We reveal that numerical optimization-based prompt recovery methods are
fundamentally limited as they do not account for the initial random noise used
during image generation. We identify and exploit a noise-generation
vulnerability (CWE-339), prevalent in major image-generation frameworks,
originating from PyTorch's restriction of seed values to a range of $2^{32}$
when generating the initial random noise on CPUs. Through a large-scale
empirical analysis conducted on images shared via the popular platform CivitAI,
we demonstrate that approximately 95% of these images' seed values can be
effectively brute-forced in 140 minutes per seed using our seed-recovery tool,
SeedSnitch. Leveraging the recovered seed, we propose PromptPirate, a genetic
algorithm-based optimization method explicitly designed for prompt stealing.
PromptPirate surpasses state-of-the-art methods, i.e., PromptStealer, P2HP, and
CLIP-Interrogator, achieving an 8-11% improvement in LPIPS similarity.
Furthermore, we introduce straightforward and effective countermeasures that
render seed stealing, and thus optimization-based prompt stealing, ineffective.
We have disclosed our findings responsibly and initiated coordinated mitigation
efforts with the developers to address this critical vulnerability.

</details>


### [18] [What Does Normal Even Mean? Evaluating Benign Traffic in Intrusion Detection Datasets](https://arxiv.org/abs/2509.09564)
*Meghan Wilkinson,Robert H Thomson*

Main category: cs.CR

TL;DR: 本文分析了网络入侵检测数据集中的良性流量结构，通过无监督聚类技术发现良性流量存在有意义的子类别，这可能提高多类分类性能。


<details>
  <summary>Details</summary>
Motivation: 目前大多数入侵检测算法将数据集中的标签类别视为真实情况，特别是将所有非攻击流量罚制地归为单一的大型良性类别，这可能忽略了良性流量内部的有意义结构差异。

Method: 使用无监督聚类技术（如HDBSCAN、Mean Shift Clustering）对常见入侵检测数据集（NSL-KDD、UNSW-NB15、CIC-IDS 2017）中的良性流量进行聚类分析，识别其中的子类别结构。

Result: 研究发现良性流量在多个数据集中都存在明显的子类别结构，不同的无监督聚类方法能够差异地聚类良性流量空间。

Conclusion: 良性网络流量并非单一同质的类别，而是包含多个有意义子类别的复杂结构。识别和利用这些子类别可以提高多类分类入侵检测算法的性能。

Abstract: Supervised machine learning techniques rely on labeled data to achieve high
task performance, but this requires the labels to capture some meaningful
differences in the underlying data structure. For training network intrusion
detection algorithms, most datasets contain a series of attack classes and a
single large benign class which captures all non-attack network traffic. A
review of intrusion detection papers and guides that explicitly state their
data preprocessing steps identified that the majority took the labeled
categories of the dataset at face value when training their algorithms. The
present paper evaluates the structure of benign traffic in several common
intrusion detection datasets (NSL-KDD, UNSW-NB15, and CIC-IDS 2017) and
determines whether there are meaningful sub-categories within this traffic
which may improve overall multi-classification performance using common machine
learning techniques. We present an overview of some unsupervised clustering
techniques (e.g., HDBSCAN, Mean Shift Clustering) and show how they
differentially cluster the benign traffic space.

</details>


### [19] [Bridging the Gap in Phishing Detection: A Comprehensive Phishing Dataset Collector](https://arxiv.org/abs/2509.09592)
*Aditya Kulkarni,Shahil Manishbhai Patel,Shivam Pradip Tirmare,Vivek Balachandran,Tamal Das*

Main category: cs.CR

TL;DR: 这篇论文提出了一种全面的网页资源收集工具，用于收集涉及网址、源代码、截图等多种资源的鱼网攻击数据集，解决现有鱼网数据集不够多样性的问题。


<details>
  <summary>Details</summary>
Motivation: 鱼网攻击检测需要多样化的数据集，但现有数据集库常常缺乏完整的鱼网页面资源（URL、源代码、截图等），而且鱼网网站存活时间短、收集困难，导致模型偏差。

Method: 设计了一种资源收集工具，利用PhishTank作为活跃鱼网URL的主要来源，收集URL、CSS、Javascript、favicon、网页图片和截图等多种资源，比PyWebCopy库收集更多资源类型。

Result: 分享了一个样本数据集，包含4,056个合法网址和5,666个鱼网网址及其相关资源，并分析了数据集中与鱼网类别最相关的特征。

Conclusion: 该工具提供了全面的资源集合，能够帮助研究人员开发更有效的鱼网检测方法，解决了鱼网数据集多样性不足的问题。

Abstract: To combat phishing attacks -- aimed at luring web users to divulge their
sensitive information -- various phishing detection approaches have been
proposed. As attackers focus on devising new tactics to bypass existing
detection solutions, researchers have adapted by integrating machine learning
and deep learning into phishing detection. Phishing dataset collection is vital
to developing effective phishing detection approaches, which highly depend on
the diversity of the gathered datasets. The lack of diversity in the dataset
results in a biased model. Since phishing websites are often short-lived,
collecting them is also a challenge. Consequently, very few phishing webpage
dataset repositories exist to date. No single repository comprehensively
consolidates all phishing elements corresponding to a phishing webpage, namely,
URL, webpage source code, screenshot, and related webpage resources. This paper
introduces a resource collection tool designed to gather various resources
associated with a URL, such as CSS, Javascript, favicons, webpage images, and
screenshots. Our tool leverages PhishTank as the primary source for obtaining
active phishing URLs. Our tool fetches several additional webpage resources
compared to PyWebCopy Python library, which provides webpage content for a
given URL. Additionally, we share a sample dataset generated using our tool
comprising 4,056 legitimate and 5,666 phishing URLs along with their associated
resources. We also remark on the top correlated phishing features with their
associated class label found in our dataset. Our tool offers a comprehensive
resource set that can aid researchers in developing effective phishing
detection approaches.

</details>


### [20] [CryptoGuard: An AI-Based Cryptojacking Detection Dashboard Prototype](https://arxiv.org/abs/2509.09638)
*Amitabh Chakravorty,Jess Kropczynski,Nelly Elsayed*

Main category: cs.CR

TL;DR: 提出了CryptoGuard AI安全仪表板的前端原型设计，专注于通过用户中心设计帮助加密货币钱包用户检测和应对加密劫持威胁


<details>
  <summary>Details</summary>
Motivation: 随着加密货币的广泛采用，加密劫持已成为钱包用户的重要安全威胁，需要开发直观的安全工具来保护非技术用户

Method: 采用用户中心设计流程，通过Figma构建高保真可点击原型，模拟关键用户交互，设计包含监控登录交易活动、识别可疑行为的功能界面

Result: 开发了概念性AI功能的原型，展示了视觉警报和报告等特性，虽然AI功能是概念性的，但原型验证了界面设计的可行性

Conclusion: 实用安全工具不仅需要强大的后端功能，还需要用户中心的设计来有效传达风险并赋能用户采取行动，该工作连接了加密劫持检测研究与以人为中心的界面设计

Abstract: With the widespread adoption of cryptocurrencies, cryptojacking has become a
significant security threat to crypto wallet users. This paper presents a
front-end prototype of an AI-powered security dashboard, namely, CryptoGuard.
Developed through a user-centered design process, the prototype was constructed
as a high-fidelity, click-through model from Figma mockups to simulate key user
interactions. It is designed to assist users in monitoring their login and
transaction activity, identifying any suspicious behavior, and enabling them to
take action directly within the wallet interface. The dashboard is designed for
a general audience, prioritizing an intuitive user experience for non-technical
individuals. Although its AI functionality is conceptual, the prototype
demonstrates features like visual alerts and reporting. This work is positioned
explicitly as a design concept, bridging cryptojacking detection research with
human-centered interface design. This paper also demonstrates how usability
heuristics can directly inform a tool's ability to support rapid and confident
decision-making under real-world threats. This paper argues that practical
security tools require not only robust backend functionality but also a
user-centric design that communicates risk and empowers users to take
meaningful action.

</details>
