{"id": "2509.02578", "categories": ["cs.CR", "cs.PF"], "pdf": "https://arxiv.org/pdf/2509.02578", "abs": "https://arxiv.org/abs/2509.02578", "authors": ["Abel C. H. Chen"], "title": "Secure Password Generator Based on Secure Pseudo-Random Number Generator", "comment": "in Chinese language", "summary": "In recent years, numerous incidents involving the leakage of website accounts\nand text passwords (referred to as passwords) have raised significant concerns\nregarding the potential exposure of personal information. These events\nunderscore the critical importance of both information security and password\nprotection. While many of these breaches are attributable to vulnerabilities\nwithin website infrastructure, the strength and security of the passwords\nthemselves also play a crucial role. Consequently, the creation of secure\npasswords constitutes a fundamental aspect of enhancing overall system security\nand protecting personal data. In response to these challenges, this study\npresents a secure password generation approach utilizing a cryptographically\nsecure Pseudo-Random Number Generator (PRNG). The generator is implemented\nusing a range of Message Authentication Code (MAC) algorithms, including the\nKeyed-Hash Message Authentication Code (HMAC), Cipher-based Message\nAuthentication Code (CMAC), and KECCAK Message Authentication Code (KMAC), to\nproduce robust random values suitable for password generation. To evaluate the\nproposed method, empirical assessments were conducted in accordance with the\nguidelines provided in the National Institute of Standards and Technology\n(NIST) Special Publication (SP) 800-90B. The evaluation focused on two primary\naspects: entropy estimation and verification of independent and identically\ndistributed (IID) properties. Experimental results indicate that the proposed\nmethod satisfies both entropy and IID requirements, thereby demonstrating its\nability to generate passwords with a high degree of randomness and security."}
{"id": "2509.02856", "categories": ["cs.CR", "cs.LG"], "pdf": "https://arxiv.org/pdf/2509.02856", "abs": "https://arxiv.org/abs/2509.02856", "authors": ["Syomantak Chaudhuri", "Thomas A. Courtade"], "title": "Managing Correlations in Data and Privacy Demand", "comment": "To appeat at ACM CCS, 2025", "summary": "Previous works in the differential privacy literature that allow users to\nchoose their privacy levels typically operate under the heterogeneous\ndifferential privacy (HDP) framework with the simplifying assumption that user\ndata and privacy levels are not correlated. Firstly, we demonstrate that the\nstandard HDP framework falls short when user data and privacy demands are\nallowed to be correlated. Secondly, to address this shortcoming, we propose an\nalternate framework, Add-remove Heterogeneous Differential Privacy (AHDP), that\njointly accounts for user data and privacy preference. We show that AHDP is\nrobust to possible correlations between data and privacy. Thirdly, we formalize\nthe guarantees of the proposed AHDP framework through an operational hypothesis\ntesting perspective. The hypothesis testing setup may be of independent\ninterest in analyzing other privacy frameworks as well. Fourthly, we show that\nthere exists non-trivial AHDP mechanisms that notably do not require prior\nknowledge of the data-privacy correlations. We propose some such mechanisms and\napply them to core statistical tasks such as mean estimation, frequency\nestimation, and linear regression. The proposed mechanisms are simple to\nimplement with minimal assumptions and modeling requirements, making them\nattractive for real-world use. Finally, we empirically evaluate proposed AHDP\nmechanisms, highlighting their trade-offs using LLM-generated synthetic\ndatasets, which we release for future research."}
{"id": "2509.03024", "categories": ["cs.CR", "cs.AI", "cs.LG"], "pdf": "https://arxiv.org/pdf/2509.03024", "abs": "https://arxiv.org/abs/2509.03024", "authors": ["Moontaha Nishat Chowdhury", "André Bauer", "Minxuan Zhou"], "title": "Efficient Privacy-Preserving Recommendation on Sparse Data using Fully Homomorphic Encryption", "comment": "The paper is accepted at the 21st IEEE International eScience\n  Conference (eScience'25) and will be published soon. Link:\n  https://www.escience-conference.org/2025/papers", "summary": "In today's data-driven world, recommendation systems personalize user\nexperiences across industries but rely on sensitive data, raising privacy\nconcerns. Fully homomorphic encryption (FHE) can secure these systems, but a\nsignificant challenge in applying FHE to recommendation systems is efficiently\nhandling the inherently large and sparse user-item rating matrices. FHE\noperations are computationally intensive, and naively processing various sparse\nmatrices in recommendation systems would be prohibitively expensive.\nAdditionally, the communication overhead between parties remains a critical\nconcern in encrypted domains. We propose a novel approach combining Compressed\nSparse Row (CSR) representation with FHE-based matrix factorization that\nefficiently handles matrix sparsity in the encrypted domain while minimizing\ncommunication costs. Our experimental results demonstrate high recommendation\naccuracy with encrypted data while achieving the lowest communication costs,\neffectively preserving user privacy."}
{"id": "2509.03037", "categories": ["cs.CR", "cs.ET", "cs.SE"], "pdf": "https://arxiv.org/pdf/2509.03037", "abs": "https://arxiv.org/abs/2509.03037", "authors": ["Shuzheng Wang", "Yue Huang", "Zhuoer Xu", "Yuming Huang", "Jing Tang"], "title": "TraceLLM: Security Diagnosis Through Traces and Smart Contracts in Ethereum", "comment": null, "summary": "Ethereum smart contracts hold tens of billions of USD in DeFi and NFTs, yet\ncomprehensive security analysis remains difficult due to unverified code,\nproxy-based architectures, and the reliance on manual inspection of complex\nexecution traces. Existing approaches fall into two main categories: anomaly\ntransaction detection, which flags suspicious transactions but offers limited\ninsight into specific attack strategies hidden in execution traces inside\ntransactions, and code vulnerability detection, which cannot analyze unverified\ncontracts and struggles to show how identified flaws are exploited in real\nincidents. As a result, analysts must still manually align transaction traces\nwith contract code to reconstruct attack scenarios and conduct forensics. To\naddress this gap, TraceLLM is proposed as a framework that leverages LLMs to\nintegrate execution trace-level detection with decompiled contract code. We\nintroduce a new anomaly execution path identification algorithm and an\nLLM-refined decompile tool to identify vulnerable functions and provide\nexplicit attack paths to LLM. TraceLLM establishes the first benchmark for\njoint trace and contract code-driven security analysis. For comparison, proxy\nbaselines are created by jointly transmitting the results of three\nrepresentative code analysis along with raw traces to LLM. TraceLLM identifies\nattacker and victim addresses with 85.19\\% precision and produces automated\nreports with 70.37\\% factual precision across 27 cases with ground truth expert\nreports, achieving 25.93\\% higher accuracy than the best baseline. Moreover,\nacross 148 real-world Ethereum incidents, TraceLLM automatically generates\nreports with 66.22\\% expert-verified accuracy, demonstrating strong\ngeneralizability."}
{"id": "2509.03058", "categories": ["cs.CR"], "pdf": "https://arxiv.org/pdf/2509.03058", "abs": "https://arxiv.org/abs/2509.03058", "authors": ["Zhenhua Xu", "Meng Han", "Wenpeng Xing"], "title": "EverTracer: Hunting Stolen Large Language Models via Stealthy and Robust Probabilistic Fingerprint", "comment": "Accepted by EMNLP2025 Main", "summary": "The proliferation of large language models (LLMs) has intensified concerns\nover model theft and license violations, necessitating robust and stealthy\nownership verification. Existing fingerprinting methods either require\nimpractical white-box access or introduce detectable statistical anomalies. We\npropose EverTracer, a novel gray-box fingerprinting framework that ensures\nstealthy and robust model provenance tracing. EverTracer is the first to\nrepurpose Membership Inference Attacks (MIAs) for defensive use, embedding\nownership signals via memorization instead of artificial trigger-output\noverfitting. It consists of Fingerprint Injection, which fine-tunes the model\non any natural language data without detectable artifacts, and Verification,\nwhich leverages calibrated probability variation signal to distinguish\nfingerprinted models. This approach remains robust against adaptive\nadversaries, including input level modification, and model-level modifications.\nExtensive experiments across architectures demonstrate EverTracer's\nstate-of-the-art effectiveness, stealthness, and resilience, establishing it as\na practical solution for securing LLM intellectual property. Our code and data\nare publicly available at https://github.com/Xuzhenhua55/EverTracer."}
{"id": "2509.03098", "categories": ["cs.CR"], "pdf": "https://arxiv.org/pdf/2509.03098", "abs": "https://arxiv.org/abs/2509.03098", "authors": ["Gustavo Banegas", "Anaëlle Le Dévéhat", "Benjamin Smith"], "title": "Compressed verification for post-quantum signatures with long-term public keys", "comment": null, "summary": "Many signature applications-such as root certificates, secure software\nupdates, and authentication protocols-involve long-lived public keys that are\ntransferred or installed once and then used for many verifications. This key\nlongevity makes post-quantum signature schemes with conservative assumptions\n(e.g., structure-free lattices) attractive for long-term security. But many\nsuch schemes, especially those with short signatures, suffer from extremely\nlarge public keys. Even in scenarios where bandwidth is not a major concern,\nlarge keys increase storage costs and slow down verification. We address this\nwith a method to replace large public keys in GPV-style signatures with\nsmaller, private verification keys. This significantly reduces verifier storage\nand runtime while preserving security. Applied to the conservative,\nshort-signature schemes Wave and Squirrels, our method compresses Squirrels-I\nkeys from 665 kB to 20.7 kB and Wave822 keys from 3.5 MB to 207.97 kB."}
{"id": "2509.03117", "categories": ["cs.CR"], "pdf": "https://arxiv.org/pdf/2509.03117", "abs": "https://arxiv.org/abs/2509.03117", "authors": ["Yuchen Yang", "Yiming Li", "Hongwei Yao", "Enhao Huang", "Shuo Shao", "Bingrun Yang", "Zhibo Wang", "Dacheng Tao", "Zhan Qin"], "title": "PromptCOS: Towards System Prompt Copyright Auditing for LLMs via Content-level Output Similarity", "comment": null, "summary": "The rapid progress of large language models (LLMs) has greatly enhanced\nreasoning tasks and facilitated the development of LLM-based applications. A\ncritical factor in improving LLM-based applications is the design of effective\nsystem prompts, which significantly impact the behavior and output quality of\nLLMs. However, system prompts are susceptible to theft and misuse, which could\nundermine the interests of prompt owners. Existing methods protect prompt\ncopyrights through watermark injection and verification but face challenges due\nto their reliance on intermediate LLM outputs (e.g., logits), which limits\ntheir practical feasibility.\n  In this paper, we propose PromptCOS, a method for auditing prompt copyright\nbased on content-level output similarity. It embeds watermarks by optimizing\nthe prompt while simultaneously co-optimizing a special verification query and\ncontent-level signal marks. This is achieved by leveraging cyclic output\nsignals and injecting auxiliary tokens to ensure reliable auditing in\ncontent-only scenarios. Additionally, it incorporates cover tokens to protect\nthe watermark from malicious deletion. For copyright verification, PromptCOS\nidentifies unauthorized usage by comparing the similarity between the\nsuspicious output and the signal mark. Experimental results demonstrate that\nour method achieves high effectiveness (99.3% average watermark similarity),\nstrong distinctiveness (60.8% greater than the best baseline), high fidelity\n(accuracy degradation of no more than 0.58%), robustness (resilience against\nthree types of potential attacks), and computational efficiency (up to 98.1%\nreduction in computational cost). Our code is available at GitHub\nhttps://github.com/LianPing-cyber/PromptCOS."}
{"id": "2509.03123", "categories": ["cs.CR"], "pdf": "https://arxiv.org/pdf/2509.03123", "abs": "https://arxiv.org/abs/2509.03123", "authors": ["Wei Xu", "Hui Zhu", "Yandong Zheng", "Song Bian", "Ning Sun", "Hao Yuan", "Dengguo Feng", "Hui Li"], "title": "Kangaroo: A Private and Amortized Inference Framework over WAN for Large-Scale Decision Tree Evaluation", "comment": null, "summary": "With the rapid adoption of Models-as-a-Service, concerns about data and model\nprivacy have become increasingly critical. To solve these problems, various\nprivacy-preserving inference schemes have been proposed. In particular, due to\nthe efficiency and interpretability of decision trees, private decision tree\nevaluation (PDTE) has garnered significant attention. However, existing PDTE\nschemes suffer from significant limitations: their communication and\ncomputation costs scale with the number of trees, the number of nodes, or the\ntree depth, which makes them inefficient for large-scale models, especially\nover WAN networks. To address these issues, we propose Kangaroo, a private and\namortized decision tree inference framework build upon packed homomorphic\nencryption. Specifically, we design a novel model hiding and encoding scheme,\ntogether with secure feature selection, oblivious comparison, and secure path\nevaluation protocols, enabling full amortization of the overhead as the number\nof nodes or trees scales. Furthermore, we enhance the performance and\nfunctionality of the framework through optimizations, including\nsame-sharing-for-same-model, latency-aware, and adaptive encoding adjustment\nstrategies. Kangaroo achieves a $14\\times$ to $59\\times$ performance\nimprovement over state-of-the-art (SOTA) one-round interactive schemes in WAN\nenvironments. For large-scale decision tree inference tasks, it delivers a\n$3\\times$ to $44\\times$ speedup compared to existing schemes. Notably, Kangaroo\nenables the evaluation of a random forest with $969$ trees and $411825$ nodes\nin approximately $60$ ms per tree (amortized) under WAN environments."}
{"id": "2509.03294", "categories": ["cs.CR", "cs.AI", "cs.LG", "68P27, 68T09, 94A60"], "pdf": "https://arxiv.org/pdf/2509.03294", "abs": "https://arxiv.org/abs/2509.03294", "authors": ["Napsu Karmitsa", "Antti Airola", "Tapio Pahikkala", "Tinja Pitkämäki"], "title": "A Comprehensive Guide to Differential Privacy: From Theory to User Expectations", "comment": null, "summary": "The increasing availability of personal data has enabled significant advances\nin fields such as machine learning, healthcare, and cybersecurity. However,\nthis data abundance also raises serious privacy concerns, especially in light\nof powerful re-identification attacks and growing legal and ethical demands for\nresponsible data use. Differential privacy (DP) has emerged as a principled,\nmathematically grounded framework for mitigating these risks. This review\nprovides a comprehensive survey of DP, covering its theoretical foundations,\npractical mechanisms, and real-world applications. It explores key algorithmic\ntools and domain-specific challenges - particularly in privacy-preserving\nmachine learning and synthetic data generation. The report also highlights\nusability issues and the need for improved communication and transparency in DP\nsystems. Overall, the goal is to support informed adoption of DP by researchers\nand practitioners navigating the evolving landscape of data privacy."}
{"id": "2509.03350", "categories": ["cs.CR"], "pdf": "https://arxiv.org/pdf/2509.03350", "abs": "https://arxiv.org/abs/2509.03350", "authors": ["Somiya Chhillar", "Mary K. Righi", "Rebecca E. Sutter", "Evgenios M. Kornaropoulos"], "title": "Exposing Privacy Risks in Anonymizing Clinical Data: Combinatorial Refinement Attacks on k-Anonymity Without Auxiliary Information", "comment": null, "summary": "Despite longstanding criticism from the privacy community, k-anonymity\nremains a widely used standard for data anonymization, mainly due to its\nsimplicity, regulatory alignment, and preservation of data utility. However,\nnon-experts often defend k-anonymity on the grounds that, in the absence of\nauxiliary information, no known attacks can compromise its protections. In this\nwork, we refute this claim by introducing Combinatorial Refinement Attacks\n(CRA), a new class of privacy attacks targeting k-anonymized datasets produced\nusing local recoding. This is the first method that does not rely on external\nauxiliary information or assumptions about the underlying data distribution.\nCRA leverages the utility-optimizing behavior of local recoding anonymization\nof ARX, which is a widely used open-source software for anonymizing data in\nclinical settings, to formulate a linear program that significantly reduces the\nspace of plausible sensitive values. To validate our findings, we partnered\nwith a network of free community health clinics, an environment where (1)\nauxiliary information is indeed hard to find due to the population they serve\nand (2) open-source k-anonymity solutions are attractive due to regulatory\nobligations and limited resources. Our results on real-world clinical microdata\nreveal that even in the absence of external information, established\nanonymization frameworks do not deliver the promised level of privacy, raising\ncritical privacy concerns."}
{"id": "2509.03367", "categories": ["cs.CR"], "pdf": "https://arxiv.org/pdf/2509.03367", "abs": "https://arxiv.org/abs/2509.03367", "authors": ["Narges Dadkhah", "Somayeh Mohammadi", "Gerhard Wunder"], "title": "Tuning Block Size for Workload Optimization in Consortium Blockchain Networks", "comment": null, "summary": "Determining the optimal block size is crucial for achieving high throughput\nin blockchain systems. Many studies have focused on tuning various components,\nsuch as databases, network bandwidth, and consensus mechanisms. However, the\nimpact of block size on system performance remains a topic of debate, often\nresulting in divergent views and even leading to new forks in blockchain\nnetworks. This research proposes a mathematical model to maximize performance\nby determining the ideal block size for Hyperledger Fabric, a prominent\nconsortium blockchain. By leveraging machine learning and solving the model\nwith a genetic algorithm, the proposed approach assesses how factors such as\nblock size, transaction size, and network capacity influence the block\nprocessing time. The integration of an optimization solver enables precise\nadjustments to block size configuration before deployment, ensuring improved\nperformance from the outset. This systematic approach aims to balance block\nprocessing efficiency, network latency, and system throughput, offering a\nrobust solution to improve blockchain performance across diverse business\ncontexts."}
{"id": "2509.03427", "categories": ["cs.CR", "E.3; C.2.0; C.2.4"], "pdf": "https://arxiv.org/pdf/2509.03427", "abs": "https://arxiv.org/abs/2509.03427", "authors": ["Pedro Correia", "Ivan Silva", "Ivone Amorim", "Eva Maia", "Isabel Praça"], "title": "Federated Learning: An approach with Hybrid Homomorphic Encryption", "comment": "19 pages, 8 figures, To be published in the conference Security and\n  Trust Management(STM), ESORICS 2025", "summary": "Federated Learning (FL) is a distributed machine learning approach that\npromises privacy by keeping the data on the device. However, gradient\nreconstruction and membership-inference attacks show that model updates still\nleak information. Fully Homomorphic Encryption (FHE) can address those privacy\nconcerns but it suffers from ciphertext expansion and requires prohibitive\noverhead on resource-constrained devices. We propose the first Hybrid\nHomomorphic Encryption (HHE) framework for FL that pairs the PASTA symmetric\ncipher with the BFV FHE scheme. Clients encrypt local model updates with PASTA\nand send both the lightweight ciphertexts and the PASTA key (itself\nBFV-encrypted) to the server, which performs a homomorphic evaluation of the\ndecryption circuit of PASTA and aggregates the resulting BFV ciphertexts. A\nprototype implementation, developed on top of the Flower FL framework, shows\nthat on independently and identically distributed MNIST dataset with 12 clients\nand 10 training rounds, the proposed HHE system achieves 97.6% accuracy, just\n1.3% below plaintext, while reducing client upload bandwidth by over 2,000x and\ncutting client runtime by 30% compared to a system based solely on the BFV FHE\nscheme. However, server computational cost increases by roughly 15621x for each\nclient participating in the training phase, a challenge to be addressed in\nfuture work."}
{"id": "2509.03442", "categories": ["cs.CR"], "pdf": "https://arxiv.org/pdf/2509.03442", "abs": "https://arxiv.org/abs/2509.03442", "authors": ["Zhuoyun Qian", "Hongyi Miao", "Yili Jiang", "Qin Hu", "Jiaqi Huang", "Cheng Zhang", "Fangtian Zhong"], "title": "Evaluating Diverse Feature Extraction Techniques of Multifaceted IoT Malware Analysis: A Survey", "comment": null, "summary": "As IoT devices continue to proliferate, their reliability is increasingly\nconstrained by security concerns. In response, researchers have developed\ndiverse malware analysis techniques to detect and classify IoT malware. These\ntechniques typically rely on extracting features at different levels from IoT\napplications, giving rise to a wide range of feature extraction methods.\nHowever, current approaches still face significant challenges when applied in\npractice. This survey provides a comprehensive review of feature extraction\ntechniques for IoT malware analysis from multiple perspectives. We first\nexamine static and dynamic feature extraction methods, followed by hybrid\napproaches. We then explore feature representation strategies based on graph\nlearning. Finally, we compare the strengths and limitations of existing\ntechniques, highlight open challenges, and outline promising directions for\nfuture research."}
