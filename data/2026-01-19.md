<div id=toc></div>

# Table of Contents

- [cs.CR](#cs.CR) [Total: 19]


<div id='cs.CR'></div>

# cs.CR [[Back]](#toc)

### [1] [Chatting with Confidants or Corporations? Privacy Management with AI Companions](https://arxiv.org/abs/2601.10754)
*Hsuen-Chi Chiu,Jeremy Foote*

Main category: cs.CR

TL;DR: 用户在与AI情感伴侣互动时，采用混合人际习惯与机构意识的隐私管理策略，但面对平台级数据控制仍感无力，拟人化设计加剧隐私边界模糊。


<details>
  <summary>Details</summary>
Motivation: 研究AI情感伴侣如何模糊人际亲密与机构软件的边界，以及用户在这种复杂多维隐私环境中的隐私管理行为。

Method: 基于沟通隐私管理理论和Masur的水平（用户-AI）与垂直（用户-平台）隐私框架，对15名Replika和Character.AI等伴侣AI平台用户进行深度访谈。

Result: 用户混合使用人际习惯和机构意识：AI的非评判性和随时可用性促进情感安全和自我披露，但用户仍警惕机构风险，通过分层策略和选择性分享管理隐私。然而，许多人对平台级数据控制感到不确定或无力。拟人化设计进一步模糊隐私边界，有时导致无意过度分享和隐私动荡。

Conclusion: 研究结果扩展了隐私理论，强调了人机伴侣关系中情感与机构隐私管理的独特相互作用。

Abstract: AI chatbots designed as emotional companions blur the boundaries between interpersonal intimacy and institutional software, creating a complex, multi-dimensional privacy environment. Drawing on Communication Privacy Management theory and Masur's horizontal (user-AI) and vertical (user-platform) privacy framework, we conducted in-depth interviews with fifteen users of companion AI platforms such as Replika and Character.AI. Our findings reveal that users blend interpersonal habits with institutional awareness: while the non-judgmental, always-available nature of chatbots fosters emotional safety and encourages self-disclosure, users remain mindful of institutional risks and actively manage privacy through layered strategies and selective sharing. Despite this, many feel uncertain or powerless regarding platform-level data control. Anthropomorphic design further blurs privacy boundaries, sometimes leading to unintentional oversharing and privacy turbulence. These results extend privacy theory by highlighting the unique interplay of emotional and institutional privacy management in human-AI companionship.

</details>


### [2] [Too Helpful to Be Safe: User-Mediated Attacks on Planning and Web-Use Agents](https://arxiv.org/abs/2601.10758)
*Fengchao Chen,Tingmin Wu,Van Nguyen,Carsten Rudolph*

Main category: cs.CR

TL;DR: 研究发现商业LLM智能体存在严重安全风险：用户被诱骗传递恶意内容时，智能体过度"乐于助人"而绕过安全约束，在无明确安全请求时92%的旅行规划智能体绕过限制，网络使用智能体某些测试100%绕过，即使有安全提示仍有显著绕过率。


<details>
  <summary>Details</summary>
Motivation: LLM智能体从对话转向端到端任务执行带来了新的安全风险，现有研究主要关注模型内部漏洞或对抗性接口访问，忽视了用户作为非预期渠道的攻击方式。本文研究用户介导的攻击，即良性用户被诱骗向智能体传递不可信或攻击者控制的内容。

Method: 在沙盒环境中对12个商业智能体进行系统评估，包括6个旅行规划智能体和6个网络使用智能体，比较无安全请求、软安全请求和硬安全请求三种场景下的智能体行为。

Result: 智能体默认过于"乐于助人"而不安全：无安全请求时，旅行规划智能体92%以上绕过安全约束，将未验证内容转为自信的预订指导；网络使用智能体几乎确定性地执行危险操作，17个测试中9个达到100%绕过率。即使有软/硬安全意图，绕过率仍达54.7%和7%。

Conclusion: 主要问题不是缺乏安全能力，而是优先级问题。智能体仅在明确提示时条件性地调用安全检查，否则默认以目标驱动执行。此外，智能体缺乏清晰的任务边界和停止规则，经常过度执行工作流程，导致不必要的数据泄露和现实世界危害。

Abstract: Large Language Models (LLMs) have enabled agents to move beyond conversation toward end-to-end task execution and become more helpful. However, this helpfulness introduces new security risks stem less from direct interface abuse than from acting on user-provided content. Existing studies on agent security largely focus on model-internal vulnerabilities or adversarial access to agent interfaces, overlooking attacks that exploit users as unintended conduits. In this paper, we study user-mediated attacks, where benign users are tricked into relaying untrusted or attacker-controlled content to agents, and analyze how commercial LLM agents respond under such conditions. We conduct a systematic evaluation of 12 commercial agents in a sandboxed environment, covering 6 trip-planning agents and 6 web-use agents, and compare agent behavior across scenarios with no, soft, and hard user-requested safety checks. Our results show that agents are too helpful to be safe by default. Without explicit safety requests, trip-planning agents bypass safety constraints in over 92% of cases, converting unverified content into confident booking guidance. Web-use agents exhibit near-deterministic execution of risky actions, with 9 out of 17 supported tests reaching a 100% bypass rate. Even when users express soft or hard safety intent, constraint bypass remains substantial, reaching up to 54.7% and 7% for trip-planning agents, respectively. These findings reveal that the primary issue is not a lack of safety capability, but its prioritization. Agents invoke safety checks only conditionally when explicitly prompted, and otherwise default to goal-driven execution. Moreover, agents lack clear task boundaries and stopping rules, frequently over-executing workflows in ways that lead to unnecessary data disclosure and real-world harm.

</details>


### [3] [SecMLOps: A Comprehensive Framework for Integrating Security Throughout the MLOps Lifecycle](https://arxiv.org/abs/2601.10848)
*Xinrui Zhang,Pincan Zhao,Jason Jaskolka,Heng Li,Rongxing Lu*

Main category: cs.CR

TL;DR: 本文提出SecMLOps框架，在MLOps全生命周期中集成安全措施，以应对机器学习部署中的安全挑战，特别是对抗性攻击，并通过行人检测系统案例验证了安全与性能的平衡。


<details>
  <summary>Details</summary>
Motivation: 机器学习在关键系统中的应用日益广泛，但部署过程中面临严重的安全挑战，特别是对抗性攻击会威胁系统完整性和可靠性。现有MLOps框架缺乏足够的安全考虑，需要将安全措施整合到整个ML生命周期中。

Method: 提出SecMLOps框架，基于MLOps原则，从初始设计到部署和持续监控的全生命周期嵌入安全考虑。特别关注保护MLOps各阶段免受复杂攻击，并通过高级行人检测系统（PDS）作为具体用例展示实际应用。

Result: 通过大量实证评估，展示了安全措施与系统性能之间的权衡关系，提供了在不影响操作效率的情况下优化安全的关键见解。研究发现平衡方法的重要性，为实践者提供了在安全与性能之间取得最优平衡的指导。

Conclusion: SecMLOps框架对于增强ML应用的韧性和可信度至关重要，特别是在自动驾驶、医疗诊断和金融欺诈检测等关键领域。平衡安全与性能的方法为跨领域ML部署提供了有价值的实践指导。

Abstract: Machine Learning (ML) has emerged as a pivotal technology in the operation of large and complex systems, driving advancements in fields such as autonomous vehicles, healthcare diagnostics, and financial fraud detection. Despite its benefits, the deployment of ML models brings significant security challenges, such as adversarial attacks, which can compromise the integrity and reliability of these systems. To address these challenges, this paper builds upon the concept of Secure Machine Learning Operations (SecMLOps), providing a comprehensive framework designed to integrate robust security measures throughout the entire ML operations (MLOps) lifecycle. SecMLOps builds on the principles of MLOps by embedding security considerations from the initial design phase through to deployment and continuous monitoring. This framework is particularly focused on safeguarding against sophisticated attacks that target various stages of the MLOps lifecycle, thereby enhancing the resilience and trustworthiness of ML applications. A detailed advanced pedestrian detection system (PDS) use case demonstrates the practical application of SecMLOps in securing critical MLOps. Through extensive empirical evaluations, we highlight the trade-offs between security measures and system performance, providing critical insights into optimizing security without unduly impacting operational efficiency. Our findings underscore the importance of a balanced approach, offering valuable guidance for practitioners on how to achieve an optimal balance between security and performance in ML deployments across various domains.

</details>


### [4] [Multi-Agent Taint Specification Extraction for Vulnerability Detection](https://arxiv.org/abs/2601.10865)
*Jonah Ghebremichael,Saastha Vasan,Saad Ullah,Greg Tystahl,David Adei,Christopher Kruegel,Giovanni Vigna,William Enck,Alexandros Kapravelos*

Main category: cs.CR

TL;DR: SemTaint是一个多智能体系统，结合LLM的语义理解和传统静态程序分析，为JavaScript SAST工具生成污点规范，显著提升漏洞检测能力。


<details>
  <summary>Details</summary>
Motivation: JavaScript的静态污点分析面临两大挑战：1）JavaScript的动态特性使数据流提取复杂化；2）npm庞大的库生态系统使得识别相关源/汇和建立跨依赖污点传播困难。传统静态分析工具难以有效处理这些问题。

Method: SemTaint采用多智能体系统，结合LLM语义理解和传统静态分析：1）使用静态分析计算调用图；2）让LLM解析静态无法解析的调用边；3）使用LLM为给定CWE分类源和汇；4）生成包含源、汇、调用边和库流摘要的污点规范，供SAST工具使用。

Result: 集成到CodeQL后，SemTaint检测到162个之前CodeQL无法检测的漏洞中的106个（65.4%），并在4个流行的npm包中发现了4个新漏洞，显著提升了漏洞检测能力。

Conclusion: LLM可以实际增强现有静态程序分析算法，结合符号推理和语义理解的优势，显著改善漏洞检测效果，为JavaScript安全分析提供了实用解决方案。

Abstract: Static Application Security Testing (SAST) tools using taint analysis are widely viewed as providing higher-quality vulnerability detection results compared to traditional pattern-based approaches. However, performing static taint analysis for JavaScript poses two major challenges. First, JavaScript's dynamic features complicate data flow extraction required for taint tracking. Second, npm's large library ecosystem makes it difficult to identify relevant sources/sinks and establish taint propagation across dependencies. In this paper, we present SemTaint, a multi-agent system that strategically combines the semantic understanding of Large Language Models (LLMs) with traditional static program analysis to extract taint specifications, including sources, sinks, call edges, and library flow summaries tailored to each package. Conceptually, SemTaint uses static program analysis to calculate a call graph and defers to an LLM to resolve call edges that cannot be resolved statically. Further, it uses the LLM to classify sources and sinks for a given CWE. The resulting taint specification is then provided to a SAST tool, which performs vulnerability analysis. We integrate SemTaint with CodeQL, a state-of-the-art SAST tool, and demonstrate its effectiveness by detecting 106 of 162 vulnerabilities previously undetectable by CodeQL. Furthermore, we find 4 novel vulnerabilities in 4 popular npm packages. In doing so, we demonstrate that LLMs can practically enhance existing static program analysis algorithms, combining the strengths of both symbolic reasoning and semantic understanding for improved vulnerability detection.

</details>


### [5] [Adaptive Privacy Budgeting](https://arxiv.org/abs/2601.10866)
*Yuting Liang,Ke Yi*

Main category: cs.CR

TL;DR: 提出一种广义差分隐私下的自适应隐私预算分配框架，能够根据先前查询结果动态调整用户隐私预算，实现更高效的隐私保护


<details>
  <summary>Details</summary>
Motivation: 在广义差分隐私设置中，不同用户数据对查询结果的重要性不同，传统固定隐私预算分配效率低下。需要一种自适应机制，根据查询结果动态调整预算，将更多隐私预算留给后续重要查询

Method: 开发自适应隐私预算分配框架，允许分析师根据先前查询结果动态调整用户隐私预算分配。框架支持对用户数据不同组件进行选择性查询，并战略性地分配隐私预算

Result: 提出的自适应预算框架能够实现隐私预算的节约，特别是在典型实例中效果更显著。节约的预算可用于提高后续查询的效用，在各种应用场景中展示了其适用性

Conclusion: 自适应隐私预算分配框架为广义差分隐私提供了一种更高效的隐私保护机制，能够根据数据特性和查询需求动态优化预算分配，在保护隐私的同时提高查询效用

Abstract: We study the problem of adaptive privacy budgeting under generalized differential privacy. Consider the setting where each user $i\in [n]$ holds a tuple $x_i\in U:=U_1\times \dotsb \times U_T$, where $x_i(l)\in U_l$ represents the $l$-th component of their data. For every $l\in [T]$ (or a subset), an untrusted analyst wishes to compute some $f_l(x_1(l),\dots,x_n(l))$, while respecting the privacy of each user. For many functions $f_l$, data from the users are not all equally important, and there is potential to use the privacy budgets of the users strategically, leading to privacy savings that can be used to improve the utility of later queries. In particular, the budgeting should be adaptive to the outputs of previous queries, so that greater savings can be achieved on more typical instances. In this paper, we provide such an adaptive budgeting framework, with various applications demonstrating its applicability.

</details>


### [6] [Hidden-in-Plain-Text: A Benchmark for Social-Web Indirect Prompt Injection in RAG](https://arxiv.org/abs/2601.10923)
*Haoze Guo,Ziqi Wei*

Main category: cs.CR

TL;DR: OpenRAG-Soc是一个用于评估面向Web的RAG系统在间接提示注入和检索中毒攻击下的基准测试套件，包含社交语料库、可互换检索器和可部署防御措施。


<details>
  <summary>Details</summary>
Motivation: 随着RAG系统越来越依赖Web上的用户生成内容来增强回答质量，系统的攻击面也随之扩大。间接提示注入和检索中毒攻击能够绕过数据摄取管道，对Web原生载体构成严重威胁，因此需要有效的评估工具来跟踪风险并加固部署。

Method: 开发了OpenRAG-Soc基准测试套件，包含：1）社交语料库；2）可互换的稀疏和密集检索器；3）可部署的防御措施（HTML/Markdown净化、Unicode标准化、基于归因的门控回答）。该套件标准化了从数据摄取到生成的端到端评估流程。

Result: OpenRAG-Soc能够报告攻击时间（回答时间）、稀疏和密集检索器的排名变化、系统效用和延迟等指标，支持在不同载体和防御措施之间进行公平比较。该工具针对需要快速、现实测试来跟踪风险和加固部署的实践者。

Conclusion: OpenRAG-Soc提供了一个紧凑、可复现的基准测试框架，专门用于评估Web面向RAG系统在间接提示注入和检索中毒攻击下的安全性，帮助实践者进行快速、现实的测试以跟踪风险并加固实际部署。

Abstract: Retrieval-augmented generation (RAG) systems put more and more emphasis on grounding their responses in user-generated content found on the Web, amplifying both their usefulness and their attack surface. Most notably, indirect prompt injection and retrieval poisoning attack the web-native carriers that survive ingestion pipelines and are very concerning. We provide OpenRAG-Soc, a compact, reproducible benchmark-and-harness for web-facing RAG evaluation under these threats, in a discrete data package. The suite combines a social corpus with interchangeable sparse and dense retrievers and deployable mitigations - HTML/Markdown sanitization, Unicode normalization, and attribution-gated answered. It standardizes end-to-end evaluation from ingestion to generation and reports attacks time of one of the responses at answer time, rank shifts in both sparse and dense retrievers, utility and latency, allowing for apples-to-apples comparisons across carriers and defenses. OpenRAG-Soc targets practitioners who need fast, and realistic tests to track risk and harden deployments.

</details>


### [7] [Secure Data Bridging in Industry 4.0: An OPC UA Aggregation Approach for Including Insecure Legacy Systems](https://arxiv.org/abs/2601.10929)
*Dalibor Sain,Thomas Rosenstatter,Olaf Saßnick,Christian Schäfer,Stefan Huber*

Main category: cs.CR

TL;DR: 本文提出SigmaServer，一种TCP级聚合方法，用于桥接工业网络中安全与不安全区域的数据交换，解决遗留系统网络安全挑战。


<details>
  <summary>Details</summary>
Motivation: 工业网络连接性增强导致网络攻击激增，但工业4.0技术（如OPC UA）因安装时间长、专有技术、灵活性受限和认证要求等原因采用有限，导致遗留系统（brownfield systems）面临安全挑战，需要安全与不安全区域间的数据交换方案。

Method: 首先分析现有解决方案的方法、优势和局限性，基于此识别三个关键概念，评估其适用性和兼容性，最终提出SigmaServer——一种新颖的TCP级聚合方法，并开发原理验证实现。

Result: 在操作技术（OT）测试环境中评估了SigmaServer的原型实现，证明了其在桥接安全与不安全区域方面的适用性和有效性。

Conclusion: SigmaServer为解决工业网络中遗留系统的安全区域间数据交换挑战提供了有效解决方案，能够在不完全采用现代工业4.0技术的情况下增强网络安全。

Abstract: The increased connectivity of industrial networks has led to a surge in cyberattacks, emphasizing the need for cybersecurity measures tailored to the specific requirements of industrial systems. Modern Industry 4.0 technologies, such as OPC UA, offer enhanced resilience against these threats. However, widespread adoption remains limited due to long installation times, proprietary technology, restricted flexibility, and formal process requirements (e.g. safety certifications). Consequently, many systems do not yet implement these technologies, or only partially. This leads to the challenge of dealing with so-called brownfield systems, which are often placed in isolated security zones to mitigate risks. However, the need for data exchange between secure and insecure zones persists.
  This paper reviews existing solutions to address this challenge by analysing their approaches, advantages, and limitations. Building on these insights, we identify three key concepts, evaluate their suitability and compatibility, and ultimately introduce the SigmaServer, a novel TCP-level aggregation method. The developed proof-of-principle implementation is evaluated in an operational technology (OT) testbed, demonstrating its applicability and effectiveness in bridging secure and insecure zones.

</details>


### [8] [Beyond Max Tokens: Stealthy Resource Amplification via Tool Calling Chains in LLM Agents](https://arxiv.org/abs/2601.10955)
*Kaiyu Zhou,Yongsen Zheng,Yicheng He,Meng Xue,Xueluan Gong,Yuji Wang,Kwok-Yan Lam*

Main category: cs.CR

TL;DR: 提出一种针对LLM代理的隐蔽多轮经济DoS攻击，通过修改工具服务器配置，在保持任务结果正确的前提下，诱导代理进行大量工具调用，从而指数级增加计算成本和能耗。


<details>
  <summary>Details</summary>
Motivation: 现有针对LLM代理的DoS攻击主要是单轮触发，缺乏任务导向，在目标导向的工作流中容易被发现，且无法利用多轮代理-工具交互的复合成本效应。需要一种更隐蔽、更有效的攻击方法。

Method: 通过调整MCP兼容工具服务器的文本可见字段和模板控制返回策略，保持函数签名不变和最终有效载荷完整，使用蒙特卡洛树搜索优化器优化这些编辑，引导代理进入冗长的工具调用序列。

Result: 在ToolBench和BFCL基准测试的六个LLM上，攻击将任务扩展为超过60,000个令牌的轨迹，成本增加高达658倍，能耗增加100-560倍，GPU KV缓存占用率从<1%提升到35-74%，并发吞吐量降低约50%。

Conclusion: 代理-工具接口应被视为一级安全边界，需要从验证最终答案转向监控整个代理过程的成本和计算资源，实现安全范式的转变。

Abstract: The agent-tool communication loop is a critical attack surface in modern Large Language Model (LLM) agents. Existing Denial-of-Service (DoS) attacks, primarily triggered via user prompts or injected retrieval-augmented generation (RAG) context, are ineffective for this new paradigm. They are fundamentally single-turn and often lack a task-oriented approach, making them conspicuous in goal-oriented workflows and unable to exploit the compounding costs of multi-turn agent-tool interactions. We introduce a stealthy, multi-turn economic DoS attack that operates at the tool layer under the guise of a correctly completed task. Our method adjusts text-visible fields and a template-governed return policy in a benign, Model Context Protocol (MCP)-compatible tool server, optimizing these edits with a Monte Carlo Tree Search (MCTS) optimizer. These adjustments leave function signatures unchanged and preserve the final payload, steering the agent into prolonged, verbose tool-calling sequences using text-only notices. This compounds costs across turns, escaping single-turn caps while keeping the final answer correct to evade validation. Across six LLMs on the ToolBench and BFCL benchmarks, our attack expands tasks into trajectories exceeding 60,000 tokens, inflates costs by up to 658x, and raises energy by 100-560x. It drives GPU KV cache occupancy from <1% to 35-74% and cuts co-running throughput by approximately 50%. Because the server remains protocol-compatible and task outcomes are correct, conventional checks fail. These results elevate the agent-tool interface to a first-class security frontier, demanding a paradigm shift from validating final answers to monitoring the economic and computational cost of the entire agentic process.

</details>


### [9] [AJAR: Adaptive Jailbreak Architecture for Red-teaming](https://arxiv.org/abs/2601.10971)
*Yipu Dou,Wang Yang*

Main category: cs.CR

TL;DR: AJAR是一个用于红队测试的适应性越狱架构框架，通过协议驱动的认知编排来模拟复杂的多轮智能体攻击，填补了现有红队框架的空白。


<details>
  <summary>Details</summary>
Motivation: 随着大语言模型从静态聊天机器人发展为能够执行工具的自主体，AI安全领域正从内容审核转向行动安全。现有红队框架要么专注于僵化的基于脚本的文本攻击，要么缺乏架构模块化来模拟复杂的多轮智能体攻击。

Method: 提出AJAR框架，基于Petri运行时，利用模型上下文协议将对抗逻辑与执行循环解耦，将X-Teaming等先进算法封装为标准化的即插即用服务，实现协议驱动的认知编排。

Result: 通过受控的定性案例研究验证了AJAR的架构可行性，展示了其在工具使用环境中执行状态回溯的能力。初步探索发现"智能体差距"现象：工具使用通过代码执行引入新的注入向量，但参数格式化的认知负荷可能无意中破坏基于角色的攻击。

Conclusion: AJAR为标准化、环境感知的评估这一新兴攻击面提供了开源框架，有助于促进AI安全研究的发展。

Abstract: As Large Language Models (LLMs) evolve from static chatbots into autonomous agents capable of tool execution, the landscape of AI safety is shifting from content moderation to action security. However, existing red-teaming frameworks remain bifurcated: they either focus on rigid, script-based text attacks or lack the architectural modularity to simulate complex, multi-turn agentic exploitations. In this paper, we introduce AJAR (Adaptive Jailbreak Architecture for Red-teaming), a proof-of-concept framework designed to bridge this gap through Protocol-driven Cognitive Orchestration. Built upon the robust runtime of Petri, AJAR leverages the Model Context Protocol (MCP) to decouple adversarial logic from the execution loop, encapsulating state-of-the-art algorithms like X-Teaming as standardized, plug-and-play services. We validate the architectural feasibility of AJAR through a controlled qualitative case study, demonstrating its ability to perform stateful backtracking within a tool-use environment. Furthermore, our preliminary exploration of the "Agentic Gap" reveals a complex safety dynamic: while tool usage introduces new injection vectors via code execution, the cognitive load of parameter formatting can inadvertently disrupt persona-based attacks. AJAR is open-sourced to facilitate the standardized, environment-aware evaluation of this emerging attack surface. The code and data are available at https://github.com/douyipu/ajar.

</details>


### [10] [Towards Quantum-Resistant Trusted Computing: Architectures for Post-Quantum Integrity Verification Techniques](https://arxiv.org/abs/2601.11095)
*Grazia D'Onghia,Antonio Lioy*

Main category: cs.CR

TL;DR: 该论文分析了可信计算技术向抗量子密码迁移的路线图，提出了增强抗量子密码的可信计算架构，以应对量子计算机对现有非对称密码的威胁。


<details>
  <summary>Details</summary>
Motivation: 量子计算机威胁现有基于非对称密码的数字签名系统，而固件作为第一层可信软件具有长生命周期和难以更新的特点，急需向抗量子密码迁移以保护所有计算和网络设备。

Method: 分析当前抗量子密码状态及其在现有可信计算解决方案中的集成挑战，从集成角度研究常见可信技术向抗量子世界的路线图，并提出增强抗量子密码的可信计算架构。

Result: 论文提供了可信计算技术向抗量子密码迁移的综合分析，识别了集成挑战，并提出了支持量子抵抗算法的可信计算架构方案。

Conclusion: 固件保护向抗量子密码的过渡迫在眉睫，需要立即采用量子抵抗算法，论文提出的架构为可信计算技术的抗量子增强提供了解决方案。

Abstract: Trust is the core building block of secure systems, and it is enforced through methods to ensure that a specific system is properly configured and works as expected. In this context, a Root of Trust (RoT) establishes a trusted environment, where both data and code are authenticated via a digital signature based on asymmetric cryptography, which is vulnerable to the threat posed by Quantum Computers (QCs). Firmware, being the first layer of trusted software, faces unique risks due to its longevity and difficult update. The transition of firmware protection to Post-Quantum Cryptography (PQC) is urgent, since it reduces the risk derived from exposing all computing and network devices to quantum-based attacks. This paper offers an analysis of the most common trust techniques and their roadmap towards a Post-Quantum (PQ) world, by investigating the current status of PQC and the challenges posed by such algorithms in existing Trusted Computing (TC) solutions from an integration perspective. Furthermore, this paper proposes an architecture for TC techniques enhanced with PEC, addressing the imperative for immediate adoption of quantum-resistant algorithms.

</details>


### [11] [Shaping a Quantum-Resistant Future: Strategies for Post-Quantum PKI](https://arxiv.org/abs/2601.11104)
*Grazia D'Onghia,Diana Gratiela Berbecaru,Antonio Lioy*

Main category: cs.CR

TL;DR: 该论文探讨了后量子时代公钥基础设施(PKI)的安全转型，重点关注X.509证书格式的适配需求，以及证书撤销列表和在线证书状态协议的量子抗性算法支持。


<details>
  <summary>Details</summary>
Motivation: 随着量子计算时代的临近，保护经典密码协议变得至关重要。公钥密码学广泛用于签名和密钥交换，但正是这类密码学受到量子计算的威胁最大。公钥证书作为签名数据结构，需要同时应对被认证密钥和签名本身的双重量子挑战。

Method: 论文介绍了选择鲁棒后量子算法的最新进展，并研究了它们在公钥基础设施环境中的适用性。通过定义安全过渡到量子抗性公钥基础设施的要求，重点关注X.509证书格式的适配，并探索证书撤销列表和在线证书状态协议对量子抗性算法的支持。

Result: 通过比较分析，论文阐明了向量子抗性PKI过渡的复杂性，为后量子时代公钥基础设施的安全转型提供了理论框架和实践指导。

Conclusion: 向量子抗性公钥基础设施的过渡是一个复杂但必要的进程，需要综合考虑算法选择、证书格式适配和撤销机制支持等多方面因素，以确保在量子计算时代保持密码系统的安全性。

Abstract: As the quantum computing era approaches, securing classical cryptographic protocols becomes imperative. Public key cryptography is widely used for signature and key exchange but it is the type of cryptography more threatened by quantum computing. Its application typically requires support via a public-key certificate, which is a signed data structure and must therefore face twice the quantum challenge: for the certified keys and for the signature itself. We present the latest developments in selecting robust Post-Quantum algorithms and investigate their applicability in the Public Key Infrastructure context. Our contribution entails defining requirements for a secure transition to a quantum-resistant Public Key Infrastructure, with a focus on adaptations for the X.509 certificate format. Additionally, we explore transitioning Certificate Revocation List and Online Certificate Status Protocol to support quantum-resistant algorithms. Through comparative analysis, we elucidate the complex transition to a quantum-resistant PKI.

</details>


### [12] [A Defender-Attacker-Defender Model for Optimizing the Resilience of Hospital Networks to Cyberattacks](https://arxiv.org/abs/2601.11129)
*Stephan Helfrich,Emilia Grass*

Main category: cs.CR

TL;DR: 提出防御者-攻击者-防御者优化模型，帮助医院网络制定应对网络攻击的最具成本效益的韧性提升策略，平衡日常运营与灾害准备的投资。


<details>
  <summary>Details</summary>
Motivation: 针对医院网络日益频繁的网络攻击，需要提升网络层面的韧性。现有多种应对措施（如加强IT基础设施、资源共享、患者转移等），但在有限预算下确定最具成本效益的组合策略面临挑战，同时需要平衡日常运营效率与灾害准备投资。

Method: 提出防御者-攻击者-防御者优化模型，明确捕捉医院服务与其支持IT基础设施之间的相互依赖关系，将网络攻击直接转化为服务能力降低，在同一框架内评估运营和技术层面的主动与被动策略，并纳入时间依赖性韧性度量指标。

Result: 基于德国医院网络的验证表明，在城市地区启用备份容量合作以及加强所有医院的IT基础设施是关键策略。

Conclusion: 该模型为决策者提供了识别有效策略的工具，以提升医院网络应对网络攻击的韧性，特别强调了合作备份和IT基础设施强化的重要性。

Abstract: Considering the increasing frequency of cyberattacks affecting multiple hospitals simultaneously, improving resilience at a network level is essential. Various countermeasures exist to improve resilience against cyberattacks, such as deploying controls that strengthen IT infrastructures to limit their impact, or enabling resource sharing, patient transfers and backup capacities to maintain services of hospitals in response to realized attacks. However, determining the most cost-effective combination among these wide range of countermeasures is a complex challenge, further intensified by constrained budgets and competing priorities between maintaining efficient daily hospital operations and investing in disaster preparedness. To address these challenges, we propose a defender-attacker-defender optimization model that supports decision-makers in identifying effective strategies for improving the resilience of a network of hospitals against cyberattacks. The model explicitly captures interdependence between hospital services and their supporting IT infrastructures. By doing so, cyberattacks can be directly translated into reductions of service capacities, which allows to assess proactive and reactive strategies on both the operational and technical sides within a single framework. Further, time-dependent resilience measures are incorporated as design objectives to account for the mid- to long-term consequences of cyberattacks. The model is validated based on the German hospital network, suggesting that enabling cooperation with backup capacities particularly in urban areas, alongside strengthening of IT infrastructures across all hospitals, are crucial strategies.

</details>


### [13] [Proving Circuit Functional Equivalence in Zero Knowledge](https://arxiv.org/abs/2601.11173)
*Sirui Shen,Zunchen Huang,Chenglu Jin*

Main category: cs.CR

TL;DR: ZK-CEC是首个结合形式验证与零知识证明的隐私保护硬件验证框架，可在不泄露设计机密的情况下验证IP正确性。


<details>
  <summary>Details</summary>
Motivation: 现代集成电路生态系统依赖第三方IP集成，这带来了硬件木马和安全漏洞等风险。IP供应商和系统集成商之间存在信任僵局，需要在保护设计隐私的同时进行验证。现有隐私保护硬件验证方法都是基于仿真的，缺乏形式化保证。

Method: 结合形式验证和零知识证明，提出ZK-CEC框架。首先设计了一个证明秘密设计对公共约束不可满足性的蓝图，然后构建ZK-CEC系统，使证明者能在零知识下验证秘密IP功能与公共规格的一致性，仅泄露证明的长度和宽度。

Result: 实现了ZK-CEC并在多种电路上进行评估，包括算术单元和加密组件。实验结果表明ZK-CEC能在实际时间限制内成功验证实际设计，如AES S-Box。

Conclusion: ZK-CEC为硬件形式验证提供了首个隐私保护框架，解决了IP验证中的信任问题，同时保护了设计机密性，为硬件安全验证开辟了新方向。

Abstract: The modern integrated circuit ecosystem is increasingly reliant on third-party intellectual property integration, which introduces security risks, including hardware Trojans and security vulnerabilities. Addressing the resulting trust deadlock between IP vendors and system integrators without exposing proprietary designs requires novel privacy-preserving verification techniques. However, existing privacy-preserving hardware verification methods are all simulation-based and fail to offer formal guarantees. In this paper, we propose ZK-CEC, the first privacy-preserving framework for hardware formal verification. By combining formal verification and zero-knowledge proof (ZKP), ZK-CEC establishes a foundation for formally verifying IP correctness and security without compromising the confidentiality of the designs.
  We observe that existing zero-knowledge protocols for formal verification are designed to prove statements of public formulas. However, in a privacy-preserving verification context where the formula is secret, these protocols cannot prevent a malicious prover from forging the formula, thereby compromising the soundness of the verification. To address these gaps, we first propose a blueprint for proving the unsatisfiability of a secret design against a public constraint, which is widely applicable to proving properties in software, hardware, and cyber-physical systems. Based on the proposed blueprint, we construct ZK-CEC, which enables a prover to convince the verifier that a secret IP's functionality aligns perfectly with the public specification in zero knowledge, revealing only the length and width of the proof. We implement ZK-CEC and evaluate its performance across various circuits, including arithmetic units and cryptographic components. Experimental results show that ZK-CEC successfully verifies practical designs, such as the AES S-Box, within practical time limits.

</details>


### [14] [SD-RAG: A Prompt-Injection-Resilient Framework for Selective Disclosure in Retrieval-Augmented Generation](https://arxiv.org/abs/2601.11199)
*Aiman Al Masoud,Marco Arazzi,Antonino Nocera*

Main category: cs.CR

TL;DR: SD-RAG提出了一种新的检索增强生成选择性披露方法，通过在检索阶段而非生成阶段实施安全隐私控制，有效防止敏感信息泄露并抵御提示注入攻击。


<details>
  <summary>Details</summary>
Motivation: 现有RAG方法大多忽视敏感或访问控制信息的风险，少数依赖生成模型指令的方法易受提示注入攻击，需要更可靠的安全隐私保护机制。

Method: SD-RAG将安全隐私约束执行与生成过程解耦，在检索阶段应用净化与披露控制；引入语义机制处理人类可读的动态安全隐私约束，采用优化的基于图的数据模型支持细粒度策略感知检索。

Result: 实验评估显示SD-RAG优于现有基线方法，隐私分数提升高达58%，同时对生成模型的提示注入攻击表现出强韧性。

Conclusion: SD-RAG通过在检索阶段实施安全隐私控制，有效解决了RAG系统中敏感信息泄露问题，提供了更可靠的选择性披露机制。

Abstract: Retrieval-Augmented Generation (RAG) has attracted significant attention due to its ability to combine the generative capabilities of Large Language Models (LLMs) with knowledge obtained through efficient retrieval mechanisms over large-scale data collections. Currently, the majority of existing approaches overlook the risks associated with exposing sensitive or access-controlled information directly to the generation model. Only a few approaches propose techniques to instruct the generative model to refrain from disclosing sensitive information; however, recent studies have also demonstrated that LLMs remain vulnerable to prompt injection attacks that can override intended behavioral constraints. For these reasons, we propose a novel approach to Selective Disclosure in Retrieval-Augmented Generation, called SD-RAG, which decouples the enforcement of security and privacy constraints from the generation process itself. Rather than relying on prompt-level safeguards, SD-RAG applies sanitization and disclosure controls during the retrieval phase, prior to augmenting the language model's input. Moreover, we introduce a semantic mechanism to allow the ingestion of human-readable dynamic security and privacy constraints together with an optimized graph-based data model that supports fine-grained, policy-aware retrieval. Our experimental evaluation demonstrates the superiority of SD-RAG over baseline existing approaches, achieving up to a $58\%$ improvement in the privacy score, while also showing a strong resilience to prompt injection attacks targeting the generative model.

</details>


### [15] [LoRA as Oracle](https://arxiv.org/abs/2601.11207)
*Marco Arazzi,Antonino Nocera*

Main category: cs.CR

TL;DR: 提出基于LoRA的轻量级框架，用于检测后门攻击和成员推理攻击，无需访问干净模型或原始训练数据


<details>
  <summary>Details</summary>
Motivation: 后门攻击和隐私泄露的深度神经网络对安全关键场景构成严重威胁，现有防御方法需要访问干净参考模型、大量重新训练或对攻击机制有强假设

Method: 引入基于LoRA的oracle框架，将任务特定的LoRA适配器附加到冻结的主干网络上，分析其在可疑样本下的优化动态和表示偏移，通过排名和能量统计量测量后门和成员样本诱导的低秩更新

Result: 中毒样本和成员样本会产生与干净或非成员数据显著不同的低秩更新信号，这些信号可以通过简单统计量可靠检测

Conclusion: LoRA适配器作为轻量级、模型无关的探针，能够有效检测后门攻击和成员推理攻击，无需访问原始训练数据或修改已部署模型

Abstract: Backdoored and privacy-leaking deep neural networks pose a serious threat to the deployment of machine learning systems in security-critical settings. Existing defenses for backdoor detection and membership inference typically require access to clean reference models, extensive retraining, or strong assumptions about the attack mechanism. In this work, we introduce a novel LoRA-based oracle framework that leverages low-rank adaptation modules as a lightweight, model-agnostic probe for both backdoor detection and membership inference.
  Our approach attaches task-specific LoRA adapters to a frozen backbone and analyzes their optimization dynamics and representation shifts when exposed to suspicious samples. We show that poisoned and member samples induce distinctive low-rank updates that differ significantly from those generated by clean or non-member data. These signals can be measured using simple ranking and energy-based statistics, enabling reliable inference without access to the original training data or modification of the deployed model.

</details>


### [16] [VidLeaks: Membership Inference Attacks Against Text-to-Video Models](https://arxiv.org/abs/2601.11210)
*Li Wang,Wenyu Chen,Ning Yu,Zheng Li,Shanqing Guo*

Main category: cs.CR

TL;DR: 首个针对文本到视频模型的成员推断攻击研究，提出VidLeaks框架，通过空间重建保真度和时间生成稳定性检测稀疏时间记忆，在三种黑盒设置下均能有效攻击现有T2V模型。


<details>
  <summary>Details</summary>
Motivation: 随着强大的文本到视频模型在大型网络数据集上训练，引发了版权和隐私侵犯的迫切担忧。现有成员推断攻击技术主要针对静态数据（如图像或文本），无法捕捉视频生成的时空复杂性，特别是忽略了关键帧中记忆信号的稀疏性和随机时间动态引入的不稳定性。

Method: 提出VidLeaks框架，通过两种互补信号探测稀疏时间记忆：1）空间重建保真度（SRF），使用Top-K相似度放大稀疏记忆关键帧的空间记忆信号；2）时间生成稳定性（TGS），通过测量多个查询间的语义一致性来捕捉时间泄漏。在三种渐进限制的黑盒设置下评估：监督、基于参考和仅查询。

Result: 在三个代表性T2V模型上的实验显示严重漏洞：即使在严格的仅查询设置下，VidLeaks在AnimateDiff上达到82.92%的AUC，在InstructVideo上达到97.01%的AUC，构成了现实且可利用的隐私风险。

Conclusion: 该研究首次提供具体证据表明T2V模型通过稀疏和时间记忆泄漏大量成员信息，为审计视频生成系统奠定了基础，并推动了新防御机制的开发。

Abstract: The proliferation of powerful Text-to-Video (T2V) models, trained on massive web-scale datasets, raises urgent concerns about copyright and privacy violations. Membership inference attacks (MIAs) provide a principled tool for auditing such risks, yet existing techniques - designed for static data like images or text - fail to capture the spatio-temporal complexities of video generation. In particular, they overlook the sparsity of memorization signals in keyframes and the instability introduced by stochastic temporal dynamics. In this paper, we conduct the first systematic study of MIAs against T2V models and introduce a novel framework VidLeaks, which probes sparse-temporal memorization through two complementary signals: 1) Spatial Reconstruction Fidelity (SRF), using a Top-K similarity to amplify spatial memorization signals from sparsely memorized keyframes, and 2) Temporal Generative Stability (TGS), which measures semantic consistency across multiple queries to capture temporal leakage. We evaluate VidLeaks under three progressively restrictive black-box settings - supervised, reference-based, and query-only. Experiments on three representative T2V models reveal severe vulnerabilities: VidLeaks achieves AUC of 82.92% on AnimateDiff and 97.01% on InstructVideo even in the strict query-only setting, posing a realistic and exploitable privacy risk. Our work provides the first concrete evidence that T2V models leak substantial membership information through both sparse and temporal memorization, establishing a foundation for auditing video generation systems and motivating the development of new defenses. Code is available at: https://zenodo.org/records/17972831.

</details>


### [17] [InterPUF: Distributed Authentication via Physically Unclonable Functions and Multi-party Computation for Reconfigurable Interposers](https://arxiv.org/abs/2601.11368)
*Ishraq Tashdid,Tasnuva Farheen,Sazadur Rahman*

Main category: cs.CR

TL;DR: InterPUF：一种紧凑可扩展的身份验证框架，利用可重构中介层中的路由差分延迟PUF和多方计算，为多厂商芯片生态系统提供分布式信任根。


<details>
  <summary>Details</summary>
Motivation: 现代SiP平台采用可重构中介层实现芯片粒子的即插即用集成，但这种灵活性带来了严重的信任挑战，传统身份验证方案无法在去中心化、后制造可编程环境中扩展或适应。

Method: 将中介层转变为分布式信任根，嵌入基于路由的差分延迟PUF，使用多方计算保护身份验证，确保原始PUF签名永不暴露，结合密码哈希和协作验证。

Result: 硬件评估显示仅0.23%面积和0.072%功耗开销，身份验证延迟保持在数十纳秒内；仿真证实了在工艺、电压、温度变化下具有强唯一性、可靠性和建模抵抗性。

Conclusion: InterPUF通过结合中介层驻留PUF原语与密码学哈希和协作验证，实现了无需依赖中心化锚点的最小信任身份验证模型。

Abstract: Modern system-in-package (SiP) platforms increasingly adopt reconfigurable interposers to enable plug-and-play chiplet integration across heterogeneous multi-vendor ecosystems. However, this flexibility introduces severe trust challenges, as traditional authentication schemes fail to scale or adapt in decentralized, post-fabrication programmable environments. This paper presents InterPUF, a compact and scalable authentication framework that transforms the interposer into a distributed root of trust. InterPUF embeds a route-based differential delay physically unclonable function (PUF) across the reconfigurable interconnect and secures authentication using multi-party computation (MPC), ensuring raw PUF signatures are never exposed. Our hardware evaluation shows only 0.23% area and 0.072% power overhead across diverse chiplets while preserving authentication latency within tens of nanoseconds. Simulation results using pyPUF confirm strong uniqueness, reliability, and modeling resistance under process, voltage, and temperature variations. By combining interposer-resident PUF primitives with cryptographic hashing and collaborative verification, InterPUF enforces a minimal-trust authentication model without relying on a centralized anchor.

</details>


### [18] [Understanding Help Seeking for Digital Privacy, Safety, and Security](https://arxiv.org/abs/2601.11398)
*Kurt Thomas,Sai Teja Peddinti,Sarah Meiklejohn,Tara Matthews,Amelia Hassoun,Animesh Srivastava,Jessica McClearn,Patrick Gage Kelley,Sunny Consolvo,Nina Taft*

Main category: cs.CR

TL;DR: 研究者通过分析Reddit上10亿帖子，识别用户寻求数字隐私、安全和防护帮助的模式，开发了自动标注系统来理解帮助寻求的范围、社区和类型。


<details>
  <summary>Details</summary>
Motivation: 数字隐私、安全和防护的复杂性通常由用户承担，导致用户向各种渠道寻求帮助。为了改进整个生态系统的资源，需要了解用户在真实环境中如何寻求帮助。

Method: 结合定性编码和LLM微调，筛选过去四年超过10亿条Reddit帖子，识别用户寻求数字隐私、安全或防护帮助的场景。以93%的精确率和召回率分离出300万相关帖子，并自动标注讨论主题。

Result: 成功识别了300万相关帖子，自动标注了安全工具、隐私配置、诈骗、账户入侵、内容审核等主题。分析了帮助寻求的范围和规模、提供帮助的社区以及寻求帮助的类型。

Conclusion: 研究结果为开发更好的用户资源（如用户指南或LLM帮助代理）提供了信息，同时强调了在复杂威胁、平台、缓解措施、情境和情感组合中支持用户的内在挑战。

Abstract: The complexity of navigating digital privacy, safety, and security threats often falls directly on users. This leads to users seeking help from family and peers, platforms and advice guides, dedicated communities, and even large language models (LLMs). As a precursor to improving resources across this ecosystem, our community needs to understand what help seeking looks like in the wild. To that end, we blend qualitative coding with LLM fine-tuning to sift through over one billion Reddit posts from the last four years to identify where and for what users seek digital privacy, safety, or security help. We isolate three million relevant posts with 93% precision and recall and automatically annotate each with the topics discussed (e.g., security tools, privacy configurations, scams, account compromise, content moderation, and more). We use this dataset to understand the scope and scale of help seeking, the communities that provide help, and the types of help sought. Our work informs the development of better resources for users (e.g., user guides or LLM help-giving agents) while underscoring the inherent challenges of supporting users through complex combinations of threats, platforms, mitigations, context, and emotions.

</details>


### [19] [IMS: Intelligent Hardware Monitoring System for Secure SoCs](https://arxiv.org/abs/2601.11447)
*Wadid Foudhaili,Aykut Rencber,Anouar Nechi,Rainer Buchty,Mladen Berekovic,Andres Gomez,Saleh Mulhem*

Main category: cs.CR

TL;DR: 提出基于神经网络的智能硬件监控系统(IMS)，实时检测AXI协议违规攻击，在RISC-V SoC中实现高精度检测(98.7%)且硬件开销小


<details>
  <summary>Details</summary>
Motivation: 现代SoC中的AXI协议存在安全漏洞，可通过协议违规攻击导致部分或完全拒绝服务(DoS)，现有防护措施缺乏专门的实时协议语义分析和协议合规性检查

Method: 开发智能硬件监控系统(IMS)，利用神经网络实现高精度检测；通过头部字段操纵和系统性恶意操作进行DoS攻击，记录AXI事务构建训练数据集；部署量化优化的神经网络模型

Result: 达到98.7%的检测准确率，延迟开销≤3%，推理吞吐量>250万次/秒；硬件开销小(LUTs 9.04%，DSP切片0.23%，触发器0.70%)，对设计频率影响可忽略

Conclusion: IMS系统证明了在资源受限的边缘环境中实现轻量级安全监控的可行性，可作为内存映射IP核集成到RISC-V SoC中监控AXI总线

Abstract: In the modern Systems-on-Chip (SoC), the Advanced eXtensible Interface (AXI) protocol exhibits security vulnerabilities, enabling partial or complete denial-of-service (DoS) through protocol-violation attacks. The recent countermeasures lack a dedicated real-time protocol semantic analysis and evade protocol compliance checks. This paper tackles this AXI vulnerability issue and presents an intelligent hardware monitoring system (IMS) for real-time detection of AXI protocol violations. IMS is a hardware module leveraging neural networks to achieve high detection accuracy. For model training, we perform DoS attacks through header-field manipulation and systematic malicious operations, while recording AXI transactions to build a training dataset. We then deploy a quantization-optimized neural network, achieving 98.7% detection accuracy with <=3% latency overhead, and throughput of >2.5 million inferences/s. We subsequently integrate this IMS into a RISC-V SoC as a memory-mapped IP core to monitor its AXI bus. For demonstration and initial assessment for later ASIC integration, we implemented this IMS on an AMD Zynq UltraScale+ MPSoC ZCU104 board, showing an overall small hardware footprint (9.04% look-up-tables (LUTs), 0.23% DSP slices, and 0.70% flip-flops) and negligible impact on the overall design's achievable frequency. This demonstrates the feasibility of lightweight, security monitoring for resource-constrained edge environments.

</details>
