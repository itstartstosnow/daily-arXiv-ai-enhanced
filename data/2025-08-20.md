<div id=toc></div>

# Table of Contents

- [cs.CR](#cs.CR) [Total: 15]


<div id='cs.CR'></div>

# cs.CR [[Back]](#toc)

### [1] [Too Easily Fooled? Prompt Injection Breaks LLMs on Frustratingly Simple Multiple-Choice Questions](https://arxiv.org/abs/2508.13214)
*Xuyang Guo,Zekai Huang,Zhao Song,Jiahao Zhang*

Main category: cs.CR

TL;DR: LLM在PDF文件中隐藏提示注入攻击下表现脆弱，即使在简单算术问题上也容易被误导，暴露了LLM作为评判者的严重鲁棒性风险。


<details>
  <summary>Details</summary>
Motivation: 大型语言模型在复杂推理和零样本泛化方面展现出强大能力，但在提示注入攻击下的鲁棒性仍然是一个重要关切点。研究旨在测试LLM是否容易被简单攻击误导。

Method: 通过将基本算术问题（如3+2）以选择题或判断题形式嵌入PDF文件，并在文件中隐藏恶意提示指令，评估LLM在这种攻击设置下的表现。

Result: 研究结果显示LLM确实容易受到这种隐藏提示注入攻击的影响，即使在如此简单的场景下也会被误导。

Conclusion: 这项工作揭示了LLM作为评判者应用存在的严重鲁棒性风险，需要关注和改进模型对提示注入攻击的防御能力。

Abstract: Large Language Models (LLMs) have recently demonstrated strong emergent
abilities in complex reasoning and zero-shot generalization, showing
unprecedented potential for LLM-as-a-judge applications in education, peer
review, and data quality evaluation. However, their robustness under prompt
injection attacks, where malicious instructions are embedded into the content
to manipulate outputs, remains a significant concern. In this work, we explore
a frustratingly simple yet effective attack setting to test whether LLMs can be
easily misled. Specifically, we evaluate LLMs on basic arithmetic questions
(e.g., "What is 3 + 2?") presented as either multiple-choice or true-false
judgment problems within PDF files, where hidden prompts are injected into the
file. Our results reveal that LLMs are indeed vulnerable to such hidden prompt
injection attacks, even in these trivial scenarios, highlighting serious
robustness risks for LLM-as-a-judge applications.

</details>


### [2] [MCPSecBench: A Systematic Security Benchmark and Playground for Testing Model Context Protocols](https://arxiv.org/abs/2508.13220)
*Yixuan Yang,Daoyuan Wu,Yufan Chen*

Main category: cs.CR

TL;DR: 首个系统性的MCP安全分类法，提出MCPSecBench安全测试平台，识别了17种攻击类型，过超85%攻击成功突破主要MCP提供商


<details>
  <summary>Details</summary>
Motivation: MCP协议在扩大LLM代理能力的同时引入了新的安全风险和攻击面，需要系统性的安全分析和评估方法

Method: 提出包含17种攻击类型的4大攻击面分类法，建立MCPSecBench安全测试平台，整合了提示数据集、MCP服务器、MCP客户端和攻击脚本，对三大MCP提供商进行实验评测

Result: 识别的17种攻击中，超过85%的攻击成功突破至少一个平台，核心漏洞影响所有平台，提示基和工具中心攻击在不同主机和模型间存在显著差异

Conclusion: MCPSecBench为MCP安全评估提供了标准化方法，支持所有MCP层面的严格测试，可以集成自定义实现进行系统性的安全评估

Abstract: Large Language Models (LLMs) are increasingly integrated into real-world
applications via the Model Context Protocol (MCP), a universal, open standard
for connecting AI agents with data sources and external tools. While MCP
enhances the capabilities of LLM-based agents, it also introduces new security
risks and expands their attack surfaces. In this paper, we present the first
systematic taxonomy of MCP security, identifying 17 attack types across 4
primary attack surfaces. We introduce MCPSecBench, a comprehensive security
benchmark and playground that integrates prompt datasets, MCP servers, MCP
clients, and attack scripts to evaluate these attacks across three major MCP
providers. Our benchmark is modular and extensible, allowing researchers to
incorporate custom implementations of clients, servers, and transport protocols
for systematic security assessment. Experimental results show that over 85% of
the identified attacks successfully compromise at least one platform, with core
vulnerabilities universally affecting Claude, OpenAI, and Cursor, while
prompt-based and tool-centric attacks exhibit considerable variability across
different hosts and models. Overall, MCPSecBench standardizes the evaluation of
MCP security and enables rigorous testing across all MCP layers.

</details>


### [3] [Quantifying Loss Aversion in Cyber Adversaries via LLM Analysis](https://arxiv.org/abs/2508.13240)
*Soham Hans,Nikolos Gurney,Stacy Marsella,Sofia Hirschmann*

Main category: cs.CR

TL;DR: 利用大语言模型从黑客行为中量化提取损失嫂恶偏见，为网络安全防御提供实时行为分析新方法


<details>
  <summary>Details</summary>
Motivation: 传统网络安全防御策略难以动态解释攻击过程，需要新方法来推断和利用攻击者的认知偏见

Method: 采用大语言模型处理黑客在控制实验网络中生成的笔记，分析其操作行为并与预定义的持久机制相关联

Result: 成功从黑客行为中提取出损失嫂恶偏见的量化见解，显示了认知偏见在黑客决策中的表现方式

Conclusion: 大语言模型能够有效解析和识别细微的行为模式，为通过实时行为分析提升网络安全防御策略提供了变革性方法

Abstract: Understanding and quantifying human cognitive biases from empirical data has
long posed a formidable challenge, particularly in cybersecurity, where
defending against unknown adversaries is paramount. Traditional cyber defense
strategies have largely focused on fortification, while some approaches attempt
to anticipate attacker strategies by mapping them to cognitive vulnerabilities,
yet they fall short in dynamically interpreting attacks in progress. In
recognition of this gap, IARPA's ReSCIND program seeks to infer, defend
against, and even exploit attacker cognitive traits. In this paper, we present
a novel methodology that leverages large language models (LLMs) to extract
quantifiable insights into the cognitive bias of loss aversion from hacker
behavior. Our data are collected from an experiment in which hackers were
recruited to attack a controlled demonstration network. We process the hacker
generated notes using LLMs using it to segment the various actions and
correlate the actions to predefined persistence mechanisms used by hackers. By
correlating the implementation of these mechanisms with various operational
triggers, our analysis provides new insights into how loss aversion manifests
in hacker decision-making. The results demonstrate that LLMs can effectively
dissect and interpret nuanced behavioral patterns, thereby offering a
transformative approach to enhancing cyber defense strategies through
real-time, behavior-based analysis.

</details>


### [4] [Involuntary Jailbreak](https://arxiv.org/abs/2508.13246)
*Yangyang Guo,Yangyan Li,Mohan Kankanhalli*

Main category: cs.CR

TL;DR: 本文揭示了一种名为"非自愿越狱"的新型LLM漏洞，仅需单一通用提示即可绕过主流大语言模型的安全防护机制。


<details>
  <summary>Details</summary>
Motivation: 发现现有越狱攻击主要针对LLM防护的局部组件，而存在可能破坏整个防护结构的脆弱性，需要重新评估LLM护栏的鲁棒性。

Method: 使用单一通用提示，要求LLM生成通常会被拒绝的问题及其深度回答（而非拒绝回答），测试多种主流LLM模型。

Result: 这种简单提示策略能够持续越狱大多数领先LLM，包括Claude Opus 4.1、Grok 4、Gemini 2.5 Pro和GPT 4.1。

Conclusion: LLM防护结构存在惊人脆弱性，需要研究人员和从业者重新评估护栏鲁棒性，为未来更强的安全对齐做出贡献。

Abstract: In this study, we disclose a worrying new vulnerability in Large Language
Models (LLMs), which we term \textbf{involuntary jailbreak}. Unlike existing
jailbreak attacks, this weakness is distinct in that it does not involve a
specific attack objective, such as generating instructions for \textit{building
a bomb}. Prior attack methods predominantly target localized components of the
LLM guardrail. In contrast, involuntary jailbreaks may potentially compromise
the entire guardrail structure, which our method reveals to be surprisingly
fragile. We merely employ a single universal prompt to achieve this goal. In
particular, we instruct LLMs to generate several questions that would typically
be rejected, along with their corresponding in-depth responses (rather than a
refusal). Remarkably, this simple prompt strategy consistently jailbreaks the
majority of leading LLMs, including Claude Opus 4.1, Grok 4, Gemini 2.5 Pro,
and GPT 4.1. We hope this problem can motivate researchers and practitioners to
re-evaluate the robustness of LLM guardrails and contribute to stronger safety
alignment in future.

</details>


### [5] [Silentflow: Leveraging Trusted Execution for Resource-Limited MPC via Hardware-Algorithm Co-design](https://arxiv.org/abs/2508.13357)
*Zhuoran Li,Hanieh Totonchi Asl,Ebrahim Nouri,Yifei Cai,Danella Zhao*

Main category: cs.CR

TL;DR: SilentFlow是一个基于TEE的高效安全多方计算协议，通过消除COT生成中的通信和优化计算强度，在资源受限设备上实现了显著加速


<details>
  <summary>Details</summary>
Motivation: 传统COT生成在资源受限设备（如IoT传感器）上成为关键瓶颈，限制了隐私保护机器学习在边缘计算中的实时应用

Method: 采用TEE辅助协议消除COT生成的通信，通过结构化算法分解（核融合、BOX内存优化、向量化批处理）提升计算强度

Result: 相比最先进协议实现39.51倍加速，在ImageNet数据集上比Cryptflow2和Cheetah分别快4.62倍和3.95倍

Conclusion: SilentFlow成功解决了资源受限设备上的COT性能瓶颈，为边缘计算中的实时隐私保护机器学习推理提供了可行方案

Abstract: Secure Multi-Party Computation (MPC) offers a practical foundation for
privacy-preserving machine learning at the edge, with MPC commonly employed to
support nonlinear operations. These MPC protocols fundamentally rely on
Oblivious Transfer (OT), particularly Correlated OT (COT), to generate
correlated randomness essential for secure computation. Although COT generation
is efficient in conventional two-party settings with resource-rich
participants, it becomes a critical bottleneck in real-world inference on
resource-constrained devices (e.g., IoT sensors and wearables), due to both
communication latency and limited computational capacity. To enable real-time
secure inference, we introduce Silentflow, a highly efficient Trusted Execution
Environment (TEE)-assisted protocol that eliminates communication in COT
generation. We tackle the core performance bottleneck-low computational
intensity-through structured algorithmic decomposition: kernel fusion for
parallelism, Blocked On-chip eXpansion (BOX) to improve memory access patterns,
and vectorized batch operations to maximize memory bandwidth utilization.
Through design space exploration, we balance end-to-end latency and resource
demands, achieving up to 39.51x speedup over state-of-the-art protocols. By
offloading COT computations to a Zynq-7000 SoC, SilentFlow accelerates PPMLaaS
inference on the ImageNet dataset under resource constraints, achieving a 4.62x
and 3.95x speedup over Cryptflow2 and Cheetah, respectively.

</details>


### [6] [A Risk Manager for Intrusion Tolerant Systems: Enhancing HAL 9000 with New Scoring and Data Sources](https://arxiv.org/abs/2508.13364)
*Tadeu Freitas,Carlos Novo,Inês Dutra,João Soares,Manuel Correia,Benham Shariati,Rolando Martins*

Main category: cs.CR

TL;DR: 通过构建自定义爬虫工具，扩展HAL 9000入侵容忍系统的威胁情报来源，提升对未经验证漏洞的早期检测和评估能力


<details>
  <summary>Details</summary>
Motivation: 现有入侵容忍系统依赖NVD和ExploitDB等公开数据库，需要人工分析新漏洞，影响对快速发展威胁的响应速度

Method: 开发自定义爬虫工具，持续抓取多样化威胁来源，包括安全公告、研究论坛和实时利用代码验证，并将这些情报集成到HAL 9000风险管理框架中

Result: 整合爬虫获取的情报后，HAL 9000的风险管理能力显著提升，能够更好地应对新兴威胁

Conclusion: 通过扩展情报源来源并集成到入侵容忍系统中，可以有效提升系统对新兴威胁的反应能力和主动防御能力

Abstract: Intrusion Tolerant Systems (ITSs) have become increasingly critical due to
the rise of multi-domain adversaries exploiting diverse attack surfaces. ITS
architectures aim to tolerate intrusions, ensuring system compromise is
prevented or mitigated even with adversary presence. Existing ITS solutions
often employ Risk Managers leveraging public security intelligence to adjust
system defenses dynamically against emerging threats. However, these approaches
rely heavily on databases like NVD and ExploitDB, which require manual analysis
for newly discovered vulnerabilities. This dependency limits the system's
responsiveness to rapidly evolving threats. HAL 9000, an ITS Risk Manager
introduced in our prior work, addressed these challenges through machine
learning. By analyzing descriptions of known vulnerabilities, HAL 9000 predicts
and assesses new vulnerabilities automatically. To calculate the risk of a
system, it also incorporates the Exploitability Probability Scoring system to
estimate the likelihood of exploitation within 30 days, enhancing proactive
defense capabilities.
  Despite its success, HAL 9000's reliance on NVD and ExploitDB knowledge is a
limitation, considering the availability of other sources of information. This
extended work introduces a custom-built scraper that continuously mines diverse
threat sources, including security advisories, research forums, and real-time
exploit proofs-of-concept. This significantly expands HAL 9000's intelligence
base, enabling earlier detection and assessment of unverified vulnerabilities.
Our evaluation demonstrates that integrating scraper-derived intelligence with
HAL 9000's risk management framework substantially improves its ability to
address emerging threats. This paper details the scraper's integration into the
architecture, its role in providing additional information on new threats, and
the effects on HAL 9000's management.

</details>


### [7] [When Secure Aggregation Falls Short: Achieving Long-Term Privacy in Asynchronous Federated Learning for LEO Satellite Networks](https://arxiv.org/abs/2508.13425)
*Mohamed Elmahallawy,Tie Luo*

Main category: cs.CR

TL;DR: LTP-FLEO是一个针对低地球轨道卫星网络的异步联邦学习框架，解决了传统安全聚合方法在动态资源受限环境中的局限性，通过隐私感知卫星分区、模型年龄平衡和公平全局聚合来保护长期隐私。


<details>
  <summary>Details</summary>
Motivation: 传统联邦学习安全聚合方法在LEO卫星网络中面临两个主要问题：1) 假设客户端持续可用，但卫星可见性是间歇性和不规则的；2) 只考虑单轮通信隐私，忽视了多轮训练中的隐私泄露风险。

Method: 提出LTP-FLEO框架，包含三个核心组件：(i) 基于可预测可见性的隐私感知卫星分区，强制联合参与；(ii) 模型年龄平衡机制，减轻陈旧模型更新的负面影响；(iii) 公平全局聚合，对不同可见时长的卫星进行公平对待。

Result: 理论分析和实证验证表明，LTP-FLEO在多轮训练中有效保护模型和数据隐私，促进与卫星贡献相符的公平性，加速全局收敛，并达到有竞争力的模型精度。

Conclusion: LTP-FLEO成功解决了LEO卫星网络中联邦学习的长期隐私保护问题，为动态资源受限环境下的安全联邦学习提供了有效解决方案。

Abstract: Secure aggregation is a common technique in federated learning (FL) for
protecting data privacy from both curious internal entities (clients or server)
and external adversaries (eavesdroppers). However, in dynamic and
resource-constrained environments such as low Earth orbit (LEO) satellite
networks, traditional secure aggregation methods fall short in two aspects: (1)
they assume continuous client availability while LEO satellite visibility is
intermittent and irregular; (2) they consider privacy in each communication
round but have overlooked the possible privacy leakage through multiple rounds.
To address these limitations, we propose LTP-FLEO, an asynchronous FL framework
that preserves long-term privacy (LTP) for LEO satellite networks. LTP-FLEO
introduces (i) privacy-aware satellite partitioning, which groups satellites
based on their predictable visibility to the server and enforces joint
participation; (ii) model age balancing, which mitigates the adverse impact of
stale model updates; and (iii) fair global aggregation, which treats satellites
of different visibility durations in an equitable manner. Theoretical analysis
and empirical validation demonstrate that LTP-FLEO effectively safeguards both
model and data privacy across multi-round training, promotes fairness in line
with satellite contributions, accelerates global convergence, and achieves
competitive model accuracy.

</details>


### [8] [Beneath the Mask: Can Contribution Data Unveil Malicious Personas in Open-Source Projects?](https://arxiv.org/abs/2508.13453)
*Ruby Nealon*

Main category: cs.CR

TL;DR: 利用GitHub开源情报数据和图数据库分析，识别开源项目中类似JiaT75的异常贡献者行为模式


<details>
  <summary>Details</summary>
Motivation: XZ Utils后门事件暴露了开源项目缺乏监控异常贡献者行为的工具，需要开发有效方法来检测潜在恶意行为

Method: 从GitHub贡献数据收集OSINT信息，使用图数据库和图论分析方法来识别异常行为模式

Result: 成功识别出JiaT75在其他开源项目中表现出的异常行为特征

Conclusion: 基于图论的OSINT分析方法能够有效监控和识别开源项目中的可疑贡献者行为，提高开源生态安全性

Abstract: In February 2024, after building trust over two years with project
maintainers by making a significant volume of legitimate contributions, GitHub
user "JiaT75" self-merged a version of the XZ Utils project containing a highly
sophisticated, well-disguised backdoor targeting sshd processes running on
systems with the backdoored package installed. A month later, this package
began to be distributed with popular Linux distributions until a Microsoft
employee discovered the backdoor while investigating how a recent system
upgrade impacted the performance of SSH authentication. Despite its potential
global impact, no tooling exists for monitoring and identifying anomalous
behavior by personas contributing to other open-source projects. This paper
demonstrates how Open Source Intelligence (OSINT) data gathered from GitHub
contributions, analyzed using graph databases and graph theory, can efficiently
identify anomalous behaviors exhibited by the "JiaT75" persona across other
open-source projects.

</details>


### [9] [Optimizing Scalar Selection in Elliptic Curve Cryptography Using Differential Evolution for Enhanced Security](https://arxiv.org/abs/2508.13520)
*Takreem Haider*

Main category: cs.CR

TL;DR: 使用差分进化算法优化生成高熵的椭圆曲线秘码标量，提高对熵攻击的抵御能力


<details>
  <summary>Details</summary>
Motivation: 资源受限环境中传统随机数生成方法容易产生低熵或偏彩标量，增加侦听攻击风险

Method: 将标量选择重构为熵优化问题，使用差分进化算法搜索二进制表示具有最大熵值的标量

Result: 实验结果显示DE优化标量的熵值显著高于传统方法生成的标量

Conclusion: 该方法为区块链、安全通信、IoT等资源受限应用提供了可调的确定性高熵标量生成方案

Abstract: Elliptic Curve Cryptography (ECC) is a fundamental component of modern
public-key cryptosystems that enable efficient and secure digital signatures,
key exchanges, and encryption. Its core operation, scalar multiplication,
denoted as $k \cdot P$, where $P$ is a base point and $k$ is a private scalar,
relies heavily on the secrecy and unpredictability of $k$. Conventionally, $k$
is selected using user input or pseudorandom number generators. However, in
resource-constrained environments with weak entropy sources, these approaches
may yield low-entropy or biased scalars, increasing susceptibility to
side-channel and key recovery attacks. To mitigate these vulnerabilities, we
introduce an optimization-driven scalar generation method that explicitly
maximizes bit-level entropy. Our approach uses differential evolution (DE), a
population-based metaheuristic algorithm, to search for scalars whose binary
representations exhibit maximal entropy, defined by an even and statistically
uniform distribution of ones and zeros. This reformulation of scalar selection
as an entropy-optimization problem enhances resistance to entropy-based
cryptanalytic techniques and improves overall unpredictability. Experimental
results demonstrate that DE-optimized scalars achieve entropy significantly
higher than conventionally generated scalars. The proposed method can be
integrated into existing ECC-based protocols, offering a deterministic, tunable
alternative to traditional randomness, ideal for applications in blockchain,
secure messaging, IoT, and other resource-constrained environments.

</details>


### [10] [CAI Fluency: A Framework for Cybersecurity AI Fluency](https://arxiv.org/abs/2508.13588)
*Víctor Mayoral-Vilches,Jasmin Wachter,Cristóbal R. J. Veas Chavez,Cathrin Schachner,Luis Javier Navarrete-Lozano,María Sanz-Gómez*

Main category: cs.CR

TL;DR: CAI Fluency是一个基于网络安全AI框架的教育平台，旨在普及网络安全AI工具的知识和应用，促进AI在网络安全领域的广泛采用和有效使用。


<details>
  <summary>Details</summary>
Motivation: 为了在网络安全社区中普及AI工具的知识和应用，加速AI驱动的网络安全解决方案的广泛采用，实现类似"vibe-coding"的"vibe-hacking"网络安全范式。

Method: 基于AI Fluency框架，调整其三种人机交互模式和四个核心能力，专门针对网络安全应用进行适配，包括技术技能、批判性思维和道德意识培养。

Result: 开发了一个综合性的教育平台，提供理论指导、教育资源和实践指南，帮助用户理解CAI框架原理并在实际安全场景中应用。

Conclusion: CAI Fluency为网络安全从业者提供了系统化的AI教育框架，不仅培养技术能力，还强调负责任的AI使用，推动网络安全AI工具的民主化应用。

Abstract: This work introduces CAI Fluency, an an educational platform of the
Cybersecurity AI (CAI) framework dedicated to democratizing the knowledge and
application of cybersecurity AI tools in the global security community. The
main objective of the CAI framework is to accelerate the widespread adoption
and effective use of artificial intelligence-based cybersecurity solutions,
pathing the way to vibe-hacking, the cybersecurity analogon to vibe-coding.
  CAI Fluency builds upon the Framework for AI Fluency, adapting its three
modalities of human-AI interaction and four core competencies specifically for
cybersecurity applications. This theoretical foundation ensures that
practitioners develop not just technical skills, but also the critical thinking
and ethical awareness necessary for responsible AI use in security contexts.
  This technical report serves as a white-paper, as well as detailed
educational and practical guide that helps users understand the principles
behind the CAI framework, and educates them how to apply this knowledge in
their projects and real-world security contexts.

</details>


### [11] [Conflicting Scores, Confusing Signals: An Empirical Study of Vulnerability Scoring Systems](https://arxiv.org/abs/2508.13644)
*Viktoria Koscinski,Mark Nelson,Ahmet Okutan,Robert Falso,Mehdi Mirakhorli*

Main category: cs.CR

TL;DR: 首次大规模实证比较四种漏洞评分系统（CVSS、SSVC、EPSS、Exploitability Index），使用600个真实漏洞数据，发现不同系统对同一漏洞的评分存在显著差异，影响基于风险的决策。


<details>
  <summary>Details</summary>
Motivation: 现有漏洞评分系统的目标、方法和输出不一致，导致优先级决策不一致，需要实证比较来评估其实际效果。

Method: 使用微软Patch Tuesday披露的4个月内600个真实漏洞数据集，分析四种评分系统的关系、对漏洞管理任务的支持、分类层级和捕获实际利用风险的能力。

Result: 发现评分系统对同一漏洞的排名存在显著差异，影响组织基于数据驱动的风险决策。

Conclusion: 需要更透明和一致的漏洞可利用性、风险和严重性评估方法。

Abstract: Accurately assessing software vulnerabilities is essential for effective
prioritization and remediation. While various scoring systems exist to support
this task, their differing goals, methodologies and outputs often lead to
inconsistent prioritization decisions. This work provides the first
large-scale, outcome-linked empirical comparison of four publicly available
vulnerability scoring systems: the Common Vulnerability Scoring System (CVSS),
the Stakeholder-Specific Vulnerability Categorization (SSVC), the Exploit
Prediction Scoring System (EPSS), and the Exploitability Index. We use a
dataset of 600 real-world vulnerabilities derived from four months of
Microsoft's Patch Tuesday disclosures to investigate the relationships between
these scores, evaluate how they support vulnerability management task, how
these scores categorize vulnerabilities across triage tiers, and assess their
ability to capture the real-world exploitation risk. Our findings reveal
significant disparities in how scoring systems rank the same vulnerabilities,
with implications for organizations relying on these metrics to make
data-driven, risk-based decisions. We provide insights into the alignment and
divergence of these systems, highlighting the need for more transparent and
consistent exploitability, risk, and severity assessments.

</details>


### [12] [Know Me by My Pulse: Toward Practical Continuous Authentication on Wearable Devices via Wrist-Worn PPG](https://arxiv.org/abs/2508.13690)
*Wei Shao,Zequan Liang,Ruoyu Zhang,Ruijie Fang,Ning Miao,Ehsan Kourkchi,Setareh Rafatirad,Houman Homayoun,Chongzhou Fang*

Main category: cs.CR

TL;DR: 基于25Hz低频率多通道PPG信号的智能手表连续身份验证系统，通过Bi-LSTM注意力机制实现88.11%准确率，低耗电且性能稳定


<details>
  <summary>Details</summary>
Motivation: 解决高频PPG身份验证方案的高耗电和计算复杂度问题，提供一种适合手表等功耗约束设备的连续、非侵入式生物识别方案

Method: 使用25Hz低频率多通道PPG信号，采用Bi-LSTM注意力机制从4秒短时间窗口提取身份特征，在公共PTTPPG数据集和自建We-Be数据集(26名参与者)上进行评估

Result: 平均测试准确率88.11%，宏观F1分0.88，FAR 0.48%，FRR 11.77%，EER 2.76%。与512Hz相比耗电降低53%，与128Hz相比降低19%，但性能无损失。25Hz为最优低频率阈值

Conclusion: 低频率(25Hz)PPG系统在保持高准确性的同时显著降低耗电，适合实际部署；活动多样性训练能提升游移性能，为可穿戴设备提供了实用的连续身份验证方案

Abstract: Biometric authentication using physiological signals offers a promising path
toward secure and user-friendly access control in wearable devices. While
electrocardiogram (ECG) signals have shown high discriminability, their
intrusive sensing requirements and discontinuous acquisition limit
practicality. Photoplethysmography (PPG), on the other hand, enables
continuous, non-intrusive authentication with seamless integration into
wrist-worn wearable devices. However, most prior work relies on high-frequency
PPG (e.g., 75 - 500 Hz) and complex deep models, which incur significant energy
and computational overhead, impeding deployment in power-constrained real-world
systems. In this paper, we present the first real-world implementation and
evaluation of a continuous authentication system on a smartwatch, We-Be Band,
using low-frequency (25 Hz) multi-channel PPG signals. Our method employs a
Bi-LSTM with attention mechanism to extract identity-specific features from
short (4 s) windows of 4-channel PPG. Through extensive evaluations on both
public datasets (PTTPPG) and our We-Be Dataset (26 subjects), we demonstrate
strong classification performance with an average test accuracy of 88.11%,
macro F1-score of 0.88, False Acceptance Rate (FAR) of 0.48%, False Rejection
Rate (FRR) of 11.77%, and Equal Error Rate (EER) of 2.76%. Our 25 Hz system
reduces sensor power consumption by 53% compared to 512 Hz and 19% compared to
128 Hz setups without compromising performance. We find that sampling at 25 Hz
preserves authentication accuracy, whereas performance drops sharply at 20 Hz
while offering only trivial additional power savings, underscoring 25 Hz as the
practical lower bound. Additionally, we find that models trained exclusively on
resting data fail under motion, while activity-diverse training improves
robustness across physiological states.

</details>


### [13] [On the Security and Privacy of Federated Learning: A Survey with Attacks, Defenses, Frameworks, Applications, and Future Directions](https://arxiv.org/abs/2508.13730)
*Daniel M. Jimenez-Gutierrez,Yelizaveta Falkouskaya,Jose L. Hernandez-Ramos,Aris Anagnostopoulos,Ioannis Chatzigiannakis,Andrea Vitaletti*

Main category: cs.CR

TL;DR: 这是一份关于联邦学习(FL)安全性和隐私性的综述性调查，涵盖200多篇论文，分析了攻击方法和防御机制，并讨论了现有方法的优缺点和未来研究方向。


<details>
  <summary>Details</summary>
Motivation: 虽然联邦学习从设计上增强了数据隐私，但仍然存在各种安全和隐私风险，需要系统性地调查和分析现有的防御技术。

Method: 调查论文综述方法，对200多篇相关论文进行系统分析，将防御技术分为安全增强和隐私保护两大类。安全增强方法包括对投毒攻击、Byzantine攻击、Sybil攻击等的防御；隐私保护方法包括加密技术、差分隐私、安全聚合等。

Result: 综述了现有防御方法的优缺点，分析了隐私、安全和模型性能之间的权衡关系，讨论了非IID数据分布对防御效果的影响。

Conclusion: 本调查指出了联邦学习安全性和隐私性领域的重要研究挑战，包括需要可扩展、适配性强、能源效率高的解决方案，以满足动态异构环境下的需求，为研空人员和实践者提供了开发稳健隐私保护FL系统的指南。

Abstract: Federated Learning (FL) is an emerging distributed machine learning paradigm
enabling multiple clients to train a global model collaboratively without
sharing their raw data. While FL enhances data privacy by design, it remains
vulnerable to various security and privacy threats. This survey provides a
comprehensive overview of more than 200 papers regarding the state-of-the-art
attacks and defense mechanisms developed to address these challenges,
categorizing them into security-enhancing and privacy-preserving techniques.
Security-enhancing methods aim to improve FL robustness against malicious
behaviors such as byzantine attacks, poisoning, and Sybil attacks. At the same
time, privacy-preserving techniques focus on protecting sensitive data through
cryptographic approaches, differential privacy, and secure aggregation. We
critically analyze the strengths and limitations of existing methods, highlight
the trade-offs between privacy, security, and model performance, and discuss
the implications of non-IID data distributions on the effectiveness of these
defenses. Furthermore, we identify open research challenges and future
directions, including the need for scalable, adaptive, and energy-efficient
solutions operating in dynamic and heterogeneous FL environments. Our survey
aims to guide researchers and practitioners in developing robust and
privacy-preserving FL systems, fostering advancements safeguarding
collaborative learning frameworks' integrity and confidentiality.

</details>


### [14] [NodeShield: Runtime Enforcement of Security-Enhanced SBOMs for Node.js](https://arxiv.org/abs/2508.13750)
*Eric Cornelissen,Musard Balliu*

Main category: cs.CR

TL;DR: NodeShield是一个针对Node.js应用的运行时保护机制，通过SBOM和CBOM来强制执行依赖层次结构和系统资源访问控制，有效防止98%的已知供应链攻击，且开销极小。


<details>
  <summary>Details</summary>
Motivation: Node.js生态系统因其规模和普及性成为恶意攻击的常见目标，现有防护机制需要更兼容、自动化、低开销且策略简洁的解决方案。

Method: 设计实现NodeShield，利用SBOM作为依赖层次结构的真实来源，提出CBOM扩展记录组件能力，通过代码轮廓化在运行时强制执行策略，无需修改原始代码或Node.js运行时。

Result: 评估显示NodeShield能防止67个已知供应链攻击中98%的攻击，服务器端每请求开销小于1ms，保持与原生Node.js的广泛兼容性。

Conclusion: NodeShield提供了一种有效的运行时保护机制，通过SBOM/CBOM和代码轮廓化技术实现了兼容性、自动化、低开销和策略简洁性的目标，能有效防御Node.js供应链攻击。

Abstract: The software supply chain is an increasingly common attack vector for
malicious actors. The Node.js ecosystem has been subject to a wide array of
attacks, likely due to its size and prevalence. To counter such attacks, the
research community and practitioners have proposed a range of static and
dynamic mechanisms, including process- and language-level sandboxing,
permission systems, and taint tracking. Drawing on valuable insight from these
works, this paper studies a runtime protection mechanism for (the supply chain
of) Node.js applications with the ambitious goals of compatibility, automation,
minimal overhead, and policy conciseness.
  Specifically, we design, implement and evaluate NodeShield, a protection
mechanism for Node.js that enforces an application's dependency hierarchy and
controls access to system resources at runtime. We leverage the up-and-coming
SBOM standard as the source of truth for the dependency hierarchy of the
application, thus preventing components from stealthily abusing undeclared
components. We propose to enhance the SBOM with a notion of capabilities that
represents a set of related system resources a component may access. Our
proposed SBOM extension, the Capability Bill of Materials or CBOM, records the
required capabilities of each component, providing valuable insight into the
potential privileged behavior. NodeShield enforces the SBOM and CBOM at runtime
via code outlining (as opposed to inlining) with no modifications to the
original code or Node.js runtime, thus preventing unexpected, potentially
malicious behavior. Our evaluation shows that NodeShield can prevent over 98%
out of 67 known supply chain attacks while incurring minimal overhead on
servers at less than 1ms per request. We achieve this while maintaining broad
compatibility with vanilla Node.js and a concise policy language that consists
of at most 7 entries per dependency.

</details>


### [15] [Red Teaming Methodology for Design Obfuscation](https://arxiv.org/abs/2508.13965)
*Yuntao Liu,Abir Akib,Zelin Lu,Qian Xu,Ankur Srivastava,Gang Qu,David Kehlet,Nij Dorairaj*

Main category: cs.CR

TL;DR: 本文提出了一种系统化的红队评估方法来测试设计混淆方案的安全性，特别是在攻击者无法获得工作芯片的场景下，通过案例研究发现RIPPER工具泄露的设计结构信息比通常认为的更多


<details>
  <summary>Details</summary>
Motivation: 保护VLSI供应链中敏感设计细节免受不可信方（如离岸代工厂和终端用户）的侵害，需要评估设计混淆方案的实际安全性

Method: 提出了安全指标和评估方法，特别针对攻击者无法获得工作芯片的场景，并以佛罗里达大学开发的RIPPER工具作为案例进行研究

Result: 研究发现RIPPER工具泄露的原始设计结构信息比通常认为的要多，表明现有设计混淆方案存在安全漏洞

Conclusion: 需要更严格的安全评估方法来验证设计混淆方案的有效性，当前方案可能无法充分保护敏感设计信息

Abstract: The main goal of design obfuscation schemes is to protect sensitive design
details from untrusted parties in the VLSI supply chain, including but not
limited to off-shore foundries and untrusted end users. In this work, we
provide a systematic red teaming approach to evaluate the security of design
obfuscation approaches. Specifically, we propose security metrics and
evaluation methodology for the scenarios where the adversary does not have
access to a working chip. A case study on the RIPPER tool developed by the
University of Florida indicates that more information is leaked about the
structure of the original design than commonly considered.

</details>
