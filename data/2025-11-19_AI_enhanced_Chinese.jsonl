{"id": "2511.13725", "categories": ["cs.CR", "cs.AI"], "pdf": "https://arxiv.org/pdf/2511.13725", "abs": "https://arxiv.org/abs/2511.13725", "authors": ["Sechan Lee", "Sangdon Park"], "title": "AI Kill Switch for malicious web-based LLM agent", "comment": null, "summary": "Recently, web-based Large Language Model (LLM) agents autonomously perform increasingly complex tasks, thereby bringing significant convenience. However, they also amplify the risks of malicious misuse cases such as unauthorized collection of personally identifiable information (PII), generation of socially divisive content, and even automated web hacking. To address these threats, we propose an AI Kill Switch technique that can immediately halt the operation of malicious web-based LLM agents. To achieve this, we introduce AutoGuard - the key idea is generating defensive prompts that trigger the safety mechanisms of malicious LLM agents. In particular, generated defense prompts are transparently embedded into the website's DOM so that they remain invisible to human users but can be detected by the crawling process of malicious agents, triggering its internal safety mechanisms to abort malicious actions once read. To evaluate our approach, we constructed a dedicated benchmark consisting of three representative malicious scenarios (PII collection, social rift content generation, and web hacking attempts). Experimental results show that the AutoGuard method achieves over 80% Defense Success Rate (DSR) on malicious agents, including GPT-4o, Claude-3, and Llama3.3-70B-Instruct. It also maintains strong performance, achieving around 90% DSR on GPT-5, GPT-4.1, and Gemini-2.5-Flash when used as the malicious agent, demonstrating robust generalization across models and scenarios. Through this research, we have demonstrated the controllability of web-based LLM agents across various scenarios and models, thereby contributing to the broader effort of AI control and safety.", "AI": {"tldr": "\u63d0\u51faAutoGuard\u6280\u672f\uff0c\u901a\u8fc7\u751f\u6210\u9632\u5fa1\u6027\u63d0\u793a\u8bcd\u5d4c\u5165\u7f51\u7ad9DOM\uff0c\u89e6\u53d1\u6076\u610fLLM\u4ee3\u7406\u7684\u5b89\u5168\u673a\u5236\u6765\u4e2d\u6b62\u5176\u6076\u610f\u884c\u4e3a\u3002", "motivation": "\u5e94\u5bf9\u57fa\u4e8e\u7f51\u9875\u7684LLM\u4ee3\u7406\u5728\u81ea\u4e3b\u6267\u884c\u590d\u6742\u4efb\u52a1\u65f6\u5e26\u6765\u7684\u6076\u610f\u6ee5\u7528\u98ce\u9669\uff0c\u5982\u672a\u7ecf\u6388\u6743\u6536\u96c6\u4e2a\u4eba\u4fe1\u606f\u3001\u751f\u6210\u793e\u4f1a\u5206\u88c2\u5185\u5bb9\u548c\u81ea\u52a8\u5316\u7f51\u7edc\u653b\u51fb\u3002", "method": "\u5f00\u53d1AutoGuard\u7cfb\u7edf\uff0c\u751f\u6210\u9632\u5fa1\u63d0\u793a\u8bcd\u5e76\u900f\u660e\u5d4c\u5165\u7f51\u7ad9DOM\uff0c\u8fd9\u4e9b\u63d0\u793a\u5bf9\u7528\u6237\u4e0d\u53ef\u89c1\u4f46\u80fd\u88ab\u6076\u610f\u4ee3\u7406\u722c\u53d6\u8fc7\u7a0b\u68c0\u6d4b\uff0c\u89e6\u53d1\u5176\u5185\u90e8\u5b89\u5168\u673a\u5236\u4e2d\u6b62\u6076\u610f\u64cd\u4f5c\u3002", "result": "\u5728\u5305\u542b\u4e09\u79cd\u6076\u610f\u573a\u666f\u7684\u57fa\u51c6\u6d4b\u8bd5\u4e2d\uff0cAutoGuard\u5bf9GPT-4o\u3001Claude-3\u548cLlama3.3-70B-Instruct\u7b49\u6076\u610f\u4ee3\u7406\u8fbe\u523080%\u4ee5\u4e0a\u7684\u9632\u5fa1\u6210\u529f\u7387\uff0c\u5bf9GPT-5\u3001GPT-4.1\u548cGemini-2.5-Flash\u8fbe\u5230\u7ea690%\u7684\u9632\u5fa1\u6210\u529f\u7387\u3002", "conclusion": "\u8be5\u7814\u7a76\u8bc1\u660e\u4e86\u57fa\u4e8e\u7f51\u9875\u7684LLM\u4ee3\u7406\u5728\u5404\u79cd\u573a\u666f\u548c\u6a21\u578b\u4e2d\u7684\u53ef\u63a7\u6027\uff0c\u4e3aAI\u63a7\u5236\u548c\u5b89\u5168\u6027\u505a\u51fa\u4e86\u8d21\u732e\u3002"}}
{"id": "2511.13771", "categories": ["cs.CR", "cs.AI"], "pdf": "https://arxiv.org/pdf/2511.13771", "abs": "https://arxiv.org/abs/2511.13771", "authors": ["Shaowei Guan", "Yu Zhai", "Zhengyu Zhang", "Yanze Wang", "Hin Chi Kwok"], "title": "ExplainableGuard: Interpretable Adversarial Defense for Large Language Models Using Chain-of-Thought Reasoning", "comment": "9 pages, 2 figures", "summary": "Large Language Models (LLMs) are increasingly vulnerable to adversarial attacks that can subtly manipulate their outputs. While various defense mechanisms have been proposed, many operate as black boxes, lacking transparency in their decision-making. This paper introduces ExplainableGuard, an interpretable adversarial defense framework leveraging the chain-of-thought (CoT) reasoning capabilities of DeepSeek-Reasoner. Our approach not only detects and neutralizes adversarial perturbations in text but also provides step-by-step explanations for each defense action. We demonstrate how tailored CoT prompts guide the LLM to perform a multi-faceted analysis (character, word, structural, and semantic) and generate a purified output along with a human-readable justification. Preliminary results on the GLUE Benchmark and IMDB Movie Reviews dataset show promising defense efficacy. Additionally, a human evaluation study reveals that ExplainableGuard's explanations outperform ablated variants in clarity, specificity, and actionability, with a 72.5% deployability-trust rating, underscoring its potential for more trustworthy LLM deployments.", "AI": {"tldr": "\u63d0\u51fa\u4e86ExplainableGuard\u6846\u67b6\uff0c\u5229\u7528DeepSeek-Reasoner\u7684\u601d\u7ef4\u94fe\u63a8\u7406\u80fd\u529b\uff0c\u63d0\u4f9b\u53ef\u89e3\u91ca\u7684\u5bf9\u6297\u9632\u5fa1\uff0c\u4e0d\u4ec5\u80fd\u68c0\u6d4b\u548c\u6d88\u9664\u6587\u672c\u5bf9\u6297\u6270\u52a8\uff0c\u8fd8\u80fd\u4e3a\u6bcf\u4e2a\u9632\u5fa1\u52a8\u4f5c\u63d0\u4f9b\u9010\u6b65\u89e3\u91ca\u3002", "motivation": "\u5f53\u524dLLM\u9762\u4e34\u5bf9\u6297\u653b\u51fb\u5a01\u80c1\uff0c\u73b0\u6709\u9632\u5fa1\u673a\u5236\u591a\u4e3a\u9ed1\u76d2\uff0c\u7f3a\u4e4f\u51b3\u7b56\u900f\u660e\u5ea6\u3002\u9700\u8981\u5f00\u53d1\u65e2\u80fd\u6709\u6548\u9632\u5fa1\u53c8\u80fd\u63d0\u4f9b\u89e3\u91ca\u7684\u6846\u67b6\u3002", "method": "\u5229\u7528\u5b9a\u5236\u5316\u7684\u601d\u7ef4\u94fe\u63d0\u793a\u5f15\u5bfcLLM\u8fdb\u884c\u591a\u5c42\u9762\u5206\u6790\uff08\u5b57\u7b26\u3001\u8bcd\u6c47\u3001\u7ed3\u6784\u548c\u8bed\u4e49\uff09\uff0c\u751f\u6210\u51c0\u5316\u8f93\u51fa\u53ca\u4eba\u7c7b\u53ef\u8bfb\u7684\u9632\u5fa1\u7406\u7531\u3002", "result": "\u5728GLUE\u57fa\u51c6\u548cIMDB\u7535\u5f71\u8bc4\u8bba\u6570\u636e\u96c6\u4e0a\u663e\u793a\u51fa\u6709\u524d\u666f\u7684\u9632\u5fa1\u6548\u679c\u3002\u4eba\u5de5\u8bc4\u4f30\u663e\u793a\u5176\u89e3\u91ca\u5728\u6e05\u6670\u5ea6\u3001\u7279\u5f02\u6027\u548c\u53ef\u64cd\u4f5c\u6027\u65b9\u9762\u4f18\u4e8e\u6d88\u878d\u53d8\u4f53\uff0c\u90e8\u7f72\u53ef\u4fe1\u5ea6\u8bc4\u5206\u4e3a72.5%\u3002", "conclusion": "ExplainableGuard\u6846\u67b6\u5177\u6709\u6784\u5efa\u66f4\u53ef\u4fe1LLM\u90e8\u7f72\u7684\u6f5c\u529b\uff0c\u901a\u8fc7\u63d0\u4f9b\u900f\u660e\u5316\u7684\u9632\u5fa1\u51b3\u7b56\u8fc7\u7a0b\u589e\u5f3a\u7528\u6237\u4fe1\u4efb\u3002"}}
{"id": "2511.13777", "categories": ["cs.CR", "math.OC", "math.PR"], "pdf": "https://arxiv.org/pdf/2511.13777", "abs": "https://arxiv.org/abs/2511.13777", "authors": ["Pierre-Olivier Goffard", "Hansjoerg Albrecher", "Jean-Pierre Fouque"], "title": "Hashpower allocation in Pay-per-Share blockchain mining pools", "comment": null, "summary": "Mining blocks in a blockchain using the \\textit{Proof-of-Work} consensus protocol involves significant risk, as network participants face continuous operational costs while earning infrequent capital gains upon successfully mining a block. A common risk mitigation strategy is to join a mining pool, which combines the computing resources of multiple miners to provide a more stable income. This article examines a Pay-per-Share (PPS) reward system, where the pool manager can adjust both the share difficulty and the management fee. Using a simplified wealth model for miners, we explore how miners should allocate their computing resources among different mining pools, considering the trade-off between risk transfer to the manager and management fees.", "AI": {"tldr": "\u672c\u6587\u5206\u6790PPS\u6316\u77ff\u6c60\u4e2d\u77ff\u5de5\u5982\u4f55\u5206\u914d\u7b97\u529b\uff0c\u8003\u8651\u98ce\u9669\u8f6c\u79fb\u4e0e\u7ba1\u7406\u8d39\u7684\u6743\u8861", "motivation": "PoW\u6316\u77ff\u5b58\u5728\u663e\u8457\u98ce\u9669\uff0c\u77ff\u5de5\u9762\u4e34\u6301\u7eed\u8fd0\u8425\u6210\u672c\u4f46\u6536\u76ca\u4e0d\u7a33\u5b9a\u3002\u52a0\u5165\u77ff\u6c60\u662f\u5e38\u89c1\u7684\u98ce\u9669\u7f13\u89e3\u7b56\u7565\uff0c\u4f46\u9700\u8981\u7814\u7a76\u77ff\u5de5\u5982\u4f55\u5728\u77ff\u6c60\u95f4\u4f18\u5316\u7b97\u529b\u5206\u914d", "method": "\u4f7f\u7528\u7b80\u5316\u7684\u77ff\u5de5\u8d22\u5bcc\u6a21\u578b\uff0c\u5206\u6790PPS\u5956\u52b1\u7cfb\u7edf\u4e2d\u77ff\u6c60\u7ba1\u7406\u8005\u8c03\u6574\u4efd\u989d\u96be\u5ea6\u548c\u7ba1\u7406\u8d39\u5bf9\u77ff\u5de5\u51b3\u7b56\u7684\u5f71\u54cd", "result": "\u77ff\u5de5\u9700\u8981\u5728\u5c06\u98ce\u9669\u8f6c\u79fb\u7ed9\u77ff\u6c60\u7ba1\u7406\u8005\u4e0e\u652f\u4ed8\u7ba1\u7406\u8d39\u4e4b\u95f4\u8fdb\u884c\u6743\u8861\uff0c\u4ee5\u4f18\u5316\u7b97\u529b\u5206\u914d\u7b56\u7565", "conclusion": "PPS\u77ff\u6c60\u7cfb\u7edf\u4e3a\u77ff\u5de5\u63d0\u4f9b\u4e86\u98ce\u9669\u8f6c\u79fb\u673a\u5236\uff0c\u4f46\u77ff\u5de5\u9700\u8981\u6839\u636e\u7ba1\u7406\u8d39\u6c34\u5e73\u5408\u7406\u5206\u914d\u7b97\u529b\uff0c\u5728\u98ce\u9669\u5206\u6563\u548c\u6210\u672c\u63a7\u5236\u4e4b\u95f4\u627e\u5230\u5e73\u8861"}}
{"id": "2511.13781", "categories": ["cs.CR", "cs.CY"], "pdf": "https://arxiv.org/pdf/2511.13781", "abs": "https://arxiv.org/abs/2511.13781", "authors": ["Warda Usman", "Yixin Zou", "Daniel Zappala"], "title": "Human-Centered Threat Modeling in Practice: Lessons, Challenges, and Paths Forward", "comment": null, "summary": "Human-centered threat modeling (HCTM) is an emerging area within security and privacy research that focuses on how people define and navigate threats in various social, cultural, and technological contexts. While researchers increasingly approach threat modeling from a human-centered perspective, little is known about how they prepare for and engage with HCTM in practice. In this work, we conduct 23 semi-structured interviews with researchers to examine the state of HCTM, including how researchers design studies, elicit threats, and navigate values, constraints, and long-term goals. We find that HCTM is not a prescriptive process but a set of evolving practices shaped by relationships with participants, disciplinary backgrounds, and institutional structures. Researchers approach threat modeling through sustained groundwork and participant-centered inquiry, guided by values such as care, justice, and autonomy. They also face challenges including emotional strain, ethical dilemmas, and structural barriers that complicate efforts to translate findings into real-world impact. We conclude by identifying opportunities to advance HCTM through shared infrastructure, broader recognition of diverse contributions, and stronger mechanisms for translating findings into policy, design, and societal change.", "AI": {"tldr": "\u901a\u8fc7\u5bf923\u4f4d\u7814\u7a76\u4eba\u5458\u7684\u534a\u7ed3\u6784\u5316\u8bbf\u8c08\uff0c\u63a2\u8ba8\u4e86\u4ee5\u4eba\u4e3a\u4e2d\u5fc3\u7684\u5a01\u80c1\u5efa\u6a21(HCTM)\u7684\u5b9e\u8df5\u73b0\u72b6\uff0c\u53d1\u73b0HCTM\u662f\u4e00\u5957\u4e0d\u65ad\u6f14\u53d8\u7684\u5b9e\u8df5\uff0c\u53d7\u5230\u53c2\u4e0e\u8005\u5173\u7cfb\u3001\u5b66\u79d1\u80cc\u666f\u548c\u5236\u5ea6\u7ed3\u6784\u7684\u5f71\u54cd\u3002", "motivation": "\u867d\u7136\u7814\u7a76\u4eba\u5458\u8d8a\u6765\u8d8a\u591a\u5730\u4ece\u4ee5\u4eba\u4e3a\u4e2d\u5fc3\u7684\u89d2\u5ea6\u8fdb\u884c\u5a01\u80c1\u5efa\u6a21\uff0c\u4f46\u5bf9\u4e8e\u4ed6\u4eec\u5982\u4f55\u5728\u5b9e\u8df5\u4e2d\u51c6\u5907\u548c\u53c2\u4e0eHCTM\u77e5\u4e4b\u751a\u5c11\u3002", "method": "\u5bf923\u4f4d\u7814\u7a76\u4eba\u5458\u8fdb\u884c\u534a\u7ed3\u6784\u5316\u8bbf\u8c08\uff0c\u8003\u5bdf\u4ed6\u4eec\u5982\u4f55\u8bbe\u8ba1\u7814\u7a76\u3001\u5f15\u51fa\u5a01\u80c1\u3001\u4ee5\u53ca\u5904\u7406\u4ef7\u503c\u89c2\u3001\u7ea6\u675f\u548c\u957f\u671f\u76ee\u6807\u3002", "result": "HCTM\u4e0d\u662f\u89c4\u5b9a\u6027\u8fc7\u7a0b\uff0c\u800c\u662f\u7531\u4e0e\u53c2\u4e0e\u8005\u7684\u5173\u7cfb\u3001\u5b66\u79d1\u80cc\u666f\u548c\u5236\u5ea6\u7ed3\u6784\u5851\u9020\u7684\u4e0d\u65ad\u6f14\u53d8\u7684\u5b9e\u8df5\u3002\u7814\u7a76\u4eba\u5458\u901a\u8fc7\u6301\u7eed\u7684\u57fa\u7840\u5de5\u4f5c\u548c\u4ee5\u53c2\u4e0e\u8005\u4e3a\u4e2d\u5fc3\u7684\u8c03\u67e5\u6765\u8fdb\u884c\u5a01\u80c1\u5efa\u6a21\uff0c\u9075\u5faa\u5173\u6000\u3001\u6b63\u4e49\u548c\u81ea\u4e3b\u7b49\u4ef7\u503c\u89c2\uff0c\u4f46\u4e5f\u9762\u4e34\u60c5\u611f\u538b\u529b\u3001\u4f26\u7406\u56f0\u5883\u548c\u7ed3\u6784\u969c\u788d\u7b49\u6311\u6218\u3002", "conclusion": "\u63d0\u51fa\u4e86\u901a\u8fc7\u5171\u4eab\u57fa\u7840\u8bbe\u65bd\u3001\u66f4\u5e7f\u6cdb\u8ba4\u53ef\u591a\u6837\u5316\u8d21\u732e\u4ee5\u53ca\u66f4\u5f3a\u6709\u529b\u7684\u673a\u5236\u5c06\u7814\u7a76\u6210\u679c\u8f6c\u5316\u4e3a\u653f\u7b56\u3001\u8bbe\u8ba1\u548c\u793e\u4f1a\u53d8\u9769\u6765\u63a8\u8fdbHCTM\u7684\u673a\u4f1a\u3002"}}
{"id": "2511.13789", "categories": ["cs.CR", "cs.AI"], "pdf": "https://arxiv.org/pdf/2511.13789", "abs": "https://arxiv.org/abs/2511.13789", "authors": ["Haotian Jin", "Yang Li", "Haihui Fan", "Lin Shen", "Xiangfang Li", "Bo Li"], "title": "Uncovering and Aligning Anomalous Attention Heads to Defend Against NLP Backdoor Attacks", "comment": null, "summary": "Backdoor attacks pose a serious threat to the security of large language models (LLMs), causing them to exhibit anomalous behavior under specific trigger conditions. The design of backdoor triggers has evolved from fixed triggers to dynamic or implicit triggers. This increased flexibility in trigger design makes it challenging for defenders to identify their specific forms accurately. Most existing backdoor defense methods are limited to specific types of triggers or rely on an additional clean model for support. To address this issue, we propose a backdoor detection method based on attention similarity, enabling backdoor detection without prior knowledge of the trigger. Our study reveals that models subjected to backdoor attacks exhibit unusually high similarity among attention heads when exposed to triggers. Based on this observation, we propose an attention safety alignment approach combined with head-wise fine-tuning to rectify potentially contaminated attention heads, thereby effectively mitigating the impact of backdoor attacks. Extensive experimental results demonstrate that our method significantly reduces the success rate of backdoor attacks while preserving the model's performance on downstream tasks.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8e\u6ce8\u610f\u529b\u76f8\u4f3c\u6027\u7684\u540e\u95e8\u68c0\u6d4b\u65b9\u6cd5\uff0c\u65e0\u9700\u5148\u9a8c\u77e5\u8bc6\u5373\u53ef\u68c0\u6d4b\u52a8\u6001\u6216\u9690\u5f0f\u89e6\u53d1\u5668\uff0c\u5e76\u901a\u8fc7\u6ce8\u610f\u529b\u5b89\u5168\u5bf9\u9f50\u548c\u9010\u5934\u5fae\u8c03\u6765\u7f13\u89e3\u540e\u95e8\u653b\u51fb\u3002", "motivation": "\u540e\u95e8\u653b\u51fb\u5bf9LLMs\u5b89\u5168\u6784\u6210\u4e25\u91cd\u5a01\u80c1\uff0c\u73b0\u6709\u9632\u5fa1\u65b9\u6cd5\u5c40\u9650\u4e8e\u7279\u5b9a\u89e6\u53d1\u5668\u7c7b\u578b\u6216\u4f9d\u8d56\u989d\u5916\u5e72\u51c0\u6a21\u578b\u652f\u6301\uff0c\u96be\u4ee5\u5e94\u5bf9\u52a8\u6001\u6216\u9690\u5f0f\u89e6\u53d1\u5668\u7684\u6311\u6218\u3002", "method": "\u57fa\u4e8e\u6ce8\u610f\u529b\u76f8\u4f3c\u6027\u68c0\u6d4b\u540e\u95e8\uff0c\u53d1\u73b0\u53d7\u653b\u51fb\u6a21\u578b\u5728\u89e6\u53d1\u6761\u4ef6\u4e0b\u6ce8\u610f\u529b\u5934\u95f4\u76f8\u4f3c\u5ea6\u5f02\u5e38\u9ad8\uff0c\u91c7\u7528\u6ce8\u610f\u529b\u5b89\u5168\u5bf9\u9f50\u548c\u9010\u5934\u5fae\u8c03\u6765\u4fee\u6b63\u53d7\u6c61\u67d3\u7684\u6ce8\u610f\u529b\u5934\u3002", "result": "\u5b9e\u9a8c\u7ed3\u679c\u8868\u660e\u8be5\u65b9\u6cd5\u663e\u8457\u964d\u4f4e\u540e\u95e8\u653b\u51fb\u6210\u529f\u7387\uff0c\u540c\u65f6\u4fdd\u6301\u6a21\u578b\u5728\u4e0b\u6e38\u4efb\u52a1\u4e0a\u7684\u6027\u80fd\u3002", "conclusion": "\u8be5\u65b9\u6cd5\u80fd\u6709\u6548\u68c0\u6d4b\u548c\u7f13\u89e3\u540e\u95e8\u653b\u51fb\uff0c\u65e0\u9700\u89e6\u53d1\u5668\u5148\u9a8c\u77e5\u8bc6\uff0c\u4e3aLLMs\u5b89\u5168\u63d0\u4f9b\u4e86\u65b0\u7684\u9632\u5fa1\u601d\u8def\u3002"}}
{"id": "2511.13808", "categories": ["cs.CR", "cs.LG", "cs.MS"], "pdf": "https://arxiv.org/pdf/2511.13808", "abs": "https://arxiv.org/abs/2511.13808", "authors": ["Edward Raff", "Ryan R. Curtin", "Derek Everett", "Robert J. Joyce", "James Holt"], "title": "Zipf-Gramming: Scaling Byte N-Grams Up to Production Sized Malware Corpora", "comment": "Published in CIKM 2025", "summary": "A classifier using byte n-grams as features is the only approach we have found fast enough to meet requirements in size (sub 2 MB), speed (multiple GB/s), and latency (sub 10 ms) for deployment in numerous malware detection scenarios. However, we've consistently found that 6-8 grams achieve the best accuracy on our production deployments but have been unable to deploy regularly updated models due to the high cost of finding the top-k most frequent n-grams over terabytes of executable programs. Because the Zipfian distribution well models the distribution of n-grams, we exploit its properties to develop a new top-k n-gram extractor that is up to $35\\times$ faster than the previous best alternative. Using our new Zipf-Gramming algorithm, we are able to scale up our production training set and obtain up to 30\\% improvement in AUC at detecting new malware. We show theoretically and empirically that our approach will select the top-k items with little error and the interplay between theory and engineering required to achieve these results.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u540d\u4e3aZipf-Gramming\u7684\u65b0\u7b97\u6cd5\uff0c\u7528\u4e8e\u9ad8\u6548\u63d0\u53d6\u5b57\u8282n-gram\u7279\u5f81\uff0c\u5728\u6076\u610f\u8f6f\u4ef6\u68c0\u6d4b\u4e2d\u5b9e\u73b035\u500d\u901f\u5ea6\u63d0\u5347\u548c30%\u7684AUC\u6539\u8fdb\u3002", "motivation": "\u73b0\u6709\u57fa\u4e8e\u5b57\u8282n-gram\u7684\u5206\u7c7b\u5668\u5728\u6076\u610f\u8f6f\u4ef6\u68c0\u6d4b\u4e2d\u5177\u6709\u7406\u60f3\u7684\u901f\u5ea6\u548c\u5ef6\u8fdf\u7279\u6027\uff0c\u4f46\u66f4\u65b0\u6a21\u578b\u6210\u672c\u9ad8\u6602\uff0c\u65e0\u6cd5\u9891\u7e41\u90e8\u7f72\u66f4\u65b0\u7684\u6a21\u578b\u3002", "method": "\u5229\u7528Zipf\u5206\u5e03\u7279\u6027\u5f00\u53d1\u65b0\u7684top-k n-gram\u63d0\u53d6\u5668Zipf-Gramming\u7b97\u6cd5\uff0c\u901a\u8fc7\u7406\u8bba\u5206\u6790\u548c\u5de5\u7a0b\u5b9e\u73b0\u4f18\u5316\u63d0\u53d6\u8fc7\u7a0b\u3002", "result": "\u65b0\u7b97\u6cd5\u6bd4\u4e4b\u524d\u6700\u4f73\u65b9\u6848\u5feb35\u500d\uff0c\u901a\u8fc7\u6269\u5927\u8bad\u7ec3\u96c6\u89c4\u6a21\u4f7f\u68c0\u6d4b\u65b0\u6076\u610f\u8f6f\u4ef6\u7684AUC\u63d0\u534730%\u3002", "conclusion": "Zipf-Gramming\u7b97\u6cd5\u80fd\u591f\u9ad8\u6548\u51c6\u786e\u5730\u9009\u62e9top-k n-gram\u7279\u5f81\uff0c\u5b9e\u73b0\u4e86\u7406\u8bba\u4e0e\u5de5\u7a0b\u7684\u7ed3\u5408\uff0c\u89e3\u51b3\u4e86\u5927\u89c4\u6a21\u6076\u610f\u8f6f\u4ef6\u68c0\u6d4b\u4e2d\u7684\u6a21\u578b\u66f4\u65b0\u74f6\u9888\u3002"}}
{"id": "2511.13939", "categories": ["cs.CR"], "pdf": "https://arxiv.org/pdf/2511.13939", "abs": "https://arxiv.org/abs/2511.13939", "authors": ["Paul Staat", "Christof Paar", "Swarun Kumar"], "title": "The Battle of Metasurfaces: Understanding Security in Smart Radio Environments", "comment": null, "summary": "Metasurfaces, or Reconfigurable Intelligent Surfaces (RISs), have emerged as a transformative technology for next-generation wireless systems, enabling digitally controlled manipulation of electromagnetic wave propagation. By turning the traditionally passive radio environment into a smart, programmable medium, metasurfaces promise advances in communication and sensing. However, metasurfaces also present a new security frontier: both attackers and defenders can exploit them to alter wireless propagation for their own advantage. While prior security research has primarily explored unilateral metasurface applications - empowering either attackers or defenders - this work investigates symmetric scenarios, where both sides possess comparable metasurface capabilities. Using both theoretical modeling and real-world experiments, we analyze how competing metasurfaces interact for diverse objectives, including signal power and sensing perception. Thereby, we present the first systematic study of context-agnostic metasurface-to-metasurface interactions and their implications for wireless security. Our results reveal that the outcome of metasurface \"battles\" depends on an interplay of timing, placement, algorithmic strategy, and hardware scale. Across multiple case studies in Wi-Fi environments, including wireless jamming, channel obfuscation for sensing and communication, and sensing spoofing, we demonstrate that opposing metasurfaces can substantially or fully negate each other's effects. By undermining previously proposed security and privacy schemes, our findings open new opportunities for designing resilient and high-assurance physical-layer systems in smart radio environments.", "AI": {"tldr": "\u672c\u6587\u9996\u6b21\u7cfb\u7edf\u7814\u7a76\u4e86\u5bf9\u79f0\u573a\u666f\u4e0b\u7ade\u4e89\u6027\u8d85\u8868\u9762\u7684\u76f8\u4e92\u4f5c\u7528\u53ca\u5176\u5bf9\u65e0\u7ebf\u5b89\u5168\u7684\u5f71\u54cd\uff0c\u53d1\u73b0\u5728Wi-Fi\u73af\u5883\u4e2d\uff0c\u5bf9\u7acb\u7684\u8d85\u8868\u9762\u53ef\u4ee5\u76f8\u4e92\u62b5\u6d88\u6548\u679c\uff0c\u8fd9\u65e2\u6311\u6218\u4e86\u73b0\u6709\u5b89\u5168\u65b9\u6848\uff0c\u4e5f\u4e3a\u8bbe\u8ba1\u5f39\u6027\u7269\u7406\u5c42\u7cfb\u7edf\u63d0\u4f9b\u4e86\u65b0\u673a\u4f1a\u3002", "motivation": "\u8d85\u8868\u9762\u6280\u672f\u4f7f\u65e0\u7ebf\u73af\u5883\u53d8\u5f97\u53ef\u7f16\u7a0b\uff0c\u4f46\u73b0\u6709\u5b89\u5168\u7814\u7a76\u4e3b\u8981\u5173\u6ce8\u5355\u8fb9\u5e94\u7528\u3002\u672c\u6587\u7814\u7a76\u5bf9\u79f0\u573a\u666f\uff0c\u5373\u653b\u51fb\u8005\u548c\u9632\u5fa1\u8005\u90fd\u62e5\u6709\u8d85\u8868\u9762\u80fd\u529b\u65f6\u7684\u76f8\u4e92\u4f5c\u7528\u3002", "method": "\u901a\u8fc7\u7406\u8bba\u5efa\u6a21\u548c\u771f\u5b9e\u4e16\u754c\u5b9e\u9a8c\uff0c\u5206\u6790\u7ade\u4e89\u6027\u8d85\u8868\u9762\u5728\u4e0d\u540c\u76ee\u6807\uff08\u4fe1\u53f7\u529f\u7387\u3001\u611f\u77e5\u611f\u77e5\uff09\u4e0b\u7684\u76f8\u4e92\u4f5c\u7528\uff0c\u5e76\u5728Wi-Fi\u73af\u5883\u4e2d\u8fdb\u884c\u591a\u4e2a\u6848\u4f8b\u7814\u7a76\u3002", "result": "\u7ed3\u679c\u8868\u660e\u8d85\u8868\u9762\"\u6218\u6597\"\u7684\u7ed3\u679c\u53d6\u51b3\u4e8e\u65f6\u673a\u3001\u4f4d\u7f6e\u3001\u7b97\u6cd5\u7b56\u7565\u548c\u786c\u4ef6\u89c4\u6a21\u7684\u76f8\u4e92\u4f5c\u7528\u3002\u5bf9\u7acb\u7684\u8d85\u8868\u9762\u53ef\u4ee5\u663e\u8457\u6216\u5b8c\u5168\u62b5\u6d88\u5f7c\u6b64\u7684\u6548\u679c\u3002", "conclusion": "\u7814\u7a76\u7ed3\u679c\u65e2\u6311\u6218\u4e86\u5148\u524d\u63d0\u51fa\u7684\u5b89\u5168\u548c\u9690\u79c1\u65b9\u6848\uff0c\u4e5f\u4e3a\u5728\u667a\u80fd\u65e0\u7ebf\u7535\u73af\u5883\u4e2d\u8bbe\u8ba1\u5f39\u6027\u548c\u9ad8\u4fdd\u8bc1\u7684\u7269\u7406\u5c42\u7cfb\u7edf\u5f00\u8f9f\u4e86\u65b0\u673a\u4f1a\u3002"}}
{"id": "2511.14005", "categories": ["cs.CR", "cs.MM"], "pdf": "https://arxiv.org/pdf/2511.14005", "abs": "https://arxiv.org/abs/2511.14005", "authors": ["Kaiyuan Hu", "Hong Kang", "Yili Jin", "Junhua Liu", "Chengming Hu", "Haolun Wu", "Xue Liu"], "title": "Privis: Towards Content-Aware Secure Volumetric Video Delivery", "comment": null, "summary": "Volumetric video has emerged as a key paradigm in eXtended Reality (XR) and immersive multimedia because it enables highly interactive, spatially consistent 3D experiences. However, the transport-layer security for such 3D content remains largely unaddressed. Existing volumetric streaming pipelines inherit uniform encryption schemes from 2D video, overlooking the heterogeneous privacy sensitivity of different geometry and the strict motion-to-photon latency constraints of real-time XR.\n  We take an initial step toward content-aware secure volumetric video delivery by introducing Privis, a saliency-guided transport framework that (i) partitions volumetric assets into independent units, (ii) applies lightweight authenticated encryption with adaptive key rotation, and (iii) employs selective traffic shaping to balance confidentiality and low latency. Privis specifies a generalized transport-layer security architecture for volumetric media, defining core abstractions and adaptive protection mechanisms. We further explore a prototype implementation and present initial latency measurements to illustrate feasibility and design tradeoffs, providing early empirical guidance toward future work on real-time, saliency-conditioned secure delivery.", "AI": {"tldr": "Privis\u662f\u4e00\u4e2a\u57fa\u4e8e\u663e\u8457\u6027\u7684\u5b89\u5168\u4f53\u79ef\u89c6\u9891\u4f20\u8f93\u6846\u67b6\uff0c\u901a\u8fc7\u5206\u533a\u52a0\u5bc6\u3001\u8f7b\u91cf\u8ba4\u8bc1\u548c\u9009\u62e9\u6027\u6d41\u91cf\u6574\u5f62\u6765\u5e73\u8861\u673a\u5bc6\u6027\u548c\u4f4e\u5ef6\u8fdf\u9700\u6c42\u3002", "motivation": "\u73b0\u6709\u4f53\u79ef\u89c6\u9891\u6d41\u5a92\u4f53\u7ee7\u627f\u4e862D\u89c6\u9891\u7684\u7edf\u4e00\u52a0\u5bc6\u65b9\u6848\uff0c\u5ffd\u7565\u4e86\u4e0d\u540c\u51e0\u4f55\u6570\u636e\u7684\u9690\u79c1\u654f\u611f\u5ea6\u5dee\u5f02\u548c\u5b9e\u65f6XR\u7684\u4e25\u683c\u5ef6\u8fdf\u7ea6\u675f\u3002", "method": "\u5c06\u4f53\u79ef\u8d44\u4ea7\u5206\u533a\u4e3a\u72ec\u7acb\u5355\u5143\uff0c\u5e94\u7528\u8f7b\u91cf\u7ea7\u8ba4\u8bc1\u52a0\u5bc6\u548c\u81ea\u9002\u5e94\u5bc6\u94a5\u8f6e\u6362\uff0c\u91c7\u7528\u9009\u62e9\u6027\u6d41\u91cf\u6574\u5f62\u3002", "result": "\u63d0\u51fa\u4e86\u901a\u7528\u7684\u4f20\u8f93\u5c42\u5b89\u5168\u67b6\u6784\uff0c\u5b9a\u4e49\u4e86\u6838\u5fc3\u62bd\u8c61\u548c\u81ea\u9002\u5e94\u4fdd\u62a4\u673a\u5236\uff0c\u5e76\u901a\u8fc7\u539f\u578b\u5b9e\u73b0\u5c55\u793a\u4e86\u53ef\u884c\u6027\u3002", "conclusion": "\u4e3a\u5b9e\u65f6\u3001\u57fa\u4e8e\u663e\u8457\u6027\u7684\u5b89\u5168\u4f53\u79ef\u89c6\u9891\u4f20\u8f93\u63d0\u4f9b\u4e86\u65e9\u671f\u5b9e\u8bc1\u6307\u5bfc\uff0c\u662f\u5185\u5bb9\u611f\u77e5\u5b89\u5168\u4f53\u79ef\u89c6\u9891\u4f20\u8f93\u7684\u521d\u6b65\u63a2\u7d22\u3002"}}
{"id": "2511.14032", "categories": ["cs.CR"], "pdf": "https://arxiv.org/pdf/2511.14032", "abs": "https://arxiv.org/abs/2511.14032", "authors": ["Kunal Mukherjee"], "title": "Location-Dependent Cryptosystem", "comment": null, "summary": "Digital content distribution and proprietary research-driven industries face persistent risks from intellectual property theft and unauthorized redistribution. Conventional encryption schemes such as AES, TDES, ECC, and ElGamal provide strong cryptographic guarantees, but they remain fundamentally agnostic to where decryption takes place.In practice, this means that once a decryption key is leaked or intercepted, any adversary can misuse the key to decrypt the protected content from any location. We present a location-dependent cryptosystem in which the decryption key is not transmitted as human- or machine-readable data, but implicitly encoded in precise time-of-flight differences of ultra-wideband (UWB) data transmission packets. The system leverages precise timing hardware and a custom JMTK protocol to map a SHA-256 hashed AES key onto scheduled transmission timestamps. Only receivers located within a predefined spatial region can observe the packet timings that align with the intended \"time slot\" pattern, enabling them to reconstruct the key and decrypt the secret. Receivers outside the authorized region observe incorrect keys. We implement a complete prototype that encrypts and transmits audio data using our cryptosystem, and only when the receiver is within the authorized data, they are able to decrypt the data. Our evaluation demonstrates that the system (i) removes the need to share decryption passwords electronically or physically, (ii) ensures the decryption key cannot be recovered by the eavesdropper, and (iii) provides a non-trivial spatial tolerance for legitimate users.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8e\u8d85\u5bbd\u5e26(UWB)\u6570\u636e\u4f20\u8f93\u5305\u98de\u884c\u65f6\u95f4\u5dee\u5f02\u7684\u4f4d\u7f6e\u4f9d\u8d56\u52a0\u5bc6\u7cfb\u7edf\uff0c\u89e3\u5bc6\u5bc6\u94a5\u4e0d\u662f\u76f4\u63a5\u4f20\u8f93\uff0c\u800c\u662f\u901a\u8fc7\u7cbe\u786e\u7684\u65f6\u95f4\u5dee\u9690\u5f0f\u7f16\u7801\uff0c\u53ea\u6709\u4f4d\u4e8e\u9884\u5b9a\u7a7a\u95f4\u533a\u57df\u5185\u7684\u63a5\u6536\u5668\u624d\u80fd\u6b63\u786e\u91cd\u5efa\u5bc6\u94a5\u3002", "motivation": "\u89e3\u51b3\u4f20\u7edf\u52a0\u5bc6\u65b9\u6848(\u5982AES\u3001TDES\u3001ECC\u7b49)\u5728\u5bc6\u94a5\u6cc4\u9732\u540e\u65e0\u6cd5\u9650\u5236\u89e3\u5bc6\u4f4d\u7f6e\u7684\u95ee\u9898\uff0c\u9632\u6b62\u77e5\u8bc6\u4ea7\u6743\u88ab\u76d7\u548c\u672a\u7ecf\u6388\u6743\u7684\u518d\u5206\u53d1\u3002", "method": "\u5229\u7528\u7cbe\u786e\u8ba1\u65f6\u786c\u4ef6\u548c\u81ea\u5b9a\u4e49JMTK\u534f\u8bae\uff0c\u5c06SHA-256\u54c8\u5e0c\u7684AES\u5bc6\u94a5\u6620\u5c04\u5230\u9884\u5b9a\u7684\u4f20\u8f93\u65f6\u95f4\u6233\u4e0a\uff0c\u901a\u8fc7UWB\u6570\u636e\u5305\u7684\u98de\u884c\u65f6\u95f4\u5dee\u5f02\u9690\u5f0f\u7f16\u7801\u89e3\u5bc6\u5bc6\u94a5\u3002", "result": "\u5b9e\u73b0\u4e86\u5b8c\u6574\u539f\u578b\u7cfb\u7edf\uff0c\u80fd\u591f\u52a0\u5bc6\u4f20\u8f93\u97f3\u9891\u6570\u636e\uff0c\u53ea\u6709\u4f4d\u4e8e\u6388\u6743\u533a\u57df\u5185\u7684\u63a5\u6536\u5668\u624d\u80fd\u6210\u529f\u89e3\u5bc6\uff1b\u7cfb\u7edf\u65e0\u9700\u7535\u5b50\u6216\u7269\u7406\u5171\u4eab\u89e3\u5bc6\u5bc6\u7801\uff0c\u5bc6\u94a5\u65e0\u6cd5\u88ab\u7a83\u542c\u8005\u6062\u590d\uff0c\u5e76\u4e3a\u5408\u6cd5\u7528\u6237\u63d0\u4f9b\u7a7a\u95f4\u5bb9\u5dee\u3002", "conclusion": "\u4f4d\u7f6e\u4f9d\u8d56\u52a0\u5bc6\u7cfb\u7edf\u901a\u8fc7\u7a7a\u95f4\u9650\u5236\u6709\u6548\u589e\u5f3a\u4e86\u6570\u5b57\u5185\u5bb9\u4fdd\u62a4\uff0c\u89e3\u51b3\u4e86\u4f20\u7edf\u52a0\u5bc6\u65b9\u6848\u7684\u4f4d\u7f6e\u65e0\u5173\u6027\u7f3a\u9677\u3002"}}
{"id": "2511.14045", "categories": ["cs.CR", "cs.AI", "cs.CL"], "pdf": "https://arxiv.org/pdf/2511.14045", "abs": "https://arxiv.org/abs/2511.14045", "authors": ["Yule Liu", "Heyi Zhang", "Jinyi Zheng", "Zhen Sun", "Zifan Peng", "Tianshuo Cong", "Yilong Yang", "Xinlei He", "Zhuo Ma"], "title": "GRPO Privacy Is at Risk: A Membership Inference Attack Against Reinforcement Learning With Verifiable Rewards", "comment": null, "summary": "Membership inference attacks (MIAs) on large language models (LLMs) pose significant privacy risks across various stages of model training. Recent advances in Reinforcement Learning with Verifiable Rewards (RLVR) have brought a profound paradigm shift in LLM training, particularly for complex reasoning tasks. However, the on-policy nature of RLVR introduces a unique privacy leakage pattern: since training relies on self-generated responses without fixed ground-truth outputs, membership inference must now determine whether a given prompt (independent of any specific response) is used during fine-tuning. This creates a threat where leakage arises not from answer memorization.\n  To audit this novel privacy risk, we propose Divergence-in-Behavior Attack (DIBA), the first membership inference framework specifically designed for RLVR. DIBA shifts the focus from memorization to behavioral change, leveraging measurable shifts in model behavior across two axes: advantage-side improvement (e.g., correctness gain) and logit-side divergence (e.g., policy drift). Through comprehensive evaluations, we demonstrate that DIBA significantly outperforms existing baselines, achieving around 0.8 AUC and an order-of-magnitude higher TPR@0.1%FPR. We validate DIBA's superiority across multiple settings--including in-distribution, cross-dataset, cross-algorithm, black-box scenarios, and extensions to vision-language models. Furthermore, our attack remains robust under moderate defensive measures.\n  To the best of our knowledge, this is the first work to systematically analyze privacy vulnerabilities in RLVR, revealing that even in the absence of explicit supervision, training data exposure can be reliably inferred through behavioral traces.", "AI": {"tldr": "\u63d0\u51fa\u4e86DIBA\u653b\u51fb\u65b9\u6cd5\uff0c\u4e13\u95e8\u9488\u5bf9RLVR\u8bad\u7ec3\u7684\u5927\u8bed\u8a00\u6a21\u578b\u8fdb\u884c\u6210\u5458\u63a8\u7406\u653b\u51fb\uff0c\u901a\u8fc7\u68c0\u6d4b\u6a21\u578b\u884c\u4e3a\u53d8\u5316\u800c\u975e\u7b54\u6848\u8bb0\u5fc6\u6765\u8bc6\u522b\u8bad\u7ec3\u6570\u636e\uff0c\u5728\u591a\u4e2a\u573a\u666f\u4e0b\u663e\u8457\u4f18\u4e8e\u73b0\u6709\u57fa\u7ebf\u65b9\u6cd5\u3002", "motivation": "RLVR\u8bad\u7ec3\u8303\u5f0f\u5f15\u5165\u4e86\u65b0\u7684\u9690\u79c1\u6cc4\u9732\u6a21\u5f0f\uff1a\u7531\u4e8e\u8bad\u7ec3\u4f9d\u8d56\u81ea\u751f\u6210\u54cd\u5e94\u800c\u975e\u56fa\u5b9a\u771f\u503c\u8f93\u51fa\uff0c\u6210\u5458\u63a8\u7406\u9700\u8981\u5224\u65ad\u7ed9\u5b9a\u63d0\u793a\u662f\u5426\u7528\u4e8e\u5fae\u8c03\uff0c\u8fd9\u79cd\u5a01\u80c1\u6e90\u4e8e\u884c\u4e3a\u53d8\u5316\u800c\u975e\u7b54\u6848\u8bb0\u5fc6\u3002", "method": "\u63d0\u51faDIBA\u653b\u51fb\u6846\u67b6\uff0c\u4ece\u8bb0\u5fc6\u8f6c\u5411\u884c\u4e3a\u53d8\u5316\u68c0\u6d4b\uff0c\u5229\u7528\u4e24\u4e2a\u7ef4\u5ea6\u7684\u53ef\u6d4b\u91cf\u884c\u4e3a\u53d8\u5316\uff1a\u4f18\u52bf\u4fa7\u6539\u8fdb\uff08\u5982\u6b63\u786e\u6027\u63d0\u5347\uff09\u548c\u5bf9\u6570\u4fa7\u5206\u6b67\uff08\u5982\u7b56\u7565\u6f02\u79fb\uff09\u3002", "result": "DIBA\u663e\u8457\u4f18\u4e8e\u73b0\u6709\u57fa\u7ebf\uff0c\u8fbe\u5230\u7ea60.8\u7684AUC\u548c\u6570\u91cf\u7ea7\u66f4\u9ad8\u7684TPR@0.1%FPR\uff0c\u5728\u5206\u5e03\u5185\u3001\u8de8\u6570\u636e\u96c6\u3001\u8de8\u7b97\u6cd5\u3001\u9ed1\u76d2\u573a\u666f\u4ee5\u53ca\u6269\u5c55\u5230\u89c6\u89c9\u8bed\u8a00\u6a21\u578b\u7b49\u591a\u4e2a\u8bbe\u7f6e\u4e2d\u5747\u8868\u73b0\u4f18\u8d8a\uff0c\u4e14\u5bf9\u9002\u5ea6\u9632\u5fa1\u63aa\u65bd\u4fdd\u6301\u9c81\u68d2\u3002", "conclusion": "\u8fd9\u662f\u9996\u4e2a\u7cfb\u7edf\u5206\u6790RLVR\u9690\u79c1\u6f0f\u6d1e\u7684\u5de5\u4f5c\uff0c\u63ed\u793a\u4e86\u5373\u4f7f\u5728\u7f3a\u4e4f\u663e\u5f0f\u76d1\u7763\u7684\u60c5\u51b5\u4e0b\uff0c\u8bad\u7ec3\u6570\u636e\u66b4\u9732\u4ecd\u53ef\u901a\u8fc7\u884c\u4e3a\u75d5\u8ff9\u53ef\u9760\u63a8\u65ad\u3002"}}
{"id": "2511.14074", "categories": ["cs.CR", "cs.LG"], "pdf": "https://arxiv.org/pdf/2511.14074", "abs": "https://arxiv.org/abs/2511.14074", "authors": ["Ajesh Koyatan Chathoth", "Stephen Lee"], "title": "Dynamic Black-box Backdoor Attacks on IoT Sensory Data", "comment": null, "summary": "Sensor data-based recognition systems are widely used in various applications, such as gait-based authentication and human activity recognition (HAR). Modern wearable and smart devices feature various built-in Inertial Measurement Unit (IMU) sensors, and such sensor-based measurements can be fed to a machine learning-based model to train and classify human activities. While deep learning-based models have proven successful in classifying human activity and gestures, they pose various security risks. In our paper, we discuss a novel dynamic trigger-generation technique for performing black-box adversarial attacks on sensor data-based IoT systems. Our empirical analysis shows that the attack is successful on various datasets and classifier models with minimal perturbation on the input data. We also provide a detailed comparative analysis of performance and stealthiness to various other poisoning techniques found in backdoor attacks. We also discuss some adversarial defense mechanisms and their impact on the effectiveness of our trigger-generation technique.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u9488\u5bf9\u4f20\u611f\u5668\u6570\u636e\u7269\u8054\u7f51\u7cfb\u7edf\u7684\u9ed1\u76d2\u5bf9\u6297\u653b\u51fb\u65b9\u6cd5\uff0c\u901a\u8fc7\u52a8\u6001\u89e6\u53d1\u5668\u751f\u6210\u6280\u672f\uff0c\u5728\u6700\u5c0f\u6270\u52a8\u4e0b\u6210\u529f\u653b\u51fb\u591a\u79cd\u6570\u636e\u96c6\u548c\u5206\u7c7b\u5668\u6a21\u578b\u3002", "motivation": "\u57fa\u4e8e\u4f20\u611f\u5668\u6570\u636e\u7684\u8bc6\u522b\u7cfb\u7edf\uff08\u5982\u6b65\u6001\u8ba4\u8bc1\u548c\u4eba\u7c7b\u6d3b\u52a8\u8bc6\u522b\uff09\u5e7f\u6cdb\u5e94\u7528\uff0c\u4f46\u6df1\u5ea6\u5b66\u4e60\u6a21\u578b\u5b58\u5728\u5b89\u5168\u98ce\u9669\uff0c\u9700\u8981\u7814\u7a76\u5bf9\u6297\u653b\u51fb\u4ee5\u63ed\u793a\u5176\u8106\u5f31\u6027\u3002", "method": "\u5f00\u53d1\u4e86\u65b0\u9896\u7684\u52a8\u6001\u89e6\u53d1\u5668\u751f\u6210\u6280\u672f\uff0c\u7528\u4e8e\u5bf9\u4f20\u611f\u5668\u6570\u636e\u7269\u8054\u7f51\u7cfb\u7edf\u6267\u884c\u9ed1\u76d2\u5bf9\u6297\u653b\u51fb\uff0c\u5e76\u4e0e\u73b0\u6709\u540e\u95e8\u653b\u51fb\u4e2d\u7684\u6295\u6bd2\u6280\u672f\u8fdb\u884c\u6027\u80fd\u6bd4\u8f83\u3002", "result": "\u7ecf\u9a8c\u5206\u6790\u8868\u660e\uff0c\u8be5\u653b\u51fb\u65b9\u6cd5\u5728\u591a\u79cd\u6570\u636e\u96c6\u548c\u5206\u7c7b\u5668\u6a21\u578b\u4e0a\u5747\u80fd\u6210\u529f\uff0c\u4e14\u5bf9\u8f93\u5165\u6570\u636e\u7684\u6270\u52a8\u6700\u5c0f\u3002", "conclusion": "\u8ba8\u8bba\u4e86\u5bf9\u6297\u9632\u5fa1\u673a\u5236\u53ca\u5176\u5bf9\u89e6\u53d1\u5668\u751f\u6210\u6280\u672f\u6709\u6548\u6027\u7684\u5f71\u54cd\uff0c\u5f3a\u8c03\u4e86\u4f20\u611f\u5668\u6570\u636e\u7cfb\u7edf\u9762\u4e34\u7684\u5b89\u5168\u5a01\u80c1\u3002"}}
{"id": "2511.14088", "categories": ["cs.CR"], "pdf": "https://arxiv.org/pdf/2511.14088", "abs": "https://arxiv.org/abs/2511.14088", "authors": ["Adam Caulfield", "Muhammad Wasif Kamran", "N. Asokan"], "title": "Resolving Availability and Run-time Integrity Conflicts in Real-Time Embedded Systems", "comment": null, "summary": "Run-time integrity enforcement in real-time systems presents a fundamental conflict with availability. Existing approaches in real- time systems primarily focus on minimizing the execution-time overhead of monitoring. After a violation is detected, prior works face a trade-off: (1) prioritize availability and allow a compromised system to continue to ensure applications meet their deadlines, or (2) prioritize security by generating a fault to abort all execution. In this work, we propose PAIR, an approach that offers a middle ground between the stark extremes of this trade-off. PAIR monitors real-time tasks for run-time integrity violations and maintains an Availability Region (AR) of all tasks that are safe to continue. When a task causes a violation, PAIR triggers a non-maskable interrupt to kill the task and continue executing a non-violating task within AR. Thus, PAIR ensures only violating tasks are prevented from execution, while granting availability to remaining tasks. With its hardware approach, PAIR does not cause any run-time overhead to the executing tasks, integrates with real-time operating systems (RTOSs), and is affordable to low-end microcontroller units (MCUs) by incurring +2.3% overhead in memory and hardware usage.", "AI": {"tldr": "PAIR\u63d0\u51fa\u4e86\u4e00\u79cd\u5728\u5b9e\u65f6\u7cfb\u7edf\u4e2d\u5e73\u8861\u5b89\u5168\u6027\u548c\u53ef\u7528\u6027\u7684\u65b9\u6cd5\uff0c\u901a\u8fc7\u786c\u4ef6\u76d1\u63a7\u4efb\u52a1\u5b8c\u6574\u6027\u8fdd\u89c4\uff0c\u4ec5\u7ec8\u6b62\u8fdd\u89c4\u4efb\u52a1\u800c\u4fdd\u6301\u5176\u4ed6\u4efb\u52a1\u7ee7\u7eed\u6267\u884c\u3002", "motivation": "\u73b0\u6709\u5b9e\u65f6\u7cfb\u7edf\u5728\u68c0\u6d4b\u5230\u5b8c\u6574\u6027\u8fdd\u89c4\u65f6\u9762\u4e34\u4e24\u96be\u9009\u62e9\uff1a\u8981\u4e48\u4f18\u5148\u53ef\u7528\u6027\u8ba9\u53d7\u611f\u67d3\u7cfb\u7edf\u7ee7\u7eed\u8fd0\u884c\uff0c\u8981\u4e48\u4f18\u5148\u5b89\u5168\u6027\u4e2d\u6b62\u6240\u6709\u6267\u884c\u3002\u9700\u8981\u627e\u5230\u4e2d\u95f4\u89e3\u51b3\u65b9\u6848\u3002", "method": "PAIR\u76d1\u63a7\u5b9e\u65f6\u4efb\u52a1\u7684\u8fd0\u884c\u65f6\u5b8c\u6574\u6027\u8fdd\u89c4\uff0c\u7ef4\u62a4\u5b89\u5168\u4efb\u52a1\u53ef\u7528\u533a\u57df(AR)\u3002\u5f53\u4efb\u52a1\u8fdd\u89c4\u65f6\uff0c\u89e6\u53d1\u4e0d\u53ef\u5c4f\u853d\u4e2d\u65ad\u7ec8\u6b62\u8be5\u4efb\u52a1\uff0c\u7ee7\u7eed\u6267\u884cAR\u4e2d\u7684\u975e\u8fdd\u89c4\u4efb\u52a1\u3002", "result": "PAIR\u901a\u8fc7\u786c\u4ef6\u65b9\u6cd5\u5b9e\u73b0\uff0c\u5bf9\u6267\u884c\u4efb\u52a1\u4e0d\u4ea7\u751f\u8fd0\u884c\u65f6\u5f00\u9500\uff0c\u4e0e\u5b9e\u65f6\u64cd\u4f5c\u7cfb\u7edf\u96c6\u6210\uff0c\u5728\u5185\u5b58\u548c\u786c\u4ef6\u4f7f\u7528\u4e0a\u4ec5\u589e\u52a02.3%\u7684\u5f00\u9500\u3002", "conclusion": "PAIR\u5728\u5b89\u5168\u6027\u548c\u53ef\u7528\u6027\u4e4b\u95f4\u63d0\u4f9b\u4e86\u5e73\u8861\u7684\u4e2d\u95f4\u65b9\u6848\uff0c\u4ec5\u963b\u6b62\u8fdd\u89c4\u4efb\u52a1\u6267\u884c\uff0c\u540c\u65f6\u4fdd\u8bc1\u5176\u4ed6\u4efb\u52a1\u7684\u53ef\u7528\u6027\uff0c\u9002\u7528\u4e8e\u4f4e\u7aef\u5fae\u63a7\u5236\u5668\u5355\u5143\u3002"}}
{"id": "2511.14129", "categories": ["cs.CR", "cs.LG"], "pdf": "https://arxiv.org/pdf/2511.14129", "abs": "https://arxiv.org/abs/2511.14129", "authors": ["Xiang Luo", "Chang Liu", "Gang Xiong", "Chen Yang", "Gaopeng Gou", "Yaochen Ren", "Zhen Li"], "title": "MalRAG: A Retrieval-Augmented LLM Framework for Open-set Malicious Traffic Identification", "comment": "13 pages, 13 figures. Intended for submission to IEEE Transactions on Information Forensics and Security (TIFS)", "summary": "Fine-grained identification of IDS-flagged suspicious traffic is crucial in cybersecurity. In practice, cyber threats evolve continuously, making the discovery of novel malicious traffic a critical necessity as well as the identification of known classes. Recent studies have advanced this goal with deep models, but they often rely on task-specific architectures that limit transferability and require per-dataset tuning. In this paper we introduce MalRAG, the first LLM driven retrieval-augmented framework for open-set malicious traffic identification. MalRAG freezes the LLM and operates via comprehensive traffic knowledge construction, adaptive retrieval, and prompt engineering. Concretely, we construct a multi-view traffic database by mining prior malicious traffic from content, structural, and temporal perspectives. Furthermore, we introduce a Coverage-Enhanced Retrieval Algorithm that queries across these views to assemble the most probable candidates, thereby improving the inclusion of correct evidence. We then employ Traffic-Aware Adaptive Pruning to select a variable subset of these candidates based on traffic-aware similarity scores, suppressing incorrect matches and yielding reliable retrieved evidence. Moreover, we develop a suite of guidance prompts where task instruction, evidence referencing, and decision guidance are integrated with the retrieved evidence to improve LLM performance. Across diverse real-world datasets and settings, MalRAG delivers state-of-the-art results in both fine-grained identification of known classes and novel malicious traffic discovery. Ablation and deep-dive analyses further show that MalRAG effective leverages LLM capabilities yet achieves open-set malicious traffic identification without relying on a specific LLM.", "AI": {"tldr": "MalRAG\u662f\u4e00\u4e2a\u57fa\u4e8eLLM\u7684\u68c0\u7d22\u589e\u5f3a\u6846\u67b6\uff0c\u7528\u4e8e\u5f00\u653e\u96c6\u6076\u610f\u6d41\u91cf\u8bc6\u522b\uff0c\u901a\u8fc7\u591a\u89c6\u89d2\u6d41\u91cf\u77e5\u8bc6\u6784\u5efa\u3001\u81ea\u9002\u5e94\u68c0\u7d22\u548c\u63d0\u793a\u5de5\u7a0b\u5b9e\u73b0\u7ec6\u7c92\u5ea6\u5df2\u77e5\u7c7b\u522b\u8bc6\u522b\u548c\u65b0\u6076\u610f\u6d41\u91cf\u53d1\u73b0\u3002", "motivation": "\u73b0\u6709\u7684\u6df1\u5ea6\u5b66\u4e60\u65b9\u6cd5\u4f9d\u8d56\u7279\u5b9a\u4efb\u52a1\u67b6\u6784\uff0c\u9650\u5236\u4e86\u53ef\u8fc1\u79fb\u6027\u4e14\u9700\u8981\u9488\u5bf9\u6bcf\u4e2a\u6570\u636e\u96c6\u8fdb\u884c\u8c03\u6574\u3002\u7f51\u7edc\u5b89\u5168\u5a01\u80c1\u4e0d\u65ad\u6f14\u53d8\uff0c\u53d1\u73b0\u65b0\u578b\u6076\u610f\u6d41\u91cf\u4e0e\u8bc6\u522b\u5df2\u77e5\u7c7b\u522b\u540c\u6837\u91cd\u8981\u3002", "method": "\u6784\u5efa\u591a\u89c6\u89d2\u6d41\u91cf\u6570\u636e\u5e93\uff08\u5185\u5bb9\u3001\u7ed3\u6784\u3001\u65f6\u95f4\u89c6\u89d2\uff09\uff0c\u5f15\u5165\u8986\u76d6\u7387\u589e\u5f3a\u68c0\u7d22\u7b97\u6cd5\u548c\u6d41\u91cf\u611f\u77e5\u81ea\u9002\u5e94\u526a\u679d\uff0c\u5f00\u53d1\u96c6\u6210\u4efb\u52a1\u6307\u4ee4\u3001\u8bc1\u636e\u5f15\u7528\u548c\u51b3\u7b56\u6307\u5bfc\u7684\u63d0\u793a\u7cfb\u7edf\u3002", "result": "\u5728\u591a\u6837\u5316\u771f\u5b9e\u6570\u636e\u96c6\u548c\u8bbe\u7f6e\u4e0b\uff0cMalRAG\u5728\u5df2\u77e5\u7c7b\u522b\u7ec6\u7c92\u5ea6\u8bc6\u522b\u548c\u65b0\u6076\u610f\u6d41\u91cf\u53d1\u73b0\u65b9\u9762\u5747\u53d6\u5f97\u6700\u5148\u8fdb\u7684\u7ed3\u679c\u3002", "conclusion": "MalRAG\u6709\u6548\u5229\u7528LLM\u80fd\u529b\uff0c\u5728\u4e0d\u4f9d\u8d56\u7279\u5b9aLLM\u7684\u60c5\u51b5\u4e0b\u5b9e\u73b0\u5f00\u653e\u96c6\u6076\u610f\u6d41\u91cf\u8bc6\u522b\uff0c\u5c55\u793a\u4e86\u826f\u597d\u7684\u6cdb\u5316\u6027\u80fd\u3002"}}
{"id": "2511.14132", "categories": ["cs.CR"], "pdf": "https://arxiv.org/pdf/2511.14132", "abs": "https://arxiv.org/abs/2511.14132", "authors": ["Kavya Bhand", "Payal Khubchandani", "Jyoti Khubchandani"], "title": "A Fuzzy Logic-Based Cryptographic Framework For Real-Time Dynamic Key Generation For Enhanced Data Encryption", "comment": null, "summary": "With the ever-growing demand for cybersecurity, static key encryption mechanisms are increasingly vulnerable to adversarial attacks due to their deterministic and non-adaptive nature. Brute-force attacks, key compromise, and unauthorized access have become highly common cyber threats. This research presents a novel fuzzy logic-based cryptographic framework that dynamically generates encryption keys in real-time by accessing system-level entropy and hardware-bound trust. The proposed system leverages a Fuzzy Inference System (FIS) to evaluate system parameters that include CPU utilization, process count, and timestamp variation. It assigns entropy level based on linguistically defined fuzzy rules which are fused with hardware-generated randomness and then securely sealed using a Trusted Platform Module (TPM). The sealed key is incorporated in an AES-GCM encryption scheme to ensure both confidentiality and integrity of the data. This system introduces a scalable solution for adaptive encryption in high-assurance computing, zero-trust environments, and cloud-based infrastructure.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8e\u6a21\u7cca\u903b\u8f91\u7684\u52a0\u5bc6\u6846\u67b6\uff0c\u901a\u8fc7\u7cfb\u7edf\u71b5\u548c\u786c\u4ef6\u4fe1\u4efb\u52a8\u6001\u751f\u6210\u5b9e\u65f6\u52a0\u5bc6\u5bc6\u94a5\uff0c\u7ed3\u5408TPM\u548cAES-GCM\u63d0\u4f9b\u81ea\u9002\u5e94\u52a0\u5bc6\u65b9\u6848\u3002", "motivation": "\u9759\u6001\u5bc6\u94a5\u52a0\u5bc6\u673a\u5236\u56e0\u5176\u786e\u5b9a\u6027\u548c\u975e\u81ea\u9002\u5e94\u7279\u6027\u5bb9\u6613\u53d7\u5230\u5bf9\u6297\u653b\u51fb\uff0c\u9762\u4e34\u66b4\u529b\u7834\u89e3\u3001\u5bc6\u94a5\u6cc4\u9732\u548c\u672a\u6388\u6743\u8bbf\u95ee\u7b49\u5e38\u89c1\u7f51\u7edc\u5b89\u5168\u5a01\u80c1\u3002", "method": "\u4f7f\u7528\u6a21\u7cca\u63a8\u7406\u7cfb\u7edf\u8bc4\u4f30CPU\u5229\u7528\u7387\u3001\u8fdb\u7a0b\u6570\u548c\u65f6\u95f4\u6233\u53d8\u5316\u7b49\u7cfb\u7edf\u53c2\u6570\uff0c\u57fa\u4e8e\u6a21\u7cca\u89c4\u5219\u5206\u914d\u71b5\u7ea7\u522b\uff0c\u4e0e\u786c\u4ef6\u751f\u6210\u7684\u968f\u673a\u6027\u878d\u5408\uff0c\u901a\u8fc7\u53ef\u4fe1\u5e73\u53f0\u6a21\u5757\u5b89\u5168\u5bc6\u5c01\u5bc6\u94a5\uff0c\u5e76\u96c6\u6210\u5230AES-GCM\u52a0\u5bc6\u65b9\u6848\u4e2d\u3002", "result": "\u5f00\u53d1\u4e86\u4e00\u4e2a\u53ef\u6269\u5c55\u7684\u81ea\u9002\u5e94\u52a0\u5bc6\u89e3\u51b3\u65b9\u6848\uff0c\u9002\u7528\u4e8e\u9ad8\u4fdd\u8bc1\u8ba1\u7b97\u3001\u96f6\u4fe1\u4efb\u73af\u5883\u548c\u4e91\u57fa\u7840\u8bbe\u65bd\u3002", "conclusion": "\u8be5\u7814\u7a76\u63d0\u4f9b\u4e86\u4e00\u79cd\u52a8\u6001\u3001\u81ea\u9002\u5e94\u7684\u52a0\u5bc6\u65b9\u6cd5\uff0c\u80fd\u591f\u6709\u6548\u5e94\u5bf9\u4f20\u7edf\u9759\u6001\u5bc6\u94a5\u52a0\u5bc6\u7684\u8106\u5f31\u6027\uff0c\u589e\u5f3a\u7cfb\u7edf\u5b89\u5168\u6027\u3002"}}
{"id": "2511.14140", "categories": ["cs.CR"], "pdf": "https://arxiv.org/pdf/2511.14140", "abs": "https://arxiv.org/abs/2511.14140", "authors": ["Hajun Kim", "Hyunsik Na", "Daeseon Choi"], "title": "Beyond Fixed and Dynamic Prompts: Embedded Jailbreak Templates for Advancing LLM Security", "comment": null, "summary": "As the use of large language models (LLMs) continues to expand, ensuring their safety and robustness has become a critical challenge. In particular, jailbreak attacks that bypass built-in safety mechanisms are increasingly recognized as a tangible threat across industries, driving the need for diverse templates to support red-teaming efforts and strengthen defensive techniques. However, current approaches predominantly rely on two limited strategies: (i) substituting harmful queries into fixed templates, and (ii) having the LLM generate entire templates, which often compromises intent clarity and reproductibility. To address this gap, this paper introduces the Embedded Jailbreak Template, which preserves the structure of existing templates while naturally embedding harmful queries within their context. We further propose a progressive prompt-engineering methodology to ensure template quality and consistency, alongside standardized protocols for generation and evaluation. Together, these contributions provide a benchmark that more accurately reflects real-world usage scenarios and harmful intent, facilitating its application in red-teaming and policy regression testing.", "AI": {"tldr": "\u63d0\u51fa\u5d4c\u5165\u5f0f\u8d8a\u72f1\u6a21\u677f\uff0c\u5728\u73b0\u6709\u6a21\u677f\u7ed3\u6784\u4e2d\u81ea\u7136\u5d4c\u5165\u6709\u5bb3\u67e5\u8be2\uff0c\u901a\u8fc7\u6e10\u8fdb\u5f0f\u63d0\u793a\u5de5\u7a0b\u786e\u4fdd\u6a21\u677f\u8d28\u91cf\u548c\u4e00\u81f4\u6027\uff0c\u4e3a\u7ea2\u961f\u6d4b\u8bd5\u548c\u653f\u7b56\u56de\u5f52\u6d4b\u8bd5\u63d0\u4f9b\u66f4\u51c6\u786e\u7684\u57fa\u51c6\u3002", "motivation": "\u968f\u7740\u5927\u578b\u8bed\u8a00\u6a21\u578b\u7684\u5e7f\u6cdb\u5e94\u7528\uff0c\u786e\u4fdd\u5176\u5b89\u5168\u6027\u548c\u9c81\u68d2\u6027\u6210\u4e3a\u5173\u952e\u6311\u6218\u3002\u73b0\u6709\u7684\u8d8a\u72f1\u653b\u51fb\u65b9\u6cd5\u4e3b\u8981\u4f9d\u8d56\u4e24\u79cd\u6709\u9650\u7b56\u7565\uff1a\u5c06\u6709\u5bb3\u67e5\u8be2\u66ff\u6362\u5230\u56fa\u5b9a\u6a21\u677f\u4e2d\uff0c\u6216\u8ba9LLM\u751f\u6210\u6574\u4e2a\u6a21\u677f\uff0c\u4f46\u8fd9\u4f1a\u635f\u5bb3\u610f\u56fe\u6e05\u6670\u5ea6\u548c\u53ef\u590d\u73b0\u6027\u3002", "method": "\u5f15\u5165\u5d4c\u5165\u5f0f\u8d8a\u72f1\u6a21\u677f\uff0c\u4fdd\u7559\u73b0\u6709\u6a21\u677f\u7ed3\u6784\u7684\u540c\u65f6\u5728\u4e0a\u4e0b\u6587\u4e2d\u81ea\u7136\u5d4c\u5165\u6709\u5bb3\u67e5\u8be2\uff1b\u63d0\u51fa\u6e10\u8fdb\u5f0f\u63d0\u793a\u5de5\u7a0b\u65b9\u6cd5\u786e\u4fdd\u6a21\u677f\u8d28\u91cf\u548c\u4e00\u81f4\u6027\uff1b\u5236\u5b9a\u6807\u51c6\u5316\u7684\u751f\u6210\u548c\u8bc4\u4f30\u534f\u8bae\u3002", "result": "\u63d0\u4f9b\u4e86\u4e00\u4e2a\u66f4\u51c6\u786e\u53cd\u6620\u771f\u5b9e\u4e16\u754c\u4f7f\u7528\u573a\u666f\u548c\u6709\u5bb3\u610f\u56fe\u7684\u57fa\u51c6\uff0c\u4fbf\u4e8e\u5728\u7ea2\u961f\u6d4b\u8bd5\u548c\u653f\u7b56\u56de\u5f52\u6d4b\u8bd5\u4e2d\u5e94\u7528\u3002", "conclusion": "\u5d4c\u5165\u5f0f\u8d8a\u72f1\u6a21\u677f\u548c\u6e10\u8fdb\u5f0f\u63d0\u793a\u5de5\u7a0b\u65b9\u6cd5\u6709\u6548\u89e3\u51b3\u4e86\u73b0\u6709\u8d8a\u72f1\u653b\u51fb\u65b9\u6cd5\u7684\u5c40\u9650\u6027\uff0c\u4e3aLLM\u5b89\u5168\u6d4b\u8bd5\u63d0\u4f9b\u4e86\u66f4\u53ef\u9760\u7684\u57fa\u51c6\u5de5\u5177\u3002"}}
{"id": "2511.14301", "categories": ["cs.CR", "cs.CL", "cs.LG"], "pdf": "https://arxiv.org/pdf/2511.14301", "abs": "https://arxiv.org/abs/2511.14301", "authors": ["Eric Xue", "Ruiyi Zhang", "Zijun Zhang", "Pengtao Xie"], "title": "Steganographic Backdoor Attacks in NLP: Ultra-Low Poisoning and Defense Evasion", "comment": null, "summary": "Transformer models are foundational to natural language processing (NLP) applications, yet remain vulnerable to backdoor attacks introduced through poisoned data, which implant hidden behaviors during training. To strengthen the ability to prevent such compromises, recent research has focused on designing increasingly stealthy attacks to stress-test existing defenses, pairing backdoor behaviors with stylized artifact or token-level perturbation triggers. However, this trend diverts attention from the harder and more realistic case: making the model respond to semantic triggers such as specific names or entities, where a successful backdoor could manipulate outputs tied to real people or events in deployed systems. Motivated by this growing disconnect, we introduce SteganoBackdoor, bringing stealth techniques back into line with practical threat models. Leveraging innocuous properties from natural-language steganography, SteganoBackdoor applies a gradient-guided data optimization process to transform semantic trigger seeds into steganographic carriers that embed a high backdoor payload, remain fluent, and exhibit no representational resemblance to the trigger. Across diverse experimental settings, SteganoBackdoor achieves over 99% attack success at an order-of-magnitude lower data-poisoning rate than prior approaches while maintaining unparalleled evasion against a comprehensive suite of data-level defenses. By revealing this practical and covert attack, SteganoBackdoor highlights an urgent blind spot in current defenses and demands immediate attention to adversarial data defenses and real-world threat modeling.", "AI": {"tldr": "SteganoBackdoor\u662f\u4e00\u79cd\u65b0\u578b\u540e\u95e8\u653b\u51fb\u65b9\u6cd5\uff0c\u5229\u7528\u81ea\u7136\u8bed\u8a00\u9690\u5199\u672f\u5c06\u8bed\u4e49\u89e6\u53d1\u5668\u8f6c\u5316\u4e3a\u9690\u5199\u8f7d\u4f53\uff0c\u5728\u6781\u4f4e\u6570\u636e\u6295\u6bd2\u7387\u4e0b\u5b9e\u73b0\u9ad8\u653b\u51fb\u6210\u529f\u7387\uff0c\u5e76\u80fd\u6709\u6548\u89c4\u907f\u73b0\u6709\u9632\u5fa1\u673a\u5236\u3002", "motivation": "\u73b0\u6709\u540e\u95e8\u653b\u51fb\u7814\u7a76\u8fc7\u4e8e\u5173\u6ce8\u98ce\u683c\u5316\u6216\u4ee4\u724c\u7ea7\u6270\u52a8\u89e6\u53d1\u5668\uff0c\u5ffd\u89c6\u4e86\u66f4\u73b0\u5b9e\u548c\u5371\u9669\u7684\u8bed\u4e49\u89e6\u53d1\u5668\uff08\u5982\u7279\u5b9a\u540d\u79f0\u6216\u5b9e\u4f53\uff09\uff0c\u8fd9\u79cd\u653b\u51fb\u5728\u5b9e\u9645\u90e8\u7f72\u7cfb\u7edf\u4e2d\u53ef\u80fd\u64cd\u7eb5\u4e0e\u771f\u5b9e\u4eba\u7269\u6216\u4e8b\u4ef6\u76f8\u5173\u7684\u8f93\u51fa\u3002", "method": "\u5229\u7528\u81ea\u7136\u8bed\u8a00\u9690\u5199\u672f\u7684\u65e0\u5bb3\u7279\u6027\uff0c\u901a\u8fc7\u68af\u5ea6\u5f15\u5bfc\u7684\u6570\u636e\u4f18\u5316\u8fc7\u7a0b\u5c06\u8bed\u4e49\u89e6\u53d1\u5668\u79cd\u5b50\u8f6c\u5316\u4e3a\u9690\u5199\u8f7d\u4f53\uff0c\u8fd9\u4e9b\u8f7d\u4f53\u5d4c\u5165\u9ad8\u540e\u95e8\u8f7d\u8377\u3001\u4fdd\u6301\u6d41\u7545\u6027\uff0c\u4e14\u4e0e\u89e6\u53d1\u5668\u6ca1\u6709\u8868\u5f81\u76f8\u4f3c\u6027\u3002", "result": "\u5728\u591a\u6837\u5316\u5b9e\u9a8c\u8bbe\u7f6e\u4e2d\uff0cSteganoBackdoor\u4ee5\u6bd4\u5148\u524d\u65b9\u6cd5\u4f4e\u4e00\u4e2a\u6570\u91cf\u7ea7\u7684\u6570\u636e\u6295\u6bd2\u7387\u5b9e\u73b0\u4e86\u8d85\u8fc799%\u7684\u653b\u51fb\u6210\u529f\u7387\uff0c\u540c\u65f6\u5728\u4e00\u6574\u5957\u6570\u636e\u7ea7\u9632\u5fa1\u63aa\u65bd\u4e2d\u4fdd\u6301\u65e0\u4e0e\u4f26\u6bd4\u7684\u89c4\u907f\u80fd\u529b\u3002", "conclusion": "SteganoBackdoor\u63ed\u793a\u4e86\u5f53\u524d\u9632\u5fa1\u673a\u5236\u4e2d\u7684\u7d27\u6025\u76f2\u70b9\uff0c\u8feb\u5207\u9700\u8981\u5173\u6ce8\u5bf9\u6297\u6027\u6570\u636e\u9632\u5fa1\u548c\u73b0\u5b9e\u4e16\u754c\u5a01\u80c1\u5efa\u6a21\u3002"}}
{"id": "2511.14422", "categories": ["cs.CR", "cs.AI", "cs.LG"], "pdf": "https://arxiv.org/pdf/2511.14422", "abs": "https://arxiv.org/abs/2511.14422", "authors": ["Zhengchunmin Dai", "Jiaxiong Tang", "Peng Sun", "Honglong Chen", "Liantao Wu"], "title": "Sigil: Server-Enforced Watermarking in U-Shaped Split Federated Learning via Gradient Injection", "comment": "18 pages,8 figures", "summary": "In decentralized machine learning paradigms such as Split Federated Learning (SFL) and its variant U-shaped SFL, the server's capabilities are severely restricted. Although this enhances client-side privacy, it also leaves the server highly vulnerable to model theft by malicious clients. Ensuring intellectual property protection for such capability-limited servers presents a dual challenge: watermarking schemes that depend on client cooperation are unreliable in adversarial settings, whereas traditional server-side watermarking schemes are technically infeasible because the server lacks access to critical elements such as model parameters or labels.\n  To address this challenge, this paper proposes Sigil, a mandatory watermarking framework designed specifically for capability-limited servers. Sigil defines the watermark as a statistical constraint on the server-visible activation space and embeds the watermark into the client model via gradient injection, without requiring any knowledge of the data. Besides, we design an adaptive gradient clipping mechanism to ensure that our watermarking process remains both mandatory and stealthy, effectively countering existing gradient anomaly detection methods and a specifically designed adaptive subspace removal attack. Extensive experiments on multiple datasets and models demonstrate Sigil's fidelity, robustness, and stealthiness.", "AI": {"tldr": "Sigil\u662f\u4e00\u4e2a\u4e3a\u80fd\u529b\u53d7\u9650\u670d\u52a1\u5668\u8bbe\u8ba1\u7684\u5f3a\u5236\u6c34\u5370\u6846\u67b6\uff0c\u901a\u8fc7\u5728\u670d\u52a1\u5668\u53ef\u89c1\u7684\u6fc0\u6d3b\u7a7a\u95f4\u5b9a\u4e49\u7edf\u8ba1\u7ea6\u675f\u4f5c\u4e3a\u6c34\u5370\uff0c\u5e76\u901a\u8fc7\u68af\u5ea6\u6ce8\u5165\u5d4c\u5165\u5230\u5ba2\u6237\u7aef\u6a21\u578b\u4e2d\uff0c\u65e0\u9700\u6570\u636e\u77e5\u8bc6\u3002", "motivation": "\u5728Split Federated Learning\u7b49\u53bb\u4e2d\u5fc3\u5316\u673a\u5668\u5b66\u4e60\u8303\u5f0f\u4e2d\uff0c\u670d\u52a1\u5668\u80fd\u529b\u53d7\u9650\u867d\u7136\u589e\u5f3a\u4e86\u5ba2\u6237\u7aef\u9690\u79c1\uff0c\u4f46\u4e5f\u4f7f\u670d\u52a1\u5668\u5bb9\u6613\u53d7\u5230\u6076\u610f\u5ba2\u6237\u7aef\u7684\u6a21\u578b\u7a83\u53d6\uff0c\u9700\u8981\u4fdd\u62a4\u670d\u52a1\u5668\u7684\u77e5\u8bc6\u4ea7\u6743\u3002", "method": "\u5c06\u6c34\u5370\u5b9a\u4e49\u4e3a\u670d\u52a1\u5668\u53ef\u89c1\u6fc0\u6d3b\u7a7a\u95f4\u7684\u7edf\u8ba1\u7ea6\u675f\uff0c\u901a\u8fc7\u68af\u5ea6\u6ce8\u5165\u5c06\u6c34\u5370\u5d4c\u5165\u5ba2\u6237\u7aef\u6a21\u578b\uff0c\u8bbe\u8ba1\u4e86\u81ea\u9002\u5e94\u68af\u5ea6\u88c1\u526a\u673a\u5236\u786e\u4fdd\u6c34\u5370\u8fc7\u7a0b\u7684\u5f3a\u5236\u6027\u548c\u9690\u853d\u6027\u3002", "result": "\u5728\u591a\u4e2a\u6570\u636e\u96c6\u548c\u6a21\u578b\u4e0a\u7684\u5e7f\u6cdb\u5b9e\u9a8c\u8bc1\u660e\u4e86Sigil\u7684\u4fdd\u771f\u5ea6\u3001\u9c81\u68d2\u6027\u548c\u9690\u853d\u6027\u3002", "conclusion": "Sigil\u6846\u67b6\u6709\u6548\u89e3\u51b3\u4e86\u80fd\u529b\u53d7\u9650\u670d\u52a1\u5668\u7684\u77e5\u8bc6\u4ea7\u6743\u4fdd\u62a4\u95ee\u9898\uff0c\u80fd\u591f\u5bf9\u6297\u73b0\u6709\u7684\u68af\u5ea6\u5f02\u5e38\u68c0\u6d4b\u65b9\u6cd5\u548c\u4e13\u95e8\u8bbe\u8ba1\u7684\u81ea\u9002\u5e94\u5b50\u7a7a\u95f4\u79fb\u9664\u653b\u51fb\u3002"}}
{"id": "2511.14611", "categories": ["cs.CR", "cs.HC"], "pdf": "https://arxiv.org/pdf/2511.14611", "abs": "https://arxiv.org/abs/2511.14611", "authors": ["Charles Cheng Ji", "Brandon Kong"], "title": "SecureSign: Bridging Security and UX in Mobile Web3 through Emulated EIP-6963 Sandboxing", "comment": "19 pages, 11 figures", "summary": "Mobile Web3 faces catastrophic retention (< 5%) yielding effective acquisition costs of \\$500 - \\$1,000 per retained user. Existing solutions force an impossible tradeoff: embedded wallets achieve moderate usability but suffer inherent click-jacking vulnerabilities; app wallets maintain security at the cost of 2 - 3% retention due to download friction and context-switching penalties. We present SecureSign, a PWA-based architecture that adapts desktop browser extension security to mobile via EIP-6963 provider sandboxing. SecureSign isolates dApp execution in iframes within a trusted parent application, achieving click-jacking immunity and transaction integrity while enabling native mobile capabilities (push notifications, home screen installation, zero context-switching). Our drop-in SDK requires no codebase changes for existing Web3 applications. Threat model analysis demonstrates immunity to click-jacking, overlay, and skimming attacks while maintaining wallet interoperability across dApps.", "AI": {"tldr": "SecureSign\u662f\u4e00\u4e2aPWA\u67b6\u6784\uff0c\u901a\u8fc7EIP-6963\u63d0\u4f9b\u5546\u6c99\u76d2\u5c06\u684c\u9762\u6d4f\u89c8\u5668\u6269\u5c55\u5b89\u5168\u6027\u9002\u914d\u5230\u79fb\u52a8\u7aef\uff0c\u89e3\u51b3\u4e86\u79fb\u52a8Web3\u5e94\u7528\u7684\u9ad8\u6d41\u5931\u7387\u548c\u5b89\u5168\u6f0f\u6d1e\u95ee\u9898\u3002", "motivation": "\u79fb\u52a8Web3\u9762\u4e34\u707e\u96be\u6027\u7684\u7528\u6237\u7559\u5b58\u7387\uff08<5%\uff09\uff0c\u5bfc\u81f4\u6bcf\u4e2a\u7559\u5b58\u7528\u6237\u7684\u6709\u6548\u83b7\u53d6\u6210\u672c\u9ad8\u8fbe500-1000\u7f8e\u5143\u3002\u73b0\u6709\u89e3\u51b3\u65b9\u6848\u5b58\u5728\u4e24\u96be\u9009\u62e9\uff1a\u5d4c\u5165\u5f0f\u94b1\u5305\u6709\u4e2d\u7b49\u53ef\u7528\u6027\u4f46\u5b58\u5728\u56fa\u6709\u7684\u70b9\u51fb\u52ab\u6301\u6f0f\u6d1e\uff1b\u5e94\u7528\u94b1\u5305\u4fdd\u6301\u5b89\u5168\u6027\u4f46\u4f1a\u56e0\u4e0b\u8f7d\u6469\u64e6\u548c\u4e0a\u4e0b\u6587\u5207\u6362\u60e9\u7f5a\u5bfc\u81f42-3%\u7684\u7559\u5b58\u635f\u5931\u3002", "method": "SecureSign\u91c7\u7528PWA\u67b6\u6784\uff0c\u901a\u8fc7EIP-6963\u63d0\u4f9b\u5546\u6c99\u76d2\u5c06dApp\u6267\u884c\u9694\u79bb\u5728\u53ef\u4fe1\u7236\u5e94\u7528\u7a0b\u5e8f\u7684iframe\u4e2d\uff0c\u5b9e\u73b0\u70b9\u51fb\u52ab\u6301\u514d\u75ab\u548c\u4ea4\u6613\u5b8c\u6574\u6027\uff0c\u540c\u65f6\u652f\u6301\u539f\u751f\u79fb\u52a8\u529f\u80fd\uff08\u63a8\u9001\u901a\u77e5\u3001\u4e3b\u5c4f\u5e55\u5b89\u88c5\u3001\u96f6\u4e0a\u4e0b\u6587\u5207\u6362\uff09\u3002", "result": "\u5a01\u80c1\u6a21\u578b\u5206\u6790\u8868\u660e\uff0cSecureSign\u5bf9\u70b9\u51fb\u52ab\u6301\u3001\u8986\u76d6\u548c\u7a83\u53d6\u653b\u51fb\u5177\u6709\u514d\u75ab\u529b\uff0c\u540c\u65f6\u4fdd\u6301\u8de8dApp\u7684\u94b1\u5305\u4e92\u64cd\u4f5c\u6027\u3002", "conclusion": "SecureSign\u63d0\u4f9b\u4e86\u4e00\u4e2a\u65e0\u9700\u73b0\u6709Web3\u5e94\u7528\u7a0b\u5e8f\u4ee3\u7801\u5e93\u66f4\u6539\u7684\u5373\u63d2\u5373\u7528SDK\uff0c\u5728\u4fdd\u6301\u5b89\u5168\u6027\u7684\u540c\u65f6\u89e3\u51b3\u4e86\u79fb\u52a8Web3\u5e94\u7528\u7684\u7528\u6237\u7559\u5b58\u95ee\u9898\u3002"}}
{"id": "2511.14717", "categories": ["cs.CR"], "pdf": "https://arxiv.org/pdf/2511.14717", "abs": "https://arxiv.org/abs/2511.14717", "authors": ["Benedikt Peterseim", "Milan Lopuha\u00e4-Zwakenberg"], "title": "A Unified Compositional View of Attack Tree Metrics", "comment": null, "summary": "Attack trees (ATs) are popular graphical models for reasoning about the security of complex systems, allowing for the quantification of risk through so-called AT metrics. A large variety of different such AT metrics have been proposed, and despite their wide-spread practical use, no systematic treatment of attack tree metrics so far is fully satisfactory. Existing approaches either fail to include important metrics, or they are too general to provide a useful systematic way for defining concrete AT metrics, giving only an abstract characterisation of their behaviour. We solve this problem by developing a compositional theory of ATs and their functorial semantics based on gs-monoidal categories. Viewing attack trees as string diagrams, we show that components of ATs form a channel category, a particular type of gs-monoidal category. AT metrics then correspond to functors of channel categories. This characterisation is both general enough to include all common AT metrics, and concrete enough to define AT metrics by their logical structure.", "AI": {"tldr": "\u672c\u6587\u901a\u8fc7\u57fa\u4e8egs-\u5e7a\u534a\u8303\u7574\u7684\u7ec4\u5408\u7406\u8bba\uff0c\u4e3a\u653b\u51fb\u6811\u53ca\u5176\u51fd\u5b50\u8bed\u4e49\u63d0\u4f9b\u4e86\u7cfb\u7edf\u5316\u7684\u5ea6\u91cf\u5b9a\u4e49\u6846\u67b6\uff0c\u89e3\u51b3\u4e86\u73b0\u6709\u65b9\u6cd5\u8981\u4e48\u4e0d\u591f\u5168\u9762\u8981\u4e48\u8fc7\u4e8e\u62bd\u8c61\u7684\u95ee\u9898\u3002", "motivation": "\u653b\u51fb\u6811\u662f\u590d\u6742\u7cfb\u7edf\u5b89\u5168\u63a8\u7406\u7684\u6d41\u884c\u56fe\u5f62\u6a21\u578b\uff0c\u4f46\u73b0\u6709\u7684\u653b\u51fb\u6811\u5ea6\u91cf\u5904\u7406\u65b9\u6cd5\u8981\u4e48\u65e0\u6cd5\u6db5\u76d6\u91cd\u8981\u5ea6\u91cf\uff0c\u8981\u4e48\u8fc7\u4e8e\u62bd\u8c61\u800c\u65e0\u6cd5\u63d0\u4f9b\u5b9a\u4e49\u5177\u4f53\u5ea6\u91cf\u7684\u6709\u7528\u7cfb\u7edf\u65b9\u6cd5\u3002", "method": "\u5c06\u653b\u51fb\u6811\u89c6\u4e3a\u5b57\u7b26\u4e32\u56fe\uff0c\u5c55\u793a\u653b\u51fb\u6811\u7ec4\u4ef6\u5f62\u6210\u901a\u9053\u8303\u7574\uff08\u4e00\u79cd\u7279\u6b8a\u7684gs-\u5e7a\u534a\u8303\u7574\uff09\uff0c\u653b\u51fb\u6811\u5ea6\u91cf\u5bf9\u5e94\u901a\u9053\u8303\u7574\u7684\u51fd\u5b50\u3002", "result": "\u8be5\u7279\u5f81\u5316\u65b9\u6cd5\u65e2\u8db3\u591f\u901a\u7528\u4ee5\u5305\u542b\u6240\u6709\u5e38\u89c1\u7684\u653b\u51fb\u6811\u5ea6\u91cf\uff0c\u53c8\u8db3\u591f\u5177\u4f53\u4ee5\u901a\u8fc7\u903b\u8f91\u7ed3\u6784\u5b9a\u4e49\u653b\u51fb\u6811\u5ea6\u91cf\u3002", "conclusion": "\u57fa\u4e8egs-\u5e7a\u534a\u8303\u7574\u7684\u7ec4\u5408\u7406\u8bba\u4e3a\u653b\u51fb\u6811\u5ea6\u91cf\u63d0\u4f9b\u4e86\u7cfb\u7edf\u5316\u7684\u5b9a\u4e49\u6846\u67b6\uff0c\u89e3\u51b3\u4e86\u73b0\u6709\u65b9\u6cd5\u7684\u5c40\u9650\u6027\u3002"}}
