<div id=toc></div>

# Table of Contents

- [cs.CR](#cs.CR) [Total: 32]


<div id='cs.CR'></div>

# cs.CR [[Back]](#toc)

### [1] [Aplicacion de analitica de datos para la deteccion de anomalias y fortalecimiento de la seguridad en la red WiFi del campus universitario de la Universidad Nacional del Altiplano](https://arxiv.org/abs/2601.00798)
*Adiv Brander Cari Quispe*

Main category: cs.CR

TL;DR: 该研究通过数据分析方法（描述性、预测性、规范性分析）加强秘鲁普诺高原国立大学Wi-Fi网络安全，解决QR码访问系统缺乏个体认证、用户可追溯性和访问控制的问题。


<details>
  <summary>Details</summary>
Motivation: 普诺高原国立大学使用QR码访问Wi-Fi网络存在安全漏洞：缺乏个体认证、用户不可追溯、访问控制不足，需要加强无线网络安全。

Method: 收集并处理无线控制器日志中的用户、设备和流量数据，运用统计模型和机器学习算法分析行为模式、检测异常，采用描述性、预测性和规范性数据分析方法。

Result: 发现10:00-14:00为关键使用高峰，识别出重复设备和异常流量峰值等异常行为，建立了动态警报阈值，并提出带宽管理和认证改进建议。

Conclusion: 将高级分析整合到大学网络管理中不仅能识别漏洞、优化Wi-Fi性能，还能推动建设符合现代网络安全标准的智能、主动式基础设施。

Abstract: In today's university environment, wireless connectivity is an essential resource for academic, administrative, and research activities. However, at the National University of the Altiplano of Puno (UNAP), the use of a QR code access system on the institutional Wi-Fi network has generated vulnerabilities related to the lack of individual authentication, user traceability, and access control. Given this situation, this study aims to strengthen the security of the university's wireless network through the application of data analytics, employing descriptive, predictive, and prescriptive approaches to the logs generated by the wireless controller (WLC). The methodology consisted of collecting and processing connection data from users, devices, and daily traffic, analyzing behavioral patterns, and detecting anomalies based on statistical models and machine learning algorithms. The results revealed critical usage peaks between 10:00 and 14:00, as well as anomalous behavior associated with recurring devices and irregular traffic spikes. This allowed for the establishment of dynamic alert thresholds and recommendations for improvements in bandwidth management and authentication. Furthermore, the conclusion states that integrating advanced analytics into the management of university networks not only identifies vulnerabilities and optimizes WiFi service performance, but also advances towards an intelligent, proactive infrastructure aligned with modern institutional cybersecurity standards.

</details>


### [2] [The Silicon Psyche: Anthropomorphic Vulnerabilities in Large Language Models](https://arxiv.org/abs/2601.00867)
*Giuseppe Canale,Kashyap Thimmaraju*

Main category: cs.CR

TL;DR: LLMs继承了人类心理架构的脆弱性，对权威操纵、时间压力等社会工程攻击高度敏感，需要建立"心理防火墙"来防护。


<details>
  <summary>Details</summary>
Motivation: 当前对抗性测试主要关注技术攻击向量（提示注入、越狱等），但忽略了LLMs从人类文本中继承的心理架构脆弱性，这种认知不完整可能导致灾难性后果。

Method: 提出合成心理评估协议（SPAP），将网络安全心理学框架（CPF）的100个心理脆弱性指标转化为针对LLM决策的对抗性场景，并在七大主流LLM家族中进行初步测试。

Result: LLMs对传统越狱攻击表现出强大防御，但对权威梯度操纵、时间压力利用和收敛状态攻击等人类认知失败模式表现出严重脆弱性，揭示了"拟人化脆弱性继承"现象。

Conclusion: 安全社区需要紧急开发"心理防火墙"，借鉴网络安全心理学干预框架（CPIF），保护在对抗性环境中运行的AI智能体免受心理操纵攻击。

Abstract: Large Language Models (LLMs) are rapidly transitioning from conversational assistants to autonomous agents embedded in critical organizational functions, including Security Operations Centers (SOCs), financial systems, and infrastructure management. Current adversarial testing paradigms focus predominantly on technical attack vectors: prompt injection, jailbreaking, and data exfiltration. We argue this focus is catastrophically incomplete. LLMs, trained on vast corpora of human-generated text, have inherited not merely human knowledge but human \textit{psychological architecture} -- including the pre-cognitive vulnerabilities that render humans susceptible to social engineering, authority manipulation, and affective exploitation. This paper presents the first systematic application of the Cybersecurity Psychology Framework (\cpf{}), a 100-indicator taxonomy of human psychological vulnerabilities, to non-human cognitive agents. We introduce the \textbf{Synthetic Psychometric Assessment Protocol} (\sysname{}), a methodology for converting \cpf{} indicators into adversarial scenarios targeting LLM decision-making. Our preliminary hypothesis testing across seven major LLM families reveals a disturbing pattern: while models demonstrate robust defenses against traditional jailbreaks, they exhibit critical susceptibility to authority-gradient manipulation, temporal pressure exploitation, and convergent-state attacks that mirror human cognitive failure modes. We term this phenomenon \textbf{Anthropomorphic Vulnerability Inheritance} (AVI) and propose that the security community must urgently develop ``psychological firewalls'' -- intervention mechanisms adapted from the Cybersecurity Psychology Intervention Framework (\cpif{}) -- to protect AI agents operating in adversarial environments.

</details>


### [3] [Towards eco friendly cybersecurity: machine learning based anomaly detection with carbon and energy metrics](https://arxiv.org/abs/2601.00893)
*KC Aashish,Md Zakir Hossain Zamil,Md Shafiqul Islam Mridul,Lamia Akter,Farmina Sharmin,Eftekhar Hossain Ayon,Md Maruf Bin Reza,Ali Hassan,Abdur Rahim,Sirapa Malla*

Main category: cs.CR

TL;DR: 该研究提出了一个生态感知的异常检测框架，将机器学习网络监控与实时碳足迹和能耗追踪相结合，通过Eco Efficiency Index评估模型在性能和环境成本间的平衡，发现优化后的随机森林和逻辑回归模型在保持检测准确性的同时能减少40%以上的能耗。


<details>
  <summary>Details</summary>
Motivation: 人工智能的能源足迹已成为美国数据中心排放的重要组成部分，但网络安全研究很少考虑其环境成本。需要开发能够平衡检测性能和环境影响的方法。

Method: 使用包含2300个流级观测的公开Carbon Aware Cybersecurity Traffic Dataset，在受控的Colab环境中使用CodeCarbon工具包量化训练和推理阶段的功耗和CO2排放。构建Eco Efficiency Index（F1分数/千瓦时）来评估检测质量与环境影响的权衡。测试了逻辑回归、随机森林、支持向量机、隔离森林和XGBoost模型，并使用主成分分析降低计算负载。

Result: 优化后的随机森林和轻量级逻辑回归模型实现了最高的生态效率，与XGBoost相比减少了40%以上的能耗，同时保持了有竞争力的检测准确性。主成分分析进一步降低了计算负载，而召回率损失可忽略不计。

Conclusion: 将碳和能源指标整合到网络安全工作流程中，可以在不损害操作保护的情况下实现环境友好的机器学习。该框架为可持续、碳可追溯的网络安全提供了可复现的路径，符合美国绿色计算和联邦能源效率倡议。

Abstract: The rising energy footprint of artificial intelligence has become a measurable component of US data center emissions, yet cybersecurity research seldom considers its environmental cost. This study introduces an eco aware anomaly detection framework that unifies machine learning based network monitoring with real time carbon and energy tracking. Using the publicly available Carbon Aware Cybersecurity Traffic Dataset comprising 2300 flow level observations, we benchmark Logistic Regression, Random Forest, Support Vector Machine, Isolation Forest, and XGBoost models across energy, carbon, and performance dimensions. Each experiment is executed in a controlled Colab environment instrumented with the CodeCarbon toolkit to quantify power draw and equivalent CO2 output during both training and inference. We construct an Eco Efficiency Index that expresses F1 score per kilowatt hour to capture the trade off between detection quality and environmental impact. Results reveal that optimized Random Forest and lightweight Logistic Regression models achieve the highest eco efficiency, reducing energy consumption by more than forty percent compared to XGBoost while sustaining competitive detection accuracy. Principal Component Analysis further decreases computational load with negligible loss in recall. Collectively, these findings establish that integrating carbon and energy metrics into cybersecurity workflows enables environmentally responsible machine learning without compromising operational protection. The proposed framework offers a reproducible path toward sustainable carbon accountable cybersecurity aligned with emerging US green computing and federal energy efficiency initiatives.

</details>


### [4] [Noise-Aware and Dynamically Adaptive Federated Defense Framework for SAR Image Target Recognition](https://arxiv.org/abs/2601.00900)
*Yuchao Hou,Zixuan Zhang,Jie Wang,Wenke Huang,Lianhui Liang,Di Wu,Zhiquan Liu,Youliang Tian,Jianming Zhu,Jisheng Dang,Junhao Dong,Zhongliang Guo*

Main category: cs.CR

TL;DR: NADAFD是一个针对SAR图像目标识别的联邦学习防御框架，通过频域协作反演、噪声感知对抗训练和动态健康评估，有效抵御SAR特有的后门攻击和斑点噪声。


<details>
  <summary>Details</summary>
Motivation: SAR图像目标识别通常依赖集中式训练，存在隐私和安全问题。联邦学习虽然能保护数据隐私，但面临恶意客户端利用SAR乘性斑点噪声隐藏后门触发器的安全风险，严重威胁计算智能模型的鲁棒性。

Method: 提出NADAFD框架：1) 频域协作反演机制，通过跨客户端频谱不一致性检测隐藏的后门触发器；2) 噪声感知对抗训练策略，将Γ分布斑点特性嵌入掩码引导的对抗样本生成，增强对后门攻击和SAR斑点噪声的鲁棒性；3) 动态健康评估模块，跟踪客户端更新行为并自适应调整聚合权重。

Result: 在MSTAR和OpenSARShip数据集上的实验表明，NADAFD相比现有联邦后门防御方法，在干净测试样本上获得更高准确率，在触发输入上实现更低的后门攻击成功率。

Conclusion: NADAFD通过整合频域、空间域和客户端行为分析，有效应对SAR特有的后门威胁，为SAR图像目标识别的联邦学习提供了安全可靠的防御框架。

Abstract: As a critical application of computational intelligence in remote sensing, deep learning-based synthetic aperture radar (SAR) image target recognition facilitates intelligent perception but typically relies on centralized training, where multi-source SAR data are uploaded to a single server, raising privacy and security concerns. Federated learning (FL) provides an emerging computational intelligence paradigm for SAR image target recognition, enabling cross-site collaboration while preserving local data privacy. However, FL confronts critical security risks, where malicious clients can exploit SAR's multiplicative speckle noise to conceal backdoor triggers, severely challenging the robustness of the computational intelligence model. To address this challenge, we propose NADAFD, a noise-aware and dynamically adaptive federated defense framework that integrates frequency-domain, spatial-domain, and client-behavior analyses to counter SAR-specific backdoor threats. Specifically, we introduce a frequency-domain collaborative inversion mechanism to expose cross-client spectral inconsistencies indicative of hidden backdoor triggers. We further design a noise-aware adversarial training strategy that embeds $Γ$-distributed speckle characteristics into mask-guided adversarial sample generation to enhance robustness against both backdoor attacks and SAR speckle noise. In addition, we present a dynamic health assessment module that tracks client update behaviors across training rounds and adaptively adjusts aggregation weights to mitigate evolving malicious contributions. Experiments on MSTAR and OpenSARShip datasets demonstrate that NADAFD achieves higher accuracy on clean test samples and a lower backdoor attack success rate on triggered inputs than existing federated backdoor defenses for SAR target recognition.

</details>


### [5] [Security Hardening Using FABRIC: Implementing a Unified Compliance Aggregator for Linux Servers](https://arxiv.org/abs/2601.00909)
*Sheldon Paul,Izzat Alsmadi*

Main category: cs.CR

TL;DR: 提出一个统一框架，通过聚合异构安全审计工具来评估FABRIC测试平台上的Linux安全加固效果，使用Unified Compliance Aggregator将不同工具结果标准化并加权计算，提供更清晰可复现的安全态势评估。


<details>
  <summary>Details</summary>
Motivation: 现有Linux安全审计工具（如Lynis、OpenSCAP、AIDE）缺乏一致的评估标准和解释，难以系统评估安全加固效果，特别是在可编程测试平台环境中需要更清晰、可复现的安全态势评估方法。

Method: 在FABRIC测试平台部署三个Ubuntu 22.04节点（基线、部分加固、完全加固），使用Lynis、OpenSCAP和AIDE进行108次审计运行，开发Unified Compliance Aggregator解析工具输出、将分数标准化到0-100范围，通过加权指标和可定制规则引擎整合结果。

Result: 完全加固使OpenSCAP合规性从39.7提升到71.8，自定义规则合规性从39.3%提升到83.6%。UCA提供了比单独工具更清晰、可复现的安全态势评估，能够系统评估可编程测试平台环境中的加固效果。

Conclusion: UCA框架通过聚合异构安全审计工具并提供统一评估标准，显著改进了Linux安全加固效果的评估能力，为可编程测试平台环境中的系统安全评估提供了更清晰、可复现的方法。

Abstract: This paper presents a unified framework for evaluating Linux security hardening on the FABRIC testbed through aggregation of heterogeneous security auditing tools. We deploy three Ubuntu 22.04 nodes configured at baseline, partial, and full hardening levels, and evaluate them using Lynis, OpenSCAP, and AIDE across 108 audit runs. To address the lack of a consistent interpretation across tools, we implement a Unified Compliance Aggregator (UCA) that parses tool outputs, normalizes scores to a common 0--100 scale, and combines them into a weighted metric augmented by a customizable rule engine for organization-specific security policies. Experimental results show that full hardening increases OpenSCAP compliance from 39.7 to 71.8, while custom rule compliance improves from 39.3\% to 83.6\%. The results demonstrate that UCA provides a clearer and more reproducible assessment of security posture than individual tools alone, enabling systematic evaluation of hardening effectiveness in programmable testbed environments.

</details>


### [6] [Device-Native Autonomous Agents for Privacy-Preserving Negotiations](https://arxiv.org/abs/2601.00911)
*Joyjit Roy*

Main category: cs.CR

TL;DR: 提出一种设备原生AI代理系统，用于隐私保护的自动化谈判，在用户硬件上运行，结合零知识证明和蒸馏世界模型，实现87%成功率，延迟降低2.4倍。


<details>
  <summary>Details</summary>
Motivation: 当前保险和B2B商务中的自动化谈判系统面临隐私与便利的权衡，需要将敏感财务数据通过中心化服务器传输，增加了安全风险并降低了用户信任。

Method: 开发设备原生自主AI代理系统，完全在用户硬件上运行，集成零知识证明确保隐私，采用蒸馏世界模型支持设备端高级推理，包含六个技术组件的代理AI工作流。

Result: 在保险和B2B采购场景中评估，平均成功率87%，相比云端基准延迟提升2.4倍，零知识证明有效保护隐私，提供决策轨迹时用户信任度提高27%。

Conclusion: 该系统为隐私敏感金融领域中的可信自主代理奠定了基础，实现了隐私保护、高性能和用户信任的平衡。

Abstract: Automated negotiations in insurance and business-to-business (B2B) commerce encounter substantial challenges. Current systems force a trade-off between convenience and privacy by routing sensitive financial data through centralized servers, increasing security risks, and diminishing user trust. This study introduces a device-native autonomous Artificial Intelligence (AI) agent system for privacy-preserving negotiations. The proposed system operates exclusively on user hardware, enabling real-time bargaining while maintaining sensitive constraints locally. It integrates zero-knowledge proofs to ensure privacy and employs distilled world models to support advanced on-device reasoning. The architecture incorporates six technical components within an agentic AI workflow. Agents autonomously plan negotiation strategies, conduct secure multi-party bargaining, and generate cryptographic audit trails without exposing user data to external servers. The system is evaluated in insurance and B2B procurement scenarios across diverse device configurations. Results show an average success rate of 87%, a 2.4x latency improvement over cloud baselines, and strong privacy preservation through zero-knowledge proofs. User studies show 27% higher trust scores when decision trails are available. These findings establish a foundation for trustworthy autonomous agents in privacy-sensitive financial domains.

</details>


### [7] [Emoji-Based Jailbreaking of Large Language Models](https://arxiv.org/abs/2601.00936)
*M P V S Gopinadh,S Mahaboob Hussain*

Main category: cs.CR

TL;DR: 该研究评估了四种开源大语言模型对表情符号攻击的脆弱性，发现不同模型存在显著差异，其中Qwen 2 7B完全免疫，而Gemma 2 9B和Mistral 7B有10%的成功率。


<details>
  <summary>Details</summary>
Motivation: 大语言模型的安全对齐机制可能被对抗性提示工程绕过，特别是通过表情符号序列嵌入文本提示来触发有害输出。现有研究主要关注针对安全判断器或分类器的表情符号攻击，而本研究直接评估提示层面的漏洞。

Method: 在四种开源LLM（Mistral 7B、Qwen 2 7B、Gemma 2 9B、Llama 3 8B）上评估50个表情符号提示，使用越狱成功率、安全对齐遵守度和延迟作为指标，将响应分类为成功、部分成功和失败。

Result: 模型存在特定脆弱性：Gemma 2 9B和Mistral 7B表现出10%的成功率，Qwen 2 7B实现完全对齐（0%成功率）。卡方检验（χ²=32.94，p<0.001）确认模型间存在显著差异。

Conclusion: 研究揭示了安全机制的局限性，强调需要在提示层面的安全和对齐流程中系统性地处理表情符号表示，以增强LLM的鲁棒性。

Abstract: Large Language Models (LLMs) are integral to modern AI applications, but their safety alignment mechanisms can be bypassed through adversarial prompt engineering. This study investigates emoji-based jailbreaking, where emoji sequences are embedded in textual prompts to trigger harmful and unethical outputs from LLMs. We evaluated 50 emoji-based prompts on four open-source LLMs: Mistral 7B, Qwen 2 7B, Gemma 2 9B, and Llama 3 8B. Metrics included jailbreak success rate, safety alignment adherence, and latency, with responses categorized as successful, partial and failed. Results revealed model-specific vulnerabilities: Gemma 2 9B and Mistral 7B exhibited 10 % success rates, while Qwen 2 7B achieved full alignment (0% success). A chi-square test (chi^2 = 32.94, p < 0.001) confirmed significant inter-model differences. While prior works focused on emoji attacks targeting safety judges or classifiers, our empirical analysis examines direct prompt-level vulnerabilities in LLMs. The results reveal limitations in safety mechanisms and highlight the necessity for systematic handling of emoji-based representations in prompt-level safety and alignment pipelines.

</details>


### [8] [CuFuzz: Hardening CUDA Programs through Transformation and Fuzzing](https://arxiv.org/abs/2601.01048)
*Saurabh Singh,Ruobing Han,Jaewon Lee,Seonjin Na,Yonghae Kim,Taesoo Kim,Hyesoon Kim*

Main category: cs.CR

TL;DR: CuFuzz：首个支持CUDA模糊测试的编译器-运行时协同设计解决方案，通过将GPU程序转换为CPU程序，利用CPU内存错误检测器发现CUDA代码中的内存安全漏洞。


<details>
  <summary>Details</summary>
Motivation: GPU安全性和可靠性日益重要，但现有模糊测试工具主要针对CPU，缺乏对GPU程序的有效支持。CUDA缺乏内存安全性可能导致严重漏洞，而GPU架构差异和内置错误检测的缺失使得传统模糊测试方法难以适用。

Method: CuFuzz采用编译器-运行时协同设计，通过编译器IR级转换将GPU程序转换为CPU程序，从而能够利用CPU模糊测试工具和内存错误检测器（如Address Sanitizer）。引入两种针对GPU代码的优化：部分代表性执行（PREX）和访问索引保留剪枝（AXIPrune），显著提高模糊测试吞吐量。

Result: CuFuzz实现了显著的性能提升：PREX带来平均32倍吞吐量提升，AXIPrune在PREX优化基础上再提升33%。两者结合最高可达224.31倍加速。在实际模糊测试活动中，CuFuzz在广泛使用的基准测试中发现了122个安全漏洞。

Conclusion: CuFuzz填补了GPU安全研究的关键空白，首次将模糊测试支持引入CUDA，有效发现GPU程序中的内存安全漏洞，显著提升了GPU加速应用程序的安全性和可靠性。

Abstract: GPUs have gained significant popularity over the past decade, extending beyond their original role in graphics rendering. This evolution has brought GPU security and reliability to the forefront of concerns. Prior research has shown that CUDA's lack of memory safety can lead to serious vulnerabilities. While fuzzing is effective for finding such bugs on CPUs, equivalent tools for GPUs are lacking due to architectural differences and lack of built-in error detection. In this paper, we propose CuFuzz, a novel compiler-runtime co-design solution to extend state-of-the-art CPU fuzzing tools to GPU programs. CuFuzz transforms GPU programs into CPU programs using compiler IR-level transformations to enable effective fuzz testing. To the best of our knowledge, CuFuzz is the first mechanism to bring fuzzing support to CUDA, addressing a critical gap in GPU security research. By leveraging CPU memory error detectors such as Address Sanitizer, CuFuzz aims to uncover memory safety bugs and related correctness vulnerabilities in CUDA code, enhancing the security and reliability of GPU-accelerated applications. To ensure high fuzzing throughput, we introduce two compiler-runtime co-optimizations tailored for GPU code: Partial Representative Execution (PREX) and Access-Index Preserving Pruning (AXIPrune), achieving average throughput improvements of 32x with PREX and an additional 33% gain with AXIPrune on top of PREX-optimized code. Together, these optimizations can yield up to a 224.31x speedup. In our fuzzing campaigns, CuFuzz uncovered 122 security vulnerabilities in widely used benchmarks.

</details>


### [9] [Byzantine-Robust Federated Learning Framework with Post-Quantum Secure Aggregation for Real-Time Threat Intelligence Sharing in Critical IoT Infrastructure](https://arxiv.org/abs/2601.01053)
*Milad Rahmati,Nima Rahmati*

Main category: cs.CR

TL;DR: 提出结合后量子安全聚合的拜占庭鲁棒联邦学习框架，用于关键物联网基础设施的实时威胁检测，同时防御模型投毒攻击和量子计算威胁。


<details>
  <summary>Details</summary>
Motivation: 关键基础设施中物联网设备激增带来网络安全挑战，需要既保护数据隐私又对抗复杂攻击的协作威胁检测机制。传统联邦学习方法存在两个关键漏洞：易受拜占庭攻击（恶意参与者毒化模型更新）和无法抵御未来量子计算威胁（可能破坏密码聚合协议）。

Method: 提出新颖的拜占庭鲁棒联邦学习框架，集成后量子安全聚合。结合自适应加权聚合机制和基于格的密码协议，同时防御模型投毒攻击和量子对手。引入基于信誉的客户端选择算法，动态识别并排除拜占庭参与者，同时保持差分隐私保证。安全聚合协议使用CRYSTALS-Kyber进行密钥封装和同态加密，确保参数更新期间的机密性。

Result: 在工业物联网入侵检测数据集上的实验评估显示，该框架达到96.8%的威胁检测准确率，成功缓解高达40%的拜占庭攻击者，相比非安全联邦方法仅增加18%的计算开销。框架保持亚秒级聚合延迟，适合实时应用，并提供256位后量子安全级别。

Conclusion: 该框架为关键物联网基础设施提供了一种有效的实时威胁情报共享解决方案，同时解决了拜占庭攻击和量子计算威胁这两个关键安全问题，在安全性和性能之间取得了良好平衡。

Abstract: The proliferation of Internet of Things devices in critical infrastructure has created unprecedented cybersecurity challenges, necessitating collaborative threat detection mechanisms that preserve data privacy while maintaining robustness against sophisticated attacks. Traditional federated learning approaches for IoT security suffer from two critical vulnerabilities: susceptibility to Byzantine attacks where malicious participants poison model updates, and inadequacy against future quantum computing threats that can compromise cryptographic aggregation protocols. This paper presents a novel Byzantine-robust federated learning framework integrated with post-quantum secure aggregation specifically designed for real-time threat intelligence sharing across critical IoT infrastructure. The proposed framework combines a adaptive weighted aggregation mechanism with lattice-based cryptographic protocols to simultaneously defend against model poisoning attacks and quantum adversaries. We introduce a reputation-based client selection algorithm that dynamically identifies and excludes Byzantine participants while maintaining differential privacy guarantees. The secure aggregation protocol employs CRYSTALS-Kyber for key encapsulation and homomorphic encryption to ensure confidentiality during parameter updates. Experimental evaluation on industrial IoT intrusion detection datasets demonstrates that our framework achieves 96.8% threat detection accuracy while successfully mitigating up to 40% Byzantine attackers, with only 18% computational overhead compared to non-secure federated approaches. The framework maintains sub-second aggregation latency suitable for real-time applications and provides 256-bit post-quantum security level.

</details>


### [10] [Out-of-Band Power Side-Channel Detection for Semiconductor Supply Chain Integrity at Scale](https://arxiv.org/abs/2601.01054)
*Rajiv Thummala,Katherine Winton,Luke Flores,Elizabeth Redmond,Gregory Falco*

Main category: cs.CR

TL;DR: 提出一种基于功率侧信道测量和生成对抗网络（GAN）的非破坏性微控制器篡改检测方法，仅需良性样本训练，可作为半导体供应链安全的中级筛查手段。


<details>
  <summary>Details</summary>
Motivation: 微控制器的带外筛查是半导体供应链安全的主要缺口。现有高保证技术（如X射线、破坏性逆向工程）准确但缓慢昂贵，难以大规模检测硬件木马或固件篡改。需要自动化、快速、大规模的检测方法。

Method: 使用功率侧信道测量和生成对抗网络（GAN）进行非破坏性筛查。从ChipWhisperer收集差分功率分析（DPA）轨迹，仅用良性测量训练GAN学习正常功率行为。训练后的判别器作为单类异常检测器。

Result: 在多种篡改场景下报告检测性能，证明该方法可作为基本功能测试和高成本法证分析之间的中间筛查层级。评估了其在半导体供应链实践和政策中的适用性。

Conclusion: 提出的基于功率侧信道和生成建模的方法能够实现快速、大规模的微控制器篡改检测，无需可信硬件，可作为半导体供应链安全的中级保证机制。

Abstract: Out-of-band screening of microcontrollers is a major gap in semiconductor supply chain security. High-assurance techniques such as X-ray and destructive reverse engineering are accurate but slow and expensive, hindering comprehensive detection for hardware Trojans or firmware tampering. Consequently, there has been increased interest in applying machine learning techniques to automate forensic examination, enabling rapid, large-scale inspection of components without manual oversight. We introduce a non-destructive screening method that uses power side-channel measurements and generative modeling to detect tampering in commodity microcontrollers without trusted hardware. As a proof-of-concept, differential power analysis (DPA) traces are collected from the ChipWhisperer and a generative adversarial network (GAN) is trained only on benign measurements to learn nominal power behavior. The trained discriminator then serves as a one-class anomaly detector. We report detection performance on multiple tampering scenarios and discuss how this technique can serve as an intermediate screening tier between basic functional tests and high-cost forensic analysis. The proposed method is evaluated in the context of semiconductor supply chain practice and policy to assess its suitability as an intermediate assurance mechanism.

</details>


### [11] [Post-Quantum Cryptography for Intelligent Transportation Systems: An Implementation-Focused Review](https://arxiv.org/abs/2601.01068)
*Abdullah Al Mamun,Akid Abrar,Mizanur Rahman,M Sabbir Salek,Mashrur Chowdhury*

Main category: cs.CR

TL;DR: 该综述评估了智能交通系统(ITS)中后量子密码(PQC)的采用准备情况，识别了13个研究空白，并提出了分阶段部署路线图。


<details>
  <summary>Details</summary>
Motivation: 随着量子计算的发展，智能交通系统中的传统密码算法面临量子攻击威胁，而现有研究对PQC在ITS领域的实施方面关注不足。

Method: 通过评估车辆通信和安全标准对PQC的适配性，分析车内网络和V2X接口，并调查物理层漏洞（侧信道和故障注入攻击）。

Result: 识别了13个研究空白：标准未适配PQC、嵌入式实现限制、混合密码约束、互操作性和证书管理障碍、缺乏实际部署数据、物理攻击漏洞等。

Conclusion: 提出了未来研究方向：更新标准、优化低功耗设备PQC、增强互操作性框架、进行实际部署评估、防御AI辅助物理攻击，并制定了分阶段部署路线图。

Abstract: As quantum computing advances, the cryptographic algorithms that underpin confidentiality, integrity, and authentication in Intelligent Transportation Systems (ITS) face increasing vulnerability to quantum-enabled attacks. To address these risks, governments and industry stakeholders are turning toward post-quantum cryptography (PQC), a class of algorithms designed to resist adversaries equipped with quantum computing capabilities. However, existing studies provide limited insight into the implementation-focused aspects of PQC in the ITS domain. This review fills that gap by evaluating the readiness of vehicular communication and security standards for PQC adoption. It examines in-vehicle networks and vehicle-to-everything (V2X) interfaces, while also investigating vulnerabilities at the physical layer, primarily exposure to side-channel and fault injection attacks. The review identifies thirteen research gaps reflecting non-PQC-ready standards, constraints in embedded implementation and hybrid cryptography, interoperability and certificate-management barriers, lack of real-world PQC deployment data in ITS, and physical-attack vulnerabilities in PQC-enabled vehicular communication. Future research directions include updating vehicular communication and security standards, optimizing PQC for low-power devices, enhancing interoperability and certificate-management frameworks for PQC integration, conducting real-world evaluations of PQC-enabled communication and control functions across ITS deployments, and strengthening defenses against AI-assisted physical attacks. A phased roadmap is presented, aligning PQC deployment with regulatory, performance, and safety requirements, thereby guiding the secure evolution of ITS in the quantum computing era.

</details>


### [12] [NADD: Amplifying Noise for Effective Diffusion-based Adversarial Purification](https://arxiv.org/abs/2601.01109)
*David D. Nguyen,The-Anh Ta,Yansong Gao,Alsharif Abuadbba*

Main category: cs.CR

TL;DR: 提出一种改进的对抗净化方法，通过系统放大噪声和环形邻近校正来增强鲁棒性，同时大幅降低推理时间


<details>
  <summary>Details</summary>
Motivation: 现有基于扩散模型的对抗净化方法存在两个主要问题：1）推理速度过慢，不实用；2）由于使用低噪声水平，鲁棒性有限。需要在保持输入语义特征的同时提高鲁棒性和效率。

Method: 1）在正向扩散过程中引入高水平噪声，并提出环形邻近校正技术，逐步消除对抗扰动同时保持原始数据样本；2）提出新的随机采样方法，在反向扩散过程中引入额外噪声以稀释对抗扰动

Result: 在ImageNet上使用AutoAttack（ℓ∞=4/255）达到44.23%的鲁棒准确率，比之前最佳方法提升2.07%；推理时间降至1.08秒/样本，比现有最佳方法快47倍

Conclusion: 通过系统放大噪声和环形邻近校正，可以在不依赖梯度混淆的情况下显著提高对抗净化的鲁棒性和效率，使其更适合实际防御场景

Abstract: The strategy of combining diffusion-based generative models with classifiers continues to demonstrate state-of-the-art performance on adversarial robustness benchmarks.
  Known as adversarial purification, this exploits a diffusion model's capability of identifying high density regions in data distributions to purify adversarial perturbations from inputs.
  However, existing diffusion-based purification defenses are impractically slow and limited in robustness due to the low levels of noise used in the diffusion process.
  This low noise design aims to preserve the semantic features of the original input, thereby minimizing utility loss for benign inputs.
  Our findings indicate that systematic amplification of noise throughout the diffusion process improves the robustness of adversarial purification.
  However, this approach presents a key challenge, as noise levels cannot be arbitrarily increased without risking distortion of the input.
  To address this key problem, we introduce high levels of noise during the forward process and propose the ring proximity correction to gradually eliminate adversarial perturbations whilst closely preserving the original data sample.
  As a second contribution, we propose a new stochastic sampling method which introduces additional noise during the reverse diffusion process to dilute adversarial perturbations.
  Without relying on gradient obfuscation, these contributions result in a new robustness accuracy record of 44.23% on ImageNet using AutoAttack ($\ell_{\infty}=4/255$), an improvement of +2.07% over the previous best work.
  Furthermore, our method reduces inference time to 1.08 seconds per sample on ImageNet, a $47\times$ improvement over the existing state-of-the-art approach, making it far more practical for real-world defensive scenarios.

</details>


### [13] [AI-Powered Hybrid Intrusion Detection Framework for Cloud Security Using Novel Metaheuristic Optimization](https://arxiv.org/abs/2601.01134)
*Maryam Mahdi Alhusseini,Alireza Rouhi,Mohammad-Reza Feizi-Derakhshi*

Main category: cs.CR

TL;DR: 提出HyIDS混合入侵检测系统，使用EVO算法进行特征选择，结合四种机器学习模型，在两类不平衡数据集上显著提升检测性能。


<details>
  <summary>Details</summary>
Motivation: 云计算中的网络安全面临挑战，特别是入侵检测系统在处理不平衡数据集和分类模型性能不佳的问题。需要开发更有效的检测方法来应对云环境中的网络安全威胁。

Method: 提出HyIDS混合入侵检测系统，采用Energy Valley Optimizer (EVO)算法进行特征选择，减少特征维度。结合四种机器学习模型（SVM、RF、决策树、KNN），使用下采样技术平衡数据集，在CIC-DDoS2019和CSE-CIC-IDS2018两个真实数据集上进行评估。

Result: EVO算法显著减少特征数量（CIC-DDoS2019从88到38，CSE-CIC-IDS2018从80到43）。D_TreeEVO模型在CIC-DDoS2019上达到99.13%准确率和98.94% F1分数，在CSE-CIC-IDS2018上达到99.78%准确率和99.70% F1分数。进行了24次实验，分类准确率、精确率和召回率均有显著提升。

Conclusion: EVO算法显著提升了云计算中的网络安全防护能力，HyIDS系统在处理不平衡数据集时表现出优越的检测性能，为云环境入侵检测提供了有效解决方案。

Abstract: Cybersecurity poses considerable problems to Cloud Computing (CC), especially regarding Intrusion Detection Systems (IDSs), facing difficulties with skewed datasets and suboptimal classification model performance. This study presents the Hybrid Intrusion Detection System (HyIDS), an innovative IDS that employs the Energy Valley Optimizer (EVO) for Feature Selection (FS). Additionally, it introduces a novel technique for enhancing the cybersecurity of cloud computing through the integration of machine learning methodologies with the EVO Algorithm. The Energy Valley Optimizer (EVO) effectively diminished features in the CIC-DDoS2019 dataset from 88 to 38 and in the CSE-CIC-IDS2018 data from 80 to 43, significantly enhancing computing efficiency. HyIDS incorporates four Machine Learning (ML) models: Support Vector Machine (SVM), Random Forest (RF), Decision Tree (D_Tree), and K-Nearest Neighbors (KNN). The proposed HyIDS was assessed utilizing two real-world intrusion datasets, CIC-DDoS2019 and CSE-CIC-IDS2018, both distinguished by considerable class imbalances. The CIC-DDoS2019 dataset has a significant imbalance between DDoS assault samples and legal traffic, while the CSE-CIC-IDS2018 dataset primarily comprises benign traffic with insufficient representation of attack types, complicating the detection of minority attacks. A downsampling technique was employed to balance the datasets, hence improving detection efficacy for both benign and malicious traffic. Twenty-four trials were done, revealing substantial enhancements in categorization accuracy, precision, and recall. Our suggested D_TreeEVO model attained an accuracy rate of 99.13% and an F1 score of 98.94% on the CIC-DDoS2019 dataset, and an accuracy rate of 99.78% and an F1 score of 99.70% on the CSE-CIC-IDS2018 data. These data demonstrate that EVO significantly improves cybersecurity in Cloud Computing (CC).

</details>


### [14] [Comparative Evaluation of VAE, GAN, and SMOTE for Tor Detection in Encrypted Network Traffic](https://arxiv.org/abs/2601.01183)
*Saravanan A,Aswani Kumar Cherukuri*

Main category: cs.CR

TL;DR: 该研究探索使用生成式AI模型（VAE、GAN、SMOTE）合成加密网络流量数据，以解决入侵检测中因加密导致的可见性不足、标注数据稀缺和类别不平衡问题，在UNSW NB-15数据集上评估发现VAE在隐私和性能间取得最佳平衡。


<details>
  <summary>Details</summary>
Motivation: 加密网络流量给入侵检测带来三大挑战：1) 缺乏有效载荷可见性；2) 标注数据集有限；3) 正常与恶意活动之间的类别高度不平衡。传统数据增强方法难以保持真实网络流量的复杂时序和统计特征。

Method: 研究评估了三种生成式AI方法：变分自编码器（VAE）、生成对抗网络（GAN）和合成少数类过采样技术（SMOTE）。所有方法都集成了包含特征选择和类别平衡的预处理流程。使用UNSW NB-15数据集作为主要基准，重点关注Tor流量作为异常。通过统计相似性分析和分类器性能评估（准确率、F1分数、AUC-ROC）来比较不同方法。

Result: VAE生成的数据在隐私保护和性能之间提供了最佳平衡；GANs提供更高的保真度但存在过拟合风险；SMOTE虽然简单，能提高召回率但可能缺乏多样性。生成式AI方法在使用隐私保护的合成数据训练时，能显著改善加密流量检测性能。

Conclusion: 生成式AI方法能够有效合成真实多样的加密流量数据，解决入侵检测中的数据稀缺和类别不平衡问题。VAE在隐私和性能间取得最佳平衡，为加密流量检测提供了一种可行的数据增强方案。

Abstract: Encrypted network traffic poses significant challenges for intrusion detection due to the lack of payload visibility, limited labeled datasets, and high class imbalance between benign and malicious activities. Traditional data augmentation methods struggle to preserve the complex temporal and statistical characteristics of real network traffic. To address these issues, this work explores the use of Generative AI (GAI) models to synthesize realistic and diverse encrypted traffic traces. We evaluate three approaches: Variational Autoencoders (VAE), Generative Adversarial Networks (GAN), and SMOTE (Synthetic Minority Over-sampling Technique), each integrated with a preprocessing pipeline that includes feature selection and class balancing. The UNSW NB-15 dataset is used as the primary benchmark, focusing on Tor traffic as anomalies. We analyze statistical similarity between real and synthetic data, and assess classifier performance using metrics such as Accuracy, F1-score, and AUC-ROC. Results show that VAE-generated data provides the best balance between privacy and performance, while GANs offer higher fidelity but risk overfitting. SMOTE, though simple, enhances recall but may lack diversity. The findings demonstrate that GAI methods can significantly improve encrypted traffic detection when trained with privacy-preserving synthetic data.

</details>


### [15] [SecureCodeRL: Security-Aware Reinforcement Learning for Code Generation with Partial-Credit Rewards](https://arxiv.org/abs/2601.01184)
*Suryansh Singh Sijwali,Suman Saha*

Main category: cs.CR

TL;DR: SecureCodeRL使用强化学习优化代码生成，结合功能性和安全性奖励，在竞争性编程任务中提高语法有效性和测试通过率。


<details>
  <summary>Details</summary>
Motivation: 大型语言模型生成的代码虽然看似合理，但在需要精确输入输出行为的场景中经常编译成功但测试失败，有时还会引入安全敏感模式，需要改进代码生成的安全性和功能性。

Method: 提出SecureCodeRL强化学习管道，使用组合奖励R = αRfunc + βRsec，其中包含部分信用功能奖励，为语法有效性、成功执行和产生输出分配中间分数，减少奖励稀疏性。评估了监督微调和PPO变体。

Result: 在APPS+的小型测试集上，PPO与部分信用奖励将语法有效性从45%（SFT）提高到60%，实现了5%的至少通过一个测试的成功信号，同时在Bandit静态分析中保持100%清洁。

Conclusion: SecureCodeRL通过强化学习和组合奖励机制，在保持代码安全性的同时，显著提高了代码生成的功能正确性，为安全感知的代码生成提供了有效方法。

Abstract: Large Language Models (LLMs) can generate plausible code, but in settings that require exact stdin/stdout behavior they frequently produce programs that compile yet fail tests, and in some cases they introduce security-sensitive patterns. This paper presents SecureCodeRL, a reinforcement learning (RL) pipeline for security-aware code generation that optimizes a combined reward R = αRfunc + \b{eta}Rsec. The key idea is a partial-credit functional reward that assigns intermediate scores for syntactic validity, successful execution, and producing output, reducing reward sparsity that otherwise stalls learning on competitive programming style tasks. I evaluate supervised fine-tuning (SFT) and PPO variants on a small held-out prompt set from APPS+ and observe that PPO with partial credit (using a continued-training variant) improves syntax validity from 45% (SFT) to 60% and achieves the only non-zero test success signal in this pilot evaluation (5% at-least-one-test-pass), while remaining 100% clean under Bandit static analysis. Although Bandit findings were absent in this small evaluation, the security term is integrated into training to discourage insecure shortcuts when they appear.

</details>


### [16] [Arca: A Lightweight Confidential Container Architecture for Cloud-Native Environments](https://arxiv.org/abs/2601.01214)
*Di Lu,Mengna Sun,Qingwen Zhang,Yujia Liu,Jia Zhang,Xuewen Dong,Yulong Shen,Jianfeng Ma*

Main category: cs.CR

TL;DR: Arca是一个基于TEE-in-Container架构的轻量级机密容器框架，将每个工作负载隔离在独立的硬件强制信任域中，同时将编排逻辑保留在TEE外部，从而减少可信计算基并提升性能。


<details>
  <summary>Details</summary>
Motivation: 现有容器内TEE设计（如CoCo）将整个运行时封装在TEE内，导致可信计算基膨胀，引入冗余组件和跨层开销，违背了TEE的最小信任原则。

Method: 采用TEE-in-Container架构，将每个工作负载隔离在独立的硬件强制信任域中，保持编排逻辑在TEE外部，最小化层间依赖，将安全威胁限制在单容器边界内。

Result: 在Intel SGX、Intel TDX和AMD SEV上实现Arca，实验结果显示其达到接近原生性能，在大多数基准测试中优于CoCo，减少的可信计算基显著提升了可验证性和对主机级攻击的抵御能力。

Conclusion: Arca证明了高效容器管理和强运行时机密性可以在不牺牲安全保障的情况下实现，恢复了TEE的最小信任原则。

Abstract: Confidential containers protect cloud-native workloads using trusted execution environments (TEEs). However, existing Container-in-TEE designs (e.g., Confidential Containers (CoCo)) encapsulate the entire runtime within the TEE, inflating the trusted computing base (TCB) and introducing redundant components and cross-layer overhead. We present Arca, a lightweight confidential container framework based on a TEE-in-Container architecture that isolates each workload in an independent, hardware-enforced trust domain while keeping orchestration logic outside the TEE. This design minimizes inter-layer dependencies, confines compromise to per-container boundaries, and restores the TEE's minimal trust principle. We implemented Arca on Intel SGX, Intel TDX, and AMD SEV. Experimental results show that Arca achieves near-native performance and outperforms CoCo in most benchmarks, while the reduced TCB significantly improves verifiability and resilience against host-level compromise. Arca emonstrates that efficient container management and strong runtime confidentiality can be achieved without sacrificing security assurance.

</details>


### [17] [MCP-SandboxScan: WASM-based Secure Execution and Runtime Analysis for MCP Tools](https://arxiv.org/abs/2601.01241)
*Zhuoran Tan,Run Hao,Jeremy Singer,Yutian Tang,Christos Anagnostopoulos*

Main category: cs.CR

TL;DR: MCP-SandboxScan是一个轻量级框架，用于安全执行不受信任的工具并在WebAssembly/WASI沙箱中分析运行时行为，检测外部输入到敏感接收器的暴露风险。


<details>
  <summary>Details</summary>
Motivation: 工具增强的LLM代理引入了新的安全风险：工具执行可能引入仅运行时可见的行为，包括提示注入和外部输入（如环境密钥或本地文件）的意外暴露。现有扫描器通常关注静态工件，而分析运行时行为具有挑战性，因为直接执行不受信任的工具本身就很危险。

Method: 基于模型上下文协议（MCP）设计了一个轻量级框架，在WebAssembly/WASI沙箱中安全执行不受信任的工具，并生成可审计的外部到接收器暴露报告。原型系统：(i)从运行时输出中提取LLM相关接收器（提示/消息和结构化工具返回字段），(ii)从环境值、挂载文件内容和输出表面HTTP获取意图实例化外部输入候选，(iii)通过基于片段的子字符串匹配将源链接到接收器。

Result: 对三个代表性工具的案例研究表明，MCP-SandboxScan能够在外部输入出现在提示/消息或工具返回有效载荷时显示来源证据，并能够将文件系统能力违规暴露为运行时证据。与轻量级静态字符串签名基线比较，并使用微基准测试来表征转换下的假阴性和短令牌冲突导致的假阳性。

Conclusion: MCP-SandboxScan提供了一个实用的框架，用于安全分析工具增强LLM系统的运行时行为，能够检测外部输入暴露风险，为LLM工具安全提供了有效的运行时分析方法。

Abstract: Tool-augmented LLM agents raise new security risks: tool executions can introduce runtime-only behaviors, including prompt injection and unintended exposure of external inputs (e.g., environment secrets or local files). While existing scanners often focus on static artifacts, analyzing runtime behavior is challenging because directly executing untrusted tools can itself be dangerous. We present MCP-SandboxScan, a lightweight framework motivated by the Model Context Protocol (MCP) that safely executes untrusted tools inside a WebAssembly/WASI sandbox and produces auditable reports of external-to-sink exposures. Our prototype (i) extracts LLM-relevant sinks from runtime outputs (prompt/messages and structured tool-return fields), (ii) instantiates external-input candidates from environment values, mounted file contents, and output-surfaced HTTP fetch intents, and (iii) links sources to sinks via snippet-based substring matching. Case studies on three representative tools show that MCP-SandboxScan can surface provenance evidence when external inputs appear in prompt/messages or tool-return payloads, and can expose filesystem capability violations as runtime evidence. We further compare against a lightweight static string-signature baseline and use a micro-benchmark to characterize false negatives under transformations and false positives from short-token collisions.

</details>


### [18] [Compliance as a Trust Metric](https://arxiv.org/abs/2601.01287)
*Wenbo Wu,George Konstantinidis*

Main category: cs.CR

TL;DR: 本文提出ACE系统，将法规遵从性转化为动态信任度量，通过多维度违规严重性评估计算细粒度合规分数，超越传统二元审计方法。


<details>
  <summary>Details</summary>
Motivation: 当前信任与声誉管理系统依赖主观用户评分或有限的QoS指标，缺乏客观基础；同时GDPR、HIPAA等法规框架的自动化合规审计仅限于粗糙的二元结果。需要将法规遵从性转化为可量化的动态信任度量。

Method: 开发自动化合规引擎ACE：1) 将法律和组织政策形式化为可验证的义务中心逻辑；2) 持续审计系统事件日志检测违规；3) 建立多维度定量模型评估违规严重性（包括数量、持续时间、广度、关键性）；4) 计算细粒度、演化的合规分数。

Result: 在合成医院数据集上评估ACE，证明其能准确检测复杂的HIPAA和GDPR违规，并产生比传统二元方法更具表达力的细致合规分数。

Conclusion: ACE将法规遵从性操作化为定量动态信任度量，为Web上更透明、可问责、有韧性的信任与声誉管理系统发展奠定基础。

Abstract: Trust and Reputation Management Systems (TRMSs) are critical for the modern web, yet their reliance on subjective user ratings or narrow Quality of Service (QoS) metrics lacks objective grounding. Concurrently, while regulatory frameworks like GDPR and HIPAA provide objective behavioral standards, automated compliance auditing has been limited to coarse, binary (pass/fail) outcomes. This paper bridges this research gap by operationalizing regulatory compliance as a quantitative and dynamic trust metric through our novel automated compliance engine (ACE). ACE first formalizes legal and organizational policies into a verifiable, obligation-centric logic. It then continuously audits system event logs against this logic to detect violations. The core of our contribution is a quantitative model that assesses the severity of each violation along multiple dimensions, including its Volume, Duration, Breadth, and Criticality, to compute a fine-grained, evolving compliance score. We evaluate ACE on a synthetic hospital dataset, demonstrating its ability to accurately detect a range of complex HIPAA and GDPR violations and produce a nuanced score that is significantly more expressive than traditional binary approaches. This work enables the development of more transparent, accountable, and resilient TRMSs on the Web.

</details>


### [19] [dataRLsec: Safety, Security, and Reliability With Robust Offline Reinforcement Learning for DPAs](https://arxiv.org/abs/2601.01289)
*Shriram KS Pandian,Naresh Kshetri*

Main category: cs.CR

TL;DR: 该论文分析了数据投毒攻击在AI/ML/DL系统中的威胁，提出了一种基于加权哈希验证和密度比加权行为克隆的鲁棒离线强化学习防御方法。


<details>
  <summary>Details</summary>
Motivation: 随着AI/ML/DL算法在人工智能时代的广泛应用，数据投毒攻击变得越来越流行。黑客和渗透测试者通过在训练数据和测试数据中注入恶意内容，导致难以检测和预测的错误结果，特别是在医疗数据等领域存在严重风险。

Method: 论文分析了从深度强化学习到联邦学习等多种技术中的数据投毒攻击及其安全措施。在MuJoCo环境中展示了HalfCheetah任务在数据集被投毒前后的性能对比。提出了基于加权哈希验证和密度比加权行为克隆算法的鲁棒离线强化学习方法，该方法包含四个阶段（阶段0到阶段3），专门针对离线RL的安全性和安全性设计。

Result: 论文展示了数据投毒攻击对AI系统性能的严重影响，特别是在MuJoCo环境中HalfCheetah任务的性能下降。提出的DWBC算法结合加权哈希验证，为防御数据投毒攻击提供了新的解决方案框架。

Conclusion: 论文总结了数据投毒攻击的严重威胁，并提出了将DWBC算法与其他数据防御策略相结合的未来研究方向，以应对和防范未来的污染性网络攻击。

Abstract: Data poisoning attacks (DPAs) are becoming popular as artificial intelligence (AI) algorithms, machine learning (ML) algorithms, and deep learning (DL) algorithms in this artificial intelligence (AI) era. Hackers and penetration testers are excessively injecting malicious contents in the training data (and in testing data too) that leads to false results that are very hard to inspect and predict. We have analyzed several recent technologies used (from deep reinforcement learning to federated learning) for the DPAs and their safety, security, & countermeasures. The problem setup along with the problem estimation is shown in the MuJoCo environment with performance of HalfCheetah before the dataset is poisoned and after the dataset is poisoned. We have analyzed several risks associated with the DPAs and falsification in medical data from popular poisoning data attacks to some popular data defenses. We have proposed robust offline reinforcement learning (Offline RL) for the safety and reliability with weighted hash verification along with density-ratio weighted behavioral cloning (DWBC) algorithm. The four stages of the proposed algorithm (as the Stage 0, the Stage 1, the Stage 2, and the Stage 3) are described with respect to offline RL, safety, and security for DPAs. The conclusion and future scope are provided with the intent to combine DWBC with other data defense strategies to counter and protect future contamination cyberattacks.

</details>


### [20] [Aggressive Compression Enables LLM Weight Theft](https://arxiv.org/abs/2601.01296)
*Davis Brown,Juan-Pablo Rivera,Dan Hendrycks,Mantas Mazeika*

Main category: cs.CR

TL;DR: 该论文研究了针对大型语言模型权重窃取的网络渗透攻击，发现模型权重的可压缩性显著增加了渗透风险，攻击者可通过特定压缩技术实现16-100倍压缩，将窃取时间从数月缩短到数天，并提出三种防御策略，其中法医水印防御最为有效且成本低廉。


<details>
  <summary>Details</summary>
Motivation: 随着前沿AI模型变得更强大且开发成本更高，攻击者窃取模型权重的动机日益增强。网络渗透攻击成为现实威胁，需要研究模型权重窃取的风险因素和防御方法。

Method: 1) 分析模型权重的可压缩性作为渗透风险的关键因素；2) 设计专门针对渗透攻击的压缩技术，放宽解压缩约束；3) 提出三种防御策略：使模型更难压缩、更难被发现、使用法医水印进行溯源分析。

Result: 攻击者可通过特定压缩技术实现16-100倍的压缩比，将模型权重窃取时间从数月缩短到数天。在三种防御策略中，法医水印防御被证明既有效又成本低廉，是减轻权重渗透风险的最佳选择。

Conclusion: 模型权重的可压缩性是渗透攻击的主要风险因素，攻击者可通过专门设计的压缩技术大幅降低窃取时间。虽然多种防御策略都有前景，但法医水印防御因其有效性和低成本成为减轻权重窃取风险的最佳方案。

Abstract: As frontier AIs become more powerful and costly to develop, adversaries have increasing incentives to steal model weights by mounting exfiltration attacks. In this work, we consider exfiltration attacks where an adversary attempts to sneak model weights out of a datacenter over a network. While exfiltration attacks are multi-step cyber attacks, we demonstrate that a single factor, the compressibility of model weights, significantly heightens exfiltration risk for large language models (LLMs). We tailor compression specifically for exfiltration by relaxing decompression constraints and demonstrate that attackers could achieve 16x to 100x compression with minimal trade-offs, reducing the time it would take for an attacker to illicitly transmit model weights from the defender's server from months to days. Finally, we study defenses designed to reduce exfiltration risk in three distinct ways: making models harder to compress, making them harder to 'find,' and tracking provenance for post-attack analysis using forensic watermarks. While all defenses are promising, the forensic watermark defense is both effective and cheap, and therefore is a particularly attractive lever for mitigating weight-exfiltration risk.

</details>


### [21] [Automated SBOM-Driven Vulnerability Triage for IoT Firmware: A Lightweight Pipeline for Risk Prioritization](https://arxiv.org/abs/2601.01308)
*Abdurrahman Tolay*

Main category: cs.CR

TL;DR: 本文提出一个轻量级自动化管道，用于从Linux物联网固件提取文件系统、生成SBOM、映射漏洞，并应用多因素优先级评分模型，旨在降低告警疲劳并优先处理高风险漏洞。


<details>
  <summary>Details</summary>
Motivation: 物联网设备固件通常包含过时的第三方库，且以单片二进制形式存在，使得漏洞管理困难。现有SBOM标准虽然成熟，但从原始固件转储生成可操作情报仍依赖手动且易出错的过程。

Method: 提出轻量级自动化管道：1) 从Linux物联网固件提取文件系统；2) 生成全面SBOM；3) 映射组件到已知漏洞；4) 应用多因素优先级评分模型，整合CVSS、EPSS和CISA KEV目录信号。

Result: 该方法强调优先级排序，为每个发现计算本地化风险评分，减少传统扫描器产生的大量无上下文告警。研究概述了验证提取成功率和优先级排序效能的评估策略。

Conclusion: 该自动化管道专注于风险优先级排序，通过整合多个漏洞评分系统信号，提供可复现的固件安全研究框架，旨在降低告警疲劳并有效管理物联网固件安全风险。

Abstract: The proliferation of Internet of Things (IoT) devices has introduced significant security challenges, primarily due to the opacity of firmware components and the complexity of supply chain dependencies. IoT firmware frequently relies on outdated, third-party libraries embedded within monolithic binary blobs, making vulnerability management difficult. While Software Bill of Materials (SBOM) standards have matured, generating actionable intelligence from raw firmware dumps remains a manual and error-prone process. This paper presents a lightweight, automated pipeline designed to extract file systems from Linux-based IoT firmware, generate a comprehensive SBOM, map identified components to known vulnerabilities, and apply a multi-factor triage scoring model. The proposed system focuses on risk prioritization by integrating signals from the Common Vulnerability Scoring System (CVSS), Exploit Prediction Scoring System (EPSS), and the CISA Known Exploited Vulnerabilities (KEV) catalog. Unlike conventional scanners that produce high volumes of uncontextualized alerts, this approach emphasizes triage by calculating a localized risk score for each finding. We describe the architecture, the normalization challenges of embedded Linux, and a scoring methodology intended to reduce alert fatigue. The study outlines a planned evaluation strategy to validate the extraction success rate and triage efficacy using a dataset of public vendor firmware, offering a reproducibility framework for future research in firmware security.

</details>


### [22] [Bithoven: Formal Safety for Expressive Bitcoin Smart Contracts](https://arxiv.org/abs/2601.01436)
*Hyunhum Cho,Ik Rae Jeong*

Main category: cs.CR

TL;DR: Bithoven：一种为比特币UTXO架构设计的高级语言，通过类型检查和资源活性分析消除共识和逻辑缺陷，在保持高效编译的同时提升开发安全性。


<details>
  <summary>Details</summary>
Motivation: 比特币UTXO架构的严格安全模型牺牲了开发易用性，导致手动堆栈操作容易引发签名可塑性、不可花费状态和非约束执行路径等关键金融漏洞。现有标准如Miniscript仅提供策略验证抽象，无法满足复杂合约的完整命令式逻辑需求，存在状态管理和资源活性方面的缺陷。

Method: Bithoven语言集成了严格类型检查器、资源活性分析器和语义控制流分析器，通过形式化安全分析在部署前消除共识和逻辑缺陷。该语言编译为比特币脚本，效率接近手动优化代码。

Result: Bithoven在保持安全性的同时成本适中，编译效率与手动优化代码相当，证明类型安全、开发者友好的抽象在比特币区块链严格的字节大小限制下是可行的。

Conclusion: Bithoven成功弥合了表达能力和形式化安全之间的差距，为比特币智能合约开发提供了既安全又实用的高级语言解决方案。

Abstract: The rigorous security model of Bitcoin's UTXO architecture often comes at the cost of developer usability, forcing a reliance on manual stack manipulation that leads to critical financial vulnerabilities like signature malleability, unspendable states and unconstrained execution paths. Industry standards such as Miniscript provide necessary abstractions for policy verification but do not model the full imperative logic required for complex contracts, leaving gaps in state management and resource liveness. This paper introduces Bithoven, a high-level language designed to bridge the gap between expressiveness and formal safety. By integrating a strict type checker and a resource liveness analyzer with a semantic control-flow analyzer, Bithoven eliminates major categories of consensus and logic defects defined in our fault model prior to deployment. Our results indicate that this safety comes at modest cost: Bithoven compiles to Bitcoin Script with efficiency comparable to hand-optimized code, demonstrating that type-safe, developer-friendly abstractions are viable even within the strict byte-size constraints of the Bitcoin blockchain.

</details>


### [23] [Security in the Era of Perceptive Networks: A Comprehensive Taxonomic Framework for Integrated Sensing and Communication Security](https://arxiv.org/abs/2601.01455)
*Chandra Thapa,Surya Nepal*

Main category: cs.CR

TL;DR: 本文提出一个全面的ISAC安全分类框架，系统整合威胁、漏洞、防御机制、性能权衡等多个维度，为6G集成感知与通信系统的安全研究提供结构化参考。


<details>
  <summary>Details</summary>
Motivation: 虽然已有研究建立了ISAC安全的基础要素和感知安全模型，但缺乏一个覆盖整个ISAC安全领域的综合分类框架。本文旨在整合现有研究，提供系统性的安全分析框架。

Method: 采用多维度正交分析方法，包括威胁分类与传播方法、设计/物理/计算/架构层面的漏洞分析、按部署层分类的防御机制、安全-性能权衡的理论边界、关键基础设施的特定安全需求，以及量子韧性、AI加固和隐私保护等新兴问题。

Result: 提出了一个全面的ISAC安全分类框架，揭示了威胁与防御之间的隐藏关系，并通过结构化分析识别了关键研究空白，为研究人员和政策制定者提供了有价值的参考。

Conclusion: 该分类框架为开发安全ISAC系统和制定安全标准提供了系统化的参考，填补了现有研究在综合安全分析方面的空白，有助于推动6G集成感知与通信系统的安全发展。

Abstract: Integrated Sensing and Communication (ISAC) represents a significant shift in the 6G landscape, where wireless networks both sense the environment and communicate. While prior comprehensive surveys have established foundational elements of ISAC security, discussed perception-focused security models, and proposed layered defense strategies, this paper synthesizes these studies into a comprehensive taxonomic framework that covers the whole ISAC security domain. This paper provides a systematic and thorough review of ISAC security across multiple orthogonal dimensions. These include threat taxonomy and propagation methods; vulnerability analysis at design, physical, computational, and architectural levels; defense mechanisms categorized by deployment layer; security-performance trade-offs with theoretical bounds; sector-specific security demands for critical infrastructure; and emerging issues such as quantum resilience, AI-hardening, and privacy preservation. Unlike previous frameworks that primarily focus on vision, this review combines these dimensions, introduces new classification schemes that reveal hidden relationships between threats and defenses, and identifies key research gaps through structured analysis. This detailed taxonomy offers a valuable reference for researchers developing secure ISAC systems and policymakers establishing security standards.

</details>


### [24] [OpenRT: An Open-Source Red Teaming Framework for Multimodal LLMs](https://arxiv.org/abs/2601.01592)
*Xin Wang,Yunhao Chen,Juncheng Li,Yixu Wang,Yang Yao,Tianle Gu,Jie Li,Yan Teng,Xingjun Ma,Yingchun Wang,Xia Hu*

Main category: cs.CR

TL;DR: OpenRT是一个统一、模块化、高吞吐量的红队测试框架，用于全面评估多模态大语言模型的安全漏洞，通过标准化攻击接口和异步运行时实现系统化扩展。


<details>
  <summary>Details</summary>
Motivation: 多模态大语言模型在关键应用中的快速集成受到持续安全漏洞的阻碍，现有红队测试基准存在碎片化、仅限于单轮文本交互、缺乏系统性评估所需可扩展性等问题。

Method: 引入OpenRT框架，采用对抗性内核实现五个关键维度的模块化分离：模型集成、数据集管理、攻击策略、判断方法和评估指标。标准化攻击接口，将对抗逻辑与高吞吐量异步运行时解耦，集成37种不同的攻击方法。

Result: 对20个先进模型（包括GPT-5.2、Claude 4.5、Gemini 3 Pro）的实证研究显示严重安全漏洞：前沿模型无法跨攻击范式泛化，领先模型的平均攻击成功率高达49.14%。推理模型在面对复杂多轮越狱攻击时并不具备固有优势。

Conclusion: 通过开源OpenRT，提供了一个可持续、可扩展且持续维护的基础设施，加速AI安全开发和标准化进程，揭示了当前MLLM安全评估的系统性缺陷。

Abstract: The rapid integration of Multimodal Large Language Models (MLLMs) into critical applications is increasingly hindered by persistent safety vulnerabilities. However, existing red-teaming benchmarks are often fragmented, limited to single-turn text interactions, and lack the scalability required for systematic evaluation. To address this, we introduce OpenRT, a unified, modular, and high-throughput red-teaming framework designed for comprehensive MLLM safety evaluation. At its core, OpenRT architects a paradigm shift in automated red-teaming by introducing an adversarial kernel that enables modular separation across five critical dimensions: model integration, dataset management, attack strategies, judging methods, and evaluation metrics. By standardizing attack interfaces, it decouples adversarial logic from a high-throughput asynchronous runtime, enabling systematic scaling across diverse models. Our framework integrates 37 diverse attack methodologies, spanning white-box gradients, multi-modal perturbations, and sophisticated multi-agent evolutionary strategies. Through an extensive empirical study on 20 advanced models (including GPT-5.2, Claude 4.5, and Gemini 3 Pro), we expose critical safety gaps: even frontier models fail to generalize across attack paradigms, with leading models exhibiting average Attack Success Rates as high as 49.14%. Notably, our findings reveal that reasoning models do not inherently possess superior robustness against complex, multi-turn jailbreaks. By open-sourcing OpenRT, we provide a sustainable, extensible, and continuously maintained infrastructure that accelerates the development and standardization of AI safety.

</details>


### [25] [Exposing Hidden Interfaces: LLM-Guided Type Inference for Reverse Engineering macOS Private Frameworks](https://arxiv.org/abs/2601.01673)
*Arina Kharlamova,Youcheng Sun,Ting Yu*

Main category: cs.CR

TL;DR: MOTIF是一个用于逆向分析macOS私有框架的智能代理框架，通过结合工具增强分析和专门优化的LLM，将未文档化的二进制文件转换为可编译的头文件，显著提升方法签名恢复准确率。


<details>
  <summary>Details</summary>
Motivation: macOS的私有框架支撑着关键服务和守护进程，但这些框架既无文档说明，又只以剥离的二进制形式分发，给安全分析带来了巨大困难。现有的静态分析工具效果有限，需要更系统的方法来逆向这些不透明的二进制接口。

Method: MOTIF整合了工具增强分析和专门为Objective-C类型推断微调的大型语言模型。代理负责管理运行时元数据提取、二进制检查和约束验证，而模型则生成候选方法签名，这些签名经过验证和精炼后形成可编译的头文件。

Result: 在基于公共框架构建的MOTIF-Bench基准测试中，MOTIF将方法签名恢复准确率从基线静态分析工具的15%提升到86%，在工具使用正确性和推理稳定性方面也取得一致提升。对私有框架的案例研究表明，重建的头文件能够成功编译、链接，并支持下游安全研究和漏洞分析。

Conclusion: MOTIF通过将不透明的二进制文件转换为可分析的接口，为macOS内部组件的系统性审计建立了可扩展的基础。该框架显著改善了私有框架的逆向工程能力，为安全研究人员提供了强大的分析工具。

Abstract: Private macOS frameworks underpin critical services and daemons but remain undocumented and distributed only as stripped binaries, complicating security analysis. We present MOTIF, an agentic framework that integrates tool-augmented analysis with a finetuned large language model specialized for Objective-C type inference. The agent manages runtime metadata extraction, binary inspection, and constraint checking, while the model generates candidate method signatures that are validated and refined into compilable headers. On MOTIF-Bench, a benchmark built from public frameworks with groundtruth headers, MOTIF improves signature recovery from 15% to 86% compared to baseline static analysis tooling, with consistent gains in tool-use correctness and inference stability. Case studies on private frameworks show that reconstructed headers compile, link, and facilitate downstream security research and vulnerability studies. By transforming opaque binaries into analyzable interfaces, MOTIF establishes a scalable foundation for systematic auditing of macOS internals.

</details>


### [26] [Structural Representations for Cross-Attack Generalization in AI Agent Threat Detection](https://arxiv.org/abs/2601.01723)
*Vignesh Iyer*

Main category: cs.CR

TL;DR: 论文提出结构化标记化方法，显著提升AI代理对新型攻击的检测能力，特别是针对工具劫持和数据窃取等结构性攻击。


<details>
  <summary>Details</summary>
Motivation: 当前基于对话标记化的AI代理攻击检测方法在处理结构性攻击（如工具劫持、数据窃取）时效果很差，无法实现跨攻击类型的泛化检测。需要探索更有效的攻击检测方法。

Method: 提出结构化标记化方法，编码执行流模式（工具调用、参数、观察结果）而非对话内容；针对需要语言特征的攻击，提出门控多视图融合机制，自适应结合两种表示。

Result: 结构化标记化显著提升跨攻击泛化能力：工具劫持攻击AUC提升46点，数据窃取提升39点，未知攻击提升71点，同时提升分布内性能6点。门控多视图融合在社交工程攻击上达到AUC 0.89。

Conclusion: AI代理安全本质上是结构性问题，攻击语义存在于执行模式而非表面语言。结构化抽象原则具有普适性，即使简单实现也能显著提升检测性能。

Abstract: Autonomous AI agents executing multi-step tool sequences face semantic attacks that manifest in behavioral traces rather than isolated prompts. A critical challenge is cross-attack generalization: can detectors trained on known attack families recognize novel, unseen attack types? We discover that standard conversational tokenization -- capturing linguistic patterns from agent interactions -- fails catastrophically on structural attacks like tool hijacking (AUC 0.39) and data exfiltration (AUC 0.46), while succeeding on linguistic attacks like social engineering (AUC 0.78). We introduce structural tokenization, encoding execution-flow patterns (tool calls, arguments, observations) rather than conversational content. This simple representational change dramatically improves cross-attack generalization: +46 AUC points on tool hijacking, +39 points on data exfiltration, and +71 points on unknown attacks, while simultaneously improving in-distribution performance (+6 points). For attacks requiring linguistic features, we propose gated multi-view fusion that adaptively combines both representations, achieving AUC 0.89 on social engineering without sacrificing structural attack detection. Our findings reveal that AI agent security is fundamentally a structural problem: attack semantics reside in execution patterns, not surface language. While our rule-based tokenizer serves as a baseline, the structural abstraction principle generalizes even with simple implementation.

</details>


### [27] [Local Layer-wise Differential Privacy in Federated Learning](https://arxiv.org/abs/2601.01737)
*Yunbo Li,Jiaping Gui,Fanchao Meng,Yue Wu*

Main category: cs.CR

TL;DR: LaDP：一种用于联邦学习的层间自适应噪声注入机制，通过量化层间隐私泄漏并动态注入噪声，在保证差分隐私的同时显著提升模型精度


<details>
  <summary>Details</summary>
Motivation: 联邦学习虽然支持协作训练而不直接共享数据，但仍易受模型反演和成员推理等隐私攻击。现有差分隐私解决方案通常在整个模型中均匀注入噪声，导致效用下降且隐私-效用权衡不理想。

Method: 提出LaDP，一种层间自适应噪声注入机制。基于两个关键洞察：(1)神经网络层对模型效用的贡献不均匀；(2)层间隐私泄漏可通过本地与全局模型分布的KL散度量化。LaDP根据层的隐私敏感性和对模型性能的重要性动态选择注入噪声的层。

Result: 在CIFAR-10/100数据集上的实验表明：LaDP平均减少46.14%的噪声注入，同时提高102.99%的准确率；在相同隐私预算下，比Dynamic Privacy Allocation LDP和AdapLDP分别提升25.18%和6.1%的准确率；能有效防御重构攻击，使重构私有数据的FID增加>12.84%。

Conclusion: LaDP通过层间自适应噪声注入机制，在保证差分隐私的同时最小化效用损失，推动了隐私保护联邦学习的实际部署。

Abstract: Federated Learning (FL) enables collaborative model training without direct data sharing, yet it remains vulnerable to privacy attacks such as model inversion and membership inference. Existing differential privacy (DP) solutions for FL often inject noise uniformly across the entire model, degrading utility while providing suboptimal privacy-utility tradeoffs. To address this, we propose LaDP, a novel layer-wise adaptive noise injection mechanism for FL that optimizes privacy protection while preserving model accuracy. LaDP leverages two key insights: (1) neural network layers contribute unevenly to model utility, and (2) layer-wise privacy leakage can be quantified via KL divergence between local and global model distributions. LaDP dynamically injects noise into selected layers based on their privacy sensitivity and importance to model performance.
  We provide a rigorous theoretical analysis, proving that LaDP satisfies $(ε, δ)$-DP guarantees and converges under bounded noise. Extensive experiments on CIFAR-10/100 datasets demonstrate that LaDP reduces noise injection by 46.14% on average compared to state-of-the-art (SOTA) methods while improving accuracy by 102.99%. Under the same privacy budget, LaDP outperforms SOTA solutions like Dynamic Privacy Allocation LDP and AdapLDP by 25.18% and 6.1% in accuracy, respectively. Additionally, LaDP robustly defends against reconstruction attacks, increasing the FID of the reconstructed private data by $>$12.84% compared to all baselines. Our work advances the practical deployment of privacy-preserving FL with minimal utility loss.

</details>


### [28] [Crafting Adversarial Inputs for Large Vision-Language Models Using Black-Box Optimization](https://arxiv.org/abs/2601.01747)
*Jiwei Guan,Haibo Jin,Haohan Wang*

Main category: cs.CR

TL;DR: 提出基于零阶优化和同时扰动随机逼近的黑盒越狱攻击方法ZO-SPSA，针对大型视觉语言模型，无需模型内部知识即可实现高效攻击


<details>
  <summary>Details</summary>
Motivation: 现有白盒攻击方法需要完全访问模型，计算成本高且对抗样本迁移性不足，不适用于现实世界的黑盒场景，需要开发更实用的黑盒攻击方法

Method: 使用零阶优化和同时扰动随机逼近(ZO-SPSA)进行黑盒攻击，通过输入输出交互实现梯度近似，无需模型知识，模型无关且资源需求低

Result: 在InstructBLIP、LLaVA和MiniGPT-4三个模型上测试，最高攻击成功率达83.0%，对抗样本在MiniGPT-4上生成后迁移到其他模型可达64.18%成功率

Conclusion: ZO-SPSA方法证明了黑盒越狱的现实可行性，暴露了当前大型视觉语言模型安全机制的关键弱点

Abstract: Recent advancements in Large Vision-Language Models (LVLMs) have shown groundbreaking capabilities across diverse multimodal tasks. However, these models remain vulnerable to adversarial jailbreak attacks, where adversaries craft subtle perturbations to bypass safety mechanisms and trigger harmful outputs. Existing white-box attacks methods require full model accessibility, suffer from computing costs and exhibit insufficient adversarial transferability, making them impractical for real-world, black-box settings. To address these limitations, we propose a black-box jailbreak attack on LVLMs via Zeroth-Order optimization using Simultaneous Perturbation Stochastic Approximation (ZO-SPSA). ZO-SPSA provides three key advantages: (i) gradient-free approximation by input-output interactions without requiring model knowledge, (ii) model-agnostic optimization without the surrogate model and (iii) lower resource requirements with reduced GPU memory consumption. We evaluate ZO-SPSA on three LVLMs, including InstructBLIP, LLaVA and MiniGPT-4, achieving the highest jailbreak success rate of 83.0% on InstructBLIP, while maintaining imperceptible perturbations comparable to white-box methods. Moreover, adversarial examples generated from MiniGPT-4 exhibit strong transferability to other LVLMs, with ASR reaching 64.18%. These findings underscore the real-world feasibility of black-box jailbreaks and expose critical weaknesses in the safety mechanisms of current LVLMs

</details>


### [29] [Quantum AI for Cybersecurity: A hybrid Quantum-Classical models for attack path analysis](https://arxiv.org/abs/2601.02237)
*Jessica A. Sciammarelli,Waqas Ahmed*

Main category: cs.CR

TL;DR: 量子-经典混合学习在网络安全入侵检测中展现出潜力，特别是在数据稀缺时量子增强表示能提升攻击召回率和类别可分性。


<details>
  <summary>Details</summary>
Motivation: 现代网络攻击日益复杂，传统机器学习方法面临挑战，特别是在标记数据有限且特征交互高度非线性的情况下，需要探索量子计算在网络安全分析中的优势。

Method: 使用UNSW-NB15数据集，将网络流量转换为结构化特征向量。建立经典模型（逻辑回归、SVM）作为基准，同时构建量子增强管道：通过角度编码和纠缠层将经典特征映射到变分量子电路中，在CPU量子模拟器上执行，最终使用经典SVM对量子嵌入进行分类。

Result: 经典模型在大数据集上获得更高整体准确率，但量子增强表示在数据稀缺时展现出更优的攻击召回率和改进的类别可分性，表明量子特征空间能捕获浅层经典模型无法访问的复杂相关性。

Conclusion: 量子嵌入有潜力提升网络安全任务中的泛化能力和表示质量，为评估量子优势提供了可复现框架，随着量子硬件和模拟器的进步，量子计算在网络安全领域具有应用前景。

Abstract: Modern cyberattacks are increasingly complex, posing significant challenges to classical machine learning methods, particularly when labeled data is limited and feature interactions are highly non-linear. In this study we investigates the potential of hybrid quantum-classical learning to enhance feature representations for intrusion detection and explore possible quantum advantages in cybersecurity analytics. Using the UNSW-NB15 dataset, network traffic is transformed into structured feature vectors through classical preprocessing and normalization. Classical models, including Logistic Regression and Support Vector Machines with linear and RBF kernels, are evaluated on the full dataset to establish baseline performance under large-sample conditions. Simultaneously, a quantum-enhanced pipeline maps classical features into variational quantum circuits via angle encoding and entangling layers, executed on a CPU-based quantum simulator, with resulting quantum embeddings classified using a classical SVM. Experiments show that while classical models achieve higher overall accuracy with large datasets, quantum-enhanced representations demonstrate superior attack recall and improved class separability when data is scarce, suggesting that quantum feature spaces capture complex correlations inaccessible to shallow classical models. These results highlight the potential of quantum embeddings to improve generalization and representation quality in cybersecurity tasks and provide a reproducible framework for evaluating quantum advantages as quantum hardware and simulators continue to advance.

</details>


### [30] [MOZAIK: A Privacy-Preserving Analytics Platform for IoT Data Using MPC and FHE](https://arxiv.org/abs/2601.02245)
*Michiel Van Kenhove,Erik Pohle,Leonard Schild,Martin Zbudila,Merlijn Sebrechts,Filip De Turck,Bruno Volckaert,Aysajan Abidin*

Main category: cs.CR

TL;DR: MOZAIK是一个面向物联网到云场景的端到端隐私保护机密数据存储和分布式处理架构，采用加密数据计算技术确保数据在传输、存储和处理过程中始终保持加密状态。


<details>
  <summary>Details</summary>
Motivation: 物联网系统产生大量敏感数据，传统信任方法无法充分缓解云辅助物联网解决方案带来的安全和隐私风险，需要新的隐私保护方案。

Method: 提出MOZAIK架构，采用加密数据计算技术，探索两种具体技术：安全多方计算和全同态加密，实现端到端隐私保护。

Result: 概念验证实现和性能评估证明了MOZAIK系统的可行性，展示了端到端隐私保护系统相比普通明文替代方案的成本，所有组件已开源发布。

Conclusion: MOZAIK为物联网到云场景提供了可行的隐私保护解决方案，通过开源发布推动安全和隐私保护数据处理实践的发展。

Abstract: The rapid increase of Internet of Things (IoT) systems across several domains has led to the generation of vast volumes of sensitive data, presenting significant challenges in terms of storage and data analytics. Cloud-assisted IoT solutions offer storage, scalability, and computational resources, but introduce new security and privacy risks that conventional trust-based approaches fail to adequately mitigate. To address these challenges, this paper presents MOZAIK, a novel end-to-end privacy-preserving confidential data storage and distributed processing architecture tailored for IoT-to-cloud scenarios. MOZAIK ensures that data remains encrypted throughout its lifecycle, including during transmission, storage, and processing. This is achieved by employing a cryptographic privacy-enhancing technology known as computing on encrypted data (COED). Two distinct COED techniques are explored, specifically secure multi-party computation (MPC) and fully homomorphic encryption (FHE). The paper includes a comprehensive analysis of the MOZAIK architecture, including a proof-of-concept implementation and performance evaluations. The evaluation results demonstrate the feasibility of the MOZAIK system and indicate the cost of an end-to-end privacy-preserving system compared to regular plaintext alternatives. All components of the MOZAIK platform are released as open-source software alongside this publication, with the aim of advancing secure and privacy-preserving data processing practices.

</details>


### [31] [Vouchsafe: A Zero-Infrastructure Capability Graph Model for Offline Identity and Trust](https://arxiv.org/abs/2601.02254)
*Jay Kuri*

Main category: cs.CR

TL;DR: 论文提出了ZI-CG模型和Vouchsafe系统，实现无需基础设施的身份验证和信任机制，可在断网或对抗环境中工作


<details>
  <summary>Details</summary>
Motivation: 传统身份和信任系统依赖网络连接访问在线权威机构、解析器、目录和撤销服务，在灾难区域、断网环境或对抗条件下（如审查或基础设施干扰）会失效。这些系统在最需要的时候反而崩溃，导致信任无法验证。

Method: 提出了零基础设施能力图（ZI-CG）模型，将身份、委托和撤销表示为自包含的签名声明，其有效性完全通过本地确定性评估确定。进一步实现了Vouchsafe系统，使用广泛部署的原语（Ed25519、SHA-256、结构化JSON Web Tokens）构建，无需新密码学或在线服务。

Result: 证明了一个实用的、可离线验证的信任基础可以在今天仅使用评估时提供的密码学数据构建，无需依赖任何基础设施或网络连接。

Conclusion: 安全身份和信任可以在没有基础设施的情况下实现，通过自包含的签名声明和本地确定性评估，为断网和对抗环境提供了可行的解决方案。

Abstract: Modern identity and trust systems collapse in the environments where they are needed most: disaster zones, disconnected or damaged networks, and adversarial conditions such as censorship or infrastructure interference. These systems depend on functioning networks to reach online authorities, resolvers, directories, and revocation services, leaving trust unverifiable whenever communication is unavailable or untrusted. This work demonstrates that secure identity and trust are possible without such infrastructure. We introduce the Zero-Infrastructure Capability Graph (ZI-CG), a model showing that identity, delegation, and revocation can be represented as self-contained, signed statements whose validity is determined entirely by local, deterministic evaluation. We further present Vouchsafe, a complete working instantiation of this model built using widely deployed primitives including Ed25519, SHA-256, and structured JSON Web Tokens, requiring no new cryptography or online services. The results show that a practical, offline-verifiable trust substrate can be constructed today using only the cryptographic data presented at evaluation time.

</details>


### [32] [Improved Accuracy for Private Continual Cardinality Estimation in Fully Dynamic Streams via Matrix Factorization](https://arxiv.org/abs/2601.02257)
*Joel Daniel Andersson,Palak Jain,Satchit Sivakumar*

Main category: cs.CR

TL;DR: 本文提出了一种改进的差分隐私流式统计框架，通过分析差异流的ℓp敏感度向量特性，优化了动态持续观测模型中的基数估计问题，显著提升了计数不同元素、度直方图和三角形计数等任务的精度。


<details>
  <summary>Details</summary>
Motivation: 在完全动态持续观测模型中，每个时间步可能有多个更新（包含插入和删除），现有方法将基数估计问题转化为差异流的持续计数问题。但原始流的变化可能导致差异流发生多次变化，这给应用私有持续计数算法获得最优误差界带来了挑战。

Method: 通过研究差异流相关的ℓp敏感度向量并分离其特性，改进现有约简方法的精度。关键技术创新在于论证可以使用最先进的分解机制来处理具有特定特性的敏感度向量集，从而优化计数矩阵的分解机制。

Result: 该框架为计数不同元素、估计度直方图和三角形计数（在稍宽松的隐私模型下）提供了改进的误差界。通过实证和分析证明，在广泛参数范围内，改进的误差界为基数估计问题提供了显著的精度提升。

Conclusion: 本文提出了一种通用的差分隐私持续基数估计方法，通过深入分析差异流的敏感度向量特性，优化了分解机制，为流式设置中的私有统计问题提供了更精确的解决方案。

Abstract: We study differentially-private statistics in the fully dynamic continual observation model, where many updates can arrive at each time step and updates to a stream can involve both insertions and deletions of an item. Earlier work (e.g., Jain et al., NeurIPS 2023 for counting distinct elements; Raskhodnikova & Steiner, PODS 2025 for triangle counting with edge updates) reduced the respective cardinality estimation problem to continual counting on the difference stream associated with the true function values on the input stream. In such reductions, a change in the original stream can cause many changes in the difference stream, this poses a challenge for applying private continual counting algorithms to obtain optimal error bounds. We improve the accuracy of several such reductions by studying the associated $\ell_p$-sensitivity vectors of the resulting difference streams and isolating their properties.
  We demonstrate that our framework gives improved bounds for counting distinct elements, estimating degree histograms, and estimating triangle counts (under a slightly relaxed privacy model), thus offering a general approach to private continual cardinality estimation in streaming settings. Our improved accuracy stems from tight analysis of known factorization mechanisms for the counting matrix in this setting; the key technical challenge is arguing that one can use state-of-the-art factorizations for sensitivity vector sets with the properties we isolate. Empirically and analytically, we demonstrate that our improved error bounds offer a substantial improvement in accuracy for cardinality estimation problems over a large range of parameters.

</details>
