<div id=toc></div>

# Table of Contents

- [cs.CR](#cs.CR) [Total: 23]


<div id='cs.CR'></div>

# cs.CR [[Back]](#toc)

### [1] [Superpixel Attack: Enhancing Black-box Adversarial Attack with Image-driven Division Areas](https://arxiv.org/abs/2512.02062)
*Issa Oe,Keiichiro Yamamura,Hiroki Ishikura,Ryo Hamahira,Katsuki Fujisawa*

Main category: cs.CR

TL;DR: 提出Superpixel Attack方法，使用超像素代替简单矩形区域，结合多功能搜索策略，在黑盒对抗攻击中平均提升2.10%的攻击成功率。


<details>
  <summary>Details</summary>
Motivation: 深度学习模型在安全关键任务中应用广泛，但微小扰动可导致预测错误。现有黑盒对抗攻击使用简单矩形区域进行扰动修改，效果有限。需要更强大的黑盒攻击方法来开发更有效的防御机制。

Method: 提出Superpixel Attack方法：1) 使用超像素代替简单矩形区域，在颜色方差和紧凑性之间取得更好平衡；2) 提出多功能搜索策略；3) 结合超像素和多功能搜索进行对抗攻击。

Result: Superpixel Attack相比现有攻击方法平均提升2.10%的攻击成功率。该改进对于黑盒对抗攻击具有显著意义，特别是考虑到研究中使用的模型大多具有对抗鲁棒性。

Conclusion: Superpixel Attack通过使用超像素区域和多功能搜索策略，有效提升了黑盒对抗攻击的成功率，为开发更强大的防御机制提供了有价值的攻击方法。

Abstract: Deep learning models are used in safety-critical tasks such as automated driving and face recognition. However, small perturbations in the model input can significantly change the predictions. Adversarial attacks are used to identify small perturbations that can lead to misclassifications. More powerful black-box adversarial attacks are required to develop more effective defenses. A promising approach to black-box adversarial attacks is to repeat the process of extracting a specific image area and changing the perturbations added to it. Existing attacks adopt simple rectangles as the areas where perturbations are changed in a single iteration. We propose applying superpixels instead, which achieve a good balance between color variance and compactness. We also propose a new search method, versatile search, and a novel attack method, Superpixel Attack, which applies superpixels and performs versatile search. Superpixel Attack improves attack success rates by an average of 2.10% compared with existing attacks. Most models used in this study are robust against adversarial attacks, and this improvement is significant for black-box adversarial attacks. The code is avilable at https://github.com/oe1307/SuperpixelAttack.git.

</details>


### [2] [Large Language Model based Smart Contract Auditing with LLMBugScanner](https://arxiv.org/abs/2512.02069)
*Yining Yuan,Yifei Wang,Yichang Xu,Zachary Yahn,Sihao Hu,Ling Liu*

Main category: cs.CR

TL;DR: LLMBugScanner是一个基于大语言模型的智能合约漏洞检测框架，通过微调和集成学习提升检测效果。


<details>
  <summary>Details</summary>
Motivation: 现有的LLM在智能合约审计中存在局限性：不同预训练模型推理能力各异，单个模型无法在所有漏洞类型或合约结构上表现一致，即使微调后仍有不足。

Method: 结合领域知识适应和集成推理。领域知识适应：在互补数据集上微调LLMs，捕捉通用代码语义和指令引导的漏洞推理，使用参数高效调优降低计算成本。集成推理：利用多个LLMs的互补优势，应用基于共识的冲突解决策略。

Result: LLMBugScanner相比预训练和微调的单个模型，实现了准确率的持续提升和更强的泛化能力。

Conclusion: LLMBugScanner为智能合约审计提供了一个原则性、成本效益高且可扩展的框架。

Abstract: This paper presents LLMBugScanner, a large language model (LLM) based framework for smart contract vulnerability detection using fine-tuning and ensemble learning. Smart contract auditing presents several challenges for LLMs: different pretrained models exhibit varying reasoning abilities, and no single model performs consistently well across all vulnerability types or contract structures. These limitations persist even after fine-tuning individual LLMs.
  To address these challenges, LLMBugScanner combines domain knowledge adaptation with ensemble reasoning to improve robustness and generalization. Through domain knowledge adaptation, we fine-tune LLMs on complementary datasets to capture both general code semantics and instruction-guided vulnerability reasoning, using parameter-efficient tuning to reduce computational cost. Through ensemble reasoning, we leverage the complementary strengths of multiple LLMs and apply a consensus-based conflict resolution strategy to produce more reliable vulnerability assessments.
  We conduct extensive experiments across multiple popular LLMs and compare LLMBugScanner with both pretrained and fine-tuned individual models. Results show that LLMBugScanner achieves consistent accuracy improvements and stronger generalization, demonstrating that it provides a principled, cost-effective, and extensible framework for smart contract auditing.

</details>


### [3] [Deterministic Random Bit Generators Based on Ascon for Embedded Systems](https://arxiv.org/abs/2512.02082)
*Abel C. H. Chen*

Main category: cs.CR

TL;DR: 本研究基于NIST轻量级密码标准Ascon，提出了三种Ascon驱动的DRBG构造方案，在树莓派平台上实现并验证了其在嵌入式系统中的高效性和低内存占用优势。


<details>
  <summary>Details</summary>
Motivation: DRBG作为随机数生成和密码应用的基础组件，在资源受限的嵌入式系统中性能和安全性至关重要。NIST于2025年8月确立了适合资源受限嵌入式环境的Ascon轻量级密码标准，因此需要建立高性能且安全的DRBG以适应嵌入式系统设计需求。

Method: 本研究修订了DRBG标准，提出了三种Ascon驱动的构造方案：Ascon驱动的基于哈希的DRBG、Ascon驱动的密钥哈希消息认证码(HMAC) DRBG、以及Ascon驱动的计数器模式(CTR) DRBG。这些方法在树莓派平台上进行了实现。

Result: 实验结果表明，与现有的DRBG实现相比，所提出的方法具有更高的计算效率和更低的内存使用量，适合在嵌入式系统中部署。

Conclusion: 基于Ascon轻量级密码标准设计的DRBG方案能够有效满足嵌入式系统对高性能和低内存占用的需求，为资源受限环境提供了安全可靠的随机数生成解决方案。

Abstract: As the Deterministic Random Bit Generator (DRBG) serves as a fundamental component in random number generation and cryptographic applications, its performance and security are particularly critical in resource-constrained embedded systems, where memory capacity and computational efficiency are limited. Establishing a high-performance and secure DRBG is therefore an important issue for embedded system design. Furthermore, the National Institute of Standards and Technology (NIST) established the Ascon lightweight cryptographic standard in August 2025, which is suitable for use in resource-limited embedded environments. Therefore, this study revises the DRBG standard and proposes three Ascon-driven constructions: the Ascon-Driven Hash-Based DRBG, the Ascon-Driven keyed-Hash Message Authentication Code (HMAC) DRBG, and the Ascon-Driven Counter-mode (CTR) DRBG. In the experiments, these methods are implemented on a Raspberry Pi platform. The experimental results demonstrate that the proposed approaches achieve higher computational efficiency and lower memory usage compared with existing DRBG implementations, making them suitable for deployment in embedded systems.

</details>


### [4] [A survey about Hidden Subgroup Problem from a mathematical and cryptographic perspective](https://arxiv.org/abs/2512.02087)
*Simone Dutto,Pietro Mercuri,Nadir Murru,Lorenzo Romano*

Main category: cs.CR

TL;DR: 关于隐子群问题（HSP）的综述，重点讨论其在公钥密码系统安全性研究中的重要性，涵盖阿贝尔和非阿贝尔情况下的算法进展与密码学应用。


<details>
  <summary>Details</summary>
Motivation: 隐子群问题在量子计算中具有重要地位，特别是对于评估公钥密码系统的安全性。理解HSP的量子算法进展有助于分析现有密码方案的抗量子攻击能力。

Method: 首先回顾阿贝尔情况下的Kitaev算法，展示如何将经典问题（如阶计算、整数分解、离散对数）转化为阿贝尔HSP实例。然后分析非阿贝尔HSP的现状，重点讨论特定群（二面体群、对称群、半直积构造）及相关技术（傅里叶采样和黑盒方法）。

Result: 阿贝尔HSP已有高效量子算法解决，而非阿贝尔HSP尚无通用高效量子解。特定群如二面体群与最短向量问题相关，对称群与图同构问题相关，某些半直积构造与代码等价问题相关。

Conclusion: 隐子群问题是连接量子算法与密码安全性的关键桥梁。虽然阿贝尔情况已解决，但非阿贝尔HSP的复杂性为密码学提供了潜在的安全基础，需要进一步研究相关数学工具和算法技术。

Abstract: We provide a survey on the Hidden Subgroup Problem (HSP), which plays an important role in studying the security of public-key cryptosystems. We first review the abelian case, where Kitaev's algorithm yields an efficient quantum solution to the HSP, recalling how classical problems (such as order finding, integer factorization, and discrete logarithm) can be formulated as abelian HSP instances. We then examine the current state of the art for non-abelian HSP, where no general efficient quantum solution is known, focusing on some relevant groups including dihedral group (connected to the shortest vector problem), symmetric groups (connected to the graph isomorphism problem), and semidirect product constructions (connected, in a special case, to the code equivalence problem). We also describe the main techniques for addressing the HSP in non-abelian cases, namely Fourier sampling and the black-box approach. Throughout the paper, we highlight the mathematical notions required and exploited in this context, providing a cryptography-oriented perspective.

</details>


### [5] [Factor(T,U): Factored Cognition Strengthens Monitoring of Untrusted AI](https://arxiv.org/abs/2512.02157)
*Aaron Sandoval,Cody Rushing*

Main category: cs.CR

TL;DR: 论文提出基于分解认知的AI控制协议，通过可信模型分解任务、不可信模型独立解决子任务、再重组结果的方式提升AI安全性，在APPS编码环境中测试显示安全性从41%提升至63%。


<details>
  <summary>Details</summary>
Motivation: 现有AI控制协议依赖较弱监控器检测不安全行为，但在复杂任务中常因超出监控器理解能力而失败。需要开发更有效的控制协议来确保不可信AI的安全部署。

Method: 采用分解认知方法：可信模型将任务分解为子任务，不可信模型在隔离环境中独立解决每个子任务，最后将结果重组为完整解决方案。在APPS编码环境中实现协议，并使用对抗性GPT-4.1 Nano进行红队测试。

Result: 1) 在可信监控协议中加入分解认知可将安全性从41%提升至63%；2) 安全性提升主要源于监控器性能改善；3) 分解认知不会增加强大LLM在APPS中植入后门的难度；4) 当前协议在APPS中实用性较低。

Conclusion: 基于分解认知的控制协议能有效提升AI安全性，特别是在监控器性能改善方面。虽然当前在APPS环境中实用性有限，但有望在更复杂任务中发挥更大作用，为AI安全控制提供新思路。

Abstract: The field of AI Control seeks to develop robust control protocols, deployment safeguards for untrusted AI which may be intentionally subversive. However, existing protocols that rely on weaker monitors to detect unsafe behavior often fail on complex tasks beyond the monitor's comprehension. We develop control protocols based on factored cognition, in which a trusted model decomposes a task, an untrusted model solves each resultant child task in isolation, and the results are reassembled into a full solution. These protocols may improve safety by several means, such as by simplifying the context for monitors, or by obscuring vulnerabilities in the environment. We implement our protocols in the APPS coding setting and red team them against backdoor attempts from an adversarial GPT-4.1 Nano. We find that: (i) Adding factored cognition to a trusted monitoring protocol can boost safety from 41% to 63%; (ii) Safety improves because monitor performance improves; (iii) Factored cognition makes it no harder for capable LLMs to write backdoors in APPS. While our protocols show low usefulness in APPS, they hold promise for more complex tasks.

</details>


### [6] [PhishSnap: Image-Based Phishing Detection Using Perceptual Hashing](https://arxiv.org/abs/2512.02243)
*Md Abdul Ahad Minhaz,Zannatul Zahan Meem,Md. Shohrab Hossain*

Main category: cs.CR

TL;DR: PhishSnap是一个基于感知哈希的隐私保护钓鱼检测系统，通过浏览器扩展捕获网页截图并与合法模板进行视觉相似性比对，在本地完成检测以保护用户隐私。


<details>
  <summary>Details</summary>
Motivation: 钓鱼攻击利用人类信任窃取敏感凭证，现有基于URL和HTML的检测系统难以应对混淆和视觉欺骗技术，需要更有效的检测方法。

Method: 开发了PhishSnap浏览器扩展系统，使用感知哈希技术：捕获网页截图，计算视觉哈希值，与合法模板进行相似性比对来识别视觉相似的钓鱼页面。

Result: 在2024年收集的10,000个URL数据集上测试，系统达到0.79准确率、0.76精确率和0.78召回率，证明视觉相似性检测是可行的反钓鱼措施。

Conclusion: 视觉相似性检测是有效的反钓鱼方法，PhishSnap系统在本地完成推理过程，保护用户隐私并减少延迟，为钓鱼检测提供了新思路。

Abstract: Phishing remains one of the most prevalent online threats, exploiting human trust to harvest sensitive credentials. Existing URL- and HTML-based detection systems struggle against obfuscation and visual deception. This paper presents \textbf{PhishSnap}, a privacy-preserving, on-device phishing detection system leveraging perceptual hashing (pHash). Implemented as a browser extension, PhishSnap captures webpage screenshots, computes visual hashes, and compares them against legitimate templates to identify visually similar phishing attempts. A \textbf{2024 dataset of 10,000 URLs} (70\%/20\%/10\% train/validation/test) was collected from PhishTank and Netcraft. Due to security takedowns, a subset of phishing pages was unavailable, reducing dataset diversity. The system achieved \textbf{0.79 accuracy}, \textbf{0.76 precision}, and \textbf{0.78 recall}, showing that visual similarity remains a viable anti-phishing measure. The entire inference process occurs locally, ensuring user privacy and minimal latency.

</details>


### [7] [CVE Breadcrumbs: Tracking Vulnerabilities Through Versioned Apache Libraries](https://arxiv.org/abs/2512.02259)
*Derek Garcia,Briana Lee,Ibrahim Matar,David Rickards,Andrew Zilnicki*

Main category: cs.CR

TL;DR: 对Apache软件基金会生态系统进行历史安全漏洞分析，涵盖24,285个库、1,285个CVE和157个CWE，研究漏洞生命周期、披露时间线和修复实践。


<details>
  <summary>Details</summary>
Motivation: Apache生态系统支撑着大量现代软件基础设施，但其广泛使用使其成为高影响安全漏洞的主要目标（如Log4Shell事件）。尽管广泛采用，Apache项目仍存在重复和严重的安全弱点，需要系统性分析来理解漏洞模式和改进安全实践。

Method: 通过编译全面的CVE和CWE数据集，对Apache生态系统进行历史分析。研究四个关键问题：1) Apache库中最持久和重复的CWE；2) CVE在被解决前持续存在的时间；3) CVE引入与官方披露之间的延迟；4) 披露后修复CVE所需时间。分析涵盖24,285个Apache库、1,285个CVE和157个CWE。

Result: 提供了Apache库漏洞生命周期的详细时间线分析，包括漏洞持久性、披露延迟和修复时间。贡献了包含24,285个Apache库、1,285个CVE和157个CWE的精选数据集，以及实证发现和面向开发者的建议。

Conclusion: Apache生态系统存在重复的安全弱点模式，需要改进安全编码实践、漏洞监控和修复策略。研究提供了对漏洞生命周期的深入理解，并为开发者提供了改进Apache项目安全性的具体建议。

Abstract: The Apache Software Foundation (ASF) ecosystem underpins a vast portion of modern software infrastructure, powering widely used components such as Log4j, Tomcat, and Struts. However, the ubiquity of these libraries has made them prime targets for high-impact security vulnerabilities, as illustrated by incidents like Log4Shell. Despite their widespread adoption, Apache projects are not immune to recurring and severe security weaknesses. We conduct a historical analysis of the Apache ecosystem to follow the "breadcrumb trail of vulnerabilities" by compiling a comprehensive dataset of Common Vulnerabilities and Exposures (CVEs) and Common Weakness Enumerations (CWEs). We examine trends in exploit recurrence, disclosure timelines, and remediation practices. Our analysis is guided by four key research questions: (1) What are the most persistent and repeated CWEs in Apache libraries? (2) How long do CVEs persist before being addressed? (3) What is the delay between CVE introduction and official disclosure? and (4) How long after disclosure are CVEs remediated? We present a detailed timeline of vulnerability lifecycle stages across Apache libraries and offer insights to improve secure coding practices, vulnerability monitoring, and remediation strategies. Our contributions include a curated dataset covering 24,285 Apache libraries, 1,285 CVEs, and 157 CWEs, along with empirical findings and developer-focused recommendations.

</details>


### [8] [Property-Guided Cyber-Physical Reduction and Surrogation for Safety Analysis in Robotic Vehicles](https://arxiv.org/abs/2512.02270)
*Nazmus Shakib Sayom,Luis Garcia*

Main category: cs.CR

TL;DR: 提出一种通过属性引导的简化和代理执行来伪造机器人车辆系统安全属性的方法，构建轻量级代理模型以高效发现安全漏洞


<details>
  <summary>Details</summary>
Motivation: 机器人车辆系统的安全验证面临复杂性和可扩展性挑战，传统方法难以高效发现语义层面的安全漏洞

Method: 通过属性引导的简化技术，隔离与特定规范相关的控制逻辑和物理动力学，构建轻量级代理模型，结合基于轨迹分析和时序逻辑预言机的可扩展伪造方法

Result: 在包含已知安全缺陷的无人机控制系统上验证了方法有效性，代理模型以极低的仿真成本复现故障条件，属性引导的模糊测试器高效发现语义违规

Conclusion: 控制器简化与逻辑感知测试生成相结合，为信息物理系统的语义验证提供了实用且可扩展的路径

Abstract: We propose a methodology for falsifying safety properties in robotic vehicle systems through property-guided reduction and surrogate execution. By isolating only the control logic and physical dynamics relevant to a given specification, we construct lightweight surrogate models that preserve property-relevant behaviors while eliminating unrelated system complexity. This enables scalable falsification via trace analysis and temporal logic oracles.
  We demonstrate the approach on a drone control system containing a known safety flaw. The surrogate replicates failure conditions at a fraction of the simulation cost, and a property-guided fuzzer efficiently discovers semantic violations. Our results suggest that controller reduction, when coupled with logic-aware test generation, provides a practical and scalable path toward semantic verification of cyber-physical systems.

</details>


### [9] [HOT Protocol](https://arxiv.org/abs/2512.02287)
*Peter Volnov,Georgii Kuksa,Andrey Zhevlakov*

Main category: cs.CR

TL;DR: HOT协议通过MPC网络+TEE技术实现智能合约安全管理私钥，降低参与门槛，支持多链集成


<details>
  <summary>Details</summary>
Motivation: 解决智能合约安全拥有和管理私钥的问题，降低参与者的经济门槛，实现跨链密钥管理

Method: 使用多方计算（MPC）网络管理签名密钥，在可信执行环境（TEE）中运行MPC节点，结合NEAR协议作为去中心化状态层

Result: 实现了更强的安全保障，降低了参与者的经济要求，密钥管理可集成到Stellar、TON、Solana和EVM兼容网络中的任何智能合约

Conclusion: HOT协议为智能合约提供了安全的私钥管理基础设施，通过MPC+TEE技术实现了安全性和可访问性的平衡，支持跨链互操作性

Abstract: HOT Protocol provides the infrastructure that allows smart contracts to securely own and manage private keys. The Multi-Party Computation (MPC) Network manages signing keys. By running an MPC node inside a Trusted Execution Environment (TEE), the protocol achieves stronger security guarantees while lowering economic requirements for participants. The NEAR Protocol provides a decentralized and efficient state layer. Key management can be integrated with any smart contract across Stellar, TON, Solana, and EVM-compatible networks.

</details>


### [10] [Quantum Vanguard: Server Optimized Privacy Fortified Federated Intelligence for Future Vehicles](https://arxiv.org/abs/2512.02301)
*Dev Gurung,Shiva Raj Pokhrel*

Main category: cs.CR

TL;DR: vQFL是一个将量子机器学习与联邦学习结合的框架，用于解决自动驾驶车辆网络中的隐私和安全问题，通过量子密钥分发和差分隐私提供多层防御。


<details>
  <summary>Details</summary>
Motivation: 自动驾驶车辆网络面临严重的隐私和安全挑战，特别是量子计算时代即将到来，传统安全方法可能失效。同时，现代自动驾驶车队每天产生20-40TB数据，需要安全高效的处理方案。

Method: 提出vQFL框架，结合量子联邦学习、差分隐私和量子密钥分发。还提出服务器端自适应微调方法ft-VQFL。使用多种量子模型（VQC、QCNN、SamplerQNN），采用模块化设计便于与现有车辆网络集成。

Result: 在KITTI、Waymo和nuScenes数据集上的实验表明，vQFL在保持与标准QFL相当准确度的同时，显著提高了隐私保证和通信安全性。尽管增加了安全措施，但性能开销最小。

Conclusion: vQFL为量子抵抗的自动驾驶系统奠定了关键基础，能够在后量子时代安全运行，同时高效处理海量数据。其模块化设计使其成为未来智能交通基础设施的重要组成部分。

Abstract: This work presents vQFL (vehicular Quantum Federated Learning), a new framework that leverages quantum machine learning techniques to tackle key privacy and security issues in autonomous vehicular networks. Furthermore, we propose a server-side adapted fine-tuning method, ft-VQFL,to achieve enhanced and more resilient performance. By integrating quantum federated learning with differential privacy and quantum key distribution (QKD), our quantum vanguard approach creates a multi-layered defense against both classical and quantum threats while preserving model utility. Extensive experimentation with industry-standard datasets (KITTI, Waymo, and nuScenes) demonstrates that vQFL maintains accuracy comparable to standard QFL while significantly improving privacy guaranties and communication security. Our implementation using various quantum models (VQC, QCNN, and SamplerQNN) reveals minimal performance overhead despite the added security measures. This work establishes a crucial foundation for quantum-resistant autonomous vehicle systems that can operate securely in the post-quantum era while efficiently processing the massive data volumes (20-40TB/day per vehicle) generated by modern autonomous fleets. The modular design of the framework allows for seamless integration with existing vehicular networks, positioning vQFL as an essential component for future intelligent transportation infrastructure.

</details>


### [11] [COGNITION: From Evaluation to Defense against Multimodal LLM CAPTCHA Solvers](https://arxiv.org/abs/2512.02318)
*Junyu Wang,Changjia Zhu,Yuanbo Zhou,Lingyao Li,Xu He,Junjie Xiong*

Main category: cs.CR

TL;DR: MLLMs能够以低成本自动化破解视觉验证码，对识别类和低交互类验证码效果显著，但对需要精确定位、多步空间推理或跨帧一致性的验证码仍存在困难。


<details>
  <summary>Details</summary>
Motivation: 研究多模态大语言模型如何破坏视觉验证码的安全保障，识别攻击面并评估当前MLLMs对真实世界验证码的破解能力。

Method: 评估7个领先的商业和开源MLLMs在18种真实世界验证码任务类型上的表现，测量单次准确率、有限重试成功率、端到端延迟和每次破解成本，分析任务特定提示工程和少样本演示的影响。

Result: MLLMs能够以类似人类的成本和延迟可靠地解决识别导向和低交互验证码任务，而需要精细定位、多步空间推理或跨帧一致性的任务对当前模型仍然显著困难。

Conclusion: 通过分析MLLMs的推理轨迹，研究模型在特定验证码谜题上成功/失败的底层机制，并利用这些见解为选择和加强验证码任务提供防御导向指南，讨论对平台运营商部署验证码作为滥用缓解管道的影响。

Abstract: This paper studies how multimodal large language models (MLLMs) undermine the security guarantees of visual CAPTCHA. We identify the attack surface where an adversary can cheaply automate CAPTCHA solving using off-the-shelf models. We evaluate 7 leading commercial and open-source MLLMs across 18 real-world CAPTCHA task types, measuring single-shot accuracy, success under limited retries, end-to-end latency, and per-solve cost. We further analyze the impact of task-specific prompt engineering and few-shot demonstrations on solver effectiveness. We reveal that MLLMs can reliably solve recognition-oriented and low-interaction CAPTCHA tasks at human-like cost and latency, whereas tasks requiring fine-grained localization, multi-step spatial reasoning, or cross-frame consistency remain significantly harder for current models. By examining the reasoning traces of such MLLMs, we investigate the underlying mechanisms of why models succeed/fail on specific CAPTCHA puzzles and use these insights to derive defense-oriented guidelines for selecting and strengthening CAPTCHA tasks. We conclude by discussing implications for platform operators deploying CAPTCHA as part of their abuse-mitigation pipeline.Code Availability (https://anonymous.4open.science/r/Captcha-465E/).

</details>


### [12] [LeechHijack: Covert Computational Resource Exploitation in Intelligent Agent Systems](https://arxiv.org/abs/2512.02321)
*Yuanhe Zhang,Weiliu Wang,Zhenhong Zhou,Kun Wang,Jie Zhang,Li Sun,Yang Liu,Sen Su*

Main category: cs.CR

TL;DR: 本文提出了一种针对LLM代理系统的新型攻击方式——隐式毒性攻击，通过恶意MCP工具窃取计算资源，平均成功率77.25%


<details>
  <summary>Details</summary>
Motivation: MCP框架虽然促进了工具生态的发展，但其开放性和可组合性引入了对第三方工具提供商的隐式信任假设，这种信任边界可能被恶意利用而未被充分认识

Method: 提出LeechHijack攻击方法，采用两阶段机制：植入阶段在工具中嵌入看似良性的后门，利用阶段通过预定义触发器激活后门建立命令控制通道，注入额外任务窃取计算资源

Result: 在四大主流LLM家族上实现攻击，平均成功率77.25%，资源开销比基线高18.62%，证明攻击的有效性和隐蔽性

Conclusion: 研究揭示了MCP生态系统中存在的严重安全风险，迫切需要建立计算来源追溯和资源认证机制来保护这一新兴生态系统

Abstract: Large Language Model (LLM)-based agents have demonstrated remarkable capabilities in reasoning, planning, and tool usage. The recently proposed Model Context Protocol (MCP) has emerged as a unifying framework for integrating external tools into agent systems, enabling a thriving open ecosystem of community-built functionalities. However, the openness and composability that make MCP appealing also introduce a critical yet overlooked security assumption -- implicit trust in third-party tool providers. In this work, we identify and formalize a new class of attacks that exploit this trust boundary without violating explicit permissions. We term this new attack vector implicit toxicity, where malicious behaviors occur entirely within the allowed privilege scope. We propose LeechHijack, a Latent Embedded Exploit for Computation Hijacking, in which an adversarial MCP tool covertly expropriates the agent's computational resources for unauthorized workloads. LeechHijack operates through a two-stage mechanism: an implantation stage that embeds a benign-looking backdoor in a tool, and an exploitation stage where the backdoor activates upon predefined triggers to establish a command-and-control channel. Through this channel, the attacker injects additional tasks that the agent executes as if they were part of its normal workflow, effectively parasitizing the user's compute budget. We implement LeechHijack across four major LLM families. Experiments show that LeechHijack achieves an average success rate of 77.25%, with a resource overhead of 18.62% compared to the baseline. This study highlights the urgent need for computational provenance and resource attestation mechanisms to safeguard the emerging MCP ecosystem.

</details>


### [13] [AtomGraph: Tackling Atomicity Violation in Smart Contracts using Multimodal GCNs](https://arxiv.org/abs/2512.02399)
*Xiaoqi Li,Zongwei Li,Wenkai Li,Zeng Zhang,Lei Xie*

Main category: cs.CR

TL;DR: AtomGraph是一个基于图卷积网络的智能合约原子性违规检测框架，通过多模态特征学习和自适应融合机制，在准确率和F1分数上优于现有工具。


<details>
  <summary>Details</summary>
Motivation: 智能合约是区块链技术的核心组件，但原子性违规已成为潜在的安全风险。现有分析工具往往缺乏有效检测这些问题的精度，需要更精确的检测方法。

Method: 提出AtomGraph框架，利用图卷积网络进行多模态特征学习和融合：1) 从控制流图提取结构拓扑特征；2) 从操作码序列挖掘深层语义；3) 设计自适应加权融合机制动态调整各模态特征权重；4) 使用GCN在合约级别检测原子性违规。

Result: 实验评估显示AtomGraph达到96.88%的准确率和96.97%的F1分数，优于现有工具。与简单的拼接融合模型相比，F1分数提高了6.4%。

Conclusion: AtomGraph通过多模态特征学习和自适应融合机制，在智能合约原子性违规检测方面表现出色，证明了其在智能合约安全检测中的潜力。

Abstract: Smart contracts are a core component of blockchain technology and are widely deployed across various scenarios. However, atomicity violations have become a potential security risk. Existing analysis tools often lack the precision required to detect these issues effectively. To address this challenge, we introduce AtomGraph, an automated framework designed for detecting atomicity violations. This framework leverages Graph Convolutional Networks (GCN) to identify atomicity violations through multimodal feature learning and fusion. Specifically, driven by a collaborative learning mechanism, the model simultaneously learns from two heterogeneous modalities: extracting structural topological features from the contract's Control Flow Graph (CFG) and uncovering deep semantics from its opcode sequence. We designed an adaptive weighted fusion mechanism to dynamically adjust the weights of features from each modality to achieve optimal feature fusion. Finally, GCN detects graph-level atomicity violation on the contract. Comprehensive experimental evaluations demonstrate that AtomGraph achieves 96.88% accuracy and 96.97% F1 score, outperforming existing tools. Furthermore, compared to the concatenation fusion model, AtomGraph improves the F1 score by 6.4%, proving its potential in smart contract security detection.

</details>


### [14] [Characterizing Cyber Attacks against Space Infrastructures with Missing Data: Framework and Case Study](https://arxiv.org/abs/2512.02414)
*Ekzhin Ear,Jose Luis Castanon Remy,Caleb Chang,Qiren Que,Antonia Feffer,Shouhuai Xu*

Main category: cs.CR

TL;DR: 提出一个框架来表征针对太空基础设施的网络攻击，通过SPARTA和ATT&CK方法外推缺失数据，从108个攻击案例中推导出6206个攻击技术层面的太空网络杀伤链。


<details>
  <summary>Details</summary>
Motivation: 太空基础设施网络安全是一个新兴领域，但缺乏系统性的攻击数据记录。现有数据分散在媒体报道中且存在大量缺失细节（缺失数据问题），即使"低质量"的数据集也极具价值，因为太空网络安全数据稀缺且相关基础设施信息通常被政府限制披露。

Method: 提出一个包含指标的框架，利用太空攻击研究与战术分析（SPARTA）和对抗性战术、技术与常识（ATT&CK）等方法，以原则性方式外推缺失数据，重建"假设但合理"的太空网络杀伤链和攻击活动。

Result: 从108个针对太空基础设施的网络攻击中提取数据，通过外推这个包含缺失信息的"低质量"数据集，推导出6206个攻击技术层面的太空网络杀伤链。研究发现：针对太空基础设施的网络攻击日益复杂；成功保护太空段与用户段之间的链路段本可以阻止近一半的108个攻击。

Conclusion: 该框架能够有效表征现实世界中对太空基础设施的网络攻击，通过系统化方法处理缺失数据问题，为太空网络安全分析提供了有价值的工具和数据集。

Abstract: Cybersecurity of space infrastructures is an emerging topic, despite space-related cybersecurity incidents occurring as early as 1977 (i.e., hijacking of a satellite transmission signal). There is no single dataset that documents cyber attacks against space infrastructures that have occurred in the past; instead, these incidents are often scattered in media reports while missing many details, which we dub the missing-data problem. Nevertheless, even ``low-quality'' datasets containing such reports would be extremely valuable because of the dearth of space cybersecurity data and the sensitivity of space infrastructures which are often restricted from disclosure by governments. This prompts a research question: How can we characterize real-world cyber attacks against space infrastructures? In this paper, we address the problem by proposing a framework, including metrics, while also addressing the missing-data problem by leveraging methodologies such as the Space Attack Research and Tactic Analysis (SPARTA) and the Adversarial Tactics, Techniques, and Common Knowledge (ATT&CK) to ``extrapolate'' the missing data in a principled fashion. We show how the extrapolated data can be used to reconstruct ``hypothetical but plausible'' space cyber kill chains and space cyber attack campaigns that have occurred in practice. To show the usefulness of the framework, we extract data for 108 cyber attacks against space infrastructures and show how to extrapolate this ``low-quality'' dataset containing missing information to derive 6,206 attack technique-level space cyber kill chains. Our findings include: cyber attacks against space infrastructures are getting increasingly sophisticated; successful protection of the link segment between the space and user segments could have thwarted nearly half of the 108 attacks. We will make our dataset available.

</details>


### [15] [Leveraging Large Language Models to Bridge On-chain and Off-chain Transparency in Stablecoins](https://arxiv.org/abs/2512.02418)
*Yuexin Xiang,Yuchen Lei,SM Mahir Shazeed Rish,Yuanzhe Zhang,Qin Wang,Tsz Hon Yuen,Jiangshan Yu*

Main category: cs.CR

TL;DR: 提出基于LLM的自动化框架，通过文档解析和语义对齐将链上发行数据与链下披露声明连接起来，增强稳定币透明度分析


<details>
  <summary>Details</summary>
Motivation: 稳定币（如USDT、USDC）的透明度被分割在两个世界：可验证的链上痕迹和链下非结构化文本披露，两者互不连接。现有方法无法有效整合这两种异构数据源进行统一分析。

Method: 1. 使用LLM进行文档解析和语义对齐，从发行人证明中提取关键财务指标并映射到相应的链上指标；2. 在多链发行记录和披露文档中集成模型上下文协议（MCP）框架，标准化LLM对定量市场数据和定性披露叙述的访问；3. 通过统一检索和上下文对齐实现异构稳定币信息源的一致性分析。

Result: 研究发现披露数据与可验证数据之间存在系统性差距，LLM辅助分析能够增强跨模态透明度，支持DeFi中自动化、数据驱动的审计。

Conclusion: LLM能够在区块链分析中跨异构数据模态操作，量化报告与观察流通之间的差异，并检验其对跨链透明度和价格动态的影响，为DeFi提供增强的审计能力。

Abstract: Stablecoins such as USDT and USDC aspire to peg stability by coupling issuance controls with reserve attestations. In practice, however, the transparency is split across two worlds: verifiable on-chain traces and off-chain disclosures locked in unstructured text that are unconnected. We introduce a large language model (LLM)-based automated framework that bridges these two dimensions by aligning on-chain issuance data with off-chain disclosure statements. First, we propose an integrative framework using LLMs to capture and analyze on- and off-chain data through document parsing and semantic alignment, extracting key financial indicators from issuer attestations and mapping them to corresponding on-chain metrics. Second, we integrate multi-chain issuance records and disclosure documents within a model context protocol (MCP) framework that standardizes LLMs access to both quantitative market data and qualitative disclosure narratives. This framework enables unified retrieval and contextual alignment across heterogeneous stablecoin information sources and facilitates consistent analysis. Third, we demonstrate the capability of LLMs to operate across heterogeneous data modalities in blockchain analytics, quantifying discrepancies between reported and observed circulation and examining their implications for cross-chain transparency and price dynamics. Our findings reveal systematic gaps between disclosed and verifiable data, showing that LLM-assisted analysis enhances cross-modal transparency and supports automated, data-driven auditing in decentralized finance (DeFi).

</details>


### [16] [Detection of Crowdsourcing Cryptocurrency Laundering via Multi-Task Collaboration](https://arxiv.org/abs/2512.02534)
*Guang Li,Litong Sun,Jieying Zhou,Weigang Wu*

Main category: cs.CR

TL;DR: 提出MCCLD框架，首次针对稳定币众筹洗钱检测，通过交易组辅助信息和多任务图神经网络协作检测


<details>
  <summary>Details</summary>
Motivation: USDT稳定币因其稳定性、匿名性和易用性成为洗钱首选，特别是新兴的众筹洗钱模式通过招募大量普通个体分散资金，已成为重大威胁。这种洗钱交易模式多样、结构多中心，检测面临重大挑战

Method: 提出多任务协作众筹洗钱检测框架MCCLD，引入交易组作为辅助信息，采用端到端图神经网络实现洗钱交易检测和交易组检测任务的协作。通过共享分类器和共享特征编码器融合多级特征嵌入，提供丰富的交易语义和潜在组信息

Result: 在众筹洗钱和一般洗钱检测上的大量实验证明了MCCLD的有效性和泛化能力

Conclusion: 这是首个针对众筹洗钱检测的研究工作，提出的MCCLD框架通过多任务协作有效解决了众筹洗钱检测的挑战

Abstract: USDT, a stablecoin pegged to dollar, has become a preferred choice for money laundering due to its stability, anonymity, and ease of use. Notably, a new form of money laundering on stablecoins -- we refer to as crowdsourcing laundering -- disperses funds through recruiting a large number of ordinary individuals, and has rapidly emerged as a significant threat. However, due to the refined division of labor, crowdsourcing laundering transactions exhibit diverse patterns and a polycentric structure, posing significant challenges for detection. In this paper, we introduce transaction group as auxiliary information, and propose the Multi-Task Collaborative Crowdsourcing Laundering Detection (MCCLD) framework. MCCLD employs an end-to-end graph neural network to realize collaboration between laundering transaction detection and transaction group detection tasks, enhancing detection performance on diverse patterns within crowdsourcing laundering group. These two tasks are jointly optimized through a shared classifier, with a shared feature encoder that fuses multi-level feature embeddings to provide rich transaction semantics and potential group information. Extensive experiments on both crowdsourcing and general laundering demonstrate MCCLD's effectiveness and generalization. To the best of our knowledge, this is the first work on crowdsourcing laundering detection.

</details>


### [17] [Equilibrium SAT based PQC: New aegis against quantum computing](https://arxiv.org/abs/2512.02598)
*Keum-Bae Cho*

Main category: cs.CR

TL;DR: 提出一种基于多重集随机子集元素计数的公钥密码算法，具有速度快、无需大数运算、可扩展为单公钥多私钥系统且保持抗量子性的优势。


<details>
  <summary>Details</summary>
Motivation: 随着互联网和量子计算的发展，传统公钥密码算法计算复杂度不断增加，需要开发更高效且抗量子的新算法。

Method: 通过从多重集中随机抽取子集并计数元素来生成密文，然后使用可满足性问题进行数学精炼。

Result: 算法显著快于其他公钥算法，无需大数运算可在任何设备上执行，可扩展为单公钥多私钥系统且保持抗量子性。

Conclusion: 该算法为公钥密码学提供了一种高效、轻量且抗量子的新方法，具有实际应用潜力。

Abstract: Public-key cryptography algorithms have evolved towards increasing computational complexity to hide desired messages, which is accelerating with the development of the Internet and quantum computing. This paper introduces a novel public-key cryptography algorithm that generates ciphertexts by counting the number of elements in randomly extracted subsets from a multiset. After explaining the novel cryptographic concept, the process of mathematically refining it using satisfiability problems is described. The advantages of the proposed algorithm are: first, it is significantly faster than other public-key algorithms; second, it does not require big numbers, making it executable on any devices; and third, it can be easily extended into a public-key cryptosystem using a single public key and multiple private keys while maintaining quantum resistance.

</details>


### [18] [S3C2 SICP Summit 2025-06: Vulnerability Response Summit](https://arxiv.org/abs/2512.02600)
*Anna Lena Rotthaler,Simon Oberthür,Juraj Somorovsky,Kirsten Thommes,Simon Trang,Yasemin Acar,Michel Cukier,William Enck,Alexandros Kapravelos,Christian Kästner,Dominik Wermke,Laurie Williams*

Main category: cs.CR

TL;DR: 本文总结了2025年6月26日举行的漏洞响应峰会，该峰会汇集了9家公司的从业者，讨论软件供应链安全中的漏洞响应实践、挑战和协作机会。


<details>
  <summary>Details</summary>
Motivation: 近年来针对软件供应链的攻击日益增多，造成重大损失。美国和欧盟政府及行业都关注增强软件安全，包括供应链安全和漏洞响应。为了促进业界实践者之间的经验分享和协作，研究人员组织了这次峰会。

Method: 组织漏洞响应峰会，邀请9家公司的9名从业者参与。通过5个基于开放式问题的专题讨论：漏洞报告经验、漏洞发现和管理工具、组织结构和报告机制、CRA和NIS2法规准备、漏洞赏金计划。采用开放式讨论促进相互分享。

Result: 峰会促进了从业者之间的经验分享，揭示了业界在保护软件供应链（包括漏洞响应）时面临的共同挑战。讨论结果有助于形成新的协作关系。

Conclusion: 峰会成功为软件供应链安全从业者提供了分享实践经验和挑战的平台，促进了业界协作，为应对日益严峻的软件供应链安全威胁提供了实践见解。

Abstract: Recent years have shown increased cyber attacks targeting less secure elements in the software supply chain and causing significant damage to businesses and organizations. The US and EU governments and industry are equally interested in enhancing software security, including supply chain and vulnerability response. On June 26, 2025, researchers from the NSF-supported Secure Software Supply Chain Center (S3C2) and the Software Innovation Campus Paderborn (SICP) conducted a Vulnerability Response Summit with a diverse set of 9 practitioners from 9 companies. The goal of the Summit is to enable sharing between industry practitioners having practical experiences and challenges with software supply chain security, including vulnerability response, and helping to form new collaborations. We conducted five panel discussions based on open-ended questions regarding experiences with vulnerability reports, tools used for vulnerability discovery and management, organizational structures to report vulnerability response and management, preparedness and implementations for Cyber Resilience Act1 (CRA) and NIS22, and bug bounties. The open discussions enabled mutual sharing and shed light on common challenges that industry practitioners with practical experience face when securing their software supply chain, including vulnerability response. In this paper, we provide a summary of the Summit. Full panel questions can be found in the appendix.

</details>


### [19] [Semigroup action based on skew polynomial evaluation with applications to Cryptography](https://arxiv.org/abs/2512.02603)
*Daniel Camazón-Portela,Juan Antonio López-Ramos*

Main category: cs.CR

TL;DR: 提出基于斜多项式环的公开密钥交换协议，通过构造特殊子集控制非交换性，在Canetti-Krawczyk模型中实现安全


<details>
  <summary>Details</summary>
Motivation: 利用斜多项式环的非交换代数结构构建密码协议，探索如何控制非交换性以实现安全通信

Method: 引入斜多项式环在有限域上的作用，基于多项式赋值和左斜积概念，构造特殊子集T(X)控制环的非交换性，并以此构建公钥交换协议

Result: 成功构建了基于斜多项式环的公钥交换协议，该协议在Canetti-Krawczyk安全模型中被证明是安全的

Conclusion: 斜多项式环的非交换代数结构为构建安全密码协议提供了新途径，通过适当控制非交换性可以实现有效的公钥交换方案

Abstract: Through this work we introduce an action of the skew polynomial ring $\mathbb{F}_{q}\left[X; σ, δ\right]$ over $\mathbb{F}_{q}$ based on its polynomial valuation and the concept of left skew product of functions. This lead us to explore the construction of a certain subset $\mathcal{T}(X)\subset\mathbb{F}_{q}\left[X; σ, δ\right]$ that allow us to control the non-commutativity of this ring, and exploit this fact in order to build a public key exchange protocol that is secure in Canetti and Krawczyk model.

</details>


### [20] [CryptoQA: A Large-scale Question-answering Dataset for AI-assisted Cryptography](https://arxiv.org/abs/2512.02625)
*Mayar Elfares,Pascal Reisert,Tilman Dietz,Manpa Barman,Ahmed Zaki,Ralf Küsters,Andreas Bulling*

Main category: cs.CR

TL;DR: CryptoQA是首个针对密码学的大规模问答数据集，包含200多万个QA对，用于评估和训练LLMs在密码学任务上的能力。基准测试显示LLMs在需要形式推理和精确数学知识的任务上存在显著性能缺陷。


<details>
  <summary>Details</summary>
Motivation: 目前缺乏合适的数据集来评估和训练LLMs在密码学领域的深度推理和数学分析能力，而密码学任务需要复杂的推理和精确的数学知识。

Method: 创建CryptoQA数据集，包含200多万个从学术资源中提取的QA对及上下文元数据。对15个最先进的LLMs进行基准测试，评估事实准确性、数学推理、一致性、引用、反向推理和对对抗样本的鲁棒性，并提供专家评审建立黄金标准基线。

Result: LLMs在密码学任务上表现出显著性能缺陷，特别是在需要形式推理和精确数学知识的任务上。使用CryptoQA微调的LLMs在密码学任务上表现更好。

Conclusion: 迫切需要专门针对密码学研究和开发的LLM助手。CryptoQA数据集可以用于训练和改进LLMs在密码学任务上的性能。

Abstract: Large language models (LLMs) excel at many general-purpose natural language processing tasks. However, their ability to perform deep reasoning and mathematical analysis, particularly for complex tasks as required in cryptography, remains poorly understood, largely due to the lack of suitable data for evaluation and training. To address this gap, we present CryptoQA, the first large-scale question-answering (QA) dataset specifically designed for cryptography. CryptoQA contains over two million QA pairs drawn from curated academic sources, along with contextual metadata that can be used to test the cryptographic capabilities of LLMs and to train new LLMs on cryptographic tasks. We benchmark 15 state-of-the-art LLMs on CryptoQA, evaluating their factual accuracy, mathematical reasoning, consistency, referencing, backward reasoning, and robustness to adversarial samples. In addition to quantitative metrics, we provide expert reviews that qualitatively assess model outputs and establish a gold-standard baseline. Our results reveal significant performance deficits of LLMs, particularly on tasks that require formal reasoning and precise mathematical knowledge. This shows the urgent need for LLM assistants tailored to cryptography research and development. We demonstrate that, by using CryptoQA, LLMs can be fine-tuned to exhibit better performance on cryptographic tasks.

</details>


### [21] [Cybersecurity AI: The World's Top AI Agent for Security Capture-the-Flag (CTF)](https://arxiv.org/abs/2512.02654)
*Víctor Mayoral-Vilches,Luis Javier Navarrete-Lozano,Francesco Balassone,María Sanz-Gómez,Cristóbal R. J. Veas Chavez,Maite del Mundo de Torres,Vanesa Turiel*

Main category: cs.CR

TL;DR: AI安全代理在2025年主导了多个顶级CTF比赛，以极低成本击败数千人类团队，表明传统Jeopardy式CTF已被AI攻克，需转向更考验自适应推理的攻防赛制。


<details>
  <summary>Details</summary>
Motivation: 探讨AI在网络安全竞赛中的突破性表现是否意味着传统CTF竞赛已过时，以及这对安全人才评估体系的影响。

Method: 使用专门的alias1模型架构，在五个主要CTF赛事中测试AI代理性能，包括HTB的AI vs Humans、Cyber Apocalypse、Dragos OT CTF、UWSP Pointer Overflow和Neurogrid CTF showdown。

Result: CAI在多个比赛中获得第一名，在Neurogrid捕获41/45旗帜赢得5万美元大奖，在Dragos OT比精英人类团队快37%达到1万分，将10亿token推理成本从5940美元降至119美元。

Conclusion: 传统Jeopardy式CTF已被AI攻克，安全社区需紧急转向真正测试自适应推理和韧性的攻防赛制，这些能力目前仍为人类独有。

Abstract: Are Capture-the-Flag competitions obsolete? In 2025, Cybersecurity AI (CAI) systematically conquered some of the world's most prestigious hacking competitions, achieving Rank #1 at multiple events and consistently outperforming thousands of human teams. Across five major circuits-HTB's AI vs Humans, Cyber Apocalypse (8,129 teams), Dragos OT CTF, UWSP Pointer Overflow, and the Neurogrid CTF showdown-CAI demonstrated that Jeopardy-style CTFs have become a solved game for well-engineered AI agents. At Neurogrid, CAI captured 41/45 flags to claim the $50,000 top prize; at Dragos OT, it sprinted 37% faster to 10K points than elite human teams; even when deliberately paused mid-competition, it maintained top-tier rankings. Critically, CAI achieved this dominance through our specialized alias1 model architecture, which delivers enterprise-scale AI security operations at unprecedented cost efficiency and with augmented autonomy-reducing 1B token inference costs from $5,940 to just $119, making continuous security agent operation financially viable for the first time. These results force an uncomfortable reckoning: if autonomous agents now dominate competitions designed to identify top security talent at negligible cost, what are CTFs actually measuring? This paper presents comprehensive evidence of AI capability across the 2025 CTF circuit and argues that the security community must urgently transition from Jeopardy-style contests to Attack & Defense formats that genuinely test adaptive reasoning and resilience-capabilities that remain uniquely human, for now.

</details>


### [22] [Decryption thorough polynomial ambiguity: noise-enhanced high-memory convolutional codes for post-quantum cryptography](https://arxiv.org/abs/2512.02822)
*Meir Ariel*

Main category: cs.CR

TL;DR: 提出一种基于有向图解密和噪声增强高内存卷积码的后量子密码学新方法，通过随机化生成矩阵和噪声注入实现超越Classic McEliece的安全裕度，支持任意明文长度和线性时间解密。


<details>
  <summary>Details</summary>
Motivation: 现有后量子密码方案在安全裕度和设计灵活性方面存在不足，需要开发既能抵抗量子攻击又能提供更高安全裕度、更好可扩展性的新方案。

Method: 采用有向图解密噪声增强的高内存卷积码，生成随机化的生成矩阵隐藏代数结构，在解密过程中故意注入强噪声（来自多项式除法），合法接收者保持多项式时间解码而攻击者面临指数时间复杂性。

Result: 方案的安全裕度超过Classic McEliece的2^200倍，支持任意明文长度，具有线性时间解密和均匀的每比特计算成本，可通过并行有向图解码器阵列实现高效软硬件实现。

Conclusion: 该方案是稳健、可扩展且量子抵抗的公钥密码学的有力候选方案，在安全性和灵活性方面都有显著优势。

Abstract: We present a novel approach to post-quantum cryptography that employs directed-graph decryption of noise-enhanced high-memory convolutional codes. The proposed construction generates random-like generator matrices that effectively conceal algebraic structure and resist known structural attacks. Security is further reinforced by the deliberate injection of strong noise during decryption, arising from polynomial division: while legitimate recipients retain polynomial-time decoding, adversaries face exponential-time complexity. As a result, the scheme achieves cryptanalytic security margins surpassing those of Classic McEliece by factors exceeding 2^(200). Beyond its enhanced security, the method offers greater design flexibility, supporting arbitrary plaintext lengths with linear-time decryption and uniform per-bit computational cost, enabling seamless scalability to long messages. Practical deployment is facilitated by parallel arrays of directed-graph decoders, which identify the correct plaintext through polynomial ambiguity while allowing efficient hardware and software implementations. Altogether, the scheme represents a compelling candidate for robust, scalable, and quantum-resistant public-key cryptography.

</details>


### [23] [Belobog: Move Language Fuzzing Framework For Real-World Smart Contracts](https://arxiv.org/abs/2512.02918)
*Wanxu Xia,Ziqiao Kong,Zhengwei Li,Yi Lu,Pan Li,Liqun Yang,Yang Liu,Xiapu Luo,Shaohua Li*

Main category: cs.CR

TL;DR: Belobog是首个针对Move智能合约的模糊测试框架，通过类型感知的测试用例生成和符号执行，有效检测Move合约中的安全漏洞。


<details>
  <summary>Details</summary>
Motivation: Move语言虽然具有强大的静态类型系统和显式资源语义，但仍存在类型系统无法覆盖的安全漏洞。现有智能合约模糊测试工具由于Move的强类型特性，难以生成语法和语义有效的交易来测试Move合约。

Method: 1. 基于Move类型系统构建类型图；2. 根据类型图轨迹生成或变异交易，确保所有交易都是良类型的；3. 设计实现符号执行器以克服Move合约中的复杂检查。

Result: 在109个真实Move智能合约项目中，Belobog能够检测到100%的关键漏洞和79%的主要漏洞（与人工审计结果相比）。成功复现了Cetus和Nemo两个近期重大安全事件的全部利用过程。

Conclusion: Belobog是首个有效的Move智能合约模糊测试框架，通过类型感知的方法解决了现有模糊测试工具在强类型语言环境下的局限性，显著提升了Move合约的安全性验证能力。

Abstract: Move is a research-oriented programming language design for secure and verifiable smart contract development and has been widely used in managing billions of digital assets in blockchains, such as Sui and Aptos. Move features a strong static type system and explicit resource semantics to enforce safety properties such as the prevention of data races, invalid asset transfers, and entry vulnerabilities. However, smart contracts written in Move may still contain certain vulnerabilities that are beyond the reach of its type system. It is thus essential to validate Move smart contracts. Unfortunately, due to its strong type system, existing smart contract fuzzers are ineffective in producing syntactically or semantically valid transactions to test Move smart contracts. This paper introduces the first fuzzing framework, Belobog, for Move smart contracts. Belobog is type-aware and ensures that all generated and mutated transactions are well-typed. More specifically, for a target Move smart contract, Belobog first constructs a type graph based on Move's type system, and then generates or mutates a transaction based on the graph trace derived from the type graph. In order to overcome the complex checks in Move smart contracts, we further design and implement a concolic executor in Belobog. We evaluated Belobog on 109 real-world Move smart contract projects. The experimental results show that Belobog is able to detect 100\% critical and 79\% major vulnerabilities manually audited by human experts. We further selected two recent notorious incidents in Move smart contracts, i.e., Cetus and Nemo. Belobog successfully reproduced full exploits for both of them, without any prior knowledge.

</details>
