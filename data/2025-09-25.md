<div id=toc></div>

# Table of Contents

- [cs.CR](#cs.CR) [Total: 12]


<div id='cs.CR'></div>

# cs.CR [[Back]](#toc)

### [1] [Identifying and Addressing User-level Security Concerns in Smart Homes Using "Smaller" LLMs](https://arxiv.org/abs/2509.19485)
*Hafijul Hoque Chowdhury,Riad Ahmed Anonto,Sourov Jajodia,Suryadipta Majumdar,Md. Shohrab Hossain*

Main category: cs.CR

TL;DR: 该论文开发了一个针对智能家居安全问题的问答系统，通过分析论坛数据识别主要安全关切，并利用小型Transformer模型构建资源高效的解决方案。


<details>
  <summary>Details</summary>
Motivation: 智能家居用户面临安全风险，但现有信息来源复杂难懂，需要开发专门针对普通用户的简单有效的安全问答系统。

Method: 收集论坛Q&A数据，使用LDA主题建模提取安全关切，微调T5和Flan-T5等小型Transformer模型构建问答系统，并加入合成数据增强性能。

Result: 实验表明该方法显著提升了基础模型的性能，能够为智能家居用户提供准确相关的安全答案。

Conclusion: 小型Transformer模型在资源受限的智能家居环境中具有部署优势，能够有效解决用户安全关切问题。

Abstract: With the rapid growth of smart home IoT devices, users are increasingly
exposed to various security risks, as evident from recent studies. While
seeking answers to know more on those security concerns, users are mostly left
with their own discretion while going through various sources, such as online
blogs and technical manuals, which may render higher complexity to regular
users trying to extract the necessary information. This requirement does not go
along with the common mindsets of smart home users and hence threatens the
security of smart homes furthermore. In this paper, we aim to identify and
address the major user-level security concerns in smart homes. Specifically, we
develop a novel dataset of Q&A from public forums, capturing practical security
challenges faced by smart home users. We extract major security concerns in
smart homes from our dataset by leveraging the Latent Dirichlet Allocation
(LDA). We fine-tune relatively "smaller" transformer models, such as T5 and
Flan-T5, on this dataset to build a QA system tailored for smart home security.
Unlike larger models like GPT and Gemini, which are powerful but often resource
hungry and require data sharing, smaller models are more feasible for
deployment in resource-constrained or privacy-sensitive environments like smart
homes. The dataset is manually curated and supplemented with synthetic data to
explore its potential impact on model performance. This approach significantly
improves the system's ability to deliver accurate and relevant answers, helping
users address common security concerns with smart home IoT devices. Our
experiments on real-world user concerns show that our work improves the
performance of the base models.

</details>


### [2] [Knock-Knock: Black-Box, Platform-Agnostic DRAM Address-Mapping Reverse Engineering](https://arxiv.org/abs/2509.19568)
*Antoine Plin,Lorenzo Casalino,Thomas Rokicki,Ruben Salvador*

Main category: cs.CR

TL;DR: 本文提出了一种基于线性代数理论的自动化方法，用于逆向工程SoC中未公开的DRAM地址加扰函数，相比现有方法在效率和完整性上有显著提升。


<details>
  <summary>Details</summary>
Motivation: 现代SoC使用未公开的线性地址加扰函数来混淆DRAM寻址，这阻碍了DRAM感知的性能优化和安全分析（特别是Rowhammer攻击）。现有启发式方法存在部分性、成本高和不实用的问题。

Method: 在GF(2)有限域上建立线性代数模型，利用行缓冲区冲突的时间指纹特性，开发了多项式时间复杂度的噪声鲁棒算法来恢复完整的bank掩码基，并扩展到复杂行映射的自动恢复。

Result: 在嵌入式和服务器架构上的评估显示，该方法成功重构了已知映射并发现了新的加扰函数，在所有测试平台上达到99%的召回率和准确率，在500GB以上DRAM系统中仅需几分钟运行时间。

Conclusion: 该方法为DRAM逆向工程提供了自动化、理论化的准确路径，显著提升了可扩展性和实用性。

Abstract: Modern Systems-on-Chip (SoCs) employ undocumented linear address-scrambling
functions to obfuscate DRAM addressing, which complicates DRAM-aware
performance optimizations and hinders proactive security analysis of DRAM-based
attacks; most notably, Rowhammer. Although previous work tackled the issue of
reversing physical-to-DRAM mapping, existing heuristic-based
reverse-engineering approaches are partial, costly, and impractical for
comprehensive recovery. This paper establishes a rigorous theoretical
foundation and provides efficient practical algorithms for black-box, complete
physical-to-DRAM address-mapping recovery.
  We first formulate the reverse-engineering problem within a linear algebraic
model over the finite field GF(2). We characterize the timing fingerprints of
row-buffer conflicts, proving a relationship between a bank addressing matrix
and an empirically constructed matrix of physical addresses. Based on this
characterization, we develop an efficient, noise-robust, and fully
platform-agnostic algorithm to recover the full bank-mask basis in polynomial
time, a significant improvement over the exponential search from previous
works. We further generalize our model to complex row mappings, introducing new
hardware-based hypotheses that enable the automatic recovery of a row basis
instead of previous human-guided contributions.
  Evaluations across embedded and server-class architectures confirm our
method's effectiveness, successfully reconstructing known mappings and
uncovering previously unknown scrambling functions. Our method provides a 99%
recall and accuracy on all tested platforms. Most notably, Knock-Knock runs in
under a few minutes, even on systems with more than 500GB of DRAM, showcasing
the scalability of our method. Our approach provides an automated, principled
pathway to accurate DRAM reverse engineering.

</details>


### [3] [SoK: A Systematic Review of Malware Ontologies and Taxonomies and Implications for the Quantum Era](https://arxiv.org/abs/2509.19650)
*Dehinde Molade,Dave Ormrod,Mamello Thinyane,Nalin Arachchilage,Jill Slay*

Main category: cs.CR

TL;DR: 本文探讨量子恶意软件的基本性质和影响，通过系统文献综述和知识框架分析恶意行为如何转化为对量子技术的攻击，为保护关键基础设施提供防御基础。


<details>
  <summary>Details</summary>
Motivation: 量子恶意软件是真实且日益增长的安全威胁，如果被武器化或利用，将破坏由下一代量子架构支持的高度复杂的关键系统，如国防、通信、能源和太空领域。

Method: 通过系统文献综述（SLR），利用本体论和分类法等知识框架探索恶意软件，将恶意行为映射到量子技术攻击，并采用欧洲量子技术能力框架（CFQT）作为指导，将恶意软件行为映射到多个能力层。

Result: 研究提供了分析量子技术恶意软件严重性的视角，并在此新兴领域建立了基础。

Conclusion: 该研究为未来开发适当的缓解措施和防御机制提供了基础，从而保护关键基础设施免受量子恶意软件的威胁。

Abstract: The threat of quantum malware is real and a growing security concern that
will have catastrophic scientific and technological impacts, if not addressed
early. If weaponised or exploited especially by the wrong hands, malware will
undermine highly sophisticated critical systems supported by next-generation
quantum architectures, for example, in defence, communications, energy, and
space. This paper explores the fundamental nature and implications of quantum
malware to enable the future development of appropriate mitigations and
defences, thereby protecting critical infrastructure. By conducting a
systematic literature review (SLR) that draws on knowledge frameworks such as
ontologies and taxonomies to explore malware, this provides insights into how
malicious behaviours can be translated into attacks on quantum technologies,
thereby providing a lens to analyse the severity of malware against quantum
technologies. This study employs the European Competency Framework for Quantum
Technologies (CFQT) as a guide to map malware behaviour to several competency
layers, creating a foundation in this emerging field.

</details>


### [4] [Unmasking Fake Careers: Detecting Machine-Generated Career Trajectories via Multi-layer Heterogeneous Graphs](https://arxiv.org/abs/2509.19677)
*Michiharu Yamashita,Thanh Tran,Delvin Ce Zhang,Dongwon Lee*

Main category: cs.CR

TL;DR: 本文提出了一种新的检测方法CareerScape，用于识别由大语言模型生成的虚假职业轨迹，通过构建异质分层多图层框架来有效检测合成简历内容。


<details>
  <summary>Details</summary>
Motivation: 随着大语言模型的快速发展，能够生成高度逼真的合成数据，特别是在简历中生成虚假职业轨迹的新漏洞需要被有效检测。

Method: 提出CareerScape框架，构建基于真实简历的全局异质分层多图层，通过结构感知方法将用户特定子图与可信邻域信息结合，捕捉全局结构模式和局部不一致性。

Result: 实验结果显示CareerScape相对现有最优基线方法性能提升5.8-85.0%，证明了结构感知检测方法在识别机器生成内容方面的重要性。

Conclusion: 传统基于文本的检测器在结构化职业数据上表现不佳，而结构感知的CareerScape框架能有效检测机器生成的职业轨迹，为合成内容检测提供了新思路。

Abstract: The rapid advancement of Large Language Models (LLMs) has enabled the
generation of highly realistic synthetic data. We identify a new vulnerability,
LLMs generating convincing career trajectories in fake resumes and explore
effective detection methods. To address this challenge, we construct a dataset
of machine-generated career trajectories using LLMs and various methods, and
demonstrate that conventional text-based detectors perform poorly on structured
career data. We propose CareerScape, a novel heterogeneous, hierarchical
multi-layer graph framework that models career entities and their relations in
a unified global graph built from genuine resumes. Unlike conventional
classifiers that treat each instance independently, CareerScape employs a
structure-aware framework that augments user-specific subgraphs with trusted
neighborhood information from a global graph, enabling the model to capture
both global structural patterns and local inconsistencies indicative of
synthetic career paths. Experimental results show that CareerScape outperforms
state-of-the-art baselines by 5.8-85.0% relatively, highlighting the importance
of structure-aware detection for machine-generated content.

</details>


### [5] [A Set of Generalized Components to Achieve Effective Poison-only Clean-label Backdoor Attacks with Collaborative Sample Selection and Triggers](https://arxiv.org/abs/2509.19947)
*Zhixiao Wu,Yao Lu,Jie Wen,Hao Sun,Qi Zhou,Guangming Lu*

Main category: cs.CR

TL;DR: 本文提出了一种双向协作的样本选择和触发器设计方法，用于改进仅毒化无标签后门攻击的性能，通过三个组件协同提升攻击成功率和隐蔽性。


<details>
  <summary>Details</summary>
Motivation: 当前方法将样本选择和触发器设计孤立处理，导致攻击成功率和隐蔽性提升有限，且简单组合方法无法在保持泛化性的同时显著改善评估指标。

Method: 提出三个协作组件：组件A基于触发器规模确定关键选择因素组合来选择更合理的'困难'样本；组件B选择与触发器植入样本相似的样本来提升隐蔽性；组件C根据人眼视觉系统对RGB的敏感度重新分配触发器毒化强度。

Result: 该方法能够显著提高攻击成功率和隐蔽性，且所有组件可以策略性地集成到不同的仅毒化无标签后门攻击中。

Conclusion: 通过探索样本选择与触发器之间的双向协作关系，提出的组件框架有效解决了当前方法的局限性，为后门攻击提供了更优的性能表现。

Abstract: Poison-only Clean-label Backdoor Attacks aim to covertly inject
attacker-desired behavior into DNNs by merely poisoning the dataset without
changing the labels. To effectively implant a backdoor, multiple
\textbf{triggers} are proposed for various attack requirements of Attack
Success Rate (ASR) and stealthiness. Additionally, sample selection enhances
clean-label backdoor attacks' ASR by meticulously selecting ``hard'' samples
instead of random samples to poison. Current methods 1) usually handle the
sample selection and triggers in isolation, leading to severely limited
improvements on both ASR and stealthiness. Consequently, attacks exhibit
unsatisfactory performance on evaluation metrics when converted to PCBAs via a
mere stacking of methods. Therefore, we seek to explore the bidirectional
collaborative relations between the sample selection and triggers to address
the above dilemma. 2) Since the strong specificity within triggers, the simple
combination of sample selection and triggers fails to substantially enhance
both evaluation metrics, with generalization preserved among various attacks.
Therefore, we seek to propose a set of components to significantly improve both
stealthiness and ASR based on the commonalities of attacks. Specifically,
Component A ascertains two critical selection factors, and then makes them an
appropriate combination based on the trigger scale to select more reasonable
``hard'' samples for improving ASR. Component B is proposed to select samples
with similarities to relevant trigger implanted samples to promote
stealthiness. Component C reassigns trigger poisoning intensity on RGB colors
through distinct sensitivity of the human visual system to RGB for higher ASR,
with stealthiness ensured by sample selection, including Component B.
Furthermore, all components can be strategically integrated into diverse PCBAs.

</details>


### [6] [CyberSOCEval: Benchmarking LLMs Capabilities for Malware Analysis and Threat Intelligence Reasoning](https://arxiv.org/abs/2509.20166)
*Lauren Deason,Adam Bali,Ciprian Bejean,Diana Bolocan,James Crnkovich,Ioana Croitoru,Krishna Durai,Chase Midler,Calin Miron,David Molnar,Brad Moon,Bruno Ostarcevic,Alberto Peltea,Matt Rosenberg,Catalin Sandu,Arthur Saputkin,Sagar Shah,Daniel Stan,Ernest Szocs,Shengye Wan,Spencer Whitman,Sven Krasser,Joshua Saxe*

Main category: cs.CR

TL;DR: 本文介绍了CyberSOCEval，一个针对网络安全运营中心（SOC）操作评估的新开源基准套件，旨在解决现有评估方法在真实世界防御场景中的不足。


<details>
  <summary>Details</summary>
Motivation: 当前网络安全防御者面临大量安全警报和威胁情报信号的困扰，需要AI系统来增强安全运营工作。现有的大语言模型（LLM）评估方法未能充分评估与真实世界防御者最相关的场景。

Method: 在CyberSecEval 4框架内开发了CyberSOCEval基准套件，专门评估LLM在恶意软件分析和威胁情报推理两个核心防御领域的性能。

Result: 评估显示更大、更现代的LLM表现更好，证实了训练规模法则。但推理模型在测试时扩展方面未能获得与编码和数学相同的提升，表明这些模型尚未针对网络安全分析进行推理训练。

Conclusion: 当前LLM远未达到评估饱和，CyberSOCEval为AI开发者提供了改进网络防御能力的重要挑战和机会。

Abstract: Today's cyber defenders are overwhelmed by a deluge of security alerts,
threat intelligence signals, and shifting business context, creating an urgent
need for AI systems to enhance operational security work. While Large Language
Models (LLMs) have the potential to automate and scale Security Operations
Center (SOC) operations, existing evaluations do not fully assess the scenarios
most relevant to real-world defenders. This lack of informed evaluation impacts
both AI developers and those applying LLMs to SOC automation. Without clear
insight into LLM performance in real-world security scenarios, developers lack
a north star for development, and users cannot reliably select the most
effective models. Meanwhile, malicious actors are using AI to scale cyber
attacks, highlighting the need for open source benchmarks to drive adoption and
community-driven improvement among defenders and model developers. To address
this, we introduce CyberSOCEval, a new suite of open source benchmarks within
CyberSecEval 4. CyberSOCEval includes benchmarks tailored to evaluate LLMs in
two tasks: Malware Analysis and Threat Intelligence Reasoning--core defensive
domains with inadequate coverage in current benchmarks. Our evaluations show
that larger, more modern LLMs tend to perform better, confirming the training
scaling laws paradigm. We also find that reasoning models leveraging test time
scaling do not achieve the same boost as in coding and math, suggesting these
models have not been trained to reason about cybersecurity analysis, and
pointing to a key opportunity for improvement. Finally, current LLMs are far
from saturating our evaluations, showing that CyberSOCEval presents a
significant challenge for AI developers to improve cyber defense capabilities.

</details>


### [7] [STAF: Leveraging LLMs for Automated Attack Tree-Based Security Test Generation](https://arxiv.org/abs/2509.20190)
*Tanmay Khule,Stefan Marksteiner,Jose Alguindigue,Hannes Fuchs,Sebastian Fischmeister,Apurva Narayan*

Main category: cs.CR

TL;DR: STAF是一个基于LLM和RAG框架的自动化安全测试生成方法，用于从攻击树生成可执行的安全测试用例，显著提高了汽车安全测试的效率、准确性和可扩展性。


<details>
  <summary>Details</summary>
Motivation: 现代汽车开发中安全测试至关重要，但现有攻击树生成测试用例的方法劳动密集、易出错，在汽车系统测试中自动化程度有限。

Method: 利用LLM和四步自校正RAG框架，STAF自动化生成可执行安全测试用例，涵盖整个攻击面，并与自动化测试框架集成。

Result: 与通用LLM相比，STAF方法在效率、准确性和可扩展性方面有显著提升，易于集成到任何工作流程中。

Conclusion: STAF通过连接安全汽车开发过程中的两个关键要素（TARAs和验证测试），在自动化汽车安全测试方法学方面取得了实质性进展。

Abstract: In modern automotive development, security testing is critical for
safeguarding systems against increasingly advanced threats. Attack trees are
widely used to systematically represent potential attack vectors, but
generating comprehensive test cases from these trees remains a labor-intensive,
error-prone task that has seen limited automation in the context of testing
vehicular systems. This paper introduces STAF (Security Test Automation
Framework), a novel approach to automating security test case generation.
Leveraging Large Language Models (LLMs) and a four-step self-corrective
Retrieval-Augmented Generation (RAG) framework, STAF automates the generation
of executable security test cases from attack trees, providing an end-to-end
solution that encompasses the entire attack surface. We particularly show the
elements and processes needed to provide an LLM to actually produce sensible
and executable automotive security test suites, along with the integration with
an automated testing framework. We further compare our tailored approach with
general purpose (vanilla) LLMs and the performance of different LLMs (namely
GPT-4.1 and DeepSeek) using our approach. We also demonstrate the method of our
operation step-by-step in a concrete case study. Our results show significant
improvements in efficiency, accuracy, scalability, and easy integration in any
workflow, marking a substantial advancement in automating automotive security
testing methodologies. Using TARAs as an input for verfication tests, we create
synergies by connecting two vital elements of a secure automotive development
process.

</details>


### [8] [Investigating Security Implications of Automatically Generated Code on the Software Supply Chain](https://arxiv.org/abs/2509.20277)
*Xiaofan Li,Xing Gao*

Main category: cs.CR

TL;DR: 本文研究了大型语言模型（LLMs）生成代码时存在的固有安全问题对软件供应链（SSC）造成的安全威胁，识别了11种潜在威胁，并提出了相应的防御机制。


<details>
  <summary>Details</summary>
Motivation: 随着代码生成技术（如LLMs）在开发者社区的广泛应用，这些模型在生成代码时存在的虚构、错误信息和依赖过时训练数据等问题可能导致严重的软件供应链安全威胁。

Method: 设计了SSCGuard工具，基于在线收集的SSC相关问题生成439,138个提示，分析了GPT和Llama系列四个流行LLMs的响应；提出了Chain-of-Confirmation提示防御机制和基于中间件的防御方案。

Result: 研究发现所有识别的SSC相关威胁持续存在，某些威胁可能使攻击者劫持软件和工作流，而其他威胁可能导致长期安全隐患。

Conclusion: LLMs生成的代码存在显著的软件供应链安全风险，需要采取有效的防御措施来减轻这些威胁，确保软件供应链的安全性。

Abstract: In recent years, various software supply chain (SSC) attacks have posed
significant risks to the global community. Severe consequences may arise if
developers integrate insecure code snippets that are vulnerable to SSC attacks
into their products. Particularly, code generation techniques, such as large
language models (LLMs), have been widely utilized in the developer community.
However, LLMs are known to suffer from inherent issues when generating code,
including fabrication, misinformation, and reliance on outdated training data,
all of which can result in serious software supply chain threats. In this
paper, we investigate the security threats to the SSC that arise from these
inherent issues. We examine three categories of threats, including eleven
potential SSC-related threats, related to external components in source code,
and continuous integration configuration files. We find some threats in
LLM-generated code could enable attackers to hijack software and workflows,
while some others might cause potential hidden threats that compromise the
security of the software over time. To understand these security impacts and
severity, we design a tool, SSCGuard, to generate 439,138 prompts based on
SSC-related questions collected online, and analyze the responses of four
popular LLMs from GPT and Llama. Our results show that all identified
SSC-related threats persistently exist. To mitigate these risks, we propose a
novel prompt-based defense mechanism, namely Chain-of-Confirmation, to reduce
fabrication, and a middleware-based defense that informs users of various SSC
threats.

</details>


### [9] [Monitoring Violations of Differential Privacy over Time](https://arxiv.org/abs/2509.20283)
*Önder Askin,Tim Kutta,Holger Dette*

Main category: cs.CR

TL;DR: 本文提出了一种新的差分隐私持续审计方法，用于监控在开发和部署过程中可能发生变化的机制，通过利用整个部署历史信息来减少采样需求并维持审计可靠性。


<details>
  <summary>Details</summary>
Motivation: 现有差分隐私审计方法主要针对静态机制，无法有效应对在开发或部署过程中发生变化的机制。重复运行现有审计方法需要过多采样，且可靠性会随时间下降。

Method: 提出一种新的监控程序，从算法的整个部署历史中提取信息，通过利用历史数据来减少采样需求，同时保持审计结果的可靠性。

Result: 理论分析和实验验证表明，该方法对文献中的重要机制具有有效性，能够提供形式化的可靠性保证。

Conclusion: 该方法解决了持续审计差分隐私机制的关键挑战，为动态变化的隐私保护机制提供了可行的监控解决方案。

Abstract: Auditing differential privacy has emerged as an important area of research
that supports the design of privacy-preserving mechanisms. Privacy audits help
to obtain empirical estimates of the privacy parameter, to expose flawed
implementations of algorithms and to compare practical with theoretical privacy
guarantees. In this work, we investigate an unexplored facet of privacy
auditing: the sustained auditing of a mechanism that can go through changes
during its development or deployment. Monitoring the privacy of algorithms over
time comes with specific challenges. Running state-of-the-art (static) auditors
repeatedly requires excessive sampling efforts, while the reliability of such
methods deteriorates over time without proper adjustments. To overcome these
obstacles, we present a new monitoring procedure that extracts information from
the entire deployment history of the algorithm. This allows us to reduce
sampling efforts, while sustaining reliable outcomes of our auditor. We derive
formal guarantees with regard to the soundness of our methods and evaluate
their performance for important mechanisms from the literature. Our theoretical
findings and experiments demonstrate the efficacy of our approach.

</details>


### [10] [RAG Security and Privacy: Formalizing the Threat Model and Attack Surface](https://arxiv.org/abs/2509.20324)
*Atousa Arzanipour,Rouzbeh Behnia,Reza Ebrahimi,Kaushik Dutta*

Main category: cs.CR

TL;DR: 本文提出了首个针对检索增强生成(RAG)系统的正式威胁模型，建立了基于对手访问权限的分类法，并定义了关键威胁向量如文档级成员推断和数据投毒。


<details>
  <summary>Details</summary>
Motivation: RAG系统虽然能减少幻觉和提高事实一致性，但引入了不同于传统LLM的新隐私和安全挑战，目前缺乏正式的威胁模型框架。

Method: 提出了结构化的对手类型分类法，基于对手对模型组件和数据的访问权限，并正式定义了关键威胁向量。

Result: 建立了RAG系统隐私和安全性的理论基础，为更严谨和原则性的理解奠定了基础。

Conclusion: 该工作填补了RAG系统威胁建模的空白，为未来研究和实际部署中的安全防护提供了重要框架。

Abstract: Retrieval-Augmented Generation (RAG) is an emerging approach in natural
language processing that combines large language models (LLMs) with external
document retrieval to produce more accurate and grounded responses. While RAG
has shown strong potential in reducing hallucinations and improving factual
consistency, it also introduces new privacy and security challenges that differ
from those faced by traditional LLMs. Existing research has demonstrated that
LLMs can leak sensitive information through training data memorization or
adversarial prompts, and RAG systems inherit many of these vulnerabilities. At
the same time, reliance of RAG on an external knowledge base opens new attack
surfaces, including the potential for leaking information about the presence or
content of retrieved documents, or for injecting malicious content to
manipulate model behavior. Despite these risks, there is currently no formal
framework that defines the threat landscape for RAG systems. In this paper, we
address a critical gap in the literature by proposing, to the best of our
knowledge, the first formal threat model for retrieval-RAG systems. We
introduce a structured taxonomy of adversary types based on their access to
model components and data, and we formally define key threat vectors such as
document-level membership inference and data poisoning, which pose serious
privacy and integrity risks in real-world deployments. By establishing formal
definitions and attack models, our work lays the foundation for a more rigorous
and principled understanding of privacy and security in RAG systems.

</details>


### [11] [chainScale: Secure Functionality-oriented Scalability for Decentralized Resource Markets](https://arxiv.org/abs/2509.20356)
*Mohamed E. Najd,Ghada Almashaqbeh*

Main category: cs.CR

TL;DR: chainScale是一种安全混合侧链分片解决方案，旨在提升去中心化资源市场的吞吐量并降低延迟和存储占用。通过依赖侧链和功能导向的工作负载分割，实现流量处理的并行化。


<details>
  <summary>Details</summary>
Motivation: 去中心化资源市场面临严重的可扩展性问题，现有区块链扩容方案无法有效处理这些市场的工作模型和流量模式。

Method: 采用依赖侧链架构，将每个市场模块分配给一个侧链；引入分层工作负载共享和加权矿工分配技术；使用侧链同步维护主链作为系统状态唯一真相，并采用剪枝技术丢弃过时记录。

Result: 实验显示，与单侧链方案相比，chainScale将吞吐量提升4倍，确认延迟降低5倍；与分片方案相比，吞吐量提升2.5倍，延迟降低3.5倍。

Conclusion: chainScale为去中心化资源市场提供了一种有效的可扩展性解决方案，通过创新的侧链架构显著提升了系统性能。

Abstract: Decentralized resource markets are Web 3.0 applications that build
open-access platforms for trading digital resources among users without any
central management. They promise cost reduction, transparency, and flexible
service provision. However, these markets usually have large workload that must
be processed in a timely manner, leading to serious scalability problems.
Despite the large amount of work on blockchain scalability, existing solutions
are ineffective as they do not account for these markets' work models and
traffic patterns.
  We introduce chainScale, a secure hybrid sidechain-sharding solution that
aims to boost throughput of decentralized resource markets and reduce their
latency and storage footprint. At its core, chainScale leverages dependent
sidechains and functionality-oriented workload splitting to parallelize traffic
processing by having each market module assigned to a sidechain. Different from
sharding, chainScale does not incur any cross-sidechain transactions that tend
to be costly. chainScale introduces several techniques, including hierarchical
workload sharing that further sub-divides overloaded modules, and weighted
miner assignment that assigns miners with vested interest in the system to
critical modules' sidechains. Furthermore, chainScale employs sidechain syncing
to maintain the mainchain as the single truth of system state, and pruning to
discard stale records. Beside analyzing security, we build a proof-of-concept
implementation for a distributed file storage market as a use case. Our
experiments show that, compared to a single sidechain-based prior solution,
chainScale boosts throughput by 4x and reduces confirmation latency by 5x.
Also, they show that chainScale outperforms sharding by 2.5x in throughput and
3.5x in latency.

</details>


### [12] [FlyTrap: Physical Distance-Pulling Attack Towards Camera-based Autonomous Target Tracking Systems](https://arxiv.org/abs/2509.20362)
*Shaoyuan Xie,Mohamad Habib Fakih,Junchi Lu,Fayzah Alshammari,Ningfei Wang,Takami Sato,Halima Bouzidi,Mohammad Abdullah Al Faruque,Qi Alfred Chen*

Main category: cs.CR

TL;DR: 本文提出了一种针对自主目标跟踪（ATT）系统的新型距离牵引攻击（DPA）和FlyTrap攻击框架，利用对抗性雨伞作为攻击载体，能够危险地减少跟踪距离，导致无人机被捕获、易受传感器攻击或物理碰撞。


<details>
  <summary>Details</summary>
Motivation: ATT系统（特别是ATT无人机）在监控、边境控制等应用中广泛使用，但也可能被滥用于跟踪和破坏行为，因此ATT系统的安全性对实际应用至关重要。

Method: 提出FlyTrap攻击框架，采用对抗性雨伞作为可部署的领域特定攻击向量，通过渐进式距离牵引策略和可控时空一致性设计，在真实世界设置中操纵ATT无人机。

Result: 评估结果显示FlyTrap能够将跟踪距离减少到可被捕获、传感器攻击甚至直接坠毁的范围，突显了ATT系统的严重安全风险。

Conclusion: 这项研究揭示了ATT系统存在的紧急安全风险，对ATT系统的安全部署具有重要的实际意义。

Abstract: Autonomous Target Tracking (ATT) systems, especially ATT drones, are widely
used in applications such as surveillance, border control, and law enforcement,
while also being misused in stalking and destructive actions. Thus, the
security of ATT is highly critical for real-world applications. Under the
scope, we present a new type of attack: distance-pulling attacks (DPA) and a
systematic study of it, which exploits vulnerabilities in ATT systems to
dangerously reduce tracking distances, leading to drone capturing, increased
susceptibility to sensor attacks, or even physical collisions. To achieve these
goals, we present FlyTrap, a novel physical-world attack framework that employs
an adversarial umbrella as a deployable and domain-specific attack vector.
FlyTrap is specifically designed to meet key desired objectives in attacking
ATT drones: physical deployability, closed-loop effectiveness, and
spatial-temporal consistency. Through novel progressive distance-pulling
strategy and controllable spatial-temporal consistency designs, FlyTrap
manipulates ATT drones in real-world setups to achieve significant system-level
impacts. Our evaluations include new datasets, metrics, and closed-loop
experiments on real-world white-box and even commercial ATT drones, including
DJI and HoverAir. Results demonstrate FlyTrap's ability to reduce tracking
distances within the range to be captured, sensor attacked, or even directly
crashed, highlighting urgent security risks and practical implications for the
safe deployment of ATT systems.

</details>
