<div id=toc></div>

# Table of Contents

- [cs.CR](#cs.CR) [Total: 25]


<div id='cs.CR'></div>

# cs.CR [[Back]](#toc)

### [1] [Towards Trustworthy Agentic IoEV: AI Agents for Explainable Cyberthreat Mitigation and State Analytics](https://arxiv.org/abs/2509.12233)
*Meryem Malak Dif,Mouhamed Amine Bouchiha,Abdelaziz Amara Korba,Yacine Ghamri-Doudane*

Main category: cs.CR

TL;DR: 提出了一个面向电动汽车物联网的智能AI框架，通过多智能体协作实现自主威胁缓解、鲁棒分析和可解释决策支持，显著提升了安全性和预测准确性。


<details>
  <summary>Details</summary>
Motivation: 电动汽车物联网面临网络攻击、电池状态预测不可靠和决策过程不透明等挑战，这些因素削弱了系统信任和性能，需要新的解决方案。

Method: 设计了包含专用智能体的AAI架构：充电站网络威胁检测响应、实时SoC估计、SoH异常检测，通过可解释推理层协调；开发了可解释威胁缓解机制；提出了基于连续学习和对抗感知的鲁棒SoC/SoH模型；实现了三智能体流水线，使用LLM驱动推理和动态工具调用。

Result: 通过全面的电动汽车物联网场景实验验证，在安全性和预测准确性方面取得了显著改进。

Conclusion: 该框架有效解决了电动汽车物联网的安全和信任问题，所有数据集、模型和代码将公开发布，为行业提供了实用的解决方案。

Abstract: The Internet of Electric Vehicles (IoEV) envisions a tightly coupled
ecosystem of electric vehicles (EVs), charging infrastructure, and grid
services, yet it remains vulnerable to cyberattacks, unreliable battery-state
predictions, and opaque decision processes that erode trust and performance. To
address these challenges, we introduce a novel Agentic Artificial Intelligence
(AAI) framework tailored for IoEV, where specialized agents collaborate to
deliver autonomous threat mitigation, robust analytics, and interpretable
decision support. Specifically, we design an AAI architecture comprising
dedicated agents for cyber-threat detection and response at charging stations,
real-time State of Charge (SoC) estimation, and State of Health (SoH) anomaly
detection, all coordinated through a shared, explainable reasoning layer;
develop interpretable threat-mitigation mechanisms that proactively identify
and neutralize attacks on both physical charging points and learning
components; propose resilient SoC and SoH models that leverage continuous and
adversarial-aware learning to produce accurate, uncertainty-aware forecasts
with human-readable explanations; and implement a three-agent pipeline, where
each agent uses LLM-driven reasoning and dynamic tool invocation to interpret
intent, contextualize tasks, and execute formal optimizations for user-centric
assistance. Finally, we validate our framework through comprehensive
experiments across diverse IoEV scenarios, demonstrating significant
improvements in security and prediction accuracy. All datasets, models, and
code will be released publicly.

</details>


### [2] [Secure Human Oversight of AI: Exploring the Attack Surface of Human Oversight](https://arxiv.org/abs/2509.12290)
*Jonas C. Ditz,Veronika Lazar,Elmar Lichtmeß,Carola Plesch,Matthias Heck,Kevin Baum,Markus Langer*

Main category: cs.CR

TL;DR: 本文提出AI人工监督存在安全漏洞，可能成为新的攻击面，需要从网络安全角度分析攻击向量并制定加固策略。


<details>
  <summary>Details</summary>
Motivation: 现有关于AI人工监督的讨论主要关注其有效性，但忽视了安全维度。人工监督可能成为AI安全、安保和问责架构中的新攻击面。

Method: 从网络安全视角分析威胁有效人工监督要求的攻击向量，包括针对AI系统、监督人员通信以及监督人员本身的攻击，并制定相应的加固策略。

Result: 识别了人工监督可能面临的多类攻击向量，提出了相应的安全加固策略，为安全的人工AI监督提供了框架。

Conclusion: 必须将安全维度纳入AI人工监督的设计和实施中，通过网络安全方法确保人工监督的有效性和安全性，防止其成为新的攻击入口。

Abstract: Human oversight of AI is promoted as a safeguard against risks such as
inaccurate outputs, system malfunctions, or violations of fundamental rights,
and is mandated in regulation like the European AI Act. Yet debates on human
oversight have largely focused on its effectiveness, while overlooking a
critical dimension: the security of human oversight. We argue that human
oversight creates a new attack surface within the safety, security, and
accountability architecture of AI operations. Drawing on cybersecurity
perspectives, we analyze attack vectors that threaten the requirements of
effective human oversight, thereby undermining the safety of AI operations.
Such attacks may target the AI system, its communication with oversight
personnel, or the personnel themselves. We then outline hardening strategies to
mitigate these risks. Our contributions are: (1) introducing a security
perspective on human oversight, and (2) providing an overview of attack vectors
and hardening strategies to enable secure human oversight of AI.

</details>


### [3] [Collaborative P4-SDN DDoS Detection and Mitigation with Early-Exit Neural Networks](https://arxiv.org/abs/2509.12291)
*Ouassim Karrakchou,Alaa Zniber,Anass Sebbar,Mounir Ghogho*

Main category: cs.CR

TL;DR: 提出了一种结合P4可编程数据平面和SDN控制平面的协作架构，使用分裂早期退出神经网络实现实时DDoS检测，在数据平面进行部分推理，复杂流量交由控制平面深度分析。


<details>
  <summary>Details</summary>
Motivation: DDoS攻击对网络安全构成持续威胁，需要及时且可扩展的缓解策略。传统方法难以同时满足高速检测和深度分析的需求。

Method: 采用分裂早期退出神经网络架构：在P4数据平面使用量化CNN进行部分推理，不确定的案例交由控制平面的GRU模块处理。这种设计支持线速高速分类，同时能够将复杂流量升级进行更深层次分析。

Result: 使用真实DDoS数据集进行实验评估，该方法实现了高检测精度，同时显著降低了推理延迟和控制平面开销。

Conclusion: 紧密耦合的ML-P4-SDN系统具有高效、自适应和低延迟DDoS防御的潜力，为实时网络安全防护提供了新思路。

Abstract: Distributed Denial of Service (DDoS) attacks pose a persistent threat to
network security, requiring timely and scalable mitigation strategies. In this
paper, we propose a novel collaborative architecture that integrates a
P4-programmable data plane with an SDN control plane to enable real-time DDoS
detection and response. At the core of our approach is a split early-exit
neural network that performs partial inference in the data plane using a
quantized Convolutional Neural Network (CNN), while deferring uncertain cases
to a Gated Recurrent Unit (GRU) module in the control plane. This design
enables high-speed classification at line rate with the ability to escalate
more complex flows for deeper analysis. Experimental evaluation using
real-world DDoS datasets demonstrates that our approach achieves high detection
accuracy with significantly reduced inference latency and control plane
overhead. These results highlight the potential of tightly coupled ML-P4-SDN
systems for efficient, adaptive, and low-latency DDoS defense.

</details>


### [4] [Amulet: a Python Library for Assessing Interactions Among ML Defenses and Risks](https://arxiv.org/abs/2509.12386)
*Asim Waheed,Vasisht Duddu,Rui Zhang,Sebastian Szyller,N. Asokan*

Main category: cs.CR

TL;DR: AMULET是一个Python库，用于评估机器学习模型防御措施之间的意外交互作用，涵盖安全、隐私和公平性风险。


<details>
  <summary>Details</summary>
Motivation: 机器学习模型面临安全、隐私和公平性风险，现有防御措施可能无意中影响对其他无关风险的敏感性，需要系统化评估工具。

Method: 开发模块化的Python库，包含代表性攻击、防御和评估指标，提供用户友好的API接口，支持扩展新模块。

Result: AMULET库满足全面性、可扩展性、一致性和适用性要求，可用于评估先前未探索的意外交互作用。

Conclusion: AMULET为从业者提供大规模评估工具，为研究者设计无副作用防御措施提供支持，符合即将出台的ML监管框架要求。

Abstract: ML models are susceptible to risks to security, privacy, and fairness.
Several defenses are designed to protect against their intended risks, but can
inadvertently affect susceptibility to other unrelated risks, known as
unintended interactions. Several jurisdictions are preparing ML regulatory
frameworks that require ML practitioners to assess the susceptibility of ML
models to different risks. A library for valuating unintended interactions that
can be used by (a) practitioners to evaluate unintended interactions at scale
prior to model deployment and (b) researchers to design defenses which do not
suffer from an unintended increase in unrelated risks. Ideally, such a library
should be i) comprehensive by including representative attacks, defenses and
metrics for different risks, ii) extensible to new modules due to its modular
design, iii) consistent with a user-friendly API template for inputs and
outputs, iv) applicable to evaluate previously unexplored unintended
interactions. We present AMULET, a Python library that covers risks to
security, privacy, and fairness, which satisfies all these requirements. AMULET
can be used to evaluate unexplored unintended interactions, compare
effectiveness between defenses or attacks, and include new attacks and
defenses.

</details>


### [5] [Redefining Website Fingerprinting Attacks With Multiagent LLMs](https://arxiv.org/abs/2509.12462)
*Chuxu Song,Dheekshith Dev Manohar Mekala,Hao Wang,Richard Martin*

Main category: cs.CR

TL;DR: 网站指纹识别(WFP)在现代网络环境中面临泛化挑战，传统方法对单页面应用和脚本化浏览器流量效果不佳。研究提出使用LLM代理生成连续流量段的新范式，相比人工收集成本降低3-5倍，将模型准确率从10%提升至80%+。


<details>
  <summary>Details</summary>
Motivation: 传统网站指纹识别方法无法适应现代网络环境，特别是单页面应用(SPAs)打破了离散页面范式，脚本化浏览器缺乏真实用户行为多样性。用户行为的熵特性使得WFP问题比预想的更复杂，需要更大、更多样化的数据集。

Method: 提出新范式：放弃会话边界，采用连续流量段；开发可扩展的数据生成管道，使用大型语言模型(LLM)代理模拟真实、角色驱动的浏览行为；多代理系统协调决策和浏览器交互。

Result: 在20个现代网站、30个真实用户流量上评估9个最先进WFP模型：脚本化流量训练时准确率低于10%；LLM生成流量将准确率提升至80%范围，显示出对真实流量的强泛化能力。

Conclusion: 现代WFP中模型性能越来越受数据质量限制，可扩展的、语义基础合成的流量对于捕捉真实用户行为复杂性至关重要，LLM生成流量是解决数据瓶颈的有效方案。

Abstract: Website Fingerprinting (WFP) uses deep learning models to classify encrypted
network traffic to infer visited websites. While historically effective, prior
methods fail to generalize to modern web environments. Single-page applications
(SPAs) eliminate the paradigm of websites as sets of discrete pages,
undermining page-based classification, and traffic from scripted browsers lacks
the behavioral richness seen in real user sessions. Our study reveals that
users exhibit highly diverse behaviors even on the same website, producing
traffic patterns that vary significantly across individuals. This behavioral
entropy makes WFP a harder problem than previously assumed and highlights the
need for larger, more diverse, and representative datasets to achieve robust
performance. To address this, we propose a new paradigm: we drop
session-boundaries in favor of contiguous traffic segments and develop a
scalable data generation pipeline using large language models (LLM) agents.
These multi-agent systems coordinate decision-making and browser interaction to
simulate realistic, persona-driven browsing behavior at 3--5x lower cost than
human collection. We evaluate nine state-of-the-art WFP models on traffic from
20 modern websites browsed by 30 real users, and compare training performance
across human, scripted, and LLM-generated datasets. All models achieve under
10\% accuracy when trained on scripted traffic and tested on human data. In
contrast, LLM-generated traffic boosts accuracy into the 80\% range,
demonstrating strong generalization to real-world traces. Our findings indicate
that for modern WFP, model performance is increasingly bottlenecked by data
quality, and that scalable, semantically grounded synthetic traffic is
essential for capturing the complexity of real user behavior.

</details>


### [6] [QKD Oracles for Authenticated Key Exchange](https://arxiv.org/abs/2509.12478)
*Kathrin Hövelmanns,Daan Planken,Christian Schaffner,Sebastian R. Verschoor*

Main category: cs.CR

TL;DR: 本文分析了结合后量子认证密钥交换(AKE)和量子密钥分发(QKD)的安全协议，发现了现有安全模型在处理QKD密钥ID时的漏洞，提出了新的QKD预言机模型，并在CK+模型中证明了新混合协议的安全性。


<details>
  <summary>Details</summary>
Motivation: 结合后量子AKE和QKD可以提供量子攻击防护，但现有安全分析在处理QKD密钥ID方面存在缺陷，可能导致依赖密钥攻击。

Method: 将QKD建模为类似ETSI 014标准的预言机接口，集成到CK+安全模型中，设计并分析结合QKD和三重KEM握手的新协议。

Result: 发现了QKD密钥ID处理不当导致的依赖密钥攻击漏洞，提出了首个可证明安全且保持QKD信息论安全性的混合协议。

Conclusion: 通过适当的QKD建模和安全分析，可以构建既抵抗量子攻击又保持信息论安全性的混合密钥交换协议。

Abstract: Authenticated Key Exchange (AKE) establishes shared ('symmetric')
cryptographic keys which are essential for secure online communication. AKE
protocols can be constructed from public-key cryptography like Key
Encapsulation Mechanisms (KEMs). Another approach is to use Quantum Key
Distribution (QKD) to establish a symmetric key, which uses quantum
communication. Combining post-quantum AKE and QKD appropriately may provide
security against quantum attacks even if only one of the two approaches turns
out to be secure.
  We provide an extensive review of existing security analyses for combined AKE
and their formal security models, and identify some gaps in their treatment of
QKD key IDs. In particular, improper handling of QKD key IDs leads to
Dependent-Key attacks on AKE.
  As our main conceptual contribution, we model QKD as an oracle that closely
resembles the standard ETSI 014 QKD interface. We demonstrate the usability of
our QKD oracle for cryptographic security analyses by integrating it into a
prominent security model for AKE, called CK+ model, thereby obtaining a
security model for combined AKE that catches Dependent-Key attacks. In this
model, we formally prove security of a new protocol that combines QKD with a
triple-KEM handshake. This is the first provably secure hybrid protocol that
maintains information-theoretic security of QKD.

</details>


### [7] [Towards Closing the Performance Gap for Cryptographic Kernels Between CPUs and Specialized Hardware](https://arxiv.org/abs/2509.12494)
*Naifeng Zhang,Sophia Fu,Franz Franchetti*

Main category: cs.CR

TL;DR: 该论文通过优化x86 CPU的标量实现和SIMD指令，显著提升了密码学内核性能，并提出了MQX扩展指令集，使服务器级CPU能够接近ASIC的性能水平


<details>
  <summary>Details</summary>
Motivation: 解决CPU与专用硬件在密码学内核性能上的差距，特别是针对大整数算术运算的密码学工作负载

Method: 开发优化的标量实现，利用AVX2和AVX-512 SIMD指令，提出MQX扩展指令集（仅需3条新指令），并进行屋顶线分析

Result: NTT和BLAS操作分别实现38倍和62倍加速，单个CPU核心相对于ASIC的延迟降低至35倍，服务器级CPU可接近ASIC性能

Conclusion: 通过SIMD优化和MQX扩展指令集，CPU能够在密码学工作负载上显著缩小与专用硬件的性能差距

Abstract: Specialized hardware like application-specific integrated circuits (ASICs)
remains the primary accelerator type for cryptographic kernels based on large
integer arithmetic. Prior work has shown that commodity and server-class GPUs
can achieve near-ASIC performance for these workloads. However, achieving
comparable performance on CPUs remains an open challenge. This work
investigates the following question: How can we narrow the performance gap
between CPUs and specialized hardware for key cryptographic kernels like basic
linear algebra subprograms (BLAS) operations and the number theoretic transform
(NTT)?
  To this end, we develop an optimized scalar implementation of these kernels
for x86 CPUs at the per-core level. We utilize SIMD instructions (specifically
AVX2 and AVX-512) to further improve performance, achieving an average speedup
of 38 times and 62 times over state-of-the-art CPU baselines for NTTs and BLAS
operations, respectively. To narrow the gap further, we propose a small AVX-512
extension, dubbed multi-word extension (MQX), which delivers substantial
speedup with only three new instructions and minimal proposed hardware
modifications. MQX cuts the slowdown relative to ASICs to as low as 35 times on
a single CPU core. Finally, we perform a roofline analysis to evaluate the peak
performance achievable with MQX when scaled across an entire multi-core CPU.
Our results show that, with MQX, top-tier server-grade CPUs can approach the
performance of state-of-the-art ASICs for cryptographic workloads.

</details>


### [8] [Exploiting Timing Side-Channels in Quantum Circuits Simulation Via ML-Based Methods](https://arxiv.org/abs/2509.12535)
*Ben Dong,Hui Feng,Qian Wang*

Main category: cs.CR

TL;DR: 本文提出了一种针对云端量子模拟器的新型时序侧信道攻击，恶意进程可以通过观察执行时序模式来推断并识别并发运行的量子电路，实验显示识别率可达88%到99.9%


<details>
  <summary>Details</summary>
Motivation: 随着量子计算的发展，量子电路模拟器在云端平台部署，用户提交专有电路设计进行模拟。当前缺乏对这类模拟器安全风险的研究，特别是时序侧信道攻击的潜在威胁

Method: 使用QASMBench基准测试套件系统分析模拟器行为，分析不同电路执行时的时序和内存特征。采用模式识别技术对时序特征进行分类识别

Result: 实验结果表明时序特征呈现电路依赖性模式，能够有效分类识别量子电路。在不同数据集上实现了88%到99.9%的电路识别率

Conclusion: 这项工作揭示了量子模拟环境中先前未被探索的安全风险，呼吁需要更强的隔离机制来保护用户工作负载的机密性

Abstract: As quantum computing advances, quantum circuit simulators serve as critical
tools to bridge the current gap caused by limited quantum hardware
availability. These simulators are typically deployed on cloud platforms, where
users submit proprietary circuit designs for simulation. In this work, we
demonstrate a novel timing side-channel attack targeting cloud-based quantum
simulators. A co-located malicious process can observe fine-grained execution
timing patterns to extract sensitive information about concurrently running
quantum circuits. We systematically analyze simulator behavior using the
QASMBench benchmark suite, profiling timing and memory characteristics across
various circuit executions. Our experimental results show that timing profiles
exhibit circuit-dependent patterns that can be effectively classified using
pattern recognition techniques, enabling the adversary to infer circuit
identities and compromise user confidentiality. We were able to achieve 88% to
99.9% identification rate of quantum circuits based on different datasets. This
work highlights previously unexplored security risks in quantum simulation
environments and calls for stronger isolation mechanisms to protect user
workloads

</details>


### [9] [Yet Another Watermark for Large Language Models](https://arxiv.org/abs/2509.12574)
*Siyuan Bao,Ying Shi,Zhiguang Yang,Hanzhou Wu,Xinpeng Zhang*

Main category: cs.CR

TL;DR: 提出了一种新的大语言模型水印框架，通过操作LLM内部参数嵌入水印，无需访问模型即可从生成文本中提取，在保持语义质量的同时平衡了水印的鲁棒性和不可感知性。


<details>
  <summary>Details</summary>
Motivation: 现有LLM水印方法主要通过调整token采样预测或后处理嵌入水印，缺乏与LLM的内在耦合，可能显著降低生成标记文本的语义质量。传统基于训练或微调的水印方法要么局限于白盒场景，要么因LLM参数量巨大而耗时严重。

Method: 通过操纵LLM的内部参数来嵌入水印，水印可以与LLM的内在参数纠缠，实现黑盒场景下的水印提取，计算效率高。

Result: 实验结果表明该方法具有可行性、优越性和实用性，在保持文本语义质量的同时，更好地平衡了水印的鲁棒性和不可感知性。

Conclusion: 这项工作提供了一个不同于主流研究的新视角，可能为未来研究提供启示，特别是在黑盒场景下实现高效水印嵌入和提取方面。

Abstract: Existing watermarking methods for large language models (LLMs) mainly embed
watermark by adjusting the token sampling prediction or post-processing,
lacking intrinsic coupling with LLMs, which may significantly reduce the
semantic quality of the generated marked texts. Traditional watermarking
methods based on training or fine-tuning may be extendable to LLMs. However,
most of them are limited to the white-box scenario, or very time-consuming due
to the massive parameters of LLMs. In this paper, we present a new watermarking
framework for LLMs, where the watermark is embedded into the LLM by
manipulating the internal parameters of the LLM, and can be extracted from the
generated text without accessing the LLM. Comparing with related methods, the
proposed method entangles the watermark with the intrinsic parameters of the
LLM, which better balances the robustness and imperceptibility of the
watermark. Moreover, the proposed method enables us to extract the watermark
under the black-box scenario, which is computationally efficient for use.
Experimental results have also verified the feasibility, superiority and
practicality. This work provides a new perspective different from mainstream
works, which may shed light on future research.

</details>


### [10] [Secure and Efficient Out-of-band Call Metadata Transmission](https://arxiv.org/abs/2509.12582)
*David Adei,Varun Madathil,Nithin Shyam S.,Bradley Reaves*

Main category: cs.CR

TL;DR: Sidecar是一个分布式隐私保护系统，通过安全带外信令扩展STIR/SHAKEN框架到所有电话网络技术，解决现有方案隐私泄露问题


<details>
  <summary>Details</summary>
Motivation: 现有STIR/SHAKEN框架无法保护非VoIP基础设施的隐私，会将敏感元数据以明文广播给第三方，缺乏数据请求验证和过期机制

Method: 设计新颖的可扩展协议，实现安全带外信令，在通用可组合框架内证明安全性，并提供开源参考实现

Result: Sidecar保护用户身份和提供商商业秘密，保证记录过期，降低资源需求，提供相同呼叫建立时间，支持按使用付费计费

Conclusion: Sidecar是优于现有方案的转型工具，可改造碎片化全球电话系统，支持更强的呼叫认证和品牌呼叫等未来改进

Abstract: The STIR/SHAKEN (S/S) attestation Framework mandated by the United States,
Canada, and France to combat pervasive telephone abuse has not achieved its
goals, partly because legacy non-VoIP infrastructure could not participate. The
industry solution to extend S/S broadcasts sensitive metadata of every non-VoIP
call in plaintext to every third party required to facilitate the system. It
has no mechanism to determine whether a provider's request for call data is
appropriate, nor can it ensure that every copy of that call data is unavailable
after its specified expiration. It threatens subscriber privacy and provider
confidentiality.
  In this paper, we present Sidecar, a distributed, privacy-preserving system
with tunable decentralization that securely extends S/S across all telephone
network technologies. We introduce the notion of secure out-of-band signaling
for telephony and formalize its system and security requirements. We then
design novel, scalable protocols that realize these requirements and prove
their security within the Universal Composability framework. Finally, we
demonstrate Sidecar's efficiency with our open-sourced reference
implementation. Compared to the current solution, Sidecar 1) protects the
confidentiality of subscriber identity and provider trade secrets, 2)
guarantees record expiration as long as a single node handling a record is
honest, 3) reduces resource requirements while providing virtually identical
call-setup times and equivalent or better uptimes, and 4) enables secure
pay-per-use billing and integrates mechanisms to mitigate and detect
misbehavior. Moreover, Sidecar can be extended to provide the same security
guarantees for arbitrary call metadata. Not only is Sidecar a superior
approach, it is also a transformative tool to retrofit fragmented global
telephony and enable future improvements, such as stronger call authentication
and Branded Calling.

</details>


### [11] [A Systematic Evaluation of Parameter-Efficient Fine-Tuning Methods for the Security of Code LLMs](https://arxiv.org/abs/2509.12649)
*Kiho Lee,Jungkon Kim,Doowon Kim,Hyoungshick Kim*

Main category: cs.CR

TL;DR: 本文系统评估了7种参数高效微调(PEFT)技术对代码生成LLM安全性的影响，发现提示调优(prompt-tuning)是最有效的方法，在CodeGen2 16B模型上将安全代码生成率从67.28%提升至80.86%，结合温度采样策略可进一步提升至87.65%。


<details>
  <summary>Details</summary>
Motivation: 代码生成大语言模型虽然加速了软件开发，但频繁生成不安全代码带来了严重安全风险，需要找到有效方法来提升生成代码的安全性而不损害功能性。

Method: 使用7种不同的参数高效微调(PEFT)技术进行实验，包括提示调优、前缀调优等方法，并在CodeGen2 16B等模型上进行评估，同时测试了不同解码策略（如温度采样）的影响。

Result: 提示调优表现最佳，安全代码生成率提升13.5个百分点，每百万生成代码减少约203,700个漏洞片段。前缀调优和提示调优还增强了模型对投毒攻击的鲁棒性，在TrojanPuzzle评估中表现良好。

Conclusion: 研究为使用LLM构建更具弹性的软件系统提供了重要见解和实践指导，提示调优在Python和Java等多种编程语言中均表现出一致的有效性。

Abstract: Code-generating Large Language Models (LLMs) significantly accelerate
software development. However, their frequent generation of insecure code
presents serious risks. We present a comprehensive evaluation of seven
parameter-efficient fine-tuning (PEFT) techniques, demonstrating substantial
gains in secure code generation without compromising functionality. Our
research identifies prompt-tuning as the most effective PEFT method, achieving
an 80.86% Overall-Secure-Rate on CodeGen2 16B, a 13.5-point improvement over
the 67.28% baseline. Optimizing decoding strategies through sampling
temperature further elevated security to 87.65%. This equates to a reduction of
approximately 203,700 vulnerable code snippets per million generated. Moreover,
prompt and prefix tuning increase robustness against poisoning attacks in our
TrojanPuzzle evaluation, with strong performance against CWE-79 and CWE-502
attack vectors. Our findings generalize across Python and Java, confirming
prompt-tuning's consistent effectiveness. This study provides essential
insights and practical guidance for building more resilient software systems
with LLMs.

</details>


### [12] [Hardened CTIDH: Dummy-Free and Deterministic CTIDH](https://arxiv.org/abs/2509.12877)
*Gustavo Banegas,Andreas Hellenbrand,Matheus Saldanha*

Main category: cs.CR

TL;DR: 提出了首个无虚拟操作的dCTIDH实现，结合DACsHUND和重构的Matryoshka结构，移除了虚拟乘法和验证所有中间点，实现了确定性、恒定时间且完全无虚拟操作的CSIDH类协议


<details>
  <summary>Details</summary>
Motivation: CTIDH和dCTIDH依赖差分加法链和Matryoshka中的虚拟操作，这些操作容易受到故障注入攻击的利用，需要开发无虚拟操作的实现

Method: 结合DACsHUND（在每个批次内强制执行等长差分加法链而无需填充）和重构的Matryoshka结构（移除虚拟乘法并验证所有中间点），排除小素数参数

Result: 实现了dummy-free dCTIDH-2048-194和dCTIDH-2048-205，群作用成本约357,000-362,000 Fp乘法，中值评估时间1.59-1.60 Gcyc，比CTIDH快约5%，比dCSIDH快4倍以上

Conclusion: 这是首个同时具备确定性、恒定时间且完全无虚拟操作的高效CSIDH类协议实现，为后量子密码学提供了更安全的替代方案

Abstract: Isogeny-based cryptography has emerged as a promising postquantum
alternative, with CSIDH and its constant-time variants CTIDH and dCTIDH
offering efficient group-action protocols. However, CTIDH and dCTIDH rely on
dummy operations in differential addition chains (DACs) and Matryoshka, which
can be exploitable by fault-injection attacks. In this work, we present the
first dummy-free implementation of dCTIDH. Our approach combines two recent
ideas: DACsHUND, which enforces equal-length DACs within each batch without
padding, and a reformulated Matryoshka structure that removes dummy
multiplications and validates all intermediate points. Our analysis shows that
small primes such as 3, 5, and 7 severely restrict feasible DACsHUND
configurations, motivating new parameter sets that exclude them. We implement
dummy-free dCTIDH-2048-194 and dCTIDH-2048-205, achieving group action costs of
roughly 357,000-362,000 Fp-multiplications, with median evaluation times of
1.59-1.60 (Gcyc). These results do not surpass dC-TIDH, but they outperform
CTIDH by roughly 5% while eliminating dummy operations entirely. Compared to
dCSIDH, our construction is more than 4x faster. To the best of our knowledge,
this is the first efficient implementation of a CSIDH-like protocol that is
simultaneously deterministic, constant-time, and fully dummy-free.

</details>


### [13] [A Fault Analysis on SNOVA](https://arxiv.org/abs/2509.12879)
*Gustavo Banegas,Ricardo Villanueva-Polanco*

Main category: cs.CR

TL;DR: 本文对后量子签名方案SNOVA进行了全面的故障分析，揭示了仅需22-68个故障签名即可恢复密钥的安全漏洞，并提出了轻量级防护措施。


<details>
  <summary>Details</summary>
Motivation: SNOVA作为NIST后量子密码标准化进程的第二轮候选方案，以其高效性和紧凑密钥大小著称。然而，其在实际部署中对故障攻击的抵抗能力尚未得到充分研究，需要评估其在实际物理攻击下的安全性。

Method: 通过永久性和瞬态性故障注入策略，利用SNOVA的结构特点进行密钥恢复攻击。提出了一种新颖的故障辅助协调攻击，通过求解二次多项式系统来提取秘密密钥空间。

Result: 分析显示，根据安全级别不同，仅需22到68个故障签名就足以实现密钥恢复。仿真表明密钥签名生成步骤中的瞬态故障会严重损害SNOVA的安全性。

Conclusion: 研究结果强调了在后量子密码方案如SNOVA中实施故障抵抗机制的重要性，以确保方案的鲁棒性。同时提出了轻量级防护措施来降低故障攻击的成功率，且不会增加显著开销。

Abstract: SNOVA is a post-quantum cryptographic signature scheme known for its
efficiency and compact key sizes, making it a second-round candidate in the
NIST post-quantum cryptography standardization process. This paper presents a
comprehensive fault analysis of SNOVA, focusing on both permanent and transient
faults during signature generation. We introduce several fault injection
strategies that exploit SNOVA's structure to recover partial or complete secret
keys with limited faulty signatures. Our analysis reveals that as few as 22 to
68 faulty signatures, depending on the security level, can suffice for key
recovery. We propose a novel fault-assisted reconciliation attack,
demonstrating its effectiveness in extracting the secret key space via solving
a quadratic polynomial system. Simulations show transient faults in key
signature generation steps can significantly compromise SNOVA's security. To
address these vulnerabilities, we propose a lightweight countermeasure to
reduce the success of fault attacks without adding significant overhead. Our
results highlight the importance of fault-resistant mechanisms in post-quantum
cryptographic schemes like SNOVA to ensure robustness.

</details>


### [14] [EByFTVeS: Efficient Byzantine Fault Tolerant-based Verifiable Secret-sharing in Distributed Privacy-preserving Machine Learning](https://arxiv.org/abs/2509.12899)
*Zhen Li,Zijian Zhang,Wenjin Yang,Pengbo Wang,Zhaoqi Wang,Meng Li,Yan Wu,Xuyang Liu,Jing Sun,Liehuang Zhu*

Main category: cs.CR

TL;DR: 本文提出了一种针对现有VSS方案的适应性份额延迟提供(ASDP)攻击策略，并开发了EByFTVeS方案来应对这种攻击，同时提高了效率和安全性。


<details>
  <summary>Details</summary>
Motivation: 现有基于可验证秘密共享(VSS)的分布式隐私保护机器学习(DPML)方案存在一致性问题以及计算通信负担重的挑战，虽然拜占庭容错(BFT)系统被引入来改善，但作者发现仍存在安全漏洞。

Method: 提出了ASDP策略和ACuMPA攻击算法来分析现有方案的脆弱性，然后设计了高效的拜占庭容错可验证秘密共享(EByFTVeS)方案。

Result: 理论分析了EByFTVeS方案的有效性、活性、一致性和隐私性，实验结果表明其效率优于最先进的VSS方案。

Conclusion: EByFTVeS方案不仅能够抵御ASDP攻击，还显著提高了VSS方案的性能和安全性，为DPML系统提供了更可靠的解决方案。

Abstract: Verifiable Secret Sharing (VSS) has been widespread in Distributed
Privacy-preserving Machine Learning (DPML), because invalid shares from
malicious dealers or participants can be recognized by verifying the commitment
of the received shares for honest participants. However, the consistency and
the computation and communitation burden of the VSS-based DPML schemes are
still two serious challenges. Although Byzantine Fault Tolerance (BFT) system
has been brought to guarantee the consistency and improve the efficiency of the
existing VSS-based DPML schemes recently, we explore an Adaptive Share Delay
Provision (ASDP) strategy, and launch an ASDP-based Customized Model Poisoning
Attack (ACuMPA) for certain participants in this paper. We theoretically
analyzed why the ASDP strategy and the ACuMPA algorithm works to the existing
schemes. Next, we propose an [E]fficient [By]zantine [F]ault [T]olerant-based
[Ve]rifiable [S]ecret-sharing (EByFTVeS) scheme. Finally, the validity,
liveness, consistency and privacy of the EByFTVeS scheme are theoretically
analyzed, while the efficiency of the EByFTVeS scheme outperforms that of
the-state-of-art VSS scheme according to comparative experiment results.

</details>


### [15] [A Graph-Based Approach to Alert Contextualisation in Security Operations Centres](https://arxiv.org/abs/2509.12923)
*Magnus Wiik Eckhoff,Peter Marius Flydal,Siem Peters,Martin Eian,Jonas Halvorsen,Vasileios Mavroeidis,Gudmund Grov*

Main category: cs.CR

TL;DR: 提出基于图的方法来聚合安全警报，通过图匹配网络将新警报组与历史事件关联，提升SOC中警报上下文分析效率


<details>
  <summary>Details</summary>
Motivation: 安全运营中心(SOC)面临海量安全警报分析的挑战，需要有效区分真实威胁和良性活动，以优先处理需要进一步分析的内容

Method: 使用图结构聚合警报（节点表示警报，边表示时间窗口内的关系），采用图匹配网络(GMNs)将新警报组与历史事件进行关联分析

Result: 通过警报分组实现在更高抽象层次进行分析，比单个警报更能有效捕捉攻击步骤，为下游机器学习方法提供良好格式支持

Conclusion: 图基方法能够增强SOC中的警报上下文分析，为分析师提供额外洞察，提高安全事件处理的效率和准确性

Abstract: Interpreting the massive volume of security alerts is a significant challenge
in Security Operations Centres (SOCs). Effective contextualisation is
important, enabling quick distinction between genuine threats and benign
activity to prioritise what needs further analysis.This paper proposes a
graph-based approach to enhance alert contextualisation in a SOC by aggregating
alerts into graph-based alert groups, where nodes represent alerts and edges
denote relationships within defined time-windows. By grouping related alerts,
we enable analysis at a higher abstraction level, capturing attack steps more
effectively than individual alerts. Furthermore, to show that our format is
well suited for downstream machine learning methods, we employ Graph Matching
Networks (GMNs) to correlate incoming alert groups with historical incidents,
providing analysts with additional insights.

</details>


### [16] [Jailbreaking Large Language Models Through Content Concretization](https://arxiv.org/abs/2509.12937)
*Johan Wahréus,Ahmed Hussain,Panos Papadimitratos*

Main category: cs.CR

TL;DR: 提出Content Concretization方法，通过两阶段迭代将抽象恶意请求转化为具体可执行代码，显著提高LLM越狱成功率从7%到62%


<details>
  <summary>Details</summary>
Motivation: 大型语言模型的安全机制仍易被越狱技术绕过，需要研究新的攻击方法来揭示安全漏洞

Method: 两阶段过程：先用低安全过滤模型生成初步响应，再用高安全模型结合原始提示进行精炼，迭代优化恶意代码

Result: 在350个网络安全提示上测试，经过3次精炼迭代后越狱成功率从7%提升至62%，成本仅7.5美分/提示

Conclusion: 该方法揭示了当前LLM安全框架的关键漏洞，生成的恶意代码只需最小修改即可执行，突显了安全改进的紧迫性

Abstract: Large Language Models (LLMs) are increasingly deployed for task automation
and content generation, yet their safety mechanisms remain vulnerable to
circumvention through different jailbreaking techniques. In this paper, we
introduce \textit{Content Concretization} (CC), a novel jailbreaking technique
that iteratively transforms abstract malicious requests into concrete,
executable implementations. CC is a two-stage process: first, generating
initial LLM responses using lower-tier, less constrained safety filters models,
then refining them through higher-tier models that process both the preliminary
output and original prompt. We evaluate our technique using 350
cybersecurity-specific prompts, demonstrating substantial improvements in
jailbreak Success Rates (SRs), increasing from 7\% (no refinements) to 62\%
after three refinement iterations, while maintaining a cost of 7.5\textcent~per
prompt. Comparative A/B testing across nine different LLM evaluators confirms
that outputs from additional refinement steps are consistently rated as more
malicious and technically superior. Moreover, manual code analysis reveals that
generated outputs execute with minimal modification, although optimal
deployment typically requires target-specific fine-tuning. With eventual
improved harmful code generation, these results highlight critical
vulnerabilities in current LLM safety frameworks.

</details>


### [17] [xRWA: A Cross-Chain Framework for Interoperability of Real-World Assets](https://arxiv.org/abs/2509.12957)
*Yihao Guo,Haoming Zhu,Minghui Xu,Xiuzhen Cheng,Bin Xiao*

Main category: cs.CR

TL;DR: 提出了一个针对现实世界资产（RWAs）的跨链框架，解决多链部署中的重复认证和低效结算问题，通过集成去中心化身份验证和简化支付验证协议来提高效率。


<details>
  <summary>Details</summary>
Motivation: 现实世界资产在多个区块链上部署时面临重复认证和多步结算协议导致的效率低下问题，需要一种跨链解决方案来提升RWA的流动性和可访问性。

Method: 集成去中心化标识符和可验证凭证进行身份管理，采用基于简化支付验证的认证协议避免跨链重复验证，设计无需关闭通道的跨链结算通道。

Result: 通过模拟实验验证了框架的可行性，证明了在跨链环境中RWA操作效率的显著提升。

Conclusion: 该跨链框架有效解决了RWA在多链环境中的认证和结算效率问题，为现实世界资产的区块链化提供了可行的技术方案。

Abstract: Real-World Assets (RWAs) have recently attracted increasing attention as a
means of bridging traditional financial instruments with decentralized
infrastructures. By representing assets such as bonds, commodities, and real
estate on blockchains, RWAs can enhance liquidity, broaden accessibility, and
extend the scope of decentralized finance. Industry forecasts further suggest
rapid growth of tokenized RWAs in the coming years, underscoring their
potential role in the evolution of digital financial markets. However, when
deployed across multiple blockchains, RWAs face challenges such as repeated
authentication on different chains and inefficiency caused by multi-step
settlement protocols. To address these issues, we present a cross-chain
framework for RWAs that emphasizes identity management, authentication, and
interaction. The framework integrates Decentralized Identifiers and Verifiable
Credentials with customized attributes to support decentralized identification,
and incorporates an authentication protocol based on Simplified Payment
Verification to avoid redundant verification across chains. Furthermore, we
design a cross-chain channel that enables the settlement of RWAs without
requiring channel closure, thereby improving operational efficiency. We
implement the framework and evaluate it through simulations, which confirm its
feasibility and demonstrate improvements in efficiency for RWAs in cross-chain
settings.

</details>


### [18] [Universal share based quantum multi secret image sharing scheme](https://arxiv.org/abs/2509.12979)
*Dipak K. Rabari,Yogesh K. Meghrajani,Laxmi S. Desai*

Main category: cs.CR

TL;DR: 提出了一种基于通用共享的量子多秘密共享技术，结合量子计算和视觉密码学，为图像安全通信提供抗窃听威胁的解决方案


<details>
  <summary>Details</summary>
Motivation: 随着互联网普及和黑客攻击增加，图像信息安全变得至关重要。量子计算虽然能促进安全通信，但也威胁现有加密算法，需要结合视觉密码学来提升安全性

Method: 利用通用共享概念和量子计算技术，开发了一种新颖的量子多秘密共享方案，用于安全图像通信

Result: 该方法展现出对多种窃听威胁的高抗性，为企业和军事等应用场景提供了强大的图像安全共享解决方案

Conclusion: 结合量子计算和视觉密码学的通用共享方案为机密图像数据的安全传输提供了有效的保护机制

Abstract: Image security for information has become increasingly critical as internet
become more prevalent due to hacking and unauthorized access. To ensure the
security of confidential image data, image encryption using visual cryptography
plays a crucial role. To share multiple images using visual cryptography, the
company organizer utilizes the concept of a universal or common share.
Likewise, quantum computing is an emerging technology that facilitates secure
communication. The ability of quantum computers to solve certain mathematical
problems efficiently threatens the security of many current encryption
algorithms. Hence, to leverage the strengths of quantum computing and visual
cryptography, this research introduces a novel universal share-based quantum
multi-secret sharing technique for secure image communication. Quantum
computing enables the scheme to exhibit high resilience to different
eavesdropping threats. Consequently, the proposed method offers robust security
solution for sharing confidential images across a range of applications,
including enterprise data access and military communications.

</details>


### [19] [xOffense: An AI-driven autonomous penetration testing framework with offensive knowledge-enhanced LLMs and multi agent systems](https://arxiv.org/abs/2509.13021)
*Phung Duc Luong,Le Tran Gia Bao,Nguyen Vu Khai Tam,Dong Huu Nguyen Khoa,Nguyen Huu Quyen,Van-Hau Pham,Phan The Duy*

Main category: cs.CR

TL;DR: xOffense是一个基于AI的多智能体渗透测试框架，使用微调的Qwen3-32B大语言模型实现自动化渗透测试，在基准测试中表现优于现有方法


<details>
  <summary>Details</summary>
Motivation: 将传统依赖专家手动操作的渗透测试转变为完全自动化、可扩展的机器执行工作流，解决人工测试效率低、成本高的问题

Method: 采用微调的中等规模开源LLM(Qwen3-32B)驱动推理和决策，通过专门智能体分工负责侦察、漏洞扫描和利用，使用编排层协调各阶段工作，并基于思维链渗透测试数据进行微调

Result: 在AutoPenBench和AI-Pentest-Benchmark基准测试中，xOffense实现了79.17%的子任务完成率，显著超越VulnBot和PentestGPT等领先系统

Conclusion: 领域适配的中等规模LLM结合结构化多智能体编排，能够为自动化渗透测试提供优越、成本效益高且可复现的解决方案

Abstract: This work introduces xOffense, an AI-driven, multi-agent penetration testing
framework that shifts the process from labor-intensive, expert-driven manual
efforts to fully automated, machine-executable workflows capable of scaling
seamlessly with computational infrastructure. At its core, xOffense leverages a
fine-tuned, mid-scale open-source LLM (Qwen3-32B) to drive reasoning and
decision-making in penetration testing. The framework assigns specialized
agents to reconnaissance, vulnerability scanning, and exploitation, with an
orchestration layer ensuring seamless coordination across phases. Fine-tuning
on Chain-of-Thought penetration testing data further enables the model to
generate precise tool commands and perform consistent multi-step reasoning. We
evaluate xOffense on two rigorous benchmarks: AutoPenBench and
AI-Pentest-Benchmark. The results demonstrate that xOffense consistently
outperforms contemporary methods, achieving a sub-task completion rate of
79.17%, decisively surpassing leading systems such as VulnBot and PentestGPT.
These findings highlight the potential of domain-adapted mid-scale LLMs, when
embedded within structured multi-agent orchestration, to deliver superior,
cost-efficient, and reproducible solutions for autonomous penetration testing.

</details>


### [20] [Bridging Threat Models and Detections: Formal Verification via CADP](https://arxiv.org/abs/2509.13035)
*Dumitru-Bogdan Prelipcean,Cătălin Dima*

Main category: cs.CR

TL;DR: 提出了一个形式化验证框架，通过将检测逻辑和攻击树建模为标记转换系统，实现自动化的符合性检查，用于验证威胁检测系统规则与高级威胁模型的一致性。


<details>
  <summary>Details</summary>
Motivation: 现有的威胁检测系统依赖基于规则的逻辑来识别对抗行为，但这些规则与高级威胁模型的符合性很少被形式化验证，存在语义不匹配的问题。

Method: 将检测规则（使用GTDL语言）和攻击树都建模为标记转换系统(LTS)，通过互模拟和弱迹包含进行自动化符合性检查，并使用CADP工具箱进行验证。

Result: 在真实恶意软件场景（如LokiBot和Emotet）上验证了方法的有效性，能够识别威胁模型与检测规则之间的语义不匹配，支持迭代优化，并能扩展到现实威胁场景。

Conclusion: 该框架为威胁检测系统提供了系统化和自动化的验证方法，能够确保检测规则与威胁模型的一致性，提高检测系统的可靠性。

Abstract: Threat detection systems rely on rule-based logic to identify adversarial
behaviors, yet the conformance of these rules to high-level threat models is
rarely verified formally. We present a formal verification framework that
models both detection logic and attack trees as labeled transition systems
(LTSs), enabling automated conformance checking via bisimulation and weak trace
inclusion. Detection rules specified in the Generic Threat Detection Language
(GTDL, a general-purpose detection language we formalize in this work) are
assigned a compositional operational semantics, and threat models expressed as
attack trees are interpreted as LTSs through a structural trace semantics. Both
representations are translated to LNT, a modeling language supported by the
CADP toolbox. This common semantic domain enables systematic and automated
verification of detection coverage. We evaluate our approach on real-world
malware scenarios such as LokiBot and Emotet and provide scalability analysis
through parametric synthetic models. Results confirm that our methodology
identifies semantic mismatches between threat models and detection rules,
supports iterative refinement, and scales to realistic threat landscapes.

</details>


### [21] [MIA-EPT: Membership Inference Attack via Error Prediction for Tabular Data](https://arxiv.org/abs/2509.13046)
*Eyal German,Daniel Samira,Yuval Elovici,Asaf Shabtai*

Main category: cs.CR

TL;DR: MIA-EPT是一种针对表格扩散模型的成员推理攻击方法，通过掩码和重建属性构建误差特征向量，仅依赖合成数据输出即可有效检测训练数据成员信息泄露。


<details>
  <summary>Details</summary>
Motivation: 扩散模型生成高质量表格数据时可能记忆训练记录并泄露敏感信息，而现有成员推理攻击主要针对图像和文本，表格数据的结构化属性和有限记录多样性带来的独特风险尚未充分研究。

Method: 提出MIA-EPT黑盒攻击方法，通过掩码目标记录的属性并利用扩散模型重建，基于属性预测精度构建误差特征向量来推断成员身份，无需访问生成模型内部组件。

Result: 在三个扩散合成器上验证，AUC-ROC最高达0.599，TPR@10% FPR为22.0%；在MIDST 2025竞赛黑盒多表赛道获得第二名（TPR@10% FPR=20.0%）。

Conclusion: 该方法能有效揭示合成表格数据中的成员信息泄露，挑战了合成数据天生具有隐私保护性的假设。

Abstract: Synthetic data generation plays an important role in enabling data sharing,
particularly in sensitive domains like healthcare and finance. Recent advances
in diffusion models have made it possible to generate realistic, high-quality
tabular data, but they may also memorize training records and leak sensitive
information. Membership inference attacks (MIAs) exploit this vulnerability by
determining whether a record was used in training. While MIAs have been studied
in images and text, their use against tabular diffusion models remains
underexplored despite the unique risks of structured attributes and limited
record diversity. In this paper, we introduce MIAEPT, Membership Inference
Attack via Error Prediction for Tabular Data, a novel black-box attack
specifically designed to target tabular diffusion models. MIA-EPT constructs
errorbased feature vectors by masking and reconstructing attributes of target
records, disclosing membership signals based on how well these attributes are
predicted. MIA-EPT operates without access to the internal components of the
generative model, relying only on its synthetic data output, and was shown to
generalize across multiple state-of-the-art diffusion models. We validate
MIA-EPT on three diffusion-based synthesizers, achieving AUC-ROC scores of up
to 0.599 and TPR@10% FPR values of 22.0% in our internal tests. Under the MIDST
2025 competition conditions, MIA-EPT achieved second place in the Black-box
Multi-Table track (TPR@10% FPR = 20.0%). These results demonstrate that our
method can uncover substantial membership leakage in synthetic tabular data,
challenging the assumption that synthetic data is inherently
privacy-preserving. Our code is publicly available at
https://github.com/eyalgerman/MIA-EPT.

</details>


### [22] [SLasH-DSA: Breaking SLH-DSA Using an Extensible End-To-End Rowhammer Framework](https://arxiv.org/abs/2509.13048)
*Jeremy Boy,Antoon Purnal,Anna Pätschke,Luca Wilke,Thomas Eisenbarth*

Main category: cs.CR

TL;DR: 首个针对NIST标准化PQC方案SLH-DSA的纯软件通用伪造攻击，利用Rowhammer比特翻转破坏内部状态并伪造签名，无需物理访问即可在桌面/服务器硬件上实现


<details>
  <summary>Details</summary>
Motivation: 随着量子计算发展，PQC方案逐步取代经典算法，SLH-DSA因其保守的安全基础被NIST标准化，但实际部署中可能面临硬件漏洞威胁

Method: 开发Swage框架实现端到端Rowhammer故障攻击，通过比特翻转破坏SLH-DSA内部状态，结合新颖的复杂度分析确定最优计算路径进行后处理

Result: 在OpenSSL 3.5.1上成功攻击所有安全级别的SLH-DSA，最高安全级别仅需8小时攻击和36秒后处理即可实现通用伪造

Conclusion: 即使理论上安全的PQC方案在现实条件下也可能失效，需要额外的实现加固或硬件防御来对抗Rowhammer攻击

Abstract: As quantum computing advances, PQC schemes are adopted to replace classical
algorithms. Among them is the SLH-DSA that was recently standardized by NIST
and is favored for its conservative security foundations.
  In this work, we present the first software-only universal forgery attack on
SLH-DSA, leveraging Rowhammer-induced bit flips to corrupt the internal state
and forge signatures. While prior work targeted embedded systems and required
physical access, our attack is software-only, targeting commodity desktop and
server hardware, significantly broadening the threat model. We demonstrate a
full end-to-end attack against all security levels of SLH-DSA in OpenSSL 3.5.1,
achieving universal forgery for the highest security level after eight hours of
hammering and 36 seconds of post-processing. Our post-processing is informed by
a novel complexity analysis that, given a concrete set of faulty signatures,
identifies the most promising computational path to pursue.
  To enable the attack, we introduce Swage, a modular and extensible framework
for implementing end-to-end Rowhammer-based fault attacks. Swage abstracts and
automates key components of practical Rowhammer attacks. Unlike prior tooling,
Swage is untangled from the attacked code, making it reusable and suitable for
frictionless analysis of different targets. Our findings highlight that even
theoretically sound PQC schemes can fail under real-world conditions,
underscoring the need for additional implementation hardening or hardware
defenses against Rowhammer.

</details>


### [23] [Digital Sovereignty Control Framework for Military AI-based Cyber Security](https://arxiv.org/abs/2509.13072)
*Clara Maathuis,Kasper Cools*

Main category: cs.CR

TL;DR: 提出一个多角度框架来定义和评估军事网络安全中数据和AI模型的数字主权控制，关注自主性、风险缓解和互操作性。


<details>
  <summary>Details</summary>
Motivation: 在当今威胁环境中，确保数字主权对军事组织至关重要，特别是随着AI驱动的网络安全解决方案的发展和投资增加。

Method: 采用设计导向研究方法，结合系统文献综述、批判性思维和现场事件分析，构建多学科框架。

Result: 开发了一个关注背景、自主性、利益相关者参与和风险缓解的数字主权评估框架，保护敏感国防资产。

Conclusion: 该框架通过保持操作自主性、确保安全性和隐私、促进道德合规，增强了关键数字资产的弹性和控制力。

Abstract: In today's evolving threat landscape, ensuring digital sovereignty has become
mandatory for military organizations, especially given their increased
development and investment in AI-driven cyber security solutions. To this end,
a multi-angled framework is proposed in this article in order to define and
assess digital sovereign control of data and AI-based models for military cyber
security. This framework focuses on aspects such as context, autonomy,
stakeholder involvement, and mitigation of risks in this domain. Grounded on
the concepts of digital sovereignty and data sovereignty, the framework aims to
protect sensitive defence assets against threats such as unauthorized access,
ransomware, and supply-chain attacks. This approach reflects the multifaceted
nature of digital sovereignty by preserving operational autonomy, assuring
security and safety, securing privacy, and fostering ethical compliance of both
military systems and decision-makers. At the same time, the framework addresses
interoperability challenges among allied forces, strategic and legal
considerations, and the integration of emerging technologies by considering a
multidisciplinary approach that enhances the resilience and preservation of
control over (critical) digital assets. This is done by adopting a design
oriented research where systematic literature review is merged with critical
thinking and analysis of field incidents in order to assure the effectivity and
realism of the framework proposed.

</details>


### [24] [Characterizing Phishing Pages by JavaScript Capabilities](https://arxiv.org/abs/2509.13186)
*Aleksandr Nahapetyan,Kanv Khare,Kevin Schwarz,Bradley Reaves,Alexandros Kapravelos*

Main category: cs.CR

TL;DR: 该论文开发了一个自动化系统，能够以97%的准确率识别钓鱼工具包，并分析了434,050个钓鱼页面的JavaScript特征，发现UI交互性和基本指纹识别是最常见的技术。


<details>
  <summary>Details</summary>
Motivation: 钓鱼攻击者使用钓鱼工具包快速部署大量钓鱼页面，而研究人员和防御者仍然依赖手动分析来识别这些页面，需要自动化工具来处理大规模钓鱼攻击。

Method: 开发了一个自动化系统，通过分析JavaScript逻辑复杂性来区分钓鱼页面组，基于工具包进行聚类分析，并在包含548个工具包家族的4,562个钓鱼URL数据集上进行验证。

Result: 系统在标记数据集上达到97%的准确率；在未标记的434,050个钓鱼页面中识别出11,377个聚类；发现90%的聚类使用UI交互技术，80%使用基本指纹识别，而鼠标检测API使用率最低。

Conclusion: 该研究为研究人员和分析师提供了处理大规模钓鱼页面的新方法，自动化了原本需要手动完成的过程，并能测量不同客户端技术在钓鱼工具包中的流行程度。

Abstract: In 2024, the Anti-Phishing Work Group identified over one million phishing
pages. Phishers achieve this scale by using phishing kits -- ready-to-deploy
phishing websites -- to rapidly deploy phishing campaigns with specific data
exfiltration, evasion, or mimicry techniques. In contrast, researchers and
defenders continue to fight phishing on a page-by-page basis and rely on manual
analysis to recognize static features for kit identification.
  This paper aims to aid researchers and analysts by automatically
differentiating groups of phishing pages based on the underlying kit,
automating a previously manual process, and enabling us to measure how popular
different client-side techniques are across these groups. For kit detection,
our system has an accuracy of 97% on a ground-truth dataset of 548 kit families
deployed across 4,562 phishing URLs. On an unlabeled dataset, we leverage the
complexity of 434,050 phishing pages' JavaScript logic to group them into
11,377 clusters, annotating the clusters with what phishing techniques they
employ. We find that UI interactivity and basic fingerprinting are universal
techniques, present in 90% and 80% of the clusters, respectively. On the other
hand, mouse detection via the browser's mouse API is among the rarest
behaviors, despite being used in a deployment of a 7-year-old open-source
phishing kit. Our methods and findings provide new ways for researchers and
analysts to tackle the volume of phishing pages.

</details>


### [25] [Trustworthy and Confidential SBOM Exchange](https://arxiv.org/abs/2509.13217)
*Eman Abu Ishgair,Chinenye Okafor,Marcela S. Melara,Santiago Torres-Arias*

Main category: cs.CR

TL;DR: Petra是一个SBOM交换系统，通过选择性加密实现软件供应商对机密元数据的保护，同时允许授权用户搜索安全相关信息，平衡了透明度和保密性的需求。


<details>
  <summary>Details</summary>
Motivation: 企业软件供应商需要在SBOM中保护知识产权和安全漏洞信息，但监管要求提高软件供应链透明度，这种透明与保密的矛盾需要解决。

Method: 使用选择性加密技术对SBOM数据进行编辑，采用格式无关、防篡改的SBOM表示方法生成保密性完整性证明，支持加密审计和信任建立。

Result: 原型系统显示，交换编辑后的SBOM只需额外不到1KB数据，SBOM解密在查询过程中最多产生1%的性能开销。

Conclusion: Petra系统有效解决了SBOM透明度和保密性之间的张力，为软件供应链安全提供了实用的解决方案。

Abstract: Software Bills of Materials (SBOMs) have become a regulatory requirement for
improving software supply chain security and trust by means of transparency
regarding components that make up software artifacts. However, enterprise and
regulated software vendors commonly wish to restrict who can view confidential
software metadata recorded in their SBOMs due to intellectual property or
security vulnerability information. To address this tension between
transparency and confidentiality, we propose Petra, an SBOM exchange system
that empowers software vendors to interoperably compose and distribute redacted
SBOM data using selective encryption. Petra enables software consumers to
search redacted SBOMs for answers to specific security questions without
revealing information they are not authorized to access. Petra leverages a
format-agnostic, tamper-evident SBOM representation to generate efficient and
confidentiality-preserving integrity proofs, allowing interested parties to
cryptographically audit and establish trust in redacted SBOMs. Exchanging
redacted SBOMs in our Petra prototype requires less than 1 extra KB per SBOM,
and SBOM decryption account for at most 1% of the performance overhead during
an SBOM query.

</details>
