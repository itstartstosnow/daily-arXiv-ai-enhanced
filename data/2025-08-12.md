<div id=toc></div>

# Table of Contents

- [cs.CR](#cs.CR) [Total: 19]


<div id='cs.CR'></div>

# cs.CR [[Back]](#toc)

### [1] [Symbolic Execution in Practice: A Survey of Applications in Vulnerability, Malware, Firmware, and Protocol Analysis](https://arxiv.org/abs/2508.06643)
*Joshua Bailey,Charles Nicholas*

Main category: cs.CR

TL;DR: 本文提出了符号执行中路径爆炸问题的分类法，分为范围缩减和引导启发式两种策略，并探讨了其在不同领域的应用及未来研究方向。


<details>
  <summary>Details</summary>
Motivation: 符号执行虽强大，但路径爆炸问题阻碍其实际应用，需系统分类现有策略以推动研究。

Method: 提出分类法，将策略分为范围缩减和引导启发式，并综述其在多领域的应用。

Result: 分类法清晰总结了现有策略，并展示了符号执行在多个领域的成功应用。

Conclusion: 未来研究方向包括实时操作系统和现代类型安全语言的符号执行应用。

Abstract: Symbolic execution is a powerful program analysis technique that allows for
the systematic exploration of all program paths. Path explosion, where the
number of states to track becomes unwieldy, is one of the biggest challenges
hindering symbolic execution's practical application. To combat this,
researchers have employed various strategies to enable symbolic execution on
complex software systems. This paper introduces a systematic taxonomy of these
strategies, categorizing them into two primary approaches: Scope Reduction,
which aims to reduce the scope of symbolic execution to manageable portions of
code, and Guidance Heuristics, which steer the symbolic execution engine toward
promising paths. Using this taxonomy as a lens, we survey applications of
symbolic executions in several domains such as vulnerability analysis, malware
analysis, firmware re-hosting, and network protocol analysis. Finally, we
identify promising directions for future research, including the application of
symbolic execution to real-time operating systems and modern, type-safe
languages.

</details>


### [2] [Mitigating Distribution Shift in Graph-Based Android Malware Classification via Function Metadata and LLM Embeddings](https://arxiv.org/abs/2508.06734)
*Ngoc N. Tran,Anwar Said,Waseem Abbas,Tyler Derr,Xenofon D. Koutsoukos*

Main category: cs.CR

TL;DR: 现有基于图的恶意软件分类器在标准数据集上准确率超过94%，但在同一家族未见过的变体上准确率下降高达45%。本文提出语义增强框架，提升模型泛化能力。


<details>
  <summary>Details</summary>
Motivation: 现有方法在模型架构和结构表示上未能捕捉深层语义模式，导致泛化能力不足。

Method: 提出语义增强框架，通过函数级元数据和代码嵌入增强函数调用图，支持灵活集成语义信号。

Result: 实验表明，该方法在分布偏移下提升分类性能8%，并增强鲁棒性。

Conclusion: 该方法为构建适应威胁环境变化的恶意软件检测系统提供了实用路径。

Abstract: Graph-based malware classifiers can achieve over 94% accuracy on standard
Android datasets, yet we find they suffer accuracy drops of up to 45% when
evaluated on previously unseen malware variants from the same family - a
scenario where strong generalization would typically be expected. This
highlights a key limitation in existing approaches: both the model
architectures and their structure-only representations often fail to capture
deeper semantic patterns. In this work, we propose a robust semantic enrichment
framework that enhances function call graphs with contextual features,
including function-level metadata and, when available, code embeddings derived
from large language models. The framework is designed to operate under
real-world constraints where feature availability is inconsistent, and supports
flexible integration of semantic signals. To evaluate generalization under
realistic domain and temporal shifts, we introduce two new benchmarks:
MalNet-Tiny-Common and MalNet-Tiny-Distinct, constructed using malware family
partitioning to simulate cross-family generalization and evolving threat
behavior. Experiments across multiple graph neural network backbones show that
our method improves classification performance by up to 8% under distribution
shift and consistently enhances robustness when integrated with
adaptation-based methods. These results offer a practical path toward building
resilient malware detection systems in evolving threat environments.

</details>


### [3] [Label Inference Attacks against Federated Unlearning](https://arxiv.org/abs/2508.06789)
*Wei Wang,Xiangyun Tang,Yajie Wang,Yijing Lin,Tao Zhang,Meng Shen,Dusit Niyato,Liehuang Zhu*

Main category: cs.CR

TL;DR: 论文提出了一种针对联邦遗忘（FU）的新型标签推断攻击ULIA，通过模型参数变化推断遗忘数据的标签，实验表明攻击成功率极高。


<details>
  <summary>Details</summary>
Motivation: 联邦遗忘（FU）允许客户删除数据而不影响模型性能，但研究发现模型参数变化会泄露数据信息，导致标签推断攻击。

Method: 设计了梯度-标签映射机制，通过模型变化推断标签，并在IID和非IID设置下评估ULIA。

Result: 在IID设置下，ULIA攻击成功率达100%；即使仅遗忘1%数据，成功率仍为93%至62.3%。

Conclusion: ULIA揭示了FU的隐私风险，需进一步研究防御措施。

Abstract: Federated Unlearning (FU) has emerged as a promising solution to respond to
the right to be forgotten of clients, by allowing clients to erase their data
from global models without compromising model performance. Unfortunately,
researchers find that the parameter variations of models induced by FU expose
clients' data information, enabling attackers to infer the label of unlearning
data, while label inference attacks against FU remain unexplored. In this
paper, we introduce and analyze a new privacy threat against FU and propose a
novel label inference attack, ULIA, which can infer unlearning data labels
across three FU levels. To address the unique challenges of inferring labels
via the models variations, we design a gradient-label mapping mechanism in ULIA
that establishes a relationship between gradient variations and unlearning
labels, enabling inferring labels on accumulated model variations. We evaluate
ULIA on both IID and non-IID settings. Experimental results show that in the
IID setting, ULIA achieves a 100% Attack Success Rate (ASR) under both
class-level and client-level unlearning. Even when only 1% of a user's local
data is forgotten, ULIA still attains an ASR ranging from 93% to 62.3%.

</details>


### [4] [Towards Practical Data-Dependent Memory-Hard Functions with Optimal Sustained Space Trade-offs in the Parallel Random Oracle Model](https://arxiv.org/abs/2508.06795)
*Jeremiah Blocki,Blake Holman*

Main category: cs.CR

TL;DR: EGSample是一种新型内存硬函数（MHF），旨在提供强SSC/CMC权衡，避免依赖昂贵的组合图构造，并在动态铺砖模型和并行随机预言模型中证明其安全性。


<details>
  <summary>Details</summary>
Motivation: 现有MHF设计依赖昂贵的组合图构造且缺乏动态铺砖游戏在MHF分析中的形式化证明，EGSample旨在解决这些问题。

Method: 提出EGSample，不依赖组合图构造，并在动态铺砖模型和并行随机预言模型中分析其SSC/CMC权衡。

Result: 在动态铺砖模型中，EGSample的SSC/CMC权衡与理论构造相当；在并行随机预言模型中，证明其SSC/CMC权衡为Ω(N^{2.5−ϵ})。

Conclusion: EGSample是一种实用且具有强安全保证的MHF，解决了现有方法的局限性。

Abstract: Memory-Hard Functions (MHF) are a useful cryptographic primitive to build
egalitarian proofs-of-work and to help protect low entropy secrets (e.g., user
passwords) against brute-forces attacks. Ideally, we would like for a MHF to
have the property that (1) an honest party can evaluate the function in
sequential time $\Omega(N)$, and (2) any parallel party that evaluates the
function is forced to lockup $\Omega(N)$ memory for $\Omega(N)$ sequential
steps. Unfortunately, this goal is not quite achievable, so prior work of
Blocki and Holman [BH22] focused on designing MHFs with strong tradeoff
guarantees between sustained-space complexity (SSC) and cumulative memory costs
(CMC). However, their theoretical construction is not suitable for practical
deployment due to the reliance on expensive constructions of combinatorial
graphs. Furthermore, there is no formal justification for the heuristic use of
the dynamic pebbling game in MHF analysis so we cannot rule out the possibility
that there are more efficient attacks in the Parallel Random Oracle Model
(PROM). Towards the goal of developing a practical MHF with provably strong
SSC/CMC tradeoffs we develop a new MHF called EGSample which does not rely on
expensive combinatorial constructions like [BH22]. In the dynamic pebbling
model, we prove equivalent SSC/CMC tradeoffs for EGSample i.e., any the dynamic
pebbling strategy either (1) locks up $\Omega(N)$ memory for $\Omega(N)$ steps,
or (2) incurs cumulative memory cost at least $\Omega(N^{3-\epsilon})$. We also
develop new techniques to directly establish SSC/CMC tradeoffs in the parallel
random oracle model. In particular, we prove that {\em any} PROM algorithm
evaluating our MHF either (1) locks up $\Omega(N)$ blocks of memory for
$\Omega(N)$ steps or (2) incurs cumulative memory cost at least
$\Omega(N^{2.5-\epsilon})$.

</details>


### [5] [Towards Effective Prompt Stealing Attack against Text-to-Image Diffusion Models](https://arxiv.org/abs/2508.06837)
*Shiqian Zhao,Chong Wang,Yiming Li,Yihao Huang,Wenjie Qu,Siew-Kei Lam,Yi Xie,Kangjie Chen,Jie Zhang,Tianwei Zhang*

Main category: cs.CR

TL;DR: 论文提出了Prometheus，一种无需训练、基于搜索的提示窃取攻击方法，通过动态修饰符和上下文匹配算法，成功从多种模型中提取高价值提示。


<details>
  <summary>Details</summary>
Motivation: 现有提示窃取攻击方法适应性有限，无法有效应对多样化的展示图像和扩散模型，因此需要一种更灵活、高效的解决方案。

Method: 提出Prometheus方法，包含动态修饰符生成、上下文匹配算法和基于代理模型的贪婪搜索，以逆向工程提取提示。

Result: 实验表明，Prometheus在多种流行平台上成功提取提示，攻击成功率提升25.0%，且对潜在防御措施具有抵抗力。

Conclusion: Prometheus展示了提示窃取攻击的严重性，为未来防御研究提供了重要参考。

Abstract: Text-to-Image (T2I) models, represented by DALL$\cdot$E and Midjourney, have
gained huge popularity for creating realistic images. The quality of these
images relies on the carefully engineered prompts, which have become valuable
intellectual property. While skilled prompters showcase their AI-generated art
on markets to attract buyers, this business incidentally exposes them to
\textit{prompt stealing attacks}. Existing state-of-the-art attack techniques
reconstruct the prompts from a fixed set of modifiers (i.e., style
descriptions) with model-specific training, which exhibit restricted
adaptability and effectiveness to diverse showcases (i.e., target images) and
diffusion models.
  To alleviate these limitations, we propose Prometheus, a training-free,
proxy-in-the-loop, search-based prompt-stealing attack, which reverse-engineers
the valuable prompts of the showcases by interacting with a local proxy model.
It consists of three innovative designs. First, we introduce dynamic modifiers,
as a supplement to static modifiers used in prior works. These dynamic
modifiers provide more details specific to the showcases, and we exploit NLP
analysis to generate them on the fly. Second, we design a contextual matching
algorithm to sort both dynamic and static modifiers. This offline process helps
reduce the search space of the subsequent step. Third, we interact with a local
proxy model to invert the prompts with a greedy search algorithm. Based on the
feedback guidance, we refine the prompt to achieve higher fidelity. The
evaluation results show that Prometheus successfully extracts prompts from
popular platforms like PromptBase and AIFrog against diverse victim models,
including Midjourney, Leonardo.ai, and DALL$\cdot$E, with an ASR improvement of
25.0\%. We also validate that Prometheus is resistant to extensive potential
defenses, further highlighting its severity in practice.

</details>


### [6] [SPARE: Securing Progressive Web Applications Against Unauthorized Replications](https://arxiv.org/abs/2508.07053)
*Sajib Talukder,Nur Imtiazul Haque,Khandakar Ashrafi Akbar*

Main category: cs.CR

TL;DR: 论文提出了一种基于查询参数的安全解决方案，防止恶意开发者复制PWA链接创建假冒原生应用，并通过原型和模拟攻击验证其有效性。


<details>
  <summary>Details</summary>
Motivation: WebView和PWA技术被广泛用于移动应用，但可能被恶意开发者利用，通过复制PWA链接创建假冒应用，威胁用户和开发者安全。

Method: 提出了一种基于查询参数的安全方案，结合Unix时间戳和设备标识符，并通过原型和模拟攻击验证其效果。

Result: 开发了原型应用和模拟攻击场景，验证了方案的有效性，并提出了针对漏洞的改进措施。

Conclusion: 该安全框架能有效防御PWA链接复制攻击，为移动应用安全提供了实用解决方案。

Abstract: WebView applications are widely used in mobile applications to display web
content directly within the app, enhancing user engagement by eliminating the
need to open an external browser and providing a seamless experience.
Progressive Web Applications (PWAs) further improve usability by combining the
accessibility of web apps with the speed, offline capabilities, and
responsiveness of native applications. However, malicious developers can
exploit this technology by duplicating PWA web links to create counterfeit
native apps, monetizing through user diversion. This unethical practice poses
significant risks to users and the original application developers,
underscoring the need for robust security measures to prevent unauthorized
replication. Considering the one-way communication of Trusted Web Activity (a
method for integrating web content into Android applications) and PWAs, we
propose a query parameter-based practical security solution to defend against
or mitigate such attacks. We analyze the vulnerabilities of our proposed
security solution to assess its effectiveness and introduce advanced measures
to address any identified weaknesses, presenting a comprehensive defense
framework. As part of our work, we developed a prototype web application that
secures PWAs from replication by embedding a combination of Unix timestamps and
device identifiers into the query parameters. We evaluate the effectiveness of
this defense strategy by simulating an advanced attack scenario. Additionally,
we created a realistic dataset reflecting mobile app user behavior, modeled
using a Zipfian distribution, to validate our framework.

</details>


### [7] [ScamDetect: Towards a Robust, Agnostic Framework to Uncover Threats in Smart Contracts](https://arxiv.org/abs/2508.07094)
*Pasquale De Rosa,Pascal Felber,Valerio Schiavoni*

Main category: cs.CR

TL;DR: 论文提出ScamDetect框架，通过静态分析和图神经网络检测智能合约中的恶意行为，解决混淆代码和跨平台兼容性问题。


<details>
  <summary>Details</summary>
Motivation: 智能合约的广泛应用和金融重要性吸引了复杂威胁，传统检测方法存在隐私和安全问题。

Method: 分两阶段：1) 使用GNN分析EVM字节码的控制流图；2) 扩展至WASM等新兴运行时。

Result: PhishingHook框架已实现约90%的检测准确率。

Conclusion: ScamDetect旨在为去中心化生态系统提供可扩展的安全解决方案。

Abstract: Smart contracts have transformed decentralized finance by enabling
programmable, trustless transactions. However, their widespread adoption and
growing financial significance have attracted persistent and sophisticated
threats, such as phishing campaigns and contract-level exploits. Traditional
transaction-based threat detection methods often expose sensitive user data and
interactions, raising privacy and security concerns. In response, static
bytecode analysis has emerged as a proactive mitigation strategy, identifying
malicious contracts before they execute harmful actions.Building on this
approach, we introduced PhishingHook, the first machine-learning-based
framework for detecting phishing activities in smart contracts via static
bytecode and opcode analysis, achieving approximately 90% detection accuracy.
Nevertheless, two pressing challenges remain: (1) the increasing use of
sophisticated bytecode obfuscation techniques designed to evade static
analysis, and (2) the heterogeneity of blockchain environments requiring
platform-agnostic solutions.This paper presents a vision for ScamDetect (Smart
Contract Agnostic Malware Detector), a robust, modular, and platform-agnostic
framework for smart contract malware detection. Over the next 2.5 years,
ScamDetect will evolve in two stages: first, by tackling obfuscated Ethereum
Virtual Machine (EVM) bytecode through graph neural network (GNN) analysis of
control flow graphs (CFGs), leveraging GNNs' ability to capture complex
structural patterns beyond opcode sequences; and second, by generalizing
detection capabilities to emerging runtimes such as WASM. ScamDetect aims to
enable proactive, scalable security for the future of decentralized ecosystems.

</details>


### [8] [A Real-Time, Self-Tuning Moderator Framework for Adversarial Prompt Detection](https://arxiv.org/abs/2508.07139)
*Ivan Zhang*

Main category: cs.CR

TL;DR: 提出了一种实时自调优（RTST）框架，用于防御LLM的对立攻击和越狱，同时保持轻量级训练。


<details>
  <summary>Details</summary>
Motivation: 随着AI模型在社会中的广泛应用，确保LLM的对齐性对信息安全至关重要，但现有防御方法难以快速适应新攻击或影响模型正常响应。

Method: 引入RTST框架，实时自适应防御对立攻击，保持轻量级训练。

Result: 在Google的Gemini模型上测试，证明其优于传统微调或分类器模型。

Conclusion: RTST框架为LLM防御提供了一种高效、自适应的解决方案。

Abstract: Ensuring LLM alignment is critical to information security as AI models
become increasingly widespread and integrated in society. Unfortunately, many
defenses against adversarial attacks and jailbreaking on LLMs cannot adapt
quickly to new attacks, degrade model responses to benign prompts, or introduce
significant barriers to scalable implementation. To mitigate these challenges,
we introduce a real-time, self-tuning (RTST) moderator framework to defend
against adversarial attacks while maintaining a lightweight training footprint.
We empirically evaluate its effectiveness using Google's Gemini models against
modern, effective jailbreaks. Our results demonstrate the advantages of an
adaptive, minimally intrusive framework for jailbreak defense over traditional
fine-tuning or classifier models.

</details>


### [9] [Understanding NFTs from EIP Standards](https://arxiv.org/abs/2508.07190)
*Minfeng Qi,Qin Wang,Guangsheng Yu,Ruiqiang Li,Victor Zhou,Shiping Chen*

Main category: cs.CR

TL;DR: 本文首次从以太坊改进提案（EIPs）角度系统研究NFT技术基础，揭示标准间互操作性差及功能复杂性带来的安全风险。


<details>
  <summary>Details</summary>
Motivation: 现有研究多关注NFT市场动态和用户行为，缺乏对其技术标准的系统性分析。

Method: 对191个NFT相关EIPs及10K+社区讨论进行多维分析，包括Solidity接口解析、继承结构建模、贡献者分析和社区数据挖掘。

Result: 区分了基础与新兴标准，发现跨版本互操作性差，功能复杂性加剧安全风险。

Conclusion: NFT技术标准需进一步优化以提升互操作性和安全性。

Abstract: We argue that the technical foundations of non-fungible tokens (NFTs) remain
inadequately understood. Prior research has focused on market dynamics, user
behavior, and isolated security incidents, yet systematic analysis of the
standards underpinning NFT functionality is largely absent.
  We present the first study of NFTs through the lens of Ethereum Improvement
Proposals (EIPs). We conduct a large-scale empirical analysis of 191
NFT-related EIPs and 10K+ Ethereum Magicians discussions (as of July, 2025). We
integrate multi-dimensional analyses including the automated parsing of
Solidity interfaces, graph-based modeling of inheritance structures,
contributor profiling, and mining of community discussion data. We distinguish
foundational from emerging standards, expose poor cross-version
interoperability, and show that growing functional complexity heightens
security risks.

</details>


### [10] [Fading the Digital Ink: A Universal Black-Box Attack Framework for 3DGS Watermarking Systems](https://arxiv.org/abs/2508.07263)
*Qingyuan Zeng,Shu Jiang,Jiajing Lin,Zhenzhong Wang,Kay Chen Tan,Min Jiang*

Main category: cs.CR

TL;DR: 本文提出了一种名为GMEA的黑盒攻击框架，用于挑战3D高斯泼溅（3DGS）中的数字水印技术，通过多目标优化平衡水印移除与视觉质量。


<details>
  <summary>Details</summary>
Motivation: 随着3DGS的兴起，数字水印技术用于版权保护，但其对抗攻击的鲁棒性尚未充分研究。

Method: 提出GMEA框架，将攻击建模为大规模多目标优化问题，采用基于组的优化策略处理3DGS模型的大搜索空间。

Result: 实验表明，GMEA能有效移除主流3DGS水印方法中的1D和2D水印，同时保持高视觉保真度。

Conclusion: 揭示了现有3DGS版权保护方案的脆弱性，呼吁开发更鲁棒的水印系统。

Abstract: With the rise of 3D Gaussian Splatting (3DGS), a variety of digital
watermarking techniques, embedding either 1D bitstreams or 2D images, are used
for copyright protection. However, the robustness of these watermarking
techniques against potential attacks remains underexplored. This paper
introduces the first universal black-box attack framework, the Group-based
Multi-objective Evolutionary Attack (GMEA), designed to challenge these
watermarking systems. We formulate the attack as a large-scale multi-objective
optimization problem, balancing watermark removal with visual quality. In a
black-box setting, we introduce an indirect objective function that blinds the
watermark detector by minimizing the standard deviation of features extracted
by a convolutional network, thus rendering the feature maps uninformative. To
manage the vast search space of 3DGS models, we employ a group-based
optimization strategy to partition the model into multiple, independent
sub-optimization problems. Experiments demonstrate that our framework
effectively removes both 1D and 2D watermarks from mainstream 3DGS watermarking
methods while maintaining high visual fidelity. This work reveals critical
vulnerabilities in existing 3DGS copyright protection schemes and calls for the
development of more robust watermarking systems.

</details>


### [11] [SRAM-based Physically Unclonable Function using Lightweight Hamming-Code Fuzzy Extractor for Energy Harvesting Beat Sensors](https://arxiv.org/abs/2508.07510)
*Hoang-Long Pham,Duy-Hieu Bui,Xuan-Tu Tran,Orazio Aiello*

Main category: cs.CR

TL;DR: 本文提出了一种基于SRAM的物理不可克隆函数（PUF）结合高可靠性比特选择算法和轻量级纠错码的方法，为无电池能量收集物联网传感器节点（如心跳传感器）生成安全密钥。


<details>
  <summary>Details</summary>
Motivation: 无电池传感器节点缺乏安全机制保护用户数据，而传统加密密钥生成方法存在挑战。

Method: 利用SRAM的随机性，结合高可靠性比特选择算法和轻量级纠错码，生成可靠的安全密钥。

Result: 系统在STM32 Cortex M0+微控制器上评估并成功应用于心跳传感器数据保护。

Conclusion: 该方法为无电池传感器节点提供了一种高效、可靠的安全解决方案。

Abstract: Batteryless energy harvesting IoT sensor nodes such as beat sensors can be
deployed in millions without the need to replace batteries. They are
ultra-low-power and cost-effective wireless sensor nodes without the
maintenance cost and can work for 24 hours/365 days. However, they were not
equipped with security mechanisms to protect user data. Data encryption and
authentication can be used to secure beat sensor applications, but generating a
secure cryptographic key is challenging. In this paper, we proposed an
SRAM-based Physically Unclonable Function (PUF) combining a high-reliability
bit selection algorithm with a lightweight error-correcting code to generate
reliable secure keys for data encryption. The system employs a feature of beat
sensors, in which the microcontroller is powered on to transmit the ID signals
and then powered off. This fits the SRAM-based PUF requirement, which needs the
SRAM to be powered off to read out its random values. The proposed system has
been evaluated on STM32 Cortex M0+ microcontrollers and has been implemented to
protect important data on beat sensors.

</details>


### [12] [Chimera: Harnessing Multi-Agent LLMs for Automatic Insider Threat Simulation](https://arxiv.org/abs/2508.07745)
*Jiongchi Yu,Xiaofei Xie,Qiang Hu,Yuhan Ma,Ziming Zhao*

Main category: cs.CR

TL;DR: 提出了一种基于大型语言模型的多代理框架Chimera，用于模拟企业内部合法和恶意活动，生成高质量数据集ChimeraLog，解决了现有数据稀缺问题。


<details>
  <summary>Details</summary>
Motivation: 企业内部数据敏感且难以获取，公开数据集规模有限或缺乏真实性，阻碍了机器学习在内部威胁检测中的发展。

Method: Chimera通过多代理模拟员工行为，包括角色特定行为、组织动态和15种内部攻击类型，生成多样化日志。

Result: 生成的ChimeraLog数据集在多样性和真实性上表现优异，现有检测方法在其上的F1分数（0.83）显著低于CERT数据集（0.99）。

Conclusion: ChimeraLog为内部威胁检测研究提供了更具挑战性和实用性的数据集，推动了该领域的发展。

Abstract: Insider threats, which can lead to severe losses, remain a major security
concern. While machine learning-based insider threat detection (ITD) methods
have shown promising results, their progress is hindered by the scarcity of
high-quality data. Enterprise data is sensitive and rarely accessible, while
publicly available datasets, when limited in scale due to cost, lack sufficient
real-world coverage; and when purely synthetic, they fail to capture rich
semantics and realistic user behavior. To address this, we propose Chimera, the
first large language model (LLM)-based multi-agent framework that automatically
simulates both benign and malicious insider activities and collects diverse
logs across diverse enterprise environments. Chimera models each employee with
agents that have role-specific behavior and integrates modules for group
meetings, pairwise interactions, and autonomous scheduling, capturing realistic
organizational dynamics. It incorporates 15 types of insider attacks (e.g., IP
theft, system sabotage) and has been deployed to simulate activities in three
sensitive domains: technology company, finance corporation, and medical
institution, producing a new dataset, ChimeraLog. We assess ChimeraLog via
human studies and quantitative analysis, confirming its diversity, realism, and
presence of explainable threat patterns. Evaluations of existing ITD methods
show an average F1-score of 0.83, which is significantly lower than 0.99 on the
CERT dataset, demonstrating ChimeraLog's higher difficulty and utility for
advancing ITD research.

</details>


### [13] [A Comparative Analysis of Lightweight Hash Functions Using AVR ATXMega128 and ChipWhisperer](https://arxiv.org/abs/2508.07840)
*Mohsin Khan,Dag Johansen,Håvard Dagenborg*

Main category: cs.CR

TL;DR: 本文对22种轻量级哈希函数进行了比较分析，使用AVR ATXMega128微控制器和ChipWhisperer平台评估了执行速度、内存占用和能耗等维度，并提出了E-RANK指标。


<details>
  <summary>Details</summary>
Motivation: 轻量级哈希函数在嵌入式系统和物联网中的安全性至关重要，但现有算法的性能差异较大，需要系统化的比较分析。

Method: 采用AVR ATXMega128微控制器和ChipWhisperer平台，结合新颖的基准测试方法，评估哈希函数的执行速度、内存占用和能耗。

Result: 通过E-RANK指标，揭示了不同哈希函数在性能与资源消耗之间的权衡。

Conclusion: 研究为开发者提供了选择轻量级哈希函数的实用参考，并展示了E-RANK指标的有效性。

Abstract: Lightweight hash functions have become important building blocks for security
in embedded and IoT systems. A plethora of algorithms have been proposed and
standardized, providing a wide range of performance trade-off options for
developers to choose from. This paper presents a comparative analysis of 22 key
software-based lightweight hash functions, including the finalist from the
SHA-3 competition. We use a novel benchmark methodology that combines an AVR
ATXMega128 microcontroller with the ChipWhisperer cryptanalysis platform and
evaluate and compare the various hash functions along several dimensions,
including execution speed, % measured in Cycles per Byte (CpB), memory
footprint, and energy consumption. Using the composite E-RANK metric, we
provide new insight into the various trade-offs each hash function offers to
system developers.

</details>


### [14] [EFU: Enforcing Federated Unlearning via Functional Encryption](https://arxiv.org/abs/2508.07873)
*Samaneh Mohammadi,Vasileios Tsouvalas,Iraklis Symeonidis,Ali Balador,Tanir Ozcelebi,Francesco Flammini,Nirvana Meratnia*

Main category: cs.CR

TL;DR: EFU是一种通过加密技术强制执行联邦遗忘的框架，保护客户隐私，同时隐藏遗忘意图。


<details>
  <summary>Details</summary>
Motivation: 现有联邦遗忘方法依赖服务器合作，可能泄露客户意图和身份，EFU旨在解决这一问题。

Method: 利用功能加密绑定加密更新到特定聚合函数，结合对抗性示例和参数重要性正则化。

Result: EFU在遗忘数据上接近随机准确率，性能接近完全重新训练，同时隐藏遗忘意图。

Conclusion: EFU适用于任何客户端联邦遗忘机制，提供安全、功能隐藏和可验证的遗忘。

Abstract: Federated unlearning (FU) algorithms allow clients in federated settings to
exercise their ''right to be forgotten'' by removing the influence of their
data from a collaboratively trained model. Existing FU methods maintain data
privacy by performing unlearning locally on the client-side and sending
targeted updates to the server without exposing forgotten data; yet they often
rely on server-side cooperation, revealing the client's intent and identity
without enforcement guarantees - compromising autonomy and unlearning privacy.
In this work, we propose EFU (Enforced Federated Unlearning), a
cryptographically enforced FU framework that enables clients to initiate
unlearning while concealing its occurrence from the server. Specifically, EFU
leverages functional encryption to bind encrypted updates to specific
aggregation functions, ensuring the server can neither perform unauthorized
computations nor detect or skip unlearning requests. To further mask behavioral
and parameter shifts in the aggregated model, we incorporate auxiliary
unlearning losses based on adversarial examples and parameter importance
regularization. Extensive experiments show that EFU achieves near-random
accuracy on forgotten data while maintaining performance comparable to full
retraining across datasets and neural architectures - all while concealing
unlearning intent from the server. Furthermore, we demonstrate that EFU is
agnostic to the underlying unlearning algorithm, enabling secure,
function-hiding, and verifiable unlearning for any client-side FU mechanism
that issues targeted updates.

</details>


### [15] [Robust Anomaly Detection in O-RAN: Leveraging LLMs against Data Manipulation Attacks](https://arxiv.org/abs/2508.08029)
*Thusitha Dayaratne,Ngoc Duy Pham,Viet Vo,Shangqi Lai,Sharif Abuadbba,Hajime Suzuki,Xingliang Yuan,Carsten Rudolph*

Main category: cs.CR

TL;DR: 论文研究了5G和O-RAN架构中SDL层的数据操纵攻击问题，提出使用LLM进行异常检测，验证了其对抗攻击的鲁棒性和低延迟特性。


<details>
  <summary>Details</summary>
Motivation: 5G和O-RAN架构的灵活性和开放性带来了新的安全挑战，如恶意xApps通过Unicode操纵数据绕过传统ML检测方法。

Method: 采用大型语言模型（LLM）进行异常检测，测试其对Unicode操纵数据的处理能力和检测延迟。

Result: LLM能稳定处理被操纵数据且不崩溃，检测延迟低于0.07秒，但初始检测精度需进一步提升。

Conclusion: LLM在对抗攻击中表现出鲁棒性和低延迟，适合O-RAN部署，未来可通过提示工程提高精度。

Abstract: The introduction of 5G and the Open Radio Access Network (O-RAN) architecture
has enabled more flexible and intelligent network deployments. However, the
increased complexity and openness of these architectures also introduce novel
security challenges, such as data manipulation attacks on the semi-standardised
Shared Data Layer (SDL) within the O-RAN platform through malicious xApps. In
particular, malicious xApps can exploit this vulnerability by introducing
subtle Unicode-wise alterations (hypoglyphs) into the data that are being used
by traditional machine learning (ML)-based anomaly detection methods. These
Unicode-wise manipulations can potentially bypass detection and cause failures
in anomaly detection systems based on traditional ML, such as AutoEncoders,
which are unable to process hypoglyphed data without crashing. We investigate
the use of Large Language Models (LLMs) for anomaly detection within the O-RAN
architecture to address this challenge. We demonstrate that LLM-based xApps
maintain robust operational performance and are capable of processing
manipulated messages without crashing. While initial detection accuracy
requires further improvements, our results highlight the robustness of LLMs to
adversarial attacks such as hypoglyphs in input data. There is potential to use
their adaptability through prompt engineering to further improve the accuracy,
although this requires further research. Additionally, we show that LLMs
achieve low detection latency (under 0.07 seconds), making them suitable for
Near-Real-Time (Near-RT) RIC deployments.

</details>


### [16] [IPBA: Imperceptible Perturbation Backdoor Attack in Federated Self-Supervised Learning](https://arxiv.org/abs/2508.08031)
*Jiayao Wang,Yang Song,Zhendong Zhao,Jiale Zhang,Qilin Wu,Junwu Zhu,Dongfang Zhao*

Main category: cs.CR

TL;DR: 本文提出了一种针对联邦自监督学习（FSSL）的隐蔽且有效的后门攻击方法IPBA，解决了现有方法在隐蔽性和实用性上的不足。


<details>
  <summary>Details</summary>
Motivation: FSSL结合了去中心化建模和无监督表示学习的优势，但其易受后门攻击，且现有攻击方法隐蔽性不足。

Method: IPBA通过解耦后门样本和增强样本的特征分布，并引入Sliced-Wasserstein距离优化触发生成过程。

Result: 实验表明，IPBA在性能和隐蔽性上显著优于现有方法，并在多种防御机制下表现出强鲁棒性。

Conclusion: IPBA为FSSL中的后门攻击提供了一种高效且隐蔽的解决方案。

Abstract: Federated self-supervised learning (FSSL) combines the advantages of
decentralized modeling and unlabeled representation learning, serving as a
cutting-edge paradigm with strong potential for scalability and privacy
preservation. Although FSSL has garnered increasing attention, research
indicates that it remains vulnerable to backdoor attacks. Existing methods
generally rely on visually obvious triggers, which makes it difficult to meet
the requirements for stealth and practicality in real-world deployment. In this
paper, we propose an imperceptible and effective backdoor attack method against
FSSL, called IPBA. Our empirical study reveals that existing imperceptible
triggers face a series of challenges in FSSL, particularly limited
transferability, feature entanglement with augmented samples, and
out-of-distribution properties. These issues collectively undermine the
effectiveness and stealthiness of traditional backdoor attacks in FSSL. To
overcome these challenges, IPBA decouples the feature distributions of backdoor
and augmented samples, and introduces Sliced-Wasserstein distance to mitigate
the out-of-distribution properties of backdoor samples, thereby optimizing the
trigger generation process. Our experimental results on several FSSL scenarios
and datasets show that IPBA significantly outperforms existing backdoor attack
methods in performance and exhibits strong robustness under various defense
mechanisms.

</details>


### [17] [False Reality: Uncovering Sensor-induced Human-VR Interaction Vulnerability](https://arxiv.org/abs/2508.08043)
*Yancheng Jiang,Yan Jiang,Ruochen Zhou,Yi-Chao Chen,Xiaoyu Ji,Wenyuan Xu*

Main category: cs.CR

TL;DR: 本文首次系统分析了针对VR系统的物理攻击，提出了一种无需修改软件的新型威胁False Reality，通过干扰传感器数据欺骗用户感知甚至诱导危险行为，并通过实验验证了攻击路径，最后提出了防御方案。


<details>
  <summary>Details</summary>
Motivation: VR技术广泛应用，但现有攻击通常需要高权限和专业知识。本文旨在研究无需软件修改的物理攻击，揭示VR系统的潜在安全威胁。

Method: 提出False Reality攻击，通过干扰传感器数据欺骗用户感知；形式化攻击路径框架，并通过物理实验和用户研究验证了三种代表性攻击路径。

Result: 实验验证了False Reality攻击的有效性，成功诱导用户产生眩晕或碰撞障碍物等危险行为。

Conclusion: 本文揭示了VR系统的新型物理攻击威胁，提出了防御方案，为未来VR系统的安全性和韧性提供了重要参考。

Abstract: Virtual Reality (VR) techniques, serving as the bridge between the real and
virtual worlds, have boomed and are widely used in manufacturing, remote
healthcare, gaming, etc. Specifically, VR systems offer users immersive
experiences that include both perceptions and actions. Various studies have
demonstrated that attackers can manipulate VR software to influence users'
interactions, including perception and actions. However, such attacks typically
require strong access and specialized expertise. In this paper, we are the
first to present a systematic analysis of physical attacks against VR systems
and introduce False Reality, a new attack threat to VR devices without
requiring access to or modification of their software. False Reality disturbs
VR system services by tampering with sensor measurements, and further spoofing
users' perception even inducing harmful actions, e.g., inducing dizziness or
causing users to crash into obstacles, by exploiting perceptual and
psychological effects. We formalize these threats through an attack pathway
framework and validate three representative pathways via physical experiments
and user studies on five commercial VR devices. Finally, we further propose a
defense prototype to mitigate such threats. Our findings shall provide valuable
insights for enhancing the security and resilience of future VR systems.

</details>


### [18] [Fully-Fluctuating Participation in Sleepy Consensus](https://arxiv.org/abs/2508.08068)
*Yuval Efron,Joachim Neu,Toniann Pitassi*

Main category: cs.CR

TL;DR: 本文提出了一种新的敌手模型（外部敌手），用于解决睡眠模型中协议在参与度剧烈波动时的安全性问题，同时保持效率和抗腐败能力。


<details>
  <summary>Details</summary>
Motivation: 现有睡眠模型中的协议在参与度剧烈波动时无法媲美比特币的安全性，且需依赖限制性假设。

Method: 引入外部敌手模型，假设腐败节点不会泄露其私钥信息。

Result: 在该模型下，睡眠模型协议能够在不牺牲效率或抗腐败能力的情况下，安全应对参与度剧烈波动。

Conclusion: 外部敌手模型自然且理论上有吸引力，突破了近期研究中提出的障碍。

Abstract: Proof-of-work allows Bitcoin to boast security amidst arbitrary fluctuations
in participation of miners throughout time, so long as, at any point in time, a
majority of hash power is honest. In recent years, however, the pendulum has
shifted in favor of proof-of-stake-based consensus protocols. There, the sleepy
model is the most prominent model for handling fluctuating participation of
nodes. However, to date, no protocol in the sleepy model rivals Bitcoin in its
robustness to drastic fluctuations in participation levels, with
state-of-the-art protocols making various restrictive assumptions. In this
work, we present a new adversary model, called external adversary. Intuitively,
in our model, corrupt nodes do not divulge information about their secret keys.
In this model, we show that protocols in the sleepy model can meaningfully
claim to remain secure against fully fluctuating participation, without
compromising efficiency or corruption resilience. Our adversary model is quite
natural, and arguably naturally captures the process via which malicious
behavior arises in protocols, as opposed to traditional worst-case modeling. On
top of which, the model is also theoretically appealing, circumventing a
barrier established in a recent work of Malkhi, Momose, and Ren.

</details>


### [19] [Differential Privacy for Regulatory Compliance in Cyberattack Detection on Critical Infrastructure Systems](https://arxiv.org/abs/2508.08190)
*Paritosh Ramanan,H. M. Mohaimanul Islam,Abhiram Reddy Alugula*

Main category: cs.CR

TL;DR: 提出了一种基于差分隐私假设检验的网络攻击检测框架，旨在增强监管信心并缓解关键基础设施网络（CIN）利益相关者的隐私问题。


<details>
  <summary>Details</summary>
Motivation: 随着网络攻击风险的增加，监管合规要求也在提高，但利益相关者需要披露传感器和控制数据，引发隐私问题。

Method: 采用两阶段隐私方案，保护协方差及相关传感器驱动测试统计的隐私，同时生成警报。

Result: 理论证明该方法在非差分隐私情况下的误分类错误率相当，并提供强大的隐私保证；实际数据集验证了其在多种攻击场景下的可靠性。

Conclusion: 该框架在确保系统稳定性的同时，有效平衡了监管需求和隐私保护。

Abstract: Industrial control systems are a fundamental component of critical
infrastructure networks (CIN) such as gas, water and power. With the growing
risk of cyberattacks, regulatory compliance requirements are also increasing
for large scale critical infrastructure systems comprising multiple utility
stakeholders. The primary goal of regulators is to ensure overall system
stability with recourse to trustworthy stakeholder attack detection. However,
adhering to compliance requirements requires stakeholders to also disclose
sensor and control data to regulators raising privacy concerns. In this paper,
we present a cyberattack detection framework that utilizes differentially
private (DP) hypothesis tests geared towards enhancing regulatory confidence
while alleviating privacy concerns of CIN stakeholders. The hallmark of our
approach is a two phase privacy scheme that protects the privacy of covariance,
as well as the associated sensor driven test statistics computed as a means to
generate alarms. Theoretically, we show that our method induces a
misclassification error rate comparable to the non-DP cases while delivering
robust privacy guarantees. With the help of real-world datasets, we show the
reliability of our DP-detection outcomes for a wide variety of attack scenarios
for interdependent stakeholders.

</details>
