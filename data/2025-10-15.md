<div id=toc></div>

# Table of Contents

- [cs.CR](#cs.CR) [Total: 25]


<div id='cs.CR'></div>

# cs.CR [[Back]](#toc)

### [1] [A Comprehensive Survey of Website Fingerprinting Attacks and Defenses in Tor: Advances and Open Challenges](https://arxiv.org/abs/2510.11804)
*Yuwen Cui,Guangjing Wang,Khanh Vu,Kai Wei,Kehan Shen,Zhengyuan Jiang,Xiao Han,Ning Wang,Zhuo Lu,Yao Liu*

Main category: cs.CR

TL;DR: 本文对Tor网络中的网站指纹攻击研究进行了全面综述，系统分类了数据集、攻击模型和防御机制，分析了现有技术的优缺点，并指出了多标签浏览和粗粒度流量特征等新兴挑战。


<details>
  <summary>Details</summary>
Motivation: Tor网络虽然提供强匿名性，但仍易受流量分析攻击，特别是网站指纹攻击。尽管已有多种防御方案，但缺乏对WF研究的系统综述，需要统一分析数据集、攻击方法和防御策略。

Method: 系统性地将现有WF研究分类为三个关键领域：数据集、攻击模型和防御机制，进行深入的比较分析，评估不同威胁模型下的技术优劣。

Result: 提供了对WF攻击和防御技术的全面比较分析，揭示了各种方法的优势和局限性，特别是在不同威胁模型下的表现差异。

Conclusion: 本综述为推进Tor网络更强的隐私保护奠定了基础，通过整合先前工作并确定开放研究方向，有助于未来隐私保护技术的发展。

Abstract: The Tor network provides users with strong anonymity by routing their
internet traffic through multiple relays. While Tor encrypts traffic and hides
IP addresses, it remains vulnerable to traffic analysis attacks such as the
website fingerprinting (WF) attack, achieving increasingly high fingerprinting
accuracy even under open-world conditions. In response, researchers have
proposed a variety of defenses, ranging from adaptive padding, traffic
regularization, and traffic morphing to adversarial perturbation, that seek to
obfuscate or reshape traffic traces. However, these defenses often entail
trade-offs between privacy, usability, and system performance. Despite
extensive research, a comprehensive survey unifying WF datasets, attack
methodologies, and defense strategies remains absent. This paper fills that gap
by systematically categorizing existing WF research into three key domains:
datasets, attack models, and defense mechanisms. We provide an in-depth
comparative analysis of techniques, highlight their strengths and limitations
under diverse threat models, and discuss emerging challenges such as multi-tab
browsing and coarse-grained traffic features. By consolidating prior work and
identifying open research directions, this survey serves as a foundation for
advancing stronger privacy protection in Tor.

</details>


### [2] [BlackIce: A Containerized Red Teaming Toolkit for AI Security Testing](https://arxiv.org/abs/2510.11823)
*Caelin Kaplan,Alexander Warnecke,Neil Archibald*

Main category: cs.CR

TL;DR: BlackIce是一个开源容器化工具包，用于对大型语言模型和传统机器学习模型进行红队测试，旨在降低AI安全评估的门槛。


<details>
  <summary>Details</summary>
Motivation: AI模型在现实系统中的集成日益增加，引发了对其安全性的担忧。现有AI红队工具众多且依赖复杂，需要降低使用门槛并建立标准化环境。

Method: 开发了基于Docker的容器化工具包，集成了14个精选的开源工具，提供统一的命令行界面和模块化架构。

Result: 创建了可复现、版本固定的Docker镜像，简化了红队评估的启动过程，支持本地或云端部署。

Conclusion: BlackIce成功提供了一个标准化的AI红队测试环境，降低了使用门槛，并支持社区驱动的扩展。

Abstract: AI models are being increasingly integrated into real-world systems, raising
significant concerns about their safety and security. Consequently, AI red
teaming has become essential for organizations to proactively identify and
address vulnerabilities before they can be exploited by adversaries. While
numerous AI red teaming tools currently exist, practitioners face challenges in
selecting the most appropriate tools from a rapidly expanding landscape, as
well as managing complex and frequently conflicting software dependencies
across isolated projects. Given these challenges and the relatively small
number of organizations with dedicated AI red teams, there is a strong need to
lower barriers to entry and establish a standardized environment that
simplifies the setup and execution of comprehensive AI model assessments.
  Inspired by Kali Linux's role in traditional penetration testing, we
introduce BlackIce, an open-source containerized toolkit designed for red
teaming Large Language Models (LLMs) and classical machine learning (ML)
models. BlackIce provides a reproducible, version-pinned Docker image that
bundles 14 carefully selected open-source tools for Responsible AI and Security
testing, all accessible via a unified command-line interface. With this setup,
initiating red team assessments is as straightforward as launching a container,
either locally or using a cloud platform. Additionally, the image's modular
architecture facilitates community-driven extensions, allowing users to easily
adapt or expand the toolkit as new threats emerge. In this paper, we describe
the architecture of the container image, the process used for selecting tools,
and the types of evaluations they support.

</details>


### [3] [Countermind: A Multi-Layered Security Architecture for Large Language Models](https://arxiv.org/abs/2510.11837)
*Dominik Schwarz*

Main category: cs.CR

TL;DR: 提出了Countermind多层安全架构，通过语义边界逻辑、参数空间限制、自调节核心和多模态输入沙箱等机制，从被动防御转向主动的推理前和推理中安全执行。


<details>
  <summary>Details</summary>
Motivation: 传统LLM应用安全防御依赖事后输出过滤，脆弱且无法解决根本问题——模型无法区分可信指令和不可信数据。需要从根源上防御提示注入和越狱等'形式优先'攻击。

Method: 1. 语义边界逻辑(SBL)和时间耦合文本加密器减少明文提示注入攻击面；2. 参数空间限制(PSR)动态控制LLM对内部语义簇的访问；3. 自调节核心使用OODA循环和学习安全模块；4. 多模态输入沙箱和上下文防御机制。

Result: 论文提出了评估计划，旨在量化该架构在降低形式优先攻击成功率(ASR)方面的有效性，并测量其潜在延迟开销。

Conclusion: Countermind架构将LLM安全防御从被动反应转向主动执行，通过结构化的输入验证、语义处理路径约束和自适应防御机制，从根本上增强模型安全性。

Abstract: The security of Large Language Model (LLM) applications is fundamentally
challenged by "form-first" attacks like prompt injection and jailbreaking,
where malicious instructions are embedded within user inputs. Conventional
defenses, which rely on post hoc output filtering, are often brittle and fail
to address the root cause: the model's inability to distinguish trusted
instructions from untrusted data. This paper proposes Countermind, a
multi-layered security architecture intended to shift defenses from a reactive,
post hoc posture to a proactive, pre-inference, and intra-inference enforcement
model. The architecture proposes a fortified perimeter designed to structurally
validate and transform all inputs, and an internal governance mechanism
intended to constrain the model's semantic processing pathways before an output
is generated. The primary contributions of this work are conceptual designs
for: (1) A Semantic Boundary Logic (SBL) with a mandatory, time-coupled Text
Crypter intended to reduce the plaintext prompt injection attack surface,
provided all ingestion paths are enforced. (2) A Parameter-Space Restriction
(PSR) mechanism, leveraging principles from representation engineering, to
dynamically control the LLM's access to internal semantic clusters, with the
goal of mitigating semantic drift and dangerous emergent behaviors. (3) A
Secure, Self-Regulating Core that uses an OODA loop and a learning security
module to adapt its defenses based on an immutable audit log. (4) A Multimodal
Input Sandbox and Context-Defense mechanisms to address threats from
non-textual data and long-term semantic poisoning. This paper outlines an
evaluation plan designed to quantify the proposed architecture's effectiveness
in reducing the Attack Success Rate (ASR) for form-first attacks and to measure
its potential latency overhead.

</details>


### [4] [Deep Research Brings Deeper Harm](https://arxiv.org/abs/2510.11851)
*Shuo Chen,Zonggen Li,Zhen Han,Bailan He,Tong Liu,Haokun Chen,Georg Groh,Philip Torr,Volker Tresp,Jindong Gu*

Main category: cs.CR

TL;DR: 论文发现基于大语言模型的深度研究代理存在严重安全风险，即使LLM本身拒绝的有害查询，通过计划注入和意图劫持等新型越狱策略，DR代理仍能生成详细危险的专业报告。


<details>
  <summary>Details</summary>
Motivation: 深度研究代理在生物安全等高风险领域可能被滥用生成包含禁止知识的专业报告，现有LLM越狱方法无法暴露DR代理特有的研究能力风险。

Method: 提出两种新型越狱策略：计划注入（在代理计划中注入恶意子目标）和意图劫持（将有查询重新定义为学术研究问题），并在不同LLM和安全基准上进行广泛实验。

Result: 实验发现三个关键结果：1）DR代理中LLM对齐失效；2）多步规划和执行削弱对齐；3）DR代理不仅绕过拒绝，还产生更连贯、专业和危险的内容。

Conclusion: DR代理存在根本性对齐问题，需要专门针对DR代理设计更好的对齐技术。

Abstract: Deep Research (DR) agents built on Large Language Models (LLMs) can perform
complex, multi-step research by decomposing tasks, retrieving online
information, and synthesizing detailed reports. However, the misuse of LLMs
with such powerful capabilities can lead to even greater risks. This is
especially concerning in high-stakes and knowledge-intensive domains such as
biosecurity, where DR can generate a professional report containing detailed
forbidden knowledge. Unfortunately, we have found such risks in practice:
simply submitting a harmful query, which a standalone LLM directly rejects, can
elicit a detailed and dangerous report from DR agents. This highlights the
elevated risks and underscores the need for a deeper safety analysis. Yet,
jailbreak methods designed for LLMs fall short in exposing such unique risks,
as they do not target the research ability of DR agents. To address this gap,
we propose two novel jailbreak strategies: Plan Injection, which injects
malicious sub-goals into the agent's plan; and Intent Hijack, which reframes
harmful queries as academic research questions. We conducted extensive
experiments across different LLMs and various safety benchmarks, including
general and biosecurity forbidden prompts. These experiments reveal 3 key
findings: (1) Alignment of the LLMs often fail in DR agents, where harmful
prompts framed in academic terms can hijack agent intent; (2) Multi-step
planning and execution weaken the alignment, revealing systemic vulnerabilities
that prompt-level safeguards cannot address; (3) DR agents not only bypass
refusals but also produce more coherent, professional, and dangerous content,
compared with standalone LLMs. These results demonstrate a fundamental
misalignment in DR agents and call for better alignment techniques tailored to
DR agents. Code and datasets are available at
https://chenxshuo.github.io/deeper-harm.

</details>


### [5] [Lightweight CNN-Based Wi-Fi Intrusion Detection Using 2D Traffic Representations](https://arxiv.org/abs/2510.11898)
*Rayed Suhail Ahmad,Rehan Ahmad,Quamar Niyaz*

Main category: cs.CR

TL;DR: 提出基于深度学习的Wi-Fi网络入侵检测系统，将网络流量转换为二维数据表示，使用轻量级CNN架构实现低延迟检测，在AWID3数据集上验证了良好的检测性能。


<details>
  <summary>Details</summary>
Motivation: Wi-Fi网络普遍存在但存在安全漏洞，恶意行为者可能未经授权访问或窃取敏感数据，需要有效的入侵检测系统来保护网络。

Method: 将网络流量转换为五种不同的二维数据表示，使用基于卷积神经网络的轻量级深度学习模型进行训练，在AWID3数据集上进行二分类和多分类任务评估。

Result: 实验结果表明该方法实现了有竞争力的检测性能，同时具有低推理时间，适合实际Wi-Fi部署场景。

Conclusion: 提出的深度学习网络入侵检测系统在Wi-Fi环境中表现出良好的检测效果和实时性能，为实际部署提供了可行方案。

Abstract: Wi-Fi networks are ubiquitous in both home and enterprise environments,
serving as a primary medium for Internet access and forming the backbone of
modern IoT ecosystems. However, their inherent vulnerabilities, combined with
widespread adoption, create opportunities for malicious actors to gain
unauthorized access or compromise sensitive data stored on connected devices.
To address these challenges, we propose a deep learning based network intrusion
detection system (NIDS) for Wi-Fi environments. Building on our previous work,
we convert network traffic into two-dimensional data representations and use
them to train DL models based on convolutional neural network (CNN)
architectures. We implement five distinct techniques for generating the
two-dimensional representations, and to ensure low detection latency, we adopt
lightweight CNN architectures in our NIDS. The models are trained using the
AWID3 dataset, a publicly available benchmark for Wi-Fi NIDS research, and are
evaluated for both binary and multi-class classification tasks. Experimental
results demonstrate that the proposed approach achieves competitive detection
performance with low inference time, making it suitable for real-world Wi-Fi
deployment scenarios.

</details>


### [6] [Robust ML-based Detection of Conventional, LLM-Generated, and Adversarial Phishing Emails Using Advanced Text Preprocessing](https://arxiv.org/abs/2510.11915)
*Deeksha Hareesha Kulal,Chidozie Princewill Arannonu,Afsah Anwar,Nidhi Rastogi,Quamar Niyaz*

Main category: cs.CR

TL;DR: 提出了一种针对LLM生成钓鱼邮件的鲁棒检测系统，通过增强的文本预处理流程和机器学习算法，在对抗性攻击和LLM生成钓鱼邮件测试中表现优异。


<details>
  <summary>Details</summary>
Motivation: 随着大型语言模型的发展，钓鱼邮件变得语法正确、上下文相关且语言自然，传统检测机制难以应对，需要开发更鲁棒的检测系统。

Method: 采用增强的文本预处理流程（包括拼写纠正和分词），结合自然语言处理特征提取技术和机器学习算法。

Result: 在公开数据集上达到94.26%的检测准确率和84.39%的F1分数，在对抗性攻击和LLM生成钓鱼邮件测试中表现出良好的鲁棒性。

Conclusion: 提出的系统对不断发展的AI驱动钓鱼威胁具有显著抵抗力，为应对LLM生成的钓鱼邮件提供了有效解决方案。

Abstract: Phishing remains a critical cybersecurity threat, especially with the advent
of large language models (LLMs) capable of generating highly convincing
malicious content. Unlike earlier phishing attempts which are identifiable by
grammatical errors, misspellings, incorrect phrasing, and inconsistent
formatting, LLM generated emails are grammatically sound, contextually
relevant, and linguistically natural. These advancements make phishing emails
increasingly difficult to distinguish from legitimate ones, challenging
traditional detection mechanisms. Conventional phishing detection systems often
fail when faced with emails crafted by LLMs or manipulated using adversarial
perturbation techniques. To address this challenge, we propose a robust
phishing email detection system featuring an enhanced text preprocessing
pipeline. This pipeline includes spelling correction and word splitting to
counteract adversarial modifications and improve detection accuracy. Our
approach integrates widely adopted natural language processing (NLP) feature
extraction techniques and machine learning algorithms. We evaluate our models
on publicly available datasets comprising both phishing and legitimate emails,
achieving a detection accuracy of 94.26% and F1-score of 84.39% in model
deployment setting. To assess robustness, we further evaluate our models using
adversarial phishing samples generated by four attack methods in Python
TextAttack framework. Additionally, we evaluate models' performance against
phishing emails generated by LLMs including ChatGPT and Llama. Results
highlight the resilience of models against evolving AI-powered phishing
threats.

</details>


### [7] [CTIArena: Benchmarking LLM Knowledge and Reasoning Across Heterogeneous Cyber Threat Intelligence](https://arxiv.org/abs/2510.11974)
*Yutong Cheng,Yang Liu,Changze Li,Dawn Song,Peng Gao*

Main category: cs.CR

TL;DR: CTIArena是首个评估LLM在知识增强设置下处理异构多源网络威胁情报(CTI)性能的基准测试，涵盖3类9个任务，发现通用LLM在闭卷设置下表现不佳，但通过检索增强技术可获得显著提升。


<details>
  <summary>Details</summary>
Motivation: 现有CTI评估基准存在三个局限：(i)仅采用闭卷设置，未利用CTI知识库；(ii)任务覆盖范围窄，缺乏系统性；(iii)仅限于单源分析，不符合需要多源推理的现实场景。

Method: 开发CTIArena基准测试，涵盖结构化、非结构化和混合三类CTI任务，共9个任务，评估10个常用LLM在知识增强设置下的表现，采用设计的检索增强技术。

Result: 大多数LLM在闭卷设置下表现不佳，但通过安全特定知识的检索增强技术可获得显著性能提升。

Conclusion: 通用LLM存在局限性，需要领域定制技术才能充分发挥其在CTI分析中的潜力。

Abstract: Cyber threat intelligence (CTI) is central to modern cybersecurity, providing
critical insights for detecting and mitigating evolving threats. With the
natural language understanding and reasoning capabilities of large language
models (LLMs), there is increasing interest in applying them to CTI, which
calls for benchmarks that can rigorously evaluate their performance. Several
early efforts have studied LLMs on some CTI tasks but remain limited: (i) they
adopt only closed-book settings, relying on parametric knowledge without
leveraging CTI knowledge bases; (ii) they cover only a narrow set of tasks,
lacking a systematic view of the CTI landscape; and (iii) they restrict
evaluation to single-source analysis, unlike realistic scenarios that require
reasoning across multiple sources. To fill these gaps, we present CTIArena, the
first benchmark for evaluating LLM performance on heterogeneous, multi-source
CTI under knowledge-augmented settings. CTIArena spans three categories,
structured, unstructured, and hybrid, further divided into nine tasks that
capture the breadth of CTI analysis in modern security operations. We evaluate
ten widely used LLMs and find that most struggle in closed-book setups but show
noticeable gains when augmented with security-specific knowledge through our
designed retrieval-augmented techniques. These findings highlight the
limitations of general-purpose LLMs and the need for domain-tailored techniques
to fully unlock their potential for CTI.

</details>


### [8] [Security and Privacy Assessment of U.S. and Non-U.S. Android E-Commerce Applications](https://arxiv.org/abs/2510.12031)
*Urvashi Kishnani,Sanchari Das*

Main category: cs.CR

TL;DR: 对92个顶级Android电商应用的安全分析显示，92%使用不安全的HTTP连接，平均安全得分仅40.92/100，77个应用存在权限过度授权问题。


<details>
  <summary>Details</summary>
Motivation: 电商移动应用在全球金融交易中占据核心地位，其安全性和隐私保护至关重要，需要系统评估当前应用的安全状况。

Method: 使用MobSF、AndroBugs和RiskInDroid工具分析92个顶级Android电商应用（58个美国应用和34个国际应用）。

Result: 发现广泛的SSL和证书弱点，92%应用使用不安全的HTTP连接，平均安全得分40.92/100，77个应用存在过度授权权限。美国应用在清单、代码和证书漏洞方面表现较好，但两组应用在网络相关问题上表现相似。

Conclusion: 建议各地区采用更强、标准化且以用户为中心的安全实践。

Abstract: E-commerce mobile applications are central to global financial transactions,
making their security and privacy crucial. In this study, we analyze 92
top-grossing Android e-commerce apps (58 U.S.-based and 34 international) using
MobSF, AndroBugs, and RiskInDroid. Our analysis shows widespread SSL and
certificate weaknesses, with approximately 92% using unsecured HTTP connections
and an average MobSF security score of 40.92/100. Over-privileged permissions
were identified in 77 apps. While U.S. apps exhibited fewer manifest, code, and
certificate vulnerabilities, both groups showed similar network-related issues.
We advocate for the adoption of stronger, standardized, and user-focused
security practices across regions.

</details>


### [9] [Over-Threshold Multiparty Private Set Intersection for Collaborative Network Intrusion Detection](https://arxiv.org/abs/2510.12045)
*Onur Eren Arpaci,Raouf Boutaba,Florian Kerschbaum*

Main category: cs.CR

TL;DR: 提出一种保护隐私的IP地址收集协议，通过单收集器超阈值私有集合交集技术，让N个参与者识别出现在至少t个参与者集合中的IP地址，而不泄露其他IP地址信息。


<details>
  <summary>Details</summary>
Motivation: 协作网络入侵检测需要分析参与者的网络日志以发现共同IP地址，但直接共享IP地址会泄露个人身份信息，违反隐私法规。

Method: 使用单收集器超阈值私有集合交集协议，结合新颖的哈希方案，显著降低了计算复杂度。

Result: 将计算复杂度从O(M(N log M/t)^(2t))降低到O(t²M C(N,t))，使协议能够实际应用于真实网络日志。测试验证了协议在多机构联合网络日志中的有效性。

Conclusion: 提出了两种部署方案：防串通部署提供更强安全性但通信开销大，非交互式部署假设收集器不串通但通信成本低，适用于多种协作网络入侵检测场景。

Abstract: An important function of collaborative network intrusion detection is to
analyze the network logs of the collaborators for joint IP addresses. However,
sharing IP addresses in plain is sensitive and may be even subject to privacy
legislation as it is personally identifiable information. In this paper, we
present the privacy-preserving collection of IP addresses. We propose a single
collector, over-threshold private set intersection protocol. In this protocol
$N$ participants identify the IP addresses that appear in at least $t$
participant's sets without revealing any information about other IP addresses.
Using a novel hashing scheme, we reduce the computational complexity of the
previous state-of-the-art solution from $O(M(N \log{M}/t)^{2t})$ to
$O(t^2M\binom{N}{t})$, where $M$ denotes the dataset size. This reduction makes
it practically feasible to apply our protocol to real network logs. We test our
protocol using joint networks logs of multiple institutions. Additionally, we
present two deployment options: a collusion-safe deployment, which provides
stronger security guarantees at the cost of increased communication overhead,
and a non-interactive deployment, which assumes a non-colluding collector but
offers significantly lower communication costs and applicable to many use cases
of collaborative network intrusion detection similar to ours.

</details>


### [10] [Adding All Flavors: A Hybrid Random Number Generator for dApps and Web3](https://arxiv.org/abs/2510.12062)
*Ranjith Chodavarapu,Rabimba Karanjai,Xinxin Fan,Weidong Shi,Lei Xu*

Main category: cs.CR

TL;DR: 提出了一种基于物联网设备和可信执行环境(TEE)的混合随机数生成方案，通过密码学工具聚合多个随机源，为去中心化应用提供可配置的随机数生成框架。


<details>
  <summary>Details</summary>
Motivation: 现有随机数生成机制存在局限性：链上方法易受攻击者影响输入，链下方法安全假设强且复杂度高。需要一种能够平衡各种因素的随机数生成框架。

Method: 利用配备TEE的物联网设备作为随机源，使用密码学工具聚合多个随机源生成最终随机数。方案只需一个诚实的随机源即可保证随机性，并允许用户配置以容忍恶意参与者。

Result: 提供了具体实现方案，进一步降低了链上计算复杂度以减少实际成本。评估了计算和gas成本，证明了改进的有效性。

Conclusion: 该混合随机数生成方案能够为dApp提供灵活可配置的随机数生成服务，在保证安全性的同时降低了复杂度和成本。

Abstract: Random numbers play a vital role in many decentralized applications (dApps),
such as gaming and decentralized finance (DeFi) applications.
  Existing random number provision mechanisms can be roughly divided into two
categories, on-chain, and off-chain.
  On-chain approaches usually rely on the blockchain as the major input and all
computations are done by blockchain nodes.
  The major risk for this type of method is that the input itself is
susceptible to the adversary's influence.
  Off-chain approaches, as the name suggested, complete the generation without
the involvement of blockchain nodes and share the result directly with a dApp.
  These mechanisms usually have a strong security assumption and high
complexity.
  To mitigate these limitations and provide a framework that allows a dApp to
balance different factors involved in random number generation, we propose a
hybrid random number generation solution that leverages IoT devices equipped
with trusted execution environment (TEE) as the randomness sources, and then
utilizes a set of cryptographic tools to aggregate the multiple sources and
obtain the final random number that can be consumed by the dApp.
  The new approach only needs one honest random source to guarantee the
unbiasedness of the final random number and a user can configure the system to
tolerate malicious participants who can refuse to respond to avoid unfavored
results.
  We also provide a concrete construction that can further reduce the on-chain
computation complexity to lower the cost of the solution in practice.
  We evaluate the computation and gas costs to demonstrate the effectiveness of
the improvement.

</details>


### [11] [Elevating Medical Image Security: A Cryptographic Framework Integrating Hyperchaotic Map and GRU](https://arxiv.org/abs/2510.12084)
*Weixuan Li,Guang Yu,Quanjun Li,Junhua Zhou,Jiajun Chen,Yihang Dong,Mengqian Wang,Zimeng Li,Changwei Gong,Lin Tang,Xuhang Chen*

Main category: cs.CR

TL;DR: 提出了Kun-IE图像加密框架，包含2D-SCPHM超混沌映射和Kun-SCAN置换策略，解决了现有混沌加密方法的不足，支持任意尺寸图像加密。


<details>
  <summary>Details</summary>
Motivation: 现有混沌图像加密方法存在排列扩散不足、伪随机性差等漏洞，需要开发更安全可靠的加密方案。

Method: 开发了2D Sin-Cos Pi超混沌映射(2D-SCPHM)提供更宽混沌范围和优质伪随机序列，并提出Kun-SCAN置换策略降低像素相关性。

Result: 实验证明该框架能有效抵抗各种密码分析攻击，为安全图像通信提供了强大解决方案。

Conclusion: Kun-IE框架通过改进的混沌映射和置换策略，显著提升了图像加密的安全性，是混沌图像加密的有效改进方案。

Abstract: Chaotic systems play a key role in modern image encryption due to their
sensitivity to initial conditions, ergodicity, and complex dynamics. However,
many existing chaos-based encryption methods suffer from vulnerabilities, such
as inadequate permutation and diffusion, and suboptimal pseudorandom
properties. This paper presents Kun-IE, a novel encryption framework designed
to address these issues. The framework features two key contributions: the
development of the 2D Sin-Cos Pi Hyperchaotic Map (2D-SCPHM), which offers a
broader chaotic range and superior pseudorandom sequence generation, and the
introduction of Kun-SCAN, a novel permutation strategy that significantly
reduces pixel correlations, enhancing resistance to statistical attacks. Kun-IE
is flexible and supports encryption for images of any size. Experimental
results and security analyses demonstrate its robustness against various
cryptanalytic attacks, making it a strong solution for secure image
communication. The code is available at this
\href{https://github.com/QuincyQAQ/Elevating-Medical-Image-Security-A-Cryptographic-Framework-Integrating-Hyperchaotic-Map-and-GRU}{link}.

</details>


### [12] [Locket: Robust Feature-Locking Technique for Language Models](https://arxiv.org/abs/2510.12117)
*Lipeng He,Vasisht Duddu,N. Asokan*

Main category: cs.CR

TL;DR: Locket是一种新颖的特征锁定技术，通过将适配器与LLM合并来拒绝未经授权的功能，支持按需付费解锁方案，具有高拒绝率、低性能损失、强鲁棒性和良好可扩展性。


<details>
  <summary>Details</summary>
Motivation: 当前聊天机器人提供商使用分层订阅模式，但更细粒度的付费解锁方案被认为更具经济可行性，这需要一种能够有效拒绝锁定功能、保持解锁功能实用性、抵御规避攻击并支持多特征多用户的可扩展特征锁定技术。

Method: Locket采用新颖的合并方法，将适配器附加到LLM上以拒绝未经授权的特征。

Result: 评估显示Locket在锁定特征上达到100%拒绝率，解锁特征性能损失≤7%，攻击成功率≤5%，并能扩展到多个特征和客户端。

Conclusion: Locket是第一个鲁棒且可扩展的特征锁定技术，能够有效支持付费解锁方案，为聊天机器人提供商提供更精细化的商业模式。

Abstract: Chatbot providers (e.g., OpenAI) rely on tiered subscription schemes to
generate revenue, offering basic models for free users, and advanced models for
paying subscribers. However, a finer-grained pay-to-unlock scheme for premium
features (e.g., math, coding) is thought to be more economically viable for the
providers. Such a scheme requires a feature-locking technique (FLoTE) which is
(i) effective in refusing locked features, (ii) utility-preserving for unlocked
features, (iii) robust against evasion or unauthorized credential sharing, and
(iv) scalable to multiple features and users. However, existing FLoTEs (e.g.,
password-locked models) are not robust or scalable. We present Locket, the
first robust and scalable FLoTE to enable pay-to-unlock schemes. Locket uses a
novel merging approach to attach adapters to an LLM for refusing unauthorized
features. Our comprehensive evaluation shows that Locket is effective ($100$%
refusal on locked features), utility-preserving ($\leq 7$% utility degradation
in unlocked features), robust ($\leq 5$% attack success rate), and scales to
multiple features and clients.

</details>


### [13] [VeilAudit: Breaking the Deadlock Between Privacy and Accountability Across Blockchains](https://arxiv.org/abs/2510.12153)
*Minhao Qiao,Iqbal Gondal,Hai Dong*

Main category: cs.CR

TL;DR: VeilAudit是一个跨链审计框架，通过审计者可链接性实现隐私与监管的平衡，允许审计者在不暴露用户身份的情况下链接同一匿名实体的交易行为。


<details>
  <summary>Details</summary>
Motivation: 区块链跨链互操作性在用户隐私和监管问责之间存在根本矛盾，现有解决方案要么完全匿名要么强制身份披露，限制了在受监管金融环境中的采用。

Method: 使用用户生成的链接审计标签，包含零知识证明验证有效性而不暴露主钱包地址；采用特殊密文设计，只有指定审计者可以测试链接性；支持阈值门控身份揭示机制。

Result: 开发了原型系统并在多个EVM链上实现，评估表明该框架在当前多链环境中具有实用性。

Conclusion: VeilAudit成功平衡了隐私和合规需求，为匿名环境中的声誉建立提供了机制，支持基于可验证行为历史的跨链信用评分等应用。

Abstract: Cross chain interoperability in blockchain systems exposes a fundamental
tension between user privacy and regulatory accountability. Existing solutions
enforce an all or nothing choice between full anonymity and mandatory identity
disclosure, which limits adoption in regulated financial settings. We present
VeilAudit, a cross chain auditing framework that introduces Auditor Only
Linkability, which allows auditors to link transaction behaviors that originate
from the same anonymous entity without learning its identity. VeilAudit
achieves this with a user generated Linkable Audit Tag that embeds a zero
knowledge proof to attest to its validity without exposing the user master
wallet address, and with a special ciphertext that only designated auditors can
test for linkage. To balance privacy and compliance, VeilAudit also supports
threshold gated identity revelation under due process. VeilAudit further
provides a mechanism for building reputation in pseudonymous environments,
which enables applications such as cross chain credit scoring based on
verifiable behavioral history. We formalize the security guarantees and develop
a prototype that spans multiple EVM chains. Our evaluation shows that the
framework is practical for today multichain environments.

</details>


### [14] [Leaking Queries On Secure Stream Processing Systems](https://arxiv.org/abs/2510.12172)
*Hung Pham,Viet Vo,Tien Tuan Anh Dinh,Duc Tran,Shuhao Zhang*

Main category: cs.CR

TL;DR: 本文展示了从使用Intel SGX保护执行引擎的流处理系统中提取查询的可行性，通过基于时序侧信道的攻击，攻击成功率高达92%。


<details>
  <summary>Details</summary>
Motivation: 流处理系统在云环境中运行，查询与应用逻辑同样敏感，但现有安全方案主要关注数据保护而非查询保护。

Method: 攻击分两个阶段：离线阶段基于合成数据对单个流操作符进行执行时间分析建立模型；在线阶段隔离查询中的操作符并利用模型恢复操作符。

Result: 基于SecureStream和NEXMark基准测试实现攻击，攻击成功率最高达到92%。

Conclusion: 讨论了在不产生高开销的情况下加固流处理系统以抵御此类攻击的方法。

Abstract: Stream processing systems are important in modern applications in which data
arrive continuously and need to be processed in real time. Because of their
resource and scalability requirements, many of these systems run on the cloud,
which is considered untrusted. Existing works on securing databases on the
cloud focus on protecting the data, and most systems leverage trusted hardware
for high performance. However, in stream processing systems, queries are as
sensitive as the data because they contain the application logics.
  We demonstrate that it is practical to extract the queries from stream
processing systems that use Intel SGX for securing the execution engine. The
attack performed by a malicious cloud provider is based on timing side
channels, and it works in two phases. In the offline phase, the attacker
profiles the execution time of individual stream operators, based on synthetic
data. This phase outputs a model that identifies individual stream operators.
In the online phase, the attacker isolates the operators that make up the
query, monitors its execution, and recovers the operators using the model in
the previous phase. We implement the attack based on popular data stream
benchmarks using SecureStream and NEXMark, and demonstrate attack success rates
of up to 92%. We further discuss approaches that can harden streaming
processing systems against our attacks without incurring high overhead.

</details>


### [15] [HackWorld: Evaluating Computer-Use Agents on Exploiting Web Application Vulnerabilities](https://arxiv.org/abs/2510.12200)
*Xiaoxue Ren,Penghao Jiang,Kaixin Li,Zhiyong Huang,Xiaoning Du,Jiaojiao Jiang,Zhenchang Xing,Jiamou Sun,Terry Yue Zhuo*

Main category: cs.CR

TL;DR: HackWorld是首个通过视觉交互系统评估计算机使用代理(CUAs)利用Web应用漏洞能力的框架，包含36个真实应用和多种漏洞类型，评估显示CUAs的漏洞利用率低于12%，存在多步骤攻击规划失败和安全工具误用等问题。


<details>
  <summary>Details</summary>
Motivation: 传统渗透测试成本高且难以扩展，现代Web应用需要视觉理解和动态内容处理能力，而CUAs在通过图形界面发现和利用漏洞方面的能力尚未被充分探索。

Method: 构建包含36个真实世界应用的HackWorld框架，采用Capture-the-Flag(CTF)设置，测试CUAs在复杂Web界面中识别和利用漏洞的能力。

Result: 最先进的CUAs漏洞利用率低于12%，网络安全意识低，经常在多步骤攻击规划中失败并误用安全工具。

Conclusion: 当前CUAs在Web安全环境中存在明显局限性，需要开发更具安全意识的代理来有效检测和利用漏洞。

Abstract: Web applications are prime targets for cyberattacks as gateways to critical
services and sensitive data. Traditional penetration testing is costly and
expertise-intensive, making it difficult to scale with the growing web
ecosystem. While language model agents show promise in cybersecurity, modern
web applications demand visual understanding, dynamic content handling, and
multi-step interactions that only computer-use agents (CUAs) can perform. Yet,
their ability to discover and exploit vulnerabilities through graphical
interfaces remains largely unexplored. We present HackWorld, the first
framework for systematically evaluating CUAs' capabilities to exploit web
application vulnerabilities via visual interaction. Unlike sanitized
benchmarks, HackWorld includes 36 real-world applications across 11 frameworks
and 7 languages, featuring realistic flaws such as injection vulnerabilities,
authentication bypasses, and unsafe input handling. Using a Capture-the-Flag
(CTF) setup, it tests CUAs' capacity to identify and exploit these weaknesses
while navigating complex web interfaces. Evaluation of state-of-the-art CUAs
reveals concerning trends: exploitation rates below 12% and low cybersecurity
awareness. CUAs often fail at multi-step attack planning and misuse security
tools. These results expose the current limitations of CUAs in web security
contexts and highlight opportunities for developing more security-aware agents
capable of effective vulnerability detection and exploitation.

</details>


### [16] [PromptLocate: Localizing Prompt Injection Attacks](https://arxiv.org/abs/2510.12252)
*Yuqi Jia,Yupei Liu,Zedian Shao,Jinyuan Jia,Neil Gong*

Main category: cs.CR

TL;DR: 提出了PromptLocate方法，这是首个用于定位注入提示的方法，通过三个步骤准确识别被污染数据中的注入指令和数据。


<details>
  <summary>Details</summary>
Motivation: 提示注入攻击通过污染输入数据欺骗大语言模型执行攻击者指定的任务，而定位注入提示对于攻击后取证分析和数据恢复至关重要，但目前该领域仍未被充分探索。

Method: PromptLocate包含三个步骤：(1)将污染数据分割成语义连贯的片段，(2)识别被注入指令污染的片段，(3)定位被注入数据污染的片段。

Result: 实验表明PromptLocate在8个现有攻击和8个自适应攻击中都能准确定位注入提示。

Conclusion: PromptLocate填补了提示注入定位领域的空白，为后攻击分析和数据恢复提供了有效工具。

Abstract: Prompt injection attacks deceive a large language model into completing an
attacker-specified task instead of its intended task by contaminating its input
data with an injected prompt, which consists of injected instruction(s) and
data. Localizing the injected prompt within contaminated data is crucial for
post-attack forensic analysis and data recovery. Despite its growing
importance, prompt injection localization remains largely unexplored. In this
work, we bridge this gap by proposing PromptLocate, the first method for
localizing injected prompts. PromptLocate comprises three steps: (1) splitting
the contaminated data into semantically coherent segments, (2) identifying
segments contaminated by injected instructions, and (3) pinpointing segments
contaminated by injected data. We show PromptLocate accurately localizes
injected prompts across eight existing and eight adaptive attacks.

</details>


### [17] [DeepTrust: Multi-Step Classification through Dissimilar Adversarial Representations for Robust Android Malware Detection](https://arxiv.org/abs/2510.12310)
*Daniel Pulido-Cortázar,Daniel Gibert,Felip Manyà*

Main category: cs.CR

TL;DR: DeepTrust是一种新颖的元启发式方法，通过将柔性分类器排列成有序序列来提升Android恶意软件检测的对抗鲁棒性，在IEEE SaTML 2025竞赛中获得第一名。


<details>
  <summary>Details</summary>
Motivation: 现有的机器学习方法在检测Android恶意应用时容易受到对抗样本攻击，需要提高模型对对抗性扰动的鲁棒性。

Method: 将深度神经网络等柔性分类器排列成有序序列，通过级联激活条件进行最终决策，最大化内部模型间学习表示的差异性。

Result: 在特征空间规避攻击下，性能比次优竞争者提升高达266%，同时保持对非对抗性恶意软件的最高检测率和低于1%的误报率。

Conclusion: 通过使用产生根本不同数据嵌入的分类器，使决策空间对攻击者不可预测，从而在不影响干净样本准确性的前提下增强系统鲁棒性。

Abstract: Over the last decade, machine learning has been extensively applied to
identify malicious Android applications. However, such approaches remain
vulnerable against adversarial examples, i.e., examples that are subtly
manipulated to fool a machine learning model into making incorrect predictions.
This research presents DeepTrust, a novel metaheuristic that arranges flexible
classifiers, like deep neural networks, into an ordered sequence where the
final decision is made by a single internal model based on conditions activated
in cascade. In the Robust Android Malware Detection competition at the 2025
IEEE Conference SaTML, DeepTrust secured the first place and achieved
state-of-the-art results, outperforming the next-best competitor by up to 266%
under feature-space evasion attacks. This is accomplished while maintaining the
highest detection rate on non-adversarial malware and a false positive rate
below 1%. The method's efficacy stems from maximizing the divergence of the
learned representations among the internal models. By using classifiers
inducing fundamentally dissimilar embeddings of the data, the decision space
becomes unpredictable for an attacker. This frustrates the iterative
perturbation process inherent to evasion attacks, enhancing system robustness
without compromising accuracy on clean examples.

</details>


### [18] [IP-Augmented Multi-Modal Malicious URL Detection Via Token-Contrastive Representation Enhancement and Multi-Granularity Fusion](https://arxiv.org/abs/2510.12395)
*Ye Tian,Yanqiu Yu,Liangliang Song,Zhiquan Liu,Yanbin Wang,Jianguo Sun*

Main category: cs.CR

TL;DR: 提出了CURL-IP框架，通过多模态方法解决恶意URL检测中的三个关键挑战：URL层次结构建模、字符级混淆检测和网络信号整合。


<details>
  <summary>Details</summary>
Motivation: 现有预训练语言模型在URL检测中存在三个主要局限：无法有效建模URL的非自然层次结构、对字符级混淆不够敏感、缺乏整合网络级信号（如IP地址）的机制。

Method: CURL-IP包含三个核心创新：Token-Contrastive Representation Enhancer通过对比学习增强子词表示；Cross-Layer Multi-Scale Aggregator使用卷积和门控MLP分层聚合Transformer输出；Blockwise Multi-Modal Coupler在块级别计算跨模态注意力权重。

Result: 在大规模真实数据集上的评估表明，该框架在二分类和多分类任务中显著优于现有最先进基线方法。

Conclusion: CURL-IP框架能够同时保留细粒度词汇线索、上下文语义，并整合网络级信号，为恶意URL检测提供了更鲁棒的解决方案。

Abstract: Malicious URL detection remains a critical cybersecurity challenge as
adversaries increasingly employ sophisticated evasion techniques including
obfuscation, character-level perturbations, and adversarial attacks. Although
pre-trained language models (PLMs) like BERT have shown potential for URL
analysis tasks, three limitations persist in current implementations: (1)
inability to effectively model the non-natural hierarchical structure of URLs,
(2) insufficient sensitivity to character-level obfuscation, and (3) lack of
mechanisms to incorporate auxiliary network-level signals such as IP
addresses-all essential for robust detection. To address these challenges, we
propose CURL-IP, an advanced multi-modal detection framework incorporating
three key innovations: (1) Token-Contrastive Representation Enhancer, which
enhances subword token representations through token-aware contrastive learning
to produce more discriminative and isotropic embeddings; (2) Cross-Layer
Multi-Scale Aggregator, employing hierarchical aggregation of Transformer
outputs via convolutional operations and gated MLPs to capture both local and
global semantic patterns across layers; and (3) Blockwise Multi-Modal Coupler
that decomposes URL-IP features into localized block units and computes
cross-modal attention weights at the block level, enabling fine-grained
inter-modal interaction. This architecture enables simultaneous preservation of
fine-grained lexical cues, contextual semantics, and integration of
network-level signals. Our evaluation on large-scale real-world datasets shows
the framework significantly outperforms state-of-the-art baselines across
binary and multi-class classification tasks.

</details>


### [19] [Targeted Pooled Latent-Space Steganalysis Applied to Generative Steganography, with a Fix](https://arxiv.org/abs/2510.12414)
*Etienne Levecque,Aurélien Noirault,Tomáš Pevný,Jan Butora,Patrick Bas,Rémi Cogranne*

Main category: cs.CR

TL;DR: 该论文提出在潜在空间进行隐写分析，通过建模潜在向量范数的统计分布来检测隐写嵌入，证明了Hu等人方案的潜在空间可检测性，并提出了改进方案。


<details>
  <summary>Details</summary>
Motivation: 现有的隐写方案在潜在空间修改种子向量嵌入信息，而大多数隐写分析方法在图像空间进行检测。这种空间不匹配导致检测困难，因此需要在潜在空间直接进行隐写分析。

Method: 分析潜在向量范数的统计分布，将Cover和Stego假设下的向量范数建模为不同方差的高斯分布，然后推导似然比检验进行池化隐写分析。

Result: 发现隐写后Stego向量分布在超球面上，而Cover向量是独立同分布的高斯分布。通过潜在空间分析可以有效检测隐写嵌入，并且通过随机采样潜在向量范数可以使原始方案在潜在空间不可检测。

Conclusion: 在潜在空间进行隐写分析比图像空间更有效，通过建模向量范数分布可以检测隐写嵌入，同时提出了使方案在潜在空间不可检测的改进方法。

Abstract: Steganographic schemes dedicated to generated images modify the seed vector
in the latent space to embed a message, whereas most steganalysis methods
attempt to detect the embedding in the image space. This paper proposes to
perform steganalysis in the latent space by modeling the statistical
distribution of the norm of the latent vector. Specifically, we analyze the
practical security of a scheme proposed by Hu et. al. for latent diffusion
models, which is both robust and practically undetectable when steganalysis is
performed on generated images. We show that after embedding, the Stego (latent)
vector is distributed on a hypersphere while the Cover vector is i.i.d.
Gaussian. By going from the image space to the latent space, we show that it is
possible to model the norm of the vector in the latent space under the Cover or
Stego hypothesis as Gaussian distributions with different variances. A
Likelihood Ratio Test is then derived to perform pooled steganalysis. The
impact of the potential knowledge of the prompt and the number of diffusion
steps, is also studied. Additionally, we also show how, by randomly sampling
the norm of the latent vector before generation, the initial Stego scheme
becomes undetectable in the latent space.

</details>


### [20] [Formal Models and Convergence Analysis for Context-Aware Security Verification](https://arxiv.org/abs/2510.12440)
*Ayush Chaudhary*

Main category: cs.CR

TL;DR: 提出了一个上下文感知安全验证的正式框架，为ML增强的自适应系统建立可证明的安全保证。引入了上下文完整性这一新安全属性，并证明了样本复杂度边界、信息论限制、ML负载生成器的收敛保证以及组合健全性边界。


<details>
  <summary>Details</summary>
Motivation: 现有静态验证方法在有限负载预算下最多只能达到α的完整性，而上下文感知验证器在获得足够信息时可以实现超过α的完整性，这促使研究如何通过上下文感知实现可证明的安全改进。

Method: 引入上下文完整性安全属性，建立形式化框架，证明样本复杂度边界、信息论限制、ML负载生成器收敛保证和组合健全性边界，并通过97,224个漏洞样本进行控制实验验证。

Result: 检测准确率从58%提升到69.93%（数据集增长），成功率从51%提升到82%（上下文丰富化），训练损失以O(1/√T)速率收敛，误报率10.19%在理论边界12%内。

Conclusion: 理论基础的适应性验证在既定假设下实现了对静态方法的可证明改进，同时保持了健全性保证，展示了上下文感知安全验证的实际价值。

Abstract: We present a formal framework for context-aware security verification that
establishes provable guarantees for ML-enhanced adaptive systems. We introduce
context-completeness - a new security property - and prove: (1) sample
complexity bounds showing when adaptive verification succeeds, (2)
information-theoretic limits relating context richness to detection capability,
(3) convergence guarantees for ML-based payload generators, and (4)
compositional soundness bounds. We further provide a formal separation between
static context-blind verifiers and context-aware adaptive verifiers: for a
natural family of targets, any static verifier with finite payload budget
achieves completeness at most alpha, while a context-aware verifier with
sufficient information achieves completeness greater than alpha. We validate
our theoretical predictions through controlled experiments on 97,224 exploit
samples, demonstrating: detection accuracy improving from 58% to 69.93% with
dataset growth, success probability increasing from 51% to 82% with context
enrichment, training loss converging at O(1/sqrt(T)) rate, and false positive
rate (10.19%) within theoretical bounds (12%). Our results show that
theoretically-grounded adaptive verification achieves provable improvements
over static approaches under stated assumptions while maintaining soundness
guarantees.

</details>


### [21] [Attack-Specialized Deep Learning with Ensemble Fusion for Network Anomaly Detection](https://arxiv.org/abs/2510.12455)
*Nisith Dissanayake,Uthayasanker Thayasivam*

Main category: cs.CR

TL;DR: 提出了一种混合异常检测框架，结合专业深度学习模型和集成元分类器，用于处理不平衡数据集中的网络入侵检测问题。


<details>
  <summary>Details</summary>
Motivation: 传统入侵检测系统在处理不平衡数据集时，难以同时保持对常见和罕见攻击的高检测精度，导致对少数类攻击的漏报率增加。

Method: 使用专门针对特定攻击类别训练的深度学习模型，结合随机森林元分类器融合各模型输出，提高决策可靠性。

Result: 在NSL-KDD基准测试中表现出色，相比传统单一模型，在精度、召回率和F1分数方面均有显著提升，包括对U2R等罕见攻击类别。

Conclusion: 该框架通过专业化与集成学习的结合，为现代网络安全提供了有效且可扩展的解决方案。

Abstract: The growing scale and sophistication of cyberattacks pose critical challenges
to network security, particularly in detecting diverse intrusion types within
imbalanced datasets. Traditional intrusion detection systems (IDS) often
struggle to maintain high accuracy across both frequent and rare attacks,
leading to increased false negatives for minority classes. To address this, we
propose a hybrid anomaly detection framework that integrates specialized deep
learning models with an ensemble meta-classifier. Each model is trained to
detect a specific attack category, enabling tailored learning of class-specific
patterns, while their collective outputs are fused by a Random Forest
meta-classifier to improve overall decision reliability. The framework is
evaluated on the NSL-KDD benchmark, demonstrating superior performance in
handling class imbalance compared to conventional monolithic models. Results
show significant improvements in precision, recall, and F1-score across all
attack categories, including rare classes such as User to Root (U2R). The
proposed system achieves near-perfect detection rates with minimal false
alarms, highlighting its robustness and generalizability. This work advances
the design of intrusion detection systems by combining specialization with
ensemble learning, providing an effective and scalable solution for
safeguarding modern networks.

</details>


### [22] [Proof of Cloud: Data Center Execution Assurance for Confidential VMs](https://arxiv.org/abs/2510.12469)
*Filip Rezabek,Moe Mahhouk,Andrew Miller,Stefan Genchev,Quintus Kilbourn,Georg Carle,Jonathan Passerat-Palmbach*

Main category: cs.CR

TL;DR: DCEA通过vTPM锚定测量将机密虚拟机(CVM)与底层物理平台绑定，生成"云证明"，确保CVM启动证据和TPM引用指向同一物理机箱，从而验证CVM在可信物理平台上运行。


<details>
  <summary>Details</summary>
Motivation: 当前的机密虚拟机(CVM)部署无法证明其运行在物理可信平台上，因为TEE威胁模型排除了物理访问攻击者，而远程证明无法验证物理平台的可信性，导致租户必须信任云提供商在硬件层的完整性。

Method: 利用数据中心通常可通过TPM识别的特点，通过vTPM锚定测量将CVM与物理平台绑定，适用于访问vTPM的CVM和单租户裸机部署，信任提供商颁发证书但不信任CVM可见状态的机密性。

Result: 在Google Cloud和Intel TDX上实现了候选实现，利用Intel TXT进行可信启动，能够远程验证CVM的平台来源和完整性，减轻重放和证明代理等攻击。

Conclusion: DCEA细化了CVM的威胁模型，为在最小信任环境中部署高保证机密工作负载提供了实用路径。

Abstract: Confidential Virtual Machines (CVMs) protect data in use by running workloads
inside hardware-isolated environments. In doing so, they also inherit the
limitations of the underlying hardware. Trusted Execution Environments (TEEs),
which enforce this isolation, explicitly exclude adversaries with physical
access from their threat model. Commercial TEEs, e.g., Intel TDX, thus assume
infrastructure providers do not physically exploit hardware and serve as
safeguards instead. This creates a tension: tenants must trust provider
integrity at the hardware layer, yet existing remote attestation offers no way
to verify that CVMs actually run on physically trusted platforms, leaving
today's CVM deployments unable to demonstrate that their guarantees align with
the TEE vendor's threat model.
  We bridge this confidence gap with Data Center Execution Assurance (DCEA), a
design generating "Proofs of Cloud". DCEA binds a CVM to its underlying
platform using vTPM-anchored measurements, ensuring CVM launch evidence and TPM
quotes refer to the same physical chassis.
  This takes advantage of the fact that data centers are often identifiable via
TPMs. Our approach applies to CVMs accessing vTPMs and running on top of
software stacks fully controlled by the cloud provider, as well as
single-tenant bare-metal deployments with discrete TPMs. We trust providers for
integrity (certificate issuance), but not for the confidentiality of
CVM-visible state. DCEA enables remote verification of a CVM's platform origin
and integrity, mitigating attacks like replay and attestation proxying. We
include a candidate implementation on Google Cloud and Intel TDX that leverages
Intel TXT for trusted launch. Our design refines CVMs' threat model and
provides a practical path for deploying high-assurance, confidential workloads
in minimally trusted environments.

</details>


### [23] [Noisy Neighbor: Exploiting RDMA for Resource Exhaustion Attacks in Containerized Clouds](https://arxiv.org/abs/2510.12629)
*Gunwoo Kim,Taejune Park,Jinwoo Kim*

Main category: cs.CR

TL;DR: 本文分析了RDMA在容器化云环境中的性能隔离问题，发现了两种资源耗尽攻击（状态饱和攻击和流水线饱和攻击），并提出了HT-Verbs框架来缓解这些威胁。


<details>
  <summary>Details</summary>
Motivation: 在容器化云环境中使用RDMA时，需要确保一个容器的RDMA工作负载不会降低其他容器的性能，但现有的隔离技术难以有效应用，因为RDMA网卡内部的微架构资源管理很复杂。

Method: 实验分析了NVIDIA BlueField-3上的两种资源耗尽攻击：状态饱和攻击和流水线饱和攻击。提出了HT-Verbs框架，基于实时每个容器的RDMA动词遥测和自适应资源分类，将RNIC资源划分为热、温、冷层级，并限制滥用工作负载。

Result: 状态饱和攻击可导致受害者容器带宽损失高达93.9%，延迟增加1,117倍，缓存未命中率上升115%；流水线饱和攻击导致严重的链路级拥塞和显著的放大效应。HT-Verbs框架能够在不修改硬件的情况下恢复可预测的安全保证。

Conclusion: RDMA NIC存在严重的性能隔离漏洞，HT-Verbs框架通过资源分类和限流机制有效缓解了这些威胁，为容器化云环境提供了可靠的RDMA性能隔离解决方案。

Abstract: In modern containerized cloud environments, the adoption of RDMA (Remote
Direct Memory Access) has expanded to reduce CPU overhead and enable
high-performance data exchange. Achieving this requires strong performance
isolation to ensure that one container's RDMA workload does not degrade the
performance of others, thereby maintaining critical security assurances.
However, existing isolation techniques are difficult to apply effectively due
to the complexity of microarchitectural resource management within RDMA NICs
(RNICs). This paper experimentally analyzes two types of resource exhaustion
attacks on NVIDIA BlueField-3: (i) state saturation attacks and (ii) pipeline
saturation attacks. Our results show that state saturation attacks can cause up
to a 93.9% loss in bandwidth, a 1,117x increase in latency, and a 115% rise in
cache misses for victim containers, while pipeline saturation attacks lead to
severe link-level congestion and significant amplification, where small verb
requests result in disproportionately high resource consumption. To mitigate
these threats and restore predictable security assurances, we propose HT-Verbs,
a threshold-driven framework based on real-time per-container RDMA verb
telemetry and adaptive resource classification that partitions RNIC resources
into hot, warm, and cold tiers and throttles abusive workloads without
requiring hardware modifications.

</details>


### [24] [PromoGuardian: Detecting Promotion Abuse Fraud with Multi-Relation Fused Graph Neural Networks](https://arxiv.org/abs/2510.12652)
*Shaofei Li,Xiao Han,Ziqi Zhang,Minyao Hua,Shuli Gao,Zhenkai Liang,Yao Guo,Xiangqun Chen,Ding Li*

Main category: cs.CR

TL;DR: 该论文提出了PROMOGUARDIAN模型，一种融合时空信息的多关系图神经网络，用于检测电商平台中的促销滥用欺诈行为，在真实数据上表现出色。


<details>
  <summary>Details</summary>
Motivation: 随着电商平台发展，促销滥用欺诈快速增长，威胁平台安全稳定。这类欺诈是群体性活动，涉及普通用户进行合法交易，且囤货和返现滥用两种类型交织，传统方法难以检测。

Method: 提出PROMOGUARDIAN模型，将交易数据的时空信息整合到同质图中，使用多关系融合图神经网络检测促销滥用欺诈。

Result: 在美团真实数据上的实验表明，模型达到93.15%的精确率，检测到的欺诈者是现有最佳方法的2.1-5.0倍，在生产环境中预防的财务损失是1.5-8.8倍。

Conclusion: PROMOGUARDIAN模型通过融合时空信息有效检测促销滥用欺诈，在真实电商环境中表现出优越性能，能显著减少平台财务损失。

Abstract: As e-commerce platforms develop, fraudulent activities are increasingly
emerging, posing significant threats to the security and stability of these
platforms. Promotion abuse is one of the fastest-growing types of fraud in
recent years and is characterized by users exploiting promotional activities to
gain financial benefits from the platform. To investigate this issue, we
conduct the first study on promotion abuse fraud in e-commerce platforms
MEITUAN. We find that promotion abuse fraud is a group-based fraudulent
activity with two types of fraudulent activities: Stocking Up and Cashback
Abuse. Unlike traditional fraudulent activities such as fake reviews, promotion
abuse fraud typically involves ordinary customers conducting legitimate
transactions and these two types of fraudulent activities are often
intertwined. To address this issue, we propose leveraging additional
information from the spatial and temporal perspectives to detect promotion
abuse fraud. In this paper, we introduce PROMOGUARDIAN, a novel multi-relation
fused graph neural network that integrates the spatial and temporal information
of transaction data into a homogeneous graph to detect promotion abuse fraud.
We conduct extensive experiments on real-world data from MEITUAN, and the
results demonstrate that our proposed model outperforms state-of-the-art
methods in promotion abuse fraud detection, achieving 93.15% precision,
detecting 2.1 to 5.0 times more fraudsters, and preventing 1.5 to 8.8 times
more financial losses in production environments.

</details>


### [25] [Hash chaining degrades security at Facebook](https://arxiv.org/abs/2510.12665)
*Thomas Rivasseau*

Main category: cs.CR

TL;DR: 本文展示了Facebook密码存储方案的安全漏洞，这是首个证明该方案弱点的实际利用案例。


<details>
  <summary>Details</summary>
Motivation: 现代网络和数字应用依赖密码哈希进行存储和安全保护，但临时升级密码存储方案以节省成本可能会引入不可预见的漏洞。Meta Platforms使用的密码存储方案服务数十亿月活跃用户，存在安全隐患。

Method: 通过实际漏洞利用演示了Facebook密码存储方案的安全弱点，并遵循了适当的道德披露指南和供应商通知程序。

Result: 成功展示了Facebook密码存储方案的具体安全漏洞，这是首个公开的利用案例。

Conclusion: 临时升级密码存储方案虽然可以节省成本，但会带来安全风险，需要更谨慎地设计和实施密码存储机制。

Abstract: Modern web and digital application password storage relies on password
hashing for storage and security. Ad-hoc upgrade of password storage to keep up
with hash algorithm norms may be used to save costs but can introduce
unforeseen vulnerabilities. This is the case in the password storage scheme
used by Meta Platforms which services several billion monthly users worldwide.
In this paper we present the first example of an exploit which demonstrates the
security weakness of Facebook's password storage scheme, and discuss its
implications. Proper ethical disclosure guidelines and vendor notification were
followed.

</details>
