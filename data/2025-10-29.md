<div id=toc></div>

# Table of Contents

- [cs.CR](#cs.CR) [Total: 16]


<div id='cs.CR'></div>

# cs.CR [[Back]](#toc)

### [1] [Short Ticketing Detection Framework Analysis Report](https://arxiv.org/abs/2510.23619)
*Yuyang Miao,Huijun Xing,Danilo P. Mandic,Tony G. Constantinides*

Main category: cs.CR

TL;DR: 提出了一个无监督多专家机器学习框架，用于检测铁路系统中的短票欺诈，通过A/B/C/D车站分类系统识别了30个高风险车站的可疑模式。


<details>
  <summary>Details</summary>
Motivation: 铁路系统中短票欺诈问题严重，需要有效的检测方法来识别欺诈模式并减少经济损失。

Method: 使用四种互补算法：隔离森林、局部离群因子、一类支持向量机和马氏距离，构建无监督多专家机器学习框架，并采用A/B/C/D车站分类系统。

Result: 成功识别了30个高风险车站，发现了五种不同的短票欺诈模式，并展示了在交通系统中恢复短票损失的潜力。

Conclusion: 该无监督多专家框架能有效检测铁路短票欺诈，识别多种欺诈模式，为交通系统欺诈检测提供了实用解决方案。

Abstract: This report presents a comprehensive analysis of an unsupervised multi-expert
machine learning framework for detecting short ticketing fraud in railway
systems. The study introduces an A/B/C/D station classification system that
successfully identifies suspicious patterns across 30 high-risk stations. The
framework employs four complementary algorithms: Isolation Forest, Local
Outlier Factor, One-Class SVM, and Mahalanobis Distance. Key findings include
the identification of five distinct short ticketing patterns and potential for
short ticketing recovery in transportation systems.

</details>


### [2] [SAND: A Self-supervised and Adaptive NAS-Driven Framework for Hardware Trojan Detection](https://arxiv.org/abs/2510.23643)
*Zhixin Pan,Ziyu Shu,Linh Nguyen,Amberbir Alemayoh*

Main category: cs.CR

TL;DR: 提出SAND框架，通过自监督学习和神经架构搜索实现高效的硬件木马检测，无需手动特征工程且能自适应优化分类器


<details>
  <summary>Details</summary>
Motivation: 全球化半导体供应链使硬件木马成为嵌入式系统的重大安全威胁，现有机器学习检测方法存在特征选择随意和缺乏自适应性的问题

Method: 结合自监督学习实现自动特征提取，集成神经架构搜索动态优化下游分类器，最小化微调即可适应新基准

Result: 检测准确率比现有最优方法提升高达18.3%，对规避性木马具有高弹性，展现强泛化能力

Conclusion: SAND框架通过自监督学习和NAS实现了高效、自适应的硬件木马检测，显著提升了检测性能和泛化能力

Abstract: The globalized semiconductor supply chain has made Hardware Trojans (HT) a
significant security threat to embedded systems, necessitating the design of
efficient and adaptable detection mechanisms. Despite promising machine
learning-based HT detection techniques in the literature, they suffer from ad
hoc feature selection and the lack of adaptivity, all of which hinder their
effectiveness across diverse HT attacks. In this paper, we propose SAND, a
selfsupervised and adaptive NAS-driven framework for efficient HT detection.
Specifically, this paper makes three key contributions. (1) We leverage
self-supervised learning (SSL) to enable automated feature extraction,
eliminating the dependency on manually engineered features. (2) SAND integrates
neural architecture search (NAS) to dynamically optimize the downstream
classifier, allowing for seamless adaptation to unseen benchmarks with minimal
fine-tuning. (3) Experimental results show that SAND achieves a significant
improvement in detection accuracy (up to 18.3%) over state-of-the-art methods,
exhibits high resilience against evasive Trojans, and demonstrates strong
generalization.

</details>


### [3] [MCPGuard : Automatically Detecting Vulnerabilities in MCP Servers](https://arxiv.org/abs/2510.23673)
*Bin Wang,Zexin Liu,Hao Yu,Ao Yang,Yenan Huang,Jing Guo,Huangsheng Cheng,Hui Li,Huiyu Wu*

Main category: cs.CR

TL;DR: 本文系统分析了MCP协议的安全漏洞，识别了三种主要威胁类别，并调查了现有的防御策略，揭示了MCP安全需要针对语义解释的新型防御机制。


<details>
  <summary>Details</summary>
Motivation: MCP作为连接LLM与外部数据源的标准化接口，虽然降低了开发复杂性，但其开放性和可扩展性引入了严重的安全漏洞，威胁系统可信度和用户数据保护。

Method: 系统分析MCP安全格局，识别三类主要威胁：协议设计缺陷导致的代理劫持攻击、MCP服务器中的传统Web漏洞、供应链安全问题。全面调查现有防御策略，包括主动服务器端扫描和运行时交互监控。

Result: 分析表明MCP安全代表了攻击面从传统代码执行扩展到自然语言元数据语义解释的范式转变，需要针对这种独特威胁模型的新防御机制。

Conclusion: MCP安全需要专门针对语义解释威胁的新型防御方法，现有防御策略包括主动扫描和运行时监控，但需要进一步适应MCP特有的安全挑战。

Abstract: The Model Context Protocol (MCP) has emerged as a standardized interface
enabling seamless integration between Large Language Models (LLMs) and external
data sources and tools. While MCP significantly reduces development complexity
and enhances agent capabilities, its openness and extensibility introduce
critical security vulnerabilities that threaten system trustworthiness and user
data protection. This paper systematically analyzes the security landscape of
MCP-based systems, identifying three principal threat categories: (1) agent
hijacking attacks stemming from protocol design deficiencies; (2) traditional
web vulnerabilities in MCP servers; and (3) supply chain security. To address
these challenges, we comprehensively survey existing defense strategies,
examining both proactive server-side scanning approaches, ranging from layered
detection pipelines and agentic auditing frameworks to zero-trust registry
systems, and runtime interaction monitoring solutions that provide continuous
oversight and policy enforcement. Our analysis reveals that MCP security
fundamentally represents a paradigm shift where the attack surface extends from
traditional code execution to semantic interpretation of natural language
metadata, necessitating novel defense mechanisms tailored to this unique threat
model.

</details>


### [4] [QueryIPI: Query-agnostic Indirect Prompt Injection on Coding Agents](https://arxiv.org/abs/2510.23675)
*Yuchong Xie,Zesen Liu,Mingyu Luo,Zhixiang Zhang,Kaikai Zhang,Zongjie Li,Ping Chen,Shuai Wang,Dongdong She*

Main category: cs.CR

TL;DR: QueryIPI是一种针对编码代理的查询无关间接提示注入攻击方法，通过泄露内部提示实现白盒优化，在模拟代理中达到87%成功率，并能迁移到真实系统。


<details>
  <summary>Details</summary>
Motivation: 现有间接提示注入研究主要关注查询特定行为，导致攻击不稳定且成功率低。本文识别出更严重的查询无关威胁，可在不同用户输入下保持有效。

Method: QueryIPI通过迭代的基于提示的过程，利用泄露的代理内部提示来精炼恶意工具描述，将攻击转化为约束白盒优化问题。

Result: 在五个模拟代理上的实验显示，QueryIPI达到最高87%的成功率，优于基线方法，生成的恶意描述也能迁移到真实世界系统。

Conclusion: 该方法突显了现代基于LLM的编码代理面临的实际安全风险，需要更强的防御机制来应对此类查询无关攻击。

Abstract: Modern coding agents integrated into IDEs combine powerful tools and
system-level actions, exposing a high-stakes attack surface. Existing Indirect
Prompt Injection (IPI) studies focus mainly on query-specific behaviors,
leading to unstable attacks with lower success rates. We identify a more
severe, query-agnostic threat that remains effective across diverse user
inputs. This challenge can be overcome by exploiting a common vulnerability:
leakage of the agent's internal prompt, which turns the attack into a
constrained white-box optimization problem. We present QueryIPI, the first
query-agnostic IPI method for coding agents. QueryIPI refines malicious tool
descriptions through an iterative, prompt-based process informed by the leaked
internal prompt. Experiments on five simulated agents show that QueryIPI
achieves up to 87 percent success, outperforming baselines, and the generated
malicious descriptions also transfer to real-world systems, highlighting a
practical security risk to modern LLM-based coding agents.

</details>


### [5] [EthVault: A Secure and Resource-Conscious FPGA-Based Ethereum Cold Wallet](https://arxiv.org/abs/2510.23847)
*Joel Poncha Lemayian,Ghyslain Gagnon,Kaiwen Zhang,Pascal Giard*

Main category: cs.CR

TL;DR: EthVault是首个基于硬件的以太坊分层确定性冷钱包架构，通过硬件实现密钥生成算法和抗侧信道攻击的ECC架构，提供比软件钱包更高的安全性。


<details>
  <summary>Details</summary>
Motivation: 现有的软件钱包运行在微控制器上，容易受到恶意软件和侧信道攻击，攻击者可以提取私钥。需要硬件解决方案来增强加密货币钱包的安全性。

Method: 提出EthVault硬件架构，包括：1）硬件实现的密钥生成算法；2）抗侧信道和时序攻击的ECC架构；3）子密钥派生函数架构；4）最小化资源使用的设计。

Result: FPGA实现验证了方案的可行性：ECC架构在不同输入下表现出一致的执行行为，完整设计在Xilinx Zynq UltraScale+ FPGA上仅使用27% LUTs、7%寄存器和6% RAM块。

Conclusion: EthVault硬件架构为加密货币钱包提供了更高的安全性和便携性，通过硬件实现关键算法有效抵御侧信道攻击，同时保持低资源占用。

Abstract: Cryptocurrency blockchain networks safeguard digital assets using
cryptographic keys, with wallets playing a critical role in generating,
storing, and managing these keys. Wallets, typically categorized as hot and
cold, offer varying degrees of security and convenience. However, they are
generally software-based applications running on microcontrollers.
Consequently, they are vulnerable to malware and side-channel attacks, allowing
perpetrators to extract private keys by targeting critical algorithms, such as
ECC, which processes private keys to generate public keys and authorize
transactions. To address these issues, this work presents EthVault, the first
hardware architecture for an Ethereum hierarchically deterministic cold wallet,
featuring hardware implementations of key algorithms for secure key generation.
Also, an ECC architecture resilient to side-channel and timing attacks is
proposed. Moreover, an architecture of the child key derivation function, a
fundamental component of cryptocurrency wallets, is proposed. The design
minimizes resource usage, meeting market demand for small, portable
cryptocurrency wallets. FPGA implementation results validate the feasibility of
the proposed approach. The ECC architecture exhibits uniform execution behavior
across varying inputs, while the complete design utilizes only 27%, 7%, and 6%
of LUTs, registers, and RAM blocks, respectively, on a Xilinx Zynq UltraScale+
FPGA.

</details>


### [6] [PRO: Enabling Precise and Robust Text Watermark for Open-Source LLMs](https://arxiv.org/abs/2510.23891)
*Jiaqi Xue,Yifei Zhao,Mansour Al Ghanim,Shangqian Gao,Ruimin Sun,Qian Lou,Mengxin Zheng*

Main category: cs.CR

TL;DR: PRO是一种针对开源大语言模型的精确鲁棒文本水印方法，通过联合训练水印策略模型和LLM，解决了开源模型水印检测性差和对下游修改脆弱的问题。


<details>
  <summary>Details</summary>
Motivation: 开源LLM的所有者缺乏验证文本是否由其模型生成的实用手段，现有方法在将闭源模型水印蒸馏到开源模型时存在检测性差和易受下游修改影响的问题。

Method: PRO联合训练水印策略模型与LLM，生成更易学习且与检测标准一致的模式，并通过正则化项模拟下游扰动来惩罚水印检测性的退化。

Result: 在LLaMA-3.2、LLaMA-3、Phi-2等开源LLM上的实验表明，PRO显著提高了水印检测性和对模型修改的鲁棒性。

Conclusion: PRO为开源LLM提供了一种有效的水印解决方案，能够在保持模型性能的同时确保水印的可靠检测和抗干扰能力。

Abstract: Text watermarking for large language models (LLMs) enables model owners to
verify text origin and protect intellectual property. While watermarking
methods for closed-source LLMs are relatively mature, extending them to
open-source models remains challenging, as developers cannot control the
decoding process. Consequently, owners of open-source LLMs lack practical means
to verify whether text was generated by their models. A core difficulty lies in
embedding watermarks directly into model weights without hurting detectability.
A promising idea is to distill watermarks from a closed-source model into an
open one, but this suffers from (i) poor detectability due to mismatch between
learned and predefined patterns, and (ii) fragility to downstream modifications
such as fine-tuning or model merging. To overcome these limitations, we propose
PRO, a Precise and Robust text watermarking method for open-source LLMs. PRO
jointly trains a watermark policy model with the LLM, producing patterns that
are easier for the model to learn and more consistent with detection criteria.
A regularization term further simulates downstream perturbations and penalizes
degradation in watermark detectability, ensuring robustness under model edits.
Experiments on open-source LLMs (e.g., LLaMA-3.2, LLaMA-3, Phi-2) show that PRO
substantially improves both watermark detectability and resilience to model
modifications.

</details>


### [7] [Victim as a Service: Designing a System for Engaging with Interactive Scammers](https://arxiv.org/abs/2510.23927)
*Daniel Spokoyny,Nikolai Vogler,Xin Gao,Tianyi Zheng,Yufei Weng,Jonghyun Park,Jiajun Jiao,Geoffrey M. Voelker,Stefan Savage,Taylor Berg-Kirkpatrick*

Main category: cs.CR

TL;DR: CHATTERBOX是一个基于LLM的系统，用于自动化与在线诈骗者进行长期互动，实现大规模调查诈骗策略


<details>
  <summary>Details</summary>
Motivation: 由于杀猪盘等在线诈骗通过长期对话建立信任，调查难度大且规模受限，需要自动化工具来大规模研究诈骗策略

Method: 开发了吸引诈骗尝试的技术，使用LLM工程学与诈骗者进行可信互动，满足或规避诈骗者工作流程中的关键节点

Result: 成功实现了与诈骗者的长期自动化互动，使大规模调查成为可能

Conclusion: CHATTERBOX系统证明能够有效自动化与在线诈骗者的长期互动，为大规模研究诈骗策略提供了可行方案

Abstract: Pig butchering, and similar interactive online scams, lower their victims'
defenses by building trust over extended periods of conversation - sometimes
weeks or months. They have become increasingly public losses (at least $75B by
one recent study). However, because of their long-term conversational nature,
they are extremely challenging to investigate at scale. In this paper, we
describe the motivation, design, implementation, and experience with
CHATTERBOX, an LLM-based system that automates long-term engagement with online
scammers, making large-scale investigations of their tactics possible. We
describe the techniques we have developed to attract scam attempts, the system
and LLM-engineering required to convincingly engage with scammers, and the
necessary capabilities required to satisfy or evade "milestones" in scammers'
workflow.

</details>


### [8] [Scalable GPU-Based Integrity Verification for Large Machine Learning Models](https://arxiv.org/abs/2510.23938)
*Marcin Spoczynski,Marcela S. Melara*

Main category: cs.CR

TL;DR: 提出在GPU上原生执行完整性验证的安全框架，解决ML模型主要在GPU运行而安全验证传统在CPU执行的架构不匹配问题，显著降低验证开销。


<details>
  <summary>Details</summary>
Motivation: 传统分布式机器学习中，大型ML模型主要在GPU上运行，但安全完整性验证通常在单独的CPU进程中执行，这种架构不匹配导致性能瓶颈和验证开销大。

Method: 在GPU加速器上直接集成完整性验证，利用GPU专用计算单元（如Intel XMX、NVIDIA Tensor Cores）原生执行密码学操作，充分利用GPU的高内存带宽和并行处理能力。

Result: 消除了传统CPU验证系统的架构瓶颈，即使对于超过100GB的大型模型，完整性检查也能跟上模型执行速度，显著降低验证开销。

Conclusion: 该框架建立了跨不同GPU厂商和硬件配置的统一完整性验证机制，为企业团队提供了硬件无关的安全基础架构，可部署于各种CPU和GPU基础设施。

Abstract: We present a security framework that strengthens distributed machine learning
by standardizing integrity protections across CPU and GPU platforms and
significantly reducing verification overheads. Our approach co-locates
integrity verification directly with large ML model execution on GPU
accelerators, resolving the fundamental mismatch between how large ML workloads
typically run (primarily on GPUs) and how security verifications traditionally
operate (on separate CPU-based processes), delivering both immediate
performance benefits and long-term architectural consistency. By performing
cryptographic operations natively on GPUs using dedicated compute units (e.g.,
Intel Arc's XMX units, NVIDIA's Tensor Cores), our solution eliminates the
potential architectural bottlenecks that could plague traditional CPU-based
verification systems when dealing with large models. This approach leverages
the same GPU-based high-memory bandwidth and parallel processing primitives
that power ML workloads ensuring integrity checks keep pace with model
execution even for massive models exceeding 100GB. This framework establishes a
common integrity verification mechanism that works consistently across
different GPU vendors and hardware configurations. By anticipating future
capabilities for creating secure channels between trusted execution
environments and GPU accelerators, we provide a hardware-agnostic foundation
that enterprise teams can deploy regardless of their underlying CPU and GPU
infrastructures.

</details>


### [9] [Covert Surveillance in Smart Devices: A SCOUR Framework Analysis of Youth Privacy Implications](https://arxiv.org/abs/2510.24072)
*Austin Shouli,Yulia Bobkova,Ajay Kumar Shrestha*

Main category: cs.CR

TL;DR: 本文通过系统综述研究了智能设备如何秘密捕获私人对话及其对青少年隐私的影响，提出了SCOUR框架来分析监控机制、数据流和监管保障。


<details>
  <summary>Details</summary>
Motivation: 调查智能设备（特别是面向青少年的智能玩具和语音设备）秘密收集私人数据的现象，分析其对青少年隐私的威胁。

Method: 采用PRISMA方法进行结构化文献综述，引入SCOUR框架（监控机制、同意与意识、操作数据流、使用与利用、监管与技术保障）来组织和综合发现。

Result: 发现智能设备确实在秘密捕获个人数据，特别是面向青少年的智能玩具和语音设备；问题因数据收集实践不清晰和应用透明度不足而加剧。

Conclusion: 在智能设备中平衡隐私与效用至关重要；提出了改进监管和技术保障的策略，对政策制定和智能设备数据收集透明度具有重要影响。

Abstract: This paper investigates how smart devices covertly capture private
conversations and discusses in more in-depth the implications of this for youth
privacy. Using a structured review guided by the PRISMA methodology, the
analysis focuses on privacy concerns, data capture methods, data storage and
sharing practices, and proposed technical mitigations. To structure and
synthesize findings, we introduce the SCOUR framework, encompassing
Surveillance mechanisms, Consent and awareness, Operational data flow, Usage
and exploitation, and Regulatory and technical safeguards. Findings reveal that
smart devices have been covertly capturing personal data, especially with smart
toys and voice-activated smart gadgets built for youth. These issues are
worsened by unclear data collection practices and insufficient transparency in
smart device applications. Balancing privacy and utility in smart devices is
crucial, as youth are becoming more aware of privacy breaches and value their
personal data more. Strategies to improve regulatory and technical safeguards
are also provided. The review identifies research gaps and suggests future
directions. The limitations of this literature review are also explained. The
findings have significant implications for policy development and the
transparency of data collection for smart devices.

</details>


### [10] [Traceable Signatures from Lattices](https://arxiv.org/abs/2510.24101)
*Nam Tran,Khoa Nguyen,Dongxi Liu,Josef Pieprzyk,Willy Susilo*

Main category: cs.CR

TL;DR: 提出首个基于格假设的可追踪签名方案，在量子随机预言模型下证明安全


<details>
  <summary>Details</summary>
Motivation: 现有可追踪签名方案都基于数论/配对假设，无法抵抗量子计算机攻击，需要设计后量子安全的方案

Method: 基于格密码学构建可追踪签名方案，在量子随机预言模型(QROM)下进行安全性证明

Result: 成功构建了首个格基可追踪签名方案，并在QROM下证明了其安全性

Conclusion: 该工作填补了后量子可追踪签名的空白，为量子安全匿名认证系统提供了新选择

Abstract: Traceable signatures (Kiayas et al., EUROCRYPT 2004) is an anonymous digital
signature system that extends the tracing power of the opening authority in
group signatures. There are many known constructions of traceable signatures,
but all are based on number-theoretic/pairing assumptions. For such reason,
they may not be secure in the presence of quantum computers. This work revisits
the notion of traceable signatures and presents a lattice-based construction
provably secure in the quantum random oracle model (QROM).

</details>


### [11] [Demystifying Cookie Sharing Risks in WebView-based Mobile App-in-app Ecosystems](https://arxiv.org/abs/2510.24141)
*Miao Zhang,Shenao Wang,Guilin Zheng,Yanjie Zhao,Haoyu Wang*

Main category: cs.CR

TL;DR: 本文发现了一种名为跨小程序Cookie共享(CMCS)的新型漏洞，该漏洞源于小程序中web-view组件的共享环境，允许不同小程序之间未经授权的数据交换，违反了隔离原则。


<details>
  <summary>Details</summary>
Motivation: 小程序采用web-view组件破坏了原有的隔离机制，暴露了新的攻击面和漏洞，需要研究这些安全风险的实际影响。

Method: 分析了四大平台(微信、支付宝、抖音、百度)的web-view机制，开发了MiCoScan静态分析工具进行大规模检测，包括web-view上下文建模和跨web-view数据流分析。

Result: 在351,483个小程序中发现了45,448个共享web-view域的集群，7,965个特权数据传输实例，9,877个小程序易受合谋攻击。所有测试平台都存在CMCS漏洞。

Conclusion: CMCS漏洞在生态系统中广泛存在且带来重大安全风险，迫切需要改进小程序的隔离机制。

Abstract: Mini-programs, an emerging mobile application paradigm within super-apps,
offer a seamless and installation-free experience. However, the adoption of the
web-view component has disrupted their isolation mechanisms, exposing new
attack surfaces and vulnerabilities. In this paper, we introduce a novel
vulnerability called Cross Mini-program Cookie Sharing (CMCS), which arises
from the shared web-view environment across mini-programs. This vulnerability
allows unauthorized data exchange across mini-programs by enabling one
mini-program to access cookies set by another within the same web-view context,
violating isolation principles. As a preliminary step, we analyzed the web-view
mechanisms of four major platforms, including WeChat, AliPay, TikTok, and
Baidu, and found that all of them are affected by CMCS vulnerabilities.
Furthermore, we demonstrate the collusion attack enabled by CMCS, where
privileged mini-programs exfiltrate sensitive user data via cookies accessible
to unprivileged mini-programs. To measure the impact of collusion attacks
enabled by CMCS vulnerabilities in the wild, we developed MiCoScan, a static
analysis tool that detects mini-programs affected by CMCS vulnerabilities.
MiCoScan employs web-view context modeling to identify clusters of
mini-programs sharing the same web-view domain and cross-webview data flow
analysis to detect sensitive data transmissions to/from web-views. Using
MiCoScan, we conducted a large-scale analysis of 351,483 mini-programs,
identifying 45,448 clusters sharing web-view domains, 7,965 instances of
privileged data transmission, and 9,877 mini-programs vulnerable to collusion
attacks. Our findings highlight the widespread prevalence and significant
security risks posed by CMCS vulnerabilities, underscoring the urgent need for
improved isolation mechanisms in mini-program ecosystems.

</details>


### [12] [Cybersecurity AI Benchmark (CAIBench): A Meta-Benchmark for Evaluating Cybersecurity AI Agents](https://arxiv.org/abs/2510.24317)
*María Sanz-Gómez,Víctor Mayoral-Vilches,Francesco Balassone,Luis Javier Navarrete-Lozano,Cristóbal R. J. Veas Chavez,Maite del Mundo de Torres*

Main category: cs.CR

TL;DR: CAIBench是一个模块化的网络安全AI基准测试框架，评估LLM在攻防领域的综合能力，发现知识与应用能力之间存在显著差距。


<details>
  <summary>Details</summary>
Motivation: 现有基准测试评估孤立技能而非综合表现，预训练的网络安全知识并不等同于攻防能力，需要开发能衡量劳动相关性的基准。

Method: 提出CAIBench模块化元基准框架，整合五个评估类别：Jeopardy式CTF、攻防CTF、网络靶场演练、知识基准和隐私评估，覆盖超过10,000个实例。

Result: 评估显示最先进AI模型在安全知识指标上饱和（约70%成功率），但在多步对抗场景中表现显著下降（20-40%成功率），机器人目标上更差（22%成功率）。框架脚手架与模型选择的匹配可提升攻防CTF性能达2.6倍。

Conclusion: 概念知识与适应能力之间存在明显差距，强调需要元基准测试来全面评估网络安全AI能力。

Abstract: Cybersecurity spans multiple interconnected domains, complicating the
development of meaningful, labor-relevant benchmarks. Existing benchmarks
assess isolated skills rather than integrated performance. We find that
pre-trained knowledge of cybersecurity in LLMs does not imply attack and
defense abilities, revealing a gap between knowledge and capability. To address
this limitation, we present the Cybersecurity AI Benchmark (CAIBench), a
modular meta-benchmark framework that allows evaluating LLM models and agents
across offensive and defensive cybersecurity domains, taking a step towards
meaningfully measuring their labor-relevance. CAIBench integrates five
evaluation categories, covering over 10,000 instances: Jeopardy-style CTFs,
Attack and Defense CTFs, Cyber Range exercises, knowledge benchmarks, and
privacy assessments. Key novel contributions include systematic simultaneous
offensive-defensive evaluation, robotics-focused cybersecurity challenges
(RCTF2), and privacy-preserving performance assessment (CyberPII-Bench).
Evaluation of state-of-the-art AI models reveals saturation on security
knowledge metrics (~70\% success) but substantial degradation in multi-step
adversarial (A\&D) scenarios (20-40\% success), or worse in robotic targets
(22\% success). The combination of framework scaffolding and LLM model choice
significantly impacts performance; we find that proper matches improve up to
2.6$\times$ variance in Attack and Defense CTFs. These results demonstrate a
pronounced gap between conceptual knowledge and adaptive capability,
emphasizing the need for a meta-benchmark.

</details>


### [13] [Your Microphone Array Retains Your Identity: A Robust Voice Liveness Detection System for Smart Speakers](https://arxiv.org/abs/2510.24393)
*Yan Meng,Jiachun Li,Matthew Pillari,Arjun Deopujari,Liam Brennan,Hafsah Shamsie,Haojin Zhu,Yuan Tian*

Main category: cs.CR

TL;DR: 提出了一种基于麦克风阵列的阵列指纹特征和ARRAYID方案，用于智能音箱的被动活体检测，能有效防御语音重放攻击，在不同环境和用户移动下保持高精度。


<details>
  <summary>Details</summary>
Motivation: 智能音箱易受语音重放攻击，现有被动活体检测方案面临环境变化和用户姿势固定的性能下降问题。

Method: 利用智能音箱内置的麦克风阵列创建阵列指纹特征，结合ARRAYID轻量级检测方案和一系列协同特征。

Result: 在包含32,780个音频样本和14种欺骗设备的测试集上，ARRAYID达到99.84%的准确率，优于现有方案。

Conclusion: 阵列指纹特征和ARRAYID方案能有效提升智能音箱语音活体检测的鲁棒性和准确性，特别是在环境变化和用户移动场景下。

Abstract: Though playing an essential role in smart home systems, smart speakers are
vulnerable to voice spoofing attacks. Passive liveness detection, which
utilizes only the collected audio rather than the deployed sensors to
distinguish between live-human and replayed voices, has drawn increasing
attention. However, it faces the challenge of performance degradation under the
different environmental factors as well as the strict requirement of the fixed
user gestures.
  In this study, we propose a novel liveness feature, array fingerprint, which
utilizes the microphone array inherently adopted by the smart speaker to
determine the identity of collected audios. Our theoretical analysis
demonstrates that by leveraging the circular layout of microphones, compared
with existing schemes, array fingerprint achieves a more robust performance
under the environmental change and user's movement. Then, to leverage such a
fingerprint, we propose ARRAYID, a lightweight passive detection scheme, and
elaborate a series of features working together with array fingerprint. Our
evaluation on the dataset containing 32,780 audio samples and 14 spoofing
devices shows that ARRAYID achieves an accuracy of 99.84%, which is superior to
existing passive liveness detection schemes.

</details>


### [14] [Uncovering Gaps Between RFC Updates and TCP/IP Implementations: LLM-Facilitated Differential Checks on Intermediate Representations](https://arxiv.org/abs/2510.24408)
*Yifan Wu,Xuewei Feng,Yuxiang Yang,Ke Xu*

Main category: cs.CR

TL;DR: 提出基于LLM和差分模型的自动化分析框架，通过建模协议迭代关系和RFC标准更新关系，对不同版本内核代码实现进行增量功能分析，自动检测代码不一致性导致的安全漏洞。


<details>
  <summary>Details</summary>
Motivation: TCP/IP协议栈实现与RFC标准间的不一致性可能导致功能差异和严重安全漏洞，现有方法依赖预定义模式或基于规则的方法，无法跨不同协议规范泛化，自动化可扩展的检测仍面临重大挑战。

Method: 基于LLM和差分模型的自动化分析框架，通过建模协议迭代关系和RFC标准更新关系，对不同版本内核代码实现进行增量代码功能分析，自动执行代码检测和漏洞分析。

Result: 通过广泛评估验证了框架的有效性，证明了其在识别由RFC代码不一致性引起的潜在漏洞方面的有效性。

Conclusion: 提出的基于LLM和差分模型的自动化分析框架能够有效检测协议栈实现与RFC标准间的不一致性，识别潜在安全漏洞，解决了现有方法无法跨协议规范泛化的问题。

Abstract: As the core of the Internet infrastructure, the TCP/IP protocol stack
undertakes the task of network data transmission. However, due to the
complexity of the protocol and the uncertainty of cross-layer interaction,
there are often inconsistencies between the implementation of the protocol
stack code and the RFC standard. This inconsistency may not only lead to
differences in protocol functions but also cause serious security
vulnerabilities. At present, with the continuous expansion of protocol stack
functions and the rapid iteration of RFC documents, it is increasingly
important to detect and fix these inconsistencies. With the rise of large
language models, researchers have begun to explore how to extract protocol
specifications from RFC documents through these models, including protocol
stack modeling, state machine extraction, text ambiguity analysis, and other
related content. However, existing methods rely on predefined patterns or
rule-based approaches that fail to generalize across different protocol
specifications. Automated and scalable detection of these inconsistencies
remains a significant challenge. In this study, we propose an automated
analysis framework based on LLM and differential models. By modeling the
iterative relationship of the protocol and based on the iterative update
relationship of the RFC standard, we perform incremental code function analysis
on different versions of kernel code implementations to automatically perform
code detection and vulnerability analysis. We conduct extensive evaluations to
validate the effectiveness of our framework, demonstrating its effectiveness in
identifying potential vulnerabilities caused by RFC code inconsistencies.

</details>


### [15] [Attack on a PUF-based Secure Binary Neural Network](https://arxiv.org/abs/2510.24422)
*Bijeet Basak,Nupur Patil,Kurian Polachan,Srinivas Vivek*

Main category: cs.CR

TL;DR: 本文展示了对基于PUF保护的BNN模型的攻击方法，能够恢复85%的PUF密钥和93%准确率的模型参数


<details>
  <summary>Details</summary>
Motivation: 发现Rajendran等人提出的基于PUF的BNN保护方案存在安全漏洞，攻击者可以通过观察模型精度变化来恢复PUF密钥

Method: 采用差分密码分析方法，通过逐位观察模型精度变化来重构PUF密钥，最终恢复BNN模型参数

Result: 在MNIST数据集上，攻击能恢复85%的PUF密钥，恢复的模型达到93%分类准确率（原模型96%），整个攻击过程仅需几分钟

Conclusion: 现有的PUF-based BNN保护方案存在严重安全漏洞，需要更强的安全机制来保护边缘计算中的神经网络模型

Abstract: Binarized Neural Networks (BNNs) deployed on memristive crossbar arrays
provide energy-efficient solutions for edge computing but are susceptible to
physical attacks due to memristor nonvolatility. Recently, Rajendran et al.
(IEEE Embedded Systems Letter 2025) proposed a Physical Unclonable Function
(PUF)-based scheme to secure BNNs against theft attacks. Specifically, the
weight and bias matrices of the BNN layers were secured by swapping columns
based on device's PUF key bits.
  In this paper, we demonstrate that this scheme to secure BNNs is vulnerable
to PUF-key recovery attack. As a consequence of our attack, we recover the
secret weight and bias matrices of the BNN. Our approach is motivated by
differential cryptanalysis and reconstructs the PUF key bit-by-bit by observing
the change in model accuracy, and eventually recovering the BNN model
parameters. Evaluated on a BNN trained on the MNIST dataset, our attack could
recover 85% of the PUF key, and recover the BNN model up to 93% classification
accuracy compared to the original model's 96% accuracy. Our attack is very
efficient and it takes a couple of minutes to recovery the PUF key and the
model parameters.

</details>


### [16] [Design and Optimization of Cloud Native Homomorphic Encryption Workflows for Privacy-Preserving ML Inference](https://arxiv.org/abs/2510.24498)
*Tejaswini Bollikonda*

Main category: cs.CR

TL;DR: 提出了一个云原生同态加密框架，用于优化隐私保护的机器学习推理服务，通过容器化和Kubernetes编排实现分布式加密计算，显著提升性能并降低资源消耗。


<details>
  <summary>Details</summary>
Motivation: 随着机器学习模型在云基础设施中的部署，用户数据在推理过程中的保密性成为重要安全挑战。同态加密虽然能实现加密数据上的计算，但在大规模云原生管道中的集成仍受限于高计算开销、编排复杂性和模型兼容性问题。

Method: 设计了一个系统化框架，将容器化HE模块与Kubernetes编排集成，实现弹性扩展和分布式加密计算。采用密文打包、多项式模数调整和算子融合等优化策略来最小化延迟和资源消耗。

Result: 实验结果表明，与传统的HE管道相比，所提系统实现了高达3.2倍的推理加速和40%的内存使用减少。

Conclusion: 这些发现展示了在零信任云条件下部署安全MLaaS系统的实用途径，能够保证数据机密性。

Abstract: As machine learning (ML) models become increasingly deployed through cloud
infrastructures, the confidentiality of user data during inference poses a
significant security challenge. Homomorphic Encryption (HE) has emerged as a
compelling cryptographic technique that enables computation on encrypted data,
allowing predictions to be generated without decrypting sensitive inputs.
However, the integration of HE within large scale cloud native pipelines
remains constrained by high computational overhead, orchestration complexity,
and model compatibility issues.
  This paper presents a systematic framework for the design and optimization of
cloud native homomorphic encryption workflows that support privacy-preserving
ML inference. The proposed architecture integrates containerized HE modules
with Kubernetes-based orchestration, enabling elastic scaling and parallel
encrypted computation across distributed environments. Furthermore,
optimization strategies including ciphertext packing, polynomial modulus
adjustment, and operator fusion are employed to minimize latency and resource
consumption while preserving cryptographic integrity. Experimental results
demonstrate that the proposed system achieves up to 3.2times inference
acceleration and 40% reduction in memory utilization compared to conventional
HE pipelines. These findings illustrate a practical pathway for deploying
secure ML-as-a-Service (MLaaS) systems that guarantee data confidentiality
under zero-trust cloud conditions.

</details>
