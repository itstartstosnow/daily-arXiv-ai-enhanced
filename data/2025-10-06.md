<div id=toc></div>

# Table of Contents

- [cs.CR](#cs.CR) [Total: 36]


<div id='cs.CR'></div>

# cs.CR [[Back]](#toc)

### [1] [Hybrid Horizons: Policy for Post-Quantum Security](https://arxiv.org/abs/2510.02317)
*Anais Jaikissoon*

Main category: cs.CR

TL;DR: 该论文探讨人工智能和量子密码学领域的监管空白，重点关注混合密码学在从经典密码学向量子密码学过渡期间的监管缺失问题，并提出解决方案以确保安全有效的过渡。


<details>
  <summary>Details</summary>
Motivation: 人工智能和量子密码学等新兴技术缺乏监管，存在被滥用的风险。混合密码学作为从经典密码学向量子密码学过渡的关键技术，同样面临监管基础设施缺失的问题。

Method: 分析人工智能和量子密码学领域的监管现状，识别混合密码学在监管方面的空白，并提出相应的解决方案。

Result: 识别出混合密码学在监管基础设施方面存在显著空白，缺乏相应的法规和支持体系。

Conclusion: 需要建立混合密码学的监管框架，填补监管空白，确保从经典密码学向量子密码学的过渡能够安全有效地完成。

Abstract: The Age of Artificial Intelligence is here. In 2025, there are few
regulations governing artificial intelligence. While the expansion of
artificial intelligence is going in a relatively good direction, there is a
risk that it can be misused. Misuse of technology is nothing new and will
continue to happen. The lack of regulation in artificial intelligence is
necessary because it raises the question of how we can move forward without
knowing what the limits are. While artificial intelligence dominates the
technology industry, new technology is starting to emerge. Quantum cryptography
is expected to replace classical cryptography; however, the transition from
classical to quantum cryptography is expected to occur within the next 10
years. The ability to transition from classical to quantum cryptography
requires hybrid cryptography. Hybrid cryptography can be used now; however,
similar to artificial intelligence, there is no regulation or support for the
regulatory infrastructure regarding hybrid machines. This paper will explore
the regulatory gaps in hybrid cryptography. The paper will also offer solutions
to fix the gaps and ensure the transition from classical to quantum
cryptography is safely and effectively completed.

</details>


### [2] [Modeling the Attack: Detecting AI-Generated Text by Quantifying Adversarial Perturbations](https://arxiv.org/abs/2510.02319)
*Lekkala Sai Teja,Annepaka Yadagiri,Sangam Sai Anish,Siva Gopala Krishna Nuthakki,Partha Pakray*

Main category: cs.CR

TL;DR: 本文提出PIFE框架，通过多阶段标准化流程将输入文本转换为标准形式，然后使用编辑距离和语义相似度等指标量化变换幅度，将这些信号直接输入分类器，显著提升了AI生成文本检测器对抗语义攻击的鲁棒性。


<details>
  <summary>Details</summary>
Motivation: 大型语言模型的快速发展带来了双重用途问题，需要创建可靠的AI生成文本检测系统。现有检测器对对抗攻击（特别是改写攻击）非常脆弱，无法有效抵御语义层面的规避技术。

Method: 提出PIFE框架：1）多阶段标准化流程将文本转换为标准形式；2）使用Levenshtein距离和语义相似度等指标量化变换幅度；3）将这些特征信号直接输入分类器。同时评估了传统对抗训练的Transformer模型作为对比。

Result: 传统对抗训练在严格1%假阳性率下，真阳性率仅为48.8%，存在"语义规避阈值"问题。而PIFE模型在相同条件下保持82.6%的真阳性率，有效抵御最复杂的语义攻击。

Conclusion: 明确建模扰动特征，而不仅仅是在扰动数据上训练，是实现真正鲁棒性的更有前景的路径。PIFE框架通过显式工程化文本与其规范形式之间的差异特征，克服了传统方法的局限性。

Abstract: The growth of highly advanced Large Language Models (LLMs) constitutes a huge
dual-use problem, making it necessary to create dependable AI-generated text
detection systems. Modern detectors are notoriously vulnerable to adversarial
attacks, with paraphrasing standing out as an effective evasion technique that
foils statistical detection. This paper presents a comparative study of
adversarial robustness, first by quantifying the limitations of standard
adversarial training and then by introducing a novel, significantly more
resilient detection framework: Perturbation-Invariant Feature Engineering
(PIFE), a framework that enhances detection by first transforming input text
into a standardized form using a multi-stage normalization pipeline, it then
quantifies the transformation's magnitude using metrics like Levenshtein
distance and semantic similarity, feeding these signals directly to the
classifier. We evaluate both a conventionally hardened Transformer and our
PIFE-augmented model against a hierarchical taxonomy of character-, word-, and
sentence-level attacks. Our findings first confirm that conventional
adversarial training, while resilient to syntactic noise, fails against
semantic attacks, an effect we term "semantic evasion threshold", where its
True Positive Rate at a strict 1% False Positive Rate plummets to 48.8%. In
stark contrast, our PIFE model, which explicitly engineers features from the
discrepancy between a text and its canonical form, overcomes this limitation.
It maintains a remarkable 82.6% TPR under the same conditions, effectively
neutralizing the most sophisticated semantic attacks. This superior performance
demonstrates that explicitly modeling perturbation artifacts, rather than
merely training on them, is a more promising path toward achieving genuine
robustness in the adversarial arms race.

</details>


### [3] [Agentic-AI Healthcare: Multilingual, Privacy-First Framework with MCP Agents](https://arxiv.org/abs/2510.02325)
*Mohammed A. Shehab*

Main category: cs.CR

TL;DR: Agentic-AI Healthcare是一个隐私感知、多语言、可解释的研究原型系统，利用MCP协议协调多个智能代理进行患者交互，集成隐私合规层并符合主要医疗数据保护标准。


<details>
  <summary>Details</summary>
Motivation: 开发一个结合智能代理编排、多语言可访问性和合规架构的医疗应用，展示在医疗保健领域整合这些技术的可行性。

Method: 使用新兴的模型上下文协议(MCP)来协调多个智能代理，集成专门的隐私和合规层，应用基于角色的访问控制、AES-GCM字段级加密和防篡改审计日志。

Result: 展示了多语言患者-医生交互（英语、法语、阿拉伯语）和由大型语言模型驱动的透明诊断推理的用例，证明了系统的可行性和功能性。

Conclusion: 该工作展示了在医疗应用中结合代理编排、多语言可访问性和合规感知架构的可行性，但强调这仅是一个研究原型，并非认证医疗设备。

Abstract: This paper introduces Agentic-AI Healthcare, a privacy-aware, multilingual,
and explainable research prototype developed as a single-investigator project.
The system leverages the emerging Model Context Protocol (MCP) to orchestrate
multiple intelligent agents for patient interaction, including symptom
checking, medication suggestions, and appointment scheduling. The platform
integrates a dedicated Privacy and Compliance Layer that applies role-based
access control (RBAC), AES-GCM field-level encryption, and tamper-evident audit
logging, aligning with major healthcare data protection standards such as HIPAA
(US), PIPEDA (Canada), and PHIPA (Ontario). Example use cases demonstrate
multilingual patient-doctor interaction (English, French, Arabic) and
transparent diagnostic reasoning powered by large language models. As an
applied AI contribution, this work highlights the feasibility of combining
agentic orchestration, multilingual accessibility, and compliance-aware
architecture in healthcare applications. This platform is presented as a
research prototype and is not a certified medical device.

</details>


### [4] [CATMark: A Context-Aware Thresholding Framework for Robust Cross-Task Watermarking in Large Language Models](https://arxiv.org/abs/2510.02342)
*Yu Zhang,Shuliang Liu,Xu Yang,Xuming Hu*

Main category: cs.CR

TL;DR: 提出了一种上下文感知阈值水印框架(CAT)，通过实时语义上下文动态调整水印强度，无需预定义阈值或任务特定调优，在跨任务场景中提高文本质量而不牺牲检测准确性。


<details>
  <summary>Details</summary>
Motivation: 现有LLM水印方法在低熵场景下会导致文本质量下降，且依赖熵阈值的方法需要大量计算资源调优，对未知或跨任务生成场景适应性差。

Method: 通过logits聚类将文本生成划分为语义状态，建立上下文感知的熵阈值，在结构化内容中保持保真度同时嵌入鲁棒水印。

Result: 实验表明该方法在跨任务中提高了文本质量，且没有牺牲检测准确性。

Conclusion: CAT框架通过动态调整水印强度，有效解决了现有水印方法在文本质量和适应性方面的问题，为LLM水印提供了更优的解决方案。

Abstract: Watermarking algorithms for Large Language Models (LLMs) effectively identify
machine-generated content by embedding and detecting hidden statistical
features in text. However, such embedding leads to a decline in text quality,
especially in low-entropy scenarios where performance needs improvement.
Existing methods that rely on entropy thresholds often require significant
computational resources for tuning and demonstrate poor adaptability to unknown
or cross-task generation scenarios. We propose \textbf{C}ontext-\textbf{A}ware
\textbf{T}hreshold watermarking ($\myalgo$), a novel framework that dynamically
adjusts watermarking intensity based on real-time semantic context. $\myalgo$
partitions text generation into semantic states using logits clustering,
establishing context-aware entropy thresholds that preserve fidelity in
structured content while embedding robust watermarks. Crucially, it requires no
pre-defined thresholds or task-specific tuning. Experiments show $\myalgo$
improves text quality in cross-tasks without sacrificing detection accuracy.

</details>


### [5] [An Investigation into the Performance of Non-Contrastive Self-Supervised Learning Methods for Network Intrusion Detection](https://arxiv.org/abs/2510.02349)
*Hamed Fard,Tobias Schalau,Gerhard Wunder*

Main category: cs.CR

TL;DR: 本文系统比较了五种非对比自监督学习方法在网络入侵检测中的性能，使用三种编码器架构和六种增强策略，在UNSW-NB15和5G-NIDD数据集上进行了90次实验。


<details>
  <summary>Details</summary>
Motivation: 传统监督学习在网络入侵检测中只能检测已知异常，存在局限性。受计算机视觉中自监督学习成功的启发，需要探索非对比自监督方法在网络入侵检测中的有效性。

Method: 使用五种非对比自监督学习方法、三种编码器架构和六种增强策略，在UNSW-NB15和5G-NIDD数据集上进行了90次系统性实验。

Result: 报告了每种自监督模型的最佳编码器架构和增强方法组合，在平均精度、召回率、F1分数和AUCROC指标上表现优异。与DeepSVDD和Autoencoder等无监督基线相比，非对比方法在攻击检测方面具有竞争力。

Conclusion: 非对比自监督学习方法在网络入侵检测中表现出色，为检测未知攻击提供了有前景的替代方案。

Abstract: Network intrusion detection, a well-explored cybersecurity field, has
predominantly relied on supervised learning algorithms in the past two decades.
However, their limitations in detecting only known anomalies prompt the
exploration of alternative approaches. Motivated by the success of
self-supervised learning in computer vision, there is a rising interest in
adapting this paradigm for network intrusion detection. While prior research
mainly delved into contrastive self-supervised methods, the efficacy of
non-contrastive methods, in conjunction with encoder architectures serving as
the representation learning backbone and augmentation strategies that determine
what is learned, remains unclear for effective attack detection. This paper
compares the performance of five non-contrastive self-supervised learning
methods using three encoder architectures and six augmentation strategies.
Ninety experiments are systematically conducted on two network intrusion
detection datasets, UNSW-NB15 and 5G-NIDD. For each self-supervised model, the
combination of encoder architecture and augmentation method yielding the
highest average precision, recall, F1-score, and AUCROC is reported.
Furthermore, by comparing the best-performing models to two unsupervised
baselines, DeepSVDD, and an Autoencoder, we showcase the competitiveness of the
non-contrastive methods for attack detection. Code at:
https://github.com/renje4z335jh4/non_contrastive_SSL_NIDS

</details>


### [6] [Measuring Physical-World Privacy Awareness of Large Language Models: An Evaluation Benchmark](https://arxiv.org/abs/2510.02356)
*Xinjie Shen,Mufei Li,Pan Li*

Main category: cs.CR

TL;DR: EAPrivacy是一个评估LLM在物理世界中隐私意识的基准测试，发现当前模型在物理环境变化、隐私约束与任务平衡、以及隐私与社会规范冲突等场景中存在严重缺陷。


<details>
  <summary>Details</summary>
Motivation: 随着LLM在具身智能体中的部署，迫切需要评估其在物理世界中的隐私意识，而现有评估方法仅限于基于自然语言的场景。

Method: EAPrivacy基准测试使用程序生成的四个层级场景，测试智能体处理敏感对象、适应环境变化、平衡任务执行与隐私约束、以及解决与社会规范冲突的能力。

Result: 顶级模型Gemini 2.5 Pro在物理环境变化场景中准确率仅为59%；当任务伴随隐私请求时，模型在86%的情况下优先完成任务而非遵守隐私约束；在隐私与社会规范冲突的高风险场景中，GPT-4o和Claude-3.5-haiku等领先模型超过15%的情况下忽视社会规范。

Conclusion: 这些发现揭示了LLM在物理基础隐私方面存在根本性错位，需要更强大、物理感知的对齐方法。

Abstract: The deployment of Large Language Models (LLMs) in embodied agents creates an
urgent need to measure their privacy awareness in the physical world. Existing
evaluation methods, however, are confined to natural language based scenarios.
To bridge this gap, we introduce EAPrivacy, a comprehensive evaluation
benchmark designed to quantify the physical-world privacy awareness of
LLM-powered agents. EAPrivacy utilizes procedurally generated scenarios across
four tiers to test an agent's ability to handle sensitive objects, adapt to
changing environments, balance task execution with privacy constraints, and
resolve conflicts with social norms. Our measurements reveal a critical deficit
in current models. The top-performing model, Gemini 2.5 Pro, achieved only 59\%
accuracy in scenarios involving changing physical environments. Furthermore,
when a task was accompanied by a privacy request, models prioritized completion
over the constraint in up to 86\% of cases. In high-stakes situations pitting
privacy against critical social norms, leading models like GPT-4o and
Claude-3.5-haiku disregarded the social norm over 15\% of the time. These
findings, demonstrated by our benchmark, underscore a fundamental misalignment
in LLMs regarding physically grounded privacy and establish the need for more
robust, physically-aware alignment.

</details>


### [7] [Privacy in the Age of AI: A Taxonomy of Data Risks](https://arxiv.org/abs/2510.02357)
*Grace Billiris,Asif Gill,Madhushi Bandara*

Main category: cs.CR

TL;DR: 本文提出了一个AI隐私风险分类法，通过系统综述45项研究，识别出19个关键风险，分为数据集级、模型级、基础设施级和内部威胁四大类，发现人类错误是最重要因素。


<details>
  <summary>Details</summary>
Motivation: 传统隐私框架无法应对AI技术特有的自主学习和黑盒决策等特性，需要新的隐私风险评估方法。

Method: 通过系统综述45项研究，构建AI隐私风险分类法，识别并分类19个关键风险。

Result: 发现风险在四个维度均衡分布，人类错误(9.45%)是最显著因素，挑战了传统安全方法偏重技术控制的观念。

Conclusion: 该分类法通过连接AI隐私的技术和行为维度，为可信AI发展提供基础，并揭示需要更全面理解AI隐私风险。

Abstract: Artificial Intelligence (AI) systems introduce unprecedented privacy
challenges as they process increasingly sensitive data. Traditional privacy
frameworks prove inadequate for AI technologies due to unique characteristics
such as autonomous learning and black-box decision-making. This paper presents
a taxonomy classifying AI privacy risks, synthesised from 45 studies identified
through systematic review. We identify 19 key risks grouped under four
categories: Dataset-Level, Model-Level, Infrastructure-Level, and Insider
Threat Risks. Findings reveal a balanced distribution across these dimensions,
with human error (9.45%) emerging as the most significant factor. This taxonomy
challenges conventional security approaches that typically prioritise technical
controls over human factors, highlighting gaps in holistic understanding. By
bridging technical and behavioural dimensions of AI privacy, this paper
contributes to advancing trustworthy AI development and provides a foundation
for future research.

</details>


### [8] [Bootstrapping as a Morphism: An Arithmetic Geometry Approach to Asymptotically Faster Homomorphic Encryption](https://arxiv.org/abs/2510.02365)
*Dongfang Zhao*

Main category: cs.CR

TL;DR: 提出了一种新的全同态加密引导方法，通过几何投影模型替代传统电路评估，将引导操作复杂度从O(L_dec)降低到O(d·poly(log q))，消除了解密电路深度的依赖。


<details>
  <summary>Details</summary>
Motivation: 全同态加密的实际应用受到引导过程计算成本的严重限制，现有方法的复杂度都与解密电路的乘法深度L_dec相关，这成为主要性能瓶颈。

Method: 应用现代算术几何工具，将引导操作重新定义为几何投影。将密文空间建模为仿射概形，将可解密和新鲜密文轨迹定义为闭子概形，引导变换实现为这些空间之间的态射。计算上等效于在高度结构化的理想格上解决特定最近向量问题，使用代数折叠技术高效实现。

Result: 开发了完整且可证明正确的引导算法，计算复杂度为O(d·poly(log q))，其中d是环维度，q是密文模数。完全消除了L_dec因子，相比现有技术实现了根本性的渐进改进。

Conclusion: 这种几何视角为实现真正实用和高效的全同态加密提供了一条新的有前景的途径。

Abstract: Fully Homomorphic Encryption (FHE) provides a powerful paradigm for secure
computation, but its practical adoption is severely hindered by the prohibitive
computational cost of its bootstrapping procedure. The complexity of all
current bootstrapping methods is fundamentally tied to the multiplicative depth
of the decryption circuit, denoted $L_{dec}$, making it the primary performance
bottleneck. This paper introduces a new approach to bootstrapping that
completely bypasses the traditional circuit evaluation model. We apply the
tools of modern arithmetic geometry to reframe the bootstrapping operation as a
direct geometric projection. Our framework models the space of ciphertexts as
an affine scheme and rigorously defines the loci of decryptable and fresh
ciphertexts as distinct closed subschemes. The bootstrapping transformation is
then realized as a morphism between these two spaces. Computationally, this
projection is equivalent to solving a specific Closest Vector Problem (CVP)
instance on a highly structured ideal lattice, which we show can be done
efficiently using a technique we call algebraic folding. The primary result of
our work is a complete and provably correct bootstrapping algorithm with a
computational complexity of $O(d \cdot \text{poly}(\log q))$, where $d$ is the
ring dimension and $q$ is the ciphertext modulus. The significance of this
result lies in the complete elimination of the factor $L_{dec}$ from the
complexity, representing a fundamental asymptotic improvement over the state of
the art. This geometric perspective offers a new and promising pathway toward
achieving truly practical and high-performance FHE.

</details>


### [9] [Federated Spatiotemporal Graph Learning for Passive Attack Detection in Smart Grids](https://arxiv.org/abs/2510.02371)
*Bochra Al Agha,Razane Tajeddine*

Main category: cs.CR

TL;DR: 提出了一种基于图神经网络和联邦学习的被动窃听检测方法，通过融合物理层和行为指标来检测智能电网中的隐蔽侦察攻击。


<details>
  <summary>Details</summary>
Motivation: 智能电网面临被动窃听威胁，攻击者通过监听通信链路获取电网拓扑和运行模式信息，这种攻击信号微弱且短暂，传统单节点检测方法难以发现。

Method: 采用图中心多模态检测器，融合物理层和行为指标；使用两阶段编码器：图卷积聚合空间上下文，双向GRU建模短期时间依赖；在FedProx框架下进行联邦学习训练。

Result: 模型在测试集上达到98.32%的时间步准确率（F1攻击=0.972）和93.35%的序列准确率，误报率仅为0.15%。

Conclusion: 结合空间和时间上下文能够可靠检测隐蔽侦察攻击，同时保持低误报率，适用于非独立同分布的联邦智能电网部署。

Abstract: Smart grids are exposed to passive eavesdropping, where attackers listen
silently to communication links. Although no data is actively altered, such
reconnaissance can reveal grid topology, consumption patterns, and operational
behavior, creating a gateway to more severe targeted attacks. Detecting this
threat is difficult because the signals it produces are faint, short-lived, and
often disappear when traffic is examined by a single node or along a single
timeline. This paper introduces a graph-centric, multimodal detector that fuses
physical-layer and behavioral indicators over ego-centric star subgraphs and
short temporal windows to detect passive attacks. To capture stealthy
perturbations, a two-stage encoder is introduced: graph convolution aggregates
spatial context across ego-centric star subgraphs, while a bidirectional GRU
models short-term temporal dependencies. The encoder transforms heterogeneous
features into a unified spatio-temporal representation suitable for
classification. Training occurs in a federated learning setup under FedProx,
improving robustness to heterogeneous local raw data and contributing to the
trustworthiness of decentralized training; raw measurements remain on client
devices. A synthetic, standards-informed dataset is generated to emulate
heterogeneous HAN/NAN/WAN communications with wireless-only passive
perturbations, event co-occurrence, and leak-safe splits. The model achieves a
testing accuracy of 98.32% per-timestep (F1_{attack}=0.972) and 93.35%
per-sequence at 0.15% FPR using a simple decision rule with run-length m=2 and
threshold $\tau=0.55$. The results demonstrate that combining spatial and
temporal context enables reliable detection of stealthy reconnaissance while
maintaining low false-positive rates, making the approach suitable for non-IID
federated smart-grid deployments.

</details>


### [10] [A-MemGuard: A Proactive Defense Framework for LLM-Based Agent Memory](https://arxiv.org/abs/2510.02373)
*Qianshan Wei,Tengchao Yang,Yaochen Wang,Xinfeng Li,Lijun Li,Zhenfei Yin,Yi Zhan,Thorsten Holz,Zhiqiang Lin,XiaoFeng Wang*

Main category: cs.CR

TL;DR: A-MemGuard是一个针对LLM智能体内存安全的前瞻性防御框架，通过共识验证和双内存结构来检测和纠正恶意内存注入攻击，将攻击成功率降低95%以上。


<details>
  <summary>Details</summary>
Motivation: LLM智能体依赖内存进行自主规划，但恶意内存注入攻击难以检测且会引发自我强化的错误循环，需要主动防御机制。

Method: 结合共识验证（通过比较多个相关内存的推理路径检测异常）和双内存结构（将检测到的失败提炼为'教训'单独存储），在不修改核心架构的情况下实现内存自检自纠。

Result: 在多个基准测试中，A-MemGuard将攻击成功率降低了95%以上，同时仅产生最小的效用成本。

Conclusion: 该工作将LLM内存安全从静态过滤转向主动、经验驱动的模型，使防御能力随时间增强。

Abstract: Large Language Model (LLM) agents use memory to learn from past interactions,
enabling autonomous planning and decision-making in complex environments.
However, this reliance on memory introduces a critical security risk: an
adversary can inject seemingly harmless records into an agent's memory to
manipulate its future behavior. This vulnerability is characterized by two core
aspects: First, the malicious effect of injected records is only activated
within a specific context, making them hard to detect when individual memory
entries are audited in isolation. Second, once triggered, the manipulation can
initiate a self-reinforcing error cycle: the corrupted outcome is stored as
precedent, which not only amplifies the initial error but also progressively
lowers the threshold for similar attacks in the future. To address these
challenges, we introduce A-MemGuard (Agent-Memory Guard), the first proactive
defense framework for LLM agent memory. The core idea of our work is the
insight that memory itself must become both self-checking and self-correcting.
Without modifying the agent's core architecture, A-MemGuard combines two
mechanisms: (1) consensus-based validation, which detects anomalies by
comparing reasoning paths derived from multiple related memories and (2) a
dual-memory structure, where detected failures are distilled into ``lessons''
stored separately and consulted before future actions, breaking error cycles
and enabling adaptation. Comprehensive evaluations on multiple benchmarks show
that A-MemGuard effectively cuts attack success rates by over 95% while
incurring a minimal utility cost. This work shifts LLM memory security from
static filtering to a proactive, experience-driven model where defenses
strengthen over time. Our code is available in
https://github.com/TangciuYueng/AMemGuard

</details>


### [11] [A Hybrid CAPTCHA Combining Generative AI with Keystroke Dynamics for Enhanced Bot Detection](https://arxiv.org/abs/2510.02374)
*Ayda Aghaei Nia*

Main category: cs.CR

TL;DR: 提出了一种结合大语言模型认知挑战和击键动力学行为生物特征分析的混合CAPTCHA系统，通过双重验证机制提高安全性同时保持良好用户体验。


<details>
  <summary>Details</summary>
Motivation: 传统CAPTCHA在可用性和抵御AI机器人攻击之间存在权衡，需要开发更安全且用户友好的验证系统。

Method: 生成动态不可预测的问题（对人类简单但对自动化代理困难），同时分析用户的打字节奏来区分人类模式和机器人输入，采用双重验证架构。

Result: 实验评估显示该系统在机器人检测方面达到高精度，成功抵御基于粘贴和脚本的模拟攻击，同时人类参与者给出高可用性评分。

Conclusion: 结合认知和行为测试的方法有潜力创建更安全、用户友好的新一代CAPTCHA系统。

Abstract: Completely Automated Public Turing tests to tell Computers and Humans Apart
(CAPTCHAs) are a foundational component of web security, yet traditional
implementations suffer from a trade-off between usability and resilience
against AI-powered bots. This paper introduces a novel hybrid CAPTCHA system
that synergizes the cognitive challenges posed by Large Language Models (LLMs)
with the behavioral biometric analysis of keystroke dynamics. Our approach
generates dynamic, unpredictable questions that are trivial for humans but
non-trivial for automated agents, while simultaneously analyzing the user's
typing rhythm to distinguish human patterns from robotic input. We present the
system's architecture, formalize the feature extraction methodology for
keystroke analysis, and report on an experimental evaluation. The results
indicate that our dual-layered approach achieves a high degree of accuracy in
bot detection, successfully thwarting both paste-based and script-based
simulation attacks, while maintaining a high usability score among human
participants. This work demonstrates the potential of combining cognitive and
behavioral tests to create a new generation of more secure and user-friendly
CAPTCHAs.

</details>


### [12] [Scaling Homomorphic Applications in Deployment](https://arxiv.org/abs/2510.02376)
*Ryan Marinelli,Angelica Chowdhury*

Main category: cs.CR

TL;DR: 开发了一个概念验证的同态加密应用来评估加密生态系统的生产就绪性，通过容器化和编排技术实现电影推荐应用的生产化部署。


<details>
  <summary>Details</summary>
Motivation: 评估完全同态加密（FHE）在生产环境中的实际应用可行性，解决FHE计算限制问题。

Method: 实现电影推荐应用，使用容器化和编排技术进行生产化部署，通过调整部署配置和基础设施优化来缓解FHE的计算限制。

Result: 通过基础设施优化成功缓解了FHE的计算限制，验证了同态加密在生产环境中的可行性。

Conclusion: 同态加密生态系统已具备生产就绪性，通过适当的基础设施优化可以克服FHE的计算性能限制。

Abstract: In this endeavor, a proof-of-concept homomorphic application is developed to
determine the production readiness of encryption ecosystems. A movie
recommendation app is implemented for this purpose and productionized through
containerization and orchestration. By tuning deployment configurations, the
computational limitations of Fully Homomorphic Encryption (FHE) are mitigated
through additional infrastructure optimizations
  Index Terms: Reinforcement Learning, Orchestration, Homomorphic Encryption

</details>


### [13] [Apply Bayes Theorem to Optimize IVR Authentication Process](https://arxiv.org/abs/2510.02378)
*Jingrong Xie,Yumin Li*

Main category: cs.CR

TL;DR: 提出基于贝叶斯方法的交互式语音应答认证改进方案，通过动态评估欺诈风险和自适应调整凭证验证路径来增强金融IVR系统的安全性。


<details>
  <summary>Details</summary>
Motivation: 传统IVR系统使用静态凭证序列进行认证，假设所有凭证具有相同有效性，但欺诈者会利用这种可预测性，选择性绕过强凭证，导致安全漏洞。

Method: 应用贝叶斯定理和条件概率建模，动态评估欺诈风险并自适应调整凭证验证路径。

Result: 该方法能够更有效地识别和防范欺诈行为，提高IVR认证系统的安全性。

Conclusion: 贝叶斯方法为IVR认证提供了动态、自适应的安全增强方案，能够应对欺诈者的策略性攻击。

Abstract: This paper introduces a Bayesian approach to improve Interactive Voice
Response (IVR) authentication processes used by financial institutions.
Traditional IVR systems authenticate users through a static sequence of
credentials, assuming uniform effectiveness among them. However, fraudsters
exploit this predictability, selectively bypassing strong credentials. This
study applies Bayes' Theorem and conditional probability modeling to evaluate
fraud risk dynamically and adapt credential verification paths.

</details>


### [14] [Hybrid Schemes of NIST Post-Quantum Cryptography Standard Algorithms and Quantum Key Distribution for Key Exchange and Digital Signature](https://arxiv.org/abs/2510.02379)
*Abel C. H. Chen*

Main category: cs.CR

TL;DR: 本研究提出了结合量子密钥分发(QKD)和后量子密码(PQC)的混合方案，包括混合密钥交换协议和混合数字签名方案，以构建双重安全模型。


<details>
  <summary>Details</summary>
Motivation: 由于PQC基于数学问题难度，QKD基于量子物理原理，两者各有优缺点可以互补。为应对这一趋势，需要将QKD与NIST标准化的PQC算法集成。

Method: 混合密钥交换协议结合ML-KEM与BB84/E91 QKD协议；混合数字签名方案使用ML-DSA和SLH-DSA生成签名重构值，通过BB84/E91传输确认码进行验证。

Result: 评估了混合密钥交换协议产生的共享密钥的熵和IID特性，以及混合方案的计算时间和消息长度。

Conclusion: 提出的混合方案成功整合了QKD和PQC，为后量子时代提供了双重安全保障。

Abstract: Since the security of post-quantum cryptography (PQC) algorithms is based on
the hardness of mathematical problems, while the security of quantum key
distribution (QKD) relies on the fundamental principles of quantum physics,
each approach possesses distinct advantages and limitations that can complement
one another. Consequently, recent studies have proposed hybrid schemes that
combine QKD and PQC to establish a dual-layered security model. In response to
this trend, this study proposes hybrid schemes that integrate QKD with the
National Institute of Standards and Technology (NIST) standardized PQC
algorithms. These hybrid schemes include two core components: a hybrid QKD-PQC
key exchange protocol and a hybrid QKD-PQC digital signature scheme. For the
hybrid key exchange protocol, this study combines Module-Lattice-based Key
Encapsulation Mechanisms (ML-KEM) with QKD protocols, specifically BB84 and
E91, to construct a secure key exchange protocol. In the design of the hybrid
digital signature scheme, this study utilizes Module-Lattice-based Digital
Signature Algorithms (ML-DSA) and Stateless Hash-based Digital Signature
Algorithms (SLH-DSA) to generate signature reconstruction values. These values
are verified using confirmation codes transmitted via the BB84 and E91
protocols. The proposed hybrid key exchange protocol is evaluated by examining
the shared secret key it produces, particularly with respect to entropy and
whether the output is independent and identically distributed (IID).
Furthermore, the computation time and message lengths of the proposed hybrid
schemes are evaluated.

</details>


### [15] [Selmer-Inspired Elliptic Curve Generation](https://arxiv.org/abs/2510.02383)
*Awnon Bhowmik*

Main category: cs.CR

TL;DR: 提出基于Selmer框架的透明可审计椭圆曲线构造方法，利用2-和3-下降技术生成候选参数，通过局部可解性检查和密码学验证构建安全椭圆曲线


<details>
  <summary>Details</summary>
Motivation: 现有标准椭圆曲线的参数生成过程不透明，需要建立透明且可审计的构造框架来增强信任

Method: 使用2-和3-下降方法推导二元四次型和三元三次型，通过经典不变量确定候选(c4,c6)参数，进行局部可解性检查，最后转换为短Weierstrass形式并应用密码学验证

Result: 概念验证实现表明该流程可作为Las Vegas算法运行，提供完整可验证记录，与恒定时间实现兼容

Conclusion: 该工作扩展了椭圆曲线设计空间，证明算术几何中的下降技术可为标准化就绪的构造提供信任增强基础

Abstract: Elliptic curve cryptography (ECC) is foundational to modern secure
communication, yet existing standard curves have faced scrutiny for opaque
parameter-generation practices. This work introduces a Selmer-inspired
framework for constructing elliptic curves that is both transparent and
auditable. Drawing from $2$- and $3$-descent methods, we derive binary quartics
and ternary cubics whose classical invariants deterministically yield candidate
$(c_4,c_6)$ parameters. Local solubility checks, modeled on Selmer
admissibility, filter candidates prior to reconciliation into short-Weierstrass
form over prime fields. We then apply established cryptographic validations,
including group-order factorization, cofactor bounds, twist security, and
embedding-degree heuristics. A proof-of-concept implementation demonstrates
that the pipeline functions as a retry-until-success Las Vegas algorithm, with
complete transcripts enabling independent verification. Unlike seed-based or
purely efficiency-driven designs, our approach embeds arithmetic structure into
parameter selection while remaining compatible with constant-time, side-channel
resistant implementations. This work broadens the design space for elliptic
curves, showing that descent techniques from arithmetic geometry can underpin
trust-enhancing, standardization-ready constructions.

</details>


### [16] [Secure and Robust Watermarking for AI-generated Images: A Comprehensive Survey](https://arxiv.org/abs/2510.02384)
*Jie Cao,Qi Li,Zelin Zhang,Jianbing Ni*

Main category: cs.CR

TL;DR: 本文对AI生成图像水印技术进行全面综述，涵盖系统形式化、技术比较、评估方法、安全漏洞及未来方向五个维度，旨在促进该领域发展。


<details>
  <summary>Details</summary>
Motivation: 随着生成式AI快速发展，AI生成图像在知识产权保护、真实性验证和责任追溯方面面临严峻挑战，水印技术成为区分AI生成内容与自然内容的关键解决方案。

Method: 采用系统性综述方法，从五个维度分析AI生成图像水印技术：系统形式化、多样化水印技术概述与比较、基于视觉质量、容量和可检测性的评估方法、恶意攻击漏洞分析。

Result: 建立了AI生成图像水印技术的全面框架，系统梳理了现有技术方法、评估标准和潜在风险，为研究者提供了完整的知识体系。

Conclusion: 水印技术是构建可信数字生态系统的关键，本综述为AI生成图像水印技术的持续发展提供了理论基础和研究方向指导。

Abstract: The rapid advancement of generative artificial intelligence (Gen-AI) has
facilitated the effortless creation of high-quality images, while
simultaneously raising critical concerns regarding intellectual property
protection, authenticity, and accountability. Watermarking has emerged as a
promising solution to these challenges by distinguishing AI-generated images
from natural content, ensuring provenance, and fostering trustworthy digital
ecosystems. This paper presents a comprehensive survey of the current state of
AI-generated image watermarking, addressing five key dimensions: (1)
formalization of image watermarking systems; (2) an overview and comparison of
diverse watermarking techniques; (3) evaluation methodologies with respect to
visual quality, capacity, and detectability; (4) vulnerabilities to malicious
attacks; and (5) prevailing challenges and future directions. The survey aims
to equip researchers with a holistic understanding of AI-generated image
watermarking technologies, thereby promoting their continued development.

</details>


### [17] [On The Fragility of Benchmark Contamination Detection in Reasoning Models](https://arxiv.org/abs/2510.02386)
*Han Wang,Haoyu Li,Brian Ko,Huan Zhang*

Main category: cs.CR

TL;DR: 研究发现大型推理模型（LRMs）的基准污染检测存在严重漏洞，模型开发者可以通过简单的训练策略轻松规避现有检测方法，从而在排行榜上获得虚高的性能表现。


<details>
  <summary>Details</summary>
Motivation: 当前LRM排行榜促使开发者直接在基准套件上进行优化，而将评估基准纳入训练数据是提升排名的捷径，这导致了基准污染问题。研究旨在揭示LRM基准污染的检测漏洞。

Method: 研究分析了两种实际污染场景：(I) 基础模型通过SFT和RL演变为LRM时，发现GRPO训练能显著掩盖污染信号；(II) 在高级LRM上应用带CoT的SFT污染时，现有检测方法几乎随机猜测。通过实证实验和理论分析探究了检测失效的根本原因。

Result: PPO风格的重要性采样和裁剪目标是检测掩盖的根源，表明广泛类别的RL方法具有类似的掩盖能力。污染后的LRM对与训练集分布相似的未见样本仍具有更高置信度，从而规避基于记忆化的检测方法。

Conclusion: 研究揭示了LRM评估的独特脆弱性：模型开发者可轻易污染LRM以获得虚高的排行榜性能，同时留下极少污染痕迹，严重损害评估公平性和公共排行榜的完整性，迫切需要针对LRM的先进污染检测方法和可信评估协议。

Abstract: Leaderboards for LRMs have turned evaluation into a competition,
incentivizing developers to optimize directly on benchmark suites. A shortcut
to achieving higher rankings is to incorporate evaluation benchmarks into the
training data, thereby yielding inflated performance, known as benchmark
contamination. Surprisingly, our studies find that evading contamination
detections for LRMs is alarmingly easy. We focus on the two scenarios where
contamination may occur in practice: (I) when the base model evolves into LRM
via SFT and RL, we find that contamination during SFT can be originally
identified by contamination detection methods. Yet, even a brief GRPO training
can markedly conceal contamination signals that most detection methods rely on.
Further empirical experiments and theoretical analysis indicate that PPO style
importance sampling and clipping objectives are the root cause of this
detection concealment, indicating that a broad class of RL methods may
inherently exhibit similar concealment capability; (II) when SFT contamination
with CoT is applied to advanced LRMs as the final stage, most contamination
detection methods perform near random guesses. Without exposure to non-members,
contaminated LRMs would still have more confidence when responding to those
unseen samples that share similar distributions to the training set, and thus,
evade existing memorization-based detection methods. Together, our findings
reveal the unique vulnerability of LRMs evaluations: Model developers could
easily contaminate LRMs to achieve inflated leaderboards performance while
leaving minimal traces of contamination, thereby strongly undermining the
fairness of evaluation and threatening the integrity of public leaderboards.
This underscores the urgent need for advanced contamination detection methods
and trustworthy evaluation protocols tailored to LRMs.

</details>


### [18] [LLM-Generated Samples for Android Malware Detection](https://arxiv.org/abs/2510.02391)
*Nik Rollinson,Nikolaos Polatidis*

Main category: cs.CR

TL;DR: 本研究探索了使用GPT-4.1-mini生成Android恶意软件合成数据来增强检测模型的效果，发现在真实数据稀缺时，合成数据可以作为有效补充，但不能完全替代真实数据。


<details>
  <summary>Details</summary>
Motivation: Android恶意软件通过混淆和多态技术不断进化，给基于签名的防御和机器学习模型带来挑战。现有数据集有限且不平衡，合成数据被提出作为解决方案，但大型语言模型在生成有效恶意软件数据方面的作用尚未充分探索。

Method: 使用KronoDroid数据集，对GPT-4.1-mini进行微调，为BankBot、Locker/SLocker和Airpush/StopSMS三个恶意软件家族生成结构化记录。通过提示工程和后处理解决生成不一致问题，并在三种设置下评估多个分类器：仅使用真实数据、真实加合成数据、仅使用合成数据。

Result: 仅使用真实数据的训练实现了接近完美的检测效果，而使用合成数据增强后仍保持高性能，仅有轻微性能下降。相比之下，仅使用合成数据的训练结果参差不齐，效果因恶意软件家族和微调策略而异。

Conclusion: LLM生成的恶意软件数据可以在不损害检测准确性的情况下增强稀缺数据集，但不足以作为独立的训练来源。

Abstract: Android malware continues to evolve through obfuscation and polymorphism,
posing challenges for both signature-based defenses and machine learning models
trained on limited and imbalanced datasets. Synthetic data has been proposed as
a remedy for scarcity, yet the role of large language models (LLMs) in
generating effective malware data for detection tasks remains underexplored. In
this study, we fine-tune GPT-4.1-mini to produce structured records for three
malware families: BankBot, Locker/SLocker, and Airpush/StopSMS, using the
KronoDroid dataset. After addressing generation inconsistencies with prompt
engineering and post-processing, we evaluate multiple classifiers under three
settings: training with real data only, real-plus-synthetic data, and synthetic
data alone. Results show that real-only training achieves near perfect
detection, while augmentation with synthetic data preserves high performance
with only minor degradations. In contrast, synthetic-only training produces
mixed outcomes, with effectiveness varying across malware families and
fine-tuning strategies. These findings suggest that LLM-generated malware can
enhance scarce datasets without compromising detection accuracy, but remains
insufficient as a standalone training source.

</details>


### [19] [PolyLink: A Blockchain Based Decentralized Edge AI Platform for LLM Inference](https://arxiv.org/abs/2510.02395)
*Hongbo Liu,Jiannong Cao,Bo Yang,Dongbin Bai,Yinfeng Cao,Xiaoming Shen,Yinan Zhang,Jinwen Liang,Shan Jiang,Mingjin Zhang*

Main category: cs.CR

TL;DR: PolyLink是一个基于区块链的去中心化AI平台，旨在解决大型语言模型服务集中化带来的信任问题和成本问题。


<details>
  <summary>Details</summary>
Motivation: 当前LLM服务的部署和使用高度集中化，给终端用户和开发者带来了显著的信任问题和成本负担。

Method: 采用去中心化众包架构，支持单设备和跨设备的模型部署与推理；设计了TIQE协议确保推理完整性，结合轻量级交叉编码器模型和LLM作为评判者；集成基于代币的激励机制。

Result: 通过地理分布式部署在异构设备上进行评估，结果显示推理和验证延迟具有实用性；安全分析表明系统能够抵抗模型退化攻击和验证器损坏。

Conclusion: PolyLink成功构建了一个实用的去中心化AI平台，解决了LLM服务集中化的问题，现已开源可用。

Abstract: The rapid advancement of large language models (LLMs) in recent years has
revolutionized the AI landscape. However, the deployment model and usage of LLM
services remain highly centralized, creating significant trust issues and costs
for end users and developers. To address these issues, we propose PolyLink, a
blockchain-based decentralized AI platform that decentralizes LLM development
and inference. Specifically, PolyLink introduces a decentralized crowdsourcing
architecture that supports single-device and cross-device model deployment and
inference across heterogeneous devices at the edge. Moreover, to ensure the
inference integrity, we design the TIQE protocol, which combines a lightweight
cross-encoder model and an LLM-as-a-Judge for a high-accuracy inference
evaluation. Lastly, we integrate a comprehensive token-based incentive model
with dynamic pricing and reward mechanisms for all participants. We have
deployed PolyLink and conducted an extensive real-world evaluation through
geo-distributed deployment across heterogeneous devices. Results indicate that
the inference and verification latency is practical. Our security analysis
demonstrates that the system is resistant to model degradation attacks and
validator corruptions. PolyLink is now available at
https://github.com/IMCL-PolyLink/PolyLink.

</details>


### [20] [Dynamic Target Attack](https://arxiv.org/abs/2510.02422)
*Kedong Xiu,Churui Zeng,Tianhang Zheng,Xinzhe Huang,Xiaojun Jia,Di Wang,Puning Zhao,Zhan Qin,Kui Ren*

Main category: cs.CR

TL;DR: 提出动态目标攻击(DTA)，一种新的越狱框架，使用目标LLM自身响应作为优化目标，显著减少目标与输出分布之间的差异，提高攻击效率和成功率。


<details>
  <summary>Details</summary>
Motivation: 现有基于梯度的越狱攻击通常优化对抗后缀以诱导固定肯定响应，但固定目标通常位于安全对齐LLM输出分布的极低密度区域，导致优化过程困难且效率低下。

Method: 在每轮优化中，DTA从当前提示条件下的输出分布中采样多个候选响应，选择最具危害性的响应作为临时目标进行提示优化，动态调整目标以匹配输出分布。

Result: 在白盒设置下，DTA仅需200次优化迭代即可在最新安全对齐LLM上实现平均87%以上的攻击成功率，比最先进基线高出15%以上，时间成本减少2-26倍。在黑盒设置下，使用Llama-3-8B-Instruct作为代理模型，对Llama-3-70B-Instruct的攻击成功率达到85%，比同类方法高出25%以上。

Conclusion: DTA通过动态选择目标LLM自身响应作为优化目标，显著提高了越狱攻击的效率和成功率，在黑白盒设置下均优于现有方法。

Abstract: Existing gradient-based jailbreak attacks typically optimize an adversarial
suffix to induce a fixed affirmative response. However, this fixed target
usually resides in an extremely low-density region of a safety-aligned LLM's
output distribution conditioned on diverse harmful inputs. Due to the
substantial discrepancy between the target and the original output, existing
attacks require numerous iterations to optimize the adversarial prompt, which
might still fail to induce the low-probability target response from the target
LLM. In this paper, we propose Dynamic Target Attack (DTA), a new jailbreaking
framework relying on the target LLM's own responses as targets to optimize the
adversarial prompts. In each optimization round, DTA iteratively samples
multiple candidate responses directly from the output distribution conditioned
on the current prompt, and selects the most harmful response as a temporary
target for prompt optimization. In contrast to existing attacks, DTA
significantly reduces the discrepancy between the target and the output
distribution, substantially easing the optimization process to search for an
effective adversarial prompt.
  Extensive experiments demonstrate the superior effectiveness and efficiency
of DTA: under the white-box setting, DTA only needs 200 optimization iterations
to achieve an average attack success rate (ASR) of over 87\% on recent
safety-aligned LLMs, exceeding the state-of-the-art baselines by over 15\%. The
time cost of DTA is 2-26 times less than existing baselines. Under the
black-box setting, DTA uses Llama-3-8B-Instruct as a surrogate model for target
sampling and achieves an ASR of 85\% against the black-box target model
Llama-3-70B-Instruct, exceeding its counterparts by over 25\%.

</details>


### [21] [Adaptive Deception Framework with Behavioral Analysis for Enhanced Cybersecurity Defense](https://arxiv.org/abs/2510.02424)
*Basil Abdullah AL-Zahrani*

Main category: cs.CR

TL;DR: CADL是一个自适应欺骗框架，在CICIDS2017数据集上达到99.88%检测率和0.13%误报率，显著优于传统入侵检测系统。


<details>
  <summary>Details</summary>
Motivation: 提供比商业欺骗平台更经济实惠的替代方案，传统入侵检测系统检测率较低（Snort 71.2%，Suricata 68.5%）。

Method: 采用集成机器学习（随机森林、XGBoost、神经网络）结合行为分析，通过协调信号总线架构实现安全组件实时情报共享，基于时间模式对攻击者进行画像并部署定制化欺骗策略。

Result: 在50,000个CICIDS2017测试样本上，检测率99.88%，误报率0.13%，行为分析对攻击者画像分类准确率达89%。

Conclusion: CADL框架提供了开源实现和透明性能指标，是商业欺骗平台的经济替代方案，同时保持生产就绪的低误报率。

Abstract: This paper presents CADL (Cognitive-Adaptive Deception Layer), an adaptive
deception framework achieving 99.88% detection rate with 0.13% false positive
rate on the CICIDS2017 dataset. The framework employs ensemble machine learning
(Random Forest, XGBoost, Neural Networks) combined with behavioral profiling to
identify and adapt responses to network intrusions. Through a coordinated
signal bus architecture, security components share real-time intelligence,
enabling collective decision-making. The system profiles attackers based on
temporal patterns and deploys customized deception strategies across five
escalation levels. Evaluation on 50,000 CICIDS2017 test samples demonstrates
that CADL significantly outperforms traditional intrusion detection systems
(Snort: 71.2%, Suricata: 68.5%) while maintaining production-ready false
positive rates. The framework's behavioral analysis achieves 89% accuracy in
classifying attacker profiles. We provide open-source implementation and
transparent performance metrics, offering an accessible alternative to
commercial deception platforms costing $150-400 per host annually.

</details>


### [22] [Rigorous Evaluation of Microarchitectural Side-Channels with Statistical Model Checking](https://arxiv.org/abs/2510.02475)
*Weihang Li,Pete Crowley,Arya Tschand,Yu Wang,Miroslav Pajic,Daniel Sorin*

Main category: cs.CR

TL;DR: 本文提出使用统计模型检验(SMC)来定量评估微架构侧信道，解决了传统方法因处理器复杂性和概率性行为而面临的挑战。


<details>
  <summary>Details</summary>
Motivation: 微架构侧信道评估面临两个主要挑战：处理器、攻击和防御都表现出概率性行为；微处理器极其复杂，传统简化模型可能遗漏重要安全现象。

Method: 引入统计模型检验(SMC)技术，将处理器视为黑盒，不需要抽象或简化，通过概率实验提供统计保证。

Result: 通过三个案例研究证明SMC能有效评估现有安全漏洞和防御措施，提供更严格的统计保证，并能量化噪声注入所需的噪声量。

Conclusion: SMC为微架构侧信道评估提供了一种严谨的统计方法，使防御者能够制定可操作的计划来通过噪声注入进行混淆。

Abstract: Rigorous quantitative evaluation of microarchitectural side channels is
challenging for two reasons. First, the processors, attacks, and defenses often
exhibit probabilistic behaviors. These probabilistic behaviors arise due to
natural noise in systems (e.g., from co-running processes), probabilistic side
channel attacks, and probabilistic obfuscation defenses. Second,
microprocessors are extremely complex. Previous evaluation methods have relied
on abstract or simplified models, which are necessarily less detailed than real
systems or cycle-by-cycle simulators, and these models may miss important
phenomena. Whereas a simple model may suffice for estimating performance,
security issues frequently manifest in the details.
  We address this challenge by introducing Statistical Model Checking (SMC) to
the quantitative evaluation of microarchitectural side channels. SMC is a
rigorous statistical technique that can process the results of probabilistic
experiments and provide statistical guarantees, and it has been used in
computing applications that depend heavily on statistical guarantees (e.g.,
medical implants, vehicular computing). With SMC, we can treat processors as
opaque boxes, and we do not have to abstract or simplify them. We demonstrate
the effectiveness of SMC through three case studies, in which we experimentally
show that SMC can evaluate existing security vulnerabilities and defenses and
provide qualitatively similar conclusions with greater statistical rigor, while
making no simplifying assumptions or abstractions. We also show that SMC can
enable a defender to quantify the amount of noise necessary to have a desired
level of confidence that she has reduced an attacker's probability of success
to less than a desired threshold, thus providing the defender with an
actionable plan for obfuscation via noise injection.

</details>


### [23] [TLoRa: Implementing TLS Over LoRa for Secure HTTP Communication in IoT](https://arxiv.org/abs/2510.02519)
*Atonu Ghosh,Akhilesh Mohanasundaram,Srishivanth R F,Sudip Misra*

Main category: cs.CR

TL;DR: TLoRa是一个端到端架构，通过集成TCP隧道和完整的TLS 1.3握手，实现在LoRa上建立HTTPS通信。它使用端集线器和网络中继在WiFi设备和互联网之间创建安全通信通道。


<details>
  <summary>Details</summary>
Motivation: 为WiFi设备通过LoRa网络安全访问互联网提供解决方案，填补了在LoRa上实现完整HTTPS通信的研究空白。

Method: 采用三阶段操作：会话建立（TCP套接字管理和TLS握手）、安全隧道（在LoRa上传输加密TLS数据）和渲染（向用户交付URL内容）。还实现了轻量级TLS记录重组层和会话多路复用队列机制。

Result: 在真实硬件上评估显示，TLoRa能在9.9秒内成功建立LoRa上的TLS会话，并在3.58秒内完成API请求。

Conclusion: TLoRa提供了一个实用的解决方案，是首个在LoRa上使用完整TLS全面设计、实现和评估HTTPS访问性能的工作。

Abstract: We present TLoRa, an end-to-end architecture for HTTPS communication over
LoRa by integrating TCP tunneling and a complete TLS 1.3 handshake. It enables
a seamless and secure communication channel between WiFi-enabled end devices
and the Internet over LoRa using an End Hub (EH) and a Net Relay (NR). The EH
tethers a WiFi hotspot and a captive portal for user devices to connect and
request URLs. The EH forwards the requested URLs to the NR using a secure
tunnel over LoRa. The NR, which acts as a server-side proxy, receives and
resolves the request from the Internet-based server. It then relays back the
encrypted response from the server over the same secure tunnel. TLoRa operates
in three phases -session setup, secure tunneling, and rendering. In the first
phase, it manages the TCP socket and initiates the TLS handshake. In the
second, it creates a secure tunnel and transfers encrypted TLS data over LoRa.
Finally, it delivers the URL content to the user. TLoRa also implements a
lightweight TLS record reassembly layer and a queuing mechanism for session
multiplexing. We evaluate TLoRa on real hardware using multiple accesses to a
web API. Results indicate that it provides a practical solution by successfully
establishing a TLS session over LoRa in 9.9 seconds and takes 3.58 seconds to
fulfill API requests. To the best of our knowledge, this is the first work to
comprehensively design, implement, and evaluate the performance of HTTPS access
over LoRa using full TLS.

</details>


### [24] [ToolTweak: An Attack on Tool Selection in LLM-based Agents](https://arxiv.org/abs/2510.02554)
*Jonathan Sneh,Ruomei Yan,Jialin Yu,Philip Torr,Yarin Gal,Sunando Sengupta,Eric Sommerlade,Alasdair Paren,Adel Bibi*

Main category: cs.CR

TL;DR: ToolTweak攻击通过迭代操纵工具名称和描述，能够系统性地偏置AI代理选择特定工具，将选择率从约20%提高到81%，揭示了工具生态系统中的公平性、竞争和安全风险。


<details>
  <summary>Details</summary>
Motivation: 随着LLM驱动的代理越来越多地使用外部工具，工具选择过程存在关键漏洞：攻击者可以通过操纵工具元数据来获得不公平优势，影响工具生态系统的公平竞争。

Method: 提出ToolTweak轻量级自动攻击方法，通过迭代优化工具名称和描述来偏置代理选择，并在开源和闭源模型间验证攻击的迁移性。

Result: 攻击成功将工具选择率从基线约20%提升至最高81%，攻击在不同模型间具有强迁移性，并导致工具使用分布发生偏移。

Conclusion: 工具选择过程存在严重安全漏洞，需要防御措施。评估了释义和困惑度过滤两种防御方法，能有效减少偏见，促进功能相似工具的公平选择。

Abstract: As LLMs increasingly power agents that interact with external tools, tool use
has become an essential mechanism for extending their capabilities. These
agents typically select tools from growing databases or marketplaces to solve
user tasks, creating implicit competition among tool providers and developers
for visibility and usage. In this paper, we show that this selection process
harbors a critical vulnerability: by iteratively manipulating tool names and
descriptions, adversaries can systematically bias agents toward selecting
specific tools, gaining unfair advantage over equally capable alternatives. We
present ToolTweak, a lightweight automatic attack that increases selection
rates from a baseline of around 20% to as high as 81%, with strong
transferability between open-source and closed-source models. Beyond individual
tools, we show that such attacks cause distributional shifts in tool usage,
revealing risks to fairness, competition, and security in emerging tool
ecosystems. To mitigate these risks, we evaluate two defenses: paraphrasing and
perplexity filtering, which reduce bias and lead agents to select functionally
similar tools more equally. All code will be open-sourced upon acceptance.

</details>


### [25] [Who's Wearing? Ear Canal Biometric Key Extraction for User Authentication on Wireless Earbuds](https://arxiv.org/abs/2510.02563)
*Chenpei Huang,Lingfeng Yao,Hui Zhong,Kyu In Lee,Lan Zhang,Xiaoyong Yuan,Tomoaki Ohtsuki,Miao Pan*

Main category: cs.CR

TL;DR: EarID是一种基于耳道扫描的认证协议，直接在耳机上提取二进制密钥，使用模糊承诺方案在移动设备上验证，实现98.7%的认证准确率，具有高效和抗攻击特性。


<details>
  <summary>Details</summary>
Motivation: 现有耳道扫描认证方法依赖机器学习分类器，存在原始生物特征数据泄露风险，且计算效率不适合资源受限的耳机设备。

Method: 提出EarID协议，不依赖分类器，直接在耳机上提取唯一二进制密钥，结合隐私保护的模糊承诺方案在移动设备上验证佩戴者密钥。

Result: 达到98.7%认证准确率，移动设备注册时间160ms，耳机处理时间226ms，在所有对抗场景下误接受率低于1%。

Conclusion: EarID为下一代无线耳机提供了实用且安全的解决方案，在保持高准确率的同时解决了数据隐私和计算效率问题。

Abstract: Ear canal scanning/sensing (ECS) has emerged as a novel biometric
authentication method for mobile devices paired with wireless earbuds. Existing
studies have demonstrated the uniqueness of ear canals by training and testing
machine learning classifiers on ECS data. However, implementing practical
ECS-based authentication requires preventing raw biometric data leakage and
designing computationally efficient protocols suitable for resource-constrained
earbuds. To address these challenges, we propose an ear canal key extraction
protocol, \textbf{EarID}. Without relying on classifiers, EarID extracts unique
binary keys directly on the earbuds during authentication. These keys further
allow the use of privacy-preserving fuzzy commitment scheme that verifies the
wearer's key on mobile devices. Our evaluation results demonstrate that EarID
achieves a 98.7\% authentication accuracy, comparable to machine learning
classifiers. The mobile enrollment time (160~ms) and earbuds processing time
(226~ms) are negligible in terms of wearer's experience. Moreover, our approach
is robust and attack-resistant, maintaining a false acceptance rate below 1\%
across all adversarial scenarios. We believe the proposed EarID offers a
practical and secure solution for next-generation wireless earbuds.

</details>


### [26] [Using Preformed Resistive Random Access Memory to Create a Strong Physically Unclonable Function](https://arxiv.org/abs/2510.02643)
*Jack Garrard,John F. Hardy II,Carlo daCunha,Mayank Bakshi*

Main category: cs.CR

TL;DR: 提出了一种基于ReRAM的新型物理不可克隆函数协议，通过未形成ReRAM的差分读取生成响应，并在物理设备上进行了实验验证。


<details>
  <summary>Details</summary>
Motivation: 物理不可克隆函数在身份验证和非对称加密方面具有应用前景，需要创建具有大挑战空间的物理ReRAM PUF。

Method: 使用未形成ReRAM的差分读取作为响应生成方法，构建ReRAM PUF协议。

Result: 在物理ReRAM设备上成功演示了该协议，作为PUF表现出优异的性能特征。

Conclusion: 该ReRAM PUF协议能够有效实现身份验证和加密功能，具有实际应用价值。

Abstract: Physically Unclonable Functions (PUFs) are a promising solution for identity
verification and asymmetric encryption. In this paper, a new Resistive Random
Access Memory (ReRAM) PUF-based protocol is presented to create a physical
ReRAM PUF with a large challenge space. This protocol uses differential reads
from unformed ReRAM as the method for response generation. Lastly, this paper
also provides an experimental hardware demonstration of this protocol on a
Physical ReRAM device, along with providing notable results as a PUF, with
excellent performance characteristics.

</details>


### [27] [MALF: A Multi-Agent LLM Framework for Intelligent Fuzzing of Industrial Control Protocols](https://arxiv.org/abs/2510.02694)
*Bowei Ning,Xuejun Zong,Kan He*

Main category: cs.CR

TL;DR: MALF是一个多智能体LLM模糊测试框架，通过结合大型语言模型和多智能体协调来发现工业控制协议中的漏洞，在真实工业环境中成功识别出关键漏洞。


<details>
  <summary>Details</summary>
Motivation: 工业控制系统对现代基础设施至关重要，但其通信协议存在安全弱点，容易遭受网络攻击。需要更精确和自适应的模糊测试方法来发现漏洞。

Method: 集成大型语言模型与多智能体协调，使用RAG获取领域知识，QLoRA微调实现协议感知输入生成，优化种子生成、变异策略和反馈驱动优化。

Result: 在Modbus/TCP、S7Comm和Ethernet/IP等协议测试中，测试用例通过率达88-92%，生成更多异常触发，种子覆盖率超过90%，熵值4.2-4.6位。在实际电厂攻防环境中发现3个零日漏洞。

Conclusion: 多智能体LLM在ICS网络安全中具有变革潜力，提供了一个可扩展的自动化框架，为漏洞发现设定了新标准，增强了关键基础设施的安全性。

Abstract: Industrial control systems (ICS) are vital to modern infrastructure but
increasingly vulnerable to cybersecurity threats, particularly through
weaknesses in their communication protocols. This paper presents MALF
(Multi-Agent LLM Fuzzing Framework), an advanced fuzzing solution that
integrates large language models (LLMs) with multi-agent coordination to
identify vulnerabilities in industrial control protocols (ICPs). By leveraging
Retrieval-Augmented Generation (RAG) for domain-specific knowledge and QLoRA
fine-tuning for protocol-aware input generation, MALF enhances fuzz testing
precision and adaptability. The multi-agent framework optimizes seed
generation, mutation strategies, and feedback-driven refinement, leading to
improved vulnerability discovery. Experiments on protocols like Modbus/TCP,
S7Comm, and Ethernet/IP demonstrate that MALF surpasses traditional methods,
achieving a test case pass rate (TCPR) of 88-92% and generating more exception
triggers (ETN). MALF also maintains over 90% seed coverage and Shannon entropy
values between 4.2 and 4.6 bits, ensuring diverse, protocol-compliant
mutations. Deployed in a real-world Industrial Attack-Defense Range for power
plants, MALF identified critical vulnerabilities, including three zero-day
flaws, one confirmed and registered by CNVD. These results validate MALF's
effectiveness in real-world fuzzing applications. This research highlights the
transformative potential of multi-agent LLMs in ICS cybersecurity, offering a
scalable, automated framework that sets a new standard for vulnerability
discovery and strengthens critical infrastructure security against emerging
threats.

</details>


### [28] [A Statistical Method for Attack-Agnostic Adversarial Attack Detection with Compressive Sensing Comparison](https://arxiv.org/abs/2510.02707)
*Chinthana Wimalasuriya,Spyros Tragoudas*

Main category: cs.CR

TL;DR: 提出一种基于压缩/未压缩神经网络对行为的统计方法，实现近乎完美的实时对抗攻击检测，显著降低误报率。


<details>
  <summary>Details</summary>
Motivation: 现有对抗攻击检测方法难以有效检测未知攻击类型，且对不同攻击类型的检测准确率有限。

Method: 通过比较压缩/未压缩神经网络对的行为，生成对抗攻击存在性的度量指标，在神经网络部署前建立检测基线。

Result: 与最先进技术相比，该方法在多种攻击类型上实现近乎完美的检测效果，并显著减少误报。

Conclusion: 该方法可靠且实用，适用于现实世界应用中的对抗攻击检测。

Abstract: Adversarial attacks present a significant threat to modern machine learning
systems. Yet, existing detection methods often lack the ability to detect
unseen attacks or detect different attack types with a high level of accuracy.
In this work, we propose a statistical approach that establishes a detection
baseline before a neural network's deployment, enabling effective real-time
adversarial detection. We generate a metric of adversarial presence by
comparing the behavior of a compressed/uncompressed neural network pair. Our
method has been tested against state-of-the-art techniques, and it achieves
near-perfect detection across a wide range of attack types. Moreover, it
significantly reduces false positives, making it both reliable and practical
for real-world applications.

</details>


### [29] [Attack via Overfitting: 10-shot Benign Fine-tuning to Jailbreak LLMs](https://arxiv.org/abs/2510.02833)
*Zhixin Xie,Xurui Song,Jun Luo*

Main category: cs.CR

TL;DR: 本文提出了一种仅使用10个良性问答对就能成功破解大语言模型安全对齐的方法，该方法通过先让模型过度拟合拒绝回答，然后再用标准良性答案微调，使模型忘记拒绝态度，从而对有害问题也提供合规回答。


<details>
  <summary>Details</summary>
Motivation: 尽管已有大量安全对齐工作，但大语言模型仍然容易受到微调攻击。现有恶意微调攻击容易被检测，因此需要开发更隐蔽的攻击方法。

Method: 首先通过微调让LLM过度拟合包含相同拒绝回答的良性问答对，然后用标准良性答案进一步微调，使过度拟合的模型忘记拒绝态度。

Result: 在10个LLM上实施攻击并与5个基线方法比较，实验表明该方法在攻击效果和隐蔽性方面都具有显著优势。

Conclusion: 该方法揭示了当前LLM中先前未报告的安全漏洞，为理解即使使用良性微调如何破坏LLM安全性提供了新视角。

Abstract: Despite substantial efforts in safety alignment, recent research indicates
that Large Language Models (LLMs) remain highly susceptible to jailbreak
attacks. Among these attacks, finetuning-based ones that compromise LLMs'
safety alignment via fine-tuning stand out due to its stable jailbreak
performance. In particular, a recent study indicates that fine-tuning with as
few as 10 harmful question-answer (QA) pairs can lead to successful
jailbreaking across various harmful questions. However, such malicious
fine-tuning attacks are readily detectable and hence thwarted by moderation
models. In this paper, we demonstrate that LLMs can be jailbroken by
fine-tuning with only 10 benign QA pairs; our attack exploits the increased
sensitivity of LLMs to fine-tuning data after being overfitted. Specifically,
our fine-tuning process starts with overfitting an LLM via fine-tuning with
benign QA pairs involving identical refusal answers. Further fine-tuning is
then performed with standard benign answers, causing the overfitted LLM to
forget the refusal attitude and thus provide compliant answers regardless of
the harmfulness of a question. We implement our attack on the ten LLMs and
compare it with five existing baselines. Experiments demonstrate that our
method achieves significant advantages in both attack effectiveness and attack
stealth. Our findings expose previously unreported security vulnerabilities in
current LLMs and provide a new perspective on understanding how LLMs' security
is compromised, even with benign fine-tuning. Our code is available at
https://github.com/ZHIXINXIE/tenBenign.

</details>


### [30] [Improved Search-to-Decision Reduction for Random Local Functions](https://arxiv.org/abs/2510.02944)
*Kel Zin Tan,Prashant Nalini Vasudevan*

Main category: cs.CR

TL;DR: 本文提出了一种新的搜索到决策约简方法，适用于任何常数元谓词定义的随机局部函数。该约简能将区分器转化为求逆算法，且适用于所有谓词，无需额外的敏感性要求。


<details>
  <summary>Details</summary>
Motivation: 随机局部函数是约束满足问题的自然实例分布，被Goldreich提出作为低复杂度单向函数的候选方案，并作为潜在伪随机生成器被广泛研究。现有约简方法需要谓词具有额外的敏感性，限制了应用范围。

Method: 提出新的搜索到决策约简技术：给定一个能以优势ε区分随机局部函数输出与随机的算法，构造一个能以概率Ω(ε)求逆此类函数的算法，输出长度为Õ(m(n/ε)²)。

Result: 该约简适用于任何常数元谓词，无需额外敏感性要求。结果可推广到某些超常数元值和噪声谓词。

Conclusion: 证明如果局部函数族是单向的，则具有较短输出长度的相关函数族是伪随机生成器族，为随机局部函数的密码学性质提供了更一般的理论保证。

Abstract: A random local function defined by a $d$-ary predicate $P$ is one where each
output bit is computed by applying $P$ to $d$ randomly chosen bits of its
input. These represent natural distributions of instances for constraint
satisfaction problems. They were put forward by Goldreich as candidates for
low-complexity one-way functions, and have subsequently been widely studied
also as potential pseudo-random generators.
  We present a new search-to-decision reduction for random local functions
defined by any predicate of constant arity. Given any efficient algorithm that
can distinguish, with advantage $\epsilon$, the output of a random local
function with $m$ outputs and $n$ inputs from random, our reduction produces an
efficient algorithm that can invert such functions with
$\tilde{O}(m(n/\epsilon)^2)$ outputs, succeeding with probability
$\Omega(\epsilon)$. This implies that if a family of local functions is
one-way, then a related family with shorter output length is family of
pseudo-random generators.
  Prior to our work, all such reductions that were known required the predicate
to have additional sensitivity properties, whereas our reduction works for any
predicate. Our results also generalise to some super-constant values of the
arity $d$, and to noisy predicates.

</details>


### [31] [SoK: Preconfirmations](https://arxiv.org/abs/2510.02947)
*Aikaterini-Panagiota Stouka,Conor McMenamin,Demetris Kyriacou,Lin Oshitani,Quentin Botha*

Main category: cs.CR

TL;DR: 这是一篇关于区块链预确认协议的系统知识整理论文，探讨了预确认协议如何为用户提供早期交易确认保证，以改善用户体验。


<details>
  <summary>Details</summary>
Motivation: 传统区块链协议存在固有延迟，限制了用户体验的提升。预确认协议通过提供早期交易确认保证来弥补这一缺陷。

Method: 采用系统知识整理方法，提出预确认协议的核心术语和定义，构建通用框架，分析经济学和风险，并调查现实世界的预确认协议实现。

Result: 建立了一个理解预确认协议的完整框架，将理论与实践联系起来，为预确认协议的设计和分析提供了系统化的方法。

Conclusion: 预确认协议是改善区块链用户体验的重要发展方向，本文的系统知识整理为这一领域的研究和实践提供了理论基础和分析框架。

Abstract: In recent years, significant research efforts have focused on improving
blockchain throughput and confirmation speeds without compromising security.
While decreasing the time it takes for a transaction to be included in the
blockchain ledger enhances user experience, a fundamental delay still remains
between when a transaction is issued by a user and when its inclusion is
confirmed in the blockchain ledger. This delay limits user experience gains
through the confirmation uncertainty it brings for users. This inherent delay
in conventional blockchain protocols has led to the emergence of
preconfirmation protocols -- protocols that provide users with early guarantees
of eventual transaction confirmation.
  This article presents a Systematization of Knowledge (SoK) on
preconfirmations. We present the core terms and definitions needed to
understand preconfirmations, outline a general framework for preconfirmation
protocols, and explore the economics and risks of preconfirmations. Finally, we
survey and apply our framework to several implementations of real-world
preconfirmation protocols, bridging the gap between theory and practice.

</details>


### [32] [SoK: Kicking CAN Down the Road. Systematizing CAN Security Knowledge](https://arxiv.org/abs/2510.02960)
*Khaled Serag,Zhaozhou Tang,Sungwoo Kim,Vireshwar Kumar,Dave,Tian,Saman Zonouz,Raheem Beyah,Dongyan Xu,Z. Berkay Celik*

Main category: cs.CR

TL;DR: 本文系统化整理了CAN总线安全知识，提出了攻击者、攻击和防御的综合分类与评估模型，识别了可复现攻击和防御缺口，并分析了新兴车载总线技术的安全问题。


<details>
  <summary>Details</summary>
Motivation: CAN总线安全研究文献丰富但缺乏系统化整理，难以评估攻击严重性和防御有效性，且新兴车载总线技术的安全声明可能误导人们认为仅采用新技术就能解决CAN的安全挑战。

Method: 构建了攻击者、攻击和防御的综合分类与评估模型，识别可复现攻击和防御缺口，分析根本原因，并形式化分析三种新兴车载总线技术。

Result: 研究发现CAN比人们认为的更安全，大多数不安全根本原因在车载总线间共享，仅采用新技术无法解决持续的安全问题。

Conclusion: 挑战了常见认知，强调需要未来研究方向来确保车载总线通信安全，而不仅仅是采用新技术。

Abstract: For decades, the Controller Area Network (CAN) has served as the primary
in-vehicle bus (IVB) and extended its use to many non-vehicular systems. Over
the past years, CAN security has been intensively scrutinized, yielding
extensive research literature. Despite its wealth, the literature lacks
structured systematization, complicating efforts to assess attack severity,
defense efficacy, identify security gaps, or root causes. This leaves non
experts uncertain about the relevancy of specific attacks or defenses to their
systems, inadvertently portraying CAN as irredeemably insecure. Further, the
introduction of new IVB technologies--CAN evolutions, add-ons, and alternative
buses--with heightened security claims risks fostering the misconception that
merely adopting these technologies resolves CAN's security challenges.
  This paper systematizes existing CAN security knowledge, presenting a
comprehensive taxonomy and assessment models of attackers, attacks, and
defenses. It identifies replicable attacks and defense gaps, investigating
their root causes as inherent, accidental, unique, or universal. It then
extrapolates these insights to emerging IVB technologies by formally analyzing
three emerging IVBs to identify shared root causes with CAN and assess their
ability to close security gaps. The findings challenge common perceptions,
demonstrating that CAN is more securable than perceived, that most insecurity
root causes are shared across IVBs, and that merely adopting newer IVB
technology does not solve persistent security issues. The paper concludes by
highlighting future research directions to secure IVB communication down the
road.

</details>


### [33] [External Data Extraction Attacks against Retrieval-Augmented Large Language Models](https://arxiv.org/abs/2510.02964)
*Yu He,Yifei Chen,Yiming Li,Shuo Shao,Leyi Qi,Boheng Li,Dacheng Tao,Zhan Qin*

Main category: cs.CR

TL;DR: 本文提出了SECRET攻击框架，这是首个针对检索增强大语言模型(RAG)的外部数据提取攻击(EDEA)的全面研究。该攻击通过自适应优化和集群触发策略，显著提高了数据提取成功率，在Claude 3.7 Sonnet上实现了35%的数据提取率。


<details>
  <summary>Details</summary>
Motivation: RAG虽然能增强LLMs的专业知识，但引入了外部数据提取攻击(EDEA)风险，可能导致敏感或版权数据被提取。现有研究缺乏正式框架和强大攻击性能，无法评估真实世界EDEA的可行性。

Method: 提出统一框架将EDEA分解为提取指令、越狱操作符和检索触发器三个组件。开发SECRET攻击，包含：(1)使用LLMs作为优化器的自适应优化过程生成专用越狱提示；(2)集群聚焦触发策略，在全局探索和局部利用之间切换以生成有效检索触发器。

Result: 在4个模型上的广泛评估显示，SECRET显著优于先前攻击，对16个测试RAG实例均高度有效。首次在Claude 3.7 Sonnet驱动的RAG上成功提取35%数据，而其他攻击提取率为0%。

Conclusion: SECRET攻击展示了RAG系统面临的外部数据提取威胁的现实可行性，呼吁关注这一新兴安全风险。

Abstract: In recent years, RAG has emerged as a key paradigm for enhancing large
language models (LLMs). By integrating externally retrieved information, RAG
alleviates issues like outdated knowledge and, crucially, insufficient domain
expertise. While effective, RAG introduces new risks of external data
extraction attacks (EDEAs), where sensitive or copyrighted data in its
knowledge base may be extracted verbatim. These risks are particularly acute
when RAG is used to customize specialized LLM applications with private
knowledge bases. Despite initial studies exploring these risks, they often lack
a formalized framework, robust attack performance, and comprehensive
evaluation, leaving critical questions about real-world EDEA feasibility
unanswered.
  In this paper, we present the first comprehensive study to formalize EDEAs
against retrieval-augmented LLMs. We first formally define EDEAs and propose a
unified framework decomposing their design into three components: extraction
instruction, jailbreak operator, and retrieval trigger, under which prior
attacks can be considered instances within our framework. Guided by this
framework, we develop SECRET: a Scalable and EffeCtive exteRnal data Extraction
aTtack. Specifically, SECRET incorporates (1) an adaptive optimization process
using LLMs as optimizers to generate specialized jailbreak prompts for EDEAs,
and (2) cluster-focused triggering, an adaptive strategy that alternates
between global exploration and local exploitation to efficiently generate
effective retrieval triggers. Extensive evaluations across 4 models reveal that
SECRET significantly outperforms previous attacks, and is highly effective
against all 16 tested RAG instances. Notably, SECRET successfully extracts 35%
of the data from RAG powered by Claude 3.7 Sonnet for the first time, whereas
other attacks yield 0% extraction. Our findings call for attention to this
emerging threat.

</details>


### [34] [Untargeted Jailbreak Attack](https://arxiv.org/abs/2510.02999)
*Xinzhe Huang,Wenjing Hu,Tianhang Zheng,Kedong Xiu,Xiaojun Jia,Di Wang,Zhan Qin,Kui Ren*

Main category: cs.CR

TL;DR: 本文提出首个基于梯度的无目标越狱攻击方法UJA，通过最大化模型回答的不安全概率而非预定义目标，显著扩展了攻击搜索空间，在仅需100次优化迭代的情况下就能达到80%以上的攻击成功率。


<details>
  <summary>Details</summary>
Motivation: 现有基于梯度的越狱攻击方法（如GCG、COLD-Attack）通常优化对抗性后缀以匹配预定义目标回答，这种方法限制了对抗搜索空间，且需要大量优化迭代来弥合固定目标与原始模型回答之间的差距，导致攻击效率低下。

Method: 提出无目标越狱攻击目标，最大化LLM回答的不安全概率（通过评判模型量化）。由于目标不可微分，将其分解为两个可微分子目标：优化最优有害回答和相应的对抗提示，并通过理论分析验证分解的有效性。

Result: 在仅100次优化迭代的情况下，UJA对最新安全对齐LLM的攻击成功率超过80%，比最先进的基于梯度攻击方法（如I-GCG和COLD-Attack）高出20%以上。

Conclusion: UJA的无限制目标显著扩展了搜索空间，能够更灵活高效地探索LLM漏洞，相比目标越狱攻击具有明显优势。

Abstract: Existing gradient-based jailbreak attacks on Large Language Models (LLMs),
such as Greedy Coordinate Gradient (GCG) and COLD-Attack, typically optimize
adversarial suffixes to align the LLM output with a predefined target response.
However, by restricting the optimization objective as inducing a predefined
target, these methods inherently constrain the adversarial search space, which
limit their overall attack efficacy. Furthermore, existing methods typically
require a large number of optimization iterations to fulfill the large gap
between the fixed target and the original model response, resulting in low
attack efficiency.
  To overcome the limitations of targeted jailbreak attacks, we propose the
first gradient-based untargeted jailbreak attack (UJA), aiming to elicit an
unsafe response without enforcing any predefined patterns. Specifically, we
formulate an untargeted attack objective to maximize the unsafety probability
of the LLM response, which can be quantified using a judge model. Since the
objective is non-differentiable, we further decompose it into two
differentiable sub-objectives for optimizing an optimal harmful response and
the corresponding adversarial prompt, with a theoretical analysis to validate
the decomposition. In contrast to targeted jailbreak attacks, UJA's
unrestricted objective significantly expands the search space, enabling a more
flexible and efficient exploration of LLM vulnerabilities.Extensive evaluations
demonstrate that \textsc{UJA} can achieve over 80\% attack success rates
against recent safety-aligned LLMs with only 100 optimization iterations,
outperforming the state-of-the-art gradient-based attacks such as I-GCG and
COLD-Attack by over 20\%.

</details>


### [35] [Protecting Persona Biometric Data: The Case of Facial Privacy](https://arxiv.org/abs/2510.03035)
*Lambert Hogenhout,Rinzin Wangmo*

Main category: cs.CR

TL;DR: 本文分析了面部识别技术带来的隐私威胁，比较了各国相关法律框架，指出现有法律漏洞使个人面临风险，并提出了从数据财产权转向不可剥夺权利的新政策框架。


<details>
  <summary>Details</summary>
Motivation: 数字技术普及导致大量面部数据被收集，企业未经明确同意使用面部识别技术进行监控，而许多司法管辖区的法律薄弱且分散，形成了监管真空，威胁个人隐私和自主权。

Method: 通过全面审查现有法律框架，比较分析GDPR、巴西LGPD、加拿大PIPEDA、中国、新加坡、韩国、日本的隐私法，以及美国伊利诺伊州生物识别信息隐私法(BIPA)等专门法律。

Result: 分析显示现有法律漏洞和模糊性使个人易受侵害，面部识别技术可能带来歧视性偏见，且不可改变生物识别数据的盗窃会造成持久伤害。

Conclusion: 需要新的政策框架，从数据作为财产的模式转向不可剥夺权利的模式，确保基本人权不受不受控制的技术扩张侵害。

Abstract: The proliferation of digital technologies has led to unprecedented data
collection, with facial data emerging as a particularly sensitive commodity.
Companies are increasingly leveraging advanced facial recognition technologies,
often without the explicit consent or awareness of individuals, to build
sophisticated surveillance capabilities. This practice, fueled by weak and
fragmented laws in many jurisdictions, has created a regulatory vacuum that
allows for the commercialization of personal identity and poses significant
threats to individual privacy and autonomy. This article introduces the concept
of Facial Privacy. It analyzes the profound challenges posed by unregulated
facial recognition by conducting a comprehensive review of existing legal
frameworks. It examines and compares regulations such as the GDPR, Brazil's
LGPD, Canada's PIPEDA, and privacy acts in China, Singapore, South Korea, and
Japan, alongside sector-specific laws in the United States like the Illinois
Biometric Information Privacy Act (BIPA). The analysis highlights the societal
impacts of this technology, including the potential for discriminatory bias and
the long-lasting harm that can result from the theft of immutable biometric
data. Ultimately, the paper argues that existing legal loopholes and
ambiguities leave individuals vulnerable. It proposes a new policy framework
that shifts the paradigm from data as property to a model of inalienable
rights, ensuring that fundamental human rights are upheld against unchecked
technological expansion.

</details>


### [36] [TPM-Based Continuous Remote Attestation and Integrity Verification for 5G VNFs on Kubernetes](https://arxiv.org/abs/2510.03219)
*Al Nahian Bin Emran,Rajendra Upadhyay,Rajendra Paudyal,Lisa Donnan,Duminda Wijesekera*

Main category: cs.CR

TL;DR: 提出基于TPM 2.0和Linux IMA的5G核心组件连续远程证明解决方案，在Kubernetes环境中实现硬件级别的运行时完整性验证。


<details>
  <summary>Details</summary>
Motivation: 5G云原生部署虽然提高了可扩展性和灵活性，但缺乏对网络功能运行时完整性的持续验证机制，现有安全规范假设网络功能在认证后保持可信。

Method: 使用TPM 2.0和Linux IMA，集成Keylime框架和自定义IMA模板，实现pod级别的隔离测量和完整性验证。

Result: 原型系统在k3s集群上成功实施，能够实时检测未经授权的修改，标记每个pod的信任状态，并生成详细审计日志。

Conclusion: 该工作为云原生和边缘部署提供了硬件基础的连续证明，增强了5G作为关键基础设施在多供应商和关键任务场景中的弹性。

Abstract: In the rapidly evolving landscape of 5G technology, the adoption of
cloud-based infrastructure for the deployment of 5G services has become
increasingly common. Using a service-based architecture, critical 5G
components, such as the Access and Mobility Management Function (AMF), Session
Management Function (SMF), and User Plane Function (UPF), now run as
containerized pods on Kubernetes clusters. Although this approach improves
scalability, flexibility, and resilience, it also introduces new security
challenges, particularly to ensure the integrity and trustworthiness of these
components. Current 5G security specifications (for example, 3GPP TS 33.501)
focus on communication security and assume that network functions remain
trustworthy after authentication, consequently lacking mechanisms to
continuously validate the integrity of NVFs at runtime. To close this gap, and
to align with Zero Trust principles of 'never trust, always verify', we present
a TPM 2.0-based continuous remote attestation solution for core 5G components
deployed on Kubernetes. Our approach uses the Linux Integrity Measurement
Architecture (IMA) and a Trusted Platform Module (TPM) to provide
hardware-based runtime validation. We integrate the open-source Keylime
framework with a custom IMA template that isolates pod-level measurements,
allowing per-pod integrity verification. A prototype on a k3s cluster
(consisting of 1 master, 2 worker nodes) was implemented to attest to core
functions, including AMF, SMF and UPF. The experimental results show that the
system detects unauthorized modifications in real time, labels each pod's trust
state, and generates detailed audit logs. This work provides hardware-based
continuous attestation for cloud native and edge deployments, strengthening the
resilience of 5G as critical infrastructure in multi-vendor and
mission-critical scenarios of 5G.

</details>
