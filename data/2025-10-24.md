<div id=toc></div>

# Table of Contents

- [cs.CR](#cs.CR) [Total: 30]


<div id='cs.CR'></div>

# cs.CR [[Back]](#toc)

### [1] [CourtGuard: A Local, Multiagent Prompt Injection Classifier](https://arxiv.org/abs/2510.19844)
*Isaac Wu,Michael Maslowski*

Main category: cs.CR

TL;DR: CourtGuard是一个本地运行的多智能体提示注入分类器，采用法庭式多智能体LLM系统来检测提示注入攻击，相比Direct Detector具有更低的误报率。


<details>
  <summary>Details</summary>
Motivation: 随着LLM在敏感应用中的集成，提示注入攻击风险日益增加，可能导致数据泄露、错误信息传播等危害行为。

Method: 使用法庭式多智能体系统：'辩护律师'模型论证提示为良性，'检察官'模型论证提示为注入攻击，'法官'模型给出最终分类。

Result: CourtGuard相比Direct Detector具有更低的误报率，但总体上检测效果较差。

Conclusion: 多智能体系统在防御提示注入攻击方面具有潜力，考虑对抗性和良性场景对提示分类很重要。

Abstract: As large language models (LLMs) become integrated into various sensitive
applications, prompt injection, the use of prompting to induce harmful
behaviors from LLMs, poses an ever increasing risk. Prompt injection attacks
can cause LLMs to leak sensitive data, spread misinformation, and exhibit
harmful behaviors. To defend against these attacks, we propose CourtGuard, a
locally-runnable, multiagent prompt injection classifier. In it, prompts are
evaluated in a court-like multiagent LLM system, where a "defense attorney"
model argues the prompt is benign, a "prosecution attorney" model argues the
prompt is a prompt injection, and a "judge" model gives the final
classification. CourtGuard has a lower false positive rate than the Direct
Detector, an LLM as-a-judge. However, CourtGuard is generally a worse prompt
injection detector. Nevertheless, this lower false positive rate highlights the
importance of considering both adversarial and benign scenarios for the
classification of a prompt. Additionally, the relative performance of
CourtGuard in comparison to other prompt injection classifiers advances the use
of multiagent systems as a defense against prompt injection attacks. The
implementations of CourtGuard and the Direct Detector with full prompts for
Gemma-3-12b-it, Llama-3.3-8B, and Phi-4-mini-instruct are available at
https://github.com/isaacwu2000/CourtGuard.

</details>


### [2] [Can Reasoning Models Obfuscate Reasoning? Stress-Testing Chain-of-Thought Monitorability](https://arxiv.org/abs/2510.19851)
*Artur Zolkowski,Wen Xing,David Lindner,Florian Tramèr,Erik Jenner*

Main category: cs.CR

TL;DR: 研究表明，即使模型在链式思维（CoT）监控下，仍可能通过模糊化推理过程来规避检测，实现对抗性目标。


<details>
  <summary>Details</summary>
Motivation: 由于发现错位模型可能表现出欺骗行为，需要测试CoT监控的有效性，特别是模型是否能够通过模糊化推理来逃避检测。

Method: 开发了可组合和可量化的提示分类法来引发CoT模糊化，在玩具任务和SHADE-Arena现实环境中评估内部CoT和外部CoT。

Result: 无模糊化压力时CoT监控准确高效；强压力下部分模型能完成任务并逃避检测；模型对内部CoT的模糊化程度低于外部CoT。

Conclusion: CoT在良性设置下提供有价值的监督，但稳健部署需要对模型的可监控性进行特定压力测试。

Abstract: Recent findings suggest that misaligned models may exhibit deceptive
behavior, raising concerns about output trustworthiness. Chain-of-thought (CoT)
is a promising tool for alignment monitoring: when models articulate their
reasoning faithfully, monitors can detect and mitigate harmful behaviors before
undesirable outcomes occur. However, a key uncertainty is: Can models obfuscate
their CoT in order to pursue hidden adversarial objectives while evading
detection? To answer this question and thus stress-test CoT monitorability, we
develop a composable and quantifiable taxonomy of prompts to elicit CoT
obfuscation. We evaluate both internal CoT (reasoning traces) and external CoT
(prompted reasoning in outputs) using toy tasks and more realistic environments
in SHADE-Arena. We show that: (i) CoT monitoring performs accurately and
efficiently without obfuscation pressure. (ii) Under strong obfuscation
pressure, some models successfully complete adversarial tasks while evading
detection. (iii) Models do not obfuscate their internal CoT as much as their
external CoT (under prompt pressure). These results suggest that while CoT
provides valuable oversight in benign settings, robust deployment requires
model-specific stress-testing of monitorability.

</details>


### [3] [Model Context Contracts - MCP-Enabled Framework to Integrate LLMs With Blockchain Smart Contracts](https://arxiv.org/abs/2510.19856)
*Eranga Bandara,Sachin Shetty,Ravi Mukkamala,Ross Gore,Peter Foytik,Safdar H. Bouk,Abdul Rahman,Xueping Liang,Ng Wee Keong,Kasun De Zoysa,Aruna Withanage,Nilaan Loganathan*

Main category: cs.CR

TL;DR: 提出了MCC框架，通过类似MCP的协议让LLM直接与区块链智能合约交互，使用户能用自然语言查询与区块链系统交互和执行交易。


<details>
  <summary>Details</summary>
Motivation: 区块链在各行业广泛应用，生成式AI和LLM改变了人机交互方式，但缺乏标准化的LLM应用与区块链集成方法。

Method: 开发MCC框架，通过微调LLM使用自定义数据集（用户输入与对应MCP服务器功能配对），让智能合约能识别自然语言输入并执行相应交易。

Result: 在Rahasak区块链上开发了端到端原型，使用微调后的Llama-4 LLM，显著提高了平台性能和准确性。

Conclusion: 这是首个使用模型上下文协议概念将LLM与区块链集成的方法，实现了用户通过自然语言与区块链系统的智能交互。

Abstract: In recent years, blockchain has experienced widespread adoption across
various industries, becoming integral to numerous enterprise applications.
Concurrently, the rise of generative AI and LLMs has transformed human-computer
interactions, offering advanced capabilities in understanding and generating
human-like text. The introduction of the MCP has further enhanced AI
integration by standardizing communication between AI systems and external data
sources. Despite these advancements, there is still no standardized method for
seamlessly integrating LLM applications and blockchain. To address this
concern, we propose "MCC: Model Context Contracts" a novel framework that
enables LLMs to interact directly with blockchain smart contracts through
MCP-like protocol. This integration allows AI agents to invoke blockchain smart
contracts, facilitating more dynamic and context-aware interactions between
users and blockchain networks. Essentially, it empowers users to interact with
blockchain systems and perform transactions using queries in natural language.
Within this proposed architecture, blockchain smart contracts can function as
intelligent agents capable of recognizing user input in natural language and
executing the corresponding transactions. To ensure that the LLM accurately
interprets natural language inputs and maps them to the appropriate MCP
functions, the LLM was fine-tuned using a custom dataset comprising user inputs
paired with their corresponding MCP server functions. This fine-tuning process
significantly improved the platform's performance and accuracy. To validate the
effectiveness of MCC, we have developed an end-to-end prototype implemented on
the Rahasak blockchain with the fine-tuned Llama-4 LLM. To the best of our
knowledge, this research represents the first approach to using the concept of
Model Context Protocol to integrate LLMs with blockchain.

</details>


### [4] [Cyberattack Detection in Critical Infrastructure and Supply Chains](https://arxiv.org/abs/2510.19859)
*Smita Khapre*

Main category: cs.CR

TL;DR: 提出将密集神经网络与数据增强技术结合，以解决工业4.0中关键基础设施和供应链的零日攻击检测问题，但发现高度不平衡的网络流量数据集需要不同的数据增强方法。


<details>
  <summary>Details</summary>
Motivation: 工业4.0中关键基础设施和供应链的网络安全面临挑战，传统入侵检测系统无法检测零日攻击，需要智能化的检测方案。

Method: 使用密集神经网络与数据增强技术，特别是合成少数类过采样技术，来处理高度不平衡的网络流量数据集。

Result: 在平衡测试数据上获得较高准确率，但在原始不平衡测试数据上准确率较低，表明存在过拟合问题。与现有方法比较显示对原始数据集的分类效果不佳。

Conclusion: 高度不平衡的网络流量数据集需要不同于传统合成少数类过采样技术的数据增强方法。

Abstract: Cyberattack detection in Critical Infrastructure and Supply Chains has become
challenging in Industry 4.0. Intrusion Detection Systems (IDS) are deployed to
counter the cyberattacks. However, an IDS effectively detects attacks based on
the known signatures and patterns, Zero-day attacks go undetected. To overcome
this drawback in IDS, the integration of a Dense Neural Network (DNN) with Data
Augmentation is proposed. It makes IDS intelligent and enables it to self-learn
with high accuracy when a novel attack is encountered. The network flow
captures datasets are highly imbalanced same as the real network itself. The
Data Augmentation plays a crucial role in balancing the data. The balancing of
data is challenging as the minority class is as low as 0.000004\% of the
dataset, and the abundant class is higher than 80\% of the dataset. Synthetic
Minority Oversampling Technique is used for balancing the data. However, higher
accuracies are achieved with balanced test data, lower accuracies are
noticeable with the original imbalanced test data suggesting overfitting. A
comparison with state-of-the-art research using Synthetic Minority Oversampling
Technique with Edited Nearest Neighbor shows the classification of classes
remains poor for the original dataset. This suggests highly imbalanced datasets
of network flow require a different method of data augmentation.

</details>


### [5] [Policy-Governed RAG - Research Design Study](https://arxiv.org/abs/2510.19877)
*Jean-Marie Le Ray*

Main category: cs.CR

TL;DR: 提出了一种面向受监管工作流程的政策治理RAG架构，通过三个核心组件确保审计就绪的生成：合同控制、清单追踪和收据验证，使政策检查可审计、可重放且具有收据支持。


<details>
  <summary>Details</summary>
Motivation: 在制药、医疗器械、金融、法律和公共部门等受监管领域，错误成本可能超过数千欧元，且根据欧盟AI法案等法规，审计追踪是强制性的。现有RAG/护栏系统缺乏可审计的政策检查和可验证的证据绑定。

Method: 采用三部分架构：(I)合同/控制组件，管理输出对法律和内部政策的遵守；(II)清单/追踪组件，通过密码学锚定所有引用的源证据以确保可验证的来源；(III)收据/验证组件，为审计人员提供最终的可移植合规证明。

Result: 设定了未经验证的目标：相对自信错误减少≥20%；p95延迟≤900毫秒；服务成本≤2.2倍。设计了包含NO-GO门的预注册试点方案。

Conclusion: 该设计通过使政策检查可审计、可重放且具有收据支持，补充了现有的RAG/护栏系统。未来评估可能承诺在未满足任何NO-GO门条件时发布负面结果。

Abstract: A policy-governed RAG architecture is specified for audit-ready generation in
regulated workflows, organized as a triptych: (I) Contracts/Control
(SHRDLU-like), which governs output adherence to legal and internal policies;
(II) Manifests/Trails (Memex-like), which cryptographically anchors all cited
source evidence to ensure verifiable provenance; and (III)
Receipts/Verification (Xanadu-like), which provides the final, portable proof
of compliance for auditors (portable COSE/JOSE) (see Section 4 and Appendix A).
Rather than explaining model internals, outputs are gated ex-ante and bound to
cryptographically verifiable evidence for each material answer. Unvalidated
targets are stated (>=20% relative reduction in confident errors; p95 latency
<= 900 ms; <= 2.2x serve cost) together with a pre-registered (optional) pilot
using NO-GO gates. The design complements existing RAG/guardrails by making
policy checks auditable, replayable, and receipt-backed. Target domains include
back-office compliance in pharma, medical devices, finance, legal, and the
public sector where error costs may exceed thousands of euros and audit trails
are mandatory under regulations such as the EU AI Act. Future evaluations may
pre-commit to publishing negative results when any example NO-GO gate is not
met.

</details>


### [6] [A Proactive Insider Threat Management Framework Using Explainable Machine Learning](https://arxiv.org/abs/2510.19883)
*Selma Shikonde,Mike Wa Nkongolo*

Main category: cs.CR

TL;DR: 提出了IT-XML框架，结合CRISP-DM和隐马尔可夫模型来增强内部威胁管理，通过问卷调查评估员工安全意识，实现了91.7%的分类准确率。


<details>
  <summary>Details</summary>
Motivation: 随着技术发展，组织面临更多网络安全威胁，特别是内部威胁。在网络安全基础设施、专业知识和法规仍在发展的行业中，内部威胁仍然是一个重大挑战。

Method: 采用定量方法，通过在线问卷评估员工对内部威胁模式的了解；结合CRISP-DM和隐马尔可夫模型构建IT-XML框架，使用SHAP和LIME等方法提高模型可解释性。

Result: 框架将所有组织分类为发展中的安全成熟度水平，置信度达97-98%；分类准确率为91.7%；识别审计日志访问限制为最关键的控制措施；随机森林分析显示供应商违规通知和定期审计日志审查是弹性的关键决定因素。

Conclusion: IT-XML框架通过提高模型透明度和可解释性，展示了加强内部威胁管理实践的潜力，为主动威胁缓解提供了基于证据的建议。

Abstract: Over the years, the technological landscape has evolved, reshaping the
security posture of organisations and increasing their exposure to
cybersecurity threats, many originating from within. Insider threats remain a
major challenge, particularly in sectors where cybersecurity infrastructure,
expertise, and regulations are still developing. This study proposes the
Insider Threat Explainable Machine Learning (IT-XML) framework, which
integrates the Cross-Industry Standard Process for Data Mining (CRISP-DM) with
Hidden Markov Models (HMM) to enhance proactive insider threat management and
decision-making. A quantitative approach is adopted using an online
questionnaire to assess employees' knowledge of insider threat patterns, access
control, privacy practices, and existing policies across three large
data-sensitive organisations. The IT-XML framework provides assessment
capabilities through survey-based data, HMM-driven pattern recognition for
security maturity classification, and evidence-based recommendations for
proactive threat mitigation. The framework classified all organisations at the
developing security maturity level with 97-98% confidence and achieved a
classification accuracy of 91.7%, identifying audit log access limits as the
most critical control. Random Forest analysis highlighted vendor breach
notifications (0.081) and regular audit log reviews (0.052) as key determinants
of resilience. Explainability methods such as SHAP and LIME improved model
transparency and interpretability, demonstrating the framework's potential to
strengthen insider threat management practices.

</details>


### [7] [Analysis and Comparison of Known and Randomly Generated S-boxes for Block Ciphers](https://arxiv.org/abs/2510.19885)
*James Kim*

Main category: cs.CR

TL;DR: 比较数学构造与随机生成的S盒性能，评估随机方法的相对弱点，并在简单SPN结构中建立随机排列的平均性能指标


<details>
  <summary>Details</summary>
Motivation: 数学构造的S盒具有可证明的密码学特性，而完全随机方法缺乏理论保证但复杂度低且结果多样，需要系统比较两者的性能差异

Method: 比较数学构造与随机生成的S盒，建立随机排列的平均性能指标，包括带循环约束的随机生成，在简单SPN结构中进行评估

Result: 数学构造的S盒具有高非线性、APN特性和平衡雪崩特性，而随机方法在理论保证方面较弱但复杂度较低

Conclusion: 数学构造方法在密码学特性方面优于随机方法，但随机方法在复杂度和结果多样性方面有优势

Abstract: Mathematically constructed S-boxes arise from algebraic structures and finite
field theory to ensure strong, provable cryptographic properties. These
mathematically grounded constructions allow for generation of thousands of
S-Boxes with high nonlinearity, APN properties, and balanced avalanche
characteristics, unlike fully random methods, which lack such theoretical
guarantees in exchange for low complexity and more varied results. In this
work, we compare mathematically constructed constructions with randomly
generated ones to evaluate the relative weakness of the latter. We also
establish an average measure of performance for randomly generated
permutations, as well as random with forced cycle constraints, and compare them
to well-established designs in a simple SPN setting.

</details>


### [8] [Deep Sequence-to-Sequence Models for GNSS Spoofing Detection](https://arxiv.org/abs/2510.19890)
*Jan Zelinka,Oliver Kost,Marek Hrúz*

Main category: cs.CR

TL;DR: 提出了一个模拟欺骗攻击的数据生成框架，使用LSTM和Transformer架构进行在线欺骗检测，Transformer模型在早期融合输入时达到0.16%的错误率。


<details>
  <summary>Details</summary>
Motivation: 需要开发有效的欺骗攻击检测方法来保护系统安全，通过模拟真实攻击场景来训练检测模型。

Method: 使用数据生成框架模拟全球范围内的欺骗攻击，应用基于LSTM和Transformer架构的深度神经网络进行在线欺骗检测，采用早期融合输入策略。

Result: 深度学习模型能准确区分欺骗信号和真实信号，Transformer架构在早期融合输入时表现最佳，错误率仅为0.16%。

Conclusion: 基于Transformer的深度学习模型在欺骗检测方面表现出色，早期融合输入策略能显著提升检测性能。

Abstract: We present a data generation framework designed to simulate spoofing attacks
and randomly place attack scenarios worldwide. We apply deep neural
network-based models for spoofing detection, utilizing Long Short-Term Memory
networks and Transformer-inspired architectures. These models are specifically
designed for online detection and are trained using the generated dataset. Our
results demonstrate that deep learning models can accurately distinguish
spoofed signals from genuine ones, achieving high detection performance. The
best results are achieved by Transformer-inspired architectures with early
fusion of the inputs resulting in an error rate of 0.16%.

</details>


### [9] [Designing a Secure and Resilient Distributed Smartphone Participant Data Collection System](https://arxiv.org/abs/2510.19938)
*Foad Namjoo,Neng Wan,Devan Mallory,Yuyi Chang,Nithin Sugavanam,Long Yin Lee,Ning Xiong,Emre Ertin,Jeff M. Phillips*

Main category: cs.CR

TL;DR: MotionPI是一个基于智能手机的系统，用于通过传感器和调查收集行为和健康数据，具有被动数据收集和生态瞬时评估调查功能，能在现实生活约束下工作。


<details>
  <summary>Details</summary>
Motivation: 现实世界的健康研究需要从移动和可穿戴设备持续安全地收集数据，但面临电池寿命有限、网络连接不稳定和用户监督最小化等挑战。

Method: 系统集成被动数据收集（GPS和腕带运动数据）与生态瞬时评估调查，可通过蓝牙低功耗与腕带设备集成，支持本地和云端安全存储。

Result: MotionPI展示了一个实用解决方案，能够在网络连接有限、电池寿命受限的现实条件下，安全、可扩展地收集移动数据。

Conclusion: MotionPI为网络物理健康研究提供了一个安全且可扩展的移动数据收集解决方案，能够适应现实生活约束条件。

Abstract: Real-world health studies require continuous and secure data collection from
mobile and wearable devices. We introduce MotionPI, a smartphone-based system
designed to collect behavioral and health data through sensors and surveys with
minimal interaction from participants. The system integrates passive data
collection (such as GPS and wristband motion data) with Ecological Momentary
Assessment (EMA) surveys, which can be triggered randomly or based on physical
activity. MotionPI is designed to work under real-life constraints, including
limited battery life, weak or intermittent cellular connection, and minimal
user supervision. It stores data both locally and on a secure cloud server,
with encrypted transmission and storage. It integrates through Bluetooth Low
Energy (BLE) into wristband devices that store raw data and communicate motion
summaries and trigger events. MotionPI demonstrates a practical solution for
secure and scalable mobile data collection in cyber-physical health studies.

</details>


### [10] [Q-RAN: Quantum-Resilient O-RAN Architecture](https://arxiv.org/abs/2510.19968)
*Vipin Rathi,Lakshya Chopra,Madhav Agarwal,Nitin Rajput,Kriish Sharma,Sushant Mundepi,Shivam Gangwar,Rudraksh Rawal,Jishan*

Main category: cs.CR

TL;DR: 提出了Q-RAN量子安全框架，使用NIST标准化的后量子密码学保护O-RAN网络免受量子计算威胁


<details>
  <summary>Details</summary>
Motivation: 电信行业面临O-RAN架构转型和量子计算威胁的双重挑战，HNDL攻击策略使威胁迫在眉睫

Method: 实施ML-KEM和ML-DSA等NIST标准化PQC算法，结合QRNG，部署PQ-IPsec、PQ-DTLS、PQ-mTLS协议，建立集中式PQ-CA

Result: 为分解式O-RAN生态系统提供了完整的量子安全保护路线图

Conclusion: Q-RAN框架能够全面保护O-RAN网络免受量子对手攻击

Abstract: The telecommunications industry faces a dual transformation: the
architectural shift toward Open Radio Access Networks (O-RAN) and the emerging
threat from quantum computing. O-RAN disaggregated, multi-vendor architecture
creates a larger attack surface vulnerable to crypt-analytically relevant
quantum computers(CRQCs) that will break current public key cryptography. The
Harvest Now, Decrypt Later (HNDL) attack strategy makes this threat immediate,
as adversaries can intercept encrypted data today for future decryption. This
paper presents Q-RAN, a comprehensive quantum-resistant security framework for
O-RAN networks using NIST-standardized Post-Quantum Cryptography (PQC). We
detail the implementation of ML-KEM (FIPS 203) and ML-DSA (FIPS 204),
integrated with Quantum Random Number Generators (QRNG) for cryptographic
entropy. The solution deploys PQ-IPsec, PQ-DTLS, and PQ-mTLS protocols across
all O-RAN interfaces, anchored by a centralized Post-Quantum Certificate
Authority (PQ-CA) within the SMO framework. This work provides a complete
roadmap for securing disaggregated O-RAN ecosystems against quantum
adversaries.

</details>


### [11] [SecureInfer: Heterogeneous TEE-GPU Architecture for Privacy-Critical Tensors for Large Language Model Deployment](https://arxiv.org/abs/2510.19979)
*Tushar Nayan,Ziqi Zhang,Ruimin Sun*

Main category: cs.CR

TL;DR: SecureInfer是一个混合框架，利用异构TEE-GPU架构保护LLMs免受模型提取攻击，在SGX enclave中执行安全敏感组件，在GPU上执行加密的线性操作。


<details>
  <summary>Details</summary>
Motivation: 随着LLMs在移动和边缘平台的部署增加，保护模型隐私同时保持高性能成为关键挑战，需要在不可信AI加速器上实现安全推理。

Method: 采用信息论和威胁感知的分区策略：安全敏感组件在SGX enclave中执行，线性操作在GPU上加密执行并在enclave中安全恢复。

Result: 基于LLaMA-2模型的实现显示，SecureInfer提供强大的安全保证和合理的性能，是安全的设备端模型推理的实用解决方案。

Conclusion: SecureInfer框架成功解决了在不可信加速器上保护LLMs隐私的性能与安全权衡问题，为安全设备端推理提供了可行方案。

Abstract: With the increasing deployment of Large Language Models (LLMs) on mobile and
edge platforms, securing them against model extraction attacks has become a
pressing concern. However, protecting model privacy without sacrificing the
performance benefits of untrusted AI accelerators, such as GPUs, presents a
challenging trade-off. In this paper, we initiate the study of high-performance
execution on LLMs and present SecureInfer, a hybrid framework that leverages a
heterogeneous Trusted Execution Environments (TEEs)-GPU architecture to isolate
privacy-critical components while offloading compute-intensive operations to
untrusted accelerators. Building upon an outsourcing scheme, SecureInfer adopts
an information-theoretic and threat-informed partitioning strategy:
security-sensitive components, including non-linear layers, projection of
attention head, FNN transformations, and LoRA adapters, are executed inside an
SGX enclave, while other linear operations (matrix multiplication) are
performed on the GPU after encryption and are securely restored within the
enclave. We implement a prototype of SecureInfer using the LLaMA-2 model and
evaluate it across performance and security metrics. Our results show that
SecureInfer offers strong security guarantees with reasonable performance,
offering a practical solution for secure on-device model inference.

</details>


### [12] [QORE : Quantum Secure 5G/B5G Core](https://arxiv.org/abs/2510.19982)
*Vipin Rathi,Lakshya Chopra,Rudraksh Rawal,Nitin Rajput,Shiva Valia,Madhav Aggarwal,Aditya Gairola*

Main category: cs.CR

TL;DR: QORE是一个量子安全的5G核心框架，使用NIST标准化的ML-KEM和ML-DSA算法，为5G网络向抗量子密码迁移提供清晰路径，包括混合PQC配置以保持互操作性。


<details>
  <summary>Details</summary>
Motivation: 当前5G系统使用的RSA、ECC、DH等密码学基础都易受Shor算法攻击，保护5G网络免受未来量子攻击已成为紧迫的工程和研究重点。

Method: 使用NIST标准化的基于格的算法ML-KEM和ML-DSA，应用于5G服务架构，并提出了结合经典和量子安全原语的混合PQC配置。

Result: 实验验证显示ML-KEM在实现量子安全的同时仅有轻微性能开销，满足运营商级5G系统的低延迟和高吞吐量要求。

Conclusion: 该路线图与3GPP和NIST标准化工作保持一致，为缓解量子时代风险、保护网络数据长期机密性和完整性提供实用指导。

Abstract: Quantum computing is reshaping the security landscape of modern
telecommunications. The cryptographic foundations that secure todays 5G
systems, including RSA, Elliptic Curve Cryptography (ECC), and Diffie-Hellman
(DH), are all susceptible to attacks enabled by Shors algorithm. Protecting 5G
networks against future quantum adversaries has therefore become an urgent
engineering and research priority. In this paper we introduce QORE, a
quantum-secure 5G and Beyond 5G (B5G) Core framework that provides a clear
pathway for transitioning both the 5G Core Network Functions and User Equipment
(UE) to Post-Quantum Cryptography (PQC). The framework uses the
NIST-standardized lattice-based algorithms Module-Lattice Key Encapsulation
Mechanism (ML-KEM) and Module-Lattice Digital Signature Algorithm (ML-DSA) and
applies them across the 5G Service-Based Architecture (SBA). A Hybrid PQC
(HPQC) configuration is also proposed, combining classical and quantum-safe
primitives to maintain interoperability during migration. Experimental
validation shows that ML-KEM achieves quantum security with minor performance
overhead, meeting the low-latency and high-throughput requirements of
carrier-grade 5G systems. The proposed roadmap aligns with ongoing 3GPP SA3 and
SA5 study activities on the security and management of post-quantum networks as
well as with NIST PQC standardization efforts, providing practical guidance for
mitigating quantum-era risks while safeguarding long-term confidentiality and
integrity of network data.

</details>


### [13] [zk-Agreements: A Privacy-Preserving Way to Establish Deterministic Trust in Confidential Agreements](https://arxiv.org/abs/2510.20007)
*To-Wen Liu,Matthew Green*

Main category: cs.CR

TL;DR: 提出了zk-agreements协议，结合零知识证明、安全多方计算和智能合约，在保护隐私的同时实现可计算法律合同的可执行性


<details>
  <summary>Details</summary>
Motivation: 传统纸质合同阻碍数字化交易的自动化、可执行性和争议解决，现有区块链智能合约存在隐私泄露风险，限制了企业采用

Method: 结合零知识证明保护隐私条款、安全两方计算实现私密合规评估、智能合约保证自动执行

Result: 解决了区块链协议中透明性与保密性之间的根本矛盾，实现了隐私保护与计算可执行性的统一

Conclusion: zk-agreements协议成功实现了从纸质信任向加密信任的转变，同时保持了合同条款的机密性

Abstract: Digital transactions currently exceed trillions of dollars annually, yet
traditional paper-based agreements remain a bottleneck for automation,
enforceability, and dispute resolution. Natural language contracts introduce
ambiguity, require manual processing, and lack computational verifiability, all
of which hinder efficient digital commerce. Computable legal contracts,
expressed in machine-readable formats, offer a potential solution by enabling
automated execution and verification. Blockchain-based smart contracts further
strengthen enforceability and accelerate dispute resolution; however, current
implementations risk exposing sensitive agreement terms on public ledgers,
raising serious privacy and competitive intelligence concerns that limit
enterprise adoption.
  We introduce zk-agreements, a protocol designed to transition from
paper-based trust to cryptographic trust while preserving confidentiality. Our
design combines zero-knowledge proofs to protect private agreement terms,
secure two-party computation to enable private compliance evaluation, and smart
contracts to guarantee automated enforcement. Together, these components
achieve both privacy preservation and computational enforceability, resolving
the fundamental tension between transparency and confidentiality in
blockchain-based agreements.

</details>


### [14] [Ultra-Fast Wireless Power Hacking](https://arxiv.org/abs/2510.20056)
*Hui Wang,Hans D. Schotten,Stefan M. Goetz*

Main category: cs.CR

TL;DR: 提出了一种改进的无线充电系统攻击方法，能在3个高频信号周期内实现能量窃取，无需电路参数或查找表，同步接收器电流与磁传感器电压相位，窃取超过76%的功率。


<details>
  <summary>Details</summary>
Motivation: 电动汽车无线充电技术快速发展，但存在严重网络安全挑战。现有攻击方法需要时间跟踪频率或精确调整电感电容，对快速频率变化或电容漂移效果有限。

Method: 通过同步接收器电流与磁传感器电压相位，改进拦截器使其能在3个高频信号周期内实现入侵和能量窃取，无需电路参数或查找表。使用MATLAB/Simulink仿真、有限元分析和实验验证。

Result: 改进方法能在相同条件下窃取超过76%的完全谐振接收器接收的功率。

Conclusion: 简单的频率变化功率加密对此类威胁提供的保护有限。

Abstract: The rapid growth of electric vehicles (EVs) has driven the development of
roadway wireless charging technology, effectively extending EV driving range.
However, wireless charging introduces significant cybersecurity challenges. Any
receiver within the magnetic field can potentially extract energy, and previous
research demonstrated that a hacker could detect the operating frequency and
steal substantial power. However, our approach required time to track new
frequencies or precise adjustments of inductance and capacitance, which would
be less effective against potential rapid transmitter frequency changes or
capacitance drift. As a solution, we enhanced the interceptor and enabled it to
intrude as well as steal energy within just three cycles of the high-frequency
signal. Moreover, it can work without any circuit parameters or look-up tables.
The key innovation is synchronizing the receiver current with the phase of the
magnetic sensor voltage. Through MATLAB / Simulink simulations, finite-element
analysis, and experimental validation, we demonstrated that our improved method
can steal over 76% of the power received by a fully resonant receiver under
identical conditions. This attack demonstrates that simple frequency-changing
power encryption offers limited protection against such threats.

</details>


### [15] [Who Coordinates U.S. Cyber Defense? A Co-Authorship Network Analysis of Joint Cybersecurity Advisories (2024--2025)](https://arxiv.org/abs/2510.20080)
*M. Abdullah Canbaz,Hakan Otal,Tugce Unlu,Nour Alhussein,Brian Nussbaum*

Main category: cs.CR

TL;DR: 通过分析2024-2025年9份联合网络安全公告构建合作网络，发现美国CISA、FBI和NSA构成紧密合作核心，与五眼联盟及欧洲盟友形成协作结构。


<details>
  <summary>Details</summary>
Motivation: 网络威胁需要多方协作应对，但多机构网络安全合作的组织动态仍不明确，了解领导机构、桥梁机构和协调方式对加强美国国土安全和盟国防务至关重要。

Method: 构建基于9份联合网络安全公告（2024年11月至2025年8月）的共同作者网络，映射41个机构和442个合作关系，分析协作结构。

Result: 发现紧密的美国三机构核心（CISA、FBI、NSA），与五眼联盟和特定欧洲盟友密集连接。度中心性显示CISA和FBI是协调枢纽，中介中心性显示NSA、英国NCSC和澳大利亚ASD-ACSC是关键桥梁。

Conclusion: 通过发布首个可复制的CSA数据集和网络分析，为协作网络安全信号的组织方式和战略影响力集中位置提供了新的实证证据。

Abstract: Cyber threats increasingly demand joint responses, yet the organizational
dynamics behind multi-agency cybersecurity collaboration remain poorly
understood. Understanding who leads, who bridges, and how agencies coordinate
is critical for strengthening both U.S. homeland security and allied defense
efforts. In this study, we construct a co-authorship network from nine Joint
Cybersecurity Advisories (CSAs) issued between November 2024 and August 2025.
We map 41 agencies and 442 co-authoring ties to analyze the structure of
collaboration. We find a tightly knit U.S. triad -- CISA, FBI, and NSA --
densely connected with Five Eyes and select European allies. Degree centrality
identifies CISA and FBI as coordination hubs, while betweenness highlights NSA,
the UK's NCSC, and Australia's ASD-ACSC as key bridges linking otherwise
fragmented clusters. By releasing the first replicable dataset and network
analysis of CSAs, we provide new empirical evidence on how collaborative
cybersecurity signals are organized and where strategic influence is
concentrated.

</details>


### [16] [SAID: Empowering Large Language Models with Self-Activating Internal Defense](https://arxiv.org/abs/2510.20129)
*Yulong Chen,Yadong Liu,Jiawen Zhang,Mu Li,Chao Huang,Jie Wen*

Main category: cs.CR

TL;DR: 提出了一种无需训练的防御方法SAID，通过激活LLM内部安全机制来对抗越狱攻击，在保持良性任务性能的同时显著减少有害输出。


<details>
  <summary>Details</summary>
Motivation: 现有LLM安全对齐方法仍易受越狱攻击，而传统防御策略依赖外部干预，缺乏泛化性且影响模型效用。

Method: 采用三阶段管道：模型原生意图蒸馏提取核心语义、最优安全前缀探测激活潜在安全意识、保守聚合策略确保稳健决策。

Result: 在5个开源LLM和6种先进越狱攻击上的实验表明，SAID在减少有害输出方面显著优于现有防御方法。

Conclusion: 激活LLM内在安全机制是构建更安全可靠AI系统的更稳健和可扩展路径。

Abstract: Large Language Models (LLMs), despite advances in safety alignment, remain
vulnerable to jailbreak attacks designed to circumvent protective mechanisms.
Prevailing defense strategies rely on external interventions, such as input
filtering or output modification, which often lack generalizability and
compromise model utility while incurring significant computational overhead. In
this work, we introduce a new, training-free defense paradigm, Self-Activating
Internal Defense (SAID), which reframes the defense task from external
correction to internal capability activation. SAID uniquely leverages the LLM's
own reasoning abilities to proactively identify and neutralize malicious intent
through a three-stage pipeline: model-native intent distillation to extract
core semantics, optimal safety prefix probing to activate latent safety
awareness, and a conservative aggregation strategy to ensure robust
decision-making. Extensive experiments on five open-source LLMs against six
advanced jailbreak attacks demonstrate that SAID substantially outperforms
state-of-the-art defenses in reducing harmful outputs. Crucially, it achieves
this while preserving model performance on benign tasks and incurring minimal
computational overhead. Our work establishes that activating the intrinsic
safety mechanisms of LLMs is a more robust and scalable path toward building
safer and more reliable aligned AI systems.

</details>


### [17] [Separating Pseudorandom Generators from Logarithmic Pseudorandom States](https://arxiv.org/abs/2510.20131)
*Mohammed Barhoush*

Main category: cs.CR

TL;DR: 本文建立了PRG与PRS之间的量子黑盒分离，证明在量子可评估PRG与对数大小或线性大小PRS之间不存在黑盒构造。


<details>
  <summary>Details</summary>
Motivation: PRG是经典密码学的基础原语，而PRS作为量子环境下的替代假设，对数大小PRS已实现数字签名和量子公钥加密等强大应用。但PRG与对数大小PRS之间的关系尚未明确。

Method: 构建了一个具有逆访问权限的酉量子预言机，证明在该预言机下不存在从PRS到PRG的黑盒构造。

Result: 成功建立了PRG与PRS之间的量子黑盒分离，并作为推论获得了PRG与数字签名、量子公钥加密等原语的分离。

Conclusion: PRG与PRS（无论对数大小还是线性大小）之间存在根本性分离，这为理解量子密码学中原语之间的关系提供了重要洞见。

Abstract: Pseudorandom generators (PRGs) are a foundational primitive in classical
cryptography, underpinning a wide range of constructions. In the quantum
setting, pseudorandom quantum states (PRSs) were proposed as a potentially
weaker assumption that might serve as a substitute for PRGs in cryptographic
applications. Two primary size regimes of PRSs have been studied:
logarithmic-size and linear-size. Interestingly, logarithmic PRSs have led to
powerful cryptographic applications, such as digital signatures and quantum
public-key encryption, that have not been realized from their linear
counterparts. However, PRGs have only been black-box separated from linear
PRSs, leaving open the fundamental question of whether PRGs are also separated
from logarithmic PRSs.
  In this work, we resolve this open problem. We establish a quantum black-box
separation between (quantum-evaluable) PRGs and PRSs of either size regime.
Specifically, we construct a unitary quantum oracle with inverse access
relative to which no black-box construction of PRG from (logarithmic or linear)
PRS exists. As a direct corollary, we obtain separations between PRGs and
several primitives implied by logarithmic PRSs, including digital signatures
and quantum public-key encryption.

</details>


### [18] [Beyond Text: Multimodal Jailbreaking of Vision-Language and Audio Models through Perceptually Simple Transformations](https://arxiv.org/abs/2510.20223)
*Divyanshu Kumar,Shreyas Jena,Nitin Aravind Birur,Tanay Baswa,Sahil Agarwal,Prashanth Harshangi*

Main category: cs.CR

TL;DR: 该论文系统研究了多模态大语言模型在跨模态处理中的安全漏洞，发现即使简单的感知变换也能可靠地绕过最先进的安全过滤器，在多模态对抗攻击下暴露出严重脆弱性。


<details>
  <summary>Details</summary>
Motivation: 多模态大语言模型取得了显著进展，但在跨模态处理中存在关键脆弱性，容易受到对抗攻击的利用，需要系统评估其安全漏洞。

Method: 使用1,900个对抗提示在三个高风险安全类别中测试七个前沿模型，探索了FigStep-Pro（视觉关键词分解）、智能掩码（语义混淆）和音频扰动（Wave-Echo、Wave-Pitch、Wave-Speed）等攻击技术的有效性。

Result: 结果显示严重漏洞：文本安全近乎完美的模型（0% ASR）在感知修改输入下攻击成功率超过75%，FigStep-Pro在Llama-4变体中达到89% ASR。音频攻击进一步揭示了提供商特定弱点，即使是基本的模态转移也能在技术查询中获得25% ASR。

Conclusion: 这些发现暴露了文本中心对齐与多模态威胁之间的关键差距，表明当前安全措施无法泛化到跨模态攻击。这些攻击的可访问性表明，鲁棒的多模态AI安全需要向更广泛的语义级推理进行范式转变。

Abstract: Multimodal large language models (MLLMs) have achieved remarkable progress,
yet remain critically vulnerable to adversarial attacks that exploit weaknesses
in cross-modal processing. We present a systematic study of multimodal
jailbreaks targeting both vision-language and audio-language models, showing
that even simple perceptual transformations can reliably bypass
state-of-the-art safety filters. Our evaluation spans 1,900 adversarial prompts
across three high-risk safety categories harmful content, CBRN (Chemical,
Biological, Radiological, Nuclear), and CSEM (Child Sexual Exploitation
Material) tested against seven frontier models. We explore the effectiveness of
attack techniques on MLLMs, including FigStep-Pro (visual keyword
decomposition), Intelligent Masking (semantic obfuscation), and audio
perturbations (Wave-Echo, Wave-Pitch, Wave-Speed). The results reveal severe
vulnerabilities: models with almost perfect text-only safety (0\% ASR) suffer
>75\% attack success under perceptually modified inputs, with FigStep-Pro
achieving up to 89\% ASR in Llama-4 variants. Audio-based attacks further
uncover provider-specific weaknesses, with even basic modality transfer
yielding 25\% ASR for technical queries. These findings expose a critical gap
between text-centric alignment and multimodal threats, demonstrating that
current safeguards fail to generalize across cross-modal attacks. The
accessibility of these attacks, which require minimal technical expertise,
suggests that robust multimodal AI safety will require a paradigm shift toward
broader semantic-level reasoning to mitigate possible risks.

</details>


### [19] [HHEML: Hybrid Homomorphic Encryption for Privacy-Preserving Machine Learning on Edge](https://arxiv.org/abs/2510.20243)
*Yu Hin Chan,Hao Yang,Shiyu Shen,Xingyu Fan,Shengzhe Lyu,Patrick S. Y. Hung,Ray C. C. Cheung*

Main category: cs.CR

TL;DR: 提出了一种硬件加速的混合同态加密架构，通过优化的对称密码算法和专用硬件加速器，显著降低了客户端加密延迟和服务器端处理开销，实现了高效的隐私保护机器学习推理。


<details>
  <summary>Details</summary>
Motivation: 完全同态加密在隐私保护机器学习中通信和计算开销大，不适合边缘设备。混合同态加密结合对称加密和FHE可以降低客户端计算成本，但需要硬件加速来提高性能。

Method: 设计硬件加速的HHE架构，使用针对FHE优化的轻量级对称密码算法，实现专用硬件加速器，并集成微架构优化以提高性能和能效。

Result: 在PYNQ-Z2平台上使用MNIST数据集测试，客户端加密延迟降低50倍以上，硬件吞吐量比现有FPGA加速器提升近2倍。

Conclusion: 验证了低功耗硬件加速HHE在边缘部署的可行性，为资源受限环境提供了硬件软件协同设计方法，可构建可扩展的安全机器学习系统。

Abstract: Privacy-preserving machine learning (PPML) is an emerging topic to handle
secure machine learning inference over sensitive data in untrusted
environments. Fully homomorphic encryption (FHE) enables computation directly
on encrypted data on the server side, making it a promising approach for PPML.
However, it introduces significant communication and computation overhead on
the client side, making it impractical for edge devices. Hybrid homomorphic
encryption (HHE) addresses this limitation by combining symmetric encryption
(SE) with FHE to reduce the computational cost on the client side, and
combining with an FHE-friendly SE can also lessen the processing overhead on
the server side, making it a more balanced and efficient alternative. Our work
proposes a hardware-accelerated HHE architecture built around a lightweight
symmetric cipher optimized for FHE compatibility and implemented as a dedicated
hardware accelerator. To the best of our knowledge, this is the first design to
integrate an end-to-end HHE framework with hardware acceleration. Beyond this,
we also present several microarchitectural optimizations to achieve higher
performance and energy efficiency. The proposed work is integrated into a full
PPML pipeline, enabling secure inference with significantly lower latency and
power consumption than software implementations. Our contributions validate the
feasibility of low-power, hardware- accelerated HHE for edge deployment and
provide a hardware- software co-design methodology for building scalable,
secure machine learning systems in resource-constrained environments.
Experiments on a PYNQ-Z2 platform with the MNIST dataset show over a 50x
reduction in client-side encryption latency and nearly a 2x gain in hardware
throughput compared to existing FPGA-based HHE accelerators.

</details>


### [20] [Privacy Protection of Automotive Location Data Based on Format-Preserving Encryption of Geographical Coordinates](https://arxiv.org/abs/2510.20300)
*Haojie Ji,Long Jin,Haowen Li,Chongshi Xin,Te Hu*

Main category: cs.CR

TL;DR: 提出基于格式保持加密(FPE)的高精度汽车位置数据隐私保护机制，通过坐标数据键映射减少重复加密解密造成的地理位置精度损失。


<details>
  <summary>Details</summary>
Motivation: 汽车位置数据共享存在隐私泄露风险，可能导致用户行为识别、敏感位置推断和轨迹重建等攻击，需要保护数据安全。

Method: 设计汽车坐标数据键映射机制，采用格式保持加密技术对地理坐标进行加密处理。

Result: 平均相对距离保持率达到0.0844，关键区域热点数量减少98.9%，解密坐标数据恢复精度达到100%。

Conclusion: 该方法为自动驾驶中的敏感数据共享提供了高效的数据安全解决方案。

Abstract: There are increasing risks of privacy disclosure when sharing the automotive
location data in particular functions such as route navigation, driving
monitoring and vehicle scheduling. These risks could lead to the attacks
including user behavior recognition, sensitive location inference and
trajectory reconstruction. In order to mitigate the data security risk caused
by the automotive location sharing, this paper proposes a high-precision
privacy protection mechanism based on format-preserving encryption (FPE) of
geographical coordinates. The automotive coordinate data key mapping mechanism
is designed to reduce to the accuracy loss of the geographical location data
caused by the repeated encryption and decryption. The experimental results
demonstrate that the average relative distance retention rate (RDR) reached
0.0844, and the number of hotspots in the critical area decreased by 98.9%
after encryption. To evaluate the accuracy loss of the proposed encryption
algorithm on automotive geographical location data, this paper presents the
experimental analysis of decryption accuracy, and the result indicates that the
decrypted coordinate data achieves a restoration accuracy of 100%. This work
presents a high-precision privacy protection method for automotive location
data, thereby providing an efficient data security solution for the sensitive
data sharing in autonomous driving.

</details>


### [21] [Enhancing Security in Deep Reinforcement Learning: A Comprehensive Survey on Adversarial Attacks and Defenses](https://arxiv.org/abs/2510.20314)
*Wu Yichao,Wang Yirui,Ding Panpan,Wang Hailong,Zhu Bingqian,Liu Chun*

Main category: cs.CR

TL;DR: 本文综述了深度强化学习在对抗环境中的安全挑战，提出了基于扰动类型和攻击目标的对抗攻击分类框架，并系统总结了各种鲁棒性训练策略和防御技术。


<details>
  <summary>Details</summary>
Motivation: 随着DRL在自动驾驶、智能制造等安全敏感领域的广泛应用，提高其在动态多变环境中的安全性和鲁棒性成为核心研究问题，特别是在面对对抗攻击时防止性能下降和危险决策。

Method: 提出基于扰动类型和攻击目标的对抗攻击分类框架，详细回顾针对DRL的主流对抗攻击方法，包括扰动状态空间、动作空间、奖励函数和模型空间等攻击方式，并系统总结各种鲁棒性训练策略。

Result: 全面分析了DRL面临的安全挑战，建立了系统的对抗攻击分类体系，总结了包括对抗训练、竞争训练、鲁棒学习、对抗检测、防御蒸馏等多种防御技术的优缺点。

Conclusion: 展望了DRL在对抗环境中的未来研究方向，强调在提高泛化能力、降低计算复杂度、增强可扩展性和可解释性等方面的研究需求，为研究者提供有价值的参考和方向。

Abstract: With the wide application of deep reinforcement learning (DRL) techniques in
complex fields such as autonomous driving, intelligent manufacturing, and smart
healthcare, how to improve its security and robustness in dynamic and
changeable environments has become a core issue in current research. Especially
in the face of adversarial attacks, DRL may suffer serious performance
degradation or even make potentially dangerous decisions, so it is crucial to
ensure their stability in security-sensitive scenarios. In this paper, we first
introduce the basic framework of DRL and analyze the main security challenges
faced in complex and changing environments. In addition, this paper proposes an
adversarial attack classification framework based on perturbation type and
attack target and reviews the mainstream adversarial attack methods against DRL
in detail, including various attack methods such as perturbation state space,
action space, reward function and model space. To effectively counter the
attacks, this paper systematically summarizes various current robustness
training strategies, including adversarial training, competitive training,
robust learning, adversarial detection, defense distillation and other related
defense techniques, we also discuss the advantages and shortcomings of these
methods in improving the robustness of DRL. Finally, this paper looks into the
future research direction of DRL in adversarial environments, emphasizing the
research needs in terms of improving generalization, reducing computational
complexity, and enhancing scalability and explainability, aiming to provide
valuable references and directions for researchers.

</details>


### [22] [GhostEI-Bench: Do Mobile Agents Resilience to Environmental Injection in Dynamic On-Device Environments?](https://arxiv.org/abs/2510.20333)
*Chiyu Chen,Xinhao Song,Yunkai Chai,Yang Yao,Haodong Zhao,Lijun Li,Jie Li,Yan Teng,Gongshen Liu,Yingchun Wang*

Main category: cs.CR

TL;DR: 提出了GhostEI-Bench基准测试，用于评估移动代理在动态Android环境中对抗环境注入攻击的脆弱性，发现现有模型容易受到欺骗性UI元素的影响。


<details>
  <summary>Details</summary>
Motivation: 视觉语言模型作为自主代理在移动GUI中操作时，面临环境注入这一新威胁向量，攻击者通过插入对抗性UI元素绕过文本防护，可能导致隐私泄露、财务损失等严重后果。

Method: 开发GhostEI-Bench基准测试，在可执行的Android模拟器中注入对抗性事件到真实应用工作流，并使用judge-LLM协议对代理行为轨迹和截图序列进行细粒度失败分析。

Result: 实验表明当前最先进的代理模型在面对操纵的UI时，在感知和推理方面存在系统性失败，表现出明显的脆弱性。

Conclusion: GhostEI-Bench为量化和缓解这一新兴威胁提供了框架，有助于开发更鲁棒和安全的具身代理。

Abstract: Vision-Language Models (VLMs) are increasingly deployed as autonomous agents
to navigate mobile graphical user interfaces (GUIs). Operating in dynamic
on-device ecosystems, which include notifications, pop-ups, and inter-app
interactions, exposes them to a unique and underexplored threat vector:
environmental injection. Unlike prompt-based attacks that manipulate textual
instructions, environmental injection corrupts an agent's visual perception by
inserting adversarial UI elements (for example, deceptive overlays or spoofed
notifications) directly into the GUI. This bypasses textual safeguards and can
derail execution, causing privacy leakage, financial loss, or irreversible
device compromise. To systematically evaluate this threat, we introduce
GhostEI-Bench, the first benchmark for assessing mobile agents under
environmental injection attacks within dynamic, executable environments. Moving
beyond static image-based assessments, GhostEI-Bench injects adversarial events
into realistic application workflows inside fully operational Android emulators
and evaluates performance across critical risk scenarios. We further propose a
judge-LLM protocol that conducts fine-grained failure analysis by reviewing the
agent's action trajectory alongside the corresponding screenshot sequence,
pinpointing failure in perception, recognition, or reasoning. Comprehensive
experiments on state-of-the-art agents reveal pronounced vulnerability to
deceptive environmental cues: current models systematically fail to perceive
and reason about manipulated UIs. GhostEI-Bench provides a framework for
quantifying and mitigating this emerging threat, paving the way toward more
robust and secure embodied agents.

</details>


### [23] [NeuPerm: Disrupting Malware Hidden in Neural Network Parameters by Leveraging Permutation Symmetry](https://arxiv.org/abs/2510.20367)
*Daniel Gilkarov,Ran Dubin*

Main category: cs.CR

TL;DR: NeuPerm是一种利用神经网络置换对称性来破坏隐藏在模型参数中的恶意软件的方法，对模型性能影响极小，能有效防御最先进的攻击。


<details>
  <summary>Details</summary>
Motivation: 预训练模型共享存在安全风险，攻击者可能在神经网络参数中隐藏自执行恶意软件，通过模型分发让用户无意中执行恶意代码。

Method: 利用神经网络的置换对称性理论特性，通过参数置换来破坏隐藏的恶意软件，这种方法简单有效且不影响模型性能。

Result: NeuPerm成功破坏了最先进的攻击，这些攻击之前只能通过复杂的量化过程来解决。该方法在LLMs上也能工作，这是其他类似工作未能实现的。

Conclusion: NeuPerm提供了一种简单有效的防御机制，能够在不影响模型性能的情况下保护预训练模型免受恶意软件植入攻击。

Abstract: Pretrained deep learning model sharing holds tremendous value for researchers
and enterprises alike. It allows them to apply deep learning by fine-tuning
models at a fraction of the cost of training a brand-new model. However, model
sharing exposes end-users to cyber threats that leverage the models for
malicious purposes. Attackers can use model sharing by hiding self-executing
malware inside neural network parameters and then distributing them for
unsuspecting users to unknowingly directly execute them, or indirectly as a
dependency in another software. In this work, we propose NeuPerm, a simple yet
effec- tive way of disrupting such malware by leveraging the theoretical
property of neural network permutation symmetry. Our method has little to no
effect on model performance at all, and we empirically show it successfully
disrupts state-of-the-art attacks that were only previously addressed using
quantization, a highly complex process. NeuPerm is shown to work on LLMs, a
feat that no other previous similar works have achieved. The source code is
available at https://github.com/danigil/NeuPerm.git.

</details>


### [24] [MAC Aggregation over Lossy Channels in DTLS 1.3](https://arxiv.org/abs/2510.20419)
*Eric Wagner,David Heye,Jan Bauer,Klaus Wehrle,Martin Serror*

Main category: cs.CR

TL;DR: 该论文通过在实际部署中验证MAC聚合技术，发现即使在有损信道中，MAC聚合仍能提高50%的有效吞吐量并节省17%的能耗。


<details>
  <summary>Details</summary>
Motivation: 研究MAC聚合在无线有损环境中的实际性能，验证之前基于模拟的假设是否成立，以解决资源受限环境中的带宽和能耗问题。

Method: 设计DTLS 1.3协议的MAC聚合扩展，并在嵌入式硬件上对完整通信协议栈进行广泛性能评估。

Result: MAC聚合在有损信道中仍能显著提升性能：有效吞吐量提高50%，短消息传输能耗节省17%。

Conclusion: MAC聚合技术在实际无线部署中确实有效，能够显著改善资源受限环境的通信效率。

Abstract: Aggregating Message Authentication Codes (MACs) promises to save valuable
bandwidth in resource-constrained environments. The idea is simple: Instead of
appending an authentication tag to each message in a communication stream, the
integrity protection of multiple messages is aggregated into a single tag.
Recent studies postulate, e.g., based on simulations, that these benefits also
spread to wireless, and thus lossy, scenarios despite each lost packet
typically resulting in the loss of integrity protection information for
multiple messages. In this paper, we investigate these claims in a real
deployment. Therefore, we first design a MAC aggregation extension for the
Datagram Transport Layer Security (DTLS) 1.3 protocol. Afterward, we
extensively evaluate the performance of MAC aggregation on a complete
communication protocol stack on embedded hardware. We find that MAC aggregation
can indeed increase goodput by up to 50% and save up to 17% of energy
expenditure for the transmission of short messages, even in lossy channels.

</details>


### [25] [On the cybersecurity of LoRaWAN-based system: a Smart-Lighting case study](https://arxiv.org/abs/2510.20494)
*Florian Hofer,Barbara Russo*

Main category: cs.CR

TL;DR: 实验研究LoRaWAN智能照明系统的架构配置，评估其网络安全鲁棒性，发现大多数攻击失败，但近距离高功率干扰攻击有效，可通过网关冗余缓解。


<details>
  <summary>Details</summary>
Motivation: 工业4.0中的信息物理系统和物联网面临网络安全挑战，需要验证和改进LoRaWAN智能照明系统的攻击抵抗力。

Method: 通过体外和现场迭代实验，测试不同架构配置下LoRaWAN网络的鲁棒性。

Result: 大多数LoRaWAN网络攻击不成功，但近距离高功率干扰攻击有效，且发现已安装产品存在未解决问题。

Conclusion: LoRaWAN网络对大多数攻击具有抵抗力，但需要网关冗余来缓解高功率干扰攻击，产品实现仍需改进。

Abstract: Cyber-physical systems and the Internet of Things (IoT) are key technologies
in the Industry 4.0 vision. They incorporate sensors and actuators to interact
with the physical environment. However, when creating and interconnecting
components to form a heterogeneous smart systems architecture, these face
challenges in cybersecurity. This paper presents an experimental investigation
of architectural configurations for a LoRaWAN-based Smart-Lighting project,
aimed at verifying and improving the system's robustness against attacks. We
assess the system's robustness in a series of iterative experiments conducted
both in-vitro and on-site. The results show that most attacks on a LoRaWAN
network are unsuccessful, also highlighting unresolved issues with the
installed products. The most successful attacks are high-power jamming attacks
within a few meters of the target, which, in the case of gateways, can be
mitigated through gateway redundancy.

</details>


### [26] [AdaDoS: Adaptive DoS Attack via Deep Adversarial Reinforcement Learning in SDN](https://arxiv.org/abs/2510.20566)
*Wei Shao,Yuhao Wang,Rongguang He,Muhammad Ejaz Ahmed,Seyit Camtepe*

Main category: cs.CR

TL;DR: AdaDoS是一种基于对抗强化学习的自适应DoS攻击模型，能够动态调整攻击策略以规避现有检测机制，是首个将RL应用于生成DoS攻击序列的研究。


<details>
  <summary>Details</summary>
Motivation: 现有防御机制对基于规则的DoS攻击有效，但AI驱动技术对SDN安全构成新挑战。需要开发能够规避检测的自适应攻击模型来测试防御系统的鲁棒性。

Method: 将问题建模为攻击者与检测器之间的竞争博弈，使用对抗强化学习动态调整攻击策略。将DoS攻击建模为部分可观测马尔可夫决策过程，采用师生互学习模块解决信息不对称问题。

Result: AdaDoS能够生成自适应DoS攻击序列，成功规避基于机器学习和基于规则的DoS攻击检测器。

Conclusion: AdaDoS展示了RL在开发规避检测的自适应网络攻击方面的潜力，强调了需要更强大的防御机制来应对AI驱动的威胁。

Abstract: Existing defence mechanisms have demonstrated significant effectiveness in
mitigating rule-based Denial-of-Service (DoS) attacks, leveraging predefined
signatures and static heuristics to identify and block malicious traffic.
However, the emergence of AI-driven techniques presents new challenges to SDN
security, potentially compromising the efficacy of existing defence mechanisms.
In this paper, we introduce~AdaDoS, an adaptive attack model that disrupt
network operations while evading detection by existing DoS-based detectors
through adversarial reinforcement learning (RL). Specifically, AdaDoS models
the problem as a competitive game between an attacker, whose goal is to
obstruct network traffic without being detected, and a detector, which aims to
identify malicious traffic. AdaDoS can solve this game by dynamically adjusting
its attack strategy based on feedback from the SDN and the detector.
Additionally, recognising that attackers typically have less information than
defenders, AdaDoS formulates the DoS-like attack as a partially observed Markov
decision process (POMDP), with the attacker having access only to delay
information between attacker and victim nodes. We address this challenge with a
novel reciprocal learning module, where the student agent, with limited
observations, enhances its performance by learning from the teacher agent, who
has full observational capabilities in the SDN environment. AdaDoS represents
the first application of RL to develop DoS-like attack sequences, capable of
adaptively evading both machine learning-based and rule-based DoS-like attack
detectors.

</details>


### [27] [Decentralized Exchange that Mitigate a Bribery Attack](https://arxiv.org/abs/2510.20645)
*Nitin Awathare*

Main category: cs.CR

TL;DR: 本文分析了现有HTLC协议的安全漏洞，提出了一种新的矿工合谋贿赂攻击，并设计了一个抗所有贿赂场景的安全HTLC协议\prot。


<details>
  <summary>Details</summary>
Motivation: 尽管HTLC在支付通道、原子交换等领域广泛应用，但其在交易所中的使用仍存在问题，主要原因是激励不兼容性和易受贿赂攻击。现有解决方案如MAD-HTLC和He-HTLC只考虑了部分贿赂场景。

Method: 首先通过实施和博弈论分析暴露现有解决方案的漏洞，提出矿工合谋贿赂攻击。然后设计\prot协议，采用两阶段方法：第一阶段各方承诺转账，第二阶段执行转账而不被操纵。

Result: 成功展示了现有HTLC协议的安全漏洞，提出了比He-HTLC更强的MAD-HTLC攻击，攻击者可获得与攻击原生HTLC相当的利润。\prot协议在比特币和以太坊上的实现证明了其在交易成本和延迟方面的效率。

Conclusion: \prot协议是第一个博弈论安全的HTLC协议，能够抵抗所有贿赂场景，为HTLC在安全关键应用中的使用提供了可靠解决方案。

Abstract: Despite the popularity of Hashed Time-Locked Contracts (HTLCs) because of
their use in wide areas of applications such as payment channels, atomic swaps,
etc, their use in exchange is still questionable. This is because of its
incentive incompatibility and susceptibility to bribery attacks.
  State-of-the-art solutions such as MAD-HTLC (Oakland'21) and He-HTLC
(NDSS'23) address this by leveraging miners' profit-driven behaviour to
mitigate such attacks. The former is the mitigation against passive miners;
however, the latter works against both active and passive miners. However, they
consider only two bribing scenarios where either of the parties involved in the
transfer collude with the miner.
  In this paper, we expose vulnerabilities in state-of-the-art solutions by
presenting a miner-collusion bribery attack with implementation and
game-theoretic analysis. Additionally, we propose a stronger attack on MAD-HTLC
than He-HTLC, allowing the attacker to earn profits equivalent to attacking
naive HTLC.
  Leveraging our insights, we propose \prot, a game-theoretically secure HTLC
protocol resistant to all bribery scenarios. \prot\ employs a two-phase
approach, preventing unauthorized token confiscation by third parties, such as
miners. In Phase 1, parties commit to the transfer; in Phase 2, the transfer is
executed without manipulation. We demonstrate \prot's efficiency in transaction
cost and latency via implementations on Bitcoin and Ethereum.

</details>


### [28] [Risk Psychology & Cyber-Attack Tactics](https://arxiv.org/abs/2510.20657)
*Rubens Kim,Stephan Carney,Yvonne Fonken,Soham Hans,Sofia Hirschmann,Stacy Marsella,Peggy Wu,Nikolos Gurney*

Main category: cs.CR

TL;DR: 研究表明认知过程比专业经验更能预测网络安全攻击行为模式，支持开发基于心理学的防御策略


<details>
  <summary>Details</summary>
Motivation: 探讨认知过程是否能够预测网络攻击行为，了解个体认知差异如何影响攻击技术选择

Method: 使用多级混合效应泊松回归分析，将网络安全专业人员在红队操作中的攻击技术使用嵌套在参与者内进行分析

Result: 认知过程量表显著预测了技术使用，但效果因技术而异；专业水平和实验条件对技术模式没有显著预测作用

Conclusion: 个体认知差异是网络攻击行为的重要驱动因素，认知过程比培训或经验更能影响技术选择

Abstract: We examine whether measured cognitive processes predict cyber-attack
behavior. We analyzed data that included psychometric scale responses and
labeled attack behaviors from cybersecurity professionals who conducted
red-team operations against a simulated enterprise network. We employed
multilevel mixed-effects Poisson regression with technique counts nested within
participants to test whether cognitive processes predicted technique-specific
usage. The scales significantly predicted technique use, but effects varied by
technique rather than operating uniformly. Neither expertise level nor
experimental treatment condition significantly predicted technique patterns,
indicating that cognitive processes may be stronger drivers of technique
selection than training or experience. These findings demonstrate that
individual cognitive differences shape cyber-attack behavior and support the
development of psychology-informed defense strategies.

</details>


### [29] [Learning to Triage Taint Flows Reported by Dynamic Program Analysis in Node.js Packages](https://arxiv.org/abs/2510.20739)
*Ronghao Ni,Aidan Z. H. Yang,Min-Chien Hsu,Nuno Sabino,Limin Jia,Ruben Martins,Darion Cassel,Kevin Cheang*

Main category: cs.CR

TL;DR: 该论文研究如何利用机器学习对程序分析工具报告的漏洞进行优先级排序，通过评估多种机器学习方法在Node.js包漏洞检测中的表现，发现最佳模型能显著减少手动审查工作量。


<details>
  <summary>Details</summary>
Motivation: 程序分析工具产生大量候选漏洞报告需要人工审查，成本高昂，需要找到有效方法来优先处理最可能是真实漏洞的报告。

Method: 收集1,883个Node.js包作为基准数据集，每个包含一个ACE或ACI漏洞报告。评估经典机器学习模型、图神经网络(GNN)、大语言模型(LLM)以及GNN与LLM混合模型，基于动态程序分析工具输出数据进行训练。

Result: 最佳LLM模型F1分数达0.915，最佳GNN和经典ML模型F1分数为0.904。在假阴性率低于7%时，领先模型能消除66.9%的良性包免于手动审查，每个包处理时间约60毫秒。当精度设为0.8时，能检测99.2%的可利用污点流，仅遗漏0.8%。

Conclusion: 机器学习方法在漏洞优先级排序方面表现出强大潜力，能显著提高安全分析师的工作效率，具有实际应用价值。

Abstract: Program analysis tools often produce large volumes of candidate vulnerability
reports that require costly manual review, creating a practical challenge: how
can security analysts prioritize the reports most likely to be true
vulnerabilities?
  This paper investigates whether machine learning can be applied to
prioritizing vulnerabilities reported by program analysis tools. We focus on
Node.js packages and collect a benchmark of 1,883 Node.js packages, each
containing one reported ACE or ACI vulnerability. We evaluate a variety of
machine learning approaches, including classical models, graph neural networks
(GNNs), large language models (LLMs), and hybrid models that combine GNN and
LLMs, trained on data based on a dynamic program analysis tool's output. The
top LLM achieves $F_{1} {=} 0.915$, while the best GNN and classical ML models
reaching $F_{1} {=} 0.904$. At a less than 7% false-negative rate, the leading
model eliminates 66.9% of benign packages from manual review, taking around 60
ms per package. If the best model is tuned to operate at a precision level of
0.8 (i.e., allowing 20% false positives amongst all warnings), our approach can
detect 99.2% of exploitable taint flows while missing only 0.8%, demonstrating
strong potential for real-world vulnerability triage.

</details>


### [30] [RAGRank: Using PageRank to Counter Poisoning in CTI LLM Pipelines](https://arxiv.org/abs/2510.20768)
*Austin Jia,Avaneesh Ramesh,Zain Shamsi,Daniel Zhang,Alex Liu*

Main category: cs.CR

TL;DR: 本文提出使用PageRank等源可信度算法来增强RAG系统在网络安全威胁情报中的防御能力，通过降低恶意文档的权威性评分来提升系统安全性。


<details>
  <summary>Details</summary>
Motivation: 现有的RAG防御机制在网络安全威胁情报场景中存在不足，因为新型网络攻击信息往往是全新的，且高级威胁行为者能够模仿合法格式和术语。

Method: 在语料库上应用源可信度算法（以PageRank为例），通过计算文档权威性评分来区分可信和恶意内容。

Result: 实验证明该算法能有效降低恶意文档的权威性评分，同时在标准化MS MARCO数据集和CTI文档上展示了概念验证性能。

Conclusion: 源可信度算法能够显著提升RAG系统在网络安全威胁情报场景中的鲁棒性，有效防御投毒攻击。

Abstract: Retrieval-Augmented Generation (RAG) has emerged as the dominant
architectural pattern to operationalize Large Language Model (LLM) usage in
Cyber Threat Intelligence (CTI) systems. However, this design is susceptible to
poisoning attacks, and previously proposed defenses can fail for CTI contexts
as cyber threat information is often completely new for emerging attacks, and
sophisticated threat actors can mimic legitimate formats, terminology, and
stylistic conventions. To address this issue, we propose that the robustness of
modern RAG defenses can be accelerated by applying source credibility
algorithms on corpora, using PageRank as an example. In our experiments, we
demonstrate quantitatively that our algorithm applies a lower authority score
to malicious documents while promoting trusted content, using the standardized
MS MARCO dataset. We also demonstrate proof-of-concept performance of our
algorithm on CTI documents and feeds.

</details>
