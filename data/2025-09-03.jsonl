{"id": "2509.00005", "categories": ["cs.CR", "cs.AI", "stat.AP"], "pdf": "https://arxiv.org/pdf/2509.00005", "abs": "https://arxiv.org/abs/2509.00005", "authors": ["Rohit Dube"], "title": "Per-sender neural network classifiers for email authorship validation", "comment": "11 pages, 5 figures, 8 tables", "summary": "Business email compromise and lateral spear phishing attacks are among modern\norganizations' most costly and damaging threats. While inbound phishing\ndefenses have improved significantly, most organizations still trust internal\nemails by default, leaving themselves vulnerable to attacks from compromised\nemployee accounts. In this work, we define and explore the problem of\nauthorship validation: verifying whether a claimed sender actually authored a\ngiven email. Authorship validation is a lightweight, real-time defense that\ncomplements traditional detection methods by modeling per-sender writing style.\nFurther, the paper presents a collection of new datasets based on the Enron\ncorpus. These simulate inauthentic messages using both human-written and large\nlanguage model-generated emails. The paper also evaluates two classifiers -- a\nNaive Bayes model and a character-level convolutional neural network (Char-CNN)\n-- for the authorship validation task. Our experiments show that the Char-CNN\nmodel achieves high accuracy and F1 scores under various circumstances.\nFinally, we discuss deployment considerations and show that per-sender\nauthorship classifiers are practical for integrating into existing commercial\nemail security systems with low overhead."}
{"id": "2509.00006", "categories": ["cs.CR", "cs.CY"], "pdf": "https://arxiv.org/pdf/2509.00006", "abs": "https://arxiv.org/abs/2509.00006", "authors": ["Motunrayo Adebayo"], "title": "Case Studies: Effective Approaches for Navigating Cross-Border Cloud Data Transfers Amid U.S. Government Privacy and Safety Concerns", "comment": "Privacy, Security", "summary": "This study attempts to explain the impact of information exchange from one\ncountry to another, as well as the legal and technological implications for\nthese exchanges. Due to the emergence of cloud technology, possibilities for\nfree exchange of information between countries have increased rapidly, as it\nhas become possible to save information in a country and access it in almost\nany part of the world. Countries all around the world have been confronted with\ndeveloping frameworks to facilitate this process, although there are\nsignificant challenges which must be confronted on legal and technological\nfronts, as loopholes in the framework adopted by countries may hinder free\naccess to information stored on cloud, and also compromise data privacy. Cloud\ntechnology is impacting a lot of issues, including domestic and international\nbusinesses, hence the need for a study to propose measures for safe exchange of\ninformation using cloud technology."}
{"id": "2509.00043", "categories": ["cs.CR"], "pdf": "https://arxiv.org/pdf/2509.00043", "abs": "https://arxiv.org/abs/2509.00043", "authors": ["Md Faizul Bari", "Yi Xie", "Meghna Roy Choudhury", "Shreyas Sen"], "title": "Keystroke Detection by Exploiting Unintended RF Emission from Repaired USB Keyboards", "comment": "This journal version is an extended version of a previously published\n  conference paper which can be found here:\n  https://ieeexplore.ieee.org/abstract/document/10181751", "summary": "Electronic devices and cables inadvertently emit RF emissions as a byproduct\nof signal processing and/or transmission. Labeled as electromagnetic\nemanations, they form an EM side-channel for data leakage. Previously, it was\nbelieved that such leakage could be contained within a facility since they are\nweak signals with a short transmission range. However, in the preliminary\nversion of this work [1], we found that the traditional cable repairing process\nforms a tiny monopole antenna that helps emanations transmit over a long range.\nExperimentation with three types of cables revealed that emanations from\nrepaired cables remain detectable even at >4 m and can penetrate a 14 cm thick\nconcrete wall. In this extended version, we show that such emanation can be\nexploited at a long distance for information extraction by detecting keystrokes\ntyped on a repaired USB keyboard. By collecting data for 70 different\nkeystrokes at different distances from the target in 3 diverse environments\n(open space, a corridor outside an office room, and outside a building) and\ndeveloping an efficient detection algorithm, ~100% keystroke detection accuracy\nhas been achieved up to 12 m distance, which is the highest reported accuracy\nat such a long range for USB keyboards in the literature. The effect of two\nexperimental factors, interference and human-body coupling, has been\ninvestigated thoroughly. Along with exploring the vulnerability, multi-layer\nexternal metal shielding during the repairing process as a possible remedy has\nbeen explored. This work exposes a new attack surface caused by hardware\nmodification, its exploitation, and potential countermeasures."}
{"id": "2509.00059", "categories": ["cs.CR"], "pdf": "https://arxiv.org/pdf/2509.00059", "abs": "https://arxiv.org/abs/2509.00059", "authors": ["Andres Alejandre", "Kassandra Delfin", "Victor Castano"], "title": "Cryptographic Challenges: Masking Sensitive Data in Cyber Crimes through ASCII Art", "comment": "11 pages, 4 figures", "summary": "The use of ASCII art as a novel approach to masking sensitive information in\ncybercrime, focusing on its potential role in protecting personal data during\nthe delivery process and beyond, is presented. By examining the unique\nproperties of ASCII art and its historical context, this study discusses the\nadvantages and limitations of employing this technique in various cybercrime\nscenarios. Additionally, providing recommendations for enhancing data security\npractices and fostering a culture of privacy awareness in both businesses and\nindividuals. The findings suggest that ASCII art, with its simplicity and\nambiguity, can serve as an effective tool against cybercriminals, emphasizing\nthe need for robust data security measures and increased privacy awareness in\ntoday's interconnected world."}
{"id": "2509.00081", "categories": ["cs.CR", "cs.AI", "I.2.7; I.2.6; I.2.4"], "pdf": "https://arxiv.org/pdf/2509.00081", "abs": "https://arxiv.org/abs/2509.00081", "authors": ["Luca Cotti", "Anisa Rula", "Devis Bianchini", "Federico Cerutti"], "title": "Enabling Transparent Cyber Threat Intelligence Combining Large Language Models and Domain Ontologies", "comment": "14 pages, 3 figures, 6 tables, accepted at XAI-KRKG@ECAI25: First\n  International ECAI Workshop on eXplainable AI, Knowledge Representation and\n  Knowledge Graphs, October 25-30, 2025, Bologna, Italy", "summary": "Effective Cyber Threat Intelligence (CTI) relies upon accurately structured\nand semantically enriched information extracted from cybersecurity system logs.\nHowever, current methodologies often struggle to identify and interpret\nmalicious events reliably and transparently, particularly in cases involving\nunstructured or ambiguous log entries. In this work, we propose a novel\nmethodology that combines ontology-driven structured outputs with Large\nLanguage Models (LLMs), to build an Artificial Intelligence (AI) agent that\nimproves the accuracy and explainability of information extraction from\ncybersecurity logs. Central to our approach is the integration of domain\nontologies and SHACL-based constraints to guide the language model's output\nstructure and enforce semantic validity over the resulting graph. Extracted\ninformation is organized into an ontology-enriched graph database, enabling\nfuture semantic analysis and querying. The design of our methodology is\nmotivated by the analytical requirements associated with honeypot log data,\nwhich typically comprises predominantly malicious activity. While our case\nstudy illustrates the relevance of this scenario, the experimental evaluation\nis conducted using publicly available datasets. Results demonstrate that our\nmethod achieves higher accuracy in information extraction compared to\ntraditional prompt-only approaches, with a deliberate focus on extraction\nquality rather than processing speed."}
{"id": "2509.00085", "categories": ["cs.CR", "cs.AI", "cs.CY"], "pdf": "https://arxiv.org/pdf/2509.00085", "abs": "https://arxiv.org/abs/2509.00085", "authors": ["Tobin South"], "title": "Private, Verifiable, and Auditable AI Systems", "comment": "PhD thesis", "summary": "The growing societal reliance on artificial intelligence necessitates robust\nframeworks for ensuring its security, accountability, and trustworthiness. This\nthesis addresses the complex interplay between privacy, verifiability, and\nauditability in modern AI, particularly in foundation models. It argues that\ntechnical solutions that integrate these elements are critical for responsible\nAI innovation. Drawing from international policy contributions and technical\nresearch to identify key risks in the AI pipeline, this work introduces novel\ntechnical solutions for critical privacy and verifiability challenges.\nSpecifically, the research introduces techniques for enabling verifiable and\nauditable claims about AI systems using zero-knowledge cryptography; utilizing\nsecure multi-party computation and trusted execution environments for\nauditable, confidential deployment of large language models and information\nretrieval; and implementing enhanced delegation mechanisms, credentialing\nsystems, and access controls to secure interactions with autonomous and\nmulti-agent AI systems. Synthesizing these technical advancements, this\ndissertation presents a cohesive perspective on balancing privacy,\nverifiability, and auditability in foundation model-based AI systems, offering\npractical blueprints for system designers and informing policy discussions on\nAI safety and governance."}
{"id": "2509.00088", "categories": ["cs.CR", "cs.AI", "cs.LG"], "pdf": "https://arxiv.org/pdf/2509.00088", "abs": "https://arxiv.org/abs/2509.00088", "authors": ["Ting-Chun Liu", "Ching-Yu Hsu", "Kuan-Yi Lee", "Chi-An Fu", "Hung-yi Lee"], "title": "AEGIS : Automated Co-Evolutionary Framework for Guarding Prompt Injections Schema", "comment": null, "summary": "Prompt injection attacks pose a significant challenge to the safe deployment\nof Large Language Models (LLMs) in real-world applications. While prompt-based\ndetection offers a lightweight and interpretable defense strategy, its\neffectiveness has been hindered by the need for manual prompt engineering. To\naddress this issue, we propose AEGIS , an Automated co-Evolutionary framework\nfor Guarding prompt Injections Schema. Both attack and defense prompts are\niteratively optimized against each other using a gradient-like natural language\nprompt optimization technique. This framework enables both attackers and\ndefenders to autonomously evolve via a Textual Gradient Optimization (TGO)\nmodule, leveraging feedback from an LLM-guided evaluation loop. We evaluate our\nsystem on a real-world assignment grading dataset of prompt injection attacks\nand demonstrate that our method consistently outperforms existing baselines,\nachieving superior robustness in both attack success and detection.\nSpecifically, the attack success rate (ASR) reaches 1.0, representing an\nimprovement of 0.26 over the baseline. For detection, the true positive rate\n(TPR) improves by 0.23 compared to the previous best work, reaching 0.84, and\nthe true negative rate (TNR) remains comparable at 0.89. Ablation studies\nconfirm the importance of co-evolution, gradient buffering, and multi-objective\noptimization. We also confirm that this framework is effective in different\nLLMs. Our results highlight the promise of adversarial training as a scalable\nand effective approach for guarding prompt injections."}
{"id": "2509.00104", "categories": ["cs.CR", "cs.IT", "math.IT", "quant-ph", "94A60, 81P94, 94A17, 68Q12", "E.3; K.6.5; F.1.2; F.2.1"], "pdf": "https://arxiv.org/pdf/2509.00104", "abs": "https://arxiv.org/abs/2509.00104", "authors": ["Ruopengyu Xu", "Chenglian Liu"], "title": "Enhanced Rényi Entropy-Based Post-Quantum Key Agreement with Provable Security and Information-Theoretic Guarantees", "comment": "11 pages, 3 tables", "summary": "This paper presents an enhanced post-quantum key agreement protocol based on\nR\\'{e}nyi entropy, addressing vulnerabilities in the original construction\nwhile preserving information-theoretic security properties. We develop a\ntheoretical framework leveraging entropy-preserving operations and\nsecret-shared verification to achieve provable security against quantum\nadversaries. Through entropy amplification techniques and quantum-resistant\ncommitments, the protocol establishes $2^{128}$ quantum security guarantees\nunder the quantum random oracle model. Key innovations include a\nconfidentiality-preserving verification mechanism using distributed polynomial\ncommitments, tightened min-entropy bounds with guaranteed non-negativity, and\ncomposable security proofs in the quantum universal composability framework.\nUnlike computational approaches, our method provides information-theoretic\nsecurity without hardness assumptions while maintaining polynomial complexity.\nTheoretical analysis demonstrates resilience against known quantum attack\nvectors, including Grover-accelerated brute force and quantum memory attacks.\nThe protocol achieves parameterization for 128-bit quantum security with\nefficient $\\mathcal{O}(n^2)$ communication complexity. Extensions to secure\nmultiparty computation and quantum network applications are established,\nproviding a foundation for long-term cryptographic security. All security\nclaims are derived from mathematical proofs; this theoretical work presents no\nexperimental validation."}
{"id": "2509.00124", "categories": ["cs.CR", "cs.AI", "cs.CY"], "pdf": "https://arxiv.org/pdf/2509.00124", "abs": "https://arxiv.org/abs/2509.00124", "authors": ["Shaked Zychlinski"], "title": "A Whole New World: Creating a Parallel-Poisoned Web Only AI-Agents Can See", "comment": "10 pages, 1 figure", "summary": "This paper introduces a novel attack vector that leverages website cloaking\ntechniques to compromise autonomous web-browsing agents powered by Large\nLanguage Models (LLMs). As these agents become more prevalent, their unique and\noften homogenous digital fingerprints - comprising browser attributes,\nautomation framework signatures, and network characteristics - create a new,\ndistinguishable class of web traffic. The attack exploits this\nfingerprintability. A malicious website can identify an incoming request as\noriginating from an AI agent and dynamically serve a different, \"cloaked\"\nversion of its content. While human users see a benign webpage, the agent is\npresented with a visually identical page embedded with hidden, malicious\ninstructions, such as indirect prompt injections. This mechanism allows\nadversaries to hijack agent behavior, leading to data exfiltration, malware\nexecution, or misinformation propagation, all while remaining completely\ninvisible to human users and conventional security crawlers. This work\nformalizes the threat model, details the mechanics of agent fingerprinting and\ncloaking, and discusses the profound security implications for the future of\nagentic AI, highlighting the urgent need for robust defenses against this\nstealthy and scalable attack."}
{"id": "2509.00266", "categories": ["cs.CR"], "pdf": "https://arxiv.org/pdf/2509.00266", "abs": "https://arxiv.org/abs/2509.00266", "authors": ["Qishen Sam Liang"], "title": "A Systematic Approach to Estimate the Security Posture of a Cyber Infrastructure: A Technical Report", "comment": "11 pages, 5 figures, technical report", "summary": "Academic and research Cyber Infrastructures (CI) present unique security\nchallenges due to their collaborative nature, heterogeneous components, and the\nlack of practical, tailored security assessment frameworks. Existing standards\ncan be too generic or complex for CI administrators to apply effectively. This\nreport introduces a systematic, mission-centric approach to estimate and\nanalyze the security posture of a CI. The framework guides administrators\nthrough a top-down process: (1) defining unacceptable losses and security\nmissions, (2) identifying associated system hazards and critical assets, and\n(3) modeling the CI's components and their relationships as a security\nknowledge graph. The core of this methodology is the construction of directed\nattack graphs, which systematically map all potential paths an adversary could\ntake from an entry point to a critical asset. By visualizing these attack paths\nalongside defense mechanisms, the framework provides a clear, comprehensive\noverview of the system's vulnerabilities and security gaps. This structured\napproach enables CI operators to proactively assess risks, prioritize\nmitigation strategies, and make informed, actionable decisions to strengthen\nthe overall security posture of the CI."}
{"id": "2509.00300", "categories": ["cs.CR"], "pdf": "https://arxiv.org/pdf/2509.00300", "abs": "https://arxiv.org/abs/2509.00300", "authors": ["Ghadeer Almusaddar", "Yicheng Zhang", "Saber Ganjisaffar", "Barry Williams", "Yu David Liu", "Dmitry Ponomare", "Nael Abu-Ghazaleh"], "title": "ShadowScope: GPU Monitoring and Validation via Composable Side Channel Signals", "comment": null, "summary": "As modern systems increasingly rely on GPUs for computationally intensive\ntasks such as machine learning acceleration, ensuring the integrity of GPU\ncomputation has become critically important. Recent studies have shown that GPU\nkernels are vulnerable to both traditional memory safety issues (e.g., buffer\noverflow attacks) and emerging microarchitectural threats (e.g., Rowhammer\nattacks), many of which manifest as anomalous execution behaviors observable\nthrough side-channel signals. However, existing golden model based validation\napproaches that rely on such signals are fragile, highly sensitive to\ninterference, and do not scale well across GPU workloads with diverse\nscheduling behaviors. To address these challenges, we propose ShadowScope, a\nmonitoring and validation framework that leverages a composable golden model.\nInstead of building a single monolithic reference, ShadowScope decomposes\ntrusted kernel execution into modular, repeatable functions that encode key\nbehavioral features. This composable design captures execution patterns at\nfiner granularity, enabling robust validation that is resilient to noise,\nworkload variation, and interference across GPU workloads. To further reduce\nreliance on noisy software-only monitoring, we introduce ShadowScope+, a\nhardware-assisted validation mechanism that integrates lightweight on-chip\nchecks into the GPU pipeline. ShadowScope+ achieves high validation accuracy\nwith an average runtime overhead of just 4.6%, while incurring minimal hardware\nand design complexity. Together, these contributions demonstrate that\nside-channel observability can be systematically repurposed into a practical\ndefense for GPU kernel integrity."}
{"id": "2509.00437", "categories": ["cs.CR"], "pdf": "https://arxiv.org/pdf/2509.00437", "abs": "https://arxiv.org/abs/2509.00437", "authors": ["Hamideh Haghiri", "Rajesh Baidya", "Stefan Dvoretskii", "Klaus H. Maier-Hein", "Marco Nolden"], "title": "A Hybrid AI-based and Rule-based Approach to DICOM De-identification: A Solution for the MIDI-B Challenge", "comment": null, "summary": "Ensuring the de-identification of medical imaging data is a critical step in\nenabling safe data sharing. This paper presents a hybrid de-identification\nframework designed to process Digital Imaging and Communications in Medicine\n(DICOM) files. Our framework adopts a modified, pre-built rule-based component,\nupdated with The Cancer Imaging Archive (TCIA)'s best practices guidelines, as\noutlined in DICOM PS 3.15, for improved performance. It incorporates PaddleOCR,\na robust Optical Character Recognition (OCR) system for extracting text from\nimages, and RoBERTa, a fine-tuned transformer-based model for identifying and\nremoving Personally Identifiable Information (PII) and Protected Health\nInformation (PHI). Initially, the transformer-based model and the rule-based\ncomponent were integrated to process for both structured data and free text.\nHowever, this coarse-grained approach did not yield optimal results. To improve\nperformance, we refined our approach by applying the transformer model\nexclusively to free text, while structured data was handled only by rule-based\nmethods. In this framework the DICOM validator dciodvfy was leveraged to ensure\nthe integrity of DICOM files after the deID process. Through iterative\nrefinement, including the incorporation of custom rules and private tag\nhandling, the framework achieved a de-identification accuracy of 99.91% on the\nMIDI-B test dataset. The results demonstrate the effectiveness of combining\nrule-based compliance with AI-enabled adaptability in addressing the complex\nchallenges of DICOM de-identification."}
{"id": "2509.00476", "categories": ["cs.CR", "cs.AI", "68T10 (Primary) 68T05, 68M25 (Secondary)", "I.2.6; I.5.2; K.6.5"], "pdf": "https://arxiv.org/pdf/2509.00476", "abs": "https://arxiv.org/abs/2509.00476", "authors": ["Omar Khalid Ali Mohamed"], "title": "Cross-Domain Malware Detection via Probability-Level Fusion of Lightweight Gradient Boosting Models", "comment": "5 pages, 3 figures, 3 tables. Conference-style formatting (IEEEtran)", "summary": "The escalating sophistication of malware necessitates robust detection\nmechanisms that generalize across diverse data sources. Traditional\nsingle-dataset models struggle with cross-domain generalization and often incur\nhigh computational costs. This paper presents a novel, lightweight framework\nfor malware detection that employs probability-level fusion across three\ndistinct datasets: EMBER (static features), API Call Sequences (behavioral\nfeatures), and CIC Obfuscated Memory (memory patterns). Our method trains\nindividual LightGBM classifiers on each dataset, selects top predictive\nfeatures to ensure efficiency, and fuses their prediction probabilities using\noptimized weights determined via grid search. Extensive experiments demonstrate\nthat our fusion approach achieves a macro F1-score of 0.823 on a cross-domain\nvalidation set, significantly outperforming individual models and providing\nsuperior generalization. The framework maintains low computational overhead,\nmaking it suitable for real-time deployment, and all code and data are provided\nfor full reproducibility."}
{"id": "2509.00561", "categories": ["cs.CR"], "pdf": "https://arxiv.org/pdf/2509.00561", "abs": "https://arxiv.org/abs/2509.00561", "authors": ["Yuwen Pu", "Zhou Feng", "Chunyi Zhou", "Jiahao Chen", "Chunqiang Hu", "Haibo Hu", "Shouling Ji"], "title": "FreeTalk:A plug-and-play and black-box defense against speech synthesis attacks", "comment": "under review", "summary": "Recently, speech assistant and speech verification have been used in many\nfields, which brings much benefit and convenience for us. However, when we\nenjoy these speech applications, our speech may be collected by attackers for\nspeech synthesis. For example, an attacker generates some inappropriate\npolitical opinions with the characteristic of the victim's voice by obtaining a\npiece of the victim's speech, which will greatly influence the victim's\nreputation. Specifically, with the appearance of some zero-shot voice\nconversion methods, the cost of speech synthesis attacks has been further\nreduced, which also brings greater challenges to user voice security and\nprivacy. Some researchers have proposed the corresponding privacy-preserving\nmethods. However, the existing approaches have some non-negligible drawbacks:\nlow transferability and robustness, high computational overhead. These\ndeficiencies seriously limit the existing method deployed in practical\nscenarios. Therefore, in this paper, we propose a lightweight, robust,\nplug-and-play privacy preservation method against speech synthesis attacks in a\nblack-box setting. Our method generates and adds a frequency-domain\nperturbation to the original speech to achieve privacy protection and high\nspeech quality. Then, we present a data augmentation strategy and noise\nsmoothing mechanism to improve the robustness of the proposed method. Besides,\nto reduce the user's defense overhead, we also propose a novel identity-wise\nprotection mechanism. It can generate a universal perturbation for one speaker\nand support privacy preservation for speech of any length. Finally, we conduct\nextensive experiments on 5 speech synthesis models, 5 speech verification\nmodels, 1 speech recognition model, and 2 datasets. The experimental results\ndemonstrate that our method has satisfying privacy-preserving performance, high\nspeech quality, and utility."}
{"id": "2509.00615", "categories": ["cs.CR", "cs.AI", "cs.DC", "cs.LG"], "pdf": "https://arxiv.org/pdf/2509.00615", "abs": "https://arxiv.org/abs/2509.00615", "authors": ["Narasimha Raghavan Veeraragavan", "Jan Franz Nygård"], "title": "Federated Survival Analysis with Node-Level Differential Privacy: Private Kaplan-Meier Curves", "comment": "This is the author's accepted version of the paper in IEEE FLTA 2025.\n  The final version of record will appear in Proceedings of the IEEE\n  International Conference on Federated Learning Technologies and Applications\n  (FLTA 2025)", "summary": "We investigate how to calculate Kaplan-Meier survival curves across multiple\nhealth-care jurisdictions while protecting patient privacy with node-level\ndifferential privacy. Each site discloses its curve only once, adding Laplace\nnoise whose scale is determined by the length of the common time grid; the\nserver then averages the noisy curves, so the overall privacy budget remains\nunchanged. We benchmark four one-shot smoothing techniques: Discrete Cosine\nTransform, Haar Wavelet shrinkage, adaptive Total-Variation denoising, and a\nparametric Weibull fit on the NCCTG lung-cancer cohort under five privacy\nlevels and three partition scenarios (uniform, moderately skewed, highly\nimbalanced). Total-Variation gives the best mean accuracy, whereas the\nfrequency-domain smoothers offer stronger worst-case robustness and the Weibull\nmodel shows the most stable behaviour at the strictest privacy setting. Across\nall methods the released curves keep the empirical log-rank type-I error below\nfifteen percent for privacy budgets of 0.5 and higher, demonstrating that\nclinically useful survival information can be shared without iterative training\nor heavy cryptography."}
{"id": "2509.00634", "categories": ["cs.CR", "cs.AI"], "pdf": "https://arxiv.org/pdf/2509.00634", "abs": "https://arxiv.org/abs/2509.00634", "authors": ["Chaoyu Zhang", "Heng Jin", "Shanghao Shi", "Hexuan Yu", "Sydney Johns", "Y. Thomas Hou", "Wenjing Lou"], "title": "Enabling Trustworthy Federated Learning via Remote Attestation for Mitigating Byzantine Threats", "comment": null, "summary": "Federated Learning (FL) has gained significant attention for its\nprivacy-preserving capabilities, enabling distributed devices to\ncollaboratively train a global model without sharing raw data. However, its\ndistributed nature forces the central server to blindly trust the local\ntraining process and aggregate uncertain model updates, making it susceptible\nto Byzantine attacks from malicious participants, especially in\nmission-critical scenarios. Detecting such attacks is challenging due to the\ndiverse knowledge across clients, where variations in model updates may stem\nfrom benign factors, such as non-IID data, rather than adversarial behavior.\nExisting data-driven defenses struggle to distinguish malicious updates from\nnatural variations, leading to high false positive rates and poor filtering\nperformance.\n  To address this challenge, we propose Sentinel, a remote attestation\n(RA)-based scheme for FL systems that regains client-side transparency and\nmitigates Byzantine attacks from a system security perspective. Our system\nemploys code instrumentation to track control-flow and monitor critical\nvariables in the local training process. Additionally, we utilize a trusted\ntraining recorder within a Trusted Execution Environment (TEE) to generate an\nattestation report, which is cryptographically signed and securely transmitted\nto the server. Upon verification, the server ensures that legitimate client\ntraining processes remain free from program behavior violation or data\nmanipulation, allowing only trusted model updates to be aggregated into the\nglobal model. Experimental results on IoT devices demonstrate that Sentinel\nensures the trustworthiness of the local training integrity with low runtime\nand memory overhead."}
{"id": "2509.00647", "categories": ["cs.CR", "cs.AI"], "pdf": "https://arxiv.org/pdf/2509.00647", "abs": "https://arxiv.org/abs/2509.00647", "authors": ["Yu-Zheng Lin", "Sujan Ghimire", "Abhiram Nandimandalam", "Jonah Michael Camacho", "Unnati Tripathi", "Rony Macwan", "Sicong Shao", "Setareh Rafatirad", "Rozhin Yasaei", "Pratik Satam", "Soheil Salehi"], "title": "LLM-HyPZ: Hardware Vulnerability Discovery using an LLM-Assisted Hybrid Platform for Zero-Shot Knowledge Extraction and Refinement", "comment": "10 pages, 6 figures", "summary": "The rapid growth of hardware vulnerabilities has created an urgent need for\nsystematic and scalable analysis methods. Unlike software flaws, which are\noften patchable post-deployment, hardware weaknesses remain embedded across\nproduct lifecycles, posing persistent risks to processors, embedded devices,\nand IoT platforms. Existing efforts such as the MITRE CWE Hardware List (2021)\nrelied on expert-driven Delphi surveys, which lack statistical rigor and\nintroduce subjective bias, while large-scale data-driven foundations for\nhardware weaknesses have been largely absent. In this work, we propose\nLLM-HyPZ, an LLM-assisted hybrid framework for zero-shot knowledge extraction\nand refinement from vulnerability corpora. Our approach integrates zero-shot\nLLM classification, contextualized embeddings, unsupervised clustering, and\nprompt-driven summarization to mine hardware-related CVEs at scale. Applying\nLLM-HyPZ to the 2021-2024 CVE corpus (114,836 entries), we identified 1,742\nhardware-related vulnerabilities. We distilled them into five recurring themes,\nincluding privilege escalation via firmware and BIOS, memory corruption in\nmobile and IoT systems, and physical access exploits. Benchmarking across seven\nLLMs shows that LLaMA 3.3 70B achieves near-perfect classification accuracy\n(99.5%) on a curated validation set. Beyond methodological contributions, our\nframework directly supported the MITRE CWE Most Important Hardware Weaknesses\n(MIHW) 2025 update by narrowing the candidate search space. Specifically, our\npipeline surfaced 411 of the 1,026 CVEs used for downstream MIHW analysis,\nthereby reducing expert workload and accelerating evidence gathering. These\nresults establish LLM-HyPZ as the first data-driven, scalable approach for\nsystematically discovering hardware vulnerabilities, thereby bridging the gap\nbetween expert knowledge and real-world vulnerability evidence."}
{"id": "2509.00662", "categories": ["cs.CR"], "pdf": "https://arxiv.org/pdf/2509.00662", "abs": "https://arxiv.org/abs/2509.00662", "authors": ["Vamsi Shankar Simhadri", "Yichang Xiong", "Habiba Farrukh", "Xiaokuan Zhang"], "title": "Virtual Reality, Real Problems: A Longitudinal Security Analysis of VR Firmware", "comment": "17 pages, 25 figures, 6 tables, To appear on ACM CCS 2025", "summary": "Virtual Reality (VR) technology is rapidly growing in recent years. VR\ndevices such as Meta Quest 3 utilize numerous sensors to collect users' data to\nprovide an immersive experience. Due to the extensive data collection and the\nimmersive nature, the security of VR devices is paramount. Leading VR devices\noften adopt and customize Android systems, which makes them susceptible to both\nAndroid-based vulnerabilities and new issues introduced by VR-specific\ncustomizations (e.g., system services to support continuous head and hand\ntracking). While prior work has extensively examined the security properties of\nthe Android software stack, how these security properties hold for VR systems\nremains unexplored. In this paper, we present the first comprehensive security\nanalysis of VR firmware. We collect over 300 versions of VR firmware from two\nmajor vendors, Quest and Pico, and perform a longitudinal analysis across the\nkernel layer, the system binary and library layer, and the application layer.\nWe have identified several security issues in these VR firmware, including\nmissing kernel-level security features, insufficient binary hardening,\ninconsistent permission enforcement, and inadequate SELinux policy enforcement.\nBased on our findings, we synthesize recommendations for VR vendors to improve\nsecurity and trust for VR devices. This paper will act as an important security\nresource for VR developers, users, and vendors, and will also direct future\nadvancements in secure VR ecosystem."}
{"id": "2509.00706", "categories": ["cs.CR"], "pdf": "https://arxiv.org/pdf/2509.00706", "abs": "https://arxiv.org/abs/2509.00706", "authors": ["YuKun Zhu", "ManYuan Hua", "Hai Huang", "YongZhao Zhang", "Jie Yang", "FengHua Xu", "RuiDong Chen", "XiaoSong Zhang", "JiGuo Yu", "Yong Ma"], "title": "X-PRINT:Platform-Agnostic and Scalable Fine-Grained Encrypted Traffic Fingerprinting", "comment": null, "summary": "Although encryption protocols such as TLS are widely de-ployed,side-channel\nmetadata in encrypted traffic still reveals patterns that allow application and\nbehavior inference.How-ever,existing fine-grained fingerprinting approaches\nface two key limitations:(i)reliance on platform-dependent\ncharac-teristics,which restricts generalization across heterogeneous\nplatforms,and(ii)poor scalability for fine-grained behavior identification in\nopen-world settings.\n  In this paper,we present X-PRINT,the first server-centric,URI-based framework\nfor cross-platform fine-grained encrypted-traffic fingerprinting.X-PRINT\nsystematically demonstrates that backend URI invocation patterns can serve as\nplatform-agnostic invariants and are effective for mod-eling fine-grained\nbehaviors.To achieve robust identifica-tion,X-PRINT further leverages\ntemporally structured URI maps for behavior inference and emphasizes the\nexclusion of platform-or application-specific private URIs to handle unseen\ncases,thereby improving reliability in open-world and cross-platform\nsettings.Extensive experiments across diverse cross-platform and open-world\nsettings show that X-PRINT achieves state-of-the-art accuracy in fine-grained\nfingerprint-ing and exhibits strong scalability and robustness."}
{"id": "2509.00770", "categories": ["cs.CR"], "pdf": "https://arxiv.org/pdf/2509.00770", "abs": "https://arxiv.org/abs/2509.00770", "authors": ["Shaofei Huang", "Christopher M. Poskitt", "Lwin Khin Shar"], "title": "Bayesian and Multi-Objective Decision Support for Real-Time Cyber-Physical Incident Mitigation", "comment": null, "summary": "This research proposes a real-time, adaptive decision-support framework for\nmitigating cyber incidents in cyber-physical systems, developed in response to\nan increasing reliance on these systems within critical infrastructure and\nevolving adversarial tactics. Existing decision-support systems often fall\nshort in accounting for multi-agent, multi-path attacks and trade-offs between\nsafety and operational continuity. To address this, our framework integrates\nhierarchical system modelling with Bayesian probabilistic reasoning,\nconstructing Bayesian Network Graphs from system architecture and vulnerability\ndata. Models are encoded using a Domain Specific Language to enhance\ncomputational efficiency and support dynamic updates. In our approach, we use a\nhybrid exposure probability estimation framework, which combines Exploit\nPrediction Scoring System and Common Vulnerability Scoring System scores via\nBayesian confidence calibration to handle epistemic uncertainty caused by\nincomplete or heterogeneous vulnerability metadata. Mitigation recommendations\nare generated as countermeasure portfolios, refined using multi-objective\noptimisation to identify Pareto-optimal strategies balancing attack likelihood,\nimpact severity, and system availability. To accommodate time- and\nresource-constrained incident response, frequency-based heuristics are applied\nto prioritise countermeasures across the optimised portfolios. The framework\nwas evaluated through three representative cyber-physical attack scenarios,\ndemonstrating its versatility in handling complex adversarial behaviours under\nreal-time response constraints. The results affirm its utility in operational\ncontexts and highlight the robustness of our proposed approach across diverse\nthreat environments."}
{"id": "2509.00811", "categories": ["cs.CR"], "pdf": "https://arxiv.org/pdf/2509.00811", "abs": "https://arxiv.org/abs/2509.00811", "authors": ["Samuel Punch", "Krishnendu Guha"], "title": "MAESTROCUT: Dynamic, Noise-Adaptive, and Secure Quantum Circuit Cutting on Near-Term Hardware", "comment": "14 Pages", "summary": "We present MaestroCut, a closed-loop framework for quantum circuit cutting\nthat adapts partitioning and shot allocation to device drift and workload\nvariation. MaestroCut tracks a variance proxy in real time, triggers re-cutting\nwhen accuracy degrades, and routes shots using topology-aware priors. An online\nestimator cascade (MLE, Bayesian, GP-assisted) selects the lowest-error\nreconstruction within a fixed budget. Tier-1 simulations show consistent\nvariance contraction and reduced mean-squared error versus uniform and\nproportional baselines. Tier-2 emulation with realistic queueing and noise\ndemonstrates stable latency targets, high reliability, and ~1% software\noverhead under stress scenarios. These results indicate that adaptive circuit\ncutting can provide accuracy and efficiency improvements with minimal\noperational cost on near-term hardware."}
{"id": "2509.00812", "categories": ["cs.CR"], "pdf": "https://arxiv.org/pdf/2509.00812", "abs": "https://arxiv.org/abs/2509.00812", "authors": ["Samuel Punch", "Krishnendu Guha"], "title": "Adaptive t Design Dummy-Gate Obfuscation for Cryogenic Scale Enforcement", "comment": "6", "summary": "Cloud quantum services can reveal circuit structure and timing through\nscheduler metadata, latency patterns, and co-tenant interference. We introduce\nNADGO (Noise-Adaptive Dummy-Gate Obfuscation), a scheduling and obfuscation\nstack that enforces operational privacy for gate-model workloads by applying\nper-interval limits on observable information leakage. To support\nconfidentiality and fair multi-tenancy, operators require a method to audit\ncompliance at acceptable overheads. NADGO combines: (i) hardware-aware t-design\npadding for structured cover traffic, (ii) particle-filter timing randomization\nto mask queue patterns, (iii) CASQUE subcircuit routing across heterogeneous\nbackends, and (iv) a per-interval leakage estimator with locked calibration\nartifacts and a dual-threshold kill-switch. We prototype the approach on a\n4-qubit superconducting tile with cryo-CMOS control and evaluate both\ndepth-varied local-random circuits and small QAOA instances. Monitoring runs at\na 6.3 microsecond control interval, and per-interval decisions are recorded in\nan append-only, hash-chained audit log. Across Monte Carlo (Tier 1) and\ncloud-hardware emulation (Tier 2) evaluations, NADGO maintains leakage within\nbudget in nominal operation (interval-abort rate below 1 percent) and under\nattack yields high separation with concentrated aborts. At matched leakage\ntargets, microbenchmarks indicate lower latency and cryogenic power consumption\nthan static padding, while end-to-end workloads maintain competitive cost\nenvelopes."}
{"id": "2509.00820", "categories": ["cs.CR"], "pdf": "https://arxiv.org/pdf/2509.00820", "abs": "https://arxiv.org/abs/2509.00820", "authors": ["Zhenhua Xu", "Zhaokun Yan", "Binhan Xu", "Xin Tong", "Haitao Xu", "Yourong Chen", "Meng Han"], "title": "Unlocking the Effectiveness of LoRA-FP for Seamless Transfer Implantation of Fingerprints in Downstream Models", "comment": "Accepted By EMNLP2025", "summary": "With the rapid advancement of large language models (LLMs), safeguarding\nintellectual property (IP) has become increasingly critical. To address the\nchallenges of high costs and potential contamination in fingerprint\nintegration, we propose LoRA-FP, a lightweight, plug-and-play framework that\nembeds backdoor fingerprints into LoRA adapters through constrained\nfine-tuning. This design enables seamless fingerprint transplantation via\nparameter fusion, eliminating the need for full-parameter updates while\npreserving model integrity. Experimental results demonstrate that LoRA-FP not\nonly significantly reduces computational overhead compared to conventional\napproaches but also achieves superior robustness across diverse scenarios,\nincluding incremental training and model fusion. Our code and datasets are\npublicly available at https://github.com/Xuzhenhua55/LoRA-FP."}
{"id": "2509.00882", "categories": ["cs.CR"], "pdf": "https://arxiv.org/pdf/2509.00882", "abs": "https://arxiv.org/abs/2509.00882", "authors": ["Xiang Li", "Yueci Su", "Jiahao Liu", "Zhiwei Lin", "Yuebing Hou", "Peiming Gao", "Yuanchao Zhang"], "title": "VULSOVER: Vulnerability Detection via LLM-Driven Constraint Solving", "comment": null, "summary": "Traditional vulnerability detection methods rely heavily on predefined rule\nmatching, which often fails to capture vulnerabilities accurately. With the\nrise of large language models (LLMs), leveraging their ability to understand\ncode semantics has emerged as a promising direction for achieving more accurate\nand efficient vulnerability detection. However, current LLM-based approaches\nface significant challenges: instability in model outputs, limitations in\ncontext length, and hallucination. As a result, many existing solutions either\nuse LLMs merely to enrich predefined rule sets, thereby keeping the detection\nprocess fundamentally rule-based, or over-rely on them, leading to poor\nrobustness. To address these challenges, we propose a constraint-solving\napproach powered by LLMs named VULSOLVER. By modeling vulnerability detection\nas a constraint-solving problem, and by integrating static application security\ntesting (SAST) with the semantic reasoning capabilities of LLMs, our method\nenables the LLM to act like a professional human security expert. We assess\nVULSOLVER on the OWASP Benchmark (1,023 labeled samples), achieving 96.29%\naccuracy, 96.55% F1-score, and 100% recall. Applied to popular GitHub\nrepositories, VULSOLVER also identified 15 previously unknown high-severity\nvulnerabilities (CVSS 7.5-9.8), demonstrating its effectiveness in real-world\nsecurity analysis."}
{"id": "2509.00896", "categories": ["cs.CR", "cs.SY", "eess.SY", "D.2.0"], "pdf": "https://arxiv.org/pdf/2509.00896", "abs": "https://arxiv.org/abs/2509.00896", "authors": ["Maryam Mahdi Alhusseini", "Mohammad Reza Feizi Derakhshi"], "title": "Hybrid AI-Driven Intrusion Detection: Framework Leveraging Novel Feature Selection for Enhanced Network Security", "comment": "16 pages, 12 figures", "summary": "In today's rapidly evolving digital landscape, safeguarding network\ninfrastructures against cyberattacks has become a critical priority. This\nresearch presents an innovative AI-driven real-time intrusion detection\nframework designed to enhance network security, particularly in Wireless Sensor\nNetworks (WSNs) and Cloud Computing (CC) environments. The system employs\nclassical machine learning models, Logistic Regression, Decision Tree, and\nK-Nearest Neighbors, optimized through the novel Energy Valley Optimization\n(EVO) method using the NSL-KDD dataset. Feature selection significantly reduced\nthe number of input features from 42 to 18 while maintaining strong detection\ncapabilities. The proposed system achieved 98.95 percent accuracy with Decision\nTree, 98.47 percent with K-Nearest Neighbors, and 88.84 percent with Logistic\nRegression. Moreover, high precision, recall, and F1-scores were attained\nacross all classifiers while substantially reducing training and testing times,\nmaking the framework highly suitable for real-time applications. To ensure fair\ndetection across diverse attack types, dataset balancing via downsampling was\napplied to address class imbalance challenges. This investigation focuses on\nthe significance of advancing intrusion detection systems in cloud computing\nand WSNs. Overall, this work advances secure communications by delivering a\nscalable, low-latency, and high-accuracy intrusion detection solution aligned\nwith the latest trends in artificial intelligence, cybersecurity, and real-time\ndigital networks"}
{"id": "2509.00918", "categories": ["cs.CR"], "pdf": "https://arxiv.org/pdf/2509.00918", "abs": "https://arxiv.org/abs/2509.00918", "authors": ["Xubin Yue", "Zhenhua Xu", "Wenpeng Xing", "Jiahui Yu", "Mohan Li", "Meng Han"], "title": "PREE: Towards Harmless and Adaptive Fingerprint Editing in Large Language Models via Knowledge Prefix Enhancement", "comment": null, "summary": "Addressing the intellectual property protection challenges in commercial\ndeployment of large language models (LLMs), existing black-box fingerprinting\ntechniques face dual challenges from incremental fine-tuning erasure and\nfeature-space defense due to their reliance on overfitting high-perplexity\ntrigger patterns. Recent work has revealed that model editing in the\nfingerprinting domain offers distinct advantages, including significantly lower\nfalse positive rates, enhanced harmlessness, and superior robustness. Building\non this foundation, this paper innovatively proposes a\n$\\textbf{Pr}$efix-$\\textbf{e}$nhanced Fingerprint $\\textbf{E}$diting Framework\n(PREE), which encodes copyright information into parameter offsets through\ndual-channel knowledge edit to achieve covert embedding of fingerprint\nfeatures. Experimental results demonstrate that the proposed solution achieves\nthe 90\\% trigger precision in mainstream architectures including LLaMA-3 and\nQwen-2.5. The minimal parameter offset (change rate < 0.03) effectively\npreserves original knowledge representation while demonstrating strong\nrobustness against incremental fine-tuning and multi-dimensional defense\nstrategies, maintaining zero false positive rate throughout evaluations."}
{"id": "2509.00973", "categories": ["cs.CR", "cs.AI", "68T05, 68Q32, 94A60,", "I.2.6; I.2.3; I.2.0; D.4.6"], "pdf": "https://arxiv.org/pdf/2509.00973", "abs": "https://arxiv.org/abs/2509.00973", "authors": ["Kanchon Gharami", "Hansaka Aluvihare", "Shafika Showkat Moni", "Berker Peköz"], "title": "Clone What You Can't Steal: Black-Box LLM Replication via Logit Leakage and Distillation", "comment": "8 pages. Accepted for publication in the proceedings of 7th IEEE\n  International Conference on Trust, Privacy and Security in Intelligent\n  Systems, and Applications (IEEE TPS 2025)", "summary": "Large Language Models (LLMs) are increasingly deployed in mission-critical\nsystems, facilitating tasks such as satellite operations, command-and-control,\nmilitary decision support, and cyber defense. Many of these systems are\naccessed through application programming interfaces (APIs). When such APIs lack\nrobust access controls, they can expose full or top-k logits, creating a\nsignificant and often overlooked attack surface. Prior art has mainly focused\non reconstructing the output projection layer or distilling surface-level\nbehaviors. However, regenerating a black-box model under tight query\nconstraints remains underexplored. We address that gap by introducing a\nconstrained replication pipeline that transforms partial logit leakage into a\nfunctional deployable substitute model clone. Our two-stage approach (i)\nreconstructs the output projection matrix by collecting top-k logits from under\n10k black-box queries via singular value decomposition (SVD) over the logits,\nthen (ii) distills the remaining architecture into compact student models with\nvarying transformer depths, trained on an open source dataset. A 6-layer\nstudent recreates 97.6% of the 6-layer teacher model's hidden-state geometry,\nwith only a 7.31% perplexity increase, and a 7.58 Negative Log-Likelihood\n(NLL). A 4-layer variant achieves 17.1% faster inference and 18.1% parameter\nreduction with comparable performance. The entire attack completes in under 24\ngraphics processing unit (GPU) hours and avoids triggering API rate-limit\ndefenses. These results demonstrate how quickly a cost-limited adversary can\nclone an LLM, underscoring the urgent need for hardened inference APIs and\nsecure on-premise defense deployments."}
{"id": "2509.01046", "categories": ["cs.CR"], "pdf": "https://arxiv.org/pdf/2509.01046", "abs": "https://arxiv.org/abs/2509.01046", "authors": ["Khashayar Khajavi", "Tao Wang"], "title": "Lightening the Load: A Cluster-Based Framework for A Lower-Overhead, Provable Website Fingerprinting Defense", "comment": null, "summary": "Website fingerprinting (WF) attacks remain a significant threat to encrypted\ntraffic, prompting the development of a wide range of defenses. Among these,\ntwo prominent classes are regularization-based defenses, which shape traffic\nusing fixed padding rules, and supersequence-based approaches, which conceal\ntraces among predefined patterns. In this work, we present a unified framework\nfor designing an adaptive WF defense that combines the effectiveness of\nregularization with the provable security of supersequence-style grouping. The\nscheme first extracts behavioural patterns from traces and clusters them into\n(k,l)-diverse anonymity sets; an early-time-series classifier (adapted from\nECDIRE) then switches from a conservative global set of regularization\nparameters to the lighter, set-specific parameters. We instantiate the design\nas Adaptive Tamaraw, a variant of Tamaraw that assigns padding parameters on a\nper-cluster basis while retaining its original information-theoretic guarantee.\nComprehensive experiments on public real-world datasets confirm the benefits.\nBy tuning k, operators can trade privacy for efficiency: in its high-privacy\nmode Adaptive Tamaraw pushes the bound on any attacker's accuracy below 30%,\nwhereas in efficiency-centred settings it cuts total overhead by 99% compared\nwith classic Tamaraw."}
{"id": "2509.01178", "categories": ["cs.CR"], "pdf": "https://arxiv.org/pdf/2509.01178", "abs": "https://arxiv.org/abs/2509.01178", "authors": ["Hao Guo", "Zhaoqian Liu", "Liqiang Peng", "Shuaishuai Li", "Ximing Fu", "Weiran Liu", "Lin Qu"], "title": "Efficient and High-Accuracy Secure Two-Party Protocols for a Class of Functions with Real-number Inputs", "comment": "17 pages, 3 figures", "summary": "In two-party secret sharing scheme, values are typically encoded as unsigned\nintegers $\\mathsf{uint}(x)$, whereas real-world applications often require\ncomputations on signed real numbers $\\mathsf{Real}(x)$. To enable secure\nevaluation of practical functions, it is essential to computing\n$\\mathsf{Real}(x)$ from shared inputs, as protocols take shares as input. At\nUSENIX'25, Guo et al. proposed an efficient method for computing signed integer\nvalues $\\mathsf{int}(x)$ from shares, which can be extended to compute\n$\\mathsf{Real}(x)$. However, their approach imposes a restrictive input\nconstraint $|x| < \\frac{L}{3}$ for $x \\in \\mathbb{Z}_L$, limiting its\napplicability in real-world scenarios. In this work, we significantly relax\nthis constraint to $|x| < B$ for any $B \\leq \\frac{L}{2}$, where $B =\n\\frac{L}{2}$ corresponding to the natural representable range in $x \\in\n\\mathbb{Z}_L$. This relaxes the restrictions and enables the computation of\n$\\mathsf{Real}(x)$ with loose or no input constraints. Building upon this\nfoundation, we present a generalized framework for designing secure protocols\nfor a broad class of functions, including integer division ($\\lfloor\n\\frac{x}{d} \\rfloor$), trigonometric ($\\sin(x)$) and exponential ($e^{-x}$)\nfunctions. Our experimental evaluation demonstrates that the proposed protocols\nachieve both high efficiency and high accuracy. Notably, our protocol for\nevaluating $e^{-x}$ reduces communication costs to approximately 31% of those\nin SirNN (S&P 21) and Bolt (S&P 24), with runtime speedups of up to $5.53\n\\times$ and $3.09 \\times$, respectively. In terms of accuracy, our protocol\nachieves a maximum ULP error of $1.435$, compared to $2.64$ for SirNN and\n$8.681$ for Bolt."}
{"id": "2509.01211", "categories": ["cs.CR", "cs.AI", "cs.MA"], "pdf": "https://arxiv.org/pdf/2509.01211", "abs": "https://arxiv.org/abs/2509.01211", "authors": ["Dezhang Kong", "Hujin Peng", "Yilun Zhang", "Lele Zhao", "Zhenhua Xu", "Shi Lin", "Changting Lin", "Meng Han"], "title": "Web Fraud Attacks Against LLM-Driven Multi-Agent Systems", "comment": null, "summary": "With the proliferation of applications built upon LLM-driven multi-agent\nsystems (MAS), the security of Web links has become a critical concern in\nensuring system reliability. Once an agent is induced to visit a malicious\nwebsite, attackers can use it as a springboard to conduct diverse subsequent\nattacks, which will drastically expand the attack surface. In this paper, we\npropose Web Fraud Attacks, a novel type of attack aiming at inducing MAS to\nvisit malicious websites. We design 11 representative attack variants that\nencompass domain name tampering (homoglyph deception, character substitution,\netc.), link structure camouflage (sub-directory nesting, sub-domain grafting,\nparameter obfuscation, etc.), and other deceptive techniques tailored to\nexploit MAS's vulnerabilities in link validation. Through extensive experiments\non these crafted attack vectors, we demonstrate that Web fraud attacks not only\nexhibit significant destructive potential across different MAS architectures\nbut also possess a distinct advantage in evasion: they circumvent the need for\ncomplex input formats such as jailbreaking, which inherently carry higher\nexposure risks. These results underscore the importance of addressing Web fraud\nattacks in LLM-driven MAS, as their stealthiness and destructiveness pose\nnon-negligible threats to system security and user safety."}
{"id": "2509.01253", "categories": ["cs.CR", "cs.LG"], "pdf": "https://arxiv.org/pdf/2509.01253", "abs": "https://arxiv.org/abs/2509.01253", "authors": ["Sayan Biswas", "Philippe Chartier", "Akash Dhasade", "Tom Jurien", "David Kerriou", "Anne-Marie Kerrmarec", "Mohammed Lemou", "Franklin Tranie", "Martijn de Vos", "Milos Vujasinovic"], "title": "Practical and Private Hybrid ML Inference with Fully Homomorphic Encryption", "comment": null, "summary": "In contemporary cloud-based services, protecting users' sensitive data and\nensuring the confidentiality of the server's model are critical. Fully\nhomomorphic encryption (FHE) enables inference directly on encrypted inputs,\nbut its practicality is hindered by expensive bootstrapping and inefficient\napproximations of non-linear activations. We introduce Safhire, a hybrid\ninference framework that executes linear layers under encryption on the server\nwhile offloading non-linearities to the client in plaintext. This design\neliminates bootstrapping, supports exact activations, and significantly reduces\ncomputation. To safeguard model confidentiality despite client access to\nintermediate outputs, Safhire applies randomized shuffling, which obfuscates\nintermediate values and makes it practically impossible to reconstruct the\nmodel. To further reduce latency, Safhire incorporates advanced optimizations\nsuch as fast ciphertext packing and partial extraction. Evaluations on multiple\nstandard models and datasets show that Safhire achieves 1.5X - 10.5X lower\ninference latency than Orion, a state-of-the-art baseline, with manageable\ncommunication overhead and comparable accuracy, thereby establishing the\npracticality of hybrid FHE inference."}
{"id": "2509.01271", "categories": ["cs.CR"], "pdf": "https://arxiv.org/pdf/2509.01271", "abs": "https://arxiv.org/abs/2509.01271", "authors": ["Rujie Dai", "Peizhuo Lv", "Yujiang Gui", "Qiujian Lv", "Yuanyuan Qiao", "Yan Wang", "Degang Sun", "Weiqing Huang", "Yingjiu Li", "XiaoFeng Wang"], "title": "An Automated Attack Investigation Approach Leveraging Threat-Knowledge-Augmented Large Language Models", "comment": null, "summary": "Advanced Persistent Threats (APTs) are prolonged, stealthy intrusions by\nskilled adversaries that compromise high-value systems to steal data or disrupt\noperations. Reconstructing complete attack chains from massive, heterogeneous\nlogs is essential for effective attack investigation, yet existing methods\nsuffer from poor platform generality, limited generalization to evolving\ntactics, and an inability to produce analyst-ready reports. Large Language\nModels (LLMs) offer strong semantic understanding and summarization\ncapabilities, but in this domain they struggle to capture the long-range,\ncross-log dependencies critical for accurate reconstruction.\n  To solve these problems, we present an LLM-empowered attack investigation\nframework augmented with a dynamically adaptable Kill-Chain-aligned threat\nknowledge base. We organizes attack-relevant behaviors into stage-aware\nknowledge units enriched with semantic annotations, enabling the LLM to\niteratively retrieve relevant intelligence, perform causal reasoning, and\nprogressively expand the investigation context. This process reconstructs\nmulti-phase attack scenarios and generates coherent, human-readable\ninvestigation reports. Evaluated on 15 attack scenarios spanning single-host\nand multi-host environments across Windows and Linux (over 4.3M log events, 7.2\nGB of data), the system achieves an average True Positive Rate (TPR) of 97.1%\nand an average False Positive Rate (FPR) of 0.2%, significantly outperforming\nthe SOTA method ATLAS, which achieves an average TPR of 79.2% and an average\nFPR of 29.1%."}
{"id": "2509.01375", "categories": ["cs.CR", "cs.AI"], "pdf": "https://arxiv.org/pdf/2509.01375", "abs": "https://arxiv.org/abs/2509.01375", "authors": ["Alberto Miguel-Diez", "Adrián Campazas-Vega", "Ángel Manuel Guerrero-Higueras", "Claudia Álvarez-Aparicio", "Vicente Matellán-Olivera"], "title": "Anomaly detection in network flows using unsupervised online machine learning", "comment": "14 pages, 3 figures, 6 tables", "summary": "Nowadays, the volume of network traffic continues to grow, along with the\nfrequency and sophistication of attacks. This scenario highlights the need for\nsolutions capable of continuously adapting, since network behavior is dynamic\nand changes over time. This work presents an anomaly detection model for\nnetwork flows using unsupervised machine learning with online learning\ncapabilities. This approach allows the system to dynamically learn the normal\nbehavior of the network and detect deviations without requiring labeled data,\nwhich is particularly useful in real-world environments where traffic is\nconstantly changing and labeled data is scarce. The model was implemented using\nthe River library with a One-Class SVM and evaluated on the NF-UNSW-NB15\ndataset and its extended version v2, which contain network flows labeled with\ndifferent attack categories. The results show an accuracy above 98%, a false\npositive rate below 3.1%, and a recall of 100% in the most advanced version of\nthe dataset. In addition, the low processing time per flow (<0.033 ms)\ndemonstrates the feasibility of the approach for real-time applications."}
{"id": "2509.01434", "categories": ["cs.CR", "cs.DC"], "pdf": "https://arxiv.org/pdf/2509.01434", "abs": "https://arxiv.org/abs/2509.01434", "authors": ["Handi Chen", "Jing Deng", "Xiuzhe Wu", "Zhihan Jiang", "Xinchen Zhang", "Xianhao Chen", "Edith C. H. Ngai"], "title": "LiFeChain: Lightweight Blockchain for Secure and Efficient Federated Lifelong Learning in IoT", "comment": null, "summary": "The expansion of Internet of Things (IoT) devices constantly generates\nheterogeneous data streams, driving demand for continuous, decentralized\nintelligence. Federated Lifelong Learning (FLL) provides an ideal solution by\nincorporating federated and lifelong learning to overcome catastrophic\nforgetting. The extended lifecycle of FLL in IoT systems increases their\nvulnerability to persistent attacks, and these risks may be obscured by\nperformance degradation caused by spatial-temporal data heterogeneity.\nMoreover, this problem is exacerbated by the standard single-server\narchitecture, as its single point of failure makes it difficult to maintain a\nreliable audit trail for long-term threats. Blockchain provides a tamper-proof\nfoundation for trustworthy FLL systems. Nevertheless, directly applying\nblockchain to FLL significantly increases computational and retrieval costs\nwith the expansion of the knowledge base, slowing down the training on IoT\ndevices. To address these challenges, we propose LiFeChain, a lightweight\nblockchain for secure and efficient federated lifelong learning by providing a\ntamper-resistant ledger with minimal on-chain disclosure and bidirectional\nverification. To the best of our knowledge, LiFeChain is the first blockchain\ntailored for FLL. LiFeChain incorporates two complementary mechanisms: the\nproof-of-model-correlation (PoMC) consensus on the server, which couples\nlearning and unlearning mechanisms to mitigate negative transfer, and segmented\nzero-knowledge arbitration (Seg-ZA) on the client, which detects and arbitrates\nabnormal committee behavior without compromising privacy. LiFeChain is designed\nas a plug-and-play component that can be seamlessly integrated into existing\nFLL algorithms. Experimental results demonstrate that LiFeChain not only\nenhances model performance against two long-term attacks but also sustains high\nefficiency and scalability."}
{"id": "2509.01463", "categories": ["cs.CR"], "pdf": "https://arxiv.org/pdf/2509.01463", "abs": "https://arxiv.org/abs/2509.01463", "authors": ["Pranjay Malhotra"], "title": "LLMHoney: A Real-Time SSH Honeypot with Large Language Model-Driven Dynamic Response Generation", "comment": "7 Pages", "summary": "Cybersecurity honeypots are deception tools for engaging attackers and gather\nintelligence, but traditional low or medium-interaction honeypots often rely on\nstatic, pre-scripted interactions that can be easily identified by skilled\nadversaries. This Report presents LLMHoney, an SSH honeypot that leverages\nLarge Language Models (LLMs) to generate realistic, dynamic command outputs in\nreal time. LLMHoney integrates a dictionary-based virtual file system to handle\ncommon commands with low latency while using LLMs for novel inputs, achieving a\nbalance between authenticity and performance. We implemented LLMHoney using\nopen-source LLMs and evaluated it on a testbed with 138 representative Linux\ncommands. We report comprehensive metrics including accuracy (exact-match,\nCosine Similarity, Jaro-Winkler Similarity, Levenshtein Similarity and BLEU\nscore), response latency and memory overhead. We evaluate LLMHoney using\nmultiple LLM backends ranging from 0.36B to 3.8B parameters, including both\nopen-source models and a proprietary model(Gemini). Our experiments compare 13\ndifferent LLM variants; results show that Gemini-2.0 and moderately-sized\nmodels Qwen2.5:1.5B and Phi3:3.8B provide the most reliable and accurate\nresponses, with mean latencies around 3 seconds, whereas smaller models often\nproduce incorrect or out-of-character outputs. We also discuss how LLM\nintegration improves honeypot realism and adaptability compared to traditional\nhoneypots, as well as challenges such as occasional hallucinated outputs and\nincreased resource usage. Our findings demonstrate that LLM-driven honeypots\nare a promising approach to enhance attacker engagement and collect richer\nthreat intelligence."}
{"id": "2509.01470", "categories": ["cs.CR"], "pdf": "https://arxiv.org/pdf/2509.01470", "abs": "https://arxiv.org/abs/2509.01470", "authors": ["I. D. Lutz", "A. M. Hill", "M. C. Valenti"], "title": "Privacy-preserving authentication for military 5G networks", "comment": "To appear in Proc. IEEE Military Commun. Conf. (MILCOM), (Los\n  Angeles, CA), Oct. 2025", "summary": "As 5G networks gain traction in defense applications, ensuring the privacy\nand integrity of the Authentication and Key Agreement (AKA) protocol is\ncritical. While 5G AKA improves upon previous generations by concealing\nsubscriber identities, it remains vulnerable to replay-based synchronization\nand linkability threats under realistic adversary models. This paper provides a\nunified analysis of the standardized 5G AKA flow, identifying several\nvulnerabilities and highlighting how each exploits protocol behavior to\ncompromise user privacy. To address these risks, we present five lightweight\nmitigation strategies. We demonstrate through prototype implementation and\ntesting that these enhancements strengthen resilience against linkability\nattacks with minimal computational and signaling overhead. Among the solutions\nstudied, those introducing a UE-generated nonce emerge as the most promising,\neffectively neutralizing the identified tracking and correlation attacks with\nnegligible additional overhead. Integrating this extension as an optional\nfeature to the standard 5G AKA protocol offers a backward-compatible,\nlow-overhead path toward a more privacy-preserving authentication framework for\nboth commercial and military 5G deployments."}
{"id": "2509.01509", "categories": ["cs.CR"], "pdf": "https://arxiv.org/pdf/2509.01509", "abs": "https://arxiv.org/abs/2509.01509", "authors": ["Chengyu Song", "Jianming Zheng"], "title": "Insight-LLM: LLM-enhanced Multi-view Fusion in Insider Threat Detection", "comment": null, "summary": "Insider threat detection (ITD) requires analyzing sparse, heterogeneous user\nbehavior. Existing ITD methods predominantly rely on single-view modeling,\nresulting in limited coverage and missed anomalies. While multi-view learning\nhas shown promise in other domains, its direct application to ITD introduces\nsignificant challenges: scalability bottlenecks from independently trained\nsub-models, semantic misalignment across disparate feature spaces, and view\nimbalance that causes high-signal modalities to overshadow weaker ones. In this\nwork, we present Insight-LLM, the first modular multi-view fusion framework\nspecifically tailored for insider threat detection. Insight-LLM employs frozen,\npre-nes, achieving state-of-the-art detection with low latency and parameter\noverhead."}
{"id": "2509.01592", "categories": ["cs.CR", "cs.AI", "cs.LG", "cs.SY", "eess.SY", "68T05, 93C65, 90C35", "K.6.5; C.2.3; I.2.6"], "pdf": "https://arxiv.org/pdf/2509.01592", "abs": "https://arxiv.org/abs/2509.01592", "authors": ["Einstein Rivas Pizarro", "Wajiha Zaheer", "Li Yang", "Khalil El-Khatib", "Glenn Harvel"], "title": "Securing Radiation Detection Systems with an Efficient TinyML-Based IDS for Edge Devices", "comment": "Preprint author original pre review. Accepted and Presented at NPIC &\n  HMIT 2025. The official proceedings version is available in the ANS Digital\n  Library", "summary": "Radiation Detection Systems (RDSs) play a vital role in ensuring public\nsafety across various settings, from nuclear facilities to medical\nenvironments. However, these systems are increasingly vulnerable to\ncyber-attacks such as data injection, man-in-the-middle (MITM) attacks, ICMP\nfloods, botnet attacks, privilege escalation, and distributed denial-of-service\n(DDoS) attacks. Such threats could compromise the integrity and reliability of\nradiation measurements, posing significant public health and safety risks. This\npaper presents a new synthetic radiation dataset and an Intrusion Detection\nSystem (IDS) tailored for resource-constrained environments, bringing Machine\nLearning (ML) predictive capabilities closer to the sensing edge layer of\ncritical infrastructure. Leveraging TinyML techniques, the proposed IDS employs\nan optimized XGBoost model enhanced with pruning, quantization, feature\nselection, and sampling. These TinyML techniques significantly reduce the size\nof the model and computational demands, enabling real-time intrusion detection\non low-resource devices while maintaining a reasonable balance between\nefficiency and accuracy."}
{"id": "2509.01597", "categories": ["cs.CR", "cs.DS", "stat.AP"], "pdf": "https://arxiv.org/pdf/2509.01597", "abs": "https://arxiv.org/abs/2509.01597", "authors": ["Kaitlyn Webb", "Prottay Protivash", "John Durrell", "Daniell Toth", "Aleksandra Slavković", "Daniel Kifer"], "title": "Statistics-Friendly Confidentiality Protection for Establishment Data, with Applications to the QCEW", "comment": "37 pages (14 main text and 24 appendix pages), 7 figures", "summary": "Confidentiality for business data is an understudied area of disclosure\navoidance, where legacy methods struggle to provide acceptable results. Modern\nformal privacy techniques designed for person-level data do not provide\nsuitable confidentiality/utility trade-offs due to the highly skewed nature of\nbusiness data and because extreme outlier records are often important\ncontributors to query answers. In this paper, inspired by Gaussian Differential\nPrivacy, we propose a novel confidentiality framework for business data with a\nfocus on interpretability for policy makers. We propose two query-answering\nmechanisms and analyze new challenges that arise when noisy query answers are\nconverted into confidentiality-preserving microdata. We evaluate our mechanisms\non confidential Quarterly Census of Employment and Wages (QCEW) microdata and a\npublic substitute dataset."}
{"id": "2509.01599", "categories": ["cs.CR", "cs.AI", "cs.LG", "cs.SY", "eess.SY", "68T05, 93C65, 90C35", "K.6.5; C.2.3; I.2.6"], "pdf": "https://arxiv.org/pdf/2509.01599", "abs": "https://arxiv.org/abs/2509.01599", "authors": ["Nathanael Coolidge", "Jaime González Sanz", "Li Yang", "Khalil El Khatib", "Glenn Harvel", "Nelson Agbemava", "I Putu Susila", "Mehmet Yavuz Yagci"], "title": "An Efficient Intrusion Detection System for Safeguarding Radiation Detection Systems", "comment": "Preprint author original pre review. Accepted and Presented at ISOFIC\n  2024. The official proceedings version is available on the conference site", "summary": "Radiation Detection Systems (RDSs) are used to measure and detect abnormal\nlevels of radioactive material in the environment. These systems are used in\nmany applications to mitigate threats posed by high levels of radioactive\nmaterial. However, these systems lack protection against malicious external\nattacks to modify the data. The novelty of applying Intrusion Detection Systems\n(IDS) in RDSs is a crucial element in safeguarding these critical\ninfrastructures. While IDSs are widely used in networking environments to\nsafeguard against various attacks, their application in RDSs is novel. A common\nattack on RDSs is Denial of Service (DoS), where the attacker aims to overwhelm\nthe system, causing malfunctioning RDSs. This paper proposes an efficient\nMachine Learning (ML)-based IDS to detect anomalies in radiation data, focusing\non DoS attacks. This work explores the use of sampling methods to create a\nsimulated DoS attack based on a real radiation dataset, followed by an\nevaluation of various ML algorithms, including Random Forest, Support Vector\nMachine (SVM), logistic regression, and Light Gradient-Boosting Machine\n(LightGBM), to detect DoS attacks on RDSs. LightGBM is emphasized for its\nsuperior accuracy and low computational resource consumption, making it\nparticularly suitable for real-time intrusion detection. Additionally, model\noptimization and TinyML techniques, including feature selection, parallel\nexecution, and random search methods, are used to improve the efficiency of the\nproposed IDS. Finally, an optimized and efficient LightGBM-based IDS is\ndeveloped to achieve accurate intrusion detection for RDSs."}
{"id": "2509.01701", "categories": ["cs.CR"], "pdf": "https://arxiv.org/pdf/2509.01701", "abs": "https://arxiv.org/abs/2509.01701", "authors": ["Kazi Hassan Shakib", "Muhammad Asfand Hafeez", "Arslan Munir"], "title": "AmphiKey: A Dual-Mode Secure Authenticated Key Encapsulation Protocol for Smart Grid", "comment": null, "summary": "AmphiKey, a dual-mode post-quantum/traditional (PQ/T) hybrid authenticated\nkey exchange mechanism (AKEM) has been designed to secure smart grid\ncommunications against both classical and quantum threats. AmphiKey offers two\ndistinct operational modes within a single framework: an Authenticated Mode and\na Deniable Mode. The Authenticated Mode employs a blackbox approach, combining\nephemeral ML-KEM-768 and X25519 with long-term Raccoon DSA keys to provide\nforward secrecy and strong, non-repudiable authenticity. This design achieves\n\"OR\" confidentiality, where security holds if either of the KEMs is unbroken,\nand robust \"AND\" authenticity. For the signature operation, it leverages the\n'masking-friendly' Raccoon digital signature (DSA), which is specifically\ndesigned for side-channel attack resistance, though this protection is\nlocalized to the signing key and does not provide deniability. In contrast,\nDeniable Mode provides deniable authentication, preserving privacy. The\nprotocol used ML-KEM-768 (AKEM-1), Ephemeral X25519 (AKEM-2), Raccoon-based DSA\n(Rac) (compared performance to ML-DSA-65), and the Ascon cipher to deliver its\nsecurity guarantees. Key contributions include providing a flexible protocol\nwith enhanced security, optional deniability, and efficiency adapted to the\ndiverse needs of the smart grid infrastructure. We present a comprehensive\nperformance evaluation on a heterogeneous testbed featuring a powerful server\nand client (AMD Ryzen 5) and a resource-constrained client (Raspberry Pi). In\nefficient Deniable mode, the full handshake completes in 0.15 ms on the server\nand 0.41 ms on the Raspberry Pi client. In contrast, the Authenticated Mode is\nbottlenecked by the client-side signature generation; the handshake takes 4.8\nms for the Raspberry Pi client to initiate and 0.84 ms for the server to\nverify."}
{"id": "2509.01717", "categories": ["cs.CR", "cs.SY", "eess.SY"], "pdf": "https://arxiv.org/pdf/2509.01717", "abs": "https://arxiv.org/abs/2509.01717", "authors": ["Hojjat Farshadinia", "Ali Barati", "Hamid Barati"], "title": "Designing a Layered Framework to Secure Data via Improved Multi Stage Lightweight Cryptography in IoT Cloud Systems", "comment": null, "summary": "This paper presents a novel multi-layered hybrid security approach aimed at\nenhancing lightweight encryption for IoT-Cloud systems. The primary goal is to\novercome limitations inherent in conventional solutions such as TPA,\nBlockchain, ECDSA and ZSS which often fall short in terms of data protection,\ncomputational efficiency and scalability. Our proposed method strategically\nrefines and integrates these technologies to address their shortcomings while\nmaximizing their individual strengths. By doing so we create a more reliable\nand high-performance framework for secure data exchange across heterogeneous\nenvironments. The model leverages the combined potential of emerging\ntechnologies, particularly Blockchain, IoT and Cloud computing which when\neffectively coordinated offer significant advancements in security\narchitecture. The proposed framework consists of three core layers: (1) the\nH.E.EZ Layer which integrates improved versions of Hyperledger Fabric,\nEnc-Block and a hybrid ECDSA-ZSS scheme to improve encryption speed,\nscalability and reduce computational cost; (2) the Credential Management Layer\nindependently verifying data integrity and authenticity; and (3) the Time and\nAuditing Layer designed to reduce traffic overhead and optimize performance\nacross dynamic workloads. Evaluation results highlight that the proposed\nsolution not only strengthens security but also significantly improves\nexecution time, communication efficiency and system responsiveness, offering a\nrobust path forward for next-generation IoT-Cloud infrastructures."}
{"id": "2509.01731", "categories": ["cs.CR"], "pdf": "https://arxiv.org/pdf/2509.01731", "abs": "https://arxiv.org/abs/2509.01731", "authors": ["Tran Duc Le", "Phuc Hao Do", "Truong Duy Dinh", "Van Dai Pham"], "title": "Are Enterprises Ready for Quantum-Safe Cybersecurity?", "comment": "Are Enterprises Ready for Quantum-Safe Cybersecurity?", "summary": "Quantum computing threatens to undermine classical cryptography by breaking\nwidely deployed encryption and signature schemes. This paper examines\nenterprise readiness for quantum-safe cybersecurity through three perspectives:\n(i) the technologist view, assessing the maturity of post-quantum cryptography\n(PQC) and quantum key distribution (QKD); (ii) the enterprise (CISO/CIO) view,\nanalyzing organizational awareness, risk management, and operational barriers;\nand (iii) the threat actor view, evaluating the evolving quantum threat and the\nurgency of migration. Using recent standards (e.g., NIST's 2024 PQC\nalgorithms), industry surveys, and threat intelligence, we synthesize findings\nvia a SWOT analysis to map strengths, weaknesses, opportunities, and threats.\nResults indicate uneven and generally insufficient preparedness: while PQC\nstandards and niche QKD deployments signal technical progress, fewer than 5\\%\nof enterprises have formal quantum-transition plans, and many underestimate\n\"harvest now, decrypt later\" risks. Financial, telecom, and government sectors\nhave begun migration, but most industries remain exploratory or stalled by\ncosts, complexity, and skills gaps. Expert consensus places cryptanalytically\nrelevant quantum computers in the 2030s, yet delayed preparation could leave\ntoday's data vulnerable for decades. We recommend immediate steps: establishing\ncrypto-agility, creating quantum transition roadmaps, prioritizing PQC\ndeployment in high-value systems, and upskilling cybersecurity teams. A\ncoordinated, proactive approach is essential to secure current and future\ndigital assets in the quantum era."}
{"id": "2509.01742", "categories": ["cs.CR", "cs.AR"], "pdf": "https://arxiv.org/pdf/2509.01742", "abs": "https://arxiv.org/abs/2509.01742", "authors": ["Yitong Guo", "Hongbo Chen", "Haobin Hiroki Chen", "Yukui Luo", "XiaoFeng Wang", "Chenghong Wang"], "title": "BOLT: Bandwidth-Optimized Lightning-Fast Oblivious Map powered by Secure HBM Accelerators", "comment": "Accepted by CCS 2025", "summary": "While Trusted Execution Environments provide a strong foundation for secure\ncloud computing, they remain vulnerable to access pattern leakages. Oblivious\nMaps (OMAPs) mitigate this by fully hiding access patterns but suffer from high\noverhead due to randomized remapping and worst-case padding. We argue these\ncosts are not fundamental. Modern accelerators featuring High-Bandwidth Memory\n(HBM) offer a new opportunity: Vaswani et al. [OSDI'18] point out that\neavesdropping on HBM is difficult -- even for physical attackers -- as its\nmemory channels are sealed together with processor cores inside the same\nphysical package. Later, Hunt et al. [NSDI'20] show that, with proper\nisolation, HBM can be turned into an unobservable region where both data and\nmemory traces are hidden. This motivates a rethink of OMAP design with\nHBM-backed solutions to finally overcome their traditional performance limits.\nBuilding on these insights, we present BOLT, a Bandwidth Optimized,\nLightning-fast OMAP accelerator that, for the first time, achieves O(1) +\nO((log log N)^2) bandwidth overhead. BOLT introduces three key innovations: (i)\na new OMAP algorithm that leverages isolated HBM as an unobservable cache to\naccelerate oblivious access to large host memory; (ii) a self-hosted\narchitecture that offloads execution and memory control from the host to\nmitigate CPU-side leakage; and (iii) tailored algorithm-architecture co-designs\nthat maximize resource efficiency. We implement a prototype BOLT on a Xilinx\nU55C FPGA. Evaluations show that BOLT achieves up to 279x and 480x speedups in\ninitialization and query time, respectively, over state-of-the-art OMAPs,\nincluding an industry implementation from Facebook."}
{"id": "2509.01791", "categories": ["cs.CR", "cs.AI"], "pdf": "https://arxiv.org/pdf/2509.01791", "abs": "https://arxiv.org/abs/2509.01791", "authors": ["Luca Pajola", "Eugenio Caripoti", "Simeone Pizzi", "Mauro Conti", "Stefan Banzer", "Giovanni Apruzzese"], "title": "E-PhishGen: Unlocking Novel Research in Phishing Email Detection", "comment": "Accepted to ACM AISec '26", "summary": "Every day, our inboxes are flooded with unsolicited emails, ranging between\nannoying spam to more subtle phishing scams. Unfortunately, despite abundant\nprior efforts proposing solutions achieving near-perfect accuracy, the reality\nis that countering malicious emails still remains an unsolved dilemma.\n  This \"open problem\" paper carries out a critical assessment of scientific\nworks in the context of phishing email detection. First, we focus on the\nbenchmark datasets that have been used to assess the methods proposed in\nresearch. We find that most prior work relied on datasets containing emails\nthat -- we argue -- are not representative of current trends, and mostly\nencompass the English language. Based on this finding, we then re-implement and\nre-assess a variety of detection methods reliant on machine learning (ML),\nincluding large-language models (LLM), and release all of our codebase -- an\n(unfortunately) uncommon practice in related research. We show that most such\nmethods achieve near-perfect performance when trained and tested on the same\ndataset -- a result which intrinsically hinders development (how can future\nresearch outperform methods that are already near perfect?). To foster the\ncreation of \"more challenging benchmarks\" that reflect current phishing trends,\nwe propose E-PhishGEN, an LLM-based (and privacy-savvy) framework to generate\nnovel phishing-email datasets. We use our E-PhishGEN to create E-PhishLLM, a\nnovel phishing-email detection dataset containing 16616 emails in three\nlanguages. We use E-PhishLLM to test the detectors we considered, showing a\nmuch lower performance than that achieved on existing benchmarks -- indicating\na larger room for improvement. We also validate the quality of E-PhishLLM with\na user study (n=30). To sum up, we show that phishing email detection is still\nan open problem -- and provide the means to tackle such a problem by future\nresearch."}
{"id": "2509.01835", "categories": ["cs.CR"], "pdf": "https://arxiv.org/pdf/2509.01835", "abs": "https://arxiv.org/abs/2509.01835", "authors": ["Saad Ullah", "Praneeth Balasubramanian", "Wenbo Guo", "Amanda Burnett", "Hammond Pearce", "Christopher Kruegel", "Giovanni Vigna", "Gianluca Stringhini"], "title": "From CVE Entries to Verifiable Exploits: An Automated Multi-Agent Framework for Reproducing CVEs", "comment": null, "summary": "High-quality datasets of real-world vulnerabilities and their corresponding\nverifiable exploits are crucial resources in software security research. Yet\nsuch resources remain scarce, as their creation demands intensive manual effort\nand deep security expertise. In this paper, we present CVE-GENIE, an automated,\nlarge language model (LLM)-based multi-agent framework designed to reproduce\nreal-world vulnerabilities, provided in Common Vulnerabilities and Exposures\n(CVE) format, to enable creation of high-quality vulnerability datasets. Given\na CVE entry as input, CVE-GENIE gathers the relevant resources of the CVE,\nautomatically reconstructs the vulnerable environment, and (re)produces a\nverifiable exploit. Our systematic evaluation highlights the efficiency and\nrobustness of CVE-GENIE's design and successfully reproduces approximately 51%\n(428 of 841) CVEs published in 2024-2025, complete with their verifiable\nexploits, at an average cost of $2.77 per CVE. Our pipeline offers a robust\nmethod to generate reproducible CVE benchmarks, valuable for diverse\napplications such as fuzzer evaluation, vulnerability patching, and assessing\nAI's security capabilities."}
{"id": "2509.02004", "categories": ["cs.CR"], "pdf": "https://arxiv.org/pdf/2509.02004", "abs": "https://arxiv.org/abs/2509.02004", "authors": ["Takao Murakami", "Yuichi Sei", "Reo Eriguchi"], "title": "Augmented Shuffle Differential Privacy Protocols for Large-Domain Categorical and Key-Value Data", "comment": "Full version of the paper accepted at NDSS 2026", "summary": "Shuffle DP (Differential Privacy) protocols provide high accuracy and privacy\nby introducing a shuffler who randomly shuffles data in a distributed system.\nHowever, most shuffle DP protocols are vulnerable to two attacks: collusion\nattacks by the data collector and users and data poisoning attacks. A recent\nstudy addresses this issue by introducing an augmented shuffle DP protocol,\nwhere users do not add noise and the shuffler performs random sampling and\ndummy data addition. However, it focuses on frequency estimation over\ncategorical data with a small domain and cannot be applied to a large domain\ndue to prohibitively high communication and computational costs.\n  In this paper, we fill this gap by introducing a novel augmented shuffle DP\nprotocol called the FME (Filtering-with-Multiple-Encryption) protocol. Our FME\nprotocol uses a hash function to filter out unpopular items and then accurately\ncalculates frequencies for popular items. To perform this within one round of\ninteraction between users and the shuffler, our protocol carefully communicates\nwithin a system using multiple encryption. We also apply our FME protocol to\nmore advanced KV (Key-Value) statistics estimation with an additional technique\nto reduce bias. For both categorical and KV data, we prove that our protocol\nprovides computational DP, high robustness to the above two attacks, accuracy,\nand efficiency. We show the effectiveness of our proposals through comparisons\nwith twelve existing protocols."}
{"id": "2509.02042", "categories": ["cs.CR"], "pdf": "https://arxiv.org/pdf/2509.02042", "abs": "https://arxiv.org/abs/2509.02042", "authors": ["Pascal Zimmer", "Simon Lachnit", "Alexander Jan Zielinski", "Ghassan Karame"], "title": "Targeted Physical Evasion Attacks in the Near-Infrared Domain", "comment": "To appear in the Proceedings of the Network and Distributed Systems\n  Security Symposium (NDSS) 2026", "summary": "A number of attacks rely on infrared light sources or heat-absorbing material\nto imperceptibly fool systems into misinterpreting visual input in various\nimage recognition applications. However, almost all existing approaches can\nonly mount untargeted attacks and require heavy optimizations due to the\nuse-case-specific constraints, such as location and shape. In this paper, we\npropose a novel, stealthy, and cost-effective attack to generate both targeted\nand untargeted adversarial infrared perturbations. By projecting perturbations\nfrom a transparent film onto the target object with an off-the-shelf infrared\nflashlight, our approach is the first to reliably mount laser-free targeted\nattacks in the infrared domain. Extensive experiments on traffic signs in the\ndigital and physical domains show that our approach is robust and yields higher\nattack success rates in various attack scenarios across bright lighting\nconditions, distances, and angles compared to prior work. Equally important,\nour attack is highly cost-effective, requiring less than US\\$50 and a few tens\nof seconds for deployment. Finally, we propose a novel segmentation-based\ndetection that thwarts our attack with an F1-score of up to 99%."}
{"id": "2509.02076", "categories": ["cs.CR", "cs.AI"], "pdf": "https://arxiv.org/pdf/2509.02076", "abs": "https://arxiv.org/abs/2509.02076", "authors": ["Kong Mun Yeen", "Rafidah Md Noor", "Wahidah Md Shah", "Aslinda Hassan", "Muhammad Umair Munir"], "title": "Forecasting Future DDoS Attacks Using Long Short Term Memory (LSTM) Model", "comment": "18 pages", "summary": "This paper forecasts future Distributed Denial of Service (DDoS) attacks\nusing deep learning models. Although several studies address forecasting DDoS\nattacks, they remain relatively limited compared to detection-focused research.\nBy studying the current trends and forecasting based on newer and updated\ndatasets, mitigation plans against the attacks can be planned and formulated.\nThe methodology used in this research work conforms to the Cross Industry\nStandard Process for Data Mining (CRISP-DM) model."}
{"id": "2509.02077", "categories": ["cs.CR", "cs.CL", "cs.LG", "68T50 Natural language processing", "D.4.6; I.2.7"], "pdf": "https://arxiv.org/pdf/2509.02077", "abs": "https://arxiv.org/abs/2509.02077", "authors": ["Refat Othman", "Diaeddin Rimawi", "Bruno Rossi", "Barbara Russo"], "title": "From Attack Descriptions to Vulnerabilities: A Sentence Transformer-Based Approach", "comment": "Accepted in The Journal of Systems and Software (2025)", "summary": "In the domain of security, vulnerabilities frequently remain undetected even\nafter their exploitation. In this work, vulnerabilities refer to publicly\ndisclosed flaws documented in Common Vulnerabilities and Exposures (CVE)\nreports. Establishing a connection between attacks and vulnerabilities is\nessential for enabling timely incident response, as it provides defenders with\nimmediate, actionable insights. However, manually mapping attacks to CVEs is\ninfeasible, thereby motivating the need for automation. This paper evaluates 14\nstate-of-the-art (SOTA) sentence transformers for automatically identifying\nvulnerabilities from textual descriptions of attacks. Our results demonstrate\nthat the multi-qa-mpnet-base-dot-v1 (MMPNet) model achieves superior\nclassification performance when using attack Technique descriptions, with an\nF1-score of 89.0, precision of 84.0, and recall of 94.7. Furthermore, it was\nobserved that, on average, 56% of the vulnerabilities identified by the MMPNet\nmodel are also represented within the CVE repository in conjunction with an\nattack, while 61% of the vulnerabilities detected by the model correspond to\nthose cataloged in the CVE repository. A manual inspection of the results\nrevealed the existence of 275 predicted links that were not documented in the\nMITRE repositories. Consequently, the automation of linking attack techniques\nto vulnerabilities not only enhances the detection and response capabilities\nrelated to software security incidents but also diminishes the duration during\nwhich vulnerabilities remain exploitable, thereby contributing to the\ndevelopment of more secure systems."}
{"id": "2509.02083", "categories": ["cs.CR"], "pdf": "https://arxiv.org/pdf/2509.02083", "abs": "https://arxiv.org/abs/2509.02083", "authors": ["Dmitry Tanana"], "title": "Performance analysis of common browser extensions for cryptojacking detection", "comment": null, "summary": "This paper considers five extensions for Chromium-based browsers in order to\ndetermine how effective can browser-based defenses against cryptojacking\navailable to regular users be. We've examined most popular extensions -\nMinerBlock, AdGuard AdBlocker, Easy Redirect && Prevent Cryptojacking,\nCoinEater and Miners Shield, which claim to be designed specifically to\nidentify and stop illegal cryptocurrency mining. An empirically confirmed\ndataset of 373 distinct cryptojacking-infected websites which was assembled\nduring multi-stage procedure, was used to test those extensions. The results\nshowed that all plugins in question had significant performance limits. Easy\nRedirect and Miners Shield only blocked 6 and 5 websites respectively, while\nMinerBlock had the greatest detection rate at only 27% (101/373 sites blocked).\nMost concerningly, despite promises of cryptojacking prevention, AdGuard (which\nhas over 13 million users) and CoinEater were unable to identify any of the\ncompromised websites. These results demonstrate serious flaws in cryptojacking\ndetection products targeted for regular users, since even the best-performing\nspecimen failed to detect 73% of attacks. The obvious difference between\nadvertised capabilities and real performance highlights the urgent need for\neither accessibility improvements for laboratory-grade detection technologies\nthat show 90%+ efficiency in controlled environment or fundamental upgrades to\ncurrent commonly used extensions."}
{"id": "2509.02189", "categories": ["cs.CR"], "pdf": "https://arxiv.org/pdf/2509.02189", "abs": "https://arxiv.org/abs/2509.02189", "authors": ["Aditya Bhardwaj", "Péter Kutas"], "title": "A Gentle Introduction to Blind signatures: From RSA to Lattice-based Cryptography", "comment": null, "summary": "Blind signatures were first introduced by David Chaum. They allow a user to\nhave a message signed by a signer without revealing the message itself. This\nproperty is particularly useful in applications such as electronic voting and\ndigital cash, where user anonymity is important. In a blind signature scheme,\nthe user blinds their message before sending it to the signer, who signs the\nblinded message. The user then unblinds the signed message to obtain a valid\nsignature that can be verified publicly, ensuring that the signer cannot trace\nthe signed message back to the original unblinded version. A good analogy is\nplacing the message inside an envelope and having the envelope signed. Once the\nenvelope is opened, the signature remains valid for the enclosed message,\nensuring that the content remains confidential.\n  Such constructions provide anonymity and privacy to the user but given a\npractical quantum computer, the security of traditional crypto-systems\nproviding such features will be broken. To address this, the development of\nquantum-resistant cryptographic protocols is essential for maintaining the\nsecurity of digital transactions and data. Aligning with the same goal, this\nwork aims to thoroughly review the background of lattice-based blind\nsignatures. We start with the foundations of digital signatures in the\nclassical settings and then move on to lattice-based constructions."}
{"id": "2509.02289", "categories": ["cs.CR"], "pdf": "https://arxiv.org/pdf/2509.02289", "abs": "https://arxiv.org/abs/2509.02289", "authors": ["Anuj Gautam", "Tarun Yadav", "Garrett Smith", "Kent Seamons", "Scott Ruoti"], "title": "Passwords and FIDO2 Are Meant To Be Secret: A Practical Secure Authentication Channel for Web Browsers", "comment": "Extended version of paper published at CCS 2025:\n  https://doi.org/10.1145/3719027.3765195", "summary": "Password managers provide significant security benefits to users. However,\nmalicious client-side scripts and browser extensions can steal passwords after\nthe manager has autofilled them into the web page. In this paper, we extend\nprior work by Stock and Johns, showing how password autofill can be hardened to\nprevent these local attacks. We implement our design in the Firefox browser and\nconduct experiments demonstrating that our defense successfully protects\npasswords from XSS attacks and malicious extensions. We also show that our\nimplementation is compatible with 97% of the Alexa top 1000 websites. Next, we\ngeneralize our design, creating a second defense that prevents recently\ndiscovered local attacks against the FIDO2 protocols. We implement this second\ndefense into Firefox, demonstrating that it protects the FIDO2 protocol against\nXSS attacks and malicious extensions. This defense is compatible with all\nwebsites, though it does require a small change (2-3 lines) to web servers\nimplementing FIDO2."}
{"id": "2509.02372", "categories": ["cs.CR", "cs.AI", "cs.SE"], "pdf": "https://arxiv.org/pdf/2509.02372", "abs": "https://arxiv.org/abs/2509.02372", "authors": ["Zhiyang Chen", "Tara Saba", "Xun Deng", "Xujie Si", "Fan Long"], "title": "Poisoned at Scale: A Scalable Audit Uncovers Hidden Scam Endpoints in Production LLMs", "comment": "10 pages, 4 figures", "summary": "Large Language Models (LLMs) have become critical to modern software\ndevelopment, but their reliance on internet datasets for training introduces a\nsignificant security risk: the absorption and reproduction of malicious\ncontent. To evaluate this threat, this paper introduces a scalable, automated\naudit framework that synthesizes innocuous, developer-style prompts from known\nscam databases to query production LLMs and determine if they generate code\ncontaining harmful URLs. We conducted a large-scale evaluation across four\nproduction LLMs (GPT-4o, GPT-4o-mini, Llama-4-Scout, and DeepSeek-V3), and\nfound a systemic vulnerability, with all tested models generating malicious\ncode at a non-negligible rate. On average, 4.2\\% of programs generated in our\nexperiments contained malicious URLs. Crucially, this malicious code is often\ngenerated in response to benign prompts. We manually validate the prompts which\ncause all four LLMs to generate malicious code, and resulting in 177 innocuous\nprompts that trigger all models to produce harmful outputs. These results\nprovide strong empirical evidence that the training data of production LLMs has\nbeen successfully poisoned at scale, underscoring the urgent need for more\nrobust defense mechanisms and post-generation safety checks to mitigate the\npropagation of hidden security threats."}
{"id": "2509.02387", "categories": ["cs.CR", "cs.AI"], "pdf": "https://arxiv.org/pdf/2509.02387", "abs": "https://arxiv.org/abs/2509.02387", "authors": ["Rye Stahle-Smith", "Rasha Karakchi"], "title": "Real-time ML-based Defense Against Malicious Payload in Reconfigurable Embedded Systems", "comment": "This paper is submitted at Supercomputing (SC'25)", "summary": "The growing use of FPGAs in reconfigurable systems introducessecurity risks\nthrough malicious bitstreams that could cause denial-of-service (DoS), data\nleakage, or covert attacks. We investigated chip-level hardware malicious\npayload in embedded systems and proposed a supervised machine learning method\nto detect malicious bitstreams via static byte-level features. Our approach\ndiverges from existing methods by analyzing bitstreams directly at the binary\nlevel, enabling real-time detection without requiring access to source code or\nnetlists. Bitstreams were sourced from state-of-the-art (SOTA) benchmarks and\nre-engineered to target the Xilinx PYNQ-Z1 FPGA Development Board. Our dataset\nincluded 122 samples of benign and malicious configurations. The data were\nvectorized using byte frequency analysis, compressed using TSVD, and balanced\nusing SMOTE to address class imbalance. The evaluated classifiers demonstrated\nthat Random Forest achieved a macro F1-score of 0.97, underscoring the\nviability of real-time Trojan detection on resource-constrained systems. The\nfinal model was serialized and successfully deployed via PYNQ to enable\nintegrated bitstream analysis."}
{"id": "2509.02411", "categories": ["cs.CR", "cs.AI"], "pdf": "https://arxiv.org/pdf/2509.02411", "abs": "https://arxiv.org/abs/2509.02411", "authors": ["Honghui Xu", "Kaiyang Li", "Wei Chen", "Danyang Zheng", "Zhiyuan Li", "Zhipeng Cai"], "title": "A Survey: Towards Privacy and Security in Mobile Large Language Models", "comment": null, "summary": "Mobile Large Language Models (LLMs) are revolutionizing diverse fields such\nas healthcare, finance, and education with their ability to perform advanced\nnatural language processing tasks on-the-go. However, the deployment of these\nmodels in mobile and edge environments introduces significant challenges\nrelated to privacy and security due to their resource-intensive nature and the\nsensitivity of the data they process. This survey provides a comprehensive\noverview of privacy and security issues associated with mobile LLMs,\nsystematically categorizing existing solutions such as differential privacy,\nfederated learning, and prompt encryption. Furthermore, we analyze\nvulnerabilities unique to mobile LLMs, including adversarial attacks,\nmembership inference, and side-channel attacks, offering an in-depth comparison\nof their effectiveness and limitations. Despite recent advancements, mobile\nLLMs face unique hurdles in achieving robust security while maintaining\nefficiency in resource-constrained environments. To bridge this gap, we propose\npotential applications, discuss open challenges, and suggest future research\ndirections, paving the way for the development of trustworthy,\nprivacy-compliant, and scalable mobile LLM systems."}
{"id": "2509.02412", "categories": ["cs.CR"], "pdf": "https://arxiv.org/pdf/2509.02412", "abs": "https://arxiv.org/abs/2509.02412", "authors": ["Wenhao Chen", "Morris Chang", "Witawas Srisa-an", "Yong Guan"], "title": "APEX: Automatic Event Sequence Generation for Android Applications", "comment": null, "summary": "Due to the event driven nature and the versatility of GUI designs in Android\nprograms, it is challenging to generate event sequences with adequate code\ncoverage within a reasonable time. A common approach to handle this issue is to\nrely on GUI models to generate event sequences. These sequences can be\neffective in covering GUI states, but inconsistent in exposing program\nbehaviors that require specific inputs. A major obstacle to generate such\nspecific inputs is the lack of a systematic GUI exploration process to\naccommodate the analysis requirements. In this paper, we introduce Android Path\nExplorer (APEX), a systematic input generation framework using concolic\nexecution. APEX addresses the limitations of model-based sequence generation by\nusing concolic execution to discover the data dependencies of GUI state\ntransitions. Moreover, concolic execution is also used to prioritize events\nduring the exploration of GUI, which leads to a more robust model and accurate\ninput generation. The key novelty of APEX is that concolic execution is not\nonly used to construct event sequences, but also used to traverse the GUI more\nsystematically. As such, our experimental results show that APEX can be used to\ngenerate a set of event sequences that achieve high code coverage, as well as\nevent sequences that reach specific targets."}
{"id": "2509.02413", "categories": ["cs.CR"], "pdf": "https://arxiv.org/pdf/2509.02413", "abs": "https://arxiv.org/abs/2509.02413", "authors": ["Edoardo Marangone", "Eugenio Nerio Nemmi", "Daniele Friolo", "Giuseppe Ateniese", "Ingo Weber", "Claudio Di Ciccio"], "title": "Enabling decision support over confidential data", "comment": null, "summary": "Enabling automated decision-making processes by leveraging data-driven\nanalysis is a core goal of Decision Support Systems (DSSs). In multi-party\nscenarios where decisions rely on distributed and sensitive data, though,\nensuring confidentiality, verifiability, transparency, integrity, and\nconsistency at once remains an open challenge for DSSs. To tackle this\nmulti-faceted problem, we propose the Secure Platform for Automated decision\nRules via Trusted Applications (SPARTA) approach. By leveraging Trusted\nExecution Environments (TEEs) at its core, SPARTA ensures that the decision\nlogic and the data remain protected. To guarantee transparency and consistency\nof the decision process, SPARTA encodes decision rules into verifiable software\nobjects deployed within TEEs. To maintain the confidentiality of the outcomes\nwhile keeping the information integrity, SPARTA employs cryptography techniques\non notarized data based on user-definable access policies. Based on experiments\nconducted on public benchmarks and synthetic data, we find our approach to be\npractically applicable and scalable."}
