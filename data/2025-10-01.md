<div id=toc></div>

# Table of Contents

- [cs.CR](#cs.CR) [Total: 19]


<div id='cs.CR'></div>

# cs.CR [[Back]](#toc)

### [1] [Fast Energy-Theft Attack on Frequency-Varying Wireless Power without Additional Sensors](https://arxiv.org/abs/2509.25394)
*Hui Wang,Nima Tashakor,Xiaoyang Tian,Hans D. Schotten,Stefan M. Goetz*

Main category: cs.CR

TL;DR: 该论文提出了一种优化的攻击方法，能够在0.2毫秒内入侵加密无线充电系统并窃取65%的功率，显著提高了攻击的适用性。


<details>
  <summary>Details</summary>
Motivation: 随着无线充电的普及，公共场合的能量访问保护和网络安全日益重要。现有基于频率和阻抗变化的能量加密方法被证明不可靠，黑客可以检测频率变化并调整补偿。

Method: 优化了攻击系统，消除了耗时的最大接收电流调节，使用主接收线圈而非额外传感器天线来检测磁场，硬件更简单。通过仿真模型和实验验证。

Result: 攻击响应速度极快，在0.2毫秒内即可入侵并窃取65%的功率，显著提高了攻击的适用性。

Conclusion: 能量访问保护需要高度重视，当前的加密方法存在严重安全漏洞，为加密加固留下的空间很小。

Abstract: With the popularity of wireless charging, energy access protection and
cybersecurity are gaining importance, especially in public places. Currently,
the most common energy encryption method uses frequency and associated
impedance variation. However, we have proven that this method is not reliable,
since a hacker can detect the changing frequency and adjust the compensation.
However, the previously presented system needed time to follow the updated
frequency, while encryption systems may vary the frequency faster to avoid
energy theft. Furthermore, the previous system required an additional sensor
coil. To solve these problems, we optimized the attack and the associated
system, which can intrude and steal energy within 0.2 ms. The key is the
elimination of the time-consuming maximum receiver current regulation. Also, we
use the main receiving coil rather than any additional sensor antenna to detect
the magnetic field. Thus, the new hardware is even simpler. A simulation model
and experimental results demonstrate the fast response speed of the attack on
encrypted wireless power and steal 65% of the power. Overall, the applicability
of the attack is highly improved and leaves less room for hardening the
encryption. The results demonstrate that energy access protection needs to be
given great attention.

</details>


### [2] [Optimal Threshold Signatures in Bitcoin](https://arxiv.org/abs/2509.25408)
*Korok Ray,Sindura Saraswathi*

Main category: cs.CR

TL;DR: 该论文研究加密货币中阈值签名方案的最优设计，平衡安全性和可用性，提出动态阈值签名方案能实现最优效果。


<details>
  <summary>Details</summary>
Motivation: 在加密货币协议中，m-of-n阈值签名方案需要平衡安全性和可用性：高阈值提供更好安全性但可能锁定用户资金，低阈值则安全性不足。需要找到最优阈值来平衡这两种效应。

Method: 将阈值签名方案设计建模为优化问题，考虑用户和攻击者获取签名的概率。提出动态阈值签名方案，其中用户或攻击者获取签名的概率随时间衰减。

Result: 研究发现动态阈值签名方案是最优的，增加安全性或可用性允许使用更高阈值和更长时间锁。

Conclusion: 动态阈值签名方案能够在安全性和可用性之间实现最佳平衡，通过时间衰减的概率机制优化阈值选择。

Abstract: We formulate the design of a threshold signature scheme as made possible on
cryptocurrency protocols like Bitcoin. The funds are secured by an m-of-n
threshold signature, where at least m signatures are needed to unlock the
funds. A user designs this scheme knowing that a malicious attacker can also
obtain the signatures with some probability. Higher thresholds offer more
security, but also risk locking the user out of his own funds. The optimal
threshold balances these twin effects. Interventions like increasing the
security or usability of the signatures allow for higher thresholds. We model
dynamic threshold signature schemes, where the probability of a user or
attacker obtaining signatures decays with time. A dynamic threshold signature
scheme is optimal, and increasing security or usability allows for higher
thresholds and longer time locks.

</details>


### [3] [Characterizing Event-themed Malicious Web Campaigns: A Case Study on War-themed Websites](https://arxiv.org/abs/2509.25410)
*Maraz Mia,Mir Mehedi A. Pritom,Tariqul Islam,Shouhuai Xu*

Main category: cs.CR

TL;DR: 本文研究了以事件为主题的恶意网站活动特征，以战争主题网站为案例，发现攻击者利用事件独特方面定制攻击，并使用可解释的无监督聚类方法为早期防御设计提供指导。


<details>
  <summary>Details</summary>
Motivation: 网络犯罪如在线诈骗日益普遍，攻击者常利用全球或区域事件作为欺诈活动主题来破坏用户信任并提高攻击成功率。这些攻击试图操纵和欺骗无辜用户与精心制作的恶意网站互动。

Method: 使用可解释的无监督聚类方法来分析事件主题恶意网站活动特征，以战争主题网站为具体案例进行研究。

Result: 发现攻击者通过利用事件的独特方面来定制攻击，表现为筹款、提供援助、收集必需品或寻求最新新闻等活动。

Conclusion: 通过可解释的无监督聚类方法获得的见解可以指导设计针对各种事件主题恶意网络活动的有效早期防御措施。

Abstract: Cybercrimes such as online scams and fraud have become prevalent.
Cybercriminals often abuse various global or regional events as themes of their
fraudulent activities to breach user trust and attain a higher attack success
rate. These attacks attempt to manipulate and deceive innocent people into
interacting with meticulously crafted websites with malicious payloads,
phishing, or fraudulent transactions. To deepen our understanding of the
problem, this paper investigates how to characterize event-themed malicious
website-based campaigns, with a case study on war-themed websites. We find that
attackers tailor their attacks by exploiting the unique aspects of events, as
evidenced by activities such as fundraising, providing aid, collecting
essential supplies, or seeking updated news. We use explainable unsupervised
clustering methods to draw further insights, which could guide the design of
effective early defenses against various event-themed malicious web campaigns.

</details>


### [4] [Finding Phones Fast: Low-Latency and Scalable Monitoring of Cellular Communications in Sensitive Areas](https://arxiv.org/abs/2509.25430)
*Martin Kotuliak,Simon Erni,Jakub Polák,Marc Roeschlin,Richard Baker,Ivan Martinovic,Srdjan Čapkun*

Main category: cs.CR

TL;DR: LTag是一个低延迟、运营商无关且可扩展的蜂窝连接监控系统，能够在用户数据传输前检测和定位未经授权的通信设备。


<details>
  <summary>Details</summary>
Motivation: 现有蜂窝监控系统缺乏实时能力，无法在敏感区域及时检测未经授权的通信设备，存在安全漏洞。

Method: 使用多个下行嗅探器和分布式上行嗅探器网络，测量下行协议信息和上行信号特征，在连接建立前进行决策。

Result: 在2.3毫秒内确定信号来源位置，能够在用户数据传输前实现及时、有针对性的通信抑制。

Conclusion: LTag填补了低延迟蜂窝监控系统的空白，为敏感区域提供了有效的安全防护解决方案。

Abstract: The widespread availability of cellular devices introduces new threat vectors
that allow users or attackers to bypass security policies and physical barriers
and bring unauthorized devices into sensitive areas. These threats can arise
from user non-compliance or deliberate actions aimed at data
exfiltration/infiltration via hidden devices, drones, etc. We identify a
critical gap in this context: the absence of low-latency systems for
high-quality and instantaneous monitoring of cellular transmissions. Such
low-latency systems are crucial to allow for timely detection, decision (e.g.,
geofencing or localization), and disruption of unauthorized communication in
sensitive areas. Operator-based monitoring systems, built for purposes such as
people counting or tracking, lack real-time capability, require cooperation
across multiple operators, and thus are hard to deploy. Operator-independent
monitoring approaches proposed in the literature either lack low-latency
capabilities or do not scale.
  We propose LTag, the first low-latency, operator-independent and scalable
system designed to monitor cellular connections across all operators prior to
any user data transmission. LTag consists of several downlink sniffers and a
distributed network of uplink sniffers that measure both downlink protocol
information and uplink signal characteristics at multiple locations to gain a
detailed spatial image of uplink signals. LTag aggregates the recorded
information, processes it, and provides a decision about the connection all
prior to connection establishment of a UE. To evaluate LTag, we deployed it in
the context of geofencing, where LTag was able to determine if the signals
originate from inside or outside of an area within 2.3 ms of the initial base
station-to-device message, therefore enabling prompt and targeted suppression
of communication before any user data was transmitted.

</details>


### [5] [Fingerprinting LLMs via Prompt Injection](https://arxiv.org/abs/2509.25448)
*Yuepeng Hu,Zhengyuan Jiang,Mengyuan Li,Osama Ahmed,Zhicong Huang,Cheng Hong,Neil Gong*

Main category: cs.CR

TL;DR: LLMPrint是一个检测LLM模型来源的框架，通过利用LLM对提示注入的固有脆弱性构建指纹，能够有效识别模型是否源自某个基础模型，即使经过后处理也能保持鲁棒性。


<details>
  <summary>Details</summary>
Motivation: 现有模型来源检测方法存在两大局限：一是需要在发布前嵌入信号，不适用于已发布模型；二是使用手工或随机提示比较模型输出，对后处理不鲁棒。

Method: 通过优化指纹提示来强制执行一致的token偏好，构建既对基础模型唯一又对后处理鲁棒的指纹，并开发适用于灰盒和黑盒场景的统一验证流程。

Result: 在5个基础模型和约700个后训练或量化变体上的评估显示，LLMPrint实现了高真阳性率，同时保持假阳性率接近零。

Conclusion: LLMPrint提供了一种有效检测LLM模型来源的方法，能够克服现有方法的局限性，在模型后处理后仍能准确识别模型关系。

Abstract: Large language models (LLMs) are often modified after release through
post-processing such as post-training or quantization, which makes it
challenging to determine whether one model is derived from another. Existing
provenance detection methods have two main limitations: (1) they embed signals
into the base model before release, which is infeasible for already published
models, or (2) they compare outputs across models using hand-crafted or random
prompts, which are not robust to post-processing. In this work, we propose
LLMPrint, a novel detection framework that constructs fingerprints by
exploiting LLMs' inherent vulnerability to prompt injection. Our key insight is
that by optimizing fingerprint prompts to enforce consistent token preferences,
we can obtain fingerprints that are both unique to the base model and robust to
post-processing. We further develop a unified verification procedure that
applies to both gray-box and black-box settings, with statistical guarantees.
We evaluate LLMPrint on five base models and around 700 post-trained or
quantized variants. Our results show that LLMPrint achieves high true positive
rates while keeping false positive rates near zero.

</details>


### [6] [Managing Differentiated Secure Connectivity using Intents](https://arxiv.org/abs/2509.25462)
*Loay Abdelrazek,Filippo Rebecchi*

Main category: cs.CR

TL;DR: 提出基于意图的安全管理框架，通过区分安全级别和扩展TM Forum意图安全本体，实现5G/6G移动网络中复杂安全需求的自动化管理。


<details>
  <summary>Details</summary>
Motivation: 5G/6G时代移动网络面临新的安全挑战，现有自动化方法缺乏表达复杂、目标驱动和可衡量安全需求的能力。

Method: 引入差异化安全级别概念，利用意图作为管理框架，扩展TM Forum意图安全本体来形式化功能性和非功能性安全需求。

Result: 建立了能够表达和建模复杂安全需求的框架，讨论了实现意图安全管理所需的标准化步骤。

Conclusion: 该工作旨在推进安全自动化，提高适应性，增强下一代移动网络的弹性和安全态势。

Abstract: Mobile networks in the 5G and 6G era require to rethink how to manage
security due to the introduction of new services, use cases, each with its own
security requirements, while simultaneously expanding the threat landscape.
Although automation has emerged as a key enabler to address complexity in
networks, existing approaches lack the expressiveness to define and enforce
complex, goal-driven, and measurable security requirements. In this paper, we
propose the concept of differentiated security levels and leveraging intents as
a management framework. We discuss the requirements and enablers to extend the
currently defined intent-based management frameworks to pave the path for
intent-based security management in mobile networks. Our approach formalizes
both functional and non-functional security requirements and demonstrates how
these can be expressed and modeled using an extended TM Forum (TMF) intent
security ontology. We further discuss the required standardization steps to
achieve intent-based security management. Our work aims at advance security
automation, improve adaptability, and strengthen the resilience and security
posture of the next-generation mobile networks.

</details>


### [7] [Balancing Compliance and Privacy in Offline CBDC Transactions Using a Secure Element-based System](https://arxiv.org/abs/2509.25469)
*Panagiotis Michalopoulos,Anthony Mack,Cameron Clark,Linus Chen,Johannes Sedlmeir,Andreas Veneris*

Main category: cs.CR

TL;DR: 本文提出了一个适用于加密货币和央行数字货币的离线支付原型，通过安全元件和数字凭证解决离线支付与监管合规之间的冲突。


<details>
  <summary>Details</summary>
Motivation: 数字货币的离线交易特性虽然提升了可扩展性和隐私保护，但也为AML/CFT监管框架带来了新的挑战，需要平衡离线支付支持与监管合规。

Method: 利用安全元件和数字凭证技术构建离线支付原型，并探索集成零知识证明以提供不同层级的隐私保护。

Result: 性能评估显示该原型可灵活适应不同监管环境，交易延迟与商业支付系统相当。

Conclusion: 该原型成功解决了离线数字货币支付与监管合规之间的紧张关系，为未来数字货币系统设计提供了可行方案。

Abstract: Blockchain technology has spawned a vast ecosystem of digital currencies with
Central Bank Digital Currencies (CBDCs) -- digital forms of fiat currency --
being one of them. An important feature of digital currencies is facilitating
transactions without network connectivity, which can enhance the scalability of
cryptocurrencies and the privacy of CBDC users. However, in the case of CBDCs,
this characteristic also introduces new regulatory challenges, particularly
when it comes to applying established Anti-Money Laundering and Countering the
Financing of Terrorism (AML/CFT) frameworks. This paper introduces a prototype
for offline digital currency payments, equally applicable to cryptocurrencies
and CBDCs, that leverages Secure Elements and digital credentials to address
the tension of offline payment support with regulatory compliance. Performance
evaluation results suggest that the prototype can be flexibly adapted to
different regulatory environments, with a transaction latency comparable to
real-life commercial payment systems. Furthermore, we conceptualize how the
integration of Zero-Knowledge Proofs into our design could accommodate various
tiers of enhanced privacy protection.

</details>


### [8] [Environmental Rate Manipulation Attacks on Power Grid Security](https://arxiv.org/abs/2509.25476)
*Yonatan Gizachew Achamyeleh,Yang Xiang,Yun-Ping Hsiao,Yasamin Moghaddas,Mohammad Abdullah Al Faruque*

Main category: cs.CR

TL;DR: 提出了一种名为环境速率操纵(ERM)的新型硬件木马触发机制，通过监测环境参数的变化速率而非绝对值来激活，能够规避传统检测方法并引发电网级联故障。


<details>
  <summary>Details</summary>
Motivation: 传统硬件木马依赖数字触发器或固定阈值条件，容易被标准测试检测。随着全球供应链复杂性增加，需要更隐蔽的触发机制来应对传感器电力电子中的安全威胁。

Method: 设计了紧凑的14μm²电路，测量标准传感器前端中电容充电速率，当检测到快速变化时破坏逆变器PWM信号。在德州仪器太阳能逆变器上进行实验验证。

Result: 实验证明ERM能够触发灾难性驱动芯片故障。ETAP模拟显示单个受感染的100kW逆变器可能引发电网级联不稳定。

Conclusion: ERM攻击的重要性超越了单个传感器，影响了电力电子中常见的各类环境传感系统，揭示了硬件安全的基本挑战。

Abstract: The growing complexity of global supply chains has made hardware Trojans a
significant threat in sensor-based power electronics. Traditional Trojan
designs depend on digital triggers or fixed threshold conditions that can be
detected during standard testing. In contrast, we introduce Environmental Rate
Manipulation (ERM), a novel Trojan triggering mechanism that activates by
monitoring the rate of change in environmental parameters rather than their
absolute values. This approach allows the Trojan to remain inactive under
normal conditions and evade redundancy and sensor-fusion defenses. We implement
a compact 14~$\mu$m$^2$ circuit that measures capacitor charging rates in
standard sensor front-ends and disrupts inverter pulse-width modulation PWM
signals when a rapid change is induced. Experiments on a commercial Texas
Instruments solar inverter demonstrate that ERM can trigger catastrophic driver
chip failure. Furthermore, ETAP simulations indicate that a single compromised
100~kW inverter may initiate cascading grid instabilities. The attack's
significance extends beyond individual sensors to entire classes of
environmental sensing systems common in power electronics, demonstrating
fundamental challenges for hardware security.

</details>


### [9] [Defeating Cerberus: Concept-Guided Privacy-Leakage Mitigation in Multimodal Language Models](https://arxiv.org/abs/2509.25525)
*Boyang Zhang,Istemi Ekin Akkus,Ruichuan Chen,Alice Dethise,Klaus Satzke,Ivica Rimac,Yang Zhang*

Main category: cs.CR

TL;DR: 本文提出了一种概念引导的缓解方法，用于防止多模态大语言模型中的个人身份信息泄露，无需重新训练即可有效拒绝PII相关任务。


<details>
  <summary>Details</summary>
Motivation: 多模态大语言模型在处理多样化模态方面表现出色，但其先进能力也带来了严重的隐私风险，特别是在个人身份信息泄露方面。目前对单模态语言模型的研究已有一定进展，但多模态环境下的漏洞尚未得到充分研究。

Method: 引入概念引导的缓解方法，识别并修改模型内部与PII相关内容相关的状态。该方法指导视觉语言模型有效且高效地拒绝PII敏感任务，无需重新训练或微调。

Result: 实验结果显示，该方法在各种PII相关任务中平均拒绝率达到93.3%，且对不相关的模型性能影响最小。

Conclusion: 该方法能够有效缓解多模态大语言模型中的PII泄露风险，在各种条件下都表现出良好的适应性。

Abstract: Multimodal large language models (MLLMs) have demonstrated remarkable
capabilities in processing and reasoning over diverse modalities, but their
advanced abilities also raise significant privacy concerns, particularly
regarding Personally Identifiable Information (PII) leakage. While relevant
research has been conducted on single-modal language models to some extent, the
vulnerabilities in the multimodal setting have yet to be fully investigated. In
this work, we investigate these emerging risks with a focus on vision language
models (VLMs), a representative subclass of MLLMs that covers the two
modalities most relevant for PII leakage, vision and text. We introduce a
concept-guided mitigation approach that identifies and modifies the model's
internal states associated with PII-related content. Our method guides VLMs to
refuse PII-sensitive tasks effectively and efficiently, without requiring
re-training or fine-tuning. We also address the current lack of multimodal PII
datasets by constructing various ones that simulate real-world scenarios.
Experimental results demonstrate that the method can achieve an average refusal
rate of 93.3% for various PII-related tasks with minimal impact on unrelated
model performances. We further examine the mitigation's performance under
various conditions to show the adaptability of our proposed method.

</details>


### [10] [Zero Trust-based Decentralized Identity Management System for Autonomous Vehicles](https://arxiv.org/abs/2509.25566)
*Amal Yousseef,Shalaka Satam,Banafsheh Saber Latibari,Mai Abdel-Malek,Soheil Salehi,Pratik Satam*

Main category: cs.CR

TL;DR: 提出了一种基于零信任的去中心化身份管理协议，用于保护自动驾驶车辆的通信安全，通过区块链技术实现无需中心化权威的连续验证。


<details>
  <summary>Details</summary>
Motivation: 自动驾驶车辆日益增长的连接性带来了新的网络安全挑战，传统的基于边界的安全模型无法适应动态和不可信环境。

Method: 结合零信任架构核心原则与区块链网络的防篡改和去中心化特性，使用Hyperledger Iroha实现轻量级安全认证。

Result: 实验验证显示协议引入的开销最小，在城市环境中包接收率降低不到7.5%，LTE-V2X信道繁忙率增加低于11%。

Conclusion: 该协议为保护实时V2X通信免受冒充和重放攻击提供了高效且鲁棒的基础框架。

Abstract: The rise of autonomous vehicles (AVs) promises to significantly enhance
transportation safety and efficiency by mitigating human error, which is
responsible for over 90\% of road accidents. However, the increasing
connectivity of AVs introduces new cybersecurity challenges, as traditional
perimeter-based security models are inadequate for dynamic and untrusted
environments. This paper presents a novel Zero Trust-based Decentralized
Identity Management (D-IM) protocol for AVs. By integrating the core principles
of Zero Trust Architecture, "never trust, always verify", with the tamper
resistant and decentralized nature of a blockchain network, our framework
eliminates reliance on centralized authorities and provides continuous
verification for every entity. We detail the system's design, which leverages
Hyperledger Iroha to enable lightweight and secure authentication without a
central trusted entity. A comprehensive experimental evaluation, conducted
across both urban and highway scenarios, validates the protocol's practicality.
Our results demonstrate that the D-IM framework introduces minimal overhead,
with less than 7.5\% reduction in Packet Reception Rate (PRR) in urban settings
and an increase of under 11\% in Channel Busy Ratio (CBR) for LTE-V2X. These
findings prove the protocol's efficiency and robustness, providing a resilient
foundation for securing real-time V2X communication against impersonation and
replay attacks.

</details>


### [11] [STAC: When Innocent Tools Form Dangerous Chains to Jailbreak LLM Agents](https://arxiv.org/abs/2509.25624)
*Jing-Jing Li,Jianfeng He,Chao Shang,Devang Kulshreshtha,Xun Xian,Yi Zhang,Hang Su,Sandesh Swamy,Yanjun Qi*

Main category: cs.CR

TL;DR: 本文提出了STAC攻击框架，通过将看似无害的工具调用串联起来，在最终执行步骤实现有害操作，揭示了LLM代理在工具使用中的安全漏洞。


<details>
  <summary>Details</summary>
Motivation: 随着LLM发展为具有工具使用能力的自主代理，传统的内容安全防护已不足以应对新的安全挑战，需要研究针对工具使用的多步攻击。

Method: 采用闭环流水线设计，自动合成可执行的多步工具链，通过环境执行验证，并逆向工程生成隐蔽的多轮提示，诱导代理执行已验证的恶意序列。

Result: 评估显示最先进的LLM代理（包括GPT-4.1）对STAC攻击高度脆弱，攻击成功率超过90%。提出的推理驱动防御提示可将攻击成功率降低28.8%。

Conclusion: 防御工具启用的代理需要在整个动作序列及其累积效应上进行推理，而不是孤立评估提示或响应。

Abstract: As LLMs advance into autonomous agents with tool-use capabilities, they
introduce security challenges that extend beyond traditional content-based LLM
safety concerns. This paper introduces Sequential Tool Attack Chaining (STAC),
a novel multi-turn attack framework that exploits agent tool use. STAC chains
together tool calls that each appear harmless in isolation but, when combined,
collectively enable harmful operations that only become apparent at the final
execution step. We apply our framework to automatically generate and
systematically evaluate 483 STAC cases, featuring 1,352 sets of
user-agent-environment interactions and spanning diverse domains, tasks, agent
types, and 10 failure modes. Our evaluations show that state-of-the-art LLM
agents, including GPT-4.1, are highly vulnerable to STAC, with attack success
rates (ASR) exceeding 90% in most cases. The core design of STAC's automated
framework is a closed-loop pipeline that synthesizes executable multi-step tool
chains, validates them through in-environment execution, and reverse-engineers
stealthy multi-turn prompts that reliably induce agents to execute the verified
malicious sequence. We further perform defense analysis against STAC and find
that existing prompt-based defenses provide limited protection. To address this
gap, we propose a new reasoning-driven defense prompt that achieves far
stronger protection, cutting ASR by up to 28.8%. These results highlight a
crucial gap: defending tool-enabled agents requires reasoning over entire
action sequences and their cumulative effects, rather than evaluating isolated
prompts or responses.

</details>


### [12] [Better Privilege Separation for Agents by Restricting Data Types](https://arxiv.org/abs/2509.25926)
*Dennis Jacob,Emad Alghamdi,Zhanhao Hu,Basel Alomair,David Wagner*

Main category: cs.CR

TL;DR: 提出了一种基于类型导向权限分离的方法来系统性地防止LLM的提示注入攻击，通过将不受信任的内容转换为受限的数据类型来消除注入可能性。


<details>
  <summary>Details</summary>
Motivation: 大型语言模型在自动化语言处理系统中广泛应用，但容易受到提示注入攻击，现有检测器和微调方法存在适应性攻击漏洞或无法用于最新模型。

Method: 采用类型导向权限分离，将第三方数据转换为经过筛选的数据类型集合，每种数据类型在范围和内容上受限，从而消除提示注入的可能性。

Result: 通过多个案例研究评估，发现基于该方法的设计能够系统性地防止提示注入攻击，同时保持高实用性。

Conclusion: 类型导向权限分离为LLM提供了一种有效的系统性防御机制，能够在保持功能性的同时防止提示注入攻击。

Abstract: Large language models (LLMs) have become increasingly popular due to their
ability to interact with unstructured content. As such, LLMs are now a key
driver behind the automation of language processing systems, such as AI agents.
Unfortunately, these advantages have come with a vulnerability to prompt
injections, an attack where an adversary subverts the LLM's intended
functionality with an injected task. Past approaches have proposed detectors
and finetuning to provide robustness, but these techniques are vulnerable to
adaptive attacks or cannot be used with state-of-the-art models. To this end we
propose type-directed privilege separation for LLMs, a method that
systematically prevents prompt injections. We restrict the ability of an LLM to
interact with third-party data by converting untrusted content to a curated set
of data types; unlike raw strings, each data type is limited in scope and
content, eliminating the possibility for prompt injections. We evaluate our
method across several case studies and find that designs leveraging our
principles can systematically prevent prompt injection attacks while
maintaining high utility.

</details>


### [13] [SoK: Systematic analysis of adversarial threats against deep learning approaches for autonomous anomaly detection systems in SDN-IoT networks](https://arxiv.org/abs/2509.26350)
*Tharindu Lakshan Yasarathna,Nhien-An Le-Khac*

Main category: cs.CR

TL;DR: 本文系统分析了SDN-IoT网络中基于深度学习的异常攻击检测系统面临的对抗性攻击威胁，提出了结构化威胁模型和攻击分类法，评估了不同攻击策略的影响，并提出了适应性防御措施。


<details>
  <summary>Details</summary>
Motivation: SDN与IoT的集成增强了网络控制和灵活性，基于DL的AAD系统提高了安全性，但这些系统容易受到对抗性攻击，现有研究缺乏对SDN-IoT环境中DL-based AAD系统对抗性漏洞的系统分析。

Method: 引入结构化对抗威胁模型和全面的攻击分类法，将攻击分为数据级、模型级和混合级威胁，系统评估白盒、黑盒和灰盒攻击策略在流行基准数据集上的表现。

Result: 对抗性攻击可使检测准确率降低高达48.4%，成员推理攻击造成最显著下降，C&W和DeepFool实现高逃避成功率，对抗性训练增强了鲁棒性但计算开销大。

Conclusion: 本研究强调了现有DL-based AAD模型的关键漏洞，提出了改进弹性、可解释性和计算效率的实用建议，为研究人员和从业者提供了系统化的对抗威胁模型和防御评估框架。

Abstract: Integrating SDN and the IoT enhances network control and flexibility.
DL-based AAD systems improve security by enabling real-time threat detection in
SDN-IoT networks. However, these systems remain vulnerable to adversarial
attacks that manipulate input data or exploit model weaknesses, significantly
degrading detection accuracy. Existing research lacks a systematic analysis of
adversarial vulnerabilities specific to DL-based AAD systems in SDN-IoT
environments. This SoK study introduces a structured adversarial threat model
and a comprehensive taxonomy of attacks, categorising them into data, model,
and hybrid-level threats. Unlike previous studies, we systematically evaluate
white, black, and grey-box attack strategies across popular benchmark datasets.
Our findings reveal that adversarial attacks can reduce detection accuracy by
up to 48.4%, with Membership Inference causing the most significant drop. C&W
and DeepFool achieve high evasion success rates. However, adversarial training
enhances robustness, and its high computational overhead limits the real-time
deployment of SDN-IoT applications. We propose adaptive countermeasures,
including real-time adversarial mitigation, enhanced retraining mechanisms, and
explainable AI-driven security frameworks. By integrating structured threat
models, this study offers a more comprehensive approach to attack
categorisation, impact assessment, and defence evaluation than previous
research. Our work highlights critical vulnerabilities in existing DL-based AAD
models and provides practical recommendations for improving resilience,
interpretability, and computational efficiency. This study serves as a
foundational reference for researchers and practitioners seeking to enhance
DL-based AAD security in SDN-IoT networks, offering a systematic adversarial
threat model and conceptual defence evaluation based on prior empirical
studies.

</details>


### [14] [Exact Bias of Linear TRNG Correctors -- Spectral Approach](https://arxiv.org/abs/2509.26393)
*Maciej Skorski,Francisco-Javier Soto,Onur Günlü*

Main category: cs.CR

TL;DR: 本文通过傅里叶分析建立了真随机数生成器中线性提取器的精确安全界限，提供了首个接近最优的总变差安全特性描述，改进了之前近似方法的安全评估。


<details>
  <summary>Details</summary>
Motivation: 研究真随机数生成器中线性提取器的安全界限，通过精确分析来改进之前的安全评估方法，揭示压缩效率与密码安全之间的基本权衡。

Method: 使用傅里叶分析，通过代码权重枚举器和输入偏置参数在最优ℓ∞和ℓ2范数结果之间进行插值，扫描约20,000个代码来研究安全特性。

Result: 安全评估比之前的近似方法提高了一个数量级，揭示了压缩效率与密码安全之间的基本权衡，例如实现80位安全可能需要牺牲超过50%的代码率来纠正10%的输入偏置。

Conclusion: 所建立的界限增强了TRNG后处理方案的安全评估，并量化了硬件实现中随机性提取的固有成本。

Abstract: Using Fourier analysis, this paper establishes exact security bounds for
linear extractors in True Random Number Generators (TRNGs). We provide the
first near-optimal total variation security characterization by interpolating
between optimal $\ell_{\infty}$ and $\ell_2$ norm results, expressed through
code weight enumerators and input bias parameters. Our bounds improve security
assessments by an order of magnitude over previous approximations. By scanning
~20,000 codes, we reveal fundamental trade-offs between compression efficiency
and cryptographic security. For instance, we show that achieving 80 bits of
security can require sacrificing more than 50\% of the code rate when
correcting 10\% input bias. Our bounds enhance security evaluation of TRNG
post-processing schemes and quantify the inherent cost of randomness extraction
in hardware implementations.

</details>


### [15] [SeedPrints: Fingerprints Can Even Tell Which Seed Your Large Language Model Was Trained From](https://arxiv.org/abs/2509.26404)
*Yao Tong,Haonan Wang,Siquan Li,Kenji Kawaguchi,Tianyang Hu*

Main category: cs.CR

TL;DR: SeedPrints是一种基于随机初始化偏见的LLM指纹识别方法，能够在训练前就提取模型的内在身份标识，并在整个训练周期中保持稳定。


<details>
  <summary>Details</summary>
Motivation: 现有LLM指纹识别方法依赖于训练后的特性，存在收敛前不可靠、对分布变化敏感的问题。需要一种更内在、更持久的身份验证方法。

Method: 利用模型在随机初始化时产生的token选择偏见作为指纹，这些偏见仅依赖于初始化参数，在训练过程中保持稳定，通过统计检测方法恢复模型谱系。

Result: 在LLaMA和Qwen系列模型上的实验表明，SeedPrints能够实现种子级别的区分度，提供从初始化到整个生命周期的身份验证，在大规模预训练模型和基准测试中表现出色。

Conclusion: 初始化过程本身就在神经语言模型中留下了独特且持久的身份印记，形成了真正的'Galtonian'指纹，为LLM溯源和归属验证提供了可靠方法。

Abstract: Fingerprinting Large Language Models (LLMs) is essential for provenance
verification and model attribution. Existing methods typically extract post-hoc
signatures based on training dynamics, data exposure, or hyperparameters --
properties that only emerge after training begins. In contrast, we propose a
stronger and more intrinsic notion of LLM fingerprinting: SeedPrints, a method
that leverages random initialization biases as persistent, seed-dependent
identifiers present even before training. We show that untrained models exhibit
reproducible token selection biases conditioned solely on their parameters at
initialization. These biases are stable and measurable throughout training,
enabling our statistical detection method to recover a model's lineage with
high confidence. Unlike prior techniques, unreliable before convergence and
vulnerable to distribution shifts, SeedPrints remains effective across all
training stages and robust under domain shifts or parameter modifications.
Experiments on LLaMA-style and Qwen-style models show that SeedPrints achieves
seed-level distinguishability and can provide birth-to-lifecycle identity
verification akin to a biometric fingerprint. Evaluations on large-scale
pretrained models and fingerprinting benchmarks further confirm its
effectiveness under practical deployment scenarios. These results suggest that
initialization itself imprints a unique and persistent identity on neural
language models, forming a true ''Galtonian'' fingerprint.

</details>


### [16] [Logic Solver Guided Directed Fuzzing for Hardware Designs](https://arxiv.org/abs/2509.26509)
*Raghul Saravanan,Sai Manoj P D*

Main category: cs.CR

TL;DR: TargetFuzz是一种创新的定向硬件模糊测试机制，利用SAT技术专注于硬件设计的特定区域，在硬件抽象级别操作，提供更精确和全面的验证。


<details>
  <summary>Details</summary>
Motivation: 现代IC设计流程中硬件设计的增量更新和修改需要严格验证，延长了验证周期。现有硬件模糊测试器依赖等效软件模型，无法捕捉硬件固有特性。

Method: 采用SAT技术，在硬件抽象级别操作，专注于硬件设计的特定区域进行定向模糊测试。

Result: 在多种RTL设计中，TargetFuzz能够有效覆盖广泛的目标站点，处理目标站点能力提高30倍，实现100%状态覆盖，站点覆盖速度快1.5倍，目标状态覆盖比覆盖率引导模糊测试提高90倍。

Conclusion: TargetFuzz在定向硬件模糊测试方面具有显著优势，能够推进该领域的技术发展。

Abstract: The ever-increasing complexity of design specifications for processors and
intellectual property (IP) presents a formidable challenge for early bug
detection in the modern IC design cycle. The recent advancements in hardware
fuzzing have proven effective in detecting bugs in RTL designs of cutting-edge
processors. The modern IC design flow involves incremental updates and
modifications to the hardware designs necessitating rigorous verification and
extending the overall verification period. To accelerate this process, directed
fuzzing has emerged focusing on generating targeted stimuli for specific
regions of the design, avoiding the need for exhaustive, full-scale
verification. However, a significant limitation of these hardware fuzzers lies
in their reliance on an equivalent SW model of the hardware which fails to
capture intrinsic hardware characteristics. To circumvent the aforementioned
challenges, this work introduces TargetFuzz, an innovative and scalable
targeted hardware fuzzing mechanism. It leverages SAT-based techniques to focus
on specific regions of the hardware design while operating at its native
hardware abstraction level, ensuring a more precise and comprehensive
verification process. We evaluated this approach across a diverse range of RTL
designs for various IP cores. Our experimental results demonstrate its
capability to effectively target and fuzz a broad spectrum of sites within
these designs, showcasing its extensive coverage and precision in addressing
targeted regions. TargetFuzz demonstrates its capability to effectively scale
30x greater in terms of handling target sites, achieving 100% state coverage
and 1.5x faster in terms of site coverage, and shows 90x improvement in target
state coverage compared to Coverage-Guided Fuzzing, demonstrating its potential
to advance the state-of-the-art in directed hardware fuzzing.

</details>


### [17] [Explainable and Resilient ML-Based Physical-Layer Attack Detectors](https://arxiv.org/abs/2509.26530)
*Aleksandra Knapińska,Marija Furdek*

Main category: cs.CR

TL;DR: 本文提出了一种可解释的物理层攻击检测方法，分析了不同分类器的内部工作机制，并评估了检测器对恶意参数噪声的鲁棒性。


<details>
  <summary>Details</summary>
Motivation: 随着机器学习技术在网络安全检测中的广泛应用，模型变得越来越复杂和难以解释，因此需要开发可解释的物理层攻击检测方法。

Method: 首先分析各种分类器在检测物理层入侵时的内部工作机制，研究不同监控参数对检测不同类型攻击的影响；然后评估检测器对恶意参数噪声的鲁棒性。

Result: 分析不仅提高了模型的可解释性，还为提升检测速度提供了设计思路；研究揭示了模型速度与鲁棒性之间的关键权衡关系。

Conclusion: 这项工作为基于可用网络监控数据开发快速且鲁棒的检测器提供了设计指南。

Abstract: Detection of emerging attacks on network infrastructure is a critical aspect
of security management. To meet the growing scale and complexity of modern
threats, machine learning (ML) techniques offer valuable tools for automating
the detection of malicious activities. However, as these techniques become more
complex, their internal operations grow increasingly opaque. In this context,
we address the need for explainable physical-layer attack detection methods.
First, we analyze the inner workings of various classifiers trained to alert
about physical layer intrusions, examining how the influence of different
monitored parameters varies depending on the type of attack being detected.
This analysis not only improves the interpretability of the models but also
suggests ways to enhance their design for increased speed. In the second part,
we evaluate the detectors' resilience to malicious parameter noising. The
results highlight a key trade-off between model speed and resilience. This work
serves as a design guideline for developing fast and robust detectors trained
on available network monitoring data.

</details>


### [18] [DeepProv: Behavioral Characterization and Repair of Neural Networks via Inference Provenance Graph Analysis](https://arxiv.org/abs/2509.26562)
*Firas Ben Hmida,Abderrahmen Amich,Ata Kaboudi,Birhanu Eshete*

Main category: cs.CR

TL;DR: DeepProv是一个可定制的系统，通过推理溯源图(IPGs)捕获和表征DNN在推理过程中的运行时行为，并基于此系统性地修复DNN以提升鲁棒性、隐私性或公平性。


<details>
  <summary>Details</summary>
Motivation: 深度神经网络在高风险应用中的部署日益增多，但其在真实场景中的不可预测和不可靠行为需要新的方法来确保其可靠性。

Method: 利用系统审计溯源图的灵感，DeepProv通过推理溯源图(IPGs)建模DNN推理过程的计算信息流，提供详细的结构化行为表示，支持经验和结构分析。

Result: 在对抗鲁棒性修复案例中，仅修复DNN单层即可平均提升55%的对抗精度，且与现有防御方法互补，显著增强模型鲁棒性。

Conclusion: DeepProv不仅有效提升DNN鲁棒性，还展示了在隐私审计和公平性分析等其他关键领域的适应性潜力。

Abstract: Deep neural networks (DNNs) are increasingly being deployed in high-stakes
applications, from self-driving cars to biometric authentication. However,
their unpredictable and unreliable behaviors in real-world settings require new
approaches to characterize and ensure their reliability.
  This paper introduces DeepProv, a novel and customizable system designed to
capture and characterize the runtime behavior of DNNs during inference by using
their underlying graph structure. Inspired by system audit provenance graphs,
DeepProv models the computational information flow of a DNN's inference process
through Inference Provenance Graphs (IPGs). These graphs provide a detailed
structural representation of the behavior of DNN, allowing both empirical and
structural analysis. DeepProv uses these insights to systematically repair DNNs
for specific objectives, such as improving robustness, privacy, or fairness.
  We instantiate DeepProv with adversarial robustness as the goal of model
repair and conduct extensive case studies to evaluate its effectiveness. Our
results demonstrate its effectiveness and scalability across diverse
classification tasks, attack scenarios, and model complexities. DeepProv
automatically identifies repair actions at the node and edge-level within IPGs,
significantly enhancing the robustness of the model. In particular, applying
DeepProv repair strategies to just a single layer of a DNN yields an average
55% improvement in adversarial accuracy. Moreover, DeepProv complements
existing defenses, achieving substantial gains in adversarial robustness.
Beyond robustness, we demonstrate the broader potential of DeepProv as an
adaptable system to characterize DNN behavior in other critical areas, such as
privacy auditing and fairness analysis.

</details>


### [19] [Are Robust LLM Fingerprints Adversarially Robust?](https://arxiv.org/abs/2509.26598)
*Anshul Nasery,Edoardo Contente,Alkin Kaz,Pramod Viswanath,Sewoong Oh*

Main category: cs.CR

TL;DR: 该论文系统评估了模型指纹认证方案的对抗鲁棒性，发现现有方案在面对恶意模型托管者时存在根本性漏洞，并开发了针对性的对抗攻击方法。


<details>
  <summary>Details</summary>
Motivation: 当前模型指纹认证方案的鲁棒性评估主要关注良性扰动，缺乏对恶意模型托管者的系统性对抗鲁棒性研究，导致现有系统存在安全漏洞。

Method: 首先定义了针对模型指纹认证的具体威胁模型，然后分析现有指纹方案的根本漏洞，并针对每个漏洞开发了自适应的对抗攻击方法。

Result: 实验表明，这些对抗攻击能够完全绕过10个最新指纹认证方案的验证，同时保持模型对终端用户的高可用性。

Conclusion: 研究鼓励指纹设计者在设计阶段就考虑对抗鲁棒性，并为未来的指纹方法提供了建议。

Abstract: Model fingerprinting has emerged as a promising paradigm for claiming model
ownership. However, robustness evaluations of these schemes have mostly focused
on benign perturbations such as incremental fine-tuning, model merging, and
prompting. Lack of systematic investigations into {\em adversarial robustness}
against a malicious model host leaves current systems vulnerable. To bridge
this gap, we first define a concrete, practical threat model against model
fingerprinting. We then take a critical look at existing model fingerprinting
schemes to identify their fundamental vulnerabilities. Based on these, we
develop adaptive adversarial attacks tailored for each vulnerability, and
demonstrate that these can bypass model authentication completely for ten
recently proposed fingerprinting schemes while maintaining high utility of the
model for the end users. Our work encourages fingerprint designers to adopt
adversarial robustness by design. We end with recommendations for future
fingerprinting methods.

</details>
