<div id=toc></div>

# Table of Contents

- [cs.CR](#cs.CR) [Total: 8]


<div id='cs.CR'></div>

# cs.CR [[Back]](#toc)

### [1] [Boost+: Equitable, Incentive-Compatible Block Building](https://arxiv.org/abs/2602.04007)
*Mengqian Zhang,Sen Yang,Kartik Nayak,Fan Zhang*

Main category: cs.CR

TL;DR: Boost+ 是一个去中心化的区块构建系统，通过将交易收集和排序解耦来确保公平访问，解决 MEV-Boost 的中心化问题。


<details>
  <summary>Details</summary>
Motivation: 当前以太坊的区块构建生态系统 MEV-Boost 高度中心化，这扭曲了竞争、降低了区块空间效率，并模糊了 MEV 流的透明度。需要保证区块构建的公平性和经济效率。

Method: 提出 Boost+ 系统，将区块构建过程解耦为交易收集和排序两个阶段。核心是机制 M_Boost+，围绕默认算法构建，确保搜索者和构建者的激励一致。实现了一个基于真实交易经验分析的具体默认算法。

Result: M_Boost+ 机制中，诚实出价是所有构建者的主导策略。对于搜索者，当默认算法优于竞争构建者时，诚实报告是主导策略；对于所有无冲突交易，即使构建者可能获胜，诚实报告仍然是主导策略。即使搜索者技术上可以与构建者整合，非整合结合诚实出价仍然优于任何偏离策略。

Conclusion: Boost+ 通过解耦交易收集和排序，确保了区块构建的公平性和效率，解决了 MEV-Boost 的中心化问题，为所有参与者提供了更好的激励兼容性。

Abstract: Block space on the blockchain is scarce and must be allocated efficiently through block building. However, Ethereum's current block-building ecosystem, MEV-Boost, has become highly centralized due to integration, which distorts competition, reduces blockspace efficiency, and obscures MEV flow transparency. To guarantee equitability and economic efficiency in block building, we propose $\mathrm{Boost+}$, a system that decouples the process into collecting and ordering transactions, and ensures equal access to all collected transactions.
  The core of $\mathrm{Boost+}$ is the mechanism $\mathit{M}_{\mathrm{Boost+}}$, built around a default algorithm. $\mathit{M}_{\mathrm{Boost+}}$ aligns incentives for both searchers (intermediaries that generate or route transactions) and builders: Truthful bidding is a dominant strategy for all builders. For searchers, truthful reporting is dominant whenever the default algorithm dominates competing builders, and it remains dominant for all conflict-free transactions, even when builders may win. We further show that even if a searcher can technically integrate with a builder, non-integration combined with truthful bidding still dominates any deviation for conflict-free transactions. We also implement a concrete default algorithm informed by empirical analysis of real-world transactions and evaluate its efficacy using historical transaction data.

</details>


### [2] [Evaluating the Vulnerability Landscape of LLM-Generated Smart Contracts](https://arxiv.org/abs/2602.04039)
*Hoang Long Do,Nasrin Sohrabi,Muneeb Ul Hassan*

Main category: cs.CR

TL;DR: LLM生成的智能合约存在严重安全漏洞，不适合直接部署到生产环境，需要采取安全措施


<details>
  <summary>Details</summary>
Motivation: 随着LLM在智能合约开发中的广泛应用，但对其生成代码的安全性影响缺乏足够理解，特别是在不可修改的区块链环境中，安全至关重要

Method: 对ChatGPT、Gemini、Sonnet等先进LLM生成的Solidity智能合约进行系统性安全分析，评估其对抗已知漏洞的能力

Result: 尽管LLM生成的合约语法正确且功能完整，但经常表现出严重的安全缺陷，可能在实际环境中被利用，并识别了不同模型间的重复弱点模式

Conclusion: 需要制定实际对策和开发指南来降低风险，为开发者和研究人员提供可行见解，支持LLM在智能合约开发中的安全集成，加强区块链生态系统的整体安全

Abstract: Large language models (LLMs) have been widely adopted in modern software development lifecycles, where they are increasingly used to automate and assist code generation, significantly improving developer productivity and reducing development time. In the blockchain domain, developers increasingly rely on LLMs to generate and maintain smart contracts, the immutable, self-executing components of decentralized applications. Because deployed smart contracts cannot be modified, correctness and security are paramount, particularly in high-stakes domains such as finance and governance. Despite this growing reliance, the security implications of LLM-generated smart contracts remain insufficiently understood.
  In this work, we conduct a systematic security analysis of Solidity smart contracts generated by state-of-the-art LLMs, including ChatGPT, Gemini, and Sonnet. We evaluate these contracts against a broad set of known smart contract vulnerabilities to assess their suitability for direct deployment in production environments. Our extensive experimental study shows that, despite their syntactic correctness and functional completeness, LLM-generated smart contracts frequently exhibit severe security flaws that could be exploited in real-world settings. We further analyze and categorize these vulnerabilities, identifying recurring weakness patterns across different models. Finally, we discuss practical countermeasures and development guidelines to help mitigate these risks, offering actionable insights for both developers and researchers. Our findings aim to support safe integration of LLMs into smart contract development workflows and to strengthen the overall security of the blockchain ecosystem against future security failures.

</details>


### [3] [ZKBoost: Zero-Knowledge Verifiable Training for XGBoost](https://arxiv.org/abs/2602.04113)
*Nikolas Melissaris,Jiayi Xu,Antigoni Polychroniadou,Akira Takahashi,Chenkai Weng*

Main category: cs.CR

TL;DR: ZKBoost：首个XGBoost零知识训练证明协议，允许模型所有者证明在承诺数据集上的正确训练，同时不泄露数据或参数。


<details>
  <summary>Details</summary>
Motivation: 随着梯度提升决策树（特别是XGBoost）在敏感场景中的部署增加，需要密码学保证模型完整性。现有方法缺乏对XGBoost训练过程的零知识证明能力。

Method: 提出三个关键贡献：1）兼容算术电路的定点XGBoost实现；2）通用的XGBoost零知识训练证明模板；3）基于VOLE的实例化方案，解决非线性定点运算的证明挑战。

Result: 定点实现与标准XGBoost精度相差在1%以内，能够在真实数据集上实现实用的零知识训练证明。

Conclusion: ZKBoost是首个XGBoost零知识训练证明协议，为敏感场景中的模型部署提供了密码学完整性保证，同时保持了模型性能。

Abstract: Gradient boosted decision trees, particularly XGBoost, are among the most effective methods for tabular data. As deployment in sensitive settings increases, cryptographic guarantees of model integrity become essential. We present ZKBoost, the first zero-knowledge proof of training (zkPoT) protocol for XGBoost, enabling model owners to prove correct training on a committed dataset without revealing data or parameters. We make three key contributions: (1) a fixed-point XGBoost implementation compatible with arithmetic circuits, enabling instantiation of efficient zkPoT, (2) a generic template of zkPoT for XGBoost, which can be instantiated with any general-purpose ZKP backend, and (3) vector oblivious linear evaluation (VOLE)-based instantiation resolving challenges in proving nonlinear fixed-point operations. Our fixed-point implementation matches standard XGBoost accuracy within 1\% while enabling practical zkPoT on real-world datasets.

</details>


### [4] [Availability Attacks Without an Adversary: Evidence from Enterprise LANs](https://arxiv.org/abs/2602.04216)
*Rajendra Paudyal,Rajendra Upadhyay,Al Nahian Bin Emran,Lisa Donnan,Duminda Wijesekera*

Main category: cs.CR

TL;DR: 研究发现企业网络中常规的笔记本插拔行为会触发RSTP控制平面快速重计算，导致2-4秒的短暂转发中断，影响实时流媒体服务，属于非恶意内部人员驱动的可用性破坏。


<details>
  <summary>Details</summary>
Motivation: 企业网络中的拒绝服务条件通常归因于恶意行为者，但可用性也可能因良性的非恶意内部行为而受损。本文旨在研究常规用户终端插拔行为如何影响网络可用性。

Method: 对生产型企业局域网进行实证研究，分析用户终端常规插拔行为如何触发快速生成树协议(RSTP)控制平面的快速重计算，并将此现象映射到NIST和MITRE内部威胁框架。

Result: 研究发现常规插拔行为虽然符合协议且非恶意，但会引入持续约2-4秒的短暂转发中断，降低实时流媒体（语音和视频）服务质量，而传统安全监控通常无法检测到这些中断。

Conclusion: 明确配置边缘端口可有效缓解此问题而不影响环路预防，这属于非恶意内部人员驱动的可用性破坏，需要更细致的网络配置来避免常规操作对服务可用性的影响。

Abstract: Denial-of-Service (DoS) conditions in enterprise networks are commonly attributed to malicious actors. However, availability can also be compromised by benign non-malicious insider behavior. This paper presents an empirical study of a production enterprise LAN that demonstrates how routine docking and undocking of user endpoints repeatedly trigger rapid recalculations of the control plane of the Rapid Spanning Tree Protocol (RSTP) [1]. Although protocol-compliant and nonmalicious, these events introduce transient forwarding disruptions of approximately 2-4 seconds duration that degrade realtime streaming (voice and video) services while remaining largely undetected by conventional security monitoring. We map this phenomenon to the NIST and MITRE insider threat frameworks, characterizing it as an unintentional insider-driven availability breach, and demonstrate that explicit edge-port configuration effectively mitigates the condition without compromising loop prevention

</details>


### [5] [Post-Quantum Identity-Based TLS for 5G Service-Based Architecture and Cloud-Native Infrastructure](https://arxiv.org/abs/2602.04238)
*Vipin Kumar Rathi,Lakshya Chopra,Nikhil Kumar Rajput*

Main category: cs.CR

TL;DR: 提出基于后量子身份基加密的证书免认证框架，用于私有分布式系统，替代传统PKI和证书签名认证，减少操作开销并提升性能。


<details>
  <summary>Details</summary>
Motivation: 云原生应用平台和5G核心网等延迟敏感系统依赖证书PKI和mTLS进行服务间通信安全，但传统模型带来显著操作和性能开销，在后量子场景下因大证书和昂贵签名验证而进一步加剧。

Method: 设计基于后量子身份基加密的认证框架，用身份派生密钥和身份基密钥封装替代证书和签名认证，实现无需证书传输或验证的相互认证TLS连接。提出基于阈值私钥生成器的IBE替代私有PKI方案，包括身份生命周期管理。

Result: 将该框架应用于云原生应用部署和5G核心网，展示身份基TLS如何与5G服务化架构集成并保持安全语义和3GPP要求，同时证明相同架构可替代Kubernetes中的私有PKI而不破坏现有信任域或部署模型。

Conclusion: 基于后量子IBE的证书免认证框架为私有分布式系统提供了更高效、更轻量的安全解决方案，特别适用于云原生和5G等延迟敏感环境，能显著减少传统PKI带来的操作和性能开销。

Abstract: Cloud-native application platforms and latency-sensitive systems such as 5G Core networks rely heavily on certificate-based Public Key Infrastructure (PKI) and mutual TLS to secure service-to-service communication. While effective, this model introduces significant operational and performance overhead, which is further amplified in the post-quantum setting due to large certificates and expensive signature verification. In this paper, we present a certificate-free authentication framework for private distributed systems based on post-quantum Identity-Based Encryption(IBE). Our design replaces certificate and signature based authentication with identity-derived keys and identity-based key encapsulation, enabling mutually authenticated TLS connections without certificate transmission or validation. We describe an IBE-based replacement for private PKI, including identity lifecycle management, and show how it can be instantiated using a threshold Private Key Generator (T-PKG). We apply this framework to cloud-native application deployments and latency-sensitive 5G Core networks. In particular, we demonstrate how identity-based TLS integrates with the 5G Service-Based Architecture while preserving security semantics and 3GPP requirements, and we show how the same architecture can replace private PKI in Kubernetes, including its control plane, without disrupting existing trust domains or deployment models.

</details>


### [6] [Optimal conversion from Rényi Differential Privacy to $f$-Differential Privacy](https://arxiv.org/abs/2602.04562)
*Anneliese Riess,Juan Felipe Gomez,Flavio du Pin Calmon,Julia Anne Schnabel,Georgios Kaissis*

Main category: cs.CR

TL;DR: 证明了将Rényi差分隐私(RDP)轮廓转换为假设检验权衡函数的最优规则：基于单阶RDP隐私区域交集的转换规则在所有有效RDP轮廓和所有Type I错误水平α下都是最优的。


<details>
  <summary>Details</summary>
Motivation: 解决Zhu等人(2022)附录F.3中提出的猜想：在所有将RDP轮廓映射到有效假设检验权衡函数的转换规则中，确定基于单阶RDP隐私区域交集的规则是否最优。

Method: 利用RDP隐私区域的精确几何特征，特别是其凸性和边界完全由伯努利机制决定的特性。通过几何分析证明最优转换规则是单阶边界函数的逐点上确界。

Result: 证明了f_{ρ(·)}(α) = sup_{τ≥0.5} f_{τ,ρ(τ)}(α)是所有有效RDP轮廓和所有Type I错误水平α下的最优转换规则，即"交集规则"不仅有效而且最优。

Conclusion: 基于单阶RDP隐私区域交集的转换规则是RDP到假设检验权衡函数转换的极限，在Blackwell意义上无法被其他黑盒转换规则一致超越，这标志着仅从RDP保证推断机制隐私性的根本极限。

Abstract: We prove the conjecture stated in Appendix F.3 of [Zhu et al. (2022)]: among all conversion rules that map a Rényi Differential Privacy (RDP) profile $τ\mapsto ρ(τ)$ to a valid hypothesis-testing trade-off $f$, the rule based on the intersection of single-order RDP privacy regions is optimal. This optimality holds simultaneously for all valid RDP profiles and for all Type I error levels $α$. Concretely, we show that in the space of trade-off functions, the tightest possible bound is $f_{ρ(\cdot)}(α) = \sup_{τ\geq 0.5} f_{τ,ρ(τ)}(α)$: the pointwise maximum of the single-order bounds for each RDP privacy region. Our proof unifies and sharpens the insights of [Balle et al. (2019)], [Asoodeh et al. (2021)], and [Zhu et al. (2022)]. Our analysis relies on a precise geometric characterization of the RDP privacy region, leveraging its convexity and the fact that its boundary is determined exclusively by Bernoulli mechanisms. Our results establish that the "intersection-of-RDP-privacy-regions" rule is not only valid, but optimal: no other black-box conversion can uniformly dominate it in the Blackwell sense, marking the fundamental limit of what can be inferred about a mechanism's privacy solely from its RDP guarantees.

</details>


### [7] [Inference-Time Backdoors via Hidden Instructions in LLM Chat Templates](https://arxiv.org/abs/2602.04653)
*Ariel Fogel,Omer Hofman,Eilon Cohen,Roman Vainshtein*

Main category: cs.CR

TL;DR: 攻击者通过修改聊天模板而非模型权重，在开源语言模型中植入推理时后门，无需访问训练管道或部署基础设施，且能绕过现有安全扫描。


<details>
  <summary>Details</summary>
Motivation: 开源权重语言模型在生产环境中的使用日益增多，带来了新的安全挑战。现有后门攻击研究假设攻击者需要访问训练管道或部署基础设施，但本文提出了一种更隐蔽的攻击面——聊天模板。

Method: 利用聊天模板（可执行的Jinja2程序）在每次推理调用时执行的特权位置，攻击者通过分发带有恶意修改模板的模型，在不修改模型权重、不污染训练数据、不控制运行时基础设施的情况下植入推理时后门。

Result: 在18个模型（涵盖7个模型家族和4个推理引擎）上测试了两种目标的后门：降低事实准确性和诱导输出攻击者控制的URL。触发条件下，事实准确性从90%平均降至15%，攻击者控制的URL输出成功率超过80%；良性输入无性能下降。后门能跨推理运行时泛化，并逃逸最大开源权重分发平台的所有自动安全扫描。

Conclusion: 聊天模板是LLM供应链中一个可靠且目前无防御的攻击面，需要新的安全措施来检测和缓解这类模板后门攻击。

Abstract: Open-weight language models are increasingly used in production settings, raising new security challenges. One prominent threat in this context is backdoor attacks, in which adversaries embed hidden behaviors in language models that activate under specific conditions. Previous work has assumed that adversaries have access to training pipelines or deployment infrastructure. We propose a novel attack surface requiring neither, which utilizes the chat template. Chat templates are executable Jinja2 programs invoked at every inference call, occupying a privileged position between user input and model processing. We show that an adversary who distributes a model with a maliciously modified template can implant an inference-time backdoor without modifying model weights, poisoning training data, or controlling runtime infrastructure. We evaluated this attack vector by constructing template backdoors targeting two objectives: degrading factual accuracy and inducing emission of attacker-controlled URLs, and applied them across eighteen models spanning seven families and four inference engines. Under triggered conditions, factual accuracy drops from 90% to 15% on average while attacker-controlled URLs are emitted with success rates exceeding 80%; benign inputs show no measurable degradation. Backdoors generalize across inference runtimes and evade all automated security scans applied by the largest open-weight distribution platform. These results establish chat templates as a reliable and currently undefended attack surface in the LLM supply chain.

</details>


### [8] [Comparative Insights on Adversarial Machine Learning from Industry and Academia: A User-Study Approach](https://arxiv.org/abs/2602.04753)
*Vishruti Kakkad,Paul Chung,Hanan Hibshi,Maverick Woo*

Main category: cs.CR

TL;DR: 研究调查了业界专业人士和学生对对抗性机器学习威胁的看法，发现网络安全教育与AML关注度相关，CTF挑战能有效激发学生对AML威胁的兴趣，建议将安全教育整合到ML课程中。


<details>
  <summary>Details</summary>
Motivation: 随着机器学习和生成式AI应用的指数级增长，对抗性机器学习（AML）带来的安全挑战日益显著。研究旨在探索业界专业人士和学生对不同AML漏洞的看法及其教育策略。

Method: 进行了两项综合研究：1）对专业人士进行在线调查，分析网络安全教育与AML威胁关注度的相关性；2）开发两个CTF挑战（涉及NLP和生成式AI概念，展示训练数据集投毒攻击），并在卡内基梅隆大学对本科生和研究生进行调查评估其效果。

Result: 研究发现：1）专业人士的网络安全教育与对AML威胁的关注度存在显著相关性；2）基于CTF的方法能有效激发学生对AML威胁的兴趣；3）参与者反馈支持将安全教育整合到ML课程中。

Conclusion: 基于研究结果，提出了详细建议，强调在ML课程中整合安全教育的迫切需求，以应对日益增长的对抗性机器学习威胁。

Abstract: An exponential growth of Machine Learning and its Generative AI applications brings with it significant security challenges, often referred to as Adversarial Machine Learning (AML). In this paper, we conducted two comprehensive studies to explore the perspectives of industry professionals and students on different AML vulnerabilities and their educational strategies. In our first study, we conducted an online survey with professionals revealing a notable correlation between cybersecurity education and concern for AML threats. For our second study, we developed two CTF challenges that implement Natural Language Processing and Generative AI concepts and demonstrate a poisoning attack on the training data set. The effectiveness of these challenges was evaluated by surveying undergraduate and graduate students at Carnegie Mellon University, finding that a CTF-based approach effectively engages interest in AML threats. Based on the responses of the participants in our research, we provide detailed recommendations emphasizing the critical need for integrated security education within the ML curriculum.

</details>
