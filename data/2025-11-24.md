<div id=toc></div>

# Table of Contents

- [cs.CR](#cs.CR) [Total: 11]


<div id='cs.CR'></div>

# cs.CR [[Back]](#toc)

### [1] [AutoBackdoor: Automating Backdoor Attacks via LLM Agents](https://arxiv.org/abs/2511.16709)
*Yige Li,Zhe Li,Wei Zhao,Nay Myat Min,Hanxun Huang,Xingjun Ma,Jun Sun*

Main category: cs.CR

TL;DR: AutoBackdoor是一个自动化后门攻击框架，使用语言模型代理生成语义连贯的触发短语，在多种威胁场景下对LLM进行后门注入，攻击成功率超过90%，现有防御措施难以抵御。


<details>
  <summary>Details</summary>
Motivation: 现有后门攻击方法依赖人工设计的触发器和静态数据管道，缺乏系统性评估现代防御鲁棒性的能力，需要更严格、多样化和可扩展的红队框架来模拟真实威胁。

Method: 使用强大的语言模型代理生成语义连贯、上下文感知的触发短语，通过自主代理驱动管道自动化后门注入，包括触发生成、数据毒化和模型微调。

Result: 在LLaMA-3、Mistral、Qwen和GPT-4o等开源和商业模型上测试，仅需少量毒化样本即可实现超过90%的攻击成功率，现有防御措施往往无法缓解这些攻击。

Conclusion: AutoBackdoor展示了代理驱动威胁的严重性，强调需要更严格和自适应的评估技术来应对此类攻击，现有防御措施存在明显不足。

Abstract: Backdoor attacks pose a serious threat to the secure deployment of large language models (LLMs), enabling adversaries to implant hidden behaviors triggered by specific inputs. However, existing methods often rely on manually crafted triggers and static data pipelines, which are rigid, labor-intensive, and inadequate for systematically evaluating modern defense robustness. As AI agents become increasingly capable, there is a growing need for more rigorous, diverse, and scalable \textit{red-teaming frameworks} that can realistically simulate backdoor threats and assess model resilience under adversarial conditions. In this work, we introduce \textsc{AutoBackdoor}, a general framework for automating backdoor injection, encompassing trigger generation, poisoned data construction, and model fine-tuning via an autonomous agent-driven pipeline. Unlike prior approaches, AutoBackdoor uses a powerful language model agent to generate semantically coherent, context-aware trigger phrases, enabling scalable poisoning across arbitrary topics with minimal human effort. We evaluate AutoBackdoor under three realistic threat scenarios, including \textit{Bias Recommendation}, \textit{Hallucination Injection}, and \textit{Peer Review Manipulation}, to simulate a broad range of attacks. Experiments on both open-source and commercial models, including LLaMA-3, Mistral, Qwen, and GPT-4o, demonstrate that our method achieves over 90\% attack success with only a small number of poisoned samples. More importantly, we find that existing defenses often fail to mitigate these attacks, underscoring the need for more rigorous and adaptive evaluation techniques against agent-driven threats as explored in this work. All code, datasets, and experimental configurations will be merged into our primary repository at https://github.com/bboylyg/BackdoorLLM.

</details>


### [2] [Password Strength Analysis Through Social Network Data Exposure: A Combined Approach Relying on Data Reconstruction and Generative Models](https://arxiv.org/abs/2511.16716)
*Maurizio Atzori,Eleonora Calò,Loredana Caruccio,Stefano Cirillo,Giuseppe Polese,Giandomenico Solimando*

Main category: cs.CR

TL;DR: SODA ADVANCE是一个数据重建工具，集成了专门模块来评估密码强度，利用社交媒体等公开数据源。研究还探讨了大型语言模型在密码生成和评估方面的能力与风险。


<details>
  <summary>Details</summary>
Motivation: 用户倾向于使用易记密码，这增加了安全风险，而传统的密码强度评估方法往往不足。

Method: 开发SODA ADVANCE工具，集成专门模块利用公开数据评估密码强度；通过100名真实用户的实验评估LLMs在密码生成和评估方面的能力。

Result: 实验表明LLMs能够生成强且个性化的密码，并能有效评估密码强度，特别是在考虑用户档案数据时。

Conclusion: LLMs在密码生成和评估方面具有潜力，特别是当能够利用用户档案数据时，但同时也需要考虑相关的安全风险。

Abstract: Although passwords remain the primary defense against unauthorized access, users often tend to use passwords that are easy to remember. This behavior significantly increases security risks, also due to the fact that traditional password strength evaluation methods are often inadequate. In this discussion paper, we present SODA ADVANCE, a data reconstruction tool also designed to enhance evaluation processes related to the password strength. In particular, SODA ADVANCE integrates a specialized module aimed at evaluating password strength by leveraging publicly available data from multiple sources, including social media platforms. Moreover, we investigate the capabilities and risks associated with emerging Large Language Models (LLMs) in evaluating and generating passwords, respectively. Experimental assessments conducted with 100 real users demonstrate that LLMs can generate strong and personalized passwords possibly defined according to user profiles. Additionally, LLMs were shown to be effective in evaluating passwords, especially when they can take into account user profile data.

</details>


### [3] [RampoNN: A Reachability-Guided System Falsification for Efficient Cyber-Kinetic Vulnerability Detection](https://arxiv.org/abs/2511.16765)
*Kohei Tsujio,Mohammad Abdullah Al Faruque,Yasser Shoukry*

Main category: cs.CR

TL;DR: RampoNN是一个用于检测信息物理系统中动力学漏洞的框架，通过结合控制代码分析、物理系统建模和深度伯恩斯坦神经网络，显著加速了漏洞发现过程。


<details>
  <summary>Details</summary>
Motivation: 检测信息物理系统中的动力学漏洞面临挑战，需要分析复杂软件行为与物理动力学之间的耦合关系，以及控制代码周期性执行带来的组合爆炸问题。

Method: RampoNN首先分析控制代码以映射各种执行分支下可生成的控制信号，然后使用深度伯恩斯坦神经网络抽象物理系统行为，利用定制化的可达性算法获得更紧密的边界，最后引导反例生成引擎专注于最有希望的系统行为。

Result: 在水箱系统和汽车发动机控制器上的评估显示，RampoNN将发现动力学漏洞的过程加速了高达98.27%，并展现出优于其他最先进方法的可扩展性。

Conclusion: RampoNN框架通过高精度可达性分析和针对性搜索策略，有效解决了信息物理系统中动力学漏洞检测的挑战，显著提升了检测效率和可扩展性。

Abstract: Detecting kinetic vulnerabilities in Cyber-Physical Systems (CPS), vulnerabilities in control code that can precipitate hazardous physical consequences, is a critical challenge. This task is complicated by the need to analyze the intricate coupling between complex software behavior and the system's physical dynamics. Furthermore, the periodic execution of control code in CPS applications creates a combinatorial explosion of execution paths that must be analyzed over time, far exceeding the scope of traditional single-run code analysis.
  This paper introduces RampoNN, a novel framework that systematically identifies kinetic vulnerabilities given the control code, a physical system model, and a Signal Temporal Logic (STL) specification of safe behavior. RampoNN first analyzes the control code to map the control signals that can be generated under various execution branches. It then employs a neural network to abstract the physical system's behavior. To overcome the poor scaling and loose over-approximations of standard neural network reachability, RampoNN uniquely utilizes Deep Bernstein neural networks, which are equipped with customized reachability algorithms that yield orders of magnitude tighter bounds. This high-precision reachability analysis allows RampoNN to rapidly prune large sets of guaranteed-safe behaviors and rank the remaining traces by their potential to violate the specification. The results of this analysis are then used to effectively guide a falsification engine, focusing its search on the most promising system behaviors to find actual vulnerabilities.
  We evaluated our approach on a PLC-controlled water tank system and a switched PID controller for an automotive engine. The results demonstrate that RampoNN leads to acceleration of the process of finding kinetic vulnerabilities by up to 98.27% and superior scalability compared to other state-of-the-art methods.

</details>


### [4] [Membership Inference Attacks Beyond Overfitting](https://arxiv.org/abs/2511.16792)
*Mona Khalil,Alberto Blanco-Justicia,Najeeb Jebreel,Josep Domingo-Ferrer*

Main category: cs.CR

TL;DR: 本文研究了机器学习模型中成员推理攻击的根本原因，发现即使非过拟合模型也会泄露部分训练数据隐私，特别是那些类内异常样本。作者提出了针对性的防御策略来保护这些易受攻击的样本。


<details>
  <summary>Details</summary>
Motivation: 成员推理攻击对使用敏感数据进行训练的模型构成严重隐私威胁。虽然传统观点认为模型过拟合是主要因素，但研究发现即使非过拟合模型也会泄露部分训练数据信息，这促使作者深入探究超出传统过拟合问题的根本原因。

Method: 通过实证分析非过拟合模型中易受成员推理攻击的训练数据样本特征，发现这些样本通常是类内异常值（如噪声样本或难以分类的样本）。

Result: 研究发现易受攻击的样本往往是类内异常值，作者据此提出了保护这些易受攻击样本的防御策略，以增强机器学习模型的隐私保护能力。

Conclusion: 成员推理漏洞的根本原因不仅限于模型过拟合，类内异常样本是主要攻击目标。针对这些特定样本的防御策略可以有效提升模型的隐私保护能力。

Abstract: Membership inference attacks (MIAs) against machine learning (ML) models aim to determine whether a given data point was part of the model training data. These attacks may pose significant privacy risks to individuals whose sensitive data were used for training, which motivates the use of defenses such as differential privacy, often at the cost of high accuracy losses. MIAs exploit the differences in the behavior of a model when making predictions on samples it has seen during training (members) versus those it has not seen (non-members). Several studies have pointed out that model overfitting is the major factor contributing to these differences in behavior and, consequently, to the success of MIAs. However, the literature also shows that even non-overfitted ML models can leak information about a small subset of their training data. In this paper, we investigate the root causes of membership inference vulnerabilities beyond traditional overfitting concerns and suggest targeted defenses. We empirically analyze the characteristics of the training data samples vulnerable to MIAs in models that are not overfitted (and hence able to generalize). Our findings reveal that these samples are often outliers within their classes (e.g., noisy or hard to classify). We then propose potential defensive strategies to protect these vulnerable samples and enhance the privacy-preserving capabilities of ML models. Our code is available at https://github.com/najeebjebreel/mia_analysis.

</details>


### [5] [TICAL: Trusted and Integrity-protected Compilation of AppLications](https://arxiv.org/abs/2511.17070)
*Robert Krahn,Nikson Kanti Paul,Franz Gregor,Do Le Quoc,Andrey Brito,André Martin,Christof Fetzer*

Main category: cs.CR

TL;DR: Tical是一个实用的可信编译框架，为从源代码到最终可执行文件的构建流水线提供完整性保护和机密性。它利用TEEs作为运行时保护，并通过文件系统屏蔽和不可变审计日志来确保编译器链只能访问可信文件。


<details>
  <summary>Details</summary>
Motivation: 现有方法主要关注运行时保护，但构建时的完整性和机密性保护同样重要，因为编译过程中恶意注入的代码可能危及整个应用程序和系统。

Method: 利用TEEs作为运行时保护，并增强文件系统屏蔽和带有版本历史的不可变审计日志，确保编译器链只能访问由可信进程产生的可信文件和中间输出。

Result: 通过微基准和宏基准评估显示，Tical能够以可接受的性能开销保护整个CI/CD流水线的机密性和完整性。

Conclusion: Tical框架为构建流水线提供了实用的可信编译解决方案，有效解决了构建过程中的安全风险。

Abstract: During the past few years, we have witnessed various efforts to provide confidentiality and integrity for applications running in untrusted environments such as public clouds. In most of these approaches, hardware extensions such as Intel SGX, TDX, AMD SEV, etc., are leveraged to provide encryption and integrity protection on process or VM level. Although all of these approaches increase the trust in the application at runtime, an often overlooked aspect is the integrity and confidentiality protection at build time, which is equally important as maliciously injected code during compilation can compromise the entire application and system. In this paper, we present Tical, a practical framework for trusted compilation that provides integrity protection and confidentiality in build pipelines from source code to the final executable. Our approach harnesses TEEs as runtime protection but enriches TEEs with file system shielding and an immutable audit log with version history to provide accountability. This way, we can ensure that the compiler chain can only access trusted files and intermediate output, such as object files produced by trusted processes. Our evaluation using micro- and macro-benchmarks shows that Tical can protect the confidentiality and integrity of whole CI/CD pipelines with an acceptable performance overhead.

</details>


### [6] [AutoGraphAD: A novel approach using Variational Graph Autoencoders for anomalous network flow detection](https://arxiv.org/abs/2511.17113)
*Georgios Anyfantis,Pere Barlet-Ros*

Main category: cs.CR

TL;DR: AutoGraphAD是一种基于异构变分图自编码器的无监督异常检测方法，用于网络入侵检测，无需标记数据即可实现高性能检测


<details>
  <summary>Details</summary>
Motivation: 传统监督学习方法需要昂贵的标记数据集，而现有公共数据集存在攻击类型有限、过时和错误标记等问题，因此需要减少对标记数据的依赖

Method: 使用异构变分图自编码器构建包含连接和IP节点的异构图，通过无监督和对比学习训练模型，结合重构损失、结构损失和KL散度计算异常分数

Result: AutoGraphAD在性能上与之前的方法相当甚至更好，训练速度快约1.18个数量级，推理速度快约1.03个数量级

Conclusion: 该方法显著提高了训练和推理效率，具有实际部署优势，是网络入侵检测的有效无监督解决方案

Abstract: Network Intrusion Detection Systems (NIDS) are essential tools for detecting network attacks and intrusions. While extensive research has explored the use of supervised Machine Learning for attack detection and characterisation, these methods require accurately labelled datasets, which are very costly to obtain. Moreover, existing public datasets have limited and/or outdated attacks, and many of them suffer from mislabelled data. To reduce the reliance on labelled data, we propose AutoGraphAD, a novel unsupervised anomaly detection approach based on a Heterogeneous Variational Graph Autoencoder. AutoGraphAD operates on heterogeneous graphs, made from connection and IP nodes that capture network activity within a time window. The model is trained using unsupervised and contrastive learning, without relying on any labelled data. The reconstruction, structural loss, and KL divergence are then weighted and combined in an anomaly score that is then used for anomaly detection. Overall, AutoGraphAD yields the same, and in some cases better, results than previous unsupervised approaches, such as Anomal-E, but without requiring costly downstream anomaly detectors. As a result, AutoGraphAD achieves around 1.18 orders of magnitude faster training and 1.03 orders of magnitude faster inference, which represents a significant advantage for operational deployment.

</details>


### [7] [Constant-Size Cryptographic Evidence Structures for Regulated AI Workflows](https://arxiv.org/abs/2511.17118)
*Leo Kao*

Main category: cs.CR

TL;DR: 提出恒定大小的密码学证据结构，用于在受监管AI工作流中表示可验证的审计证据，具有固定大小、统一验证成本和与哈希链/Merkle树结构兼容的特点。


<details>
  <summary>Details</summary>
Motivation: 为受监管AI工作流提供可验证的审计证据，满足临床试验管理、制药合规和医疗AI治理等领域的监管需求。

Method: 形式化受监管AI工作流模型，定义证据结构的语法和算法，提出基于抗碰撞哈希函数和数字签名的通用哈希-签名构造方法。

Result: 实现了原型库并在商用硬件上进行微基准测试，证明恒定大小证据的每事件开销小且可预测。

Conclusion: 该设计为受监管AI系统提供了高效、安全的审计证据解决方案，具有实际工业应用价值。

Abstract: This paper introduces constant-size cryptographic evidence structures, a general abstraction for representing verifiable audit evidence for AI workflows in regulated environments. Each evidence item is a fixed-size tuple of cryptographic fields, designed to (i) provide strong binding to workflow events and configurations, (ii) support constant-size storage and uniform verification cost per event, and (iii) compose cleanly with hash-chain and Merkle-based audit constructions. We formalize a simple model of regulated AI workflows, define syntax and algorithms for evidence structures, and articulate security goals such as audit integrity and non-equivocation. We present a generic hash-and-sign construction that instantiates this abstraction using a collision-resistant hash function and a standard digital signature scheme. We then show how to integrate the construction with hash-chained logs, Merkle-tree anchoring, and optionally trusted execution environments, and we analyze the asymptotic complexity of evidence generation and verification. Finally, we implement a prototype library and report microbenchmark results on commodity hardware, demonstrating that the per-event overhead of constant-size evidence is small and predictable. The design is informed by industrial experience with regulated AI systems at Codebat Technologies Inc., while the paper focuses on the abstraction, algorithms, and their security and performance characteristics, with implications for clinical trial management, pharmaceutical compliance, and medical AI governance.

</details>


### [8] [Steering in the Shadows: Causal Amplification for Activation Space Attacks in Large Language Models](https://arxiv.org/abs/2511.17194)
*Zhiyuan Xu,Stanislav Abaimov,Joseph Gardiner,Sana Belguith*

Main category: cs.CR

TL;DR: 论文发现LLM中间激活层存在因果放大效应，可通过敏感度缩放引导攻击实现行为控制，对白盒和供应链LLM部署构成安全威胁


<details>
  <summary>Details</summary>
Motivation: 现代大语言模型通常通过审计数据、提示和拒绝策略来保障安全，但将前向传播视为实现细节。研究发现中间激活层形成了易受攻击的行为控制表面

Method: 提出敏感度缩放引导攻击，结合序列开始锚定和基于敏感度的强化，将有限扰动预算集中在最脆弱的层和token上

Result: 在多个开源模型和四个行为维度上，该方法能显著改变邪恶、幻觉、谄媚和情感等行为，同时保持高连贯性和通用能力

Conclusion: 激活引导已成为白盒和供应链LLM部署的具体安全关切，需要重新考虑LLM安全架构

Abstract: Modern large language models (LLMs) are typically secured by auditing data, prompts, and refusal policies, while treating the forward pass as an implementation detail. We show that intermediate activations in decoder-only LLMs form a vulnerable attack surface for behavioral control. Building on recent findings on attention sinks and compression valleys, we identify a high-gain region in the residual stream where small, well-aligned perturbations are causally amplified along the autoregressive trajectory--a Causal Amplification Effect (CAE). We exploit this as an attack surface via Sensitivity-Scaled Steering (SSS), a progressive activation-level attack that combines beginning-of-sequence (BOS) anchoring with sensitivity-based reinforcement to focus a limited perturbation budget on the most vulnerable layers and tokens. We show that across multiple open-weight models and four behavioral axes, SSS induces large shifts in evil, hallucination, sycophancy, and sentiment while preserving high coherence and general capabilities, turning activation steering into a concrete security concern for white-box and supply-chain LLM deployments.

</details>


### [9] [Persistent BitTorrent Trackers](https://arxiv.org/abs/2511.17260)
*Francois Xavier Wicht,Zhengwei Tong,Shunfan Zhou,Hang Yin,Aviv Yaish*

Main category: cs.CR

TL;DR: 该论文提出了一种基于区块链和可信执行环境的去中心化BitTorrent信誉系统，解决传统私有追踪器存在的信誉不可移植、中心化单点故障和自报告不可验证等问题。


<details>
  <summary>Details</summary>
Motivation: 传统私有BitTorrent追踪器存在三个关键弱点：信誉无法在不同追踪器间转移、中心化服务器造成单点故障、上传统计数据自报告且不可验证。当追踪器关闭时，用户会丢失贡献历史，无法向新社区证明其信誉。

Method: 使用智能合约存储信誉，用加密证明替代自报告。接收方对传输的数据块进行签名确认，追踪器在可信执行环境中聚合验证这些收据后更新链上信誉。当追踪器不可用时，使用认证的分布式哈希表进行节点发现，链上信誉作为公钥基础设施实现访问控制。

Result: 原型系统在Intel TDX上评估显示，传输收据在典型数据块大小下仅增加不到6%的开销，签名聚合使验证速度提升2.5倍。

Conclusion: 该设计能够持久保存信誉信息，抵御追踪器故障，并通过工厂部署合约中的单跳迁移实现信誉在不同实例间的可移植性，在标准密码学假设下证明了系统的正确性和安全性。

Abstract: Private BitTorrent trackers enforce upload-to-download ratios to prevent free-riding, but suffer from three critical weaknesses: reputation cannot move between trackers, centralized servers create single points of failure, and upload statistics are self-reported and unverifiable. When a tracker shuts down (whether by operator choice, technical failure, or legal action) users lose their contribution history and cannot prove their standing to new communities. We address these problems by storing reputation in smart contracts and replacing self-reports with cryptographic attestations. Receiving peers sign receipts for transferred pieces, which the tracker aggregates and verifies before updating on-chain reputation. Trackers run in Trusted Execution Environments (TEEs) to guarantee correct aggregation and prevent manipulation of state. If a tracker is unavailable, peers use an authenticated Distributed Hash Table (DHT) for discovery: the on-chain reputation acts as a Public Key Infrastructure (PKI), so peers can verify each other and maintain access control without the tracker. This design persists reputation across tracker failures and makes it portable to new instances through single-hop migration in factory-deployed contracts. We formalize the security requirements, prove correctness under standard cryptographic assumptions, and evaluate a prototype on Intel TDX. Measurements show that transfer receipts adds less than 6\% overhead with typical piece sizes, and signature aggregation speeds up verification by $2.5\times$.

</details>


### [10] [ThreadFuzzer: Fuzzing Framework for Thread Protocol](https://arxiv.org/abs/2511.17283)
*Ilja Siroš,Jakob Heirwegh,Dave Singelée,Bart Preneel*

Main category: cs.CR

TL;DR: ThreadFuzzer是首个专门用于系统测试Thread协议实现的模糊测试框架，通过操纵MLE层数据包，支持虚拟OpenThread节点和物理Thread设备的模糊测试。


<details>
  <summary>Details</summary>
Motivation: 随着物联网的快速发展，安全高效的网状网络变得至关重要。Thread协议已成为智能家居和商业系统的关键协议，并作为Matter标准的核心传输层，需要专门的测试工具来确保其安全性。

Method: ThreadFuzzer框架包含多种模糊测试策略：来自CovFuzz的随机和基于覆盖率的模糊器，以及专门为TLV结构MLE消息设计的新TLV插入器。在OpenThread堆栈上使用代码覆盖率和漏洞发现指标进行评估。

Result: 评估发现了OpenThread堆栈中的五个先前未知漏洞，其中几个在依赖OpenThread的商业设备上成功复现。与使用手动扩展OSS-Fuzz的AFL++设置相比，ThreadFuzzer表现出强大的有效性。

Conclusion: 这些结果证明了ThreadFuzzer的实际效用，同时突出了无线协议模糊测试研究领域的挑战和未来方向。

Abstract: With the rapid growth of IoT, secure and efficient mesh networking has become essential. Thread has emerged as a key protocol, widely used in smart-home and commercial systems, and serving as a core transport layer in the Matter standard. This paper presents ThreadFuzzer, the first dedicated fuzzing framework for systematically testing Thread protocol implementations. By manipulating packets at the MLE layer, ThreadFuzzer enables fuzzing of both virtual OpenThread nodes and physical Thread devices. The framework incorporates multiple fuzzing strategies, including Random and Coverage-based fuzzers from CovFuzz, as well as a newly introduced TLV Inserter, designed specifically for TLV-structured MLE messages. These strategies are evaluated on the OpenThread stack using code-coverage and vulnerability-discovery metrics. The evaluation uncovered five previously unknown vulnerabilities in the OpenThread stack, several of which were successfully reproduced on commercial devices that rely on OpenThread. Moreover, ThreadFuzzer was benchmarked against an oracle AFL++ setup using the manually extended OSS-Fuzz harness from OpenThread, demonstrating strong effectiveness. These results demonstrate the practical utility of ThreadFuzzer while highlighting challenges and future directions in the wireless protocol fuzzing research space.

</details>


### [11] [A Patient-Centric Blockchain Framework for Secure Electronic Health Record Management: Decoupling Data Storage from Access Control](https://arxiv.org/abs/2511.17464)
*Tanzim Hossain Romel,Kawshik Kumar Paul,Tanberul Islam Ruhan,Maisha Rahman Mim,Abu Sayed Md. Latiful Hoque*

Main category: cs.CR

TL;DR: 提出了一种以患者为中心的电子健康记录共享架构，将内容存储与授权和审计分离，使用区块链记录加密承诺和患者签名的时间限制权限，实现安全可控的医疗数据共享。


<details>
  <summary>Details</summary>
Motivation: 解决电子健康记录共享中的隐私和安全问题，恢复患者对个人医疗数据的控制权，同时满足HIPAA/GDPR等法规要求。

Method: 采用链下存储加密FHIR资源，链上记录加密承诺和患者签名的时间限制权限（EIP-712），通过公钥包装分发密钥，存储提供商保持诚实但好奇状态。

Result: 权限授予的平均链上成本为78,000 gas（L1），1MB记录的端到端访问延迟为0.7-1.4秒，Layer-2部署可将gas使用降低10-13倍。

Conclusion: 该架构为恢复患者控制权同时保持临床敏感数据所需安全属性提供了一条实用路径，讨论了元数据隐私、密钥注册要求和监管考虑。

Abstract: We present a patient-centric architecture for electronic health record (EHR) sharing that separates content storage from authorization and audit. Encrypted FHIR resources are stored off-chain; a public blockchain records only cryptographic commitments and patient-signed, time-bounded permissions using EIP-712. Keys are distributed via public-key wrapping, enabling storage providers to remain honest-but-curious without risking confidentiality. We formalize security goals (confidentiality, integrity, cryptographically attributable authorization, and auditability of authorization events) and provide a Solidity reference implementation deployed as single-patient contracts. On-chain costs for permission grants average 78,000 gas (L1), and end-to-end access latency for 1 MB records is 0.7--1.4s (mean values for S3 and IPFS respectively), dominated by storage retrieval. Layer-2 deployment reduces gas usage by 10--13x, though data availability charges dominate actual costs. We discuss metadata privacy, key registry requirements, and regulatory considerations (HIPAA/GDPR), demonstrating a practical route to restoring patient control while preserving security properties required for sensitive clinical data.

</details>
