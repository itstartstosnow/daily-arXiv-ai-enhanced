<div id=toc></div>

# Table of Contents

- [cs.CR](#cs.CR) [Total: 37]


<div id='cs.CR'></div>

# cs.CR [[Back]](#toc)

### [1] [TrojanGYM: A Detector-in-the-Loop LLM for Adaptive RTL Hardware Trojan Insertion](https://arxiv.org/abs/2601.17178)
*Saideep Sreekumar,Zeng Wang,Akashdeep Saha,Weihua Xiao,Minghao Shao,Muhammad Shafique,Ozgur Sinanoglu,Ramesh Karri,Johann Knechtel*

Main category: cs.CR

TL;DR: TrojanGYM是一个基于LLM的自动化硬件木马生成框架，通过智能代理生成多样化的木马设计来暴露检测器的盲点，同时提出改进的GNN检测器Robust-GNN4TJ。


<details>
  <summary>Details</summary>
Motivation: 现有基于学习的硬件木马检测器容易在有限的触发/负载模式和小型基准测试上过拟合，无法发现检测器的真实盲点，需要更系统化的方法来评估检测器的鲁棒性。

Method: TrojanGYM框架使用多个LLM代理（GPT-4、LLaMA-3.3-70B、Gemini-2.5Pro）协作，根据高层木马规格自动生成RTL级修改，实现多样化的触发器和负载，同时保持设计功能正确性。采用反馈驱动的基准生成循环，结合约束感知的语法检查和GNN检测器反馈来迭代优化木马插入策略。

Result: 在SRAM、AES-128和UART设计上实现了TrojanGYM，生成的功能正确的多样化木马对现代GNN检测器的逃避率高达83.33%。提出的Robust-GNN4TJ检测器在最具挑战性的TrojanGYM基准上，将检测率从0%提升到60%。

Conclusion: TrojanGYM框架能够系统性地生成多样化且功能正确的硬件木马，有效暴露现有检测器的鲁棒性缺陷，而仅依赖传统TrustHub基准测试无法发现这些缺陷。提出的Robust-GNN4TJ检测器在LLM生成的木马设计上表现出更好的性能。

Abstract: Hardware Trojans (HTs) remain a critical threat because learning-based detectors often overfit to narrow trigger/payload patterns and small, stylized benchmarks. We introduce TrojanGYM, an agentic, LLM-driven framework that automatically curates HT insertions to expose detector blind spots while preserving design correctness. Given high-level HT specifications, a suite of cooperating LLM agents (instantiated with GPT-4, LLaMA-3.3-70B, and Gemini-2.5Pro) proposes and refines RTL modifications that realize diverse triggers and payloads without impacting normal functionality. TrojanGYM implements a feedback-driven benchmark generation loop co-designed with HT detectors, in which constraint-aware syntactic checking and GNN-based HT detectors provide feedback that iteratively refines HT specifications and insertion strategies to better surface detector blind spots. We further propose Robust-GNN4TJ, a new implementation of the GNN4TJ with improved graph extraction, training robustness, and prediction reliability, especially on LLM-generated HT designs. On the most challenging TrojanGYM-generated benchmarks, Robust-GNN4TJ raises HT detection rates from 0% to 60% relative to a prior GNN-based detector. We instantiate TrojanGYM on SRAM, AES-128, and UART designs at RTL level, and show that it systematically produces diverse, functionally correct HTs that reach up to 83.33% evasion rates against modern GNN-based detectors, revealing robustness gaps that are not apparent when these detectors are evaluated solely on existing TrustHub-style benchmarks. Post peer-review, we will release all codes and artifacts.

</details>


### [2] [Toward Risk Thresholds for AI-Enabled Cyber Threats: Enhancing Decision-Making Under Uncertainty with Bayesian Networks](https://arxiv.org/abs/2601.17225)
*Krystal Jackson,Deepika Raman,Jessica Newman,Nada Madkour,Charlotte Yuan,Evan R. Murphy*

Main category: cs.CR

TL;DR: 论文提出了一种基于贝叶斯网络的概率化、证据驱动、可操作的AI网络安全风险评估框架，以解决当前AI网络风险阈值设定方法的碎片化和局限性问题。


<details>
  <summary>Details</summary>
Motivation: AI技术正在改变网络攻击的规模、速度和可及性，但当前确定AI系统何时引入不可接受网络风险的方法存在碎片化、依赖单一能力基准、缺乏实证证据等问题，需要更系统化的风险评估框架。

Method: 1) 分析现有行业网络风险阈值，识别共同要素和方法缺陷；2) 提出使用贝叶斯网络作为AI网络风险建模工具，整合异质证据、明确表示不确定性、支持持续更新；3) 通过AI增强钓鱼攻击案例研究，展示如何将定性威胁洞察分解为可测量变量并重组为结构化风险评估。

Result: 建立了一个结构化、概率化的AI网络风险评估方法，能够更好地捕捉AI如何改变攻击者行为和攻击结果，相比传统能力评估方法更具实证基础和可操作性。

Conclusion: 贝叶斯网络为AI网络风险评估提供了有效的建模框架，能够整合多种证据源、明确处理不确定性，并通过案例研究验证了该方法在AI增强钓鱼攻击风险评估中的实用性和优势。

Abstract: Artificial intelligence (AI) is increasingly being used to augment and automate cyber operations, altering the scale, speed, and accessibility of malicious activity. These shifts raise urgent questions about when AI systems introduce unacceptable or intolerable cyber risk, and how risk thresholds should be identified before harms materialize at scale. In recent years, industry, government, and civil society actors have begun to articulate such thresholds for advanced AI systems, with the goal of signaling when models meaningfully amplify cyber threats, for example, by automating multi-stage intrusions, enabling zero-day discovery, or lowering the expertise required for sophisticated attacks. However, current approaches to determine these thresholds remain fragmented and limited. Many thresholds rely solely on capability benchmarks or narrow threat scenarios, and are weakly connected to empirical evidence. This paper proposes a structured approach to developing and evaluating AI cyber risk thresholds that is probabilistic, evidence-based, and operationalizable. In this paper we make three core contributions that build on our prior work that highlights the limitations of relying solely on capability assessments. First, we analyze existing industry cyber thresholds and identify common threshold elements as well as recurring methodological shortcomings. Second, we propose the use of Bayesian networks as a tool for modeling AI-enabled cyber risk, enabling the integration of heterogeneous evidence, explicit representation of uncertainty, and continuous updating as new information emerges. Third, we illustrate this approach through a focused case study on AI-augmented phishing, demonstrating how qualitative threat insights can be decomposed into measurable variables and recombined into structured risk estimates that better capture how AI changes attacker behavior and outcomes.

</details>


### [3] [On the Insecurity of Keystroke-Based AI Authorship Detection: Timing-Forgery Attacks Against Motor-Signal Verification](https://arxiv.org/abs/2601.17280)
*David Condrey*

Main category: cs.CR

TL;DR: 基于击键时序变异系数(δ)检测AI生成文本的防御方法存在安全漏洞，可通过复制转录攻击和时序伪造攻击绕过，攻击成功率≥99.8%


<details>
  <summary>Details</summary>
Motivation: 当前使用击键时序信号（特别是击键间隔变异系数δ）来区分人类撰写文本与AI生成内容的防御方案存在安全隐患，需要评估其实际安全性

Method: 提出两种实际攻击方法：1) 复制转录攻击：人类转录LLM生成的文本产生真实运动信号；2) 时序伪造攻击：自动化代理从经验人类分布中采样击键间隔。使用SBU语料库的13,000个会话和三种时序伪造变体（直方图采样、统计模仿、生成式LSTM）进行实验

Result: 所有攻击对五种分类器的规避率≥99.8%。虽然检测器对完全自动化注入的AUC=1.000，但将≥99.8%的攻击样本分类为人类，平均置信度≥0.993。证明当检测器仅观察时序时，特征与内容来源之间的互信息为零

Conclusion: 基于击键时序的检测系统只能确认人类操作了键盘，但不能证明文本是否由该人类原创。保护来源真实性需要将写作过程与语义内容绑定的架构

Abstract: Recent proposals advocate using keystroke timing signals, specifically the coefficient of variation ($δ$) of inter-keystroke intervals, to distinguish human-composed text from AI-generated content. We demonstrate that this class of defenses is insecure against two practical attack classes: the copy-type attack, in which a human transcribes LLM-generated text producing authentic motor signals, and timing-forgery attacks, in which automated agents sample inter-keystroke intervals from empirical human distributions. Using 13,000 sessions from the SBU corpus and three timing-forgery variants (histogram sampling, statistical impersonation, and generative LSTM), we show all attacks achieve $\ge$99.8% evasion rates against five classifiers. While detectors achieve AUC=1.000 against fully-automated injection, they classify $\ge$99.8% of attack samples as human with mean confidence $\ge$0.993. We formalize a non-identifiability result: when the detector observes only timing, the mutual information between features and content provenance is zero for copy-type attacks. Although composition and transcription produce statistically distinguishable motor patterns (Cohen's d=1.28), both yield $δ$ values 2-4x above detection thresholds, rendering the distinction security-irrelevant. These systems confirm a human operated the keyboard, but not whether that human originated the text. Securing provenance requires architectures that bind the writing process to semantic content.

</details>


### [4] [Safeguard: Security Controls at the Software Defined Network Layer](https://arxiv.org/abs/2601.17355)
*Yi Lyu,Shichun Yu,Joe Catudal*

Main category: cs.CR

TL;DR: Safeguard：一种基于规则的策略，覆盖数据驱动策略，防止网络流量边缘情况下的意外响应


<details>
  <summary>Details</summary>
Motivation: 软件定义网络允许数据驱动应用调整策略以适应波动需求，但过度修正可能导致意外后果，特别是在网络安全功能如机器学习入侵检测系统中尤为严重

Method: 提出Safeguard，一种基于规则的策略，覆盖在数据驱动策略之上，防止网络流量边缘情况下的意外响应。开发了网络流量分类器的参考实现，强制执行恶意流量的防火墙规则

Result: 展示了允许已知良好流量的额外规则集对于利用数据驱动网络策略至关重要

Conclusion: Safeguard通过规则与数据驱动策略的结合，有效防止了网络安全系统中的意外响应，提高了数据驱动网络策略的可靠性和安全性

Abstract: Improvements in software defined networking allow for policy to be informed and modified by data-driven applications that can adjust policy to accommodate fluctuating requirements at line speed. However, there is some concern that over-correction can occur and cause unintended consequences depending on the data received. This is particularly problematic for network security features, such as machine-learning intrusion detection systems. We present Safeguard, a rule-based policy that overlaps a data-driven policy to prevent unintended responses for edge cases in network traffic. We develop a reference implementation of a network traffic classifier that enforces firewall rules for malicious traffic, and show how additional rulesets to allow known-good traffic are essential in utilizing a data-driven network policy.

</details>


### [5] [From Scores to Queues: Operationalizing Cross-Chain Obfuscation Signals for Smart-Contract Audits](https://arxiv.org/abs/2601.17356)
*Yao Zhao,Zhang Sheng,Shengchen Duan,Shen Wang*

Main category: cs.CR

TL;DR: HObfNET是一个高效的智能合约混淆检测模型，相比传统工具实现2.3k-5.2k倍加速，支持跨链大规模评分，并提出实用的审计队列策略。


<details>
  <summary>Details</summary>
Motivation: 智能合约混淆增加了审计成本，而现有混淆检测工具（如Obfs_Tool）运行缓慢，且跨链混淆信号的可比性和可迁移性不明确，需要高效的大规模跨链检测方案。

Method: 提出HObfNET作为Obfs_Tool的高效替代模型，实现快速跨链评分；采用链内主阈值和极端阈值（p99和p99.9）策略；分析高得分合约的特征（稀有选择器、外部调用操作码富集、低签名密度）；建立二级筛选机制和跨链关联工作流。

Result: 在以太坊上与工具输出高度对齐（PCC 0.9158，MAPE 8.20%）；处理速度达8-9ms/合约，比Obfs_Tool快2.3k-5.2k倍；在BSC、Polygon、Avalanche上发现系统性得分漂移；高得分尾部显示特定特征模式；公开事件样本均落入p99队列，验证了实际检测价值。

Conclusion: HObfNET实现了高效的大规模跨链混淆检测，提出的两级审计队列和跨链关联工作流为实际的多链安全运营提供了实用支持，能够有效识别高风险合约并优先处理。

Abstract: Obfuscation substantially increases the interpretation cost of smart-contract auditing, while the comparability and transferability of obfuscation signals across chains remain unclear. We present HObfNET as an efficient surrogate of Obfs_Tool (ObfProbe), enabling fast cross-chain scoring at scale. The model aligns well with tool outputs on Ethereum (PCC 0.9158, MAPE 8.20 percent) and achieves 8-9 ms per contract, a 2.3k-5.2k times speedup over second-level Obfs_Tool runs, enabling million-scale scoring. On large BSC, Polygon, and Avalanche corpora, we find systematic score drift: fixed-threshold transfer inflates and deflates candidate queues, motivating within-chain main and extreme thresholds (p99 and p99.9) and an actionable queueing strategy. The high-score tail exhibits rare selectors, external-call opcode enrichment, and low signature density; a proxy indicator is enriched in the BSC high-score queue, enabling secondary triage. Cross-chain reuse analysis shows tail enrichment and directional diffusion, with traceable same-hash cases across chains. In publicly alignable incident samples, all fall into the p99 queue; Transit Swap DEX Hack and New Free DAO Flash Loan exhibit cross-chain spillover, indicating real-world hit and prioritization value. We deliver a two-tier audit queue and cross-chain linkage workflow to support practical multi-chain security operations.

</details>


### [6] [Res-MIA: A Training-Free Resolution-Based Membership Inference Attack on Federated Learning Models](https://arxiv.org/abs/2601.17378)
*Mohammad Zare,Pirooz Shamsinejadbabaki*

Main category: cs.CR

TL;DR: Res-MIA是一种新型的免训练黑盒成员推理攻击，通过逐步降低输入分辨率并分析模型置信度衰减来识别训练样本，在联邦学习中表现出色。


<details>
  <summary>Details</summary>
Motivation: 尽管联邦学习被认为是隐私保护的训练范式，但研究表明最终全局模型仍可能通过黑盒访问泄露成员信息。现有成员推理攻击通常需要训练影子模型或大量辅助数据，计算成本高且不实用。

Method: Res-MIA利用深度模型对高频输入细节的敏感性，通过受控的下采样和恢复操作逐步降低输入分辨率，分析模型预测置信度的衰减模式。训练样本在分辨率侵蚀下表现出比非成员样本更陡峭的置信度下降。

Result: 在联邦ResNet-18模型和CIFAR-10数据集上的评估显示，Res-MIA始终优于现有的免训练基线方法，AUC最高可达0.88，且计算开销极小。

Conclusion: 频率敏感的过拟合是联邦学习中一个重要且未被充分探索的隐私泄露源，需要设计减少对细粒度、非鲁棒输入特征依赖的隐私感知模型。

Abstract: Membership inference attacks (MIAs) pose a serious threat to the privacy of machine learning models by allowing adversaries to determine whether a specific data sample was included in the training set. Although federated learning (FL) is widely regarded as a privacy-aware training paradigm due to its decentralized nature, recent evidence shows that the final global model can still leak sensitive membership information through black-box access. In this paper, we introduce Res-MIA, a novel training-free and black-box membership inference attack that exploits the sensitivity of deep models to high-frequency input details. Res-MIA progressively degrades the input resolution using controlled downsampling and restoration operations, and analyzes the resulting confidence decay in the model's predictions. Our key insight is that training samples exhibit a significantly steeper confidence decline under resolution erosion compared to non-member samples, revealing a robust membership signal. Res-MIA requires no shadow models, no auxiliary data, and only a limited number of forward queries to the target model. We evaluate the proposed attack on a federated ResNet-18 trained on CIFAR-10, where it consistently outperforms existing training-free baselines and achieves an AUC of up to 0.88 with minimal computational overhead. These findings highlight frequency-sensitive overfitting as an important and previously underexplored source of privacy leakage in federated learning, and emphasize the need for privacy-aware model designs that reduce reliance on fine-grained, non-robust input features.

</details>


### [7] [Prompt and Circumstances: Evaluating the Efficacy of Human Prompt Inference in AI-Generated Art](https://arxiv.org/abs/2601.17379)
*Khoi Trinh,Scott Seidenberger,Joseph Spracklen,Raveen Wijewickrama,Bimal Viswanath,Murtuza Jadliwala,Anindya Maiti*

Main category: cs.CR

TL;DR: 研究探讨AI艺术提示词市场中的知识产权问题，发现仅通过AI生成图像，人类和AI难以准确推断原始提示词，且人类-AI协作推断并未优于纯人类推断。


<details>
  <summary>Details</summary>
Motivation: 随着AI生成艺术领域的发展，出现了提示词市场，市场声称提示词是知识产权。但问题是：仅通过公开的样本图像，人类和AI工具能否推断出原始提示词？这关系到提示词是否真正构成知识产权。

Method: 通过人类受试者研究，评估人类仅通过观察AI生成图像推断原始提示词的准确性；同时探索结合人类和AI推断的提示词，使用大语言模型辅助，是否能生成更相似的图像。

Result: 人类推断的提示词和人类-AI协作推断的提示词生成的图像与原图有中等相似度，但不如使用原始提示词。结合人类和AI推断的提示词并未比纯人类推断表现更好。

Conclusion: 尽管提示词市场声称提示词是知识产权，但研究表明仅通过样本图像难以准确推断原始提示词，这为提示词作为知识产权的有效性提供了实证依据。人类-AI协作推断并未带来显著改进。

Abstract: The emerging field of AI-generated art has witnessed the rise of prompt marketplaces, where creators can purchase, sell, or share prompts to generate unique artworks. These marketplaces often assert ownership over prompts, claiming them as intellectual property. This paper investigates whether concealed prompts sold on prompt marketplaces can be considered bona fide intellectual property, given that humans and AI tools may be able to infer the prompts based on publicly advertised sample images accompanying each prompt on sale. Specifically, our study aims to assess (i) how accurately humans can infer the original prompt solely by examining an AI-generated image, with the goal of generating images similar to the original image, and (ii) the possibility of improving upon individual human and AI prompt inferences by crafting combined human and AI prompts with the help of a large language model. Although previous research has explored AI-driven prompt inference and protection strategies, our work is the first to incorporate a human subject study and examine collaborative human-AI prompt inference in depth. Our findings indicate that while prompts inferred by humans and prompts inferred through a combined human and AI effort can generate images with a moderate level of similarity, they are not as successful as using the original prompt. Moreover, combining human- and AI-inferred prompts using our suggested merging techniques did not improve performance over purely human-inferred prompts.

</details>


### [8] [PatchIsland: Orchestration of LLM Agents for Continuous Vulnerability Repair](https://arxiv.org/abs/2601.17471)
*Wonyoung Kim,Seunggi Min,Minjae Gwon,Dowoo Baik,Haein Lee,Hyeon Heo,Minjae Lee,Min Woo Baek,Yonghwi Jin,Younggi Park,Yunjae Choi,Taesoo Kim,Sangdon Park,Insu Yun*

Main category: cs.CR

TL;DR: PatchIsland是一个用于持续漏洞修复的系统，通过集成多个LLM代理来应对持续模糊测试环境的挑战，在竞赛中实现了72.1%的修复率。


<details>
  <summary>Details</summary>
Motivation: 现有自动化漏洞修复技术（包括基于LLM的系统）主要针对静态、单次运行的基准测试场景设计，无法适应持续模糊测试环境的多样性、噪声和易失败特性。

Method: 1. 紧密集成到持续模糊测试流水线中；2. 采用多样化的LLM代理集合，覆盖不同项目、漏洞类型和编程语言；3. 使用两阶段补丁去重机制，减少重复崩溃和补丁。

Result: 内部评估修复了92个漏洞中的84个；在官方AIxCC竞赛中，在完全自主环境下成功修复了43个漏洞中的31个，修复率达到72.1%。

Conclusion: PatchIsland通过集成多个LLM代理和去重机制，有效解决了持续模糊测试环境中的漏洞修复问题，展示了在实际应用中的可行性和有效性。

Abstract: Continuous fuzzing platforms such as OSS-Fuzz uncover large numbers of vulnerabilities, yet the subsequent repair process remains largely manual. Unfortunately, existing Automated Vulnerability Repair (AVR) techniques -- including recent LLM-based systems -- are not directly applicable to continuous fuzzing. This is because these systems are designed and evaluated on a static, single-run benchmark setting, making them ill-suited for the diverse, noisy, and failure-prone environments in continuous fuzzing.
  To address these issues, we introduce PatchIsland, a system for Continuous Vulnerability Repair (CVR) that tightly integrates with continuous fuzzing pipelines. PatchIsland employs an ensemble of diverse LLM agents. By leveraging multiple LLM agents, PatchIsland can cover a wider range of settings (e.g., different projects, bug types, and programming languages) and also improve operational robustness. In addition, PatchIsland utilizes a two-phase patch-based deduplication to mitigate duplicate crashes and patches, which can be problematic in continuous fuzzing.
  In our internal evaluation, PatchIsland repaired 84 of 92 vulnerabilities, demonstrating strong repair capability. In the official AIxCC competition, the system operated with no human intervention in a fully autonomous environment and successfully patched 31 out of 43 vulnerabilities, achieving a repair rate of 72.1\%.

</details>


### [9] [On the Impossibility of Simulation Security for Quantum Functional Encryption](https://arxiv.org/abs/2601.17497)
*Mohammed Barhoush,Arthur Mehta,Anne Müller,Louis Salvail*

Main category: cs.CR

TL;DR: 该论文证明在量子计算环境下，模拟安全的函数加密仍然是不可能的，扩展了经典环境中的不可能性结果


<details>
  <summary>Details</summary>
Motivation: 函数加密是一种强大的密码学原语，支持对加密数据的细粒度访问。虽然经典环境中模拟安全已被证明不可能，但这些不可能性证明依赖于经典论证，量子环境中是否可能仍是一个开放问题

Method: 将经典不可能性结果扩展到量子世界，针对不同攻击场景：1）对手可发出无限挑战消息时，证明无条件不可能性；2）对手可获得多个功能密钥时，基于伪随机量子态假设证明不可能性；3）基于公钥加密证明替代不可能性

Result: 1）无限挑战消息场景下，证明无条件不可能性，匹配经典障碍；2）多个功能密钥场景下，基于伪随机量子态假设证明不可能性；3）基于公钥加密证明替代不可能性，提供独立证据；4）证明了伪随机态的新颖不可压缩性

Conclusion: 模拟安全的函数加密在量子环境中同样不可能实现，经典不可能性结果在量子世界中基本成立，为量子密码学研究提供了重要限制

Abstract: Functional encryption is a powerful cryptographic primitive that enables fine-grained access to encrypted data and underlies numerous applications. Although the ideal security notion for FE (simulation security) has been shown to be impossible in the classical setting, those impossibility results rely on inherently classical arguments. This leaves open the question of whether simulation-secure functional encryption can be achieved in the quantum regime.
  In this work, we rule out this possibility by showing that the classical impossibility results largely extend to the quantum world. In particular, when the adversary can issue an unbounded number of challenge messages, we prove an unconditional impossibility, matching the classical barrier. In the case where the adversary may obtain many functional keys, classical arguments only yield impossibility under the assumption of pseudorandom functions; we strengthen this by proving impossibility under the potentially weaker assumption of pseudorandom quantum states. In the same setting, we also establish an alternative impossibility based on public-key encryption. Since public-key encryption is not known to imply pseudorandom quantum states, this provides independent evidence of the barrier. As part of our proofs, we show a novel incompressibility property for pseudorandom states, which may be of independent interest.

</details>


### [10] [Reconstructing Training Data from Adapter-based Federated Large Language Models](https://arxiv.org/abs/2601.17533)
*Silong Chen,Yuchuan Luo,Guilin Deng,Yi Liu,Min Xu,Shaojing Fu,Xiaohua Jia*

Main category: cs.CR

TL;DR: 本文提出UTR攻击，揭示基于适配器的联邦大语言模型中低秩适配器会创建新的梯度泄露通道，挑战了轻量级适配能增强安全性的普遍认知。


<details>
  <summary>Details</summary>
Motivation: 尽管基于适配器的联邦大语言模型被认为通过冻结主干网络和仅训练低秩适配器来限制梯度泄露，但作者发现这种低秩适配器实际上创建了新的可利用泄露通道，需要研究针对这种结构的专门攻击方法。

Method: 提出UTR攻击，通过三个关键技术：从冻结层的注意力模式推断token存在性；在适配器梯度的低秩子空间内进行句子级反转；通过语言先验引导的约束贪婪解码来强制语义一致性。

Result: 在多种模型（GPT2-Large、BERT、Qwen2.5-7B）和数据集（CoLA、SST-2、Rotten Tomatoes）上的实验表明，UTR实现了接近完美的重建精度（ROUGE-1/2 > 99），即使在批量大小较大的情况下，而之前的梯度反转攻击完全失败。

Conclusion: 研究揭示了联邦大语言模型中参数效率与隐私之间的根本矛盾，挑战了轻量级适配能增强安全性的普遍认知，表明基于适配器的联邦学习并不能提供足够的安全保障。

Abstract: Adapter-based Federated Large Language Models (FedLLMs) are widely adopted to reduce the computational, storage, and communication overhead of full-parameter fine-tuning for web-scale applications while preserving user privacy. By freezing the backbone and training only compact low-rank adapters, these methods appear to limit gradient leakage and thwart existing Gradient Inversion Attacks (GIAs).
  Contrary to this assumption, we show that low-rank adapters create new, exploitable leakage channels. We propose the Unordered-word-bag-based Text Reconstruction (UTR) attack, a novel GIA tailored to the unique structure of adapter-based FedLLMs. UTR overcomes three core challenges: low-dimensional gradients, frozen backbones, and combinatorially large reconstruction spaces by: (i) inferring token presence from attention patterns in frozen layers, (ii) performing sentence-level inversion within the low-rank subspace of adapter gradients, and (iii) enforcing semantic coherence through constrained greedy decoding guided by language priors. Extensive experiments across diverse models (GPT2-Large, BERT, Qwen2.5-7B) and datasets (CoLA, SST-2, Rotten Tomatoes) demonstrate that UTR achieves near-perfect reconstruction accuracy (ROUGE-1/2 > 99), even with large batch size settings where prior GIAs fail completely. Our results reveal a fundamental tension between parameter efficiency and privacy in FedLLMs, challenging the prevailing belief that lightweight adaptation inherently enhances security. Our code and data are available at https://github.com/shwksnshwowk-wq/GIA.

</details>


### [11] [CTF for education](https://arxiv.org/abs/2601.17543)
*Yi Lyu,Luke Dotson,Nic Draves,Andy Zhang*

Main category: cs.CR

TL;DR: 本文分析CTF在网络安全教育中的应用，将CTF比赛分为四类：攻击型、防御型、夺旗型、游戏化/战争游戏型，并探讨如何结合这些类型提升学习效果。


<details>
  <summary>Details</summary>
Motivation: 研究CTF（Capture The Flag）在网络安全教育中的实际应用价值，为教育工作者提供有效的教学方法和比赛设计指导。

Method: 首先总结四类CTF比赛的主要特征：攻击型CTF、防御型CTF、夺旗型CTF、游戏化/战争游戏型CTF，然后从学习目标、可访问性等方面进行比较分析。

Result: 研究发现，结合所有四种CTF格式可以帮助参与者构建全面的网络安全知识体系，为CTF教育者提供有价值的见解。

Conclusion: 综合运用不同类型的CTF比赛能够有效提升网络安全教育效果，为未来的CTF教育实践提供指导方向。

Abstract: In this paper, we take a close look at how CTF can be used in cybersecurity education. We divide the CTF competitions into four different categories, which are attack-based CTFs, defense-based CTFs, jeopardy CTFs and gamified and wargames CTFs.
  We start our analysis by summarizing the main characteristics of different CTF types. We then compare them with each other in both learning objectives and other aspects like accessibility. We conclude that combining all four CTF formats can help participants build one's cybersecurity knowledge.
  By doing that, we hope that our findings will provide some useful insights for future CTF educators.

</details>


### [12] [Prompt Injection Attacks on Agentic Coding Assistants: A Systematic Analysis of Vulnerabilities in Skills, Tools, and Protocol Ecosystems](https://arxiv.org/abs/2601.17548)
*Narek Maloyan,Dmitry Namiot*

Main category: cs.CR

TL;DR: 本文系统分析了针对智能编码助手的提示注入攻击，提出了三维分类法，综合了78项研究，发现攻击成功率超过85%，现有防御机制效果有限，呼吁将提示注入视为需要架构级缓解的一级漏洞。


<details>
  <summary>Details</summary>
Motivation: 随着Claude Code、GitHub Copilot等智能编码助手的普及，这些系统通过MCP等协议集成外部工具、文件系统和shell访问，扩展了能力范围，但也引入了关键的安全漏洞。需要系统分析这些智能编码助手面临的提示注入攻击。

Method: 提出了一个新颖的三维分类法，从传递向量、攻击模式和传播行为三个维度对攻击进行分类。对78项近期研究（2021-2026）进行了元分析，系统整理了42种不同的攻击技术，并批判性分析了18种防御机制。

Result: 当采用自适应攻击策略时，针对最先进防御的攻击成功率超过85%。大多数防御机制对复杂自适应攻击的缓解效果不足50%。发现了基于技能架构的漏洞和具体利用链。

Conclusion: 安全社区必须将提示注入视为需要架构级缓解的一级漏洞，而不是临时过滤方法。贡献包括：统一的攻击分类法、首次系统分析技能架构漏洞、基于识别限制的深度防御框架。

Abstract: The proliferation of agentic AI coding assistants, including Claude Code, GitHub Copilot, Cursor, and emerging skill-based architectures, has fundamentally transformed software development workflows. These systems leverage Large Language Models (LLMs) integrated with external tools, file systems, and shell access through protocols like the Model Context Protocol (MCP). However, this expanded capability surface introduces critical security vulnerabilities. In this \textbf{Systematization of Knowledge (SoK)} paper, we present a comprehensive analysis of prompt injection attacks targeting agentic coding assistants. We propose a novel three-dimensional taxonomy categorizing attacks across \textit{delivery vectors}, \textit{attack modalities}, and \textit{propagation behaviors}. Our meta-analysis synthesizes findings from 78 recent studies (2021--2026), consolidating evidence that attack success rates against state-of-the-art defenses exceed 85\% when adaptive attack strategies are employed. We systematically catalog 42 distinct attack techniques spanning input manipulation, tool poisoning, protocol exploitation, multimodal injection, and cross-origin context poisoning. Through critical analysis of 18 defense mechanisms reported in prior work, we identify that most achieve less than 50\% mitigation against sophisticated adaptive attacks. We contribute: (1) a unified taxonomy bridging disparate attack classifications, (2) the first systematic analysis of skill-based architecture vulnerabilities with concrete exploit chains, and (3) a defense-in-depth framework grounded in the limitations we identify. Our findings indicate that the security community must treat prompt injection as a first-class vulnerability class requiring architectural-level mitigations rather than ad-hoc filtering approaches.

</details>


### [13] [Breaking the Protocol: Security Analysis of the Model Context Protocol Specification and Prompt Injection Vulnerabilities in Tool-Integrated LLM Agents](https://arxiv.org/abs/2601.17549)
*Narek Maloyan,Dmitry Namiot*

Main category: cs.CR

TL;DR: 首次对MCP协议进行形式化安全分析，发现三个协议级漏洞，提出MCPSec扩展将攻击成功率从52.8%降至12.4%


<details>
  <summary>Details</summary>
Motivation: MCP已成为LLM与外部工具集成的实际标准，但缺乏正式的安全分析。需要评估协议设计的安全性和识别潜在漏洞。

Method: 1) 对MCP架构设计进行严格安全分析，识别三个协议级漏洞；2) 实现MCPBench框架，将现有智能体安全基准适配到MCP基础设施；3) 在5个MCP服务器实现上对847个攻击场景进行控制实验；4) 提出MCPSec协议扩展，添加能力证明和消息认证。

Result: 1) 发现三个根本性协议漏洞：能力证明缺失、双向采样无来源认证、多服务器配置中的隐式信任传播；2) MCP架构选择使攻击成功率比非MCP集成提高23-41%；3) MCPSec将攻击成功率从52.8%降至12.4%，每条消息延迟中位数增加8.3ms。

Conclusion: MCP的安全弱点是架构性的而非实现特定的，需要协议级修复。MCPSec提供了向后兼容的解决方案，显著提高了安全性。

Abstract: The Model Context Protocol (MCP) has emerged as a de facto standard for integrating Large Language Models with external tools, yet no formal security analysis of the protocol specification exists. We present the first rigorous security analysis of MCP's architectural design, identifying three fundamental protocol-level vulnerabilities: (1) absence of capability attestation allowing servers to claim arbitrary permissions, (2) bidirectional sampling without origin authentication enabling server-side prompt injection, and (3) implicit trust propagation in multi-server configurations. We implement \textsc{MCPBench}, a novel framework bridging existing agent security benchmarks to MCP-compliant infrastructure, enabling direct measurement of protocol-specific attack surfaces. Through controlled experiments on 847 attack scenarios across five MCP server implementations, we demonstrate that MCP's architectural choices amplify attack success rates by 23--41\% compared to equivalent non-MCP integrations. We propose \textsc{MCPSec}, a backward-compatible protocol extension adding capability attestation and message authentication, reducing attack success rates from 52.8\% to 12.4\% with median latency overhead of 8.3ms per message. Our findings establish that MCP's security weaknesses are architectural rather than implementation-specific, requiring protocol-level remediation.

</details>


### [14] [Private Iris Recognition with High-Performance FHE](https://arxiv.org/abs/2601.17561)
*Jincheol Ha,Guillaume Hanrot,Taeyeong Noh,Jung Hee Cheon,Jung Woo Kim,Damien Stehlé*

Main category: cs.CR

TL;DR: 本文比较了两种隐私保护的虹膜识别方案：基于秘密共享多方计算（SS-MPC）的方案和基于阈值全同态加密（ThFHE）的新方案。ThFHE方案在安全性、部署灵活性和性能方面都有显著优势。


<details>
  <summary>Details</summary>
Motivation: 随着World ID等大规模虹膜识别项目的兴起，生物特征数据的隐私保护变得至关重要。现有基于秘密共享多方计算的方案虽然有效，但在安全性假设、部署灵活性和通信开销方面存在限制。本文旨在探索阈值全同态加密技术能否提供更好的安全性和性能。

Method: 采用阈值全同态加密（ThFHE）方案，具体使用CKKS同态加密方案。关键技术包括：利用FHE-based线性代数的最新进展，结合int8 GPU操作进行加速，以及引入早期减少待处理密文数量的技术。

Result: 原型实现显示，ThFHE方案在8个RTX-5090 GPU上，能够在约1.8秒内完成32个虹膜与7·2^14规模数据库的匹配（4个虹膜仅需约0.33秒）。通信轮数仅需2-3轮，远少于SS-MPC方案的40多轮。

Conclusion: 阈值全同态加密方案相比秘密共享多方计算方案具有明显优势：无需可信设置、加密数据库和查询可公开、密钥可分布式管理、支持主动安全且性能影响小。ThFHE为大规模隐私保护生物识别提供了更优的解决方案。

Abstract: Among biometric verification systems, irises stand out because they offer high accuracy even in large-scale databases. For example, the World ID project aims to provide authentication to all humans via iris recognition, with millions already registered. Storing such biometric data raises privacy concerns, which can be addressed using privacy-enhancing techniques.
  Bloemen et al. describe a solution based on 2-out-of-3 Secret-Sharing Multiparty Computation (SS-MPC), for the World ID setup. In terms of security, unless an adversary corrupts 2~servers, the iris codes remain confidential and nothing leaks beyond the result of the computation. Their solution is able to match~$32$ users against a database of~$2^{22}$ iris codes in~$\approx 2$s , using~24 H100 GPUs, more than 40~communication rounds and $81$GB/party of data transferred (the timing assumes a network speed above~3Tb/s).
  In the present work, we explore the use of Threshold Fully Homomorphic Encryption (ThFHE) for the same task. The ThFHE solution brings a number of security advantages: no trusted setup, the encrypted database and queries can be public, the secret can be distributed among many parties, and active security can be added without significant performance degradation.
  Our proof-of-concept implementation of the computation phase handles $32$~eyes against a database of $7\cdot 2^{14}$ iris codes in~$\approx 1.8$s ($\approx 0.33s$ for 4 eyes against the same database), using 8 RTX-5090 GPUs. To this, one should add~2 to 3 rounds of communication (depending on deployment choice). We perform the matching using the CKKS (Th)FHE scheme. Our main technical ingredients are the use of recent progress on FHE-based linear algebra boosted using int8 GPU operations, and the introduction of a technique reducing the number of ciphertexts to be processed as early as possible.

</details>


### [15] [Reconstructing Protected Biometric Templates from Binary Authentication Results](https://arxiv.org/abs/2601.17620)
*Eliron Rahimi,Margarita Osadchy,Orr Dunkelman*

Main category: cs.CR

TL;DR: 攻击者仅通过观察认证成功/失败结果，即可重建生物特征模板，并能生成高分辨率人脸图像，成功率超过98%


<details>
  <summary>Details</summary>
Motivation: 现有生物特征模板保护方法在攻击者能够注入样本并观察系统输出的场景下，其安全性尚未得到充分评估。特别是对于仅返回认证成功/失败结果的系统，攻击可行性一直未得到验证。

Method: 通过注入足够数量的模板并观察认证成功/失败结果，开发了一种能够重建生物特征模板的攻击方法。该方法实现了可忽略的模板重建损失，并通过生成式反演方法实现人脸图像的全恢复。

Result: 攻击能够从二进制评分中重建生物特征模板，生成的高分辨率人脸图像在系统中的通过率超过98%。该攻击适用于任何保持识别准确性的保护机制。

Conclusion: 仅返回认证成功/失败结果的生物特征保护系统仍然存在安全风险，攻击者可以通过观察这些有限信息重建模板并生成有效的人脸图像，这对现有保护机制提出了新的安全挑战。

Abstract: Biometric data is considered to be very private and highly sensitive. As such, many methods for biometric template protection were considered over the years -- from biohashing and specially crafted feature extraction procedures, to the use of cryptographic solutions such as Fuzzy Commitments or the use of Fully Homomorphic Encryption (FHE).
  A key question that arises is how much protection these solutions can offer when the adversary can inject samples, and observe the outputs of the system. While for systems that return the similarity score, one can use attacks such as hill-climbing, for systems where the adversary can only learn whether the authentication attempt was successful, this question remained open.
  In this paper, we show that it is indeed possible to reconstruct the biometric template by just observing the success/failure of the authentication attempt (given the ability to inject a sufficient amount of templates). Our attack achieves negligible template reconstruction loss and enables full recovery of facial images through a generative inversion method, forming a pipeline from binary scores to high-resolution facial images that successfully pass the system more than 98\% of the time. Our results, of course, are applicable for any protection mechanism that maintains the accuracy of the recognition.

</details>


### [16] [FOCA: Multimodal Malware Classification via Hyperbolic Cross-Attention](https://arxiv.org/abs/2601.17638)
*Nitin Choudhury,Bikrant Bikram Pratap Maurya,Orchid Chetia Phukan,Arun Balaji Buduru*

Main category: cs.CR

TL;DR: FOCA是一个新颖的多模态恶意软件分类框架，首次在双曲空间中利用音频和视觉模态的层次关系进行融合，超越了传统的欧几里得方法。


<details>
  <summary>Details</summary>
Motivation: 传统基于欧几里得空间的多模态融合方法无法有效捕捉音频和视觉表示之间的内在层次关系，需要探索更适合这种关系的几何空间。

Method: 将原始二进制文件转换为音频和视觉表示，通过三个关键组件处理：1)双曲投影模块将欧几里得嵌入映射到庞加莱球；2)双曲交叉注意力机制在曲率感知约束下对齐多模态依赖；3)基于Mobius加法的融合层。

Result: 在Mal-Net和CICMalDroid2020两个基准数据集上的实验表明，FOCA始终优于单模态模型，超越大多数欧几里得多模态基线，并实现了最先进的性能。

Conclusion: FOCA通过利用双曲空间中的层次关系，为多模态恶意软件分类提供了一种更有效的融合方法，展示了双曲几何在多模态学习中的潜力。

Abstract: In this work, we introduce FOCA, a novel multimodal framework for malware classification that jointly leverages audio and visual modalities. Unlike conventional Euclidean-based fusion methods, FOCA is the first to exploit the intrinsic hierarchical relationships between audio and visual representations within hyperbolic space. To achieve this, raw binaries are transformed into both audio and visual representations, which are then processed through three key components: (i) a hyperbolic projection module that maps Euclidean embeddings into the Poincare ball, (ii) a hyperbolic cross-attention mechanism that aligns multimodal dependencies under curvature-aware constraints, and (iii) a Mobius addition-based fusion layer. Comprehensive experiments on two benchmark datasets-Mal-Net and CICMalDroid2020- show that FOCA consistently outperforms unimodal models, surpasses most Euclidean multimodal baselines, and achieves state-of-the-art performance over existing works.

</details>


### [17] [A Systemic Evaluation of Multimodal RAG Privacy](https://arxiv.org/abs/2601.17644)
*Ali Al-Lawati,Suhang Wang*

Main category: cs.CR

TL;DR: 该论文实证研究了多模态检索增强生成(mRAG)系统中的隐私风险，发现通过标准模型提示可以推断私有图像是否被包含在mRAG中，并泄露其相关元数据（如标题）。


<details>
  <summary>Details</summary>
Motivation: 随着多模态RAG在视觉任务中的广泛应用，虽然它能连接私有数据集提升模型性能，但也带来了重要的隐私挑战。mRAG在推理过程中存在泄露私有数据集信息的风险，需要对此进行实证分析。

Method: 通过实证研究分析mRAG管道中的隐私风险，实现了一个案例研究：尝试推断视觉资产（如图像）是否被包含在mRAG中，如果存在则泄露其相关元数据（如标题）。

Result: 研究发现通过标准模型提示可以成功推断私有图像是否存在于mRAG系统中，并能泄露其相关元数据，这凸显了mRAG系统存在的严重隐私风险。

Conclusion: 研究结果强调了mRAG系统中隐私保护机制的必要性，并激励未来对mRAG隐私问题的进一步研究。

Abstract: The growing adoption of multimodal Retrieval-Augmented Generation (mRAG) pipelines for vision-centric tasks (e.g. visual QA) introduces important privacy challenges. In particular, while mRAG provides a practical capability to connect private datasets to improve model performance, it risks the leakage of private information from these datasets during inference. In this paper, we perform an empirical study to analyze the privacy risks inherent in the mRAG pipeline observed through standard model prompting. Specifically, we implement a case study that attempts to infer the inclusion of a visual asset, e.g. image, in the mRAG, and if present leak the metadata, e.g. caption, related to it. Our findings highlight the need for privacy-preserving mechanisms and motivate future research on mRAG privacy.

</details>


### [18] [A PUF-Based Security Framework for Fault and Intrusion Detection](https://arxiv.org/abs/2601.17661)
*Ahmed Oun,Rishabh Das,Clay Hess,Aakriti Barat,Savas Kaya*

Main category: cs.CR

TL;DR: 提出基于物理不可克隆函数(PUF)的硬件信任根架构，用于工业控制系统传感器数据认证，在硬件在环测试中达到99.97%准确率并能检测各种注入攻击。


<details>
  <summary>Details</summary>
Motivation: 工业控制系统依赖传感器反馈维持安全关键过程，但传感器数据可能被篡改或遭受供应链攻击，需要可靠的身份验证机制来确保数据完整性。

Method: 在测量层嵌入物理不可克隆函数(PUF)，结合电压指纹和时间认证，与标准工业控制系统架构集成。在硬件在环水罐测试平台上使用Simulink PUF模拟器进行原型验证。

Result: 系统在5.18小时正常操作中保持99.97%准确率，能检测所有注入的异常，包括尖峰故障、硬过故障和硬件木马场景，防止系统进入不安全状态。

Conclusion: 该架构提供了一种过程感知、供应商无关的方法，可与遗留工厂集成，检测传感器信号退化或复杂的供应链攻击，增强工业控制系统安全性。

Abstract: Industrial Control Systems (ICS) rely on sensor feedback to keep safety-critical processes within operational limits. This research presents a hardware-root-of-trust that embeds a Physically Unclonable Function (PUF) at the measurement layer to authenticate sensor readings. The architecture combines voltage fingerprinting with a temporal authentication that integrates with standard industrial control system architecture. The research prototypes the PUF integration on a hardware-in-the-loop (HIL) water tank testbed using a Simulink-based PUF emulator. The system maintains 99.97% accuracy over a 5.18-hour period of normal operation and flags all injected anomalies, including spike faults, hard-over faults, and hardware trojan scenarios that push the system over to an unsafe operational state. The proposed architecture provides a process-aware, vendor-agnostic approach that can integrate with legacy plants to detect sensor signal degradation or sophisticated supply chain attacks.

</details>


### [19] [Performance Analysis of Quantum-Secure Digital Signature Algorithms in Blockchain](https://arxiv.org/abs/2601.17785)
*Tushar Jain*

Main category: cs.CR

TL;DR: 该论文提出了一个支持多种后量子安全签名算法的区块链原型，重点评估了CRYSTALS-Dilithium、Falcon和Hawk等基于格的签名方案在区块链系统中的性能表现。


<details>
  <summary>Details</summary>
Motivation: 当前大多数加密货币和区块链平台依赖椭圆曲线密码学，而Shor算法使其易受量子攻击。因此需要了解后量子数字签名在实际区块链系统中的表现，为量子安全区块链系统提供参考。

Method: 设计并实现了一个支持多种量子安全签名算法的区块链原型，重点测试了CRYSTALS-Dilithium、Falcon和Hawk等基于格的签名方案。通过实验方法测量了密钥生成、签名、验证时间、密钥大小和签名大小等性能指标。

Result: 报告提供了详细的性能指标对比，包括各种量子安全签名算法的效率参数。同时将分析扩展到HAETAE等其他方案，为区块链系统选择后量子签名方案提供了实证数据参考。

Conclusion: 后量子数字签名在区块链系统中的集成是可行的，但需要权衡安全性和性能。基于格的签名方案如CRYSTALS-Dilithium、Falcon和Hawk在区块链环境中表现出不同的性能特征，为未来量子安全区块链系统的设计提供了重要参考。

Abstract: The long-term security of public blockchains strictly depends on the hardness assumptions of the underlying digital signature schemes. In the current scenario, most deployed cryptocurrencies and blockchain platforms rely on elliptic-curve cryptography, which is vulnerable to quantum attacks due to Shor's algorithm. Therefore, it is important to understand how post-quantum (PQ) digital signatures behave when integrated into real blockchain systems. This report presents a blockchain prototype that supports multiple quantum-secure signature algorithms, focusing on CRYSTALS-Dilithium, Falcon and Hawk as lattice-based schemes. This report also describes the design of the prototype and discusses the performance metrics, which include key generation, signing, verification times, key sizes and signature sizes. This report covers the problem, background, and experimental methodology, also providing a detailed comparison of quantum-secure signatures in a blockchain context and extending the analysis to schemes such as HAETAE.

</details>


### [20] [@NTT: Algorithm-Targeted NTT hardware acceleration via Design-Time Constant Optimization](https://arxiv.org/abs/2601.17806)
*Mohammed Nabeel,Mahmoud Hafez,Michail Maniatakos*

Main category: cs.CR

TL;DR: 提出@NTT硬件架构，通过设计时常数优化，在紧凑面积下实现每个时钟周期N点NTT的最大吞吐量


<details>
  <summary>Details</summary>
Motivation: 数论变换(NTT)是后量子密码算法中的计算瓶颈，硬件实现通常需要大量蝶形单元才能达到最大吞吐量，导致面积过大

Method: 利用算法中环参数固定的特点，进行设计时常数优化，提出@NTT架构，在紧凑硬件面积下实现每个时钟周期N点NTT

Result: TSMC 28nm工艺下时钟频率1.0GHz，面积1.45mm²；FPGA上吞吐率每LUT比现有最佳实现高5.2倍

Conclusion: @NTT通过设计时优化实现了高吞吐率与紧凑面积的平衡，为后量子密码硬件实现提供了高效解决方案

Abstract: The Number Theoretic Transform (NTT) is a critical computational bottleneck in many lattice-based postquantum cryptographic (PQC) algorithms. By leveraging the Fast Fourier Transform (FFT) algorithm, the NTT of a polynomial of degree N - 1 can be computed with a time complexity of O(N log N). Hardware implementation of NTT is generally preferred over software ones, as the latter are significantly slower due to complex memory access patterns and modular arithmetic operations. Achieving maximum throughput in hardware, however, typically demands a prohibitively large number of butterfly unit instantiations. In this work, we propose @NTT, which exploits the fact that the ring parameters in these algorithms are fixed, enabling design-time constant optimization and achieving the maximum throughput of N-point NTT per clock cycle with a compact hardware footprint. Our case study on the Dilithium NTT, implemented using the TSMC 28 nm library, operates at a clock frequency of 1.0 GHz with an area of 1.45 mm^2. On FPGA, the design achieves a throughput-per-LUT that is 5.2x higher than the state-of-the-art implementation.

</details>


### [21] [Multi-Agent Collaborative Intrusion Detection for Low-Altitude Economy IoT: An LLM-Enhanced Agentic AI Framework](https://arxiv.org/abs/2601.17817)
*Hongjuan Li,Hui Kang,Jiahui Li,Geng Sun,Ruichen Zhang,Jiacheng Wang,Dusit Niyato,Wei Ni,Abbas Jamalipour*

Main category: cs.CR

TL;DR: 本文提出了一种基于大语言模型的多智能体协作入侵检测框架，用于解决低空经济物联网网络的安全挑战，实验显示在多个基准数据集上达到超过90%的分类准确率。


<details>
  <summary>Details</summary>
Motivation: 低空经济物联网网络的快速扩张带来了前所未有的安全挑战，包括动态三维移动模式、分布式自主操作和严重资源限制。传统为静态地面网络设计的入侵检测系统无法应对空中物联网环境的独特特性，如频繁的拓扑变化、实时检测要求和能源限制。

Method: 分析LAE-IoT网络的入侵检测需求，全面评估检测效果、响应时间和资源消耗等指标。研究智能体人工智能范式的变革潜力，引入基于大语言模型的智能体AI框架，提出新颖的多智能体协作入侵检测框架，利用专门的LLM增强智能体进行智能数据处理和自适应分类。

Result: 通过实验验证，该框架在多个基准数据集上表现出超过90%的分类准确率，显示出卓越的性能。

Conclusion: 这些结果突显了将智能体AI原理与大语言模型相结合对于下一代LAE-IoT安全系统的变革潜力。

Abstract: The rapid expansion of low-altitude economy Internet of Things (LAE-IoT) networks has created unprecedented security challenges due to dynamic three-dimensional mobility patterns, distributed autonomous operations, and severe resource constraints. Traditional intrusion detection systems designed for static ground-based networks prove inadequate for tackling the unique characteristics of aerial IoT environments, including frequent topology changes, real-time detection requirements, and energy limitations. In this article, we analyze the intrusion detection requirements for LAE-IoT networks, complemented by a comprehensive review of evaluation metrics that cover detection effectiveness, response time, and resource consumption. Then, we investigate transformative potential of agentic artificial intelligence (AI) paradigms and introduce a large language model (LLM)-enabled agentic AI framework for enhancing intrusion detection in LAE-IoT networks. This leads to our proposal of a novel multi-agent collaborative intrusion detection framework that leverages specialized LLM-enhanced agents for intelligent data processing and adaptive classification. Through experimental validation, our framework demonstrates superior performance of over 90\% classification accuracy across multiple benchmark datasets. These results highlight the transformative potential of combining agentic AI principles with LLMs for next-generation LAE-IoT security systems.

</details>


### [22] [An Effective and Cost-Efficient Agentic Framework for Ethereum Smart Contract Auditing](https://arxiv.org/abs/2601.17833)
*Xiaohui Hu,Wun Yu Chan,Yuejie Shi,Qumeng Sun,Wei-Cheng Wang,Chiachih Wu,Haoyu Wang,Ningyu He*

Main category: cs.CR

TL;DR: Heimdallr是一个自动化智能合约审计代理，通过函数级代码重组、启发式推理、功能利用链自动化和级联验证层四大创新，在轻量级开源模型上实现高性能漏洞检测，显著降低分析时间和成本。


<details>
  <summary>Details</summary>
Motivation: 智能合约安全至关重要，但现有解决方案存在明显不足：手动审计不可扩展，静态分析工具误报率高，模糊测试难以处理复杂系统的深层逻辑状态，而新兴的AI方法存在幻觉问题、上下文限制且依赖昂贵的专有大语言模型。

Method: Heimdallr采用四个核心创新：1) 函数级代码重组以最小化上下文开销；2) 启发式推理检测复杂漏洞；3) 自动链式功能利用；4) 级联验证层消除误报。该方法在轻量级开源模型GPToss-120B上实现，无需依赖专有系统。

Result: 评估显示卓越性能：成功重构了20个真实攻击中的17个（总损失3.84亿美元），发现了4个已确认的零日漏洞（保护了4亿美元TVL）。相比SOTA基线，最多减少97.59%分析时间和98.77%成本，检测精度提升超过93.66%。在审计竞赛中，以每万行代码2.31美元的成本实现92.45%检测率。

Conclusion: Heimdallr通过创新的自动化审计方法有效解决了现有智能合约安全工具的局限性，在轻量级开源模型上实现了高性能、低成本的安全审计，提供了生产就绪的审计服务并为未来工作发布了有价值的基准。

Abstract: Smart contract security is paramount, but identifying intricate business logic vulnerabilities remains a persistent challenge because existing solutions consistently fall short: manual auditing is unscalable, static analysis tools are plagued by false positives, and fuzzers struggle to navigate deep logic states within complex systems. Even emerging AI-based methods suffer from hallucinations, context constraints, and a heavy reliance on expensive, proprietary Large Language Models. In this paper, we introduce Heimdallr, an automated auditing agent designed to overcome these hurdles through four core innovations. By reorganizing code at the function level, Heimdallr minimizes context overhead while preserving essential business logic. It then employs heuristic reasoning to detect complex vulnerabilities and automatically chain functional exploits. Finally, a cascaded verification layer validates these findings to eliminate false positives. Notably, this approach achieves high performance on lightweight, open-source models like GPToss-120B without relying on proprietary systems. Our evaluations demonstrate exceptional performance, as Heimdallr successfully reconstructed 17 out of 20 real-world attacks post June 2025, resulting in total losses of $384M, and uncovered 4 confirmed zero-day vulnerabilities that safeguarded $400M in TVL. Compared to SOTA baselines including both official industrial tools and academic tools, Heimdallr at most reduces analysis time by 97.59% and financial costs by 98.77% while boosting detection precision by over 93.66%. Notably, when applied to auditing contests, Heimdallr can achieve a 92.45% detection rate at a negligible cost of $2.31 per 10K LOC. We provide production-ready auditing services and release valuable benchmarks for future work.

</details>


### [23] [The Stateless Pattern: Ephemeral Coordination as the Third Pillar of Digital Sovereignty](https://arxiv.org/abs/2601.17875)
*Sean Carlin,Kevin Curran*

Main category: cs.CR

TL;DR: 论文提出"无状态模式"网络拓扑，用"迷雾"模型替代传统"堡垒"安全模型，通过客户端加密和自毁服务器实例实现服务器作为盲中继而非状态保管者，将数字隐私商品化为实用工具。


<details>
  <summary>Details</summary>
Motivation: 互联网架构三十年来依赖网络通信和价值传输两大支柱，但私人协调这一关键支柱仍依赖中心化中介，默认形成监控架构。需要解决私人协调的中心化依赖问题。

Method: 采用"无状态模式"网络拓扑，使用客户端加密和自毁服务器实例，服务器仅作为盲中继而非状态保管者。通过实时部署(signingroom.io)收集1900多个请求和缓存命中率数据验证系统。

Result: 实证数据验证了系统的"零知识"属性和机构实用性，表明数字隐私可以商品化为实用工具，通过物理而非政策强制执行《世界人权宣言》特定条款。

Conclusion: 无状态模式为私人协调提供了去中心化解决方案，通过技术手段而非政策实现隐私保护，将隐私从依赖信任转变为基于物理的实用工具。

Abstract: For the past three decades, the architecture of the internet has rested on two primary pillars - communication on the World Wide Web and Value such as Bitcoin/Distributed ledgers). However, a third critical pillar, Private Coordination has remained dependent on centralized intermediaries, effectively creating a surveillance architecture by default. This paper introduces the 'Stateless Pattern', a novel network topology that replaces the traditional 'Fortress' security model (database-centric) with a 'Mist' model (ephemeral relays). By utilizing client-side cryptography and self-destructing server instances, we demonstrate a protocol where the server acts as a blind medium rather than a custodian of state. We present empirical data from a live deployment (signingroom.io), analyzing over 1,900 requests and cache-hit ratios to validate the system's 'Zero-Knowledge' properties and institutional utility. The findings suggest that digital privacy can be commoditized as a utility, technically enforcing specific articles of the universal declaration of human rights not through policy, but through physics.

</details>


### [24] [FARM: Few-shot Adaptive Malware Family Classification under Concept Drift](https://arxiv.org/abs/2601.17907)
*Numan Halit Guldemir,Oluwafemi Olukoya,Jesús Martínez-del-Rincón*

Main category: cs.CR

TL;DR: FARM是一个用于Windows PE恶意软件分类的框架，通过三元组自动编码器、无监督漂移检测和少样本学习，有效应对概念漂移问题，在有限监督下提升分类性能。


<details>
  <summary>Details</summary>
Motivation: 恶意软件分类模型面临概念漂移问题，包括协变量漂移和标签漂移，这源于威胁环境的不断演变和新恶意软件家族的出现，导致模型性能下降。

Method: FARM使用三元组自动编码器将样本投影到判别性潜在空间，通过DBSCAN聚类和动态阈值进行无监督漂移检测。采用基于原型的少样本学习进行快速适应，当积累足够漂移样本时支持完全重新训练以更新潜在空间。

Result: 在BenchMFC数据集上的实验表明，FARM在协变量漂移下将分类性能提高了5.6%，仅使用少样本适应在未见恶意软件家族上平均F1分数达到0.85，重新训练后进一步提升到0.94。

Conclusion: FARM在动态恶意软件检测环境中表现出强大的鲁棒性和适应性，能够在有限监督下有效应对概念漂移问题。

Abstract: Malware classification models often face performance degradation due to concept drift, arising from evolving threat landscapes and the emergence of novel malware families. This paper presents FARM (Few-shot Adaptive Recognition of Malware), a framework designed to detect and adapt to both covariate and label drift in Windows Portable Executable (PE) malware classification. FARM leverages a triplet autoencoder to project samples into a discriminative latent space, enabling unsupervised drift detection via DBSCAN clustering and dynamic thresholding. For rapid adaptation, it employs few-shot learning using prototype-based classification, requiring only a handful of labeled samples. FARM also supports full retraining when enough drifted samples accumulate, updating the latent space for long-term integration. Experiments on the BenchMFC dataset demonstrate that FARM improves classification performance under covariate drift by 5.6\%, and achieves an average F1 score of 0.85 on unseen malware families using only few-shot adaptation, which further increases to 0.94 after retraining. These results highlight FARM's robustness and adaptability in dynamic malware detection environments under limited supervision.

</details>


### [25] [From Statistical Disclosure Control to Fair AI: Navigating Fundamental Tradeoffs in Differential Privacy](https://arxiv.org/abs/2601.17909)
*Adriana Watson*

Main category: cs.CR

TL;DR: 论文系统分析了隐私、效用和公平性三者之间的基本权衡关系，揭示了同时实现这三者的根本限制，为部署隐私保护的公平学习系统提供了实践指导。


<details>
  <summary>Details</summary>
Motivation: 当前差分隐私研究主要关注隐私-效用权衡，而公平性约束被低估和研究不足。需要系统性地连接Dalenius的语义隐私不可能性结果、Dwork的可实现差分隐私以及添加公平性要求后的新不可能性结果，为实践者和政策制定者提供统一框架。

Method: 通过具体示例和技术分析，展示隐私、效用和公平性之间的三方帕累托前沿，表征这些基本限制，展示对少数群体的影响，并提供导航这些权衡的实践指导。

Result: 揭示了隐私、效用和公平性之间的基本权衡限制，证明了三者不能同时最优实现，展示了这些限制对少数群体的具体影响，并提供了应对这些权衡的实用方法。

Conclusion: 论文建立了一个统一框架，综合了分散的研究结果，帮助实践者和政策制定者在部署隐私保护的公平学习系统时做出明智决策，认识到隐私、效用和公平性之间的根本权衡关系。

Abstract: Differential privacy has become the gold standard for privacy-preserving machine learning systems. Unfortunately, subsequent work has primarily fixated on the privacy-utility tradeoff, leaving the subject of fairness constraints undervalued and under-researched. This paper provides a systematic treatment connecting three threads: (1) Dalenius's impossibility results for semantic privacy, (2) Dwork's differential privacy as an achievable alternative, and (3) emerging impossibility results from the addition of a fairness requirement. Through concrete examples and technical analysis, the three-way Pareto frontier between privacy, utility, and fairness is demonstrated to showcase the fundamental limits on what can be simultaneously achieved. In this work, these limits are characterized, the impact on minority groups is demonstrated, and practical guidance for navigating these tradeoffs are provided. This forms a unified framework synthesizing scattered results to help practitioners and policymakers make informed decisions when deploying private fair learning systems.

</details>


### [26] [Prompt Injection Evaluations: Refusal Boundary Instability and Artifact-Dependent Compliance in GPT-4-Series Models](https://arxiv.org/abs/2601.17911)
*Thomas Heverin*

Main category: cs.CR

TL;DR: 研究挑战传统将拒绝视为稳定二元安全指标的范式，通过建模拒绝为局部决策边界并检验其在结构化扰动下的稳定性，发现拒绝行为是概率性、依赖具体攻击类型的边界现象而非稳定二元属性。


<details>
  <summary>Details</summary>
Motivation: 传统提示注入评估通常将拒绝视为稳定、二元的安全指标，但本研究挑战这一范式，认为拒绝行为可能不稳定，需要更细致的分析来准确评估LLM的安全性。

Method: 评估GPT-4.1和GPT-4o两个模型，使用3,274次扰动运行（源自拒绝诱导的提示注入尝试）。每个基础提示接受25次跨五个结构化家族的扰动，结果手动编码为拒绝、部分合规或完全合规。使用卡方检验、逻辑回归、混合效应建模和新的拒绝边界熵(RBE)指标进行分析。

Result: 虽然两个模型拒绝超过94%的尝试，但拒绝不稳定性持续存在且不均匀。约三分之一初始拒绝诱导提示在扰动下至少出现一次"拒绝逃逸"（转为合规）。文本类攻击（如勒索软件说明）不稳定性显著更高，翻转率超过20%，而可执行恶意软件攻击在两个模型中均未出现拒绝逃逸。GPT-4o比GPT-4.1有更严格的拒绝执行和更低的RBE，但未消除依赖攻击类型的风险。

Conclusion: 拒绝行为是概率性、依赖具体攻击类型的边界现象而非稳定二元属性，单提示评估系统性地高估安全鲁棒性，需要改变LLM安全性的测量和审计方式。

Abstract: Prompt injection evaluations typically treat refusal as a stable, binary indicator of safety. This study challenges that paradigm by modeling refusal as a local decision boundary and examining its stability under structured perturbations. We evaluated two models, GPT-4.1 and GPT-4o, using 3,274 perturbation runs derived from refusal-inducing prompt injection attempts. Each base prompt was subjected to 25 perturbations across five structured families, with outcomes manually coded as Refusal, Partial Compliance, or Full Compliance.
  Using chi-square tests, logistic regression, mixed-effects modeling, and a novel Refusal Boundary Entropy (RBE) metric, we demonstrate that while both models refuse >94% of attempts, refusal instability is persistent and non-uniform. Approximately one-third of initial refusal-inducing prompts exhibited at least one "refusal escape," a transition to compliance under perturbation. We find that artifact type is a stronger predictor of refusal failure than perturbation style. Textual artifacts, such as ransomware notes, exhibited significantly higher instability, with flip rates exceeding 20%. Conversely, executable malware artifacts showed zero refusal escapes in both models. While GPT-4o demonstrated tighter refusal enforcement and lower RBE than GPT-4.1, it did not eliminate artifact-dependent risks. These findings suggest that single-prompt evaluations systematically overestimate safety robustness. We conclude that refusal behavior is a probabilistic, artifact-dependent boundary phenomenon rather than a stable binary property, requiring a shift in how LLM safety is measured and audited.

</details>


### [27] [Data Siphoning Through Advanced Persistent Transmission Attacks At The Physical Layer](https://arxiv.org/abs/2601.17967)
*Alon Hillel-Tuch*

Main category: cs.CR

TL;DR: 提出开发一种感知与完整性协议来缓解物理侧信道攻击，防止数据窃听和拒绝服务攻击


<details>
  <summary>Details</summary>
Motivation: 物理层数据通过铜缆、光纤或无线等介质传输，存在物理攻击向量威胁数据机密性和可用性。现有协议和加密标准虽然能混淆数据，但往往无法保护数据类型和目的地安全，对机密性和完整性的洞察有限。

Method: 研究开发一种感知与完整性协议的可行性，该协议旨在缓解物理侧信道攻击，包括数据通信窃听和拒绝服务攻击。

Result: 这是一篇研究提案，尚未提供具体实验结果。主要提出了研究物理层攻击缓解协议的可行性。

Conclusion: 需要开发新的感知和完整性协议来应对物理侧信道攻击，保护数据传输的机密性和可用性，特别是针对数据窃听和拒绝服务攻击。

Abstract: Data at the physical layer transmits via media such as copper cable, fiber optic, or wireless. Physical attack vectors exist that challenge data confidentiality and availability. Protocols and encryption standards help obfuscate but often cannot keep the data type and destination secure, with limited insight into confidentiality and integrity. We will investigate the feasibility of developing an awareness and integrity protocol to help mitigate physical side-channel attacks that lead to eavesdropping of data communication and denial-of-service.
  Keywords: data confidentiality, siphoning, eavesdropping, person-in-the-middle, denial-of-service, physical layer attacks, nation-states

</details>


### [28] [MultiChain Blockchain Data Provenance for Deterministic Stream Processing with Kafka Streams: A Weather Data Case Study](https://arxiv.org/abs/2601.18011)
*Niaz Mohammad Ramaki,Florian Schintke*

Main category: cs.CR

TL;DR: 提出基于区块链的流式平台溯源架构，通过Merkle根和Kafka偏移量边界实现窗口数据的可审计性和可重现性验证


<details>
  <summary>Details</summary>
Motivation: 流式数据管道面临可审计性和可重现性挑战，运行时调度、窗口触发、到达顺序和网络抖动等因素导致输出非确定性

Method: 设计区块链支持的溯源架构，对窗口化数据流进行规范化、去重、聚合和确定性序列化，计算Merkle根并与Kafka偏移量边界一起存储到MultiChain区块链流中作为检查点

Result: 使用柏林两个气象站实时数据评估，显示线性验证成本、确定性可重现性、可扩展的链下存储和链上加密锚定，区块链与流式平台集成获得满意的TPS值

Conclusion: 提出的架构使独立审计员能够验证窗口负载完整性、规范化序列化和派生分析的正确性，为流式平台提供了有效的可审计性和可重现性解决方案

Abstract: Auditability and reproducibility still are critical challenges for real-time data streams pipelines. Streaming engines are highly dependent on runtime scheduling, window triggers, arrival orders, and uncertainties such as network jitters. These all derive the streaming pipeline platforms to throw non-determinist outputs. In this work, we introduce a blockchain-backed provenance architecture for streaming platform (e.g Kafka Streams) the publishes cryptographic data of a windowed data stream without publishing window payloads on-chain. We used real-time weather data from weather stations in Berlin. Weather records are canonicalized, deduplicated, and aggregated per window, then serialised deterministically. Furthermore, the Merkle root of the records within the window is computed and stored alongside with Kafka offsets boundaries to MultiChain blockchain streams as checkpoints. Our design can enable an independent auditor to verify: (1) the completeness of window payloads, (2) canonical serialization, and (3) correctness of derived analytics such as minimum/maximum/average temperatures. We evaluated our system using real data stream from two weather stations (Berlin-Brandenburg and Berlin-Tempelhof) and showed linear verification cost, deterministic reproducibility, and with a scalable off-chain storage with on-chain cryptographic anchoring. We also demonstrated that the blockchain can afford to be integrated with streaming platforms particularly with our system, and we get satisfactory transactions per second values.

</details>


### [29] [XGuardian: Towards Explainable and Generalized AI Anti-Cheat on FPS Games](https://arxiv.org/abs/2601.18068)
*Jiayi Zhang,Chenxin Sun,Chenxiong Qian*

Main category: cs.CR

TL;DR: XGuardian是一个用于检测FPS游戏中自瞄作弊的服务器端系统，通过分析玩家视角的俯仰角和偏航角数据，构建时序特征来识别作弊行为，具有高检测性能、低开销和良好可解释性。


<details>
  <summary>Details</summary>
Motivation: 自瞄作弊是FPS游戏中最普遍且臭名昭著的作弊形式，严重威胁游戏产业。现有检测方法存在框架不可靠、泛化性有限、开销高、检测性能低、缺乏可解释性等问题。

Method: XGuardian仅需要俯仰角和偏航角这两个所有FPS游戏必备的原始数据输入，构建新颖的时序特征来描述瞄准轨迹，从而区分作弊者和正常玩家。

Result: 在CS2等主流FPS游戏中评估，验证了跨游戏的泛化能力。相比先前工作，在不同游戏的真实大规模数据集上实现了高检测性能和低开销，展示了广泛的泛化性和高效性。

Conclusion: XGuardian能够为预测结果提供合理解释，从而缩短封禁周期。该系统及其数据集已公开可用，为解决FPS游戏中的自瞄作弊问题提供了有效的解决方案。

Abstract: Aim-assist cheats are the most prevalent and infamous form of cheating in First-Person Shooter (FPS) games, which help cheaters illegally reveal the opponent's location and auto-aim and shoot, and thereby pose significant threats to the game industry. Although a considerable research effort has been made to automatically detect aim-assist cheats, existing works suffer from unreliable frameworks, limited generalizability, high overhead, low detection performance, and a lack of explainability of detection results. In this paper, we propose XGuardian, a server-side generalized and explainable system for detecting aim-assist cheats to overcome these limitations. It requires only two raw data inputs, pitch and yaw, which are all FPS games' must-haves, to construct novel temporal features and describe aim trajectories, which are essential for distinguishing cheaters and normal players. XGuardian is evaluated with the latest mainstream FPS game CS2, and validates its generalizability with another two different games. It achieves high detection performance and low overhead compared to prior works across different games with real-world and large-scale datasets, demonstrating wide generalizability and high effectiveness. It is able to justify its predictions and thereby shorten the ban cycle. We make XGuardian as well as our datasets publicly available.

</details>


### [30] [Mitigating the OWASP Top 10 For Large Language Models Applications using Intelligent Agents](https://arxiv.org/abs/2601.18105)
*Mohammad Fasha,Faisal Abul Rub,Nasim Matar,Bilal Sowan,Mohammad Al Khaldy*

Main category: cs.CR

TL;DR: 提出一个基于LLM智能代理的框架，用于缓解OWASP Top 10中识别的大语言模型安全漏洞


<details>
  <summary>Details</summary>
Motivation: LLM的广泛应用带来了安全风险，OWASP识别了LLM应用的十大安全漏洞，需要解决这些漏洞以保护数据完整性、机密性和服务可用性

Method: 设计一个框架，利用LLM驱动的智能代理，实时主动识别、评估和应对安全威胁

Result: 提出了一个缓解OWASP Top 10安全风险的框架，作为未来研究和开发的初步蓝图

Conclusion: 该框架旨在增强LLM的安全措施，保护其免受快速演变的安全威胁，为LLM安全提供新的主动防御方法

Abstract: Large Language Models (LLMs) have emerged as a transformative and disruptive technology, enabling a wide range of applications in natural language processing, machine translation, and beyond. However, this widespread integration of LLMs also raised several security concerns highlighted by the Open Web Application Security Project (OWASP), which has identified the top 10 security vulnerabilities inherent in LLM applications. Addressing these vulnerabilities is crucial, given the increasing reliance on LLMs and the potential threats to data integrity, confidentiality, and service availability. This paper presents a framework designed to mitigate the security risks outlined in the OWASP Top 10. Our proposed model leverages LLM-enabled intelligent agents, offering a new approach to proactively identify, assess, and counteract security threats in real-time. The proposed framework serves as an initial blueprint for future research and development, aiming to enhance the security measures of LLMs and protect against emerging threats in this rapidly evolving landscape.

</details>


### [31] [MalURLBench: A Benchmark Evaluating Agents' Vulnerabilities When Processing Web URLs](https://arxiv.org/abs/2601.18113)
*Dezhang Kong,Zhuxi Wu,Shiqi Liu,Zhicheng Tan,Kuichen Lu,Minghao Li,Qichen Liu,Shengyu Chu,Zhenhua Xu,Xuan Liu,Meng Han*

Main category: cs.CR

TL;DR: MalURLBench是首个评估LLM对恶意URL漏洞的基准测试，包含61,845个攻击实例，覆盖10个真实场景和7类恶意网站，实验显示现有模型难以检测精心伪装的恶意URL，并提出了轻量级防御模块URLGuard。


<details>
  <summary>Details</summary>
Motivation: 基于LLM的网络代理在日常工作和生活中越来越流行，但它们处理恶意URL时存在关键漏洞：接受伪装的恶意URL会导致访问不安全网页，对服务提供商和用户造成严重损害。目前缺乏针对这一新兴威胁的基准测试。

Method: 提出MalURLBench基准测试，包含61,845个攻击实例，涵盖10个真实世界场景和7类真实恶意网站。对12个流行LLM进行实验评估，分析影响攻击成功率的关键因素，并提出轻量级防御模块URLGuard。

Result: 实验发现现有模型难以检测精心伪装的恶意URL，识别了影响攻击成功率的关键因素，提出的URLGuard防御模块能有效提升安全性。

Conclusion: MalURLBench为推进网络代理安全提供了基础资源，揭示了LLM在恶意URL检测方面的脆弱性，提出的防御方案有助于增强系统安全性。

Abstract: LLM-based web agents have become increasingly popular for their utility in daily life and work. However, they exhibit critical vulnerabilities when processing malicious URLs: accepting a disguised malicious URL enables subsequent access to unsafe webpages, which can cause severe damage to service providers and users. Despite this risk, no benchmark currently targets this emerging threat. To address this gap, we propose MalURLBench, the first benchmark for evaluating LLMs' vulnerabilities to malicious URLs. MalURLBench contains 61,845 attack instances spanning 10 real-world scenarios and 7 categories of real malicious websites. Experiments with 12 popular LLMs reveal that existing models struggle to detect elaborately disguised malicious URLs. We further identify and analyze key factors that impact attack success rates and propose URLGuard, a lightweight defense module. We believe this work will provide a foundational resource for advancing the security of web agents. Our code is available at https://github.com/JiangYingEr/MalURLBench.

</details>


### [32] [Rhea: Detecting Privilege-Escalated Evasive Ransomware Attacks Using Format-Aware Validation in the Cloud](https://arxiv.org/abs/2601.18216)
*Beom Heyn Kim,Seok Min Hong,Mohammad Mannan*

Main category: cs.CR

TL;DR: Rhea是一个云卸载的勒索软件防御系统，通过分析数据快照并使用格式感知验证来检测特权提升的规避性勒索软件，显著优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 现代勒索软件变种结合了特权提升和复杂规避策略（如间歇加密、低熵加密、模仿攻击），能够击败依赖I/O模式分析的现有解决方案，而传统基于统计内容的检测在加密规模减小时因采样噪声变得不可靠。

Method: Rhea采用云卸载架构，分析复制的数据快照（称为突变快照），引入格式感知验证技术，验证文件格式的语法和语义正确性，而不是依赖统计或熵基指标，利用文件格式规范作为检测不变量。

Result: 评估表明Rhea显著优于现有方法，能够可靠识别细粒度和规避性加密，即使攻击者拥有提升的特权，证明了其对现代勒索软件威胁的实际有效性。

Conclusion: Rhea通过格式感知验证方法，为对抗特权提升的规避性勒索软件提供了一种有效的防御方案，克服了传统检测方法的局限性。

Abstract: Ransomware variants increasingly combine privilege escalation with sophisticated evasion strategies such as intermittent encryption, low-entropy encryption, and imitation attacks. Such powerful ransomware variants, privilege-escalated evasive ransomware (PEER), can defeat existing solutions relying on I/O-pattern analysis by tampering with or obfuscating I/O traces. Meanwhile, conventional statistical content-based detection becomes unreliable as the encryption size decreases due to sampling noises. We present Rhea, a cloud-offloaded ransomware defense system that analyzes replicated data snapshots, so-called mutation snapshots. Rhea introduces Format-Aware Validation that validates the syntactic and semantic correctness of file formats, instead of relying on statistical or entropy-based indicators. By leveraging file-format specifications as detection invariants, Rhea can reliably identify fine-grained and evasive encryption even under elevated attacker privileges. Our evaluation demonstrates that Rhea significantly outperforms existing approaches, establishing its practical effectiveness against modern ransomware threats.

</details>


### [33] [Fundamentals, Recent Advances, and Challenges Regarding Cryptographic Algorithms for the Quantum Computing Era](https://arxiv.org/abs/2601.18413)
*Darlan Noetzold,Valderi Reis Quietinho Leithardt*

Main category: cs.CR

TL;DR: 这是一本关于量子计算对密码学影响的葡萄牙语参考书，旨在为学生和专业人士提供从基础概念到实际应用的全面指导，涵盖经典算法、后量子密码学、标准化进程及迁移策略。


<details>
  <summary>Details</summary>
Motivation: 为葡萄牙语读者提供关于量子计算对密码学影响的清晰、最新的概述，填补该语言领域参考资料的空白，帮助学生、研究人员和专业人士理解量子时代密码学的数学原理和实际应用。

Method: 采用渐进式结构：从基本概念开始，介绍量子算法（特别是Shor算法），讨论基于格、编码、哈希函数、多元方程和同源的后量子密码方案，分析NIST标准化进程，最后探讨迁移、互操作性、性能和密码治理。

Result: 创建了一本全面的葡萄牙语参考书，涵盖了量子计算对密码学的完整影响链，从理论基础到实际实施挑战，为读者提供了批判性思维和技术决策的工具。

Conclusion: 本书旨在帮助读者形成批判性思维，做出明智的技术决策，并促进后量子时代的安全过渡策略，为学术界和工业界提供量子密码学时代的实用指南。

Abstract: This book arises from the need to provide a clear and up-to-date overview of the impacts of quantum computing on cryptography. The goal is to provide a reference in Portuguese for undergraduate, master's, and doctoral students in the field of data security and cryptography. Throughout the chapters, we present fundamentals, we discuss classical and post-quantum algorithms, evaluate emerging patterns, and point out real-world implementation challenges. The initial objective is to serve as a guide for students, researchers, and professionals who need to understand not only the mathematics involved, but also its practical implications in security systems and policies. For more advanced professionals, the main objective is to present content and ideas so that they can assess the changes and perspectives in the era of quantum cryptographic algorithms. To that end, the text's structure was designed to be progressive: we begin with essential concepts, move on to quantum algorithms and their consequences (with emphasis on Shor's algorithm), present issues focusing on "families" of post-quantum schemes (based on lattices, codes, hash functions, multivariate, isogenies), analyze the state of the art in standardization (highlighting the NIST process), and finally, discuss migration, interoperability, performance, and cryptographic governance. We hope that this work will assist in the formation of critical thinking and informed technical decision-making, fostering secure transition strategies for the post-quantum era.

</details>


### [34] [KeyMemRT Compiler and Runtime: Unlocking Memory-Scalable FHE](https://arxiv.org/abs/2601.18445)
*Eymen Ünay,Björn Franke,Jackson Woodruff*

Main category: cs.CR

TL;DR: KeyMemRT是一个基于MLIR的FHE编译器框架，通过管理旋转密钥生命周期来降低内存使用，支持任意数量的旋转索引而不导致内存膨胀。


<details>
  <summary>Details</summary>
Motivation: FHE中的旋转密钥占用大量内存，成为复杂应用的内存瓶颈。现有编译器对此问题解决不足，依赖大内存系统，阻碍了FHE的普及。

Method: 基于MLIR的编译器和运行时框架，通过数据流分析确定密钥生命周期，自动管理旋转密钥和引导密钥，支持细粒度密钥管理。

Result: 相比ANT-ACE实现1.74倍内存降低和1.20倍加速；相比Fhelipe实现1.16倍内存降低和1.73倍加速。

Conclusion: KeyMemRT作为后优化编译器，可被任何FHE编译器使用，首次实现了自动密钥管理，解决了FHE中的内存瓶颈问题。

Abstract: Fully Homomorphic Encryption (FHE) enables privacy preserving computation but it suffers from high latency and memory consumption. The computations are secured with special keys called rotation keys which often take up the majority of memory. In complex FHE applications, these rotation keys can cause a large memory bottleneck limiting program throughput. Existing compilers make little effort to solve this problem, instead relying on systems with massive memory availability. This resource requirement is a barrier to FHE uptake because optimizing FHE programs by hand is challenging due to their scale, complexity and expertise required.
  In this work, we present KeyMemRT; an MLIR based compiler and runtime framework that individually manages rotation key lifetimes to lower memory utilization and to allow arbitrary number of rotation indices to be supported without memory bloating. KeyMemRT relies on dataflow analysis to determine key lifetimes and is the first FHE compiler to provide automatic key management, handle fine-grained key-mangement and manage boostrap keys. We implement frontends for Orion and HEIR and show improvements over state-of-the-art FHE compilers. KeyMemRT achieves memory reduction of 1.74x and a speedup of 1.20x over ANT-ACE, and memory reduction of 1.16x and a speedup of 1.73x over memory-optimized compiler Fhelipe. We provide KeyMemRT as a post-optimizing compiler that can be targeted by any FHE compiler.

</details>


### [35] [Scaling up Privacy-Preserving ML: A CKKS Implementation of Llama-2-7B](https://arxiv.org/abs/2601.18511)
*Jaiyoung Park,Sejin Park,Jai Hyun Park,Jung Ho Ahn,Jung Hee Cheon,Guillaume Hanrot,Jung Woo Kim,Minje Park,Damien Stehlé*

Main category: cs.CR

TL;DR: 提出一种基于FHE的私有LLM推理方案，支持数千输入token，仅部分需要加密，通过不平衡分块预填充框架和机器学习策略优化性能。


<details>
  <summary>Details</summary>
Motivation: 随着LLM普及，推理输入的隐私问题日益突出。现有FHE方案在处理长输入token时扩展性差，且受异常值影响大，导致非线性层评估成本高。

Method: 提出不平衡分块预填充框架，将输入分为公开和私有部分分别处理；设计新的同态算法用于矩阵乘法和多项式评估；采用token前置和旋转等机器学习策略减少异常值影响。

Result: 实现了基于CKKS的Llama-2-7B端到端私有推理，支持最多4096个输入token（最后128个加密）。在8个RTX-4090 GPU集群上，摘要推理85秒，生成每个输出token需33秒。

Conclusion: 该方案显著提升了FHE在LLM私有推理中的实用性，支持长输入序列且仅部分加密，通过算法优化和机器学习策略有效降低了计算成本。

Abstract: As large language models (LLMs) become ubiquitous, privacy concerns pertaining to inference inputs keep growing. In this context, fully homomorphic encryption (FHE) has emerged as a primary cryptographic solution to provide non-interactive confidential LLM inference. Existing solutions scale poorly with the input token length, and hence focus either on small models or larger models with a small number of input tokens. They also suffer from the existence of large outlier values. These values have a strong impact on the evaluation of non-linear layers, leading to large-degree polynomial approximation and thus heavy evaluation costs.
  We propose an FHE-based private LLM inference solution that allows thousands of input tokens with only a part of them being encrypted: this fits with a scenario where the context is benign and only part of the input is sensitive. To do so, we suggest an unbalanced chunked prefill framework that processes the private and public parts of the input tokens differently. Our framework contains plaintext-plaintext, plaintext-ciphertext and ciphertext-ciphertext computational components. We adopt different strategies and ingredients for each component. We also devise new homomorphic algorithms for specific matrix multiplication and polynomial evaluation tasks encountered during LLM inference.
  Furthermore, without retraining, we tailor the LLM inference algorithm to reduce the ranges of outlier values: we leverage machine learning strategies (token prepending and rotations) to mitigate the impact of the outliers on non-linear layers.
  Based on these ingredients, we describe a CKKS-based end-to-end implementation of Llama-2-7B private inference for up to 4096 input tokens, of which the last 128 are encrypted. On a cluster of 8~NVIDIA RTX-4090 GPUs, inference takes 85s for summarization and 33s for generation per output token.

</details>


### [36] [Multimodal Privacy-Preserving Entity Resolution with Fully Homomorphic Encryption](https://arxiv.org/abs/2601.18612)
*Susim Roy,Nalini Ratha*

Main category: cs.CR

TL;DR: 提出一种多模态框架，用于高合规性领域的实体解析，在保护隐私的同时处理大规模异构数据，实现低错误率和计算可行性。


<details>
  <summary>Details</summary>
Motivation: 高合规性领域（如政府和金融机构）的实体解析面临三大挑战：数据量巨大、匹配准确性要求高、隐私保护需求严格。传统方法难以同时满足这些要求，特别是在处理包含语法变异的个人标识符等异构数据时。

Method: 采用多模态框架，在整个匹配生命周期中保持个人身份信息的明文计算不可访问。通过密码学方法确保客户机密性，同时处理典型的大规模数据集。

Result: 实现了显著低的等错误率，保持了大规模计算的可处理性，使机构能够严格满足监管要求，同时提供密码学保证的客户机密性。

Conclusion: 该多模态框架成功解决了高合规性领域实体解析的三重挑战（数据量、匹配保真度、隐私），为政府和金融机构提供了一种安全、准确且可扩展的解决方案。

Abstract: The canonical challenge of entity resolution within high-compliance sectors, where secure identity reconciliation is frequently confounded by significant data heterogeneity, including syntactic variations in personal identifiers, is a longstanding and complex problem. To this end, we introduce a novel multimodal framework operating with the voluminous data sets typical of government and financial institutions. Specifically, our methodology is designed to address the tripartite challenge of data volume, matching fidelity, and privacy. Consequently, the underlying plaintext of personally identifiable information remains computationally inaccessible throughout the matching lifecycle, empowering institutions to rigorously satisfy stringent regulatory mandates with cryptographic assurances of client confidentiality while achieving a demonstrably low equal error rate and maintaining computational tractability at scale.

</details>


### [37] [$α^3$-SecBench: A Large-Scale Evaluation Suite of Security, Resilience, and Trust for LLM-based UAV Agents over 6G Networks](https://arxiv.org/abs/2601.18754)
*Mohamed Amine Ferrag,Abderrahmane Lakas,Merouane Debbah*

Main category: cs.CR

TL;DR: α³-SecBench是首个评估LLM无人机代理在对抗环境下安全自主性的大规模测试套件，包含2万个攻击场景，覆盖7个自主层级，评估23个主流LLM模型。


<details>
  <summary>Details</summary>
Motivation: 当前LLM无人机代理在安全关键网络环境中的安全性和抗攻击能力评估不足，特别是在6G新兴环境下，缺乏系统性的安全、韧性和信任评估基准。

Method: 基于α³-Bench的多轮对话无人机任务，增加了2万个经过验证的安全覆盖攻击场景，覆盖感知、规划、控制、通信、边缘/云基础设施和LLM推理等7个自主层级，从安全、韧性和信任三个维度评估代理。

Result: 评估了23个主流LLM模型，使用来自113,475个任务、175种威胁类型的对抗性增强无人机任务。多数模型能检测异常行为，但在有效缓解、漏洞归因和可信控制行动方面表现不一致，总体得分在12.9%到57.1%之间。

Conclusion: LLM无人机代理在异常检测和安全自主决策之间存在显著差距，需要进一步研究提升其在对抗环境下的安全意识和决策能力。α³-SecBench已开源发布。

Abstract: Autonomous unmanned aerial vehicle (UAV) systems are increasingly deployed in safety-critical, networked environments where they must operate reliably in the presence of malicious adversaries. While recent benchmarks have evaluated large language model (LLM)-based UAV agents in reasoning, navigation, and efficiency, systematic assessment of security, resilience, and trust under adversarial conditions remains largely unexplored, particularly in emerging 6G-enabled settings.
  We introduce $α^{3}$-SecBench, the first large-scale evaluation suite for assessing the security-aware autonomy of LLM-based UAV agents under realistic adversarial interference. Building on multi-turn conversational UAV missions from $α^{3}$-Bench, the framework augments benign episodes with 20,000 validated security overlay attack scenarios targeting seven autonomy layers, including sensing, perception, planning, control, communication, edge/cloud infrastructure, and LLM reasoning. $α^{3}$-SecBench evaluates agents across three orthogonal dimensions: security (attack detection and vulnerability attribution), resilience (safe degradation behavior), and trust (policy-compliant tool usage).
  We evaluate 23 state-of-the-art LLMs from major industrial providers and leading AI labs using thousands of adversarially augmented UAV episodes sampled from a corpus of 113,475 missions spanning 175 threat types. While many models reliably detect anomalous behavior, effective mitigation, vulnerability attribution, and trustworthy control actions remain inconsistent. Normalized overall scores range from 12.9% to 57.1%, highlighting a significant gap between anomaly detection and security-aware autonomous decision-making. We release $α^{3}$-SecBench on GitHub: https://github.com/maferrag/AlphaSecBench

</details>
