{"id": "2601.22182", "categories": ["cs.CR", "cs.AI"], "pdf": "https://arxiv.org/pdf/2601.22182", "abs": "https://arxiv.org/abs/2601.22182", "authors": ["Yizhong Ding"], "title": "ShellForge: Adversarial Co-Evolution of Webshell Generation and Multi-View Detection for Robust Webshell Defense", "comment": null, "summary": "Webshells remain a primary foothold for attackers to compromise servers, particularly within PHP ecosystems. However, existing detection mechanisms often struggle to keep pace with rapid variant evolution and sophisticated obfuscation techniques that camouflage malicious intent. Furthermore, many current defenses suffer from high false-alarm rates when encountering benign administrative scripts that employ heavy obfuscation for intellectual property protection. To address these challenges, we present ShellForge, an adversarial co-evolution framework that couples automated webshell generation with multi-view detection to continuously harden defensive boundaries. The framework operates through an iterative co-training loop where a generator and a detector mutually reinforce each other via the exchange of hard samples. The generator is optimized through supervised fine-tuning and preference-based reinforcement learning to synthesize functional, highly evasive variants. Simultaneously, we develop a multi-view fusion detector that integrates semantic features from long-string compression, structural features from pruned abstract syntax trees, and global statistical indicators such as Shannon entropy. To minimize false positives, ShellForge utilizes a LLM-based transformation to create de-malicious samples--scripts that retain complex obfuscation patterns but lack harmful payloads--serving as high-quality hard negatives during training. Evaluations on the public FWOID benchmark demonstrate that ShellForge significantly enhances defensive robustness. Upon convergence, the detector maintains a 0.981 F1-score while the generator achieves a 0.939 evasion rate against commercial engines on VirusTotal.", "AI": {"tldr": "ShellForge\u662f\u4e00\u4e2a\u5bf9\u6297\u6027\u534f\u540c\u8fdb\u5316\u6846\u67b6\uff0c\u901a\u8fc7\u81ea\u52a8\u751f\u6210webshell\u548c\u591a\u89c6\u56fe\u68c0\u6d4b\u6765\u589e\u5f3aPHP webshell\u9632\u5fa1\u80fd\u529b\uff0c\u663e\u8457\u63d0\u9ad8\u68c0\u6d4b\u51c6\u786e\u7387\u5e76\u964d\u4f4e\u8bef\u62a5\u3002", "motivation": "\u73b0\u6709PHP webshell\u68c0\u6d4b\u673a\u5236\u96be\u4ee5\u5e94\u5bf9\u5feb\u901f\u53d8\u79cd\u548c\u590d\u6742\u6df7\u6dc6\u6280\u672f\uff0c\u4e14\u5bf9\u7528\u4e8e\u77e5\u8bc6\u4ea7\u6743\u4fdd\u62a4\u7684\u826f\u6027\u6df7\u6dc6\u811a\u672c\u8bef\u62a5\u7387\u9ad8\uff0c\u9700\u8981\u66f4\u9c81\u68d2\u7684\u9632\u5fa1\u65b9\u6848\u3002", "method": "\u91c7\u7528\u5bf9\u6297\u6027\u534f\u540c\u8bad\u7ec3\u6846\u67b6\uff0c\u5305\u542b\u751f\u6210\u5668\u548c\u68c0\u6d4b\u5668\u5faa\u73af\u5f3a\u5316\u3002\u751f\u6210\u5668\u901a\u8fc7\u76d1\u7763\u5fae\u8c03\u548c\u57fa\u4e8e\u504f\u597d\u7684\u5f3a\u5316\u5b66\u4e60\u5408\u6210\u529f\u80fd\u6027\u3001\u9ad8\u89c4\u907f\u6027\u53d8\u79cd\uff1b\u68c0\u6d4b\u5668\u878d\u5408\u957f\u5b57\u7b26\u4e32\u538b\u7f29\u8bed\u4e49\u7279\u5f81\u3001\u4fee\u526a\u62bd\u8c61\u8bed\u6cd5\u6811\u7ed3\u6784\u7279\u5f81\u548c\u9999\u519c\u71b5\u7b49\u5168\u5c40\u7edf\u8ba1\u6307\u6807\uff1b\u4f7f\u7528LLM\u751f\u6210\u53bb\u6076\u610f\u6837\u672c\u4f5c\u4e3a\u9ad8\u8d28\u91cf\u8d1f\u6837\u672c\u3002", "result": "\u5728FWOID\u57fa\u51c6\u6d4b\u8bd5\u4e2d\uff0c\u68c0\u6d4b\u5668\u4fdd\u63010.981 F1\u5206\u6570\uff0c\u751f\u6210\u5668\u5728VirusTotal\u4e0a\u5bf9\u5546\u4e1a\u5f15\u64ce\u8fbe\u52300.939\u7684\u89c4\u907f\u7387\uff0c\u663e\u8457\u63d0\u5347\u9632\u5fa1\u9c81\u68d2\u6027\u3002", "conclusion": "ShellForge\u901a\u8fc7\u5bf9\u6297\u6027\u534f\u540c\u8fdb\u5316\u6709\u6548\u89e3\u51b3\u4e86webshell\u68c0\u6d4b\u4e2d\u7684\u53d8\u79cd\u6f14\u5316\u548c\u8bef\u62a5\u95ee\u9898\uff0c\u4e3aPHP\u670d\u52a1\u5668\u5b89\u5168\u63d0\u4f9b\u4e86\u66f4\u5f3a\u5927\u7684\u9632\u5fa1\u6846\u67b6\u3002"}}
{"id": "2601.22185", "categories": ["cs.CR", "cs.CY"], "pdf": "https://arxiv.org/pdf/2601.22185", "abs": "https://arxiv.org/abs/2601.22185", "authors": ["Alberto Maria Mongardini", "Alessandro Mei"], "title": "MemeChain: A Multimodal Cross-Chain Dataset for Meme Coin Forensics and Risk Analysis", "comment": null, "summary": "The meme coin ecosystem has grown into one of the most active yet least observable segments of the cryptocurrency market, characterized by extreme churn, minimal project commitment, and widespread fraudulent behavior. While countless meme coins are deployed across multiple blockchains, they rely heavily on off-chain web and social infrastructure to signal legitimacy. These very signals are largely absent from existing datasets, which are often limited to single-chain data or lack the multimodal artifacts required for comprehensive risk modeling.\n  To address this gap, we introduce MemeChain, a large-scale, open-source, cross-chain dataset comprising 34,988 meme coins across Ethereum, BNB Smart Chain, Solana, and Base. MemeChain integrates on-chain data with off-chain artifacts, including website HTML source code, token logos, and linked social media accounts, enabling multimodal and forensic study of meme coin projects. Analysis of the dataset shows that visual branding is frequently omitted in low-effort deployments, and many projects lack a functional website. Moreover, we quantify the ecosystem's extreme volatility, identifying 1,801 tokens (5.15%) that cease all trading activity within just 24 hours of launch. By providing unified cross-chain coverage and rich off-chain context, MemeChain serves as a foundational resource for research in financial forensics, multimodal anomaly detection, and automated scam prevention in the meme coin ecosystem.", "AI": {"tldr": "MemeChain\u662f\u4e00\u4e2a\u5927\u89c4\u6a21\u3001\u5f00\u6e90\u3001\u8de8\u94fe\u6570\u636e\u96c6\uff0c\u5305\u542b34,988\u4e2ameme\u5e01\uff0c\u6574\u5408\u4e86\u94fe\u4e0a\u6570\u636e\u548c\u94fe\u4e0b\u6587\u7269\uff08\u7f51\u7ad9HTML\u3001\u4ee3\u5e01logo\u3001\u793e\u4ea4\u5a92\u4f53\u8d26\u6237\uff09\uff0c\u7528\u4e8e\u7814\u7a76meme\u5e01\u751f\u6001\u7cfb\u7edf\u7684\u98ce\u9669\u5efa\u6a21\u548c\u6b3a\u8bc8\u68c0\u6d4b\u3002", "motivation": "meme\u5e01\u751f\u6001\u7cfb\u7edf\u662f\u52a0\u5bc6\u8d27\u5e01\u5e02\u573a\u4e2d\u6700\u6d3b\u8dc3\u4f46\u6700\u4e0d\u53ef\u89c2\u5bdf\u7684\u90e8\u5206\uff0c\u5177\u6709\u6781\u9ad8\u7684\u6d41\u5931\u7387\u3001\u6700\u5c0f\u7684\u9879\u76ee\u627f\u8bfa\u548c\u5e7f\u6cdb\u7684\u6b3a\u8bc8\u884c\u4e3a\u3002\u73b0\u6709\u6570\u636e\u96c6\u901a\u5e38\u9650\u4e8e\u5355\u94fe\u6570\u636e\u6216\u7f3a\u4e4f\u591a\u6a21\u6001\u6587\u7269\uff0c\u65e0\u6cd5\u8fdb\u884c\u5168\u9762\u98ce\u9669\u5efa\u6a21\u3002", "method": "\u6784\u5efaMemeChain\u6570\u636e\u96c6\uff0c\u6574\u5408\u4ee5\u592a\u574a\u3001BNB\u667a\u80fd\u94fe\u3001Solana\u548cBase\u56db\u4e2a\u533a\u5757\u94fe\u4e0a\u768434,988\u4e2ameme\u5e01\u6570\u636e\uff0c\u5305\u62ec\u94fe\u4e0a\u4ea4\u6613\u6570\u636e\u548c\u94fe\u4e0b\u6587\u7269\uff08\u7f51\u7ad9HTML\u6e90\u4ee3\u7801\u3001\u4ee3\u5e01logo\u3001\u94fe\u63a5\u7684\u793e\u4ea4\u5a92\u4f53\u8d26\u6237\uff09\u3002", "result": "\u5206\u6790\u663e\u793a\uff1a1\uff09\u4f4e\u8d28\u91cf\u90e8\u7f72\u7ecf\u5e38\u7701\u7565\u89c6\u89c9\u54c1\u724c\uff1b2\uff09\u8bb8\u591a\u9879\u76ee\u7f3a\u4e4f\u529f\u80fd\u6027\u7f51\u7ad9\uff1b3\uff09\u751f\u6001\u7cfb\u7edf\u6781\u7aef\u6ce2\u52a8\uff0c1,801\u4e2a\u4ee3\u5e01\uff085.15%\uff09\u5728\u542f\u52a8\u540e24\u5c0f\u65f6\u5185\u505c\u6b62\u6240\u6709\u4ea4\u6613\u6d3b\u52a8\u3002", "conclusion": "MemeChain\u901a\u8fc7\u63d0\u4f9b\u7edf\u4e00\u7684\u8de8\u94fe\u8986\u76d6\u548c\u4e30\u5bcc\u7684\u94fe\u4e0b\u4e0a\u4e0b\u6587\uff0c\u6210\u4e3a\u91d1\u878d\u53d6\u8bc1\u3001\u591a\u6a21\u6001\u5f02\u5e38\u68c0\u6d4b\u548cmeme\u5e01\u751f\u6001\u7cfb\u7edf\u81ea\u52a8\u6b3a\u8bc8\u9884\u9632\u7814\u7a76\u7684\u57fa\u7840\u8d44\u6e90\u3002"}}
{"id": "2601.22240", "categories": ["cs.CR", "cs.AI", "cs.CL", "cs.LG"], "pdf": "https://arxiv.org/pdf/2601.22240", "abs": "https://arxiv.org/abs/2601.22240", "authors": ["Pedro H. Barcha Correia", "Ryan W. Achjian", "Diego E. G. Caetano de Oliveira", "Ygor Acacio Maria", "Victor Takashi Hayashi", "Marcos Lopes", "Charles Christian Miers", "Marcos A. Simplicio"], "title": "A Systematic Literature Review on LLM Defenses Against Prompt Injection and Jailbreaking: Expanding NIST Taxonomy", "comment": "27 pages, 14 figures, 11 tables, submitted to Elsevier Computer Science Review", "summary": "The rapid advancement and widespread adoption of generative artificial intelligence (GenAI) and large language models (LLMs) has been accompanied by the emergence of new security vulnerabilities and challenges, such as jailbreaking and other prompt injection attacks. These maliciously crafted inputs can exploit LLMs, causing data leaks, unauthorized actions, or compromised outputs, for instance. As both offensive and defensive prompt injection techniques evolve quickly, a structured understanding of mitigation strategies becomes increasingly important. To address that, this work presents the first systematic literature review on prompt injection mitigation strategies, comprehending 88 studies. Building upon NIST's report on adversarial machine learning, this work contributes to the field through several avenues. First, it identifies studies beyond those documented in NIST's report and other academic reviews and surveys. Second, we propose an extension to NIST taxonomy by introducing additional categories of defenses. Third, by adopting NIST's established terminology and taxonomy as a foundation, we promote consistency and enable future researchers to build upon the standardized taxonomy proposed in this work. Finally, we provide a comprehensive catalog of the reviewed prompt injection defenses, documenting their reported quantitative effectiveness across specific LLMs and attack datasets, while also indicating which solutions are open-source and model-agnostic. This catalog, together with the guidelines presented herein, aims to serve as a practical resource for researchers advancing the field of adversarial machine learning and for developers seeking to implement effective defenses in production systems.", "AI": {"tldr": "\u5bf988\u9879\u7814\u7a76\u7684\u9996\u6b21\u7cfb\u7edf\u6027\u6587\u732e\u7efc\u8ff0\uff0c\u63d0\u51fa\u4e86\u63d0\u793a\u6ce8\u5165\u9632\u5fa1\u7b56\u7565\u7684\u5206\u7c7b\u6846\u67b6\u548c\u5b9e\u7528\u8d44\u6e90\u76ee\u5f55", "motivation": "\u968f\u7740\u751f\u6210\u5f0fAI\u548c\u5927\u578b\u8bed\u8a00\u6a21\u578b\u7684\u5feb\u901f\u53d1\u5c55\uff0c\u51fa\u73b0\u4e86\u65b0\u7684\u5b89\u5168\u6f0f\u6d1e\u5982\u8d8a\u72f1\u548c\u63d0\u793a\u6ce8\u5165\u653b\u51fb\u3002\u8fd9\u4e9b\u6076\u610f\u8f93\u5165\u53ef\u80fd\u5bfc\u81f4\u6570\u636e\u6cc4\u9732\u3001\u672a\u6388\u6743\u64cd\u4f5c\u6216\u8f93\u51fa\u88ab\u7be1\u6539\u3002\u7531\u4e8e\u653b\u9632\u6280\u672f\u5feb\u901f\u6f14\u8fdb\uff0c\u9700\u8981\u7cfb\u7edf\u6027\u5730\u7406\u89e3\u9632\u5fa1\u7b56\u7565\u3002", "method": "\u57fa\u4e8eNIST\u5bf9\u6297\u673a\u5668\u5b66\u4e60\u62a5\u544a\uff0c\u5bf988\u9879\u7814\u7a76\u8fdb\u884c\u7cfb\u7edf\u6027\u6587\u732e\u7efc\u8ff0\uff0c\u6269\u5c55NIST\u5206\u7c7b\u6cd5\uff0c\u5f15\u5165\u65b0\u7684\u9632\u5fa1\u7c7b\u522b\uff0c\u5efa\u7acb\u6807\u51c6\u5316\u672f\u8bed\u548c\u5206\u7c7b\u4f53\u7cfb\u3002", "result": "\u63d0\u51fa\u4e86\u6269\u5c55\u7684NIST\u5206\u7c7b\u6cd5\uff0c\u521b\u5efa\u4e86\u5168\u9762\u7684\u63d0\u793a\u6ce8\u5165\u9632\u5fa1\u76ee\u5f55\uff0c\u8bb0\u5f55\u4e86\u5404\u9879\u9632\u5fa1\u5728\u7279\u5b9aLLM\u548c\u653b\u51fb\u6570\u636e\u96c6\u4e0a\u7684\u5b9a\u91cf\u6548\u679c\uff0c\u5e76\u6807\u6ce8\u4e86\u5f00\u6e90\u548c\u6a21\u578b\u65e0\u5173\u7684\u89e3\u51b3\u65b9\u6848\u3002", "conclusion": "\u8be5\u5de5\u4f5c\u4e3a\u5bf9\u6297\u673a\u5668\u5b66\u4e60\u9886\u57df\u7684\u7814\u7a76\u4eba\u5458\u548c\u5f00\u53d1\u4eba\u5458\u63d0\u4f9b\u4e86\u5b9e\u7528\u7684\u8d44\u6e90\uff0c\u5305\u62ec\u5206\u7c7b\u6846\u67b6\u3001\u9632\u5fa1\u76ee\u5f55\u548c\u5b9e\u65bd\u6307\u5357\uff0c\u6709\u52a9\u4e8e\u63a8\u52a8\u8be5\u9886\u57df\u7684\u6807\u51c6\u5316\u548c\u5b9e\u8df5\u5e94\u7528\u3002"}}
{"id": "2601.22246", "categories": ["cs.CR", "cs.AI"], "pdf": "https://arxiv.org/pdf/2601.22246", "abs": "https://arxiv.org/abs/2601.22246", "authors": ["Ya Jiang", "Massieh Kordi Boroujeny", "Surender Suresh Kumar", "Kai Zeng"], "title": "MirrorMark: A Distortion-Free Multi-Bit Watermark for Large Language Models", "comment": null, "summary": "As large language models (LLMs) become integral to applications such as question answering and content creation, reliable content attribution has become increasingly important. Watermarking is a promising approach, but existing methods either provide only binary signals or distort the sampling distribution, degrading text quality; distortion-free approaches, in turn, often suffer from weak detectability or robustness. We propose MirrorMark, a multi-bit and distortion-free watermark for LLMs. By mirroring sampling randomness in a measure-preserving manner, MirrorMark embeds multi-bit messages without altering the token probability distribution, preserving text quality by design. To improve robustness, we introduce a context-based scheduler that balances token assignments across message positions while remaining resilient to insertions and deletions. We further provide a theoretical analysis of the equal error rate to interpret empirical performance. Experiments show that MirrorMark matches the text quality of non-watermarked generation while achieving substantially stronger detectability: with 54 bits embedded in 300 tokens, it improves bit accuracy by 8-12% and correctly identifies up to 11% more watermarked texts at 1% false positive rate.", "AI": {"tldr": "MirrorMark\u662f\u4e00\u79cd\u7528\u4e8e\u5927\u8bed\u8a00\u6a21\u578b\u7684\u591a\u6bd4\u7279\u3001\u65e0\u5931\u771f\u7684\u6c34\u5370\u65b9\u6cd5\uff0c\u901a\u8fc7\u955c\u50cf\u91c7\u6837\u968f\u673a\u6027\u5d4c\u5165\u591a\u6bd4\u7279\u4fe1\u606f\u800c\u4e0d\u6539\u53d8token\u6982\u7387\u5206\u5e03\uff0c\u4fdd\u6301\u6587\u672c\u8d28\u91cf\u7684\u540c\u65f6\u663e\u8457\u63d0\u5347\u68c0\u6d4b\u80fd\u529b\u3002", "motivation": "\u968f\u7740\u5927\u8bed\u8a00\u6a21\u578b\u5728\u95ee\u7b54\u548c\u5185\u5bb9\u521b\u4f5c\u7b49\u5e94\u7528\u4e2d\u7684\u666e\u53ca\uff0c\u53ef\u9760\u7684\u5185\u5bb9\u6eaf\u6e90\u53d8\u5f97\u65e5\u76ca\u91cd\u8981\u3002\u73b0\u6709\u6c34\u5370\u65b9\u6cd5\u8981\u4e48\u53ea\u80fd\u63d0\u4f9b\u4e8c\u8fdb\u5236\u4fe1\u53f7\uff0c\u8981\u4e48\u4f1a\u626d\u66f2\u91c7\u6837\u5206\u5e03\u964d\u4f4e\u6587\u672c\u8d28\u91cf\uff1b\u800c\u65e0\u5931\u771f\u65b9\u6cd5\u5f80\u5f80\u68c0\u6d4b\u80fd\u529b\u5f31\u6216\u9c81\u68d2\u6027\u5dee\u3002", "method": "\u63d0\u51faMirrorMark\u6c34\u5370\u65b9\u6cd5\uff1a1) \u901a\u8fc7\u955c\u50cf\u91c7\u6837\u968f\u673a\u6027\u7684\u4fdd\u6d4b\u5ea6\u65b9\u5f0f\u5d4c\u5165\u591a\u6bd4\u7279\u4fe1\u606f\uff0c\u4e0d\u6539\u53d8token\u6982\u7387\u5206\u5e03\uff1b2) \u5f15\u5165\u57fa\u4e8e\u4e0a\u4e0b\u6587\u7684\u8c03\u5ea6\u5668\uff0c\u5e73\u8861\u4e0d\u540c\u6d88\u606f\u4f4d\u7f6e\u7684token\u5206\u914d\uff0c\u540c\u65f6\u4fdd\u6301\u5bf9\u63d2\u5165\u548c\u5220\u9664\u64cd\u4f5c\u7684\u9c81\u68d2\u6027\uff1b3) \u63d0\u4f9b\u9519\u8bef\u7387\u7684\u7406\u8bba\u5206\u6790\u6765\u89e3\u91ca\u7ecf\u9a8c\u6027\u80fd\u3002", "result": "\u5b9e\u9a8c\u8868\u660eMirrorMark\u4e0e\u975e\u6c34\u5370\u751f\u6210\u7684\u6587\u672c\u8d28\u91cf\u76f8\u5f53\uff0c\u540c\u65f6\u68c0\u6d4b\u80fd\u529b\u663e\u8457\u589e\u5f3a\uff1a\u5728300\u4e2atoken\u4e2d\u5d4c\u516554\u6bd4\u7279\u65f6\uff0c\u6bd4\u7279\u51c6\u786e\u7387\u63d0\u9ad88-12%\uff0c\u57281%\u8bef\u62a5\u7387\u4e0b\u80fd\u6b63\u786e\u8bc6\u522b\u591a\u51fa11%\u7684\u6c34\u5370\u6587\u672c\u3002", "conclusion": "MirrorMark\u662f\u4e00\u79cd\u6709\u6548\u7684\u591a\u6bd4\u7279\u3001\u65e0\u5931\u771f\u6c34\u5370\u65b9\u6cd5\uff0c\u5728\u4fdd\u6301\u6587\u672c\u8d28\u91cf\u7684\u540c\u65f6\u663e\u8457\u63d0\u5347\u4e86\u6c34\u5370\u7684\u68c0\u6d4b\u80fd\u529b\u548c\u9c81\u68d2\u6027\uff0c\u4e3a\u5927\u8bed\u8a00\u6a21\u578b\u7684\u5185\u5bb9\u6eaf\u6e90\u63d0\u4f9b\u4e86\u5b9e\u7528\u89e3\u51b3\u65b9\u6848\u3002"}}
{"id": "2601.22434", "categories": ["cs.CR", "cs.CY", "cs.LG"], "pdf": "https://arxiv.org/pdf/2601.22434", "abs": "https://arxiv.org/abs/2601.22434", "authors": ["Georgi Ganev", "Emiliano De Cristofaro"], "title": "Rethinking Anonymity Claims in Synthetic Data Generation: A Model-Centric Privacy Attack Perspective", "comment": null, "summary": "Training generative machine learning models to produce synthetic tabular data has become a popular approach for enhancing privacy in data sharing. As this typically involves processing sensitive personal information, releasing either the trained model or generated synthetic datasets can still pose privacy risks. Yet, recent research, commercial deployments, and privacy regulations like the General Data Protection Regulation (GDPR) largely assess anonymity at the level of an individual dataset.\n  In this paper, we rethink anonymity claims about synthetic data from a model-centric perspective and argue that meaningful assessments must account for the capabilities and properties of the underlying generative model and be grounded in state-of-the-art privacy attacks. This perspective better reflects real-world products and deployments, where trained models are often readily accessible for interaction or querying. We interpret the GDPR's definitions of personal data and anonymization under such access assumptions to identify the types of identifiability risks that must be mitigated and map them to privacy attacks across different threat settings. We then argue that synthetic data techniques alone do not ensure sufficient anonymization. Finally, we compare the two mechanisms most commonly used alongside synthetic data -- Differential Privacy (DP) and Similarity-based Privacy Metrics (SBPMs) -- and argue that while DP can offer robust protections against identifiability risks, SBPMs lack adequate safeguards. Overall, our work connects regulatory notions of identifiability with model-centric privacy attacks, enabling more responsible and trustworthy regulatory assessment of synthetic data systems by researchers, practitioners, and policymakers.", "AI": {"tldr": "\u8be5\u8bba\u6587\u4ece\u6a21\u578b\u4e2d\u5fc3\u89c6\u89d2\u91cd\u65b0\u5ba1\u89c6\u5408\u6210\u6570\u636e\u7684\u533f\u540d\u6027\uff0c\u8ba4\u4e3a\u6709\u610f\u4e49\u7684\u8bc4\u4f30\u5fc5\u987b\u8003\u8651\u751f\u6210\u6a21\u578b\u7684\u80fd\u529b\u548c\u7279\u6027\uff0c\u5e76\u57fa\u4e8e\u6700\u5148\u8fdb\u7684\u9690\u79c1\u653b\u51fb\u3002\u4f5c\u8005\u8ba4\u4e3a\u5408\u6210\u6570\u636e\u6280\u672f\u672c\u8eab\u4e0d\u8db3\u4ee5\u4fdd\u8bc1\u5145\u5206\u533f\u540d\u5316\uff0c\u6bd4\u8f83\u4e86\u5dee\u5206\u9690\u79c1\u548c\u57fa\u4e8e\u76f8\u4f3c\u6027\u7684\u9690\u79c1\u5ea6\u91cf\uff0c\u6307\u51fa\u5dee\u5206\u9690\u79c1\u80fd\u63d0\u4f9b\u66f4\u5f3a\u4fdd\u62a4\u3002", "motivation": "\u5f53\u524d\u5408\u6210\u6570\u636e\u9690\u79c1\u8bc4\u4f30\u4e3b\u8981\u5173\u6ce8\u6570\u636e\u96c6\u5c42\u9762\uff0c\u800c\u73b0\u5b9e\u4e16\u754c\u4e2d\u751f\u6210\u6a21\u578b\u5f80\u5f80\u53ef\u8bbf\u95ee\u7528\u4e8e\u4ea4\u4e92\u6216\u67e5\u8be2\u3002\u73b0\u6709\u7814\u7a76\u3001\u5546\u4e1a\u90e8\u7f72\u548cGDPR\u7b49\u9690\u79c1\u6cd5\u89c4\u5bf9\u533f\u540d\u6027\u7684\u8bc4\u4f30\u672a\u80fd\u5145\u5206\u8003\u8651\u6a21\u578b\u4e2d\u5fc3\u89c6\u89d2\uff0c\u5bfc\u81f4\u9690\u79c1\u98ce\u9669\u8bc4\u4f30\u4e0d\u5145\u5206\u3002", "method": "\u4ece\u6a21\u578b\u4e2d\u5fc3\u89c6\u89d2\u91cd\u65b0\u601d\u8003\u5408\u6210\u6570\u636e\u533f\u540d\u6027\uff0c\u5c06GDPR\u5bf9\u4e2a\u4eba\u6570\u636e\u548c\u533f\u540d\u5316\u7684\u5b9a\u4e49\u7f6e\u4e8e\u6a21\u578b\u53ef\u8bbf\u95ee\u7684\u5047\u8bbe\u4e0b\uff0c\u8bc6\u522b\u9700\u8981\u7f13\u89e3\u7684\u53ef\u8bc6\u522b\u6027\u98ce\u9669\u7c7b\u578b\uff0c\u5e76\u5c06\u5176\u6620\u5c04\u5230\u4e0d\u540c\u5a01\u80c1\u8bbe\u7f6e\u4e0b\u7684\u9690\u79c1\u653b\u51fb\u3002\u6bd4\u8f83\u5dee\u5206\u9690\u79c1\u548c\u57fa\u4e8e\u76f8\u4f3c\u6027\u7684\u9690\u79c1\u5ea6\u91cf\u4e24\u79cd\u673a\u5236\u3002", "result": "\u5408\u6210\u6570\u636e\u6280\u672f\u672c\u8eab\u4e0d\u8db3\u4ee5\u4fdd\u8bc1\u5145\u5206\u533f\u540d\u5316\u3002\u5dee\u5206\u9690\u79c1\u80fd\u9488\u5bf9\u53ef\u8bc6\u522b\u6027\u98ce\u9669\u63d0\u4f9b\u7a33\u5065\u4fdd\u62a4\uff0c\u800c\u57fa\u4e8e\u76f8\u4f3c\u6027\u7684\u9690\u79c1\u5ea6\u91cf\u7f3a\u4e4f\u8db3\u591f\u7684\u9632\u62a4\u63aa\u65bd\u3002\u5efa\u7acb\u4e86\u76d1\u7ba1\u53ef\u8bc6\u522b\u6027\u6982\u5ff5\u4e0e\u6a21\u578b\u4e2d\u5fc3\u9690\u79c1\u653b\u51fb\u4e4b\u95f4\u7684\u8054\u7cfb\u3002", "conclusion": "\u9700\u8981\u4ece\u6a21\u578b\u4e2d\u5fc3\u89c6\u89d2\u8bc4\u4f30\u5408\u6210\u6570\u636e\u7cfb\u7edf\u7684\u9690\u79c1\u6027\uff0c\u5c06\u76d1\u7ba1\u6982\u5ff5\u4e0e\u9690\u79c1\u653b\u51fb\u6280\u672f\u8054\u7cfb\u8d77\u6765\uff0c\u4e3a\u7814\u7a76\u4eba\u5458\u3001\u4ece\u4e1a\u8005\u548c\u653f\u7b56\u5236\u5b9a\u8005\u63d0\u4f9b\u66f4\u8d1f\u8d23\u4efb\u548c\u53ef\u4fe1\u8d56\u7684\u5408\u6210\u6570\u636e\u7cfb\u7edf\u76d1\u7ba1\u8bc4\u4f30\u6846\u67b6\u3002"}}
{"id": "2601.22485", "categories": ["cs.CR", "cs.AI", "cs.CL"], "pdf": "https://arxiv.org/pdf/2601.22485", "abs": "https://arxiv.org/abs/2601.22485", "authors": ["Naen Xu", "Jinghuai Zhang", "Ping He", "Chunyi Zhou", "Jun Wang", "Zhihui Fu", "Tianyu Du", "Zhaoxiang Wang", "Shouling Ji"], "title": "FraudShield: Knowledge Graph Empowered Defense for LLMs against Fraud Attacks", "comment": "WWW 2026", "summary": "Large language models (LLMs) have been widely integrated into critical automated workflows, including contract review and job application processes. However, LLMs are susceptible to manipulation by fraudulent information, which can lead to harmful outcomes. Although advanced defense methods have been developed to address this issue, they often exhibit limitations in effectiveness, interpretability, and generalizability, particularly when applied to LLM-based applications. To address these challenges, we introduce FraudShield, a novel framework designed to protect LLMs from fraudulent content by leveraging a comprehensive analysis of fraud tactics. Specifically, FraudShield constructs and refines a fraud tactic-keyword knowledge graph to capture high-confidence associations between suspicious text and fraud techniques. The structured knowledge graph augments the original input by highlighting keywords and providing supporting evidence, guiding the LLM toward more secure responses. Extensive experiments show that FraudShield consistently outperforms state-of-the-art defenses across four mainstream LLMs and five representative fraud types, while also offering interpretable clues for the model's generations.", "AI": {"tldr": "FraudShield\u662f\u4e00\u4e2a\u4fdd\u62a4LLMs\u514d\u53d7\u6b3a\u8bc8\u5185\u5bb9\u653b\u51fb\u7684\u65b0\u6846\u67b6\uff0c\u901a\u8fc7\u6784\u5efa\u6b3a\u8bc8\u6218\u672f-\u5173\u952e\u8bcd\u77e5\u8bc6\u56fe\u8c31\u6765\u589e\u5f3a\u6a21\u578b\u5b89\u5168\u6027", "motivation": "LLMs\u5df2\u5e7f\u6cdb\u5e94\u7528\u4e8e\u5173\u952e\u81ea\u52a8\u5316\u5de5\u4f5c\u6d41\u7a0b\uff08\u5982\u5408\u540c\u5ba1\u67e5\u3001\u6c42\u804c\u7533\u8bf7\uff09\uff0c\u4f46\u5bb9\u6613\u53d7\u5230\u6b3a\u8bc8\u4fe1\u606f\u7684\u64cd\u7eb5\uff0c\u5bfc\u81f4\u6709\u5bb3\u540e\u679c\u3002\u73b0\u6709\u9632\u5fa1\u65b9\u6cd5\u5728\u6709\u6548\u6027\u3001\u53ef\u89e3\u91ca\u6027\u548c\u6cdb\u5316\u6027\u65b9\u9762\u5b58\u5728\u5c40\u9650\u3002", "method": "\u6784\u5efa\u5e76\u4f18\u5316\u6b3a\u8bc8\u6218\u672f-\u5173\u952e\u8bcd\u77e5\u8bc6\u56fe\u8c31\uff0c\u6355\u6349\u53ef\u7591\u6587\u672c\u4e0e\u6b3a\u8bc8\u6280\u672f\u4e4b\u95f4\u7684\u9ad8\u7f6e\u4fe1\u5ea6\u5173\u8054\u3002\u8be5\u7ed3\u6784\u5316\u77e5\u8bc6\u56fe\u8c31\u901a\u8fc7\u7a81\u51fa\u5173\u952e\u8bcd\u548c\u63d0\u4f9b\u652f\u6301\u8bc1\u636e\u6765\u589e\u5f3a\u539f\u59cb\u8f93\u5165\uff0c\u5f15\u5bfcLLM\u751f\u6210\u66f4\u5b89\u5168\u7684\u54cd\u5e94\u3002", "result": "\u5728\u56db\u4e2a\u4e3b\u6d41LLMs\u548c\u4e94\u79cd\u4ee3\u8868\u6027\u6b3a\u8bc8\u7c7b\u578b\u4e0a\u7684\u5e7f\u6cdb\u5b9e\u9a8c\u8868\u660e\uff0cFraudShield\u59cb\u7ec8\u4f18\u4e8e\u6700\u5148\u8fdb\u7684\u9632\u5fa1\u65b9\u6cd5\uff0c\u540c\u65f6\u4e3a\u6a21\u578b\u751f\u6210\u63d0\u4f9b\u53ef\u89e3\u91ca\u7684\u7ebf\u7d22\u3002", "conclusion": "FraudShield\u901a\u8fc7\u7ed3\u6784\u5316\u77e5\u8bc6\u56fe\u8c31\u65b9\u6cd5\u6709\u6548\u4fdd\u62a4LLMs\u514d\u53d7\u6b3a\u8bc8\u5185\u5bb9\u653b\u51fb\uff0c\u5728\u6027\u80fd\u3001\u53ef\u89e3\u91ca\u6027\u548c\u6cdb\u5316\u6027\u65b9\u9762\u4f18\u4e8e\u73b0\u6709\u65b9\u6cd5\u3002"}}
{"id": "2601.22556", "categories": ["cs.CR"], "pdf": "https://arxiv.org/pdf/2601.22556", "abs": "https://arxiv.org/abs/2601.22556", "authors": ["Weizhi Liu", "Yue Li", "Zhaoxia Yin"], "title": "VocBulwark: Towards Practical Generative Speech Watermarking via Additional-Parameter Injection", "comment": null, "summary": "Generated speech achieves human-level naturalness but escalates security risks of misuse. However, existing watermarking methods fail to reconcile fidelity with robustness, as they rely either on simple superposition in the noise space or on intrusive alterations to model weights. To bridge this gap, we propose VocBulwark, an additional-parameter injection framework that freezes generative model parameters to preserve perceptual quality. Specifically, we design a Temporal Adapter to deeply entangle watermarks with acoustic attributes, synergizing with a Coarse-to-Fine Gated Extractor to resist advanced attacks. Furthermore, we develop an Accuracy-Guided Optimization Curriculum that dynamically orchestrates gradient flow to resolve the optimization conflict between fidelity and robustness. Comprehensive experiments demonstrate that VocBulwark achieves high-capacity and high-fidelity watermarking, offering robust defense against complex practical scenarios, with resilience to Codec regenerations and variable-length manipulations.", "AI": {"tldr": "VocBulwark\u662f\u4e00\u79cd\u8bed\u97f3\u6c34\u5370\u6846\u67b6\uff0c\u901a\u8fc7\u51bb\u7ed3\u751f\u6210\u6a21\u578b\u53c2\u6570\u4fdd\u6301\u97f3\u8d28\uff0c\u4f7f\u7528\u65f6\u95f4\u9002\u914d\u5668\u5c06\u6c34\u5370\u4e0e\u58f0\u5b66\u5c5e\u6027\u6df1\u5ea6\u7ea0\u7f20\uff0c\u7ed3\u5408\u7c97\u5230\u7ec6\u95e8\u63a7\u63d0\u53d6\u5668\u62b5\u6297\u653b\u51fb\uff0c\u5b9e\u73b0\u9ad8\u5bb9\u91cf\u3001\u9ad8\u4fdd\u771f\u7684\u9c81\u68d2\u6c34\u5370\u3002", "motivation": "\u751f\u6210\u8bed\u97f3\u5df2\u8fbe\u5230\u4eba\u7c7b\u81ea\u7136\u6c34\u5e73\uff0c\u4f46\u589e\u52a0\u4e86\u6ee5\u7528\u98ce\u9669\u3002\u73b0\u6709\u6c34\u5370\u65b9\u6cd5\u65e0\u6cd5\u5e73\u8861\u4fdd\u771f\u5ea6\u4e0e\u9c81\u68d2\u6027\uff0c\u8981\u4e48\u5728\u566a\u58f0\u7a7a\u95f4\u7b80\u5355\u53e0\u52a0\uff0c\u8981\u4e48\u9700\u8981\u4fb5\u5165\u5f0f\u4fee\u6539\u6a21\u578b\u6743\u91cd\u3002", "method": "\u63d0\u51faVocBulwark\u6846\u67b6\uff1a1)\u51bb\u7ed3\u751f\u6210\u6a21\u578b\u53c2\u6570\u4fdd\u6301\u611f\u77e5\u8d28\u91cf\uff1b2)\u8bbe\u8ba1\u65f6\u95f4\u9002\u914d\u5668\u6df1\u5ea6\u7ea0\u7f20\u6c34\u5370\u4e0e\u58f0\u5b66\u5c5e\u6027\uff1b3)\u7ed3\u5408\u7c97\u5230\u7ec6\u95e8\u63a7\u63d0\u53d6\u5668\u62b5\u6297\u9ad8\u7ea7\u653b\u51fb\uff1b4)\u5f00\u53d1\u7cbe\u5ea6\u5f15\u5bfc\u4f18\u5316\u8bfe\u7a0b\u52a8\u6001\u534f\u8c03\u68af\u5ea6\u6d41\uff0c\u89e3\u51b3\u4fdd\u771f\u5ea6\u4e0e\u9c81\u68d2\u6027\u7684\u4f18\u5316\u51b2\u7a81\u3002", "result": "\u7efc\u5408\u5b9e\u9a8c\u8868\u660e\uff0cVocBulwark\u5b9e\u73b0\u9ad8\u5bb9\u91cf\u3001\u9ad8\u4fdd\u771f\u7684\u6c34\u5370\uff0c\u80fd\u6709\u6548\u9632\u5fa1\u590d\u6742\u5b9e\u9645\u573a\u666f\u7684\u653b\u51fb\uff0c\u5bf9\u7f16\u89e3\u7801\u5668\u518d\u751f\u548c\u53d8\u957f\u64cd\u4f5c\u5177\u6709\u9c81\u68d2\u6027\u3002", "conclusion": "VocBulwark\u6210\u529f\u89e3\u51b3\u4e86\u8bed\u97f3\u6c34\u5370\u4e2d\u4fdd\u771f\u5ea6\u4e0e\u9c81\u68d2\u6027\u7684\u5e73\u8861\u95ee\u9898\uff0c\u4e3a\u751f\u6210\u8bed\u97f3\u7684\u5b89\u5168\u5e94\u7528\u63d0\u4f9b\u4e86\u6709\u6548\u4fdd\u62a4\u65b9\u6848\u3002"}}
{"id": "2601.22569", "categories": ["cs.CR", "cs.AI"], "pdf": "https://arxiv.org/pdf/2601.22569", "abs": "https://arxiv.org/abs/2601.22569", "authors": ["Tanusree Debi", "Wentian Zhu"], "title": "Whispers of Wealth: Red-Teaming Google's Agent Payments Protocol via Prompt Injection", "comment": null, "summary": "Large language model (LLM) based agents are increasingly used to automate financial transactions, yet their reliance on contextual reasoning exposes payment systems to prompt-driven manipulation. The Agent Payments Protocol (AP2) aims to secure agent-led purchases through cryptographically verifiable mandates, but its practical robustness remains underexplored. In this work, we perform an AI red-teaming evaluation of AP2 and identify vulnerabilities arising from indirect and direct prompt injection. We introduce two attack techniques, the Branded Whisper Attack and the Vault Whisper Attack which manipulate product ranking and extract sensitive user data. Using a functional AP2 based shopping agent built with Gemini-2.5-Flash and the Google ADK framework, we experimentally validate that simple adversarial prompts can reliably subvert agent behavior. Our findings reveal critical weaknesses in current agentic payment architectures and highlight the need for stronger isolation and defensive safeguards in LLM-mediated financial systems.", "AI": {"tldr": "\u5bf9AP2\u652f\u4ed8\u534f\u8bae\u8fdb\u884cAI\u7ea2\u961f\u8bc4\u4f30\uff0c\u53d1\u73b0\u5176\u5b58\u5728\u95f4\u63a5\u548c\u76f4\u63a5\u63d0\u793a\u6ce8\u5165\u6f0f\u6d1e\uff0c\u63d0\u51fa\u4e24\u79cd\u653b\u51fb\u6280\u672f\uff0c\u5b9e\u9a8c\u9a8c\u8bc1\u7b80\u5355\u5bf9\u6297\u63d0\u793a\u53ef\u6210\u529f\u64cd\u7eb5\u8d2d\u7269\u4ee3\u7406\u884c\u4e3a", "motivation": "LLM\u4ee3\u7406\u5728\u91d1\u878d\u4ea4\u6613\u4e2d\u5e94\u7528\u65e5\u76ca\u5e7f\u6cdb\uff0c\u4f46\u5176\u4f9d\u8d56\u4e0a\u4e0b\u6587\u63a8\u7406\u7684\u7279\u6027\u4f7f\u652f\u4ed8\u7cfb\u7edf\u9762\u4e34\u63d0\u793a\u9a71\u52a8\u7684\u64cd\u7eb5\u98ce\u9669\u3002AP2\u534f\u8bae\u65e8\u5728\u901a\u8fc7\u52a0\u5bc6\u53ef\u9a8c\u8bc1\u6388\u6743\u4fdd\u62a4\u4ee3\u7406\u4e3b\u5bfc\u7684\u8d2d\u4e70\uff0c\u4f46\u5176\u5b9e\u9645\u9c81\u68d2\u6027\u5c1a\u672a\u5145\u5206\u63a2\u7d22", "method": "\u5bf9AP2\u8fdb\u884cAI\u7ea2\u961f\u8bc4\u4f30\uff0c\u8bc6\u522b\u95f4\u63a5\u548c\u76f4\u63a5\u63d0\u793a\u6ce8\u5165\u6f0f\u6d1e\uff0c\u63d0\u51fa\u54c1\u724c\u8033\u8bed\u653b\u51fb\u548c\u4fdd\u9669\u5e93\u8033\u8bed\u653b\u51fb\u4e24\u79cd\u6280\u672f\uff0c\u4f7f\u7528\u57fa\u4e8eGemini-2.5-Flash\u548cGoogle ADK\u6846\u67b6\u6784\u5efa\u7684AP2\u8d2d\u7269\u4ee3\u7406\u8fdb\u884c\u5b9e\u9a8c\u9a8c\u8bc1", "result": "\u5b9e\u9a8c\u9a8c\u8bc1\u7b80\u5355\u5bf9\u6297\u63d0\u793a\u53ef\u4ee5\u53ef\u9760\u5730\u98a0\u8986\u4ee3\u7406\u884c\u4e3a\uff0c\u653b\u51fb\u80fd\u591f\u64cd\u7eb5\u4ea7\u54c1\u6392\u540d\u548c\u63d0\u53d6\u654f\u611f\u7528\u6237\u6570\u636e\uff0c\u63ed\u793a\u4e86\u5f53\u524d\u4ee3\u7406\u652f\u4ed8\u67b6\u6784\u7684\u5173\u952e\u5f31\u70b9", "conclusion": "\u5f53\u524d\u57fa\u4e8eLLM\u7684\u91d1\u878d\u7cfb\u7edf\u5b58\u5728\u4e25\u91cd\u5b89\u5168\u6f0f\u6d1e\uff0c\u9700\u8981\u66f4\u5f3a\u7684\u9694\u79bb\u548c\u9632\u5fa1\u4fdd\u62a4\u63aa\u65bd\u6765\u786e\u4fdd\u4ee3\u7406\u652f\u4ed8\u67b6\u6784\u7684\u5b89\u5168\u6027"}}
{"id": "2601.22655", "categories": ["cs.CR", "cs.SE"], "pdf": "https://arxiv.org/pdf/2601.22655", "abs": "https://arxiv.org/abs/2601.22655", "authors": ["Feiyang Huang", "Yuqiang Sun", "Fan Zhang", "Ziqi Yang", "Han Liu", "Yang Liu"], "title": "The Semantic Trap: Do Fine-tuned LLMs Learn Vulnerability Root Cause or Just Functional Pattern?", "comment": "21 pages", "summary": "LLMs demonstrate promising performance in software vulnerability detection after fine-tuning. However, it remains unclear whether these gains reflect a genuine understanding of vulnerability root causes or merely an exploitation of functional patterns. In this paper, we identify a critical failure mode termed the \"semantic trap,\" where fine-tuned LLMs achieve high detection scores by associating certain functional domains with vulnerability likelihood rather than reasoning about the underlying security semantics.To systematically evaluate this phenomenon, we propose TrapEval, a comprehensive evaluation framework designed to disentangle vulnerability root cause from functional pattern. TrapEval introduces two complementary datasets derived from real-world open-source projects: V2N, which pairs vulnerable code with unrelated benign code, and V2P, which pairs vulnerable code with its corresponding patched version, forcing models to distinguish near-identical code that differs only in subtle security-critical logic. Using TrapEval, we fine-tune five representative state-of-the-art LLMs across three model families and evaluate them under cross-dataset testing, semantic-preserving perturbations, and varying degrees of semantic gap measured by CodeBLEU.Our empirical results reveal that, despite improvements in metrics, fine-tuned LLMs consistently struggle to distinguish vulnerable code from its patched counterpart, exhibit severe robustness degradation under minor semantic-preserving transformations, and rely heavily on functional-context shortcuts when the semantic gap is small. These findings provide strong evidence that current fine-tuning practices often fail to impart true vulnerability reasoning. Our findings serve as a wake-up call: high benchmark scores on traditional datasets may be illusory, masking the model's inability to understand the true causal logic of vulnerabilities.", "AI": {"tldr": "\u7814\u7a76\u53d1\u73b0\u5fae\u8c03\u540e\u7684LLMs\u5728\u6f0f\u6d1e\u68c0\u6d4b\u4e2d\u4e3b\u8981\u4f9d\u8d56\u529f\u80fd\u6a21\u5f0f\u800c\u975e\u5b89\u5168\u8bed\u4e49\u7406\u89e3\uff0c\u5b58\u5728\"\u8bed\u4e49\u9677\u9631\"\u73b0\u8c61\uff0c\u5bfc\u81f4\u9ad8\u57fa\u51c6\u5206\u6570\u5177\u6709\u8bef\u5bfc\u6027\u3002", "motivation": "\u5c3d\u7ba1\u5fae\u8c03\u540e\u7684LLMs\u5728\u8f6f\u4ef6\u6f0f\u6d1e\u68c0\u6d4b\u4e2d\u8868\u73b0\u51fa\u8272\uff0c\u4f46\u5c1a\u4e0d\u6e05\u695a\u8fd9\u79cd\u6539\u8fdb\u662f\u6e90\u4e8e\u5bf9\u6f0f\u6d1e\u6839\u672c\u539f\u56e0\u7684\u771f\u6b63\u7406\u89e3\uff0c\u8fd8\u662f\u4ec5\u4ec5\u5229\u7528\u4e86\u529f\u80fd\u6a21\u5f0f\u3002\u9700\u8981\u7cfb\u7edf\u8bc4\u4f30LLMs\u662f\u5426\u771f\u6b63\u7406\u89e3\u5b89\u5168\u8bed\u4e49\u3002", "method": "\u63d0\u51faTrapEval\u8bc4\u4f30\u6846\u67b6\uff0c\u5305\u542b\u4e24\u4e2a\u4e92\u8865\u6570\u636e\u96c6\uff1aV2N\uff08\u6f0f\u6d1e\u4ee3\u7801\u4e0e\u65e0\u5173\u826f\u6027\u4ee3\u7801\u914d\u5bf9\uff09\u548cV2P\uff08\u6f0f\u6d1e\u4ee3\u7801\u4e0e\u5176\u4fee\u8865\u7248\u672c\u914d\u5bf9\uff09\u3002\u4f7f\u7528\u4e94\u4e2a\u4ee3\u8868\u6027LLMs\u8fdb\u884c\u5fae\u8c03\uff0c\u5e76\u901a\u8fc7\u8de8\u6570\u636e\u96c6\u6d4b\u8bd5\u3001\u8bed\u4e49\u4fdd\u7559\u6270\u52a8\u548cCodeBLEU\u5ea6\u91cf\u7684\u8bed\u4e49\u5dee\u8ddd\u8fdb\u884c\u8bc4\u4f30\u3002", "result": "\u5fae\u8c03\u540e\u7684LLMs\u96be\u4ee5\u533a\u5206\u6f0f\u6d1e\u4ee3\u7801\u4e0e\u5176\u4fee\u8865\u7248\u672c\uff0c\u5728\u5fae\u5c0f\u8bed\u4e49\u4fdd\u7559\u53d8\u6362\u4e0b\u9c81\u68d2\u6027\u4e25\u91cd\u4e0b\u964d\uff0c\u5f53\u8bed\u4e49\u5dee\u8ddd\u8f83\u5c0f\u65f6\u4e25\u91cd\u4f9d\u8d56\u529f\u80fd\u4e0a\u4e0b\u6587\u6377\u5f84\u3002\u4f20\u7edf\u6570\u636e\u96c6\u7684\u9ad8\u57fa\u51c6\u5206\u6570\u5177\u6709\u8bef\u5bfc\u6027\u3002", "conclusion": "\u5f53\u524d\u5fae\u8c03\u5b9e\u8df5\u672a\u80fd\u4f20\u6388\u771f\u6b63\u7684\u6f0f\u6d1e\u63a8\u7406\u80fd\u529b\uff0cLLMs\u4e3b\u8981\u4f9d\u8d56\u529f\u80fd\u6a21\u5f0f\u800c\u975e\u5b89\u5168\u8bed\u4e49\u7406\u89e3\u3002\u9ad8\u57fa\u51c6\u5206\u6570\u63a9\u76d6\u4e86\u6a21\u578b\u65e0\u6cd5\u7406\u89e3\u6f0f\u6d1e\u771f\u6b63\u56e0\u679c\u903b\u8f91\u7684\u95ee\u9898\uff0c\u9700\u8981\u66f4\u4e25\u683c\u7684\u8bc4\u4f30\u65b9\u6cd5\u3002"}}
{"id": "2601.22706", "categories": ["cs.CR", "cs.SE"], "pdf": "https://arxiv.org/pdf/2601.22706", "abs": "https://arxiv.org/abs/2601.22706", "authors": ["Yanlin Wang", "Ziyao Zhang", "Chong Wang", "Xinyi Xu", "Mingwei Liu", "Yong Wang", "Jiachi Chen", "Zibin Zheng"], "title": "RealSec-bench: A Benchmark for Evaluating Secure Code Generation in Real-World Repositories", "comment": "9 pages, 6 figures", "summary": "Large Language Models (LLMs) have demonstrated remarkable capabilities in code generation, but their proficiency in producing secure code remains a critical, under-explored area. Existing benchmarks often fall short by relying on synthetic vulnerabilities or evaluating functional correctness in isolation, failing to capture the complex interplay between functionality and security found in real-world software. To address this gap, we introduce RealSec-bench, a new benchmark for secure code generation meticulously constructed from real-world, high-risk Java repositories. Our methodology employs a multi-stage pipeline that combines systematic SAST scanning with CodeQL, LLM-based false positive elimination, and rigorous human expert validation. The resulting benchmark contains 105 instances grounded in real-word repository contexts, spanning 19 Common Weakness Enumeration (CWE) types and exhibiting a wide diversity of data flow complexities, including vulnerabilities with up to 34-hop inter-procedural dependencies. Using RealSec-bench, we conduct an extensive empirical study on 5 popular LLMs. We introduce a novel composite metric, SecurePass@K, to assess both functional correctness and security simultaneously. We find that while Retrieval-Augmented Generation (RAG) techniques can improve functional correctness, they provide negligible benefits to security. Furthermore, explicitly prompting models with general security guidelines often leads to compilation failures, harming functional correctness without reliably preventing vulnerabilities. Our work highlights the gap between functional and secure code generation in current LLMs.", "AI": {"tldr": "RealSec-bench\u662f\u4e00\u4e2a\u57fa\u4e8e\u771f\u5b9eJava\u4ed3\u5e93\u6784\u5efa\u7684\u4ee3\u7801\u5b89\u5168\u751f\u6210\u57fa\u51c6\u6d4b\u8bd5\uff0c\u5305\u542b105\u4e2a\u5b9e\u4f8b\uff0c\u8986\u76d619\u79cdCWE\u7c7b\u578b\u3002\u7814\u7a76\u53d1\u73b0\u5f53\u524dLLM\u5728\u529f\u80fd\u6b63\u786e\u6027\u548c\u5b89\u5168\u6027\u4e4b\u95f4\u5b58\u5728\u663e\u8457\u5dee\u8ddd\uff0cRAG\u6280\u672f\u5bf9\u5b89\u5168\u6027\u63d0\u5347\u6709\u9650\uff0c\u5b89\u5168\u63d0\u793a\u53cd\u800c\u53ef\u80fd\u5bfc\u81f4\u7f16\u8bd1\u5931\u8d25\u3002", "motivation": "\u73b0\u6709\u57fa\u51c6\u6d4b\u8bd5\u5927\u591a\u4f9d\u8d56\u5408\u6210\u6f0f\u6d1e\u6216\u5b64\u7acb\u8bc4\u4f30\u529f\u80fd\u6b63\u786e\u6027\uff0c\u65e0\u6cd5\u6355\u6349\u771f\u5b9e\u8f6f\u4ef6\u4e2d\u529f\u80fd\u4e0e\u5b89\u5168\u7684\u590d\u6742\u4ea4\u4e92\u3002\u9700\u8981\u6784\u5efa\u57fa\u4e8e\u771f\u5b9e\u4e16\u754c\u4ee3\u7801\u7684\u57fa\u51c6\u6d4b\u8bd5\u6765\u8bc4\u4f30LLM\u751f\u6210\u5b89\u5168\u4ee3\u7801\u7684\u80fd\u529b\u3002", "method": "\u91c7\u7528\u591a\u9636\u6bb5\u6d41\u6c34\u7ebf\u6784\u5efaRealSec-bench\uff1a1) \u4f7f\u7528CodeQL\u8fdb\u884c\u7cfb\u7edfSAST\u626b\u63cf\uff1b2) LLM\u8f85\u52a9\u6d88\u9664\u8bef\u62a5\uff1b3) \u4eba\u7c7b\u4e13\u5bb6\u4e25\u683c\u9a8c\u8bc1\u3002\u57fa\u51c6\u5305\u542b105\u4e2a\u771f\u5b9eJava\u4ed3\u5e93\u5b9e\u4f8b\uff0c\u6db5\u76d619\u79cdCWE\u7c7b\u578b\uff0c\u6570\u636e\u6d41\u590d\u6742\u5ea6\u6700\u9ad8\u8fbe34\u8df3\u8fc7\u7a0b\u95f4\u4f9d\u8d56\u3002", "result": "\u5bf95\u4e2a\u6d41\u884cLLM\u7684\u5b9e\u8bc1\u7814\u7a76\u53d1\u73b0\uff1a1) RAG\u6280\u672f\u80fd\u63d0\u5347\u529f\u80fd\u6b63\u786e\u6027\u4f46\u5bf9\u5b89\u5168\u6027\u6539\u5584\u6709\u9650\uff1b2) \u663e\u5f0f\u5b89\u5168\u63d0\u793a\u5e38\u5bfc\u81f4\u7f16\u8bd1\u5931\u8d25\uff0c\u635f\u5bb3\u529f\u80fd\u6b63\u786e\u6027\u4e14\u4e0d\u80fd\u53ef\u9760\u9632\u6b62\u6f0f\u6d1e\uff1b3) \u63d0\u51faSecurePass@K\u590d\u5408\u6307\u6807\u540c\u65f6\u8bc4\u4f30\u529f\u80fd\u6b63\u786e\u6027\u548c\u5b89\u5168\u6027\u3002", "conclusion": "\u5f53\u524dLLM\u5728\u529f\u80fd\u6b63\u786e\u6027\u548c\u5b89\u5168\u4ee3\u7801\u751f\u6210\u4e4b\u95f4\u5b58\u5728\u663e\u8457\u5dee\u8ddd\uff0c\u73b0\u6709\u6280\u672f\uff08\u5982RAG\u548c\u5b89\u5168\u63d0\u793a\uff09\u65e0\u6cd5\u6709\u6548\u89e3\u51b3\u6b64\u95ee\u9898\u3002\u9700\u8981\u5f00\u53d1\u65b0\u65b9\u6cd5\u6765\u63d0\u5347LLM\u751f\u6210\u5b89\u5168\u4ee3\u7801\u7684\u80fd\u529b\u3002"}}
{"id": "2601.22710", "categories": ["cs.CR", "cs.CL"], "pdf": "https://arxiv.org/pdf/2601.22710", "abs": "https://arxiv.org/abs/2601.22710", "authors": ["Jaehee Kim", "Pilsung Kang"], "title": "AlienLM: Alienization of Language for API-Boundary Privacy in Black-Box LLMs", "comment": null, "summary": "Modern LLMs are increasingly accessed via black-box APIs, requiring users to transmit sensitive prompts, outputs, and fine-tuning data to external providers, creating a critical privacy risk at the API boundary. We introduce AlienLM, a deployable API-only privacy layer that protects text by translating it into an Alien Language via a vocabulary-scale bijection, enabling lossless recovery on the client side. Using only standard fine-tuning APIs, Alien Adaptation Training (AAT) adapts target models to operate directly on alienized inputs. Across four LLM backbones and seven benchmarks, AlienLM retains over 81\\% of plaintext-oracle performance on average, substantially outperforming random-bijection and character-level baselines. Under adversaries with access to model weights, corpus statistics, and learning-based inverse translation, recovery attacks reconstruct fewer than 0.22\\% of alienized tokens. Our results demonstrate a practical pathway for privacy-preserving LLM deployment under API-only access, substantially reducing plaintext exposure while maintaining task performance.", "AI": {"tldr": "AlienLM\u662f\u4e00\u4e2aAPI\u9690\u79c1\u4fdd\u62a4\u5c42\uff0c\u901a\u8fc7\u8bcd\u6c47\u7ea7\u53cc\u5c04\u5c06\u6587\u672c\u8f6c\u6362\u4e3a\"\u5916\u661f\u8bed\u8a00\"\uff0c\u5728\u5ba2\u6237\u7aef\u65e0\u635f\u6062\u590d\uff0c\u4ec5\u4f7f\u7528\u6807\u51c6\u5fae\u8c03API\u8ba9\u76ee\u6807\u6a21\u578b\u76f4\u63a5\u5728\u8f6c\u6362\u540e\u7684\u8f93\u5165\u4e0a\u5de5\u4f5c\uff0c\u5728\u4fdd\u62a4\u9690\u79c1\u7684\u540c\u65f6\u4fdd\u630181%\u4ee5\u4e0a\u7684\u539f\u59cb\u6027\u80fd\u3002", "motivation": "\u73b0\u4ee3LLM\u8d8a\u6765\u8d8a\u591a\u5730\u901a\u8fc7\u9ed1\u76d2API\u8bbf\u95ee\uff0c\u7528\u6237\u9700\u8981\u5c06\u654f\u611f\u7684\u63d0\u793a\u3001\u8f93\u51fa\u548c\u5fae\u8c03\u6570\u636e\u4f20\u8f93\u5230\u5916\u90e8\u63d0\u4f9b\u5546\uff0c\u8fd9\u5728API\u8fb9\u754c\u9020\u6210\u4e86\u4e25\u91cd\u7684\u9690\u79c1\u98ce\u9669\u3002\u9700\u8981\u4e00\u79cd\u53ef\u90e8\u7f72\u7684\u9690\u79c1\u4fdd\u62a4\u5c42\u6765\u51cf\u5c11\u660e\u6587\u66b4\u9732\u3002", "method": "AlienLM\u901a\u8fc7\u8bcd\u6c47\u7ea7\u53cc\u5c04\u5c06\u6587\u672c\u8f6c\u6362\u4e3a\"\u5916\u661f\u8bed\u8a00\"\uff0c\u5ba2\u6237\u7aef\u53ef\u4ee5\u65e0\u635f\u6062\u590d\u3002\u4f7f\u7528Alien Adaptation Training (AAT)\u4ec5\u901a\u8fc7\u6807\u51c6\u5fae\u8c03API\uff0c\u8ba9\u76ee\u6807\u6a21\u578b\u76f4\u63a5\u5728\u8f6c\u6362\u540e\u7684\u8f93\u5165\u4e0a\u5de5\u4f5c\u3002\u8bc4\u4f30\u4e86\u56db\u79cdLLM\u4e3b\u5e72\u548c\u4e03\u4e2a\u57fa\u51c6\u6d4b\u8bd5\u3002", "result": "AlienLM\u5e73\u5747\u4fdd\u6301\u8d85\u8fc781%\u7684\u660e\u6587\u6027\u80fd\uff0c\u663e\u8457\u4f18\u4e8e\u968f\u673a\u53cc\u5c04\u548c\u5b57\u7b26\u7ea7\u57fa\u7ebf\u3002\u5728\u5bf9\u624b\u62e5\u6709\u6a21\u578b\u6743\u91cd\u3001\u8bed\u6599\u7edf\u8ba1\u548c\u57fa\u4e8e\u5b66\u4e60\u7684\u9006\u7ffb\u8bd1\u7684\u60c5\u51b5\u4e0b\uff0c\u6062\u590d\u653b\u51fb\u53ea\u80fd\u91cd\u5efa\u5c11\u4e8e0.22%\u7684\u8f6c\u6362\u540e\u6807\u8bb0\u3002", "conclusion": "AlienLM\u4e3aAPI-only\u8bbf\u95ee\u4e0b\u7684\u9690\u79c1\u4fdd\u62a4LLM\u90e8\u7f72\u63d0\u4f9b\u4e86\u5b9e\u7528\u9014\u5f84\uff0c\u5728\u4fdd\u6301\u4efb\u52a1\u6027\u80fd\u7684\u540c\u65f6\u663e\u8457\u51cf\u5c11\u660e\u6587\u66b4\u9732\uff0c\u4e3a\u9690\u79c1\u4fdd\u62a4LLM\u90e8\u7f72\u5f00\u8f9f\u4e86\u53ef\u884c\u8def\u5f84\u3002"}}
{"id": "2601.22720", "categories": ["cs.CR", "cs.AI"], "pdf": "https://arxiv.org/pdf/2601.22720", "abs": "https://arxiv.org/abs/2601.22720", "authors": ["Ivan K. Tung", "Yu Xiang Shi", "Alex Chien", "Wenkai Liu", "Lawrence Zheng"], "title": "AEGIS: White-Box Attack Path Generation using LLMs and Training Effectiveness Evaluation for Large-Scale Cyber Defence Exercises", "comment": null, "summary": "Creating attack paths for cyber defence exercises requires substantial expert effort. Existing automation requires vulnerability graphs or exploit sets curated in advance, limiting where it can be applied. We present AEGIS, a system that generates attack paths using LLMs, white-box access, and Monte Carlo Tree Search over real exploit execution. LLM-based search discovers exploits dynamically without pre-existing vulnerability graphs, while white-box access enables validating exploits in isolation before committing to attack paths. Evaluation at CIDeX 2025, a large-scale exercise spanning 46 IT hosts, showed that AEGIS-generated paths are comparable to human-authored scenarios across four dimensions of training experience (perceived learning, engagement, believability, challenge). Results were measured with a validated questionnaire extensible to general simulation-based training. By automating exploit chain discovery and validation, AEGIS reduces scenario development from months to days, shifting expert effort from technical validation to scenario design.", "AI": {"tldr": "AEGIS\u7cfb\u7edf\u4f7f\u7528LLM\u3001\u767d\u76d2\u8bbf\u95ee\u548c\u8499\u7279\u5361\u6d1b\u6811\u641c\u7d22\u81ea\u52a8\u751f\u6210\u7f51\u7edc\u9632\u5fa1\u6f14\u7ec3\u7684\u653b\u51fb\u8def\u5f84\uff0c\u65e0\u9700\u9884\u5148\u6784\u5efa\u6f0f\u6d1e\u56fe\uff0c\u5c06\u573a\u666f\u5f00\u53d1\u65f6\u95f4\u4ece\u6570\u6708\u7f29\u77ed\u5230\u6570\u5929\u3002", "motivation": "\u5f53\u524d\u7f51\u7edc\u9632\u5fa1\u6f14\u7ec3\u7684\u653b\u51fb\u8def\u5f84\u521b\u5efa\u9700\u8981\u5927\u91cf\u4e13\u5bb6\u5de5\u4f5c\uff0c\u73b0\u6709\u81ea\u52a8\u5316\u65b9\u6cd5\u9700\u8981\u9884\u5148\u6784\u5efa\u6f0f\u6d1e\u56fe\u6216\u5229\u7528\u96c6\uff0c\u9650\u5236\u4e86\u5e94\u7528\u8303\u56f4\u3002\u9700\u8981\u4e00\u79cd\u80fd\u591f\u52a8\u6001\u53d1\u73b0\u5229\u7528\u94fe\u800c\u4e0d\u4f9d\u8d56\u9884\u5b9a\u4e49\u6f0f\u6d1e\u56fe\u7684\u81ea\u52a8\u5316\u7cfb\u7edf\u3002", "method": "AEGIS\u7cfb\u7edf\u7ed3\u5408LLM\u8fdb\u884c\u52a8\u6001\u6f0f\u6d1e\u53d1\u73b0\u3001\u767d\u76d2\u8bbf\u95ee\u9a8c\u8bc1\u5355\u4e2a\u5229\u7528\u7684\u6709\u6548\u6027\uff0c\u4ee5\u53ca\u8499\u7279\u5361\u6d1b\u6811\u641c\u7d22\u5728\u771f\u5b9e\u5229\u7528\u6267\u884c\u4e0a\u8fdb\u884c\u8def\u5f84\u89c4\u5212\u3002LLM\u65e0\u9700\u9884\u5b9a\u4e49\u6f0f\u6d1e\u56fe\u5373\u53ef\u53d1\u73b0\u5229\u7528\uff0c\u767d\u76d2\u8bbf\u95ee\u786e\u4fdd\u5728\u63d0\u4ea4\u653b\u51fb\u8def\u5f84\u524d\u9a8c\u8bc1\u5229\u7528\u7684\u6709\u6548\u6027\u3002", "result": "\u5728CIDeX 2025\u5927\u89c4\u6a21\u6f14\u7ec3\uff08\u6db5\u76d646\u4e2aIT\u4e3b\u673a\uff09\u4e2d\u8bc4\u4f30\u663e\u793a\uff0cAEGIS\u751f\u6210\u7684\u653b\u51fb\u8def\u5f84\u5728\u56db\u4e2a\u8bad\u7ec3\u4f53\u9a8c\u7ef4\u5ea6\uff08\u611f\u77e5\u5b66\u4e60\u3001\u53c2\u4e0e\u5ea6\u3001\u53ef\u4fe1\u5ea6\u3001\u6311\u6218\u6027\uff09\u4e0a\u4e0e\u4eba\u5de5\u7f16\u5199\u7684\u573a\u666f\u76f8\u5f53\u3002\u4f7f\u7528\u53ef\u6269\u5c55\u5230\u4e00\u822c\u6a21\u62df\u8bad\u7ec3\u7684\u9a8c\u8bc1\u95ee\u5377\u8fdb\u884c\u6d4b\u91cf\u3002", "conclusion": "AEGIS\u901a\u8fc7\u81ea\u52a8\u5316\u5229\u7528\u94fe\u53d1\u73b0\u548c\u9a8c\u8bc1\uff0c\u5c06\u573a\u666f\u5f00\u53d1\u65f6\u95f4\u4ece\u6570\u6708\u7f29\u77ed\u5230\u6570\u5929\uff0c\u5c06\u4e13\u5bb6\u5de5\u4f5c\u4ece\u6280\u672f\u9a8c\u8bc1\u8f6c\u5411\u573a\u666f\u8bbe\u8ba1\uff0c\u4e3a\u7f51\u7edc\u9632\u5fa1\u6f14\u7ec3\u63d0\u4f9b\u4e86\u9ad8\u6548\u4e14\u8d28\u91cf\u76f8\u5f53\u7684\u81ea\u52a8\u5316\u89e3\u51b3\u65b9\u6848\u3002"}}
{"id": "2601.22770", "categories": ["cs.CR"], "pdf": "https://arxiv.org/pdf/2601.22770", "abs": "https://arxiv.org/abs/2601.22770", "authors": ["Haoyun Yang", "Ronghong Huang", "Yong Fang", "Beizeng Zhang", "Junpu Guo", "Zhanyu Wu", "Xianghang Mi"], "title": "Okara: Detection and Attribution of TLS Man-in-the-Middle Vulnerabilities in Android Apps with Foundation Models", "comment": "Accepted to ACISP 2026", "summary": "Transport Layer Security (TLS) is fundamental to secure online communication, yet vulnerabilities in certificate validation that enable Man-in-the-Middle (MitM) attacks remain a pervasive threat in Android apps. Existing detection tools are hampered by low-coverage UI interaction, costly instrumentation, and a lack of scalable root-cause analysis. We present Okara, a framework that leverages foundation models to automate the detection and deep attribution of TLS MitM Vulnerabilities (TMVs). Okara's detection component, TMV-Hunter, employs foundation model-driven GUI agents to achieve high-coverage app interaction, enabling efficient vulnerability discovery at scale. Deploying TMV-Hunter on 37,349 apps from Google Play and a third-party store revealed 8,374 (22.42%) vulnerable apps. Our measurement shows these vulnerabilities are widespread across all popularity levels, affect critical functionalities like authentication and code delivery, and are highly persistent with a median vulnerable lifespan of over 1,300 days. Okara's attribution component, TMV-ORCA, combines dynamic instrumentation with a novel LLM-based classifier to locate and categorize vulnerable code according to a comprehensive new taxonomy. This analysis attributes 41% of vulnerabilities to third-party libraries and identifies recurring insecure patterns, such as empty trust managers and flawed hostname verification. We have initiated a large-scale responsible disclosure effort and will release our tools and datasets to support further research and mitigation.", "AI": {"tldr": "Okara\u6846\u67b6\u5229\u7528\u57fa\u7840\u6a21\u578b\u81ea\u52a8\u5316\u68c0\u6d4b\u548c\u6df1\u5ea6\u5f52\u56e0TLS\u4e2d\u95f4\u4eba\u653b\u51fb\u6f0f\u6d1e\uff0c\u572837,349\u4e2aAndroid\u5e94\u7528\u4e2d\u53d1\u73b0\u4e8622.42%\u5b58\u5728\u6f0f\u6d1e\uff0c\u5e76\u5f00\u53d1\u4e86\u65b0\u7684\u5206\u7c7b\u6cd5\u548c\u5206\u6790\u5de5\u5177\u3002", "motivation": "TLS\u662f\u5b89\u5168\u5728\u7ebf\u901a\u4fe1\u7684\u57fa\u7840\uff0c\u4f46Android\u5e94\u7528\u4e2d\u8bc1\u4e66\u9a8c\u8bc1\u6f0f\u6d1e\u5bfc\u81f4\u7684\u4e2d\u95f4\u4eba\u653b\u51fb\u4ecd\u7136\u666e\u904d\u5b58\u5728\u3002\u73b0\u6709\u68c0\u6d4b\u5de5\u5177\u5b58\u5728UI\u4ea4\u4e92\u8986\u76d6\u7387\u4f4e\u3001\u63d2\u6869\u6210\u672c\u9ad8\u3001\u7f3a\u4e4f\u53ef\u6269\u5c55\u7684\u6839\u56e0\u5206\u6790\u7b49\u95ee\u9898\u3002", "method": "\u63d0\u51fa\u4e86Okara\u6846\u67b6\uff0c\u5305\u542b\u4e24\u4e2a\u7ec4\u4ef6\uff1aTMV-Hunter\u4f7f\u7528\u57fa\u7840\u6a21\u578b\u9a71\u52a8\u7684GUI\u4ee3\u7406\u5b9e\u73b0\u9ad8\u8986\u76d6\u7387\u5e94\u7528\u4ea4\u4e92\uff0c\u9ad8\u6548\u53d1\u73b0\u6f0f\u6d1e\uff1bTMV-ORCA\u7ed3\u5408\u52a8\u6001\u63d2\u6869\u548c\u57fa\u4e8eLLM\u7684\u5206\u7c7b\u5668\uff0c\u6309\u7167\u65b0\u7684\u5206\u7c7b\u6cd5\u5b9a\u4f4d\u548c\u5206\u7c7b\u6f0f\u6d1e\u4ee3\u7801\u3002", "result": "\u5728Google Play\u548c\u7b2c\u4e09\u65b9\u5546\u5e97\u768437,349\u4e2a\u5e94\u7528\u4e2d\uff0c\u53d1\u73b08,374\u4e2a\uff0822.42%\uff09\u5b58\u5728\u6f0f\u6d1e\u3002\u8fd9\u4e9b\u6f0f\u6d1e\u5728\u6240\u6709\u6d41\u884c\u5ea6\u7ea7\u522b\u90fd\u5e7f\u6cdb\u5b58\u5728\uff0c\u5f71\u54cd\u8ba4\u8bc1\u548c\u4ee3\u7801\u4ea4\u4ed8\u7b49\u5173\u952e\u529f\u80fd\uff0c\u4e2d\u4f4d\u6f0f\u6d1e\u5bff\u547d\u8d85\u8fc71,300\u5929\u300241%\u7684\u6f0f\u6d1e\u5f52\u56e0\u4e8e\u7b2c\u4e09\u65b9\u5e93\uff0c\u5e76\u8bc6\u522b\u51fa\u7a7a\u4fe1\u4efb\u7ba1\u7406\u5668\u3001\u4e3b\u673a\u540d\u9a8c\u8bc1\u7f3a\u9677\u7b49\u5e38\u89c1\u4e0d\u5b89\u5168\u6a21\u5f0f\u3002", "conclusion": "TLS\u4e2d\u95f4\u4eba\u653b\u51fb\u6f0f\u6d1e\u5728Android\u5e94\u7528\u4e2d\u666e\u904d\u4e14\u6301\u4e45\uff0cOkara\u6846\u67b6\u901a\u8fc7\u57fa\u7840\u6a21\u578b\u9a71\u52a8\u7684\u81ea\u52a8\u5316\u68c0\u6d4b\u548c\u6df1\u5ea6\u5f52\u56e0\u5206\u6790\uff0c\u6709\u6548\u8bc6\u522b\u548c\u5206\u7c7b\u8fd9\u4e9b\u6f0f\u6d1e\uff0c\u652f\u6301\u5927\u89c4\u6a21\u8d1f\u8d23\u4efb\u62ab\u9732\u548c\u8fdb\u4e00\u6b65\u7814\u7a76\u3002"}}
{"id": "2601.22772", "categories": ["cs.CR"], "pdf": "https://arxiv.org/pdf/2601.22772", "abs": "https://arxiv.org/abs/2601.22772", "authors": ["Timofey Mezhuev", "Darya Parygina", "Daniil Kuts"], "title": "Rust and Go directed fuzzing with LibAFL-DiFuzz", "comment": null, "summary": "In modern SSDLC, program analysis and automated testing are essential for minimizing vulnerabilities before software release, with fuzzing being a fast and widely used dynamic testing method. However, traditional coverage-guided fuzzing may be less effective in specific tasks like verifying static analysis reports or reproducing crashes, while directed fuzzing, focusing on targeted program locations using proximity metrics, proves to be more effective. Some of the earliest directed fuzzers are, for example, AFLGo and BEACON, which use different proximity metric approaches. Although most automated testing tools focus on C/C++ code, the growing popularity of Rust and Go causes the need for precise and efficient testing solutions for these languages. This work expands the applicability of directed fuzzing beyond traditional analysis of C/C++ software. We present a novel approach to directed greybox fuzzing tailored specifically for Rust and Go applications. We introduce advanced preprocessing techniques, rustc compiler customizations, and elaborate graph construction and instrumentation methods to enable effective targeting of specific program locations. Our implemented fuzzing tools, based on LibAFL-DiFuzz backend, demonstrate competitive advantages compared to popular existing fuzzers like afl.rs, cargo-fuzz, and go-fuzz. According to TTE (Time to Exposure) experiments, Rust-LibAFL-DiFuzz outperforms other tools by the best TTE result. Some stability issues can be explained by different mutation approaches. Go-LibAFL-DiFuzz outperforms its opponent by the best and, in the majority of cases, by average result, having two cases with orders of magnitude difference. These results prove better efficiency and accuracy of our approach.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u9488\u5bf9Rust\u548cGo\u8bed\u8a00\u7684\u5b9a\u5411\u7070\u76d2\u6a21\u7cca\u6d4b\u8bd5\u65b9\u6cd5\uff0c\u901a\u8fc7\u7f16\u8bd1\u5668\u5b9a\u5236\u548c\u9ad8\u7ea7\u9884\u5904\u7406\u6280\u672f\uff0c\u5728TTE\u6307\u6807\u4e0a\u4f18\u4e8e\u73b0\u6709\u5de5\u5177\u3002", "motivation": "\u968f\u7740Rust\u548cGo\u8bed\u8a00\u7684\u6d41\u884c\uff0c\u9700\u8981\u4e3a\u8fd9\u4e9b\u8bed\u8a00\u63d0\u4f9b\u7cbe\u786e\u9ad8\u6548\u7684\u6d4b\u8bd5\u65b9\u6848\u3002\u4f20\u7edf\u5b9a\u5411\u6a21\u7cca\u6d4b\u8bd5\u4e3b\u8981\u9488\u5bf9C/C++\uff0c\u9700\u8981\u6269\u5c55\u5230\u65b0\u5174\u8bed\u8a00\u3002", "method": "\u63d0\u51fa\u9488\u5bf9Rust\u548cGo\u7684\u5b9a\u5411\u7070\u76d2\u6a21\u7cca\u6d4b\u8bd5\u65b9\u6cd5\uff0c\u5305\u62ec\u9ad8\u7ea7\u9884\u5904\u7406\u6280\u672f\u3001rustc\u7f16\u8bd1\u5668\u5b9a\u5236\u3001\u7cbe\u7ec6\u7684\u56fe\u6784\u5efa\u548c\u63d2\u6869\u65b9\u6cd5\uff0c\u57fa\u4e8eLibAFL-DiFuzz\u540e\u7aef\u5b9e\u73b0\u3002", "result": "Rust-LibAFL-DiFuzz\u5728TTE\u5b9e\u9a8c\u4e2d\u8868\u73b0\u6700\u4f73\uff0cGo-LibAFL-DiFuzz\u5728\u591a\u6570\u60c5\u51b5\u4e0b\u4f18\u4e8e\u73b0\u6709\u5de5\u5177\uff0c\u90e8\u5206\u6848\u4f8b\u6709\u6570\u91cf\u7ea7\u5dee\u5f02\u3002", "conclusion": "\u8be5\u65b9\u6cd5\u5728Rust\u548cGo\u8bed\u8a00\u7684\u5b9a\u5411\u6a21\u7cca\u6d4b\u8bd5\u4e2d\u5c55\u73b0\u51fa\u66f4\u597d\u7684\u6548\u7387\u548c\u51c6\u786e\u6027\uff0c\u8bc1\u660e\u4e86\u5c06\u5b9a\u5411\u6a21\u7cca\u6d4b\u8bd5\u6269\u5c55\u5230\u975eC/C++\u8bed\u8a00\u7684\u53ef\u884c\u6027\u3002"}}
{"id": "2601.22800", "categories": ["cs.CR", "cs.LG"], "pdf": "https://arxiv.org/pdf/2601.22800", "abs": "https://arxiv.org/abs/2601.22800", "authors": ["Md Zahurul Haque", "Md. Hafizur Rahman", "Yeahyea Sarker"], "title": "Trackly: A Unified SaaS Platform for User Behavior Analytics and Real Time Rule Based Anomaly Detection", "comment": null, "summary": "Understanding user behavior is essential for improving digital experiences, optimizing business conversions, and mitigating threats like account takeovers, fraud, and bot attacks. Most platforms separate product analytics and security, creating fragmented visibility and delayed threat detection. Trackly, a scalable SaaS platform, unifies comprehensive user behavior analytics with real time, rule based anomaly detection. It tracks sessions, IP based geo location, device browser fingerprints, and granular events such as page views, add to cart, and checkouts. Suspicious activities logins from new devices or locations, impossible travel (Haversine formula), rapid bot like actions, VPN proxy usage, or multiple accounts per IP are flagged via configurable rules with weighted risk scoring, enabling transparent, explainable decisions. A real time dashboard provides global session maps, DAU MAU, bounce rates, and session durations. Integration is simplified with a lightweight JavaScript SDK and secure REST APIs. Implemented on a multi tenant microservices stack (ASP.NET Core, MongoDB, RabbitMQ, Next.js), Trackly achieved 98.1% accuracy, 97.7% precision, and 2.25% false positives on synthetic datasets, proving its efficiency for SMEs and ecommerce.", "AI": {"tldr": "Trackly\u662f\u4e00\u4e2a\u7edf\u4e00\u7684SaaS\u5e73\u53f0\uff0c\u5c06\u7528\u6237\u884c\u4e3a\u5206\u6790\u4e0e\u5b9e\u65f6\u5f02\u5e38\u68c0\u6d4b\u76f8\u7ed3\u5408\uff0c\u901a\u8fc7\u53ef\u914d\u7f6e\u89c4\u5219\u548c\u52a0\u6743\u98ce\u9669\u8bc4\u5206\u6765\u8bc6\u522b\u53ef\u7591\u6d3b\u52a8\uff0c\u4e3a\u4e2d\u5c0f\u4f01\u4e1a\u63d0\u4f9b\u9ad8\u6548\u7684\u5b89\u5168\u5206\u6790\u89e3\u51b3\u65b9\u6848\u3002", "motivation": "\u5927\u591a\u6570\u5e73\u53f0\u5c06\u4ea7\u54c1\u5206\u6790\u548c\u5b89\u5168\u529f\u80fd\u5206\u79bb\uff0c\u5bfc\u81f4\u788e\u7247\u5316\u7684\u53ef\u89c6\u6027\u548c\u5ef6\u8fdf\u7684\u5a01\u80c1\u68c0\u6d4b\u3002\u9700\u8981\u7edf\u4e00\u7528\u6237\u884c\u4e3a\u5206\u6790\u548c\u5b9e\u65f6\u5b89\u5168\u76d1\u63a7\uff0c\u4ee5\u6539\u5584\u6570\u5b57\u4f53\u9a8c\u3001\u4f18\u5316\u4e1a\u52a1\u8f6c\u5316\u5e76\u7f13\u89e3\u8d26\u6237\u52ab\u6301\u3001\u6b3a\u8bc8\u548c\u673a\u5668\u4eba\u653b\u51fb\u7b49\u5a01\u80c1\u3002", "method": "Trackly\u5e73\u53f0\u8ddf\u8e2a\u4f1a\u8bdd\u3001\u57fa\u4e8eIP\u7684\u5730\u7406\u4f4d\u7f6e\u3001\u8bbe\u5907\u6d4f\u89c8\u5668\u6307\u7eb9\u548c\u7ec6\u7c92\u5ea6\u4e8b\u4ef6\uff08\u5982\u9875\u9762\u6d4f\u89c8\u3001\u52a0\u5165\u8d2d\u7269\u8f66\u3001\u7ed3\u8d26\uff09\u3002\u901a\u8fc7\u53ef\u914d\u7f6e\u89c4\u5219\u548c\u52a0\u6743\u98ce\u9669\u8bc4\u5206\u7cfb\u7edf\u68c0\u6d4b\u53ef\u7591\u6d3b\u52a8\uff0c\u5305\u62ec\u65b0\u8bbe\u5907/\u4f4d\u7f6e\u767b\u5f55\u3001\u4e0d\u53ef\u80fd\u65c5\u884c\uff08\u4f7f\u7528Haversine\u516c\u5f0f\uff09\u3001\u5feb\u901f\u673a\u5668\u4eba\u5f0f\u64cd\u4f5c\u3001VPN/\u4ee3\u7406\u4f7f\u7528\u3001\u5355IP\u591a\u8d26\u6237\u7b49\u3002\u91c7\u7528\u8f7b\u91cf\u7ea7JavaScript SDK\u548c\u5b89\u5168REST API\u7b80\u5316\u96c6\u6210\uff0c\u57fa\u4e8e\u591a\u79df\u6237\u5fae\u670d\u52a1\u67b6\u6784\uff08ASP.NET Core\u3001MongoDB\u3001RabbitMQ\u3001Next.js\uff09\u5b9e\u73b0\u3002", "result": "\u5728\u5408\u6210\u6570\u636e\u96c6\u4e0a\uff0cTrackly\u5b9e\u73b0\u4e8698.1%\u7684\u51c6\u786e\u7387\u300197.7%\u7684\u7cbe\u786e\u5ea6\u548c2.25%\u7684\u8bef\u62a5\u7387\uff0c\u8bc1\u660e\u4e86\u5176\u5bf9\u4e2d\u5c0f\u4f01\u4e1a\u548c\u7535\u5b50\u5546\u52a1\u7684\u9ad8\u6548\u6027\u3002\u5b9e\u65f6\u4eea\u8868\u677f\u63d0\u4f9b\u5168\u7403\u4f1a\u8bdd\u5730\u56fe\u3001\u65e5\u6d3b/\u6708\u6d3b\u7528\u6237\u3001\u8df3\u51fa\u7387\u548c\u4f1a\u8bdd\u65f6\u957f\u7b49\u6307\u6807\u3002", "conclusion": "Trackly\u6210\u529f\u7edf\u4e00\u4e86\u7528\u6237\u884c\u4e3a\u5206\u6790\u548c\u5b9e\u65f6\u5b89\u5168\u76d1\u63a7\uff0c\u63d0\u4f9b\u900f\u660e\u3001\u53ef\u89e3\u91ca\u7684\u51b3\u7b56\u652f\u6301\uff0c\u89e3\u51b3\u4e86\u4f20\u7edf\u5e73\u53f0\u4e2d\u4ea7\u54c1\u5206\u6790\u548c\u5b89\u5168\u529f\u80fd\u5206\u79bb\u7684\u95ee\u9898\uff0c\u4e3a\u4e2d\u5c0f\u4f01\u4e1a\u63d0\u4f9b\u4e86\u9ad8\u6548\u7684\u53ef\u6269\u5c55\u89e3\u51b3\u65b9\u6848\u3002"}}
{"id": "2601.22804", "categories": ["cs.CR", "cs.AR"], "pdf": "https://arxiv.org/pdf/2601.22804", "abs": "https://arxiv.org/abs/2601.22804", "authors": ["Rourab Paul", "Krishnendu Guha", "Amlan Chakrabarti"], "title": "Trojan-Resilient NTT: Protecting Against Control Flow and Timing Faults on Reconfigurable Platforms", "comment": null, "summary": "Number Theoretic Transform (NTT) is the most essential component for polynomial multiplications used in lattice-based Post-Quantum Cryptography (PQC) algorithms such as Kyber, Dilithium, NTRU etc. However, side-channel attacks (SCA) and hardware vulnerabilities in the form of hardware Trojans may alter control signals to disrupt the circuit's control flow and introduce unconventional delays in the critical hardware of PQC. Hardware Trojans, especially on control signals, are more low cost and impactful than data signals because a single corrupted control signal can disrupt or bypass entire computation sequences, whereas data faults usually cause only localized errors. On the other hand, adversaries can perform Soft Analytical Side Channel Attacks (SASCA) on the design using the inserted hardware Trojan. In this paper, we present a secure NTT architecture capable of detecting unconventional delays, control-flow disruptions, and SASCA, while providing an adaptive fault-correction methodology for their mitigation. Extensive simulations and implementations of our Secure NTT on Artix-7 FPGA with different Kyber variants show that our fault detection and correction modules can efficiently detect and correct faults whether caused unintentionally or intentionally by hardware Trojans with a high success rate, while introducing only modest area and time overheads.", "AI": {"tldr": "\u63d0\u51fa\u4e00\u79cd\u5b89\u5168\u7684NTT\u67b6\u6784\uff0c\u80fd\u591f\u68c0\u6d4b\u975e\u5e38\u89c4\u5ef6\u8fdf\u3001\u63a7\u5236\u6d41\u4e2d\u65ad\u548cSASCA\u653b\u51fb\uff0c\u5e76\u63d0\u4f9b\u81ea\u9002\u5e94\u6545\u969c\u6821\u6b63\u65b9\u6cd5\uff0c\u5728FPGA\u5b9e\u73b0\u4e2d\u663e\u793a\u9ad8\u6548\u68c0\u6d4b\u548c\u6821\u6b63\u80fd\u529b\u3002", "motivation": "NTT\u662f\u540e\u91cf\u5b50\u5bc6\u7801\u7b97\u6cd5\u4e2d\u7684\u6838\u5fc3\u7ec4\u4ef6\uff0c\u4f46\u9762\u4e34\u4fa7\u4fe1\u9053\u653b\u51fb\u548c\u786c\u4ef6\u6728\u9a6c\u7684\u5a01\u80c1\u3002\u786c\u4ef6\u6728\u9a6c\u7279\u522b\u662f\u9488\u5bf9\u63a7\u5236\u4fe1\u53f7\u7684\u653b\u51fb\u6210\u672c\u4f4e\u3001\u5f71\u54cd\u5927\uff0c\u5355\u4e2a\u88ab\u7834\u574f\u7684\u63a7\u5236\u4fe1\u53f7\u5c31\u80fd\u4e2d\u65ad\u6574\u4e2a\u8ba1\u7b97\u5e8f\u5217\uff0c\u800c\u6570\u636e\u6545\u969c\u901a\u5e38\u53ea\u9020\u6210\u5c40\u90e8\u9519\u8bef\u3002\u6b64\u5916\uff0c\u653b\u51fb\u8005\u53ef\u4ee5\u5229\u7528\u63d2\u5165\u7684\u786c\u4ef6\u6728\u9a6c\u6267\u884c\u8f6f\u5206\u6790\u4fa7\u4fe1\u9053\u653b\u51fb\u3002", "method": "\u63d0\u51fa\u4e00\u79cd\u5b89\u5168\u7684NTT\u67b6\u6784\uff0c\u80fd\u591f\u68c0\u6d4b\u975e\u5e38\u89c4\u5ef6\u8fdf\u3001\u63a7\u5236\u6d41\u4e2d\u65ad\u548cSASCA\u653b\u51fb\uff0c\u5e76\u63d0\u4f9b\u81ea\u9002\u5e94\u6545\u969c\u6821\u6b63\u65b9\u6cd5\u3002\u5728Artix-7 FPGA\u4e0a\u5bf9\u4e0d\u540cKyber\u53d8\u4f53\u8fdb\u884c\u4e86\u5e7f\u6cdb\u7684\u4eff\u771f\u548c\u5b9e\u73b0\u3002", "result": "\u6545\u969c\u68c0\u6d4b\u548c\u6821\u6b63\u6a21\u5757\u80fd\u591f\u9ad8\u6548\u68c0\u6d4b\u548c\u6821\u6b63\u7531\u786c\u4ef6\u6728\u9a6c\u6709\u610f\u6216\u65e0\u610f\u5f15\u8d77\u7684\u6545\u969c\uff0c\u5177\u6709\u9ad8\u6210\u529f\u7387\uff0c\u540c\u65f6\u53ea\u5f15\u5165\u9002\u5ea6\u7684\u9762\u79ef\u548c\u65f6\u95f4\u5f00\u9500\u3002", "conclusion": "\u63d0\u51fa\u7684\u5b89\u5168NTT\u67b6\u6784\u80fd\u591f\u6709\u6548\u5e94\u5bf9\u786c\u4ef6\u6728\u9a6c\u548c\u4fa7\u4fe1\u9053\u653b\u51fb\u7684\u5a01\u80c1\uff0c\u4e3a\u540e\u91cf\u5b50\u5bc6\u7801\u7b97\u6cd5\u63d0\u4f9b\u53ef\u9760\u7684\u786c\u4ef6\u5b89\u5168\u4fdd\u62a4\u3002"}}
{"id": "2601.22818", "categories": ["cs.CR", "cs.AI"], "pdf": "https://arxiv.org/pdf/2601.22818", "abs": "https://arxiv.org/abs/2601.22818", "authors": ["Charles Westphal", "Keivan Navaie", "Fernando E. Rosas"], "title": "Hide and Seek in Embedding Space: Geometry-based Steganography and Detection in Large Language Models", "comment": null, "summary": "Fine-tuned LLMs can covertly encode prompt secrets into outputs via steganographic channels. Prior work demonstrated this threat but relied on trivially recoverable encodings. We formalize payload recoverability via classifier accuracy and show previous schemes achieve 100\\% recoverability. In response, we introduce low-recoverability steganography, replacing arbitrary mappings with embedding-space-derived ones. For Llama-8B (LoRA) and Ministral-8B (LoRA) trained on TrojanStego prompts, exact secret recovery rises from 17$\\rightarrow$30\\% (+78\\%) and 24$\\rightarrow$43\\% (+80\\%) respectively, while on Llama-70B (LoRA) trained on Wiki prompts, it climbs from 9$\\rightarrow$19\\% (+123\\%), all while reducing payload recoverability. We then discuss detection. We argue that detecting fine-tuning-based steganographic attacks requires approaches beyond traditional steganalysis. Standard approaches measure distributional shift, which is an expected side-effect of fine-tuning. Instead, we propose a mechanistic interpretability approach: linear probes trained on later-layer activations detect the secret with up to 33\\% higher accuracy in fine-tuned models compared to base models, even for low-recoverability schemes. This suggests that malicious fine-tuning leaves actionable internal signatures amenable to interpretability-based defenses.", "AI": {"tldr": "\u8bba\u6587\u7814\u7a76LLM\u5fae\u8c03\u4e2d\u7684\u9690\u5199\u653b\u51fb\uff0c\u63d0\u51fa\u4f4e\u53ef\u6062\u590d\u6027\u9690\u5199\u65b9\u6848\uff0c\u5e76\u63a2\u8ba8\u57fa\u4e8e\u673a\u5236\u53ef\u89e3\u91ca\u6027\u7684\u68c0\u6d4b\u65b9\u6cd5", "motivation": "\u73b0\u6709\u7814\u7a76\u8868\u660e\u5fae\u8c03\u540e\u7684LLM\u53ef\u4ee5\u901a\u8fc7\u9690\u5199\u901a\u9053\u5c06\u63d0\u793a\u79d8\u5bc6\u7f16\u7801\u5230\u8f93\u51fa\u4e2d\uff0c\u4f46\u5148\u524d\u65b9\u6cd5\u4f9d\u8d56\u6613\u4e8e\u6062\u590d\u7684\u7f16\u7801\u65b9\u5f0f\u3002\u672c\u6587\u65e8\u5728\u5f62\u5f0f\u5316\u6709\u6548\u8f7d\u8377\u53ef\u6062\u590d\u6027\uff0c\u5e76\u63d0\u51fa\u66f4\u9690\u853d\u7684\u4f4e\u53ef\u6062\u590d\u6027\u9690\u5199\u65b9\u6848\uff0c\u540c\u65f6\u63a2\u7d22\u6709\u6548\u7684\u68c0\u6d4b\u65b9\u6cd5\u3002", "method": "1. \u5f62\u5f0f\u5316\u6709\u6548\u8f7d\u8377\u53ef\u6062\u590d\u6027\uff0c\u7528\u5206\u7c7b\u5668\u51c6\u786e\u7387\u8861\u91cf\uff1b2. \u63d0\u51fa\u4f4e\u53ef\u6062\u590d\u6027\u9690\u5199\u65b9\u6848\uff0c\u7528\u5d4c\u5165\u7a7a\u95f4\u6d3e\u751f\u7684\u6620\u5c04\u66ff\u4ee3\u4efb\u610f\u6620\u5c04\uff1b3. \u63d0\u51fa\u57fa\u4e8e\u673a\u5236\u53ef\u89e3\u91ca\u6027\u7684\u68c0\u6d4b\u65b9\u6cd5\uff0c\u4f7f\u7528\u7ebf\u6027\u63a2\u9488\u5206\u6790\u6df1\u5c42\u6fc0\u6d3b\u6765\u68c0\u6d4b\u79d8\u5bc6\u3002", "result": "1. \u4f4e\u53ef\u6062\u590d\u6027\u65b9\u6848\u663e\u8457\u63d0\u5347\u79d8\u5bc6\u6062\u590d\u7387\uff1aLlama-8B\u4ece17%\u219230%(+78%)\uff0cMinistral-8B\u4ece24%\u219243%(+80%)\uff0cLlama-70B\u4ece9%\u219219%(+123%)\uff0c\u540c\u65f6\u964d\u4f4e\u6709\u6548\u8f7d\u8377\u53ef\u6062\u590d\u6027\uff1b2. \u57fa\u4e8e\u673a\u5236\u53ef\u89e3\u91ca\u6027\u7684\u68c0\u6d4b\u65b9\u6cd5\u5728\u5fae\u8c03\u6a21\u578b\u4e2d\u6bd4\u57fa\u7840\u6a21\u578b\u68c0\u6d4b\u51c6\u786e\u7387\u9ad833%\uff0c\u5373\u4f7f\u5bf9\u4f4e\u53ef\u6062\u590d\u6027\u65b9\u6848\u4e5f\u6709\u6548\u3002", "conclusion": "\u6076\u610f\u5fae\u8c03\u4f1a\u5728LLM\u5185\u90e8\u7559\u4e0b\u53ef\u64cd\u4f5c\u7684\u7279\u5f81\uff0c\u8fd9\u4e9b\u7279\u5f81\u53ef\u901a\u8fc7\u673a\u5236\u53ef\u89e3\u91ca\u6027\u65b9\u6cd5\u68c0\u6d4b\u3002\u4f20\u7edf\u9690\u5199\u5206\u6790\u65b9\u6cd5\u4e0d\u9002\u7528\u4e8e\u68c0\u6d4b\u57fa\u4e8e\u5fae\u8c03\u7684\u9690\u5199\u653b\u51fb\uff0c\u9700\u8981\u5f00\u53d1\u57fa\u4e8e\u5185\u90e8\u6fc0\u6d3b\u7279\u5f81\u7684\u65b0\u578b\u9632\u5fa1\u65b9\u6cd5\u3002"}}
{"id": "2601.22892", "categories": ["cs.CR", "cs.NI", "cs.PF"], "pdf": "https://arxiv.org/pdf/2601.22892", "abs": "https://arxiv.org/abs/2601.22892", "authors": ["Lukas K\u00f6der", "Nils Lohmiller", "Phil Schmieder", "Bastian Buck", "Michael Menth", "Tobias Heer"], "title": "Assessing the Real-World Impact of Post-Quantum Cryptography on WPA-Enterprise Networks", "comment": null, "summary": "The advent of large-scale quantum computers poses a significant threat to contemporary network security protocols, including Wi-Fi Protected Access (WPA)-Enterprise authentication. To mitigate this threat, the adoption of Post-Quantum Cryptography (PQC) is critical. In this work, we investigate the performance impact of PQC algorithms on WPA-Enterprise-based authentication. To this end, we conduct an experimental evaluation of authentication latency using a testbed built with the open-source tools FreeRADIUS and hostapd, measuring the time spent at the client, access point, and RADIUS server. We evaluate multiple combinations of PQC algorithms and analyze their performance overhead in comparison to currently deployed cryptographic schemes. Beyond performance, we assess the security implications of these algorithm choices by relating authentication mechanisms to the quantum effort required for their exploitation. This perspective enables a systematic categorization of PQ-relevant weaknesses in WPA-Enterprise according to their practical urgency. The evaluation results show that, although PQC introduces additional authentication latency, combinations such as ML-DSA-65 and Falcon-1024 used in conjunction with ML-KEM provide a favorable trade-off between security and performance. Furthermore, we demonstrate that the resulting overhead can be effectively mitigated through session resumption. Overall, this work presents a first real-world performance evaluation of PQC-enabled WPA-Enterprise authentication and demonstrates its practical feasibility for enterprise Wi-Fi deployments.", "AI": {"tldr": "\u8be5\u8bba\u6587\u9996\u6b21\u5bf9\u540e\u91cf\u5b50\u5bc6\u7801\u7b97\u6cd5\u5728WPA-Enterprise\u8ba4\u8bc1\u4e2d\u7684\u6027\u80fd\u5f71\u54cd\u8fdb\u884c\u4e86\u771f\u5b9e\u4e16\u754c\u8bc4\u4f30\uff0c\u53d1\u73b0ML-DSA-65\u548cFalcon-1024\u4e0eML-KEM\u7ed3\u5408\u80fd\u5728\u5b89\u5168\u4e0e\u6027\u80fd\u95f4\u53d6\u5f97\u826f\u597d\u5e73\u8861\uff0c\u4e14\u4f1a\u8bdd\u6062\u590d\u80fd\u6709\u6548\u7f13\u89e3\u989d\u5916\u5ef6\u8fdf\u3002", "motivation": "\u5927\u89c4\u6a21\u91cf\u5b50\u8ba1\u7b97\u673a\u7684\u51fa\u73b0\u5bf9\u5305\u62ecWPA-Enterprise\u8ba4\u8bc1\u5728\u5185\u7684\u73b0\u4ee3\u7f51\u7edc\u5b89\u5168\u534f\u8bae\u6784\u6210\u91cd\u5927\u5a01\u80c1\uff0c\u9700\u8981\u91c7\u7528\u540e\u91cf\u5b50\u5bc6\u7801\u5b66\u6765\u5e94\u5bf9\u8fd9\u4e00\u5a01\u80c1\uff0c\u4f46\u9700\u8981\u8bc4\u4f30\u5176\u5bf9\u8ba4\u8bc1\u6027\u80fd\u7684\u5b9e\u9645\u5f71\u54cd\u3002", "method": "\u4f7f\u7528FreeRADIUS\u548chostapd\u6784\u5efa\u5b9e\u9a8c\u6d4b\u8bd5\u5e8a\uff0c\u6d4b\u91cf\u5ba2\u6237\u7aef\u3001\u63a5\u5165\u70b9\u548cRADIUS\u670d\u52a1\u5668\u7684\u8ba4\u8bc1\u5ef6\u8fdf\uff0c\u8bc4\u4f30\u591a\u79cdPQC\u7b97\u6cd5\u7ec4\u5408\u7684\u6027\u80fd\u5f00\u9500\uff0c\u5e76\u4e0e\u73b0\u6709\u52a0\u5bc6\u65b9\u6848\u5bf9\u6bd4\uff0c\u540c\u65f6\u5206\u6790\u7b97\u6cd5\u9009\u62e9\u7684\u5b89\u5168\u5f71\u54cd\u3002", "result": "PQC\u786e\u5b9e\u4f1a\u5f15\u5165\u989d\u5916\u7684\u8ba4\u8bc1\u5ef6\u8fdf\uff0c\u4f46ML-DSA-65\u548cFalcon-1024\u4e0eML-KEM\u7684\u7ec4\u5408\u5728\u5b89\u5168\u4e0e\u6027\u80fd\u95f4\u63d0\u4f9b\u4e86\u826f\u597d\u7684\u6743\u8861\uff1b\u901a\u8fc7\u4f1a\u8bdd\u6062\u590d\u53ef\u4ee5\u6709\u6548\u7f13\u89e3\u7531\u6b64\u4ea7\u751f\u7684\u5f00\u9500\u3002", "conclusion": "\u8fd9\u662f\u9996\u6b21\u5bf9\u652f\u6301PQC\u7684WPA-Enterprise\u8ba4\u8bc1\u8fdb\u884c\u771f\u5b9e\u4e16\u754c\u6027\u80fd\u8bc4\u4f30\uff0c\u8bc1\u660e\u4e86\u5176\u5728\u4f01\u4e1aWi-Fi\u90e8\u7f72\u4e2d\u7684\u5b9e\u9645\u53ef\u884c\u6027\uff0c\u4e3a\u540e\u91cf\u5b50\u65f6\u4ee3\u7684\u4f01\u4e1a\u7f51\u7edc\u5b89\u5168\u63d0\u4f9b\u4e86\u5b9e\u8df5\u6307\u5bfc\u3002"}}
{"id": "2601.22921", "categories": ["cs.CR", "cs.AI", "cs.LG"], "pdf": "https://arxiv.org/pdf/2601.22921", "abs": "https://arxiv.org/abs/2601.22921", "authors": ["Farnaz Soltaniani", "Shoaib Razzaq", "Mohammad Ghafari"], "title": "Evaluating Large Language Models for Security Bug Report Prediction", "comment": null, "summary": "Early detection of security bug reports (SBRs) is critical for timely vulnerability mitigation. We present an evaluation of prompt-based engineering and fine-tuning approaches for predicting SBRs using Large Language Models (LLMs). Our findings reveal a distinct trade-off between the two approaches. Prompted proprietary models demonstrate the highest sensitivity to SBRs, achieving a G-measure of 77% and a recall of 74% on average across all the datasets, albeit at the cost of a higher false-positive rate, resulting in an average precision of only 22%. Fine-tuned models, by contrast, exhibit the opposite behavior, attaining a lower overall G-measure of 51% but substantially higher precision of 75% at the cost of reduced recall of 36%. Though a one-time investment in building fine-tuned models is necessary, the inference on the largest dataset is up to 50 times faster than that of proprietary models. These findings suggest that further investigations to harness the power of LLMs for SBR prediction are necessary.", "AI": {"tldr": "\u8bc4\u4f30\u57fa\u4e8e\u63d0\u793a\u5de5\u7a0b\u548c\u5fae\u8c03\u65b9\u6cd5\u4f7f\u7528\u5927\u8bed\u8a00\u6a21\u578b\u9884\u6d4b\u5b89\u5168\u6f0f\u6d1e\u62a5\u544a\u7684\u6027\u80fd\uff0c\u53d1\u73b0\u63d0\u793a\u65b9\u6cd5\u53ec\u56de\u7387\u9ad8\u4f46\u7cbe\u5ea6\u4f4e\uff0c\u5fae\u8c03\u65b9\u6cd5\u7cbe\u5ea6\u9ad8\u4f46\u53ec\u56de\u7387\u4f4e\uff0c\u5b58\u5728\u660e\u663e\u6743\u8861", "motivation": "\u5b89\u5168\u6f0f\u6d1e\u62a5\u544a\u7684\u65e9\u671f\u68c0\u6d4b\u5bf9\u53ca\u65f6\u7f13\u89e3\u6f0f\u6d1e\u81f3\u5173\u91cd\u8981\uff0c\u9700\u8981\u8bc4\u4f30\u4e0d\u540cLLM\u65b9\u6cd5\u5728SBR\u9884\u6d4b\u4e2d\u7684\u6027\u80fd\u8868\u73b0", "method": "\u6bd4\u8f83\u57fa\u4e8e\u63d0\u793a\u5de5\u7a0b\u7684\u4e13\u6709\u6a21\u578b\u548c\u5fae\u8c03\u6a21\u578b\u4e24\u79cd\u65b9\u6cd5\uff0c\u8bc4\u4f30\u5b83\u4eec\u5728\u5b89\u5168\u6f0f\u6d1e\u62a5\u544a\u9884\u6d4b\u4efb\u52a1\u4e0a\u7684\u6027\u80fd", "result": "\u63d0\u793a\u4e13\u6709\u6a21\u578b\u5e73\u5747G-measure 77%\uff0c\u53ec\u56de\u738774%\uff0c\u4f46\u7cbe\u5ea6\u4ec522%\uff1b\u5fae\u8c03\u6a21\u578bG-measure 51%\uff0c\u7cbe\u5ea675%\uff0c\u53ec\u56de\u738736%\uff1b\u5fae\u8c03\u6a21\u578b\u63a8\u7406\u901f\u5ea6\u6bd4\u4e13\u6709\u6a21\u578b\u5feb50\u500d", "conclusion": "\u4e24\u79cd\u65b9\u6cd5\u5b58\u5728\u660e\u663e\u6743\u8861\uff1a\u63d0\u793a\u65b9\u6cd5\u654f\u611f\u5ea6\u9ad8\u4f46\u5047\u9633\u6027\u591a\uff0c\u5fae\u8c03\u65b9\u6cd5\u7cbe\u5ea6\u9ad8\u4f46\u53ec\u56de\u7387\u4f4e\uff0c\u9700\u8981\u8fdb\u4e00\u6b65\u7814\u7a76\u4ee5\u5145\u5206\u5229\u7528LLM\u8fdb\u884cSBR\u9884\u6d4b"}}
{"id": "2601.22935", "categories": ["cs.CR", "cs.AI"], "pdf": "https://arxiv.org/pdf/2601.22935", "abs": "https://arxiv.org/abs/2601.22935", "authors": ["Evgeny Grigorenko", "David Stanojevi\u0107", "David Ili\u0107", "Egor Bogomolov", "Kostadin Cvejoski"], "title": "Protecting Private Code in IDE Autocomplete using Differential Privacy", "comment": "6 pages", "summary": "Modern Integrated Development Environments (IDEs) increasingly leverage Large Language Models (LLMs) to provide advanced features like code autocomplete. While powerful, training these models on user-written code introduces significant privacy risks, making the models themselves a new type of data vulnerability. Malicious actors can exploit this by launching attacks to reconstruct sensitive training data or infer whether a specific code snippet was used for training. This paper investigates the use of Differential Privacy (DP) as a robust defense mechanism for training an LLM for Kotlin code completion. We fine-tune a \\texttt{Mellum} model using DP and conduct a comprehensive evaluation of its privacy and utility. Our results demonstrate that DP provides a strong defense against Membership Inference Attacks (MIAs), reducing the attack's success rate close to a random guess (AUC from 0.901 to 0.606). Furthermore, we show that this privacy guarantee comes at a minimal cost to model performance, with the DP-trained model achieving utility scores comparable to its non-private counterpart, even when trained on 100x less data. Our findings suggest that DP is a practical and effective solution for building private and trustworthy AI-powered IDE features.", "AI": {"tldr": "\u8be5\u8bba\u6587\u7814\u7a76\u4e86\u5728Kotlin\u4ee3\u7801\u8865\u5168LLM\u8bad\u7ec3\u4e2d\u4f7f\u7528\u5dee\u5206\u9690\u79c1(DP)\u4f5c\u4e3a\u9632\u5fa1\u673a\u5236\uff0c\u8bc1\u660eDP\u80fd\u6709\u6548\u62b5\u5fa1\u6210\u5458\u63a8\u7406\u653b\u51fb\uff0c\u540c\u65f6\u4fdd\u6301\u6a21\u578b\u6027\u80fd\uff0c\u4ec5\u97001%\u7684\u6570\u636e\u5373\u53ef\u8fbe\u5230\u4e0e\u975e\u79c1\u6709\u6a21\u578b\u76f8\u5f53\u7684\u6548\u679c\u3002", "motivation": "\u73b0\u4ee3IDE\u4f7f\u7528LLM\u8fdb\u884c\u4ee3\u7801\u8865\u5168\uff0c\u4f46\u8bad\u7ec3\u8fd9\u4e9b\u6a21\u578b\u65f6\u4f7f\u7528\u7528\u6237\u4ee3\u7801\u4f1a\u5e26\u6765\u9690\u79c1\u98ce\u9669\uff0c\u6076\u610f\u653b\u51fb\u8005\u53ef\u80fd\u91cd\u6784\u654f\u611f\u8bad\u7ec3\u6570\u636e\u6216\u63a8\u65ad\u7279\u5b9a\u4ee3\u7801\u7247\u6bb5\u662f\u5426\u88ab\u7528\u4e8e\u8bad\u7ec3\u3002", "method": "\u4f7f\u7528\u5dee\u5206\u9690\u79c1(DP)\u8bad\u7ec3Kotlin\u4ee3\u7801\u8865\u5168\u7684LLM\uff0c\u5bf9Mellum\u6a21\u578b\u8fdb\u884cDP\u5fae\u8c03\uff0c\u5e76\u5168\u9762\u8bc4\u4f30\u5176\u9690\u79c1\u6027\u548c\u5b9e\u7528\u6027\u3002", "result": "DP\u80fd\u6709\u6548\u9632\u5fa1\u6210\u5458\u63a8\u7406\u653b\u51fb(MIA)\uff0c\u5c06\u653b\u51fb\u6210\u529f\u7387\u964d\u4f4e\u81f3\u63a5\u8fd1\u968f\u673a\u731c\u6d4b\u6c34\u5e73(AUC\u4ece0.901\u964d\u81f30.606)\u3002DP\u8bad\u7ec3\u6a21\u578b\u5728\u6027\u80fd\u635f\u5931\u6781\u5c0f\u7684\u60c5\u51b5\u4e0b\uff0c\u5373\u4f7f\u4f7f\u7528100\u500d\u5c11\u7684\u6570\u636e\u4e5f\u80fd\u8fbe\u5230\u4e0e\u975e\u79c1\u6709\u6a21\u578b\u76f8\u5f53\u7684\u5b9e\u7528\u5206\u6570\u3002", "conclusion": "\u5dee\u5206\u9690\u79c1\u662f\u6784\u5efa\u79c1\u5bc6\u4e14\u53ef\u4fe1\u8d56\u7684AI\u9a71\u52a8IDE\u529f\u80fd\u7684\u5b9e\u7528\u6709\u6548\u89e3\u51b3\u65b9\u6848\uff0c\u80fd\u5728\u4fdd\u62a4\u9690\u79c1\u7684\u540c\u65f6\u4fdd\u6301\u6a21\u578b\u6027\u80fd\u3002"}}
{"id": "2601.22938", "categories": ["cs.CR", "cs.AI", "eess.IV", "eess.SP"], "pdf": "https://arxiv.org/pdf/2601.22938", "abs": "https://arxiv.org/abs/2601.22938", "authors": ["Huan Song", "Shuyu Tian", "Junyi Hao", "Cheng Yuan", "Zhenyu Jia", "Jiawei Shao", "Xuelong Li"], "title": "A Real-Time Privacy-Preserving Behavior Recognition System via Edge-Cloud Collaboration", "comment": null, "summary": "As intelligent sensing expands into high-privacy environments such as restrooms and changing rooms, the field faces a critical privacy-security paradox. Traditional RGB surveillance raises significant concerns regarding visual recording and storage, while existing privacy-preserving methods-ranging from physical desensitization to traditional cryptographic or obfuscation techniques-often compromise semantic understanding capabilities or fail to guarantee mathematical irreversibility against reconstruction attacks. To address these challenges, this study presents a novel privacy-preserving perception technology based on the AI Flow theoretical framework and an edge-cloud collaborative architecture. The proposed methodology integrates source desensitization with irreversible feature mapping. Leveraging Information Bottleneck theory, the edge device performs millisecond-level processing to transform raw imagery into abstract feature vectors via non-linear mapping and stochastic noise injection. This process constructs a unidirectional information flow that strips identity-sensitive attributes, rendering the reconstruction of original images impossible. Subsequently, the cloud platform utilizes multimodal family models to perform joint inference solely on these abstract vectors to detect abnormal behaviors. This approach fundamentally severs the path to privacy leakage at the architectural level, achieving a breakthrough from video surveillance to de-identified behavior perception and offering a robust solution for risk management in high-sensitivity public spaces.", "AI": {"tldr": "\u63d0\u51fa\u57fa\u4e8eAI Flow\u7406\u8bba\u548c\u8fb9\u7f18\u4e91\u534f\u4f5c\u67b6\u6784\u7684\u9690\u79c1\u4fdd\u62a4\u611f\u77e5\u6280\u672f\uff0c\u901a\u8fc7\u6e90\u7aef\u8131\u654f\u548c\u4e0d\u53ef\u9006\u7279\u5f81\u6620\u5c04\uff0c\u5728\u8fb9\u7f18\u8bbe\u5907\u5c06\u539f\u59cb\u56fe\u50cf\u8f6c\u6362\u4e3a\u62bd\u8c61\u7279\u5f81\u5411\u91cf\uff0c\u4e91\u7aef\u4ec5\u57fa\u4e8e\u8fd9\u4e9b\u5411\u91cf\u8fdb\u884c\u5f02\u5e38\u884c\u4e3a\u68c0\u6d4b\uff0c\u5b9e\u73b0\u4ece\u89c6\u9891\u76d1\u63a7\u5230\u53bb\u8eab\u4efd\u5316\u884c\u4e3a\u611f\u77e5\u7684\u7a81\u7834\u3002", "motivation": "\u667a\u80fd\u611f\u77e5\u6269\u5c55\u5230\u536b\u751f\u95f4\u3001\u66f4\u8863\u5ba4\u7b49\u9ad8\u9690\u79c1\u73af\u5883\u65f6\u9762\u4e34\u9690\u79c1\u5b89\u5168\u6096\u8bba\uff1a\u4f20\u7edfRGB\u76d1\u63a7\u5b58\u5728\u89c6\u89c9\u8bb0\u5f55\u548c\u5b58\u50a8\u7684\u9690\u79c1\u62c5\u5fe7\uff0c\u73b0\u6709\u9690\u79c1\u4fdd\u62a4\u65b9\u6cd5\u8981\u4e48\u635f\u5bb3\u8bed\u4e49\u7406\u89e3\u80fd\u529b\uff0c\u8981\u4e48\u65e0\u6cd5\u4fdd\u8bc1\u6570\u5b66\u4e0d\u53ef\u9006\u6027\u5bf9\u6297\u91cd\u5efa\u653b\u51fb\u3002", "method": "\u57fa\u4e8eAI Flow\u7406\u8bba\u6846\u67b6\u548c\u8fb9\u7f18\u4e91\u534f\u4f5c\u67b6\u6784\uff0c\u96c6\u6210\u6e90\u7aef\u8131\u654f\u4e0e\u4e0d\u53ef\u9006\u7279\u5f81\u6620\u5c04\u3002\u5229\u7528\u4fe1\u606f\u74f6\u9888\u7406\u8bba\uff0c\u8fb9\u7f18\u8bbe\u5907\u901a\u8fc7\u975e\u7ebf\u6027\u6620\u5c04\u548c\u968f\u673a\u566a\u58f0\u6ce8\u5165\uff0c\u5c06\u539f\u59cb\u56fe\u50cf\u8f6c\u6362\u4e3a\u62bd\u8c61\u7279\u5f81\u5411\u91cf\uff0c\u6784\u5efa\u5355\u5411\u4fe1\u606f\u6d41\uff1b\u4e91\u7aef\u4f7f\u7528\u591a\u6a21\u6001\u5bb6\u65cf\u6a21\u578b\u4ec5\u57fa\u4e8e\u8fd9\u4e9b\u62bd\u8c61\u5411\u91cf\u8fdb\u884c\u8054\u5408\u63a8\u7406\u68c0\u6d4b\u5f02\u5e38\u884c\u4e3a\u3002", "result": "\u8be5\u65b9\u6cd5\u5728\u67b6\u6784\u5c42\u9762\u4ece\u6839\u672c\u4e0a\u5207\u65ad\u4e86\u9690\u79c1\u6cc4\u9732\u8def\u5f84\uff0c\u5b9e\u73b0\u4e86\u4ece\u89c6\u9891\u76d1\u63a7\u5230\u53bb\u8eab\u4efd\u5316\u884c\u4e3a\u611f\u77e5\u7684\u7a81\u7834\uff0c\u4e3a\u9ad8\u654f\u611f\u6027\u516c\u5171\u7a7a\u95f4\u7684\u98ce\u9669\u7ba1\u7406\u63d0\u4f9b\u4e86\u9c81\u68d2\u89e3\u51b3\u65b9\u6848\u3002", "conclusion": "\u63d0\u51fa\u7684\u9690\u79c1\u4fdd\u62a4\u611f\u77e5\u6280\u672f\u901a\u8fc7\u4e0d\u53ef\u9006\u7279\u5f81\u6620\u5c04\u548c\u8fb9\u7f18\u4e91\u534f\u4f5c\u67b6\u6784\uff0c\u89e3\u51b3\u4e86\u9ad8\u9690\u79c1\u73af\u5883\u4e2d\u7684\u9690\u79c1\u5b89\u5168\u6096\u8bba\uff0c\u5728\u4fdd\u62a4\u4e2a\u4eba\u9690\u79c1\u7684\u540c\u65f6\u4fdd\u6301\u4e86\u8bed\u4e49\u7406\u89e3\u80fd\u529b\uff0c\u4e3a\u667a\u80fd\u611f\u77e5\u5728\u654f\u611f\u573a\u666f\u7684\u5e94\u7528\u63d0\u4f9b\u4e86\u53ef\u884c\u65b9\u6848\u3002"}}
{"id": "2601.22946", "categories": ["cs.CR", "cs.AI", "cs.LG"], "pdf": "https://arxiv.org/pdf/2601.22946", "abs": "https://arxiv.org/abs/2601.22946", "authors": ["Farnaz Soltaniani", "Mohammad Ghafari"], "title": "From Data Leak to Secret Misses: The Impact of Data Leakage on Secret Detection Models", "comment": null, "summary": "Machine learning models are increasingly used for software security tasks. These models are commonly trained and evaluated on large Internet-derived datasets, which often contain duplicated or highly similar samples. When such samples are split across training and test sets, data leakage may occur, allowing models to memorize patterns instead of learning to generalize. We investigate duplication in a widely used benchmark dataset of hard coded secrets and show how data leakage can substantially inflate the reported performance of AI-based secret detectors, resulting in a misleading picture of their real-world effectiveness.", "AI": {"tldr": "\u7814\u7a76\u53d1\u73b0\u673a\u5668\u5b66\u4e60\u5b89\u5168\u5de5\u5177\u5728\u91cd\u590d\u6570\u636e\u6cc4\u9732\u4e0b\u6027\u80fd\u865a\u9ad8\uff0c\u5b9e\u9645\u6548\u679c\u88ab\u5938\u5927", "motivation": "\u673a\u5668\u5b66\u4e60\u6a21\u578b\u8d8a\u6765\u8d8a\u591a\u7528\u4e8e\u8f6f\u4ef6\u5b89\u5168\u4efb\u52a1\uff0c\u8fd9\u4e9b\u6a21\u578b\u901a\u5e38\u5728\u5927\u578b\u4e92\u8054\u7f51\u6570\u636e\u96c6\u4e0a\u8bad\u7ec3\u548c\u8bc4\u4f30\uff0c\u8fd9\u4e9b\u6570\u636e\u96c6\u5e38\u5305\u542b\u91cd\u590d\u6216\u9ad8\u5ea6\u76f8\u4f3c\u7684\u6837\u672c\u3002\u5f53\u8fd9\u4e9b\u6837\u672c\u5206\u5e03\u5728\u8bad\u7ec3\u96c6\u548c\u6d4b\u8bd5\u96c6\u4e4b\u95f4\u65f6\uff0c\u53ef\u80fd\u5bfc\u81f4\u6570\u636e\u6cc4\u9732\uff0c\u4f7f\u6a21\u578b\u80fd\u591f\u8bb0\u5fc6\u6a21\u5f0f\u800c\u975e\u5b66\u4e60\u6cdb\u5316\u80fd\u529b\u3002", "method": "\u7814\u7a76\u5206\u6790\u4e86\u5e7f\u6cdb\u4f7f\u7528\u7684\u786c\u7f16\u7801\u5bc6\u94a5\u57fa\u51c6\u6570\u636e\u96c6\u4e2d\u7684\u91cd\u590d\u95ee\u9898\uff0c\u5c55\u793a\u4e86\u6570\u636e\u6cc4\u9732\u5982\u4f55\u663e\u8457\u5938\u5927\u57fa\u4e8eAI\u7684\u5bc6\u94a5\u68c0\u6d4b\u5668\u62a5\u544a\u7684\u6027\u80fd\u3002", "result": "\u6570\u636e\u6cc4\u9732\u4f1a\u5927\u5e45\u865a\u9ad8AI\u5bc6\u94a5\u68c0\u6d4b\u5668\u7684\u62a5\u544a\u6027\u80fd\uff0c\u5bfc\u81f4\u5bf9\u5176\u771f\u5b9e\u4e16\u754c\u6709\u6548\u6027\u7684\u8bef\u5bfc\u6027\u8bc4\u4f30\u3002", "conclusion": "\u5f53\u524d\u673a\u5668\u5b66\u4e60\u5b89\u5168\u5de5\u5177\u7684\u6027\u80fd\u8bc4\u4f30\u5b58\u5728\u6570\u636e\u6cc4\u9732\u95ee\u9898\uff0c\u9700\u8981\u66f4\u4e25\u8c28\u7684\u6570\u636e\u5904\u7406\u548c\u8bc4\u4f30\u65b9\u6cd5\u624d\u80fd\u51c6\u786e\u53cd\u6620\u5176\u5b9e\u9645\u5e94\u7528\u6548\u679c\u3002"}}
{"id": "2601.22978", "categories": ["cs.CR", "cs.PL"], "pdf": "https://arxiv.org/pdf/2601.22978", "abs": "https://arxiv.org/abs/2601.22978", "authors": ["Jonathan Baumann", "Yonghyun Kim", "Yan Farba", "Catalin Hritcu", "Julay Leatherman-Brooks"], "title": "SpecIBT: Formally Verified Protection Against Speculative Control-Flow Hijacking", "comment": "Submitted to CSF'26", "summary": "This paper introduces SpecIBT, a formally verified defense against Spectre BTB, RSB, and PHT that combines CET-style hardware-assisted control-flow integrity with compiler-inserted speculative load hardening (SLH). SpecIBT is based on the novel observation that in the presence of CET-style protection, we can precisely detect BTB misspeculation for indirect calls and set the SLH misspeculation flag. We formalize SpecIBT as a transformation in Rocq and provide a machine-checked proof that it achieves relative security: any transformed program running with speculation leaks no more than what the source program leaks without speculation. This strong security guarantee applies to arbitrary programs, even those not following the cryptographic constant-time programming discipline.", "AI": {"tldr": "SpecIBT\uff1a\u9488\u5bf9Spectre BTB\u3001RSB\u548cPHT\u653b\u51fb\u7684\u6b63\u5f0f\u9a8c\u8bc1\u9632\u5fa1\u65b9\u6848\uff0c\u7ed3\u5408\u786c\u4ef6\u8f85\u52a9\u63a7\u5236\u6d41\u5b8c\u6574\u6027\u548c\u7f16\u8bd1\u5668\u63d2\u5165\u7684\u63a8\u6d4b\u52a0\u8f7d\u786c\u5316\u6280\u672f", "motivation": "Spectre\u653b\u51fb\u5229\u7528\u73b0\u4ee3\u5904\u7406\u5668\u7684\u63a8\u6d4b\u6267\u884c\u6f0f\u6d1e\uff0c\u901a\u8fc7\u5206\u652f\u76ee\u6807\u7f13\u51b2\u533a\uff08BTB\uff09\u3001\u8fd4\u56de\u6808\u7f13\u51b2\u533a\uff08RSB\uff09\u548c\u6a21\u5f0f\u5386\u53f2\u8868\uff08PHT\uff09\u7b49\u7ec4\u4ef6\u6cc4\u9732\u654f\u611f\u4fe1\u606f\u3002\u73b0\u6709\u9632\u5fa1\u65b9\u6848\u8981\u4e48\u4e0d\u591f\u5b89\u5168\uff0c\u8981\u4e48\u6027\u80fd\u5f00\u9500\u5927\uff0c\u9700\u8981\u4e00\u79cd\u65e2\u5b89\u5168\u53c8\u9ad8\u6548\u7684\u9632\u5fa1\u673a\u5236\u3002", "method": "\u7ed3\u5408CET\u98ce\u683c\u7684\u786c\u4ef6\u8f85\u52a9\u63a7\u5236\u6d41\u5b8c\u6574\u6027\uff08CFI\uff09\u4e0e\u7f16\u8bd1\u5668\u63d2\u5165\u7684\u63a8\u6d4b\u52a0\u8f7d\u786c\u5316\uff08SLH\uff09\u3002\u5173\u952e\u521b\u65b0\u662f\uff1a\u5728CET\u4fdd\u62a4\u4e0b\uff0c\u53ef\u4ee5\u7cbe\u786e\u68c0\u6d4b\u95f4\u63a5\u8c03\u7528\u7684BTB\u8bef\u63a8\u6d4b\u5e76\u8bbe\u7f6eSLH\u8bef\u63a8\u6d4b\u6807\u5fd7\u3002\u5728Rocq\u4e2d\u5f62\u5f0f\u5316SpecIBT\u8f6c\u6362\uff0c\u5e76\u63d0\u4f9b\u673a\u5668\u9a8c\u8bc1\u8bc1\u660e\u3002", "result": "\u5b9e\u73b0\u4e86\u76f8\u5bf9\u5b89\u5168\u6027\u8bc1\u660e\uff1a\u4efb\u4f55\u7ecf\u8fc7\u8f6c\u6362\u7684\u7a0b\u5e8f\u5728\u63a8\u6d4b\u6267\u884c\u4e0b\u6cc4\u9732\u7684\u4fe1\u606f\u4e0d\u4f1a\u8d85\u8fc7\u6e90\u7a0b\u5e8f\u5728\u65e0\u63a8\u6d4b\u6267\u884c\u65f6\u6cc4\u9732\u7684\u4fe1\u606f\u3002\u8fd9\u4e00\u5f3a\u5b89\u5168\u4fdd\u8bc1\u9002\u7528\u4e8e\u4efb\u610f\u7a0b\u5e8f\uff0c\u5305\u62ec\u90a3\u4e9b\u4e0d\u9075\u5faa\u5bc6\u7801\u5b66\u5e38\u6570\u65f6\u95f4\u7f16\u7a0b\u89c4\u8303\u7684\u7a0b\u5e8f\u3002", "conclusion": "SpecIBT\u63d0\u4f9b\u4e86\u9488\u5bf9Spectre BTB\u3001RSB\u548cPHT\u653b\u51fb\u7684\u6b63\u5f0f\u9a8c\u8bc1\u9632\u5fa1\u65b9\u6848\uff0c\u901a\u8fc7\u786c\u4ef6\u8f85\u52a9CFI\u4e0e\u7f16\u8bd1\u5668SLH\u7684\u7ed3\u5408\uff0c\u5b9e\u73b0\u4e86\u65e2\u5b89\u5168\u53c8\u5b9e\u7528\u7684\u4fdd\u62a4\u673a\u5236\uff0c\u4e3a\u4efb\u610f\u7a0b\u5e8f\u63d0\u4f9b\u4e86\u5f3a\u5b89\u5168\u4fdd\u8bc1\u3002"}}
{"id": "2601.22983", "categories": ["cs.CR", "cs.LG"], "pdf": "https://arxiv.org/pdf/2601.22983", "abs": "https://arxiv.org/abs/2601.22983", "authors": ["Tristan Bilot", "Baoxiang Jiang", "Thomas Pasquier"], "title": "PIDSMaker: Building and Evaluating Provenance-based Intrusion Detection Systems", "comment": null, "summary": "Recent provenance-based intrusion detection systems (PIDSs) have demonstrated strong potential for detecting advanced persistent threats (APTs) by applying machine learning to system provenance graphs. However, evaluating and comparing PIDSs remains difficult: prior work uses inconsistent preprocessing pipelines, non-standard dataset splits, and incompatible ground-truth labeling and metrics. These discrepancies undermine reproducibility, impede fair comparison, and impose substantial re-implementation overhead on researchers. We present PIDSMaker, an open-source framework for developing and evaluating PIDSs under consistent protocols. PIDSMaker consolidates eight state-of-the-art systems into a modular, extensible architecture with standardized preprocessing and ground-truth labels, enabling consistent experiments and apples-to-apples comparisons. A YAML-based configuration interface supports rapid prototyping by composing components across systems without code changes. PIDSMaker also includes utilities for ablation studies, hyperparameter tuning, multi-run instability measurement, and visualization, addressing methodological gaps identified in prior work. We demonstrate PIDSMaker through concrete use cases and release it with preprocessed datasets and labels to support shared evaluation for the PIDS community.", "AI": {"tldr": "PIDSMaker\u662f\u4e00\u4e2a\u5f00\u6e90\u6846\u67b6\uff0c\u7528\u4e8e\u5728\u4e00\u81f4\u534f\u8bae\u4e0b\u5f00\u53d1\u548c\u8bc4\u4f30\u57fa\u4e8e\u6eaf\u6e90\u56fe\u7684\u5165\u4fb5\u68c0\u6d4b\u7cfb\u7edf\uff0c\u89e3\u51b3\u4e86\u73b0\u6709\u8bc4\u4f30\u65b9\u6cd5\u4e0d\u4e00\u81f4\u7684\u95ee\u9898\u3002", "motivation": "\u73b0\u6709\u57fa\u4e8e\u6eaf\u6e90\u56fe\u7684\u5165\u4fb5\u68c0\u6d4b\u7cfb\u7edf\u8bc4\u4f30\u5b58\u5728\u4e0d\u4e00\u81f4\u6027\uff1a\u4f7f\u7528\u4e0d\u4e00\u81f4\u7684\u9884\u5904\u7406\u6d41\u7a0b\u3001\u975e\u6807\u51c6\u6570\u636e\u96c6\u5212\u5206\u3001\u4e0d\u517c\u5bb9\u7684\u6807\u7b7e\u548c\u6307\u6807\uff0c\u8fd9\u7834\u574f\u4e86\u53ef\u590d\u73b0\u6027\u3001\u963b\u788d\u516c\u5e73\u6bd4\u8f83\uff0c\u5e76\u7ed9\u7814\u7a76\u4eba\u5458\u5e26\u6765\u5927\u91cf\u91cd\u65b0\u5b9e\u73b0\u7684\u5f00\u9500\u3002", "method": "\u63d0\u51fa\u4e86PIDSMaker\u6846\u67b6\uff0c\u5c06\u516b\u4e2a\u6700\u5148\u8fdb\u7684\u7cfb\u7edf\u6574\u5408\u5230\u6a21\u5757\u5316\u3001\u53ef\u6269\u5c55\u7684\u67b6\u6784\u4e2d\uff0c\u91c7\u7528\u6807\u51c6\u5316\u7684\u9884\u5904\u7406\u548c\u771f\u5b9e\u6807\u7b7e\uff1b\u63d0\u4f9b\u57fa\u4e8eYAML\u7684\u914d\u7f6e\u63a5\u53e3\uff0c\u652f\u6301\u8de8\u7cfb\u7edf\u7ec4\u4ef6\u7ec4\u5408\u800c\u65e0\u9700\u4ee3\u7801\u4fee\u6539\uff1b\u5305\u542b\u6d88\u878d\u7814\u7a76\u3001\u8d85\u53c2\u6570\u8c03\u4f18\u3001\u591a\u8f6e\u8fd0\u884c\u4e0d\u7a33\u5b9a\u6027\u6d4b\u91cf\u548c\u53ef\u89c6\u5316\u7b49\u5de5\u5177\u3002", "result": "PIDSMaker\u901a\u8fc7\u5177\u4f53\u7528\u4f8b\u5c55\u793a\u4e86\u5176\u529f\u80fd\uff0c\u5e76\u53d1\u5e03\u4e86\u9884\u5904\u7406\u6570\u636e\u96c6\u548c\u6807\u7b7e\uff0c\u652f\u6301PIDS\u793e\u533a\u7684\u5171\u4eab\u8bc4\u4f30\u3002", "conclusion": "PIDSMaker\u4e3a\u57fa\u4e8e\u6eaf\u6e90\u56fe\u7684\u5165\u4fb5\u68c0\u6d4b\u7cfb\u7edf\u63d0\u4f9b\u4e86\u7edf\u4e00\u7684\u5f00\u53d1\u548c\u8bc4\u4f30\u6846\u67b6\uff0c\u89e3\u51b3\u4e86\u73b0\u6709\u8bc4\u4f30\u65b9\u6cd5\u7684\u4e0d\u4e00\u81f4\u95ee\u9898\uff0c\u4fc3\u8fdb\u4e86\u516c\u5e73\u6bd4\u8f83\u548c\u53ef\u590d\u73b0\u6027\u7814\u7a76\u3002"}}
{"id": "2601.23088", "categories": ["cs.CR", "cs.AI"], "pdf": "https://arxiv.org/pdf/2601.23088", "abs": "https://arxiv.org/abs/2601.23088", "authors": ["Zhixiang Zhang", "Zesen Liu", "Yuchong Xie", "Quanfeng Huang", "Dongdong She"], "title": "From Similarity to Vulnerability: Key Collision Attack on LLM Semantic Caching", "comment": null, "summary": "Semantic caching has emerged as a pivotal technique for scaling LLM applications, widely adopted by major providers including AWS and Microsoft. By utilizing semantic embedding vectors as cache keys, this mechanism effectively minimizes latency and redundant computation for semantically similar queries. In this work, we conceptualize semantic cache keys as a form of fuzzy hashes. We demonstrate that the locality required to maximize cache hit rates fundamentally conflicts with the cryptographic avalanche effect necessary for collision resistance. Our conceptual analysis formalizes this inherent trade-off between performance (locality) and security (collision resilience), revealing that semantic caching is naturally vulnerable to key collision attacks.\n  While prior research has focused on side-channel and privacy risks, we present the first systematic study of integrity risks arising from cache collisions. We introduce CacheAttack, an automated framework for launching black-box collision attacks. We evaluate CacheAttack in security-critical tasks and agentic workflows. It achieves a hit rate of 86\\% in LLM response hijacking and can induce malicious behaviors in LLM agent, while preserving strong transferability across different embedding models. A case study on a financial agent further illustrates the real-world impact of these vulnerabilities. Finally, we discuss mitigation strategies.", "AI": {"tldr": "\u8be5\u8bba\u6587\u5c06\u8bed\u4e49\u7f13\u5b58\u89c6\u4e3a\u6a21\u7cca\u54c8\u5e0c\uff0c\u63ed\u793a\u4e86\u5176\u6027\u80fd\uff08\u5c40\u90e8\u6027\uff09\u4e0e\u5b89\u5168\uff08\u6297\u78b0\u649e\u6027\uff09\u4e4b\u95f4\u7684\u6839\u672c\u51b2\u7a81\uff0c\u5e76\u63d0\u51fa\u4e86\u9996\u4e2a\u9488\u5bf9\u7f13\u5b58\u78b0\u649e\u7684\u5b8c\u6574\u6027\u653b\u51fb\u6846\u67b6CacheAttack\u3002", "motivation": "\u8bed\u4e49\u7f13\u5b58\u4f5c\u4e3aLLM\u5e94\u7528\u6269\u5c55\u7684\u5173\u952e\u6280\u672f\u5df2\u88abAWS\u3001\u5fae\u8f6f\u7b49\u4e3b\u8981\u63d0\u4f9b\u5546\u5e7f\u6cdb\u91c7\u7528\uff0c\u4f46\u73b0\u6709\u7814\u7a76\u4e3b\u8981\u5173\u6ce8\u4fa7\u4fe1\u9053\u548c\u9690\u79c1\u98ce\u9669\uff0c\u7f3a\u4e4f\u5bf9\u7f13\u5b58\u78b0\u649e\u5f15\u53d1\u7684\u5b8c\u6574\u6027\u98ce\u9669\u7684\u7cfb\u7edf\u6027\u7814\u7a76\u3002", "method": "\u5c06\u8bed\u4e49\u7f13\u5b58\u952e\u6982\u5ff5\u5316\u4e3a\u6a21\u7cca\u54c8\u5e0c\uff0c\u5f62\u5f0f\u5316\u6027\u80fd\u4e0e\u5b89\u5168\u4e4b\u95f4\u7684\u6743\u8861\uff0c\u5e76\u5f00\u53d1CacheAttack\u6846\u67b6\u2014\u2014\u4e00\u4e2a\u7528\u4e8e\u53d1\u8d77\u9ed1\u76d2\u78b0\u649e\u653b\u51fb\u7684\u81ea\u52a8\u5316\u7cfb\u7edf\u3002", "result": "CacheAttack\u5728LLM\u54cd\u5e94\u52ab\u6301\u4e2d\u8fbe\u523086%\u7684\u547d\u4e2d\u7387\uff0c\u80fd\u591f\u8bf1\u5bfcLLM\u4ee3\u7406\u7684\u6076\u610f\u884c\u4e3a\uff0c\u4e14\u5728\u4e0d\u540c\u5d4c\u5165\u6a21\u578b\u95f4\u4fdd\u6301\u5f3a\u53ef\u8fc1\u79fb\u6027\u3002\u91d1\u878d\u4ee3\u7406\u6848\u4f8b\u7814\u7a76\u8fdb\u4e00\u6b65\u5c55\u793a\u4e86\u5b9e\u9645\u5f71\u54cd\u3002", "conclusion": "\u8bed\u4e49\u7f13\u5b58\u5929\u7136\u6613\u53d7\u5bc6\u94a5\u78b0\u649e\u653b\u51fb\uff0c\u9700\u8981\u5728\u6027\u80fd\u4e0e\u5b89\u5168\u4e4b\u95f4\u8fdb\u884c\u6743\u8861\u3002\u8bba\u6587\u63ed\u793a\u4e86\u8fd9\u4e00\u7cfb\u7edf\u6027\u6f0f\u6d1e\uff0c\u5e76\u8ba8\u8bba\u4e86\u7f13\u89e3\u7b56\u7565\u3002"}}
{"id": "2601.23092", "categories": ["cs.CR", "cs.AI"], "pdf": "https://arxiv.org/pdf/2601.23092", "abs": "https://arxiv.org/abs/2601.23092", "authors": ["Haitham S. Al-Sinani", "Chris J. Mitchell"], "title": "WiFiPenTester: Advancing Wireless Ethical Hacking with Governed GenAI", "comment": "35 pages, 10 figures", "summary": "Wireless ethical hacking relies heavily on skilled practitioners manually interpreting reconnaissance results and executing complex, time-sensitive sequences of commands to identify vulnerable targets, capture authentication handshakes, and assess password resilience; a process that is inherently labour-intensive, difficult to scale, and prone to subjective judgement and human error. To help address these limitations, we propose WiFiPenTester, an experimental, governed, and reproducible system for GenAI-enabled wireless ethical hacking. The system integrates large language models into the reconnaissance and decision-support phases of wireless security assessment, enabling intelligent target ranking, attack feasibility estimation, and strategy recommendation, while preserving strict human-in-the-loop control and budget-aware execution. We describe the system architecture, threat model, governance mechanisms, and prompt-engineering methodology, and empirical experiments conducted across multiple wireless environments. The results demonstrate that GenAI assistance improves target selection accuracy and overall assessment efficiency, while maintaining auditability and ethical safeguards. This indicates that WiFiPenTester is a meaningful step toward practical, safe, and scalable GenAI-assisted wireless penetration testing, while reinforcing the necessity of bounded autonomy, human oversight, and rigorous governance mechanisms when deploying GenAI in ethical hacking.", "AI": {"tldr": "WiFiPenTester\u662f\u4e00\u4e2a\u5b9e\u9a8c\u6027\u7684GenAI\u8f85\u52a9\u65e0\u7ebf\u4f26\u7406\u9ed1\u5ba2\u7cfb\u7edf\uff0c\u901a\u8fc7\u96c6\u6210\u5927\u8bed\u8a00\u6a21\u578b\u6539\u8fdb\u65e0\u7ebf\u5b89\u5168\u8bc4\u4f30\u7684\u76ee\u6807\u9009\u62e9\u3001\u653b\u51fb\u53ef\u884c\u6027\u5206\u6790\u548c\u7b56\u7565\u63a8\u8350\uff0c\u540c\u65f6\u4fdd\u6301\u4e25\u683c\u7684\u4eba\u5de5\u76d1\u7763\u548c\u6cbb\u7406\u673a\u5236\u3002", "motivation": "\u4f20\u7edf\u65e0\u7ebf\u4f26\u7406\u9ed1\u5ba2\u4f9d\u8d56\u4eba\u5de5\u64cd\u4f5c\uff0c\u5b58\u5728\u52b3\u52a8\u5bc6\u96c6\u3001\u96be\u4ee5\u6269\u5c55\u3001\u4e3b\u89c2\u5224\u65ad\u548c\u4eba\u4e3a\u9519\u8bef\u7b49\u95ee\u9898\uff0c\u9700\u8981\u66f4\u667a\u80fd\u3001\u53ef\u6269\u5c55\u4e14\u53ef\u63a7\u7684\u89e3\u51b3\u65b9\u6848\u3002", "method": "\u63d0\u51faWiFiPenTester\u7cfb\u7edf\uff0c\u5c06\u5927\u8bed\u8a00\u6a21\u578b\u96c6\u6210\u5230\u65e0\u7ebf\u5b89\u5168\u8bc4\u4f30\u7684\u4fa6\u5bdf\u548c\u51b3\u7b56\u652f\u6301\u9636\u6bb5\uff0c\u5b9e\u73b0\u667a\u80fd\u76ee\u6807\u6392\u5e8f\u3001\u653b\u51fb\u53ef\u884c\u6027\u4f30\u8ba1\u548c\u7b56\u7565\u63a8\u8350\uff0c\u540c\u65f6\u4fdd\u6301\u4e25\u683c\u7684\u4eba\u5de5\u76d1\u7763\u3001\u9884\u7b97\u611f\u77e5\u6267\u884c\u548c\u6cbb\u7406\u673a\u5236\u3002", "result": "\u5b9e\u9a8c\u7ed3\u679c\u8868\u660e\uff0cGenAI\u8f85\u52a9\u63d0\u9ad8\u4e86\u76ee\u6807\u9009\u62e9\u51c6\u786e\u6027\u548c\u6574\u4f53\u8bc4\u4f30\u6548\u7387\uff0c\u540c\u65f6\u4fdd\u6301\u4e86\u53ef\u5ba1\u8ba1\u6027\u548c\u4f26\u7406\u4fdd\u969c\uff0c\u9a8c\u8bc1\u4e86\u7cfb\u7edf\u5728\u591a\u4e2a\u65e0\u7ebf\u73af\u5883\u4e2d\u7684\u6709\u6548\u6027\u3002", "conclusion": "WiFiPenTester\u662f\u8fc8\u5411\u5b9e\u7528\u3001\u5b89\u5168\u3001\u53ef\u6269\u5c55\u7684GenAI\u8f85\u52a9\u65e0\u7ebf\u6e17\u900f\u6d4b\u8bd5\u7684\u91cd\u8981\u4e00\u6b65\uff0c\u540c\u65f6\u5f3a\u8c03\u4e86\u5728\u4f26\u7406\u9ed1\u5ba2\u4e2d\u90e8\u7f72GenAI\u65f6\u9700\u8981\u6709\u9650\u81ea\u4e3b\u6027\u3001\u4eba\u5de5\u76d1\u7763\u548c\u4e25\u683c\u6cbb\u7406\u673a\u5236\u7684\u5fc5\u8981\u6027\u3002"}}
{"id": "2601.23132", "categories": ["cs.CR", "cs.AI"], "pdf": "https://arxiv.org/pdf/2601.23132", "abs": "https://arxiv.org/abs/2601.23132", "authors": ["Saeid Jamshidi", "Kawser Wazed Nafi", "Arghavan Moradi Dakhel", "Foutse Khomh", "Amin Nikanjam", "Mohammad Adnan Hamdaqa"], "title": "Secure Tool Manifest and Digital Signing Solution for Verifiable MCP and LLM Pipelines", "comment": null, "summary": "Large Language Models (LLMs) are increasingly adopted in sensitive domains such as healthcare and financial institutions' data analytics; however, their execution pipelines remain vulnerable to manipulation and unverifiable behavior. Existing control mechanisms, such as the Model Context Protocol (MCP), define compliance policies for tool invocation but lack verifiable enforcement and transparent validation of model actions. To address this gap, we propose a novel Secure Tool Manifest and Digital Signing Framework, a structured and security-aware extension of Model Context Protocols. The framework enforces cryptographically signed manifests, integrates transparent verification logs, and isolates model-internal execution metadata from user-visible components to ensure verifiable execution integrity. Furthermore, the evaluation demonstrates that the framework scales nearly linearly (R-squared = 0.998), achieves near-perfect acceptance of valid executions while consistently rejecting invalid ones, and maintains balanced model utilization across execution pipelines.", "AI": {"tldr": "\u63d0\u51fa\u4e00\u4e2a\u5b89\u5168\u7684\u5de5\u5177\u6e05\u5355\u548c\u6570\u5b57\u7b7e\u540d\u6846\u67b6\uff0c\u7528\u4e8e\u589e\u5f3aLLM\u5728\u654f\u611f\u9886\u57df\u6267\u884c\u7ba1\u9053\u7684\u5b89\u5168\u6027\u548c\u53ef\u9a8c\u8bc1\u6027\u3002", "motivation": "LLM\u5728\u533b\u7597\u548c\u91d1\u878d\u7b49\u654f\u611f\u9886\u57df\u5e94\u7528\u65e5\u76ca\u5e7f\u6cdb\uff0c\u4f46\u5176\u6267\u884c\u7ba1\u9053\u5bb9\u6613\u53d7\u5230\u64cd\u7eb5\u4e14\u884c\u4e3a\u4e0d\u53ef\u9a8c\u8bc1\u3002\u73b0\u6709\u63a7\u5236\u673a\u5236\uff08\u5982MCP\uff09\u7f3a\u4e4f\u53ef\u9a8c\u8bc1\u7684\u5f3a\u5236\u6267\u884c\u548c\u900f\u660e\u7684\u6a21\u578b\u884c\u4e3a\u9a8c\u8bc1\u3002", "method": "\u63d0\u51fa\u4e00\u4e2a\u7ed3\u6784\u5316\u3001\u5b89\u5168\u611f\u77e5\u7684\u6a21\u578b\u4e0a\u4e0b\u6587\u534f\u8bae\u6269\u5c55\u6846\u67b6\uff0c\u5305\u542b\u52a0\u5bc6\u7b7e\u540d\u7684\u6e05\u5355\u3001\u900f\u660e\u9a8c\u8bc1\u65e5\u5fd7\uff0c\u5e76\u5c06\u6a21\u578b\u5185\u90e8\u6267\u884c\u5143\u6570\u636e\u4e0e\u7528\u6237\u53ef\u89c1\u7ec4\u4ef6\u9694\u79bb\u3002", "result": "\u6846\u67b6\u6269\u5c55\u6027\u63a5\u8fd1\u7ebf\u6027\uff08R\u5e73\u65b9=0.998\uff09\uff0c\u6709\u6548\u6267\u884c\u63a5\u53d7\u7387\u63a5\u8fd1\u5b8c\u7f8e\uff0c\u80fd\u6301\u7eed\u62d2\u7edd\u65e0\u6548\u6267\u884c\uff0c\u5e76\u5728\u6267\u884c\u7ba1\u9053\u95f4\u4fdd\u6301\u5e73\u8861\u7684\u6a21\u578b\u5229\u7528\u7387\u3002", "conclusion": "\u8be5\u6846\u67b6\u4e3aLLM\u5728\u654f\u611f\u9886\u57df\u7684\u5e94\u7528\u63d0\u4f9b\u4e86\u53ef\u9a8c\u8bc1\u7684\u6267\u884c\u5b8c\u6574\u6027\u4fdd\u969c\uff0c\u89e3\u51b3\u4e86\u73b0\u6709\u63a7\u5236\u673a\u5236\u7684\u5b89\u5168\u6027\u548c\u53ef\u9a8c\u8bc1\u6027\u4e0d\u8db3\u95ee\u9898\u3002"}}
{"id": "2601.23157", "categories": ["cs.CR", "cs.LG"], "pdf": "https://arxiv.org/pdf/2601.23157", "abs": "https://arxiv.org/abs/2601.23157", "authors": ["Paulius Rauba", "Dominykas Seputis", "Patrikas Vanagas", "Mihaela van der Schaar"], "title": "No More, No Less: Least-Privilege Language Models", "comment": null, "summary": "Least privilege is a core security principle: grant each request only the minimum access needed to achieve its goal. Deployed language models almost never follow it, instead being exposed through a single API endpoint that serves all users and requests. This gap exists not because least privilege would be unhelpful; deployments would benefit greatly from reducing unnecessary capability exposure. The real obstacle is definitional and mechanistic: what does \"access\" mean inside a language model, and how can we enforce it without retraining or deploying multiple models? We take inspiration from least privilege in computer systems and define a class of models called least-privilege language models, where privilege is reachable internal computation during the forward pass. In this view, lowering privilege literally shrinks the model's accessible function class, as opposed to denying access via learned policies. We formalize deployment-time control as a monitor-allocator-enforcer stack, separating (i) request-time signals, (ii) a decision rule that allocates privilege, and (iii) an inference-time mechanism that selects privilege. We then propose Nested Least-Privilege Networks, a shape-preserving, rank-indexed intervention that provides a smooth, reversible control knob. We show that this knob yields policy-usable privilege-utility frontiers and enables selective suppression of targeted capabilities with limited collateral degradation across various policies. Most importantly, we argue for a new deployment paradigm that challenges the premise that language models can only be controlled at the output level.", "AI": {"tldr": "\u8bba\u6587\u63d0\u51fa\"\u6700\u5c0f\u7279\u6743\u8bed\u8a00\u6a21\u578b\"\u6982\u5ff5\uff0c\u901a\u8fc7\u6a21\u578b\u5185\u90e8\u8ba1\u7b97\u53ef\u8fbe\u6027\u5b9a\u4e49\u7279\u6743\uff0c\u5f00\u53d1\u90e8\u7f72\u65f6\u63a7\u5236\u673a\u5236\uff0c\u5b9e\u73b0\u65e0\u9700\u91cd\u65b0\u8bad\u7ec3\u5373\u53ef\u9650\u5236\u6a21\u578b\u80fd\u529b\u66b4\u9732\u3002", "motivation": "\u5f53\u524d\u8bed\u8a00\u6a21\u578b\u90e8\u7f72\u8fdd\u53cd\u6700\u5c0f\u7279\u6743\u5b89\u5168\u539f\u5219\uff0c\u6240\u6709\u7528\u6237\u8bf7\u6c42\u90fd\u901a\u8fc7\u5355\u4e00API\u7aef\u70b9\u66b4\u9732\u5168\u90e8\u80fd\u529b\u3002\u8fd9\u79cd\u8bbe\u8ba1\u5b58\u5728\u5b89\u5168\u98ce\u9669\uff0c\u4f46\u7f3a\u4e4f\u5b9a\u4e49\u548c\u673a\u5236\u6765\u5b9e\u65bd\u6700\u5c0f\u7279\u6743\u63a7\u5236\u3002", "method": "\u63d0\u51fa\u6700\u5c0f\u7279\u6743\u8bed\u8a00\u6a21\u578b\u6846\u67b6\uff0c\u5c06\u7279\u6743\u5b9a\u4e49\u4e3a\u524d\u5411\u4f20\u64ad\u4e2d\u53ef\u8fbe\u7684\u5185\u90e8\u8ba1\u7b97\u3002\u8bbe\u8ba1\u76d1\u63a7-\u5206\u914d-\u6267\u884c\u4e09\u5c42\u90e8\u7f72\u65f6\u63a7\u5236\u67b6\u6784\uff0c\u5e76\u5f00\u53d1\u5d4c\u5957\u6700\u5c0f\u7279\u6743\u7f51\u7edc\u4f5c\u4e3a\u5f62\u72b6\u4fdd\u6301\u3001\u79e9\u7d22\u5f15\u7684\u5e72\u9884\u673a\u5236\u3002", "result": "\u8be5\u65b9\u6cd5\u63d0\u4f9b\u4e86\u5e73\u6ed1\u53ef\u9006\u7684\u63a7\u5236\u65cb\u94ae\uff0c\u80fd\u591f\u4ea7\u751f\u7b56\u7565\u53ef\u7528\u7684\u7279\u6743-\u6548\u7528\u8fb9\u754c\uff0c\u5b9e\u73b0\u76ee\u6807\u80fd\u529b\u7684\u9009\u62e9\u6027\u6291\u5236\uff0c\u540c\u65f6\u9650\u5236\u5bf9\u5176\u4ed6\u80fd\u529b\u7684\u9644\u5e26\u635f\u5bb3\u3002", "conclusion": "\u6311\u6218\u4e86\u8bed\u8a00\u6a21\u578b\u53ea\u80fd\u5728\u8f93\u51fa\u5c42\u9762\u63a7\u5236\u7684\u4f20\u7edf\u89c2\u5ff5\uff0c\u63d0\u51fa\u65b0\u7684\u90e8\u7f72\u8303\u5f0f\uff0c\u901a\u8fc7\u5185\u90e8\u8ba1\u7b97\u53ef\u8fbe\u6027\u5b9e\u73b0\u6700\u5c0f\u7279\u6743\u539f\u5219\uff0c\u63d0\u9ad8\u6a21\u578b\u90e8\u7f72\u5b89\u5168\u6027\u3002"}}
