<div id=toc></div>

# Table of Contents

- [cs.CR](#cs.CR) [Total: 23]


<div id='cs.CR'></div>

# cs.CR [[Back]](#toc)

### [1] [Transferable Hypergraph Attack via Injecting Nodes into Pivotal Hyperedges](https://arxiv.org/abs/2511.10698)
*Meixia He,Peican Zhu,Le Cheng,Yangming Guo,Manman Yuan,Keke Tang*

Main category: cs.CR

TL;DR: 提出TH-Attack框架，通过识别关键超边并注入恶意节点来提升超图神经网络对抗攻击的迁移性和有效性。


<details>
  <summary>Details</summary>
Motivation: 现有超图神经网络对抗攻击方法依赖目标模型的特定信息机制，忽略了大多数HGNN中沿聚合路径的超边重要性差异导致的共同脆弱性，限制了攻击的迁移性和有效性。

Method: 设计基于重要性评估的超边识别器获取关键超边；引入基于关键超边的特征反转器生成恶意节点；将恶意节点注入关键超边来实施攻击。

Result: 在六个真实数据集上的广泛实验验证了TH-Attack的有效性及其相对于最先进方法的优越性。

Conclusion: TH-Attack通过识别和利用超边重要性差异，显著提升了超图神经网络对抗攻击的迁移性和攻击效果。

Abstract: Recent studies have demonstrated that hypergraph neural networks (HGNNs) are susceptible to adversarial attacks. However, existing methods rely on the specific information mechanisms of target HGNNs, overlooking the common vulnerability caused by the significant differences in hyperedge pivotality along aggregation paths in most HGNNs, thereby limiting the transferability and effectiveness of attacks. In this paper, we present a novel framework, i.e., Transferable Hypergraph Attack via Injecting Nodes into Pivotal Hyperedges (TH-Attack), to address these limitations. Specifically, we design a hyperedge recognizer via pivotality assessment to obtain pivotal hyperedges within the aggregation paths of HGNNs. Furthermore, we introduce a feature inverter based on pivotal hyperedges, which generates malicious nodes by maximizing the semantic divergence between the generated features and the pivotal hyperedges features. Lastly, by injecting these malicious nodes into the pivotal hyperedges, TH-Attack improves the transferability and effectiveness of attacks. Extensive experiments are conducted on six authentic datasets to validate the effectiveness of TH-Attack and the corresponding superiority to state-of-the-art methods.

</details>


### [2] [Do Not Merge My Model! Safeguarding Open-Source LLMs Against Unauthorized Model Merging](https://arxiv.org/abs/2511.10712)
*Qinfeng Li,Miao Pan,Jintao Chen,Fu Teng,Zhiqiang Shen,Ge Su,Hao Peng,Xuhong Zhang*

Main category: cs.CR

TL;DR: MergeBarrier是一种即插即用的防御机制，通过破坏受保护模型与其同源模型之间的线性模式连接性，主动防止未经授权的模型合并窃取。


<details>
  <summary>Details</summary>
Motivation: 模型合并技术虽然能高效扩展大语言模型，但也引入了模型合并窃取的新威胁，现有防御机制无法同时满足主动防止未经授权合并、兼容开源设置和低性能损失高安全性这三个关键保护属性。

Method: 提出MergeBarrier防御方法，通过破坏受保护模型与其同源模型之间的线性模式连接性，消除有效模型合并所需的低损失路径。

Result: 大量实验表明，MergeBarrier能有效防止模型合并窃取，且仅带来可忽略的准确率损失。

Conclusion: MergeBarrier为模型合并窃取问题提供了一种有效的防御解决方案，在保证安全性的同时保持了模型性能。

Abstract: Model merging has emerged as an efficient technique for expanding large language models (LLMs) by integrating specialized expert models. However, it also introduces a new threat: model merging stealing, where free-riders exploit models through unauthorized model merging. Unfortunately, existing defense mechanisms fail to provide effective protection. Specifically, we identify three critical protection properties that existing methods fail to simultaneously satisfy: (1) proactively preventing unauthorized merging; (2) ensuring compatibility with general open-source settings; (3) achieving high security with negligible performance loss. To address the above issues, we propose MergeBarrier, a plug-and-play defense that proactively prevents unauthorized merging. The core design of MergeBarrier is to disrupt the Linear Mode Connectivity (LMC) between the protected model and its homologous counterparts, thereby eliminating the low-loss path required for effective model merging. Extensive experiments show that MergeBarrier effectively prevents model merging stealing with negligible accuracy loss.

</details>


### [3] [BadThink: Triggered Overthinking Attacks on Chain-of-Thought Reasoning in Large Language Models](https://arxiv.org/abs/2511.10714)
*Shuaitong Liu,Renjue Li,Lijia Yu,Lijun Zhang,Zhiming Liu,Gaojie Jin*

Main category: cs.CR

TL;DR: BadThink是一种针对思维链提示的后门攻击，通过精心设计的触发提示诱导模型产生过度思考行为，生成冗余的推理过程但保持最终输出一致，从而显著增加计算成本但难以被检测。


<details>
  <summary>Details</summary>
Motivation: 随着思维链提示技术提升大语言模型推理能力，其计算效率成为新的攻击面。本文旨在揭示思维链推理效率可能被隐蔽操纵的漏洞。

Method: 通过基于中毒的微调策略实现攻击，采用基于LLM的迭代优化过程生成高度自然的污染数据，将过度思考行为嵌入模型中。

Result: 在多个最先进模型和推理任务上的实验表明，BadThink能持续增加推理轨迹长度，在MATH-500数据集上实现超过17倍的增长，同时保持隐蔽性和鲁棒性。

Conclusion: 这项工作揭示了一个关键且先前未被探索的漏洞，即推理效率可能被隐蔽操纵，展示了对思维链系统的新型复杂攻击类别。

Abstract: Recent advances in Chain-of-Thought (CoT) prompting have substantially improved the reasoning capabilities of large language models (LLMs), but have also introduced their computational efficiency as a new attack surface. In this paper, we propose BadThink, the first backdoor attack designed to deliberately induce "overthinking" behavior in CoT-enabled LLMs while ensuring stealth. When activated by carefully crafted trigger prompts, BadThink manipulates the model to generate inflated reasoning traces - producing unnecessarily redundant thought processes while preserving the consistency of final outputs. This subtle attack vector creates a covert form of performance degradation that significantly increases computational costs and inference time while remaining difficult to detect through conventional output evaluation methods. We implement this attack through a sophisticated poisoning-based fine-tuning strategy, employing a novel LLM-based iterative optimization process to embed the behavior by generating highly naturalistic poisoned data. Our experiments on multiple state-of-the-art models and reasoning tasks show that BadThink consistently increases reasoning trace lengths - achieving an over 17x increase on the MATH-500 dataset - while remaining stealthy and robust. This work reveals a critical, previously unexplored vulnerability where reasoning efficiency can be covertly manipulated, demonstrating a new class of sophisticated attacks against CoT-enabled systems.

</details>


### [4] [PISanitizer: Preventing Prompt Injection to Long-Context LLMs via Prompt Sanitization](https://arxiv.org/abs/2511.10720)
*Runpeng Geng,Yanting Wang,Chenlong Yin,Minhao Cheng,Ying Chen,Jinyuan Jia*

Main category: cs.CR

TL;DR: PISanitizer是一种针对长上下文LLM的提示注入防御方法，通过识别和净化潜在注入的token来防止攻击，同时保持模型效用。


<details>
  <summary>Details</summary>
Motivation: 现有的提示注入防御方法主要针对短上下文设计，在长上下文场景下效果有限，因为注入指令只占长上下文的很小部分，防御难度大。

Method: 基于两个观察：1) 提示注入攻击本质是强制LLM遵循指令；2) LLM通过注意力机制关注关键输入token。PISanitizer首先让LLM遵循任意指令，然后净化驱动指令跟随行为的高注意力token。

Result: 广泛评估表明PISanitizer能成功防止提示注入、保持效用、优于现有防御方法、效率高，并对基于优化的和强自适应攻击具有鲁棒性。

Conclusion: PISanitizer为攻击者制造了一个困境：注入指令越有效，越容易被PISanitizer净化，从而提供了一种有效的长上下文提示注入防御方案。

Abstract: Long context LLMs are vulnerable to prompt injection, where an attacker can inject an instruction in a long context to induce an LLM to generate an attacker-desired output. Existing prompt injection defenses are designed for short contexts. When extended to long-context scenarios, they have limited effectiveness. The reason is that an injected instruction constitutes only a very small portion of a long context, making the defense very challenging. In this work, we propose PISanitizer, which first pinpoints and sanitizes potential injected tokens (if any) in a context before letting a backend LLM generate a response, thereby eliminating the influence of the injected instruction. To sanitize injected tokens, PISanitizer builds on two observations: (1) prompt injection attacks essentially craft an instruction that compels an LLM to follow it, and (2) LLMs intrinsically leverage the attention mechanism to focus on crucial input tokens for output generation. Guided by these two observations, we first intentionally let an LLM follow arbitrary instructions in a context and then sanitize tokens receiving high attention that drive the instruction-following behavior of the LLM. By design, PISanitizer presents a dilemma for an attacker: the more effectively an injected instruction compels an LLM to follow it, the more likely it is to be sanitized by PISanitizer. Our extensive evaluation shows that PISanitizer can successfully prevent prompt injection, maintain utility, outperform existing defenses, is efficient, and is robust to optimization-based and strong adaptive attacks. The code is available at https://github.com/sleeepeer/PISanitizer.

</details>


### [5] [AFLGopher: Accelerating Directed Fuzzing via Feasibility-Aware Guidance](https://arxiv.org/abs/2511.10828)
*Weiheng Bai,Kefu Wu,Qiushi Wu,Kangjie Lu*

Main category: cs.CR

TL;DR: AFLGopher是一种可行性感知的定向模糊测试工具，通过改进距离计算机制，显著提高了到达目标代码和触发已知漏洞的效率。


<details>
  <summary>Details</summary>
Motivation: 现有定向模糊测试工具的距离计算机制缺乏可行性感知，无法有效判断哪些路径实际可达目标，导致测试效率低下。

Method: 提出可行性感知的距离计算方法，包括基于有限轨迹预测所有分支可行性的分类方法，以及运行时逐步改进预测精度的更新机制。

Result: AFLGopher在到达目标速度上比现有工具快2.52-3.76倍，在触发已知漏洞上快4.52-5.60倍。

Conclusion: 可行性感知的定向模糊测试能显著提高测试效率，AFLGopher在多个基准测试中均优于现有最先进的定向模糊测试工具。

Abstract: Directed fuzzing is a useful testing technique that aims to efficiently reach target code sites in a program. The core of directed fuzzing is the guiding mechanism that directs the fuzzing to the specified target. A general guiding mechanism adopted in existing directed fuzzers is to calculate the control-flow distance between the current progress and the target, and use that as feedback to guide the directed fuzzing. A fundamental problem with the existing guiding mechanism is that the distance calculation is \emph{feasibility-unaware}.
  In this work, we propose feasibility-aware directed fuzzing named AFLGopher. Our new feasibility-aware distance calculation provides pragmatic feedback to guide directed fuzzing to reach targets efficiently. We propose new techniques to address the challenges of feasibility prediction. Our new classification method allows us to predict the feasibility of all branches based on limited traces, and our runtime feasibility-updating mechanism gradually and efficiently improves the prediction precision. We implemented AFLGopher and compared AFLGopher with state-of-the-art directed fuzzers including AFLGo, enhanced AFLGo, WindRanger, BEACON and SelectFuzz. AFLGopher is 3.76x, 2.57x, 3.30x, 2.52x and 2.86x faster than AFLGo, BEACON, WindRanger, SelectFuzz and enhanced AFLGo, respectively, in reaching targets. AFLGopher is 5.60x, 5.20x, 4.98x, 4.52x, and 5.07x faster than AFLGo, BEACON, WindRanger, SelectFuzz and enhanced AFLGo, respectively, in triggering known vulnerabilities.

</details>


### [6] [Armadillo: Robust Single-Server Secure Aggregation for Federated Learning with Input Validation](https://arxiv.org/abs/2511.10863)
*Yiping Ma,Yue Guo,Harish Karthikeyan,Antigoni Polychroniadou*

Main category: cs.CR

TL;DR: Armadillo是一个具有抗破坏性的安全聚合系统，能够抵御恶意客户端的攻击，确保聚合结果只受客户端在预定义合法范围内误报私有输入的影响。


<details>
  <summary>Details</summary>
Motivation: 现有的联邦学习安全聚合方案要么每个客户端成本高，要么需要多轮通信。Armadillo旨在实现高效的抗破坏性安全聚合，同时保持低计算开销和少轮数。

Method: 采用两层安全聚合协议，仅需简单算术计算；设计协议移除恶意客户端对聚合的影响，保持低轮复杂度；结合零知识证明技术。

Result: Armadillo每轮安全聚合仅需3轮通信，服务器和客户端计算负载轻量，在保持安全性的同时显著提升了效率。

Conclusion: Armadillo通过创新的两层聚合协议和恶意客户端移除机制，实现了高效、抗破坏的安全聚合，为联邦学习提供了实用的安全解决方案。

Abstract: This paper presents a secure aggregation system Armadillo that has disruptive resistance against adversarial clients, such that any coalition of malicious clients (within the tolerated threshold) can affect the aggregation result only by misreporting their private inputs in a pre-defined legitimate range. Armadillo is designed for federated learning setting, where a single powerful server interacts with many weak clients iteratively to train models on client's private data. While a few prior works consider disruption resistance under such setting, they either incur high per-client cost (Chowdhury et al. CCS '22) or require many rounds (Bell et al. USENIX Security '23). Although disruption resistance can be achieved generically with zero-knowledge proof techniques (which we also use in this paper), we realize an efficient system with two new designs: 1) a simple two-layer secure aggregation protocol that requires only simple arithmetic computation; 2) an agreement protocol that removes the effect of malicious clients from the aggregation with low round complexity. With these techniques, Armadillo completes each secure aggregation in 3 rounds while keeping the server and clients computationally lightweight.

</details>


### [7] [On the Information-Theoretic Fragility of Robust Watermarking under Diffusion Editing](https://arxiv.org/abs/2511.10933)
*Yunyi Ni,Ziyu Yang,Ze Niu,Emily Davis,Finn Carter*

Main category: cs.CR

TL;DR: 本文研究了扩散模型图像编辑对鲁棒水印的威胁，证明扩散变换会破坏水印信息，并提出针对性攻击算法，在保持图像质量的同时几乎完全移除水印。


<details>
  <summary>Details</summary>
Motivation: 随着基于扩散模型的图像生成和编辑技术的兴起，传统的鲁棒水印方案面临新的安全威胁，需要研究扩散编辑如何影响水印的生存能力。

Method: 通过理论分析和实验验证，证明扩散变换会降低水印图像与嵌入载荷的互信息；提出引导扩散攻击算法，在生成过程中明确针对并擦除水印信号。

Result: 在最新的深度学习水印方案上评估，攻击后水印恢复率接近零，同时再生图像保持高视觉保真度。

Conclusion: 讨论了此类水印移除能力的伦理影响，并为未来水印策略在生成AI时代提供更具韧性的设计指南。

Abstract: Robust invisible watermarking embeds hidden information in images such that the watermark can survive various manipulations. However, the emergence of powerful diffusion-based image generation and editing techniques poses a new threat to these watermarking schemes. In this paper, we investigate the intersection of diffusion-based image editing and robust image watermarking. We analyze how diffusion-driven image edits can significantly degrade or even fully remove embedded watermarks from state-of-the-art robust watermarking systems. Both theoretical formulations and empirical experiments are provided. We prove that as a image undergoes iterative diffusion transformations, the mutual information between the watermarked image and the embedded payload approaches zero, causing watermark decoding to fail. We further propose a guided diffusion attack algorithm that explicitly targets and erases watermark signals during generation. We evaluate our approach on recent deep learning-based watermarking schemes and demonstrate near-zero watermark recovery rates after attack, while maintaining high visual fidelity of the regenerated images. Finally, we discuss ethical implications of such watermark removal capablities and provide design guidelines for future watermarking strategies to be more resilient in the era of generative AI.

</details>


### [8] [Gynopticon: Consensus-Based Cheating Detection System for Competitive Games](https://arxiv.org/abs/2511.10992)
*Jeuk Kang,Jungheum Park*

Main category: cs.CR

TL;DR: GYNOPTICON是一个基于用户共识的作弊检测框架，通过客户端轻量级检测和服务器端投票系统来识别游戏作弊行为，为竞争性在线游戏提供隐私保护的解决方案。


<details>
  <summary>Details</summary>
Motivation: 现有研究主要关注MMORPG游戏，而竞争性游戏类型（如MOBA、FPS、RTS）由于检测难度大且需要复杂数据和技术而研究不足。传统的内核级反作弊方案虽然有效但存在用户隐私和系统安全问题。

Method: 提出GYNOPTICON框架，集成了客户端轻量级检测机制和服务器端投票系统：当检测到可疑活动时，客户端向服务器投票，服务器聚合投票建立共识来区分作弊者和合法玩家。

Result: 在受控模拟和真实FPS环境中进行评估，模拟结果验证了其可行性和要求，真实实验证实了其可靠检测作弊用户的有效性。使用公共数据集展示了系统的长期适用性和可持续性。

Conclusion: GYNOPTICON代表了一种用户驱动、基于共识的传统反作弊系统替代方案，为竞争性在线游戏提供了实用且保护隐私的解决方案。

Abstract: Cheating in online games poses significant threats to the gaming industry, yet most prior research has concentrated on Massively Multiplayer Online Role-Playing Games (MMORPGs). Competitive genres-such as Multiplayer Online Battle Arena (MOBA), First Person Shooter (FPS), Real Time Strategy (RTS), and Action games-remain underexplored due to the difficulty of detecting cheating users and the demand for complex data and techniques. To address this gap, many game companies rely on kernel-level anti-cheat solutions, which, while effective, raise serious concerns regarding user privacy and system security. In this paper, we propose GYNOPTICON, a novel cheating detection framework that leverages user consensus to identify abnormal behavior. GYNOPTICON integrates a lightweight client-side detection mechanism with a server-side voting system: when suspicious activity is identified, clients cast votes to the server, which aggregates them to establish consensus and distinguish cheaters from legitimate players. This architecture enables transparency, reduces reliance on intrusive monitoring, and mitigates privacy risks. We evaluate GYNOPTICON in both a controlled simulation and a real-world FPS environment. Simulation results verify its feasibility and requirements, while real-world experiments confirm its effectiveness in reliably detecting cheating users. Furthermore, we demonstrate the system's applicability and sustainability for long-term game management using public datasets. GYNOPTICON represents a user-driven, consensus-based alternative to conventional anti-cheat systems, offering a practical and privacy-preserving solution for competitive online games.

</details>


### [9] [PATCHEVAL: A New Benchmark for Evaluating LLMs on Patching Real-World Vulnerabilities](https://arxiv.org/abs/2511.11019)
*Zichao Wei,Jun Zeng,Ming Wen,Zeliang Yu,Kai Cheng,Yiding Zhu,Jingyi Guo,Shiqi Zhou,Le Yin,Xiaodong Su,Zhechao Ma*

Main category: cs.CR

TL;DR: PATCHEVAL是一个多语言漏洞修复基准测试，涵盖Go、JavaScript和Python语言，包含1000个CVE漏洞，其中230个配备运行时沙箱环境，用于系统评估LLM在自动漏洞修复中的能力。


<details>
  <summary>Details</summary>
Motivation: 现有漏洞修复基准存在漏洞过时、语言覆盖有限、补丁验证不可靠和可复现性不足等问题，需要构建更全面的基准来评估LLM在自动漏洞修复中的能力。

Method: 构建PATCHEVAL基准，从2015-2025年的CVE中收集1000个漏洞，覆盖65种CWE类型，为230个CVE配备运行时沙箱环境进行安全测试和功能测试，系统评估多种最先进的LLM和代理。

Result: 通过PATCHEVAL基准对LLM进行系统评估，获得了关于LLM在自动漏洞修复中能力的关键见解。

Conclusion: PATCHEVAL为未来自动漏洞修复研究提供了可靠的评估基准和指导性见解。

Abstract: Software vulnerabilities are increasing at an alarming rate. However, manual patching is both time-consuming and resource-intensive, while existing automated vulnerability repair (AVR) techniques remain limited in effectiveness. Recent advances in large language models (LLMs) have opened a new paradigm for AVR, demonstrating remarkable progress. To examine the capability of LLMs in AVR, several vulnerability benchmarks have been proposed recently. However, they still suffer from key limitations of outdated vulnerabilities, limited language coverage, unreliable patch validation, and insufficient reproducibility. To overcome these challenges, we introduce PATCHEVAL, a multilingual benchmark for Go, JavaScript, and Python, languages for which existing benchmarks remain unexplored. PATCHEVAL curates a dataset of 1,000 vulnerabilities drawn from CVEs reported between 2015 and 2025, covering 65 distinct CWEs. A subset of 230 CVEs is further equipped with runtime sandbox environments, enabling patch verification through both security tests and functionality tests. To provide a systematic comparison of LLM-based vulnerability repair, we evaluate a series of state-of-the-art LLMs and agents, presenting an in-depth analysis that empirically yields key insights to guide future research in AVR.

</details>


### [10] [Data Poisoning Vulnerabilities Across Healthcare AI Architectures: A Security Threat Analysis](https://arxiv.org/abs/2511.11020)
*Farhad Abtahi,Fernando Seoane,Iván Pau,Mario Vega-Barbas*

Main category: cs.CR

TL;DR: 医疗AI系统面临严重的数据投毒漏洞，攻击者仅需100-500个样本即可成功攻击，成功率超过60%，检测时间长达6-12个月甚至无法检测。


<details>
  <summary>Details</summary>
Motivation: 当前防御措施和法规无法充分应对医疗AI系统的数据投毒攻击，分布式医疗基础设施和隐私法规无意中为攻击者提供了保护。

Method: 分析了四类攻击场景：架构攻击（CNN、LLM、RL）、基础设施攻击（联邦学习、医疗文档系统）、关键资源分配攻击（器官移植、危机分诊）和供应链攻击（基础模型）。

Result: 攻击者可通过常规访问权限发动攻击，无需高技术技能；供应链漏洞使单一受感染供应商可污染50-200个机构的模型；隐私法规限制检测所需的分析。

Conclusion: 建议采用多层防御措施，包括强制性对抗测试、基于集成的检测、隐私保护安全机制和国际AI安全标准协调，并质疑黑盒模型是否适合高风险临床决策。

Abstract: Healthcare AI systems face major vulnerabilities to data poisoning that current defenses and regulations cannot adequately address. We analyzed eight attack scenarios in four categories: architectural attacks on convolutional neural networks, large language models, and reinforcement learning agents; infrastructure attacks exploiting federated learning and medical documentation systems; critical resource allocation attacks affecting organ transplantation and crisis triage; and supply chain attacks targeting commercial foundation models. Our findings indicate that attackers with access to only 100-500 samples can compromise healthcare AI regardless of dataset size, often achieving over 60 percent success, with detection taking an estimated 6 to 12 months or sometimes not occurring at all. The distributed nature of healthcare infrastructure creates many entry points where insiders with routine access can launch attacks with limited technical skill. Privacy laws such as HIPAA and GDPR can unintentionally shield attackers by restricting the analyses needed for detection. Supply chain weaknesses allow a single compromised vendor to poison models across 50 to 200 institutions. The Medical Scribe Sybil scenario shows how coordinated fake patient visits can poison data through legitimate clinical workflows without requiring a system breach. Current regulations lack mandatory adversarial robustness testing, and federated learning can worsen risks by obscuring attribution. We recommend multilayer defenses including required adversarial testing, ensemble-based detection, privacy-preserving security mechanisms, and international coordination on AI security standards. We also question whether opaque black-box models are suitable for high-stakes clinical decisions, suggesting a shift toward interpretable systems with verifiable safety guarantees.

</details>


### [11] [SALT-V: Lightweight Authentication for 5G V2X Broadcasting](https://arxiv.org/abs/2511.11028)
*Liu Cao,Weizheng Wang,Qipeng Xie,Dongyu Wei,Lyutianyang Zhang*

Main category: cs.CR

TL;DR: SALT-V是一个混合认证框架，通过协议分层解决V2X认证的延迟与效率矛盾，使用ECDSA认证10%流量建立信任，90%消息使用轻量GMAC操作，实现0.035ms平均计算时间和1ms端到端延迟。


<details>
  <summary>Details</summary>
Motivation: 解决V2X通信中传统公钥方案验证延迟过高（2ms）与对称方案密钥披露延迟过长（20-100ms）的矛盾，满足5G NR-V2X对即时认证和计算效率的严格要求。

Method: 采用混合认证框架：ECDSA签名认证10%的BOOT帧建立发送者信任，利用信任锚点通过轻量GMAC认证90%的DATA帧；核心创新是临时会话标签白名单机制和Bloom过滤器集成，实现95%消息即时验证和1us的O(1)撤销检查。

Result: 平均计算时间0.035ms（比纯ECDSA快57倍），端到端延迟1ms，开销41字节，可线性扩展到2000辆车，满足所有安全关键实时V2X部署要求。

Conclusion: SALT-V是首个实用解决方案，成功调和了V2X认证中的基本权衡，满足实时V2X部署的所有安全关键要求。

Abstract: Vehicle-to-Everything (V2X) communication faces a critical authentication dilemma: traditional public-key schemes like ECDSA provide strong security but impose 2 ms verification delays unsuitable for collision avoidance, while symmetric approaches like TESLA achieve microsecond-level efficiency at the cost of 20-100 ms key disclosure latency. Neither meets 5G New Radio (NR)-V2X's stringent requirements for both immediate authentication and computational efficiency. This paper presents SALT-V, a novel hybrid authentication framework that reconciles this fundamental trade-off through intelligent protocol stratification. SALT-V employs ECDSA signatures for 10% of traffic (BOOT frames) to establish sender trust, then leverages this trust anchor to authenticate 90% of messages (DATA frames) using lightweight GMAC operations. The core innovation - an Ephemeral Session Tag (EST) whitelist mechanism - enables 95% of messages to achieve immediate verification without waiting for key disclosure, while Bloom filter integration provides O(1) revocation checking in 1 us. Comprehensive evaluation demonstrates that SALT-V achieves 0.035 ms average computation time (57x faster than pure ECDSA), 1 ms end-to-end latency, 41-byte overhead, and linear scalability to 2000 vehicles, making it the first practical solution to satisfy all safety-critical requirements for real-time V2X deployment.

</details>


### [12] [Finding Software Supply Chain Attack Paths with Logical Attack Graphs](https://arxiv.org/abs/2511.11171)
*Luıs Soeiro,Thomas Robert,Stefano Zacchiroli*

Main category: cs.CR

TL;DR: 扩展MulVal工具以支持软件供应链威胁传播分析，解决其在现代软件供应链攻击中的局限性


<details>
  <summary>Details</summary>
Motivation: 网络攻击日益频繁和复杂，经常利用软件供应链作为攻击向量。MulVal作为广泛使用的开源攻击图生成工具，目前缺乏对软件供应链威胁传播的支持，无法应对现代软件供应链攻击

Method: 提出MulVal的扩展，在现有MulVal语法中引入新的谓词集，集成软件供应链威胁传播分析与现有基于网络的威胁分析。新的事实和交互规则建模软件供应链资产、依赖关系、交互、妥协、额外安全机制、初始系统状态和已知威胁

Result: 实现了软件供应链威胁传播与网络威胁分析的双向集成，展示了扩展的实际应用

Conclusion: 该扩展使MulVal能够有效应对现代软件供应链攻击，填补了现有工具在软件供应链安全分析方面的空白

Abstract: Cyberattacks are becoming increasingly frequent and sophisticated, often exploiting the software supply chain (SSC) as an attack vector. Attack graphs provide a detailed representation of the sequence of events and vulnerabilities that could lead to a successful security breach in a system. MulVal is a widely used open-source tool for logical attack graph generation in networked systems. However, its current lack of support for capturing and reasoning about SSC threat propagation makes it unsuitable for addressing modern SSC attacks, such as the XZ compromise or the 3CX double SSC attack. To address this limitation, we propose an extension to MulVal that integrates SSC threat propagation analysis with existing network-based threat analysis. This extension introduces a new set of predicates within the familiar MulVal syntax, enabling seamless integration. The new facts and interaction rules model SSC assets, their dependencies, interactions, compromises, additional security mechanisms, initial system states, and known threats. We explain how this integration operates in both directions and demonstrate the practical application of the extension.

</details>


### [13] [Bridging Local and Federated Data Normalization in Federated Learning: A Privacy-Preserving Approach](https://arxiv.org/abs/2511.11249)
*Melih Coşğun,Mert Gençtürk,Sinem Sav*

Main category: cs.CR

TL;DR: 本文提出了联邦归一化方法，通过安全交换归一化参数来模拟集中式归一化的效果，同时保护数据隐私。


<details>
  <summary>Details</summary>
Motivation: 联邦学习中数据分布在多个参与方，传统本地归一化在非IID数据下效果差，而集中式归一化违背联邦学习的去中心化原则。

Method: 提出联邦归一化方法，使用同态加密计算k阶元素和中位数，实现安全高效的归一化参数交换。

Result: 联邦归一化能达到与集中式归一化相当的性能，同时不损害数据本地性。

Conclusion: 联邦归一化是联邦学习中有效的预处理方法，通过隐私保护技术解决了归一化参数共享的安全问题。

Abstract: Data normalization is a crucial preprocessing step for enhancing model performance and training stability. In federated learning (FL), where data remains distributed across multiple parties during collaborative model training, normalization presents unique challenges due to the decentralized and often heterogeneous nature of the data. Traditional methods rely on either independent client-side processing, i.e., local normalization, or normalizing the entire dataset before distributing it to parties, i.e., pooled normalization. Local normalization can be problematic when data distributions across parties are non-IID, while the pooled normalization approach conflicts with the decentralized nature of FL. In this paper, we explore the adaptation of widely used normalization techniques to FL and define the term federated normalization. Federated normalization simulates pooled normalization by enabling the collaborative exchange of normalization parameters among parties. Thus, it achieves performance on par with pooled normalization without compromising data locality. However, sharing normalization parameters such as the mean introduces potential privacy risks, which we further mitigate through a robust privacy-preserving solution. Our contributions include: (i) We systematically evaluate the impact of various federated and local normalization techniques in heterogeneous FL scenarios, (ii) We propose a novel homomorphically encrypted $k$-th ranked element (and median) calculation tailored for the federated setting, enabling secure and efficient federated normalization, (iii) We propose privacy-preserving implementations of widely used normalization techniques for FL, leveraging multiparty fully homomorphic encryption (MHE).

</details>


### [14] [Prompt Engineering vs. Fine-Tuning for LLM-Based Vulnerability Detection in Solana and Algorand Smart Contracts](https://arxiv.org/abs/2511.11250)
*Biagio Boi,Christian Esposito*

Main category: cs.CR

TL;DR: 本文研究大型语言模型在非EVM区块链平台（Solana和Algorand）上检测智能合约OWASP漏洞的能力，通过构建合成数据集并比较提示工程、微调和混合方法的性能。


<details>
  <summary>Details</summary>
Motivation: 智能合约在去中心化环境中日益重要，但代码设计不当会带来安全风险。现有研究主要关注EVM生态系统，缺乏对非EVM平台（如Solana和Algorand）漏洞检测的研究。

Method: 构建基于OWASP漏洞分类法的合成数据集（Rust用于Solana，PyTeal用于Algorand），评估LLMs在三种配置下的性能：提示工程、微调和混合方法。

Result: 提示工程具有通用鲁棒性，微调在语义丰富度较低的语言（如TEAL）上提高了精确率和召回率。平台架构差异影响漏洞表现和可检测性。

Conclusion: 基于LLM的方法在智能合约静态漏洞检测中可行，但需要将领域特定数据和分类整合到训练流程中。

Abstract: Smart contracts have emerged as key components within decentralized environments, enabling the automation of transactions through self-executing programs. While these innovations offer significant advantages, they also present potential drawbacks if the smart contract code is not carefully designed and implemented. This paper investigates the capability of large language models (LLMs) to detect OWASP-inspired vulnerabilities in smart contracts beyond the Ethereum Virtual Machine (EVM) ecosystem, focusing specifically on Solana and Algorand. Given the lack of labeled datasets for non-EVM platforms, we design a synthetic dataset of annotated smart contract snippets in Rust (for Solana) and PyTeal (for Algorand), structured around a vulnerability taxonomy derived from OWASP. We evaluate LLMs under three configurations: prompt engineering, fine-tuning, and a hybrid of both, comparing their performance on different vulnerability categories. Experimental results show that prompt engineering achieves general robustness, while fine-tuning improves precision and recall on less semantically rich languages such as TEAL. Additionally, we analyze how the architectural differences of Solana and Algorand influence the manifestation and detectability of vulnerabilities, offering platform-specific mappings that highlight limitations in existing security tooling. Our findings suggest that LLM-based approaches are viable for static vulnerability detection in smart contracts, provided domain-specific data and categorization are integrated into training pipelines.

</details>


### [15] [Privacy Challenges and Solutions in Retrieval-Augmented Generation-Enhanced LLMs for Healthcare Chatbots: A Review of Applications, Risks, and Future Directions](https://arxiv.org/abs/2511.11347)
*Shaowei Guan,Hin Chi Kwok,Ngai Fong Law,Gregor Stiglic,Vivian Hui*

Main category: cs.CR

TL;DR: 本文综述了检索增强生成(RAG)在医疗领域的应用现状，分析了敏感数据类型、隐私风险、保护机制及未来方向，揭示了临床验证不足、标准化评估框架缺失等关键问题。


<details>
  <summary>Details</summary>
Motivation: RAG技术正快速改变临床和生物医学工作流程，但受保护健康信息(PHI)暴露等隐私风险仍未得到一致缓解，需要系统分析隐私挑战并提供解决方案。

Method: 通过管道结构化框架分析23篇医疗RAG应用文章，涵盖数据存储、传输、检索和生成阶段，识别潜在故障模式及其在威胁模型和系统机制中的根本原因。

Result: 评估发现存在关键差距：临床验证不足、缺乏标准化评估框架和自动化评估工具。基于17篇隐私保护策略文章的分析，提出了可行的改进方向。

Conclusion: 为研究人员和从业者提供了理解医疗RAG隐私漏洞的结构化框架，并提供了开发既具有临床有效性又具备强大隐私保护系统的路线图。

Abstract: Retrieval-augmented generation (RAG) has rapidly emerged as a transformative approach for integrating large language models into clinical and biomedical workflows. However, privacy risks, such as protected health information (PHI) exposure, remain inconsistently mitigated. This review provides a thorough analysis of the current landscape of RAG applications in healthcare, including (i) sensitive data type across clinical scenarios, (ii) the associated privacy risks, (iii) current and emerging data-privacy protection mechanisms and (iv) future direction for patient data privacy protection. We synthesize 23 articles on RAG applications in healthcare and systematically analyze privacy challenges through a pipeline-structured framework encompassing data storage, transmission, retrieval and generation stages, delineating potential failure modes, their underlying causes in threat models and system mechanisms, and their practical implications. Building on this analysis, we critically review 17 articles on privacy-preserving strategies for RAG systems. Our evaluation reveals critical gaps, including insufficient clinical validation, absence of standardized evaluation frameworks, and lack of automated assessment tools. We propose actionable directions based on these limitations and conclude with a call to action. This review provides researchers and practitioners with a structured framework for understanding privacy vulnerabilities in healthcare RAG and offers a roadmap toward developing systems that achieve both clinical effectiveness and robust privacy preservation.

</details>


### [16] [SEAL: Subspace-Anchored Watermarks for LLM Ownership](https://arxiv.org/abs/2511.11356)
*Yanbo Dai,Zongjie Li,Zhenlan Ji,Shuai Wang*

Main category: cs.CR

TL;DR: SEAL是一个基于子空间锚定的水印框架，通过在模型潜在表示空间中嵌入多比特签名来保护LLM的知识产权，支持白盒和黑盒验证，具有高隐蔽性和鲁棒性。


<details>
  <summary>Details</summary>
Motivation: 现有IP保护方法存在局限性：模型指纹技术只能识别架构无法确认所有权，传统后门水印方法容易被微调或知识蒸馏等后处理操作移除。需要开发更有效的LLM知识产权保护机制。

Method: 利用模型编辑技术将选定锚点样本的隐藏表示与预定义的正交比特向量对齐，在保持模型原始预测的同时将水印嵌入到潜在表示子空间中。

Result: 在多个基准数据集和6个主流LLM上的实验表明，SEAL相比11种现有方法在有效性、保真度、效率和鲁棒性方面表现优越，即使在对手知晓水印机制和签名的情况下仍能保持强验证性能。

Conclusion: SEAL框架为LLM提供了功能无害且隐蔽的知识产权保护方案，通过子空间锚定方法实现了对后处理攻击的强鲁棒性。

Abstract: Large language models (LLMs) have achieved remarkable success across a wide range of natural language processing tasks, demonstrating human-level performance in text generation, reasoning, and question answering. However, training such models requires substantial computational resources, large curated datasets, and sophisticated alignment procedures. As a result, they constitute highly valuable intellectual property (IP) assets that warrant robust protection mechanisms. Existing IP protection approaches suffer from critical limitations. Model fingerprinting techniques can identify model architectures but fail to establish ownership of specific model instances. In contrast, traditional backdoor-based watermarking methods embed behavioral anomalies that can be easily removed through common post-processing operations such as fine-tuning or knowledge distillation.
  We propose SEAL, a subspace-anchored watermarking framework that embeds multi-bit signatures directly into the model's latent representational space, supporting both white-box and black-box verification scenarios. Our approach leverages model editing techniques to align the hidden representations of selected anchor samples with predefined orthogonal bit vectors. This alignment embeds the watermark while preserving the model's original factual predictions, rendering the watermark functionally harmless and stealthy. We conduct comprehensive experiments on multiple benchmark datasets and six prominent LLMs, comparing SEAL with 11 existing fingerprinting and watermarking methods to demonstrate its superior effectiveness, fidelity, efficiency, and robustness. Furthermore, we evaluate SEAL under potential knowledgeable attacks and show that it maintains strong verification performance even when adversaries possess knowledge of the watermarking mechanism and the embedded signatures.

</details>


### [17] [Grid-STIX: A STIX 2.1-Compliant Cyber-Physical Security Ontology for Power Grid](https://arxiv.org/abs/2511.11366)
*Benjamin Blakely,Daniel Karcz*

Main category: cs.CR

TL;DR: Grid-STIX是一个针对电力系统的网络安全框架，扩展了STIX 2.1标准，专门处理电网特有的资产、运营技术关系和网络物理相互依赖性。


<details>
  <summary>Details</summary>
Motivation: 现有的威胁情报标准如STIX 2.1和MITRE ATT&CK缺乏对电网特定资产、运营技术关系和网络物理相互依赖性的覆盖，而这些对电力系统安全至关重要。

Method: 采用模块化架构，涵盖物理资产、运营技术组件、网络物理关系和安全策略，支持分布式能源资源、高级计量基础设施和核能设施等现代电力系统。

Result: 实现了威胁建模能力，包括攻击模式系统表示、供应链风险和跨域影响分析，同时保持STIX 2.1兼容性。包含核保障和不扩散验证模块，支持零信任执行。

Conclusion: Grid-STIX作为开源框架，能够推进电力行业的协作网络安全研究，支持跨公用事业威胁情报共享、供应链风险评估和核设施网络安全等应用。

Abstract: Modern electrical power grids represent complex cyber-physical systems requiring specialized cybersecurity frameworks beyond traditional IT security models. Existing threat intelligence standards such as STIX 2.1 and MITRE ATT\&CK lack coverage for grid-specific assets, operational technology relationships, and cyber-physical interdependencies essential for power system security. We present Grid-STIX, a domain-specific extension of STIX 2.1 for electrical grid cybersecurity applications. Grid-STIX employs a modular architecture encompassing physical assets, operational technology components, cyber-physical relationships, and security policies that capture modern power systems including distributed energy resources, advanced metering infrastructure, and nuclear energy facilities. The framework provides threat modeling capabilities through systematic representation of attack patterns, supply chain risks, and cross-domain impact analysis while maintaining STIX 2.1 compliance. Grid-STIX includes modules for nuclear safeguards and non-proliferation verification, enabling cybersecurity modeling across conventional and nuclear energy sectors. The ontology supports Zero Trust enforcement through policy decision points and operational context integration. Our implementation includes validation pipelines, Python code generation, and visualizations. Use cases demonstrate applications including cross-utility threat intelligence sharing, supply chain risk assessment, and nuclear facility cybersecurity. Grid-STIX is available as an open-source framework to advance collaborative cybersecurity research across the electrical power sector.

</details>


### [18] [SoK: Security Evaluation of Wi-Fi CSI Biometrics: Attacks, Metrics, and Systemic Weaknesses](https://arxiv.org/abs/2511.11381)
*Gioliano de Oliveira Braga,Pedro Henrique dos Santos Rocha,Rafael Pimenta de Mattos Paixão,Giovani Hoff da Costa,Gustavo Cavalcanti Morais,Lourenço Alves Pereira Júnior*

Main category: cs.CR

TL;DR: 这篇论文系统分析了基于Wi-Fi信道状态信息(CSI)的生物识别认证的安全性问题，揭示了现有研究在评估方法和安全属性方面存在系统性不一致，并提出了统一评估框架来暴露隐藏的风险。


<details>
  <summary>Details</summary>
Motivation: Wi-Fi CSI作为生物识别模式虽然被多次提出并报告高准确率，但该领域缺乏对其安全属性、对抗弹性和方法一致性的统一理解，需要从安全角度进行系统化分析。

Method: 采用知识系统化(SoK)方法，分析现有工作在感知基础设施、信号表示、特征管道、学习模型和评估方法等方面的差异，构建统一评估框架，使用安全相关指标如每类EER、FCS和基尼系数进行实证分析。

Result: 研究发现存在系统性不一致：依赖聚合准确率指标、有限的FAR/FRR/EER报告、缺乏每用户风险分析、很少考虑威胁模型或对抗可行性。实证分析揭示了传统报告方法隐藏的风险集中问题。

Conclusion: 当前CSI生物识别的安全边界需要明确界定，论文为严格评估、可重复实验和未来研究方向提供了指导方针，为安全社区提供了对Wi-Fi CSI生物识别作为认证原语适用性的结构化评估。

Abstract: Wi-Fi Channel State Information (CSI) has been repeatedly proposed as a biometric modality, often with reports of high accuracy and operational feasibility. However, the field lacks a consolidated understanding of its security properties, adversarial resilience, and methodological consistency. This Systematization of Knowledge (SoK) examines CSI-based biometric authentication through a security perspective, analyzing how existing work differs across sensing infrastructure, signal representations, feature pipelines, learning models, and evaluation methodologies. Our synthesis reveals systemic inconsistencies: reliance on aggregate accuracy metrics, limited reporting of FAR/FRR/EER, absence of per-user risk analysis, and scarce consideration of threat models or adversarial feasibility. We construct a unified evaluation framework to empirically expose these issues and demonstrate how security-relevant metrics, such as per-class EER, FCS, and the Gini Coefficient, uncover risk concentration that remains hidden under traditional reporting practices. Our analysis highlights concrete attack surfaces and shows how methodological choices materially influence vulnerability profiles, which include replay, geometric mimicry, and environmental perturbation. Based on these findings, we articulate the security boundaries of current CSI biometrics and provide guidelines for rigorous evaluation, reproducible experimentation, and future research directions. This SoK offers the security community a structured, evidence-driven reassessment of Wi-Fi CSI biometrics and their suitability as an authentication primitive.

</details>


### [19] [Automated Side-Channel Analysis of Cryptographic Protocol Implementations](https://arxiv.org/abs/2511.11385)
*Faezeh Nasrabadi,Robert Künnemann,Hamed Nemati*

Main category: cs.CR

TL;DR: 通过逆向工程和二进制分析提取WhatsApp的正式模型，结合侧信道泄漏合约进行安全分析，发现隐私攻击和已知漏洞。


<details>
  <summary>Details</summary>
Motivation: 分析大型闭源应用WhatsApp的安全实现，识别功能漏洞和侧信道攻击风险，填补规范与实现之间的差距。

Method: 结合CryptoBap二进制分析和Ghidra逆向工程提取协议模型，扩展框架集成硬件泄漏合约，使用DeepSec协议验证器进行分析。

Result: 证明前向安全性，识别克隆攻击，发现WhatsApp实现与规范间的功能差距，确认电子护照BAC协议的非链接性攻击。

Conclusion: 提出的方法能够发现规范方法无法识别的关键漏洞，为闭源应用的侧信道安全分析提供了有效框架。

Abstract: We extract the first formal model of WhatsApp from its implementation by combining binary-level analysis (via CryptoBap) with reverse engineering (via Ghidra) to handle this large closed-source application. Using this model, we prove forward secrecy, identify a known clone-attack against post-compromise security and discover functional gaps between WhatsApp's implementation and its specification. We further introduce a methodology to analyze cryptographic protocol implementations for their resilience to side-channel attacks. This is achieved by extending the CryptoBap framework to integrate hardware leakage contracts into the protocol model, which we then pass to the state-of-the-art protocol prover, DeepSec. This enables a detailed security analysis against both functional bugs and microarchitectural side-channel attacks. Using this methodology, we identify a privacy attack in WhatsApp that allows a side-channel attacker to learn the victim's contacts and confirm a known unlinkability attack on the BAC protocol used in electronic passports.
  Key contributions include (1) the first formal model of WhatsApp, extracted from its binary, (2) a framework to integrate side-channel leakage contracts into protocol models for the first time, and (3) revealing critical vulnerabilities invisible to specification-based methods.

</details>


### [20] [Adaptive Intrusion Detection for Evolving RPL IoT Attacks Using Incremental Learning](https://arxiv.org/abs/2511.11464)
*Sumeyye Bas,Kiymet Kaya,Elif Ak,Sule Gunduz Oguducu*

Main category: cs.CR

TL;DR: 该论文研究在RPL物联网网络中应用增量学习进行入侵检测，评估了五种模型家族，证明增量学习能够有效应对新型攻击并减轻灾难性遗忘问题。


<details>
  <summary>Details</summary>
Motivation: RPL协议在资源受限的IoT系统中存在路由层攻击漏洞，传统防御方法无法有效应对新型或零日攻击，需要完全重新训练，这在动态IoT环境中不实用。

Method: 系统评估了五种模型家族（包括集成模型和深度学习模型），采用增量学习策略，结合攻击特定分析、遗忘行为和时间效率评估。

Result: 增量学习不仅能够恢复对新攻击类的检测性能，还能减轻对已学习威胁的灾难性遗忘，同时相比完全重新训练减少了训练时间。

Conclusion: 增量学习为RPL物联网网络提供了可扩展的途径，能够在不断演化的环境中维持弹性的入侵检测能力。

Abstract: The routing protocol for low-power and lossy networks (RPL) has become the de facto routing standard for resource-constrained IoT systems, but its lightweight design exposes critical vulnerabilities to a wide range of routing-layer attacks such as hello flood, decreased rank, and version number manipulation. Traditional countermeasures, including protocol-level modifications and machine learning classifiers, can achieve high accuracy against known threats, yet they fail when confronted with novel or zero-day attacks unless fully retrained, an approach that is impractical for dynamic IoT environments. In this paper, we investigate incremental learning as a practical and adaptive strategy for intrusion detection in RPL-based networks. We systematically evaluate five model families, including ensemble models and deep learning models. Our analysis highlights that incremental learning not only restores detection performance on new attack classes but also mitigates catastrophic forgetting of previously learned threats, all while reducing training time compared to full retraining. By combining five diverse models with attack-specific analysis, forgetting behavior, and time efficiency, this study provides systematic evidence that incremental learning offers a scalable pathway to maintain resilient intrusion detection in evolving RPL-based IoT networks.

</details>


### [21] [Incentive Attacks in BTC: Short-Term Revenue Changes and Long-Term Efficiencies](https://arxiv.org/abs/2511.11538)
*Mustafa Doger,Sennur Ulukus*

Main category: cs.CR

TL;DR: 比特币难度调整算法存在安全漏洞，研究表明自私挖矿在长期效率上优于间歇性挖矿策略，而算力调整攻击对小矿池构成即时威胁。


<details>
  <summary>Details</summary>
Motivation: 研究比特币难度调整算法中的激励机制漏洞，包括自私挖矿、区块扣留和币种跳跃等攻击策略的收益变化。

Method: 通过严格分析攻击者和诚实矿工的短期收益变化，引入新的效率指标（单位算力单位时间的收益/成本比）来研究长期影响。

Result: 自私挖矿在长期效率上表现更好；币种跳跃策略短期对诚实矿工同样有利；区块扣留攻击中外部诚实矿工获益更多；算力调整攻击没有利润滞后问题。

Conclusion: 比特币难度调整算法存在严重安全漏洞，自私挖矿是最高效的攻击策略，算力调整攻击对小矿池构成直接威胁，需要改进算法设计。

Abstract: Bitcoin's (BTC) Difficulty Adjustment Algorithm (DAA) has been a source of vulnerability for incentive attacks such as selfish mining, block withholding and coin hopping strategies. In this paper, first, we rigorously study the short-term revenue change per hashpower of the adversarial and honest miners for these incentive attacks. To study the long-term effects, we introduce a new efficiency metric defined as the revenue/cost per hashpower per time for the attacker and the honest miners.
  Our results indicate that the short-term benefits of intermittent mining strategies are negligible compared to the original selfish mining attack, and in the long-term, selfish mining provides better efficiency. We further demonstrate that a coin hopping strategy between BTC and Bitcoin Cash (BCH) relying on BTC DAA benefits the loyal honest miners of BTC in the same way and to the same extent per unit of computational power as it does the hopper in the short-term. For the long-term, we establish a new boundary between the selfish mining and coin hopping attack, identifying the optimal efficient strategy for each parameter.
  For block withholding strategies, it turns out, the honest miners outside the pool profit from the attack, usually even more than the attacker both in the short-term and the long-term. Moreover, a power adjusting withholding attacker does not necessarily observe a profit lag in the short-term. It has been long thought that the profit lag of selfish mining is among the main reasons why such an attack has not been observed in practice. We show that such a barrier does not apply to power adjusting attacks and relatively small pools are at an immediate threat.

</details>


### [22] [HetDAPAC: Leveraging Attribute Heterogeneity in Distributed Attribute-Based Private Access Control](https://arxiv.org/abs/2511.11549)
*Shreya Meel,Sennur Ulukus*

Main category: cs.CR

TL;DR: 本文提出了HetDAPAC框架，通过将非敏感属性验证集中化处理，在保护敏感属性的同时提高了系统速率，从1/2K提升到1/(K+1)，并提出了平衡服务器下载负载的改进方案。


<details>
  <summary>Details</summary>
Motivation: 现有的分布式属性访问控制(DAPAC)系统对所有属性采用相同的隐私保护级别，但并非所有属性都是敏感的，这种统一的隐私约束限制了系统性能。需要一种能够区分敏感和非敏感属性的混合架构。

Method: 提出HetDAPAC框架，将N个属性中的N-D个非敏感属性验证集中到一个中央服务器处理，仅对D个敏感属性保持DAPAC的分布式验证架构。设计了两种方案：一种提高速率但下载不均衡，另一种实现服务器下载平衡。

Result: 第一个方案将速率从1/2K提升到1/(K+1)，第二个方案在保持服务器下载平衡的同时达到(D+1)/(2KD)的速率。

Conclusion: HetDAPAC框架通过属性隐私需求异质性，在保护敏感属性的同时显著提升了系统性能，为实际应用提供了更灵活的隐私-性能权衡方案。

Abstract: Verifying user attributes to provide fine-grained access control to databases is fundamental to attribute-based authentication. Either a single (central) authority verifies all the attributes, or multiple independent authorities verify the attributes distributedly. In the central setup, the authority verifies all user attributes, and the user downloads only the authorized record. While this is communication efficient, it reveals all user attributes to the authority. A distributed setup prevents this privacy breach by letting each authority verify and learn only one attribute. Motivated by this, Jafarpisheh~et~al. introduced an information-theoretic formulation, called distributed attribute-based private access control (DAPAC). With $N$ non-colluding authorities (servers), $N$ attributes and $K$ possible values for each attribute, the DAPAC system lets each server learn only the single attribute value that it verifies, and is oblivious to the remaining $N-1$. The user retrieves its designated record, without learning anything about the remaining database records. The goal is to maximize the rate, i.e., the ratio of desired message size to total download size. However, not all attributes are sensitive, and DAPAC's privacy constraints can be too restrictive, negatively affecting the rate. To leverage the heterogeneous privacy requirements of user attributes, we propose heterogeneous (Het)DAPAC, a framework which off-loads verification of $N-D$ of the $N$ attributes to a central server, and retains DAPAC's architecture for the $D$ sensitive attributes. We first present a HetDAPAC scheme, which improves the rate from $\frac{1}{2K}$ to $\frac{1}{K+1}$, while sacrificing the privacy of a few non-sensitive attributes. Unlike DAPAC, our scheme entails a download imbalance across servers; we propose a second scheme achieving a balanced per-server download and a rate of $\frac{D+1}{2KD}$.

</details>


### [23] [Private Frequency Estimation Via Residue Number Systems](https://arxiv.org/abs/2511.11569)
*Héber H. Arcolezi*

Main category: cs.CR

TL;DR: MSS是一种新的本地差分隐私频率估计算法，通过残数系统编码和子集选择扰动，在保持与最优方法相近精度的同时，显著降低了用户通信成本和提高了解码速度。


<details>
  <summary>Details</summary>
Motivation: 现有本地差分隐私频率估计算法如SS和PGR存在通信成本高或解码复杂的问题，需要一种既能保持精度又能降低通信和计算开销的新方法。

Method: 使用残数系统(RNS)在ℓ个互质模数上编码输入，随机选择一个索引并报告扰动后的残数，采用最优子集选择进行扰动。

Result: MSS在保持与SS、PGR和RAPPOR相近估计精度的同时，用户通信成本从Θ(ωlog₂(k/ω))位降至⌈log₂ℓ⌉+⌈log₂m_j⌉位，解码时间在良好条件下为Θ(n+k log k)。

Conclusion: MSS在精度、通信效率和计算效率之间取得了良好平衡，是所有评估LDP协议中重建攻击成功率最低的方法。

Abstract: We present \textsf{ModularSubsetSelection} (MSS), a new algorithm for locally differentially private (LDP) frequency estimation. Given a universe of size $k$ and $n$ users, our $\varepsilon$-LDP mechanism encodes each input via a Residue Number System (RNS) over $\ell$ pairwise-coprime moduli $m_0, \ldots, m_{\ell-1}$, and reports a randomly chosen index $j \in [\ell]$ along with the perturbed residue using the statistically optimal \textsf{SubsetSelection}~(SS) (Wang et al. 2016). This design reduces the user communication cost from $Θ\bigl(ω\log_2(k/ω)\bigr)$ bits required by standard SS (with $ω\approx k/(e^\varepsilon+1)$) down to $\lceil \log_2 \ell \rceil + \lceil \log_2 m_j \rceil$ bits, where $m_j < k$. Server-side decoding runs in $Θ(n + r k \ell)$ time, where $r$ is the number of LSMR (Fong and Saunders 2011) iterations. In practice, with well-conditioned moduli (\textit{i.e.}, constant $r$ and $\ell = Θ(\log k)$), this becomes $Θ(n + k \log k)$. We prove that MSS achieves worst-case MSE within a constant factor of state-of-the-art protocols such as SS and \textsf{ProjectiveGeometryResponse} (PGR) (Feldman et al. 2022), while avoiding the algebraic prerequisites and dynamic-programming decoder required by PGR. Empirically, MSS matches the estimation accuracy of SS, PGR, and \textsf{RAPPOR} (Erlingsson, Pihur, and Korolova 2014) across realistic $(k, \varepsilon)$ settings, while offering faster decoding than PGR and shorter user messages than SS. Lastly, by sampling from multiple moduli and reporting only a single perturbed residue, MSS achieves the lowest reconstruction-attack success rate among all evaluated LDP protocols.

</details>
