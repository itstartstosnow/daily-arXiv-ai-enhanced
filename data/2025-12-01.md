<div id=toc></div>

# Table of Contents

- [cs.CR](#cs.CR) [Total: 34]


<div id='cs.CR'></div>

# cs.CR [[Back]](#toc)

### [1] [A Longitudinal Measurement of Privacy Policy Evolution for Large Language Models](https://arxiv.org/abs/2511.21758)
*Zhen Tao,Shidong Pan,Zhenchang Xing,Emily Black,Talia Gillis,Chunyang Chen*

Main category: cs.CR

TL;DR: 首次对主流LLM提供商隐私政策进行纵向实证研究，分析其特点、演变模式及与LLM生态事件的关联。


<details>
  <summary>Details</summary>
Motivation: LLM服务快速融入日常生活，但收集丰富数据流引发隐私担忧。虽然传统网络和移动隐私政策已有研究，但LLM提供商的隐私政策、其LLM特定内容及时序演变仍缺乏深入探索。

Method: 收集11个LLM提供商的74个历史隐私政策和115个补充文档，提取3000多个句子级编辑，比较不同软件格式政策，提出LLM隐私政策分类法，标注政策编辑并与LLM生态关键事件时间线对齐。

Result: LLM隐私政策显著更长，需要大学阅读水平，且高度模糊。分类分析揭示提供商披露LLM特定实践的模式及区域差异。政策编辑集中在第一方数据收集和国际/特定受众部分，产品发布和监管行动是主要驱动因素。

Conclusion: 研究揭示了LLM隐私政策的现状和演变，为理解LLM生态中的隐私实践提供了实证基础，并识别了政策演变的主要驱动因素。

Abstract: Large language model (LLM) services have been rapidly integrated into people's daily lives as chatbots and agentic systems. They are nourished by collecting rich streams of data, raising privacy concerns around excessive collection of sensitive personal information. Privacy policies are the fundamental mechanism for informing users about data practices in modern information privacy paradigm. Although traditional web and mobile policies are well studied, the privacy policies of LLM providers, their LLM-specific content, and their evolution over time remain largely underexplored. In this paper, we present the first longitudinal empirical study of privacy policies for mainstream LLM providers worldwide. We curate a chronological dataset of 74 historical privacy policies and 115 supplemental privacy documents from 11 LLM providers across 5 countries up to August 2025, and extract over 3,000 sentence-level edits between consecutive policy versions. We compare LLM privacy policies to those of other software formats, propose a taxonomy tailored to LLM privacy policies, annotate policy edits and align them with a timeline of key LLM ecosystem events. Results show they are substantially longer, demand college-level reading ability, and remain highly vague. Our taxonomy analysis reveals patterns in how providers disclose LLM-specific practices and highlights regional disparities in coverage. Policy edits are concentrated in first-party data collection and international/specific-audience sections, and that product releases and regulatory actions are the primary drivers, shedding light on the status quo and the evolution of LLM privacy policies.

</details>


### [2] [Adaptive Detection of Polymorphic Malware: Leveraging Mutation Engines and YARA Rules for Enhanced Security](https://arxiv.org/abs/2511.21764)
*Shreyansh Swami,Ishwardeep Singh,Ujjwalpreet Singh,Chinmay Prawah Pant*

Main category: cs.CR

TL;DR: 该研究提出了一个可复现的框架，分析8种多态恶意软件行为，评估商业杀毒软件、自定义规则检测器和EDR系统的检测性能，发现混合检测管道能提供92%的检测覆盖率。


<details>
  <summary>Details</summary>
Motivation: 多态恶意软件通过不断改变结构来规避基于签名的防御，对商业杀毒软件和企业检测系统构成挑战。需要系统评估不同检测层面对多态行为的检测能力。

Method: 研究引入可复现框架，分析8种多态行为（垃圾代码插入、控制流混淆、打包、数据编码、域名生成、随机信标定时、协议模仿、格式/头部调整）。使用受控变异引擎生成11个惰性多态变体，在隔离环境中执行。在三个层面评估检测性能：商业杀毒软件、自定义规则检测器（YARA/Sigma）、EDR遥测。

Result: 商业杀毒软件平均检测率34%，YARA/Sigma检测率74%，EDR检测率76%。集成检测达到约92%的检测覆盖率，误报率3.5%。静态多态行为最好由自定义规则检测，动态行为由EDR检测，网络层面由Sigma类分析检测。

Conclusion: 结合静态、动态和网络层分析的混合检测管道能够提供对多态恶意软件的弹性防御，为未来自适应检测研究奠定基线。

Abstract: Polymorphic malware continually alters its structure to evade signature-based defences, challenging both commercial antivirus (AV) and enterprise detection systems. This study introduces a reproducible framework for analysing eight polymorphic behaviours-junk code insertion, control-flow obfuscation, packing, data encoding, domain generation, randomized beacon timing, protocol mimicry, and format/header tweaks-and evaluates their detectability across three layers: commercial AVs, custom rule-based detectors (YARA/Sigma), and endpoint detection and response (EDR) telemetry. Eleven inert polymorphic variants were generated per behaviour using controlled mutation engines and executed in isolated environments. Detection performance was assessed by detection rate (DR), false positive rate (FPR), and combined coverage. AVs achieved an average DR of 34%, YARA/Sigma 74% and EDR 76%; integrated detection reached ~92% with an FPR of 3.5%. Iterative YARA tuning showed a trade-off between detection and FPR, while behaviour-specific trends revealed static polymorphisms were best caught by custom rules, dynamic by EDR, and network-level by Sigma-like analysis. These results affirm that hybrid detection pipelines combining static, dynamic, and network-layer analytics offer resilient defence against polymorphic malware and form a baseline for future adaptive detection research.

</details>


### [3] [Categorical Framework for Quantum-Resistant Zero-Trust AI Security](https://arxiv.org/abs/2511.21768)
*I. Cherkaoui,C. Clarke,J. Horgan,I. Dey*

Main category: cs.CR

TL;DR: 提出基于范畴论的PQC与零信任架构融合框架，通过ESP32实现验证，显著提升AI模型安全性和内存效率


<details>
  <summary>Details</summary>
Motivation: AI模型快速部署需要量子抗性安全防护，特别是对抗对抗性威胁。现有安全方案需要更强大的保护机制来应对量子计算威胁和AI对抗攻击。

Method: 将后量子密码学与零信任架构结合，基于范畴论形式化建模：将密码工作流建模为态射，信任策略建模为函子。采用格基PQC原语，实现细粒度自适应信任和微隔离。

Result: ESP32实现显示：代理使用91.86%、代理使用97.88%空闲堆内存；100%拒绝未授权访问，亚毫秒平均延迟；提供可量化的性能和安全性改进。

Conclusion: 基于范畴论的PQC-ZTA融合框架为AI模型访问提供了强大的量子抗性安全保护，通过形式化证明和实际实现验证了其有效性和实用性。

Abstract: The rapid deployment of AI models necessitates robust, quantum-resistant security, particularly against adversarial threats. Here, we present a novel integration of post-quantum cryptography (PQC) and zero trust architecture (ZTA), formally grounded in category theory, to secure AI model access. Our framework uniquely models cryptographic workflows as morphisms and trust policies as functors, enabling fine-grained, adaptive trust and micro-segmentation for lattice-based PQC primitives. This approach offers enhanced protection against adversarial AI threats. We demonstrate its efficacy through a concrete ESP32-based implementation, validating a crypto-agile transition with quantifiable performance and security improvements, underpinned by categorical proofs for AI security. The implementation achieves significant memory efficiency on ESP32, with the agent utilizing 91.86% and the broker 97.88% of free heap after cryptographic operations, and successfully rejects 100% of unauthorized access attempts with sub-millisecond average latency.

</details>


### [4] [Advanced Data Collection Techniques in Cloud Security: A Multi-Modal Deep Learning Autoencoder Approach](https://arxiv.org/abs/2511.21795)
*Aamiruddin Syed,Mohammed Ilyas Ahmad*

Main category: cs.CR

TL;DR: 提出多模态深度学习集成架构MMDLEA，通过集成六种深度学习模型实现云安全异常检测，准确率达98.5%


<details>
  <summary>Details</summary>
Motivation: 云安全是重要关注点，需要高效的数据收集方法来识别和阻止网络威胁。多模态数据源整合对提升安全检测效果至关重要。

Method: 提出多模态深度学习集成架构MMDLEA，集成六种深度学习模型：MMDLA、ADAM、ADADELTA、ADAGRAD、RMSPROP和SGT。每个模型使用不同数据模态训练，最后融合所有模型输出进行最终预测。

Result: MMDLEA在测试数据集上达到98.5%的准确率和0.985的F1分数，优于所有单个模型。其中ADAM模型表现最佳（96.2%准确率），ADADELTA次之（95.5%准确率）。架构对模态变化和噪声数据具有增强的鲁棒性。

Conclusion: 提出的MMDLEA框架在多模态数据异常检测和分类方面表现出色，在真实场景中具有实用价值，为未来研究提供了方向。

Abstract: Cloud security is an important concern. To identify and stop cyber threats, efficient data collection methods are necessary. This research presents an innovative method to cloud security by integrating numerous data sources and modalities with multi-modal deep learning autoencoders. The Multi-Modal Deep Learning Ensemble Architecture (MMDLEA), a unique approach for anomaly detection and classification in multi-modal data, is proposed in this study. The proposed design integrates the best features of six deep learning models: Multi-Modal Deep Learning Autoencoder (MMDLA), Anomaly Detection using Adaptive Metric Learning (ADAM), ADADELTA, ADAGRAD, RMSPROP, and Stacked Graph Transformer (SGT). A final prediction is produced by combining the outputs of all the models, each of which is trained using a distinct modality of the data. Based on the test dataset, the recommended MMDLA architecture achieves an accuracy of 98.5% and an F1-score of 0.985, demonstrating its superior performance over each individual model. Of the different models, the ADAM model performs the best, with an accuracy of 96.2% and an F1-score of 0.962. With an F1-score of 0.955 and an accuracy of 95.5%, the ADADELTA model trails closely behind. MMDLA obtains an F1-score of 0.948 and an accuracy of 94.8%. Additionally, the suggested MMDLEA design exhibits enhanced resilience to fluctuating modalities and noisy data, proving its usefulness in practical settings. Future study in this area is made possible by the results, which show the potential of the proposed framework for abnormal identification and categorization in multi-modal data.

</details>


### [5] [Cross-Layer Detection of Wireless Misbehavior Using 5G RAN Telemetry and Operational Metadata](https://arxiv.org/abs/2511.21803)
*Daniyal Ganiuly,Nurzhau Bolatbek,Assel Smaiyl*

Main category: cs.CR

TL;DR: 该研究提出通过分析5G独立组网中不同层（物理层、MAC层、配置元数据）之间的一致性关系来检测上行链路异常行为，无需修改协议或引入新信令。


<details>
  <summary>Details</summary>
Motivation: 5G独立组网部署中，用户设备可能在不违反标准控制面规程的情况下表现出上行链路异常行为（如发射功率膨胀、定时漂移、短时无授权突发）。这些操纵保持信令状态完整，但扭曲了gNB产生的遥测流之间的预期关系。需要一种无需引入新信令就能可靠识别此类异常行为的方法。

Method: 使用包含商用用户设备和软件定义无线电对抗设备的受控5G独立组网测试床，研究每种操纵如何影响物理层测量、MAC调度决策和配置元数据之间的一致性。分析合并的多层时间序列轨迹和跨域视图（如SNR到CQI平面）。

Result: 每种操纵都产生独特且可复现的特征：功率偏移削弱SNR与CQI之间的自然联系，定时漂移破坏调度器维护的对齐，无授权活动产生的上行能量与分配日志不一致。这些不一致性在多层时间序列轨迹和跨域视图中可见。

Conclusion: 跨层一致性为仅使用标准gNB遥测检测上行链路异常行为提供了实用信号，无需协议修改，适合集成到运营监控和审计系统中。

Abstract: 5G Standalone deployments can exhibit uplink misbehavior from user equipment that remains fully compliant with standard control plane procedures. Manipulations such as transmit power inflation, gradual timing drift, and short off grant bursts leave the signaling state intact but distort the expected relationships among the telemetry streams produced by the gNB. This work examines whether these cross layer relationships can serve as a reliable basis for identifying such misbehavior without introducing new signaling. Using a controlled 5G Standalone testbed with commercial user equipment and a software defined radio adversarial device, we study how each manipulation affects the coherence among physical layer measurements, MAC scheduling decisions, and configuration metadata. The results show that every manipulation produces a distinct and reproducible signature that is not visible from any single telemetry source. Power offsets weaken the natural connection between SNR and CQI, timing drift breaks the alignment maintained by the scheduler, and off grant activity produces uplink energy that does not agree with allocation logs. These inconsistencies appear in merged multi layer time series traces and in cross domain views such as the SNR to CQI plane. The findings indicate that cross layer coherence provides a practical signal for detecting uplink misbehavior using only standard gNB telemetry, with no protocol modifications required, which makes the method suitable for integration into operational monitoring and auditing systems.

</details>


### [6] [Beyond Membership: Limitations of Add/Remove Adjacency in Differential Privacy](https://arxiv.org/abs/2511.21804)
*Gauri Pradhan,Joonas Jälkö,Santiago Zanella-Bèguelin,Antti Honkela*

Main category: cs.CR

TL;DR: 论文指出在差分隐私中，add/remove邻接关系会高估属性隐私保护，而substitute邻接关系更适合保护记录属性而非成员身份。


<details>
  <summary>Details</summary>
Motivation: 当前大多数DP实现使用add/remove邻接关系来保护成员身份，但在许多ML应用中需要保护的是单个记录的属性（如监督微调中的标签）。add/remove邻接关系会高估属性隐私保护水平。

Method: 开发了新的攻击方法来审计substitute邻接关系下的DP，通过实验比较add/remove和substitute邻接关系下的隐私保证差异。

Result: 审计结果显示，add/remove邻接关系下的DP保证与substitute邻接关系下的审计结果不一致，但与substitute邻接关系下计算的隐私预算一致，证实了两种邻接关系在属性保护方面的差异。

Conclusion: 当保护目标是记录属性而非成员身份时，选择正确的邻接关系对于准确报告DP保证至关重要，substitute邻接关系更适合属性保护场景。

Abstract: Training machine learning models with differential privacy (DP) limits an adversary's ability to infer sensitive information about the training data. It can be interpreted as a bound on adversary's capability to distinguish two adjacent datasets according to chosen adjacency relation. In practice, most DP implementations use the add/remove adjacency relation, where two datasets are adjacent if one can be obtained from the other by adding or removing a single record, thereby protecting membership. In many ML applications, however, the goal is to protect attributes of individual records (e.g., labels used in supervised fine-tuning). We show that privacy accounting under add/remove overstates attribute privacy compared to accounting under the substitute adjacency relation, which permits substituting one record. To demonstrate this gap, we develop novel attacks to audit DP under substitute adjacency, and show empirically that audit results are inconsistent with DP guarantees reported under add/remove, yet remain consistent with the budget accounted under the substitute adjacency relation. Our results highlight that the choice of adjacency when reporting DP guarantees is critical when the protection target is per-record attributes rather than membership.

</details>


### [7] [Standardized Threat Taxonomy for AI Security, Governance, and Regulatory Compliance](https://arxiv.org/abs/2511.21901)
*Hernan Huwyler*

Main category: cs.CR

TL;DR: 本文提出AI系统威胁向量分类法，旨在弥合技术安全团队与法律合规专业人员之间的"语言障碍"，将技术漏洞转化为可量化的财务风险，支持定量风险评估。


<details>
  <summary>Details</summary>
Motivation: 人工智能系统在受监管领域的加速部署暴露了风险评估方法的碎片化问题。技术安全团队关注算法漏洞（如MITRE ATLAS），而法律合规专业人员处理监管要求（如欧盟AI法案、NIST AI RMF），两者之间存在"语言障碍"，导致技术漏洞无法准确转化为财务责任，使从业者难以回答关于应急储备、控制投资回报和保险风险等基本经济问题。

Method: 本研究提出了AI系统威胁向量分类法，这是一个专门为定量风险评估设计的结构化本体。该框架将AI特定风险分为九个关键领域：滥用、投毒、隐私、对抗性、偏见、不可靠输出、漂移、供应链和知识产权威胁，整合了53个操作性定义的子威胁。每个领域将技术向量直接映射到业务损失类别（机密性、完整性、可用性、法律、声誉），从而将抽象威胁转化为可衡量的财务影响。

Result: 该分类法通过对2025年133个已记录的AI事件分析进行实证验证（实现100%分类覆盖），并与主要AI风险框架进行协调。此外，它明确与ISO/IEC 42001控制和NIST AI RMF功能对齐，以促进可审计性。

Conclusion: AI系统威胁向量分类法成功弥合了技术安全与法律合规之间的鸿沟，为AI系统风险评估提供了统一的框架，使技术漏洞能够转化为可量化的财务风险，支持更有效的风险管理决策。

Abstract: The accelerating deployment of artificial intelligence systems across regulated sectors has exposed critical fragmentation in risk assessment methodologies. A significant "language barrier" currently separates technical security teams, who focus on algorithmic vulnerabilities (e.g., MITRE ATLAS), from legal and compliance professionals, who address regulatory mandates (e.g., EU AI Act, NIST AI RMF). This disciplinary disconnect prevents the accurate translation of technical vulnerabilities into financial liability, leaving practitioners unable to answer fundamental economic questions regarding contingency reserves, control return-on-investment, and insurance exposure. To bridge this gap, this research presents the AI System Threat Vector Taxonomy, a structured ontology designed explicitly for Quantitative Risk Assessment (QRA). The framework categorizes AI-specific risks into nine critical domains: Misuse, Poisoning, Privacy, Adversarial, Biases, Unreliable Outputs, Drift, Supply Chain, and IP Threat, integrating 53 operationally defined sub-threats. Uniquely, each domain maps technical vectors directly to business loss categories (Confidentiality, Integrity, Availability, Legal, Reputation), enabling the translation of abstract threats into measurable financial impact. The taxonomy is empirically validated through an analysis of 133 documented AI incidents from 2025 (achieving 100% classification coverage) and reconciled against the main AI risk frameworks. Furthermore, it is explicitly aligned with ISO/IEC 42001 controls and NIST AI RMF functions to facilitate auditability.

</details>


### [8] [GECKO: Securing Digital Assets Through(out) the Physical World (Extended Technical Report)](https://arxiv.org/abs/2511.21999)
*Cyrill Krähenbühl,Nico Hauser,Christelle Gloor,Juan Angel García-Pardo,Adrian Perrig*

Main category: cs.CR

TL;DR: GECKO是一个地理PKI系统，通过地理位置和空间占用提供数字资产的全局视图，实现物理世界与数字世界之间的双向信任转换。


<details>
  <summary>Details</summary>
Motivation: 当前数字资产无法安全地与物理空间关联，导致假冒品牌店铺、产权欺诈、移动支付诈骗等问题。虽然有合同关系和地籍记录等信息，但缺乏统一的方式来检索和验证这些文档。

Method: 提出地理启用的加密密钥预言机(GECKO)，这是一个地理PKI系统，基于地理位置和占用空间提供数字资产的全局视图。系统支持高效存储数百万资产，并能基于精确位置查询提供加密材料。

Result: 在单台服务器上，GECKO能够在11毫秒内响应精确位置查询，处理速率超过每秒19000次查询，证明了系统的可行性。

Conclusion: GECKO补充了现有PKI系统，在物理世界和数字世界之间提供双向信任转换，当需要其特性时可以与传统系统结合使用。

Abstract: Although our lives are increasingly transitioning into the digital world, many digital assets still relate to objects or places in the physical world, e.g., websites of stores or restaurants, digital documents claiming property ownership, or digital identifiers encoded in QR codes for mobile payments in shops. Currently, users cannot securely associate digital assets with their related physical space, leading to problems such as fake brand stores, property fraud, and mobile payment scams. In many cases, the necessary information to protect digital assets exists, e.g., via contractual relationships and cadaster entries, but there is currently no uniform way of retrieving and verifying these documents. In this work, we propose the Geo-Enabled Cryptographic Key Oracle (GECKO), a geographical PKI that provides a global view of digital assets based on their geo-location and occupied space. GECKO allows for the bidirectional translation of trust between the physical and digital world. Users can verify which assets are supposed to exist at their location, as well as verify which physical space is claimed by a digital entity. GECKO supplements current PKI systems and can be used in addition to current systems when its properties are of value. We show the feasibility of efficiently storing millions of assets and serving cryptographic material based on precise location queries within 11 ms at a rate of more than 19000 queries per second on a single server.

</details>


### [9] [POLARIS: Cross-Domain Access Control via Verifiable Identity and Policy-Based Authorization](https://arxiv.org/abs/2511.22017)
*Aiyao Zhang,Xiaodong Lee,Zhixian Zhuang,Jiuqi Wei,Yufan Fu,Botao Peng*

Main category: cs.CR

TL;DR: POLARIS是一个统一的、可扩展的跨域访问控制架构，通过结构化承诺机制和轻量级策略语言VPPL，实现基于策略的、可验证且保护隐私的跨域访问控制。


<details>
  <summary>Details</summary>
Motivation: 传统访问控制在集中式环境中将认证和授权分开处理，面临身份分散、隐私泄露和多样化权限需求等挑战，无法适应跨域场景。需要一种新的访问控制机制，让用户能够自主控制身份和资源，满足跨域场景中隐私保护认证和灵活授权的需求。

Method: 提出POLARIS统一架构，包含：1）结构化承诺机制，实现可靠、细粒度、基于策略的身份披露；2）VPPL轻量级策略语言，支持基于发行者绑定的选择性属性揭示评估；3）专用的会话级安全机制，确保认证与访问之间的绑定，增强机密性和抗重放攻击能力。

Result: 实现了一个工作原型并进行全面实验，证明POLARIS能够有效提供可扩展、保护隐私且可互操作的跨异构域访问控制。结果表明POLARIS在去中心化跨域环境中实现安全和隐私保护访问控制具有实际可行性。

Conclusion: POLARIS通过创新的架构设计，成功解决了跨域访问控制中的关键挑战，为去中心化、跨域环境提供了实用、安全且保护隐私的访问控制解决方案。

Abstract: Access control is a security mechanism designed to ensure that only authorized users can access specific resources. Cross-domain access control involves access to resources across different organizations, institutions, or applications. Traditional access control, however, which handles authentication and authorization separately in centralized environments, faces challenges in identity dispersion, privacy leakage, and diversified permission requirements, failing to adapt to cross-domain scenarios. Thus, there is an urgent need for a new access control mechanism that empowers autonomous control over user identity and resources, addressing the demands for privacy-preserving authentication and flexible authorization in cross-domain scenarios. To address cross-domain access control challenges, we propose POLARIS, a unified and extensible architecture that enables policy-based, verifiable and privacy-preserving access control across different domains. POLARIS features a structured commitment mechanism for reliable, fine-grained, policy-based identity disclosure. It further introduces VPPL, a lightweight policy language that supports issuer-bound evaluation of selectively revealed attributes. A dedicated session-level security mechanism ensures binding between authentication and access, enhancing confidentiality and resilience to replay attacks. We implement a working prototype and conduct comprehensive experiments, demonstrating that POLARIS effectively provides scalable, privacy-preserving, and interoperable access control across heterogeneous domains. Our results highlight the practical viability of POLARIS for enabling secure and privacy-preserving access control in decentralized, cross-domain environments.

</details>


### [10] [Distillability of LLM Security Logic: Predicting Attack Success Rate of Outline Filling Attack via Ranking Regression](https://arxiv.org/abs/2511.22044)
*Tianyu Zhang,Zihang Xi,Jingyu Hua,Sheng Zhong*

Main category: cs.CR

TL;DR: 研究探索了构建轻量级安全代理模型来预测大语言模型越狱攻击成功率，通过改进的攻击方法和排名回归范式，证明了越狱行为的可预测性和可蒸馏性。


<details>
  <summary>Details</summary>
Motivation: 在黑盒越狱攻击领域，构建能够预测攻击成功率的轻量级安全代理模型（窄安全代理）的可行性尚未得到充分探索。本研究旨在探索大语言模型核心安全逻辑的可蒸馏性。

Method: 提出一个包含改进的轮廓填充攻击的新框架，实现对模型安全边界的密集采样。引入排名回归范式替代标准回归，训练代理模型预测哪个提示会产生更高的攻击成功率。

Result: 实验结果显示，代理模型在预测平均长响应相对排名方面达到91.1%的准确率，在预测攻击成功率方面达到69.2%的准确率。

Conclusion: 研究证实了越狱行为的可预测性和可蒸馏性，并展示了利用这种可蒸馏性来优化黑盒攻击的潜力。

Abstract: In the realm of black-box jailbreak attacks on large language models (LLMs), the feasibility of constructing a narrow safety proxy, a lightweight model designed to predict the attack success rate (ASR) of adversarial prompts, remains underexplored. This work investigates the distillability of an LLM's core security logic. We propose a novel framework that incorporates an improved outline filling attack to achieve dense sampling of the model's security boundaries. Furthermore, we introduce a ranking regression paradigm that replaces standard regression and trains the proxy model to predict which prompt yields a higher ASR. Experimental results show that our proxy model achieves an accuracy of 91.1 percent in predicting the relative ranking of average long response (ALR), and 69.2 percent in predicting ASR. These findings confirm the predictability and distillability of jailbreak behaviors, and demonstrate the potential of leveraging such distillability to optimize black-box attacks.

</details>


### [11] [Evaluating the Robustness of Large Language Model Safety Guardrails Against Adversarial Attacks](https://arxiv.org/abs/2511.22047)
*Richard J. Young*

Main category: cs.CR

TL;DR: LLM安全护栏模型在对抗攻击下表现脆弱，基准测试性能可能因训练数据污染而误导，泛化能力应成为主要评估指标。


<details>
  <summary>Details</summary>
Motivation: 评估LLM安全护栏模型在对抗攻击下的鲁棒性，现有研究对其在复杂攻击下的表现缺乏充分评估。

Method: 测试10个公开可用的护栏模型（来自Meta、Google、IBM、NVIDIA、Alibaba、Allen AI），使用1,445个测试提示，涵盖21种攻击类别，区分公开基准提示和新攻击。

Result: Qwen3Guard-8B总体准确率最高（85.3%），但在未见提示上性能大幅下降（从91.0%降至33.8%）。Granite-Guardian-3.2-5B泛化能力最佳（仅6.5%差距）。发现"帮助模式"越狱攻击，两个模型生成有害内容而非阻止。

Conclusion: 基准测试性能可能因训练数据污染而误导，泛化能力而非总体准确率应成为护栏评估的主要指标，现有模型在对抗攻击下存在严重脆弱性。

Abstract: Large Language Model (LLM) safety guardrail models have emerged as a primary defense mechanism against harmful content generation, yet their robustness against sophisticated adversarial attacks remains poorly characterized. This study evaluated ten publicly available guardrail models from Meta, Google, IBM, NVIDIA, Alibaba, and Allen AI across 1,445 test prompts spanning 21 attack categories. While Qwen3Guard-8B achieved the highest overall accuracy (85.3%, 95% CI: 83.4-87.1%), a critical finding emerged when separating public benchmark prompts from novel attacks: all models showed substantial performance degradation on unseen prompts, with Qwen3Guard dropping from 91.0% to 33.8% (a 57.2 percentage point gap). In contrast, Granite-Guardian-3.2-5B showed the best generalization with only a 6.5% gap. A "helpful mode" jailbreak was also discovered where two guardrail models (Nemotron-Safety-8B, Granite-Guardian-3.2-5B) generated harmful content instead of blocking it, representing a novel failure mode. These findings suggest that benchmark performance may be misleading due to training data contamination, and that generalization ability, not overall accuracy, should be the primary metric for guardrail evaluation.

</details>


### [12] [Binary-30K: A Heterogeneous Dataset for Deep Learning in Binary Analysis and Malware Detection](https://arxiv.org/abs/2511.22095)
*Michael J. Bommarito*

Main category: cs.CR

TL;DR: Binary-30K是首个为序列模型设计的异构二进制数据集，涵盖Windows、Linux、macOS和Android系统，包含29,793个二进制文件，支持跨平台恶意软件检测和二进制理解研究。


<details>
  <summary>Details</summary>
Motivation: 当前二进制分析深度学习研究面临基础设施缺口：现有数据集要么针对单一平台，需要专门工具，要么只提供与现代神经网络架构不兼容的手工特征，缺乏支持可访问研究和教学的统一数据集。

Method: 创建Binary-30K数据集，涵盖四大操作系统（Windows、Linux、macOS、Android）和15+种CPU架构，采用平台优先分层抽样确保代表性覆盖，提供预计算的字节级BPE分词和全面的结构元数据。

Result: 数据集包含29,793个二进制文件，其中约26.93%为恶意软件，通过Hugging Face平台提供官方训练/验证/测试分割，支持平台无关检测、跨目标迁移学习和长上下文二进制理解等研究。

Conclusion: Binary-30K填补了二进制分析深度学习研究的基础设施空白，为研究人员、从业者和学生提供了可访问的资源，支持可重复的基准测试和现实用例研究。

Abstract: Deep learning research for binary analysis faces a critical infrastructure gap. Today, existing datasets target single platforms, require specialized tooling, or provide only hand-engineered features incompatible with modern neural architectures; no single dataset supports accessible research and pedagogy on realistic use cases. To solve this, we introduce Binary-30K, the first heterogeneous binary dataset designed for sequence-based models like transformers. Critically, Binary-30K covers Windows, Linux, macOS, and Android across 15+ CPU architectures. With 29,793 binaries and approximately 26.93% malware representation, Binary-30K enables research on platform-invariant detection, cross-target transfer learning, and long-context binary understanding. The dataset provides pre-computed byte-level BPE tokenization alongside comprehensive structural metadata, supporting both sequence modeling and structure-aware approaches. Platform-first stratified sampling ensures representative coverage across operating systems and architectures, while distribution via Hugging Face with official train/validation/test splits enables reproducible benchmarking. The dataset is publicly available at https://huggingface.co/datasets/mjbommar/binary-30k, providing an accessible resource for researchers, practitioners, and students alike.

</details>


### [13] [Privacy-preserving formal concept analysis: A homomorphic encryption-based concept construction](https://arxiv.org/abs/2511.22117)
*Qiangqiang Chen,Yunfeng Ke,Shen Li,Jinhai Li*

Main category: cs.CR

TL;DR: 提出一种结合二进制数据表示和同态加密的隐私保护形式概念分析框架，在保护敏感数据的同时实现高效概念构建


<details>
  <summary>Details</summary>
Motivation: 形式概念分析在大规模数据集上的计算需求通常需要外包给外部计算服务，这引发了敏感信息泄露的担忧。为了解决这一挑战，需要增强FCA计算中的数据安全和隐私保护。

Method: 提出隐私保护形式概念分析框架，结合二进制数据表示和同态加密技术，能够在不解密的情况下对加密数据进行概念构建计算。

Result: 实验结果表明该方法在保护隐私的同时保持了计算性能，安全分析证实了其有效性。

Conclusion: 该研究对隐私保护数据挖掘和大规模FCA应用中的安全知识发现具有重要意义，为解决FCA计算中的隐私泄露问题提供了有效方案。

Abstract: Formal Concept Analysis (FCA) is extensively used in knowledge extraction, cognitive concept learning, and data mining. However, its computational demands on large-scale datasets often require outsourcing to external computing services, raising concerns about the leakage of sensitive information. To address this challenge, we propose a novel approach to enhance data security and privacy in FCA-based computations. Specifically, we introduce a Privacy-preserving Formal Context Analysis (PFCA) framework that combines binary data representation with homomorphic encryption techniques. This method enables secure and efficient concept construction without revealing private data. Experimental results and security analysis confirm the effectiveness of our approach in preserving privacy while maintaining computational performance. These findings have important implications for privacy-preserving data mining and secure knowledge discovery in large-scale FCA applications.

</details>


### [14] [Personalized 3D Spatiotemporal Trajectory Privacy Protection with Differential and Distortion Geo-Perturbation](https://arxiv.org/abs/2511.22180)
*Minghui Min,Yulu Li,Gang Li,Meng Li,Hongliang Zhang,Miao Pan,Dusit Niyato,Zhu Han*

Main category: cs.CR

TL;DR: 本文提出了一种个性化的3D时空轨迹隐私保护机制3DSTPM，通过结合3D地理不可区分性和失真隐私，采用窗口自适应隐私预算分配，有效平衡隐私保护与服务质量。


<details>
  <summary>Details</summary>
Motivation: 随着3D领域位置服务（如智慧城市、智能交通）的快速发展，3D时空轨迹隐私保护面临挑战。现有研究未能充分解决攻击者利用时空相关性以及高度信息带来的隐私泄露风险。

Method: 1. 分析攻击者利用轨迹位置时空相关性的特征并建立攻击模型；2. 结合3D地理不可区分性和失真隐私寻找保护位置集合；3. 提出窗口自适应隐私预算分配机制动态分配隐私预算；4. 使用PF机制对真实位置进行扰动。

Result: 仿真结果表明，3DSTPM在满足用户个性化隐私保护需求的同时，有效减少了服务质量损失。

Conclusion: 提出的3DSTPM机制能够有效解决3D时空轨迹隐私保护问题，平衡隐私保护与服务质量，为3D位置服务提供有效的隐私保护方案。

Abstract: The rapid advancement of location-based services (LBSs) in three-dimensional (3D) domains, such as smart cities and intelligent transportation, has raised concerns over 3D spatiotemporal trajectory privacy protection. However, existing research has not fully addressed the risk of attackers exploiting the spatiotemporal correlation of 3D spatiotemporal trajectories and the impact of height information, both of which can potentially lead to significant privacy leakage. To address these issues, this paper proposes a personalized 3D spatiotemporal trajectory privacy protection mechanism, named 3DSTPM. First, we analyze the characteristics of attackers that exploit spatiotemporal correlations between locations in a trajectory and present the attack model. Next, we exploit the complementary characteristics of 3D geo-indistinguishability (3D-GI) and distortion privacy to find a protection location set (PLS) that obscures the real location for all possible locations. To address the issue of privacy accumulation caused by continuous trajectory queries, we propose a Window-based Adaptive Privacy Budget Allocation (W-APBA), which dynamically allocates privacy budgets to all locations in the current PLS based on their predictability and sensitivity. Finally, we perturb the real location using the allocated privacy budget by the PF (Permute-and-Flip) mechanism, effectively balancing privacy protection and Quality of Service (QoS). Simulation results demonstrate that the proposed 3DSTPM effectively reduces QoS loss while meeting the user's personalized privacy protection needs.

</details>


### [15] [Department-Specific Security Awareness Campaigns: A Cross-Organizational Study of HR and Accounting](https://arxiv.org/abs/2511.22189)
*Matthias Pfister,Giovanni Apruzzese,Irdin Pekaric*

Main category: cs.CR

TL;DR: 研究发现当前网络安全意识培训过于通用，未能针对不同部门（如HR和财务）的具体需求，提出应设计部门定制化、场景化、短时频次的培训方案。


<details>
  <summary>Details</summary>
Motivation: 当前网络安全意识培训普遍采用"通用"视角，忽略了不同部门面临的特定威胁和需求，可能导致组织内部特定子集的漏洞被忽视。研究旨在解决这种忽视，重点关注HR和财务这两个关键部门的特定安全需求。

Method: 采用混合方法研究：1）通过系统文献回顾分析现有研究对部门特定需求的覆盖情况；2）对跨国公司16名员工进行访谈；3）基于访谈结果设计结构化调查问卷，收集9个组织90多名HR/财务部门员工的反馈。

Result: 发现HR部门主要面临包含恶意软件的求职申请和高管冒充攻击，财务部门则面临发票欺诈、凭证盗窃和勒索软件威胁。当前培训被认为过于通用，员工偏好更短、基于场景的视频和模拟培训，这与行业常见的年度培训实践相矛盾。

Conclusion: 提出应根据部门特定需求和工作流程设计定制化的安全意识培训方案，采用更短、更频繁、场景化的培训形式，以替代传统的通用年度培训。

Abstract: Many cyberattacks succeed because they exploit flaws at the human level. To address this problem, organizations rely on security awareness programs, which aim to make employees more resilient against social engineering. While some works have suggested that such programs should account for contextual relevance, the common praxis in research is to adopt a "general" viewpoint. For instance, instead of focusing on department-specific issues, prior user studies sought to provide organization-wide conclusions. Such a protocol may lead to overlooking vulnerabilities that affect only specific subsets of an organization.
  In this paper, we tackle such an oversight. First, through a systematic literature review, we provide evidence that prior literature poorly accounted for department-specific needs. Then, we carry out a multi-company and mixed-methods study focusing on two pivotal departments: human resources (HR) and accounting. We explore three dimensions: threats faced by these departments; topics covered in the security-awareness campaigns delivered to these departments; and delivery methods that maximize the effectiveness of such campaigns. We begin by interviewing 16 employees of a multinational enterprise, and then use these results as a scaffold to design a structured survey through which we collect the responses of over 90 HR/accounting members of 9 organizations. We find that HR is targeted through job applications containing malware and executive impersonation, while accounting is exposed to invoice fraud, credential theft, and ransomware. Current training is often viewed as too generic, with employees preferring shorter, scenario-based formats like videos and simulations. These preferences contradict the common industry practice of annual sessions. Based on these insights, we propose recommendations for designing awareness programs tailored to departmental needs and workflows.

</details>


### [16] [Real-PGDN: A Two-level Classification Method for Full-Process Recognition of Newly Registered Pornographic and Gambling Domain Names](https://arxiv.org/abs/2511.22215)
*Hao Wang,Yingshuo Wang,Junang Gan,Yanan Cheng,Jinshuai Zhang*

Main category: cs.CR

TL;DR: 提出Real-PGDN方法，通过两级分类器（CoSENT+MLP+传统算法）实现97.88%精度的色情赌博域名分类，并构建包含150万新注册域名20天连续检测的NRD2024数据集。


<details>
  <summary>Details</summary>
Motivation: 在线色情和赌博域名对个人资产和隐私构成威胁，但现有研究要么使用理想样本追求高精度，要么使用真实数据但精度较低，缺乏兼顾时效性、全面性和高精度的分类方法。

Method: 提出Real-PGDN方法，包括：1）及时全面的真实数据爬取；2）具有特征缺失容忍的特征提取；3）精确的PGDN分类；4）实际场景应用效果评估。采用两级分类器，集成CoSENT（基于BERT）、多层感知机（MLP）和传统分类算法。

Result: 分类精度达到97.88%，构建了NRD2024数据集（包含150万新注册域名在6个方向20天的连续检测信息）。案例研究表明，对于注册后延迟使用的PGDN，预测精度仍能保持70%以上。

Conclusion: Real-PGDN方法实现了高精度的色情赌博域名分类，并在实际场景中表现出良好的预测能力，为在线色情和赌博域名的监管提供了有效工具。

Abstract: Online pornography and gambling have consistently posed regulatory challenges for governments, threatening both personal assets and privacy. Therefore, it is imperative to research the classification of the newly registered Pornographic and Gambling Domain Names (PGDN). However, scholarly investigation into this topic is limited. Previous efforts in PGDN classification pursue high accuracy using ideal sample data, while others employ up-to-date data from real-world scenarios but achieve lower classification accuracy. This paper introduces the Real-PGDN method, which accomplishes a complete process of timely and comprehensive real-data crawling, feature extraction with feature-missing tolerance, precise PGDN classification, and assessment of application effects in actual scenarios. Our two-level classifier, which integrates CoSENT (BERT-based), Multilayer Perceptron (MLP), and traditional classification algorithms, achieves a 97.88% precision. The research process amasses the NRD2024 dataset, which contains continuous detection information over 20 days for 1,500,000 newly registered domain names across 6 directions. Results from our case study demonstrate that this method also maintains a forecast precision of over 70% for PGDN that are delayed in usage after registration.

</details>


### [17] [Silence Speaks Volumes: A New Paradigm for Covert Communication via History Timing Patterns](https://arxiv.org/abs/2511.22259)
*Christoph Weissenborn,Steffen Wendzel*

Main category: cs.CR

TL;DR: 本文提出了一种基于网络时序模式相对指针的新型历史隐蔽信道(HCC)方法，相比传统方法具有更好的比特率和更低的检测率


<details>
  <summary>Details</summary>
Motivation: 历史隐蔽信道(HCC)利用历史网络事件作为参考点嵌入隐蔽信息，相比传统时序或存储型隐蔽信道更难以检测。现有HCC方法依赖集中式时间同步，容易被标准网络监控工具发现，需要更隐蔽的通信方法。

Method: 提出使用网络时序模式的相对指针来建立和维护隐蔽通信链路，减少对集中式时间同步的依赖，并优化HCC的鲁棒性和不可检测性特征。

Result: 实验结果显示，相比先前工作，该方法获得了更好的比特率，同时降低了被标准网络监控工具检测的可能性。

Conclusion: 基于相对指针的历史隐蔽信道方法能够有效提高隐蔽通信的效率和隐蔽性，为网络安全领域提供了新的研究方向。

Abstract: A Covert Channel (CC) exploits legitimate communication mechanisms to stealthily transmit information, often bypassing traditional security controls. Among these, a novel paradigm called History Covert Channels (HCC) leverages past network events as reference points to embed covert messages. Unlike traditional timing- or storage-based CCs, which directly manipulate traffic patterns or packet contents, HCCs minimize detectability by encoding information through small pointers to historical data. This approach enables them to amplify the size of transmitted covert data by referring to more bits than are actually embedded. Recent research has explored the feasibility of such methods, demonstrating their potential to evade detection by repurposing naturally occurring network behaviors as a covert transmission medium.
  This paper introduces a novel method for establishing and maintaining covert communication links using relative pointers to network timing patterns, which minimizes the reliance of the HCC on centralized timekeeping and reduces the likelihood of being detected by standard network monitoring tools. We also explore the tailoring of HCCs to optimize their robustness and undetectability characteristics. Our experiments reveal a better bitrate compared to previous work.

</details>


### [18] [Enhancing the Security of Rollup Sequencers using Decentrally Attested TEEs](https://arxiv.org/abs/2511.22317)
*Giovanni Maria Cristiano,Salvatore D'Antonio,Jonah Giglio,Giovanni Mazzeo,Luigi Romano*

Main category: cs.CR

TL;DR: 提出一个结合TEE安全性和去中心化认证机制的Rollup Sequencer方案，在保持现有Layer-2架构兼容性的同时增强Sequencer的完整性


<details>
  <summary>Details</summary>
Motivation: Rollup中的Sequencer作为关键组件存在中心化问题，易受审查、交易操纵等攻击。现有TEE解决方案虽然能增强安全性，但其认证机制本身又引入了新的中心化，这与区块链去中心化核心原则相矛盾。

Method: 设计并实现了一个TEE保护的Sequencer，配备去中心化认证机制。包括系统架构设计、TEE集成以及认证过程的去中心化实现。

Result: 在真实的Rollup测试网上进行实验评估，结果表明该方法在不牺牲兼容性或可部署性的前提下，有效增强了Sequencer的完整性。

Conclusion: 提出的TEE安全Sequencer结合去中心化认证机制，成功解决了现有方案中的中心化矛盾，为Layer-2 Rollup提供了更安全的Sequencer解决方案。

Abstract: The growing scalability demand of public Blockchains led to the rise of Layer-2 solutions, such as Rollups. Rollups improve transaction throughput by processing operations off-chain and posting the results on-chain. A critical component in Rollups is the Sequencer, responsible for receiving, ordering and batching transactions before they are submitted to the Layer-1 blockchain. While essential, the centralized nature of the Sequencer makes it vulnerable to attacks, such as censorship, transaction manipulation and tampering. To enhance its security, there are solutions in the literature that shield the Sequencer inside a Trusted Execution Environment (TEE). However, the attestation of TEEs introduces additional centralization, which is in contrast with the core Blockchain principle. In this paper, we propose a TEE-secured Sequencer equipped with a decentralized attestation mechanism. We outline the design and implementation of our solution, covering the system architecture, TEE integration, and the decentralization of the attestation process. Additionally, we present an experimental evaluation conducted on a realistic Rollup testnet. Our results show that this approach strengthens Sequencer integrity without sacrificing compatibility or deployability in existing Layer-2 architectures.

</details>


### [19] [Keyless Entry: Breaking and Entering eMMC RPMB with EMFI](https://arxiv.org/abs/2511.22340)
*Aya Fukami,Richard Buurke*

Main category: cs.CR

TL;DR: 通过电磁脉冲注入故障，成功绕过三个eMMC芯片中RPMB的认证机制，实现了对受保护数据的任意覆盖


<details>
  <summary>Details</summary>
Motivation: RPMB在现代存储系统中提供安全区域保护关键数据，但需要验证其认证机制的安全性，特别是面对物理攻击时的脆弱性

Method: 对主要制造商的三款不同eMMC芯片，通过发送电磁脉冲注入故障，攻击RPMB的认证方案

Result: 成功绕过RPMB认证，在两款目标eMMC中覆盖了受保护区域的数据，且不影响其他数据的完整性

Conclusion: RPMB的认证机制存在物理安全漏洞，电磁脉冲攻击可有效绕过其保护，需要更强的物理安全措施

Abstract: The Replay Protected Memory Block (RPMB) in modern storage systems provides a secure area where data integrity is ensured by authentication. This block is used in digital devices to store pivotal information that must be safeguarded against modification by potential attackers. This paper targets the authentication scheme of the RPMB in three different eMMCs from a major manufacturer. A glitch was injected by sending an electromagnetic pulse to the target chip. RPMB authentication was successfully glitched and the information stored in two target eMMCs was overwritten with arbitrary data, without affecting the integrity of other data.

</details>


### [20] [Exposing Vulnerabilities in RL: A Novel Stealthy Backdoor Attack through Reward Poisoning](https://arxiv.org/abs/2511.22415)
*Bokang Zhang,Chaojun Lu,Jianhui Li,Junfeng Wu*

Main category: cs.CR

TL;DR: 该论文研究了一种针对强化学习系统的隐蔽后门攻击，通过毒化奖励信号来操纵智能体策略，在经典控制和MuJoCo环境中验证了攻击的有效性和隐蔽性。


<details>
  <summary>Details</summary>
Motivation: 强化学习虽然在各领域取得了显著成功，但其依赖奖励信号的特性带来了严重的安全漏洞。当前需要研究训练时操纵对RL系统完整性的威胁，并开发相应的防御机制。

Method: 提出一种隐蔽的后门攻击方法，通过毒化智能体的奖励信号来操纵其策略。攻击设计保持高度隐蔽性，在非触发场景下性能下降极小，而在触发条件下能显著降低智能体性能。

Result: 在Hopper和Walker2D环境中，后门智能体在非触发场景下仅分别有2.18%和4.59%的性能下降，保持高度隐蔽性；在触发条件下，性能分别下降高达82.31%和71.27%，攻击效果显著。

Conclusion: 这种基于奖励信号毒化的后门攻击揭示了RL系统的严重安全漏洞，对已部署RL系统的完整性构成重大威胁，迫切需要开发针对训练时操纵的防御机制。

Abstract: Reinforcement learning (RL) has achieved remarkable success across diverse domains, enabling autonomous systems to learn and adapt to dynamic environments by optimizing a reward function. However, this reliance on reward signals creates a significant security vulnerability. In this paper, we study a stealthy backdoor attack that manipulates an agent's policy by poisoning its reward signals. The effectiveness of this attack highlights a critical threat to the integrity of deployed RL systems and calls for urgent defenses against training-time manipulation. We evaluate the attack across classic control and MuJoCo environments. The backdoored agent remains highly stealthy in Hopper and Walker2D, with minimal performance drops of only 2.18 % and 4.59 % under non-triggered scenarios, while achieving strong attack efficacy with up to 82.31% and 71.27% declines under trigger conditions.

</details>


### [21] [Extending Quantum-Safe Communications to Real-World Networks: An Adaptive Security Framework](https://arxiv.org/abs/2511.22416)
*Ane Sanz,Eire Salegi,Asier Atutxa,David Franco,Jasone Astorga,Eduardo Jacob*

Main category: cs.CR

TL;DR: 提出自适应安全框架，结合QKD和PQC实现量子安全通信，支持混合网络环境下的端到端保护


<details>
  <summary>Details</summary>
Motivation: 量子计算威胁传统密码机制，但现实网络无法完全部署QKD，需要支持混合操作的安全解决方案

Method: 基于分层密钥管理架构（vKMS和QuSeC），根据节点能力动态分配安全级别，在纯QKD、混合和PQC模式间切换

Result: 在Kubernetes容器化测试平台上实现验证，展示稳健运行和性能，支持量子安全技术逐步集成到现有基础设施

Conclusion: 该框架为完全量子安全通信网络铺平道路，支持在异构网络中实现端到端量子安全保护

Abstract: The advent of quantum computing threats classical cryptographic mechanisms, demanding new strategies for securing communication networks. Since real-world networks cannot be fully Quantum Key Distribution (QKD)-enabled due to infrastructure constraints, practical security solutions must support hybrid operation. This paper presents an adaptive security framework that enables quantum-safe communications across real-world heterogeneous networks by combining QKD and Post-Quantum Cryptography (PQC). Building upon a hierarchical key management architecture with Virtual Key Management Systems (vKMS) and a centralized Quantum Security Controller (QuSeC), the framework dynamically assigns security levels based on node capabilities. By transitioning between pure QKD, hybrid, and PQC modes, it ensures end-to-end quantum-safe protection regardless of the underlying node capabilities. The framework has been implemented and validated on a Kubernetes-based containerized testbed, demonstrating robust operation and performance across all scenarios. Results highlight its potential to support the gradual integration of quantum-safe technologies into existing infrastructures, paving the way toward fully quantum-safe communication networks.

</details>


### [22] [FastFHE: Packing-Scalable and Depthwise-Separable CNN Inference Over FHE](https://arxiv.org/abs/2511.22434)
*Wenbo Song,Xinxin Fan,Quanliang Jing,Shaoye Luo,Wenqi Wei,Chi Lin,Yunfeng Lu,Ling Liu*

Main category: cs.CR

TL;DR: FastFHE：基于RNS-CKKS全同态加密的高效深度CNN推理加速方案，通过数据打包、深度可分离卷积、BN融合和低阶多项式近似等技术解决加密推理中的三大瓶颈问题。


<details>
  <summary>Details</summary>
Motivation: 深度学习模型在加密环境下的安全推理和样本隐私保护对安全关键应用至关重要。现有基于RNS-CKKS的方案存在高延迟问题，限制了实际应用。当前加密推理面临三大瓶颈：卷积计算的时间和存储成本、巨大引导操作的时间开销、电路乘法深度的消耗。

Method: 提出FastFHE机制，包含四项创新：1) 可扩展的密文数据打包方案，节省时间和存储；2) 深度可分离卷积方式，降低卷积计算负载；3) BN点积融合矩阵，将密文卷积层与批归一化层融合而不增加乘法深度；4) 使用低阶Legendre多项式近似非线性激活函数SiLU，保证加密前后精度误差微小。

Result: 通过多方面实验验证了所提方法的效率和有效性，在保持高推理精度的同时显著加速了全同态加密下的模型推理。

Conclusion: FastFHE成功解决了加密CNN推理中的三大瓶颈问题，实现了高效且准确的加密模型推理，为安全关键应用中的深度学习部署提供了实用解决方案。

Abstract: The deep learning (DL) has been penetrating daily life in many domains, how to keep the DL model inference secure and sample privacy in an encrypted environment has become an urgent and increasingly important issue for various security-critical applications. To date, several approaches have been proposed based on the Residue Number System variant of the Cheon-Kim-Kim-Song (RNS-CKKS) scheme. However, they all suffer from high latency, which severely limits the applications in real-world tasks. Currently, the research on encrypted inference in deep CNNs confronts three main bottlenecks: i) the time and storage costs of convolution calculation; ii) the time overhead of huge bootstrapping operations; and iii) the consumption of circuit multiplication depth. Towards these three challenges, we in this paper propose an efficient and effective mechanism FastFHE to accelerate the model inference while simultaneously retaining high inference accuracy over fully homomorphic encryption. Concretely, our work elaborates four unique novelties. First, we propose a new scalable ciphertext data-packing scheme to save the time and storage consumptions. Second, we work out a depthwise-separable convolution fashion to degrade the computation load of convolution calculation. Third, we figure out a BN dot-product fusion matrix to merge the ciphertext convolutional layer with the batch-normalization layer without incurring extra multiplicative depth. Last but not least, we adopt the low-degree Legendre polynomial to approximate the nonlinear smooth activation function SiLU under the guarantee of tiny accuracy error before and after encrypted inference. Finally, we execute multi-facet experiments to verify the efficiency and effectiveness of our proposed approach.

</details>


### [23] [GEO-Detective: Unveiling Location Privacy Risks in Images with LLM Agents](https://arxiv.org/abs/2511.22441)
*Xinyu Zhang,Yixin Wu,Boyang Zhang,Chenhao Lin,Chao Shen,Michael Backes,Yang Zhang*

Main category: cs.CR

TL;DR: Geo-Detective是一个模仿人类推理和工具使用的智能体，专门用于图像地理位置推断，通过自适应策略选择和专业工具（如视觉反向搜索）显著提升地理定位精度，特别是在缺乏明显地理特征的图像上表现优异。


<details>
  <summary>Details</summary>
Motivation: 社交媒体图像常包含地理线索，现有大型视觉语言模型（LVLMs）虽能进行地理定位但未针对此任务优化。作者旨在探索该任务的潜力及相关隐私风险，开发更有效的解决方案。

Method: 提出Geo-Detective智能体，模仿人类推理和工具使用，采用四步自适应策略选择流程，根据图像难度调整方法，配备视觉反向搜索等专业工具来收集外部地理线索。

Result: 在国家级地理定位任务中比基线LVLMs提升超过11.1%，在更细粒度级别仍有约5.2%的性能增益。配备外部线索时，准确预测率提升，"未知"预测率降低超过50.6%。

Conclusion: Geo-Detective在图像地理定位任务上表现优异，特别是在缺乏明显地理特征的图像上。其较强的鲁棒性凸显了需要更有效的隐私保护措施来应对此类技术带来的隐私风险。

Abstract: Images shared on social media often expose geographic cues. While early geolocation methods required expert effort and lacked generalization, the rise of Large Vision Language Models (LVLMs) now enables accurate geolocation even for ordinary users. However, existing approaches are not optimized for this task. To explore the full potential and associated privacy risks, we present Geo-Detective, an agent that mimics human reasoning and tool use for image geolocation inference. It follows a procedure with four steps that adaptively selects strategies based on image difficulty and is equipped with specialized tools such as visual reverse search, which emulates how humans gather external geographic clues. Experimental results show that GEO-Detective outperforms baseline large vision language models (LVLMs) overall, particularly on images lacking visible geographic features. In country level geolocation tasks, it achieves an improvement of over 11.1% compared to baseline LLMs, and even at finer grained levels, it still provides around a 5.2% performance gain. Meanwhile, when equipped with external clues, GEO-Detective becomes more likely to produce accurate predictions, reducing the "unknown" prediction rate by more than 50.6%. We further explore multiple defense strategies and find that Geo-Detective exhibits stronger robustness, highlighting the need for more effective privacy safeguards.

</details>


### [24] [CacheTrap: Injecting Trojans in LLMs without Leaving any Traces in Inputs or Weights](https://arxiv.org/abs/2511.22681)
*Mohaiminul Al Nahian,Abeer Matar A. Almalky,Gamana Aragonda,Ranyang Zhou,Sabbir Ahmed,Dmitry Ponomarev,Li Yang,Shaahin Angizi,Adnan Siraj Rakin*

Main category: cs.CR

TL;DR: CacheTrap：一种新颖的LLM特洛伊木马攻击，通过翻转KV缓存中的单个比特位来触发目标行为，无需数据或梯度信息，且不影响模型正常功能。


<details>
  <summary>Details</summary>
Motivation: 随着对抗性权重扰动防御技术的成熟，攻击者需要寻找新的攻击面。KV缓存作为存储动态激活向量的临时空间，提供了瞬时的、推理时触发的攻击机会，且不会在输入或权重中留下痕迹。

Method: 提出CacheTrap攻击方法：1）识别KV缓存中易受攻击的比特位；2）通过翻转该比特位作为触发器；3）在推理时注入触发，使模型产生目标行为（如将输入分类到目标类别）。该方法无需数据或梯度信息。

Result: 成功实现了首个在LLMs上通过KV缓存中单个比特翻转完成的特洛伊木马攻击。攻击位置具有跨任务/数据集/查询的通用性，且不影响模型正常功能。

Conclusion: KV缓存是一个新的、危险的攻击面，CacheTrap展示了通过瞬时的、推理时的比特翻转实现高效特洛伊木马攻击的可行性，为LLM安全防御提出了新的挑战。

Abstract: Adversarial weight perturbation has emerged as a concerning threat to LLMs that either use training privileges or system-level access to inject adversarial corruption in model weights. With the emergence of innovative defensive solutions that place system- and algorithm-level checks and corrections in the input and weight spaces, these perturbations are increasingly susceptible to defenses. This work develops a novel perspective on Trojan attacks that generates an attacker-designed model output while leaving no attack traces on the inputs or weights. Such an attack space can be unlocked through corruption of the key-value (KV) cache. In this paper, we introduce CacheTrap, a novel Trojan attack that corrupts the value vectors stored in the KV cache. These vectors capture the dynamic activations for specific token positions and therefore constitute a natural surface for transient, inference-time trigger insertion. The transient nature of these KV values and their dependence on victim input imply additional constraints on our attack, such as a lack of knowledge of the victim's data or domain application, and, consequently, a lack of gradient information. The objective of the proposed CacheTrap is to develop a vulnerable KV bit-searching algorithm so that, once the attack employs the identified bit-flip as a trigger, the model generates targeted behavior, e.g., classifying inputs towards the target class. Moreover, CacheTrap is a data- and gradient-free attack which also has no impact on the model's utility. Our evaluation demonstrates that the proposed attack enables the first successful Trojan attack on LLMs with a single bit flip in the KV cache. In addition, the data-independent nature of the attack ensures that once the attacker identifies the vulnerable bit index, the location remains constant and can be transferred to a wide range of victim tasks/datasets/queries with no overhead.

</details>


### [25] [Ghosting Your LLM: Without The Knowledge of Your Gradient and Data](https://arxiv.org/abs/2511.22700)
*Abeer Matar A. Almalky,Ziyan Wang,Mohaiminul Al Nahian,Li Yang,Adnan Siraj Rakin*

Main category: cs.CR

TL;DR: 提出一种无需梯度计算和样本数据的比特翻转攻击方法，通过新颖的脆弱性指标识别LLM中的易受攻击权重比特，显著降低内存需求并提高攻击效率。


<details>
  <summary>Details</summary>
Motivation: 随着LLM在关键领域的广泛应用，确保其安全性和鲁棒性变得至关重要。现有比特翻转攻击依赖梯度计算，存在计算内存成本高且需要访问受害者数据的问题，需要开发更高效实用的攻击方法。

Method: 提出新颖的脆弱性指标，无需梯度计算或数据知识即可识别LLM中的易受攻击权重比特。通过移除梯度计算依赖，大幅降低内存需求，实现跨任务的恒定复杂度扩展。

Result: 实验结果表明该方法高效实用，仅需翻转单个比特即可在五个开源LLM上实现对抗目标，显著优于现有依赖梯度的方法。

Conclusion: 成功开发了一种无需梯度计算和样本数据的比特翻转攻击框架，为LLM安全评估提供了更高效实用的工具，揭示了硬件故障攻击对LLM安全的新威胁。

Abstract: In recent years, large language models (LLMs) have achieved substantial advancements and are increasingly integrated into critical applications across various domains. This growing adoption underscores the need to ensure their security and robustness. In this work, we focus on the impact of Bit Flip Attacks (BFAs) on LLMs, which exploits hardware faults to corrupt model parameters, posing a significant threat to model integrity and performance. Existing studies on BFA against LLMs adopt a progressive bit-search strategy that predominantly relies on gradient-based techniques to identify sensitive layers or weights. However, computing gradients comes with two specific challenges: First, in the context of LLMs, it increases computational and memory costs exponentially, and Second, it requires access to a sample victim dataset or knowledge of the victim domain to compute the gradient. In this work, we investigate beyond the scope of attack efficacy and aim to develop an efficient, practical Gradient-Data-free Bit-Flip Attack. The challenge lies in the core principle of adversarial attacks, which relies heavily on computing gradients from sample test/train data and manipulating model weights based on gradient information. To overcome this, we propose novel vulnerability index metrics that can identify vulnerable weight bits in LLMs independent of any gradient or data knowledge. By removing the dependency on gradient computation, our approach drastically reduces memory requirements and scales efficiently across multiple tasks with constant complexity. Experimental results demonstrate the efficiency of our method, requiring as few as a single bit flip to achieve adversarial objectives for five open-source LLMs.

</details>


### [26] [PRISM: Privacy-Aware Routing for Adaptive Cloud-Edge LLM Inference via Semantic Sketch Collaboration](https://arxiv.org/abs/2511.22788)
*Junfei Zhan,Haoxun Shen,Zheng Lin,Tengjiao He*

Main category: cs.CR

TL;DR: PRISM是一个隐私感知的云边协同推理框架，通过动态路由和语义调制，在保护敏感信息的同时保持高质量输出，相比基线方法减少40-50%的能耗和延迟。


<details>
  <summary>Details</summary>
Motivation: 现有云边协同推理方法对所有输入采用统一的隐私保护，不考虑输入敏感性，导致对非敏感token进行不必要的扰动，降低效用。需要一种能根据上下文动态平衡隐私和推理质量的框架。

Method: PRISM包含四个阶段：1) 边缘设备分析实体级敏感性；2) 软门控模块选择执行模式（云端、边缘或协同）；3) 对协同路径应用基于实体风险的自适应两层本地差分隐私；4) 云端LLM生成语义草图，边缘SLM使用本地上下文进行精炼。

Result: PRISM在各种场景下都实现了优越的隐私-效用权衡，将能耗和延迟降低到基线方法（如Uniform和Selective LDP）的40-50%，同时在强隐私约束下保持高输出质量。

Conclusion: PRISM通过上下文感知的动态路由和语义调制，有效解决了现有云边推理中隐私保护与效用平衡的问题，为隐私敏感的LLM服务提供了实用解决方案。

Abstract: Large Language Models (LLMs) demonstrate impressive capabilities in natural language understanding and generation, but incur high communication overhead and privacy risks in cloud deployments, while facing compute and memory constraints when confined to edge devices. Cloud-edge inference has emerged as a promising paradigm for improving privacy in LLM services by retaining sensitive computations on local devices. However, existing cloud-edge inference approaches apply uniform privacy protection without considering input sensitivity, resulting in unnecessary perturbation and degraded utility even for non-sensitive tokens. To address this limitation, we propose Privacy-aware Routing for Inference with Semantic Modulation (PRISM), a context-aware framework that dynamically balances privacy and inference quality. PRISM executes in four stages: (1) the edge device profiles entity-level sensitivity; (2) a soft gating module on the edge selects an execution mode - cloud, edge, or collaboration; (3) for collaborative paths, the edge applies adaptive two-layer local differential privacy based on entity risks; and (4) the cloud LLM generates a semantic sketch from the perturbed prompt, which is then refined by the edge-side small language model (SLM) using local context. Our results show that PRISM consistently achieves superior privacy-utility trade-offs across various scenarios, reducing energy consumption and latency to 40-50% of baseline methods such as Uniform and Selective LDP, while maintaining high output quality under strong privacy constraints. These findings are validated through comprehensive evaluations involving realistic prompts, actual energy measurements, and heterogeneous cloud-edge model deployments.

</details>


### [27] [An Efficient Privacy-preserving Intrusion Detection Scheme for UAV Swarm Networks](https://arxiv.org/abs/2511.22791)
*Kanchon Gharami,Shafika Showkat Moni*

Main category: cs.CR

TL;DR: 提出基于轻量级联邦持续学习的无人机群入侵检测系统，解决传统IDS在延迟、隐私、性能开销和模型漂移方面的挑战


<details>
  <summary>Details</summary>
Motivation: 无人机群网络在监控、灾害管理、农业和国防等领域应用广泛，但面临多种安全攻击威胁。传统入侵检测系统存在二进制分类限制、资源密集型神经网络、延迟、隐私泄露、性能开销大和模型漂移等问题

Method: 开发轻量级联邦持续学习IDS方案，支持跨不同无人机群的去中心化训练，确保数据异构性和隐私保护

Result: 在多个数据集上取得优异分类准确率：UKM-IDS 99.45%、UAV-IDS 99.99%、TLM-UAV 96.85%、Cyber-Physical 98.05%

Conclusion: 提出的轻量级联邦持续学习IDS方案能有效解决无人机群网络的安全检测问题，在保持高准确率的同时解决了传统IDS的局限性

Abstract: The rapid proliferation of unmanned aerial vehicles (UAVs) and their applications in diverse domains, such as surveillance, disaster management, agriculture, and defense, have revolutionized modern technology. While the potential benefits of swarm-based UAV networks are growing significantly, they are vulnerable to various security attacks that can jeopardize the overall mission success by degrading their performance, disrupting decision-making, and compromising the trajectory planning process. The Intrusion Detection System (IDS) plays a vital role in identifying potential security attacks to ensure the secure operation of UAV swarm networks. However, conventional IDS primarily focuses on binary classification with resource-intensive neural networks and faces challenges, including latency, privacy breaches, increased performance overhead, and model drift. This research aims to address these challenges by developing a novel lightweight and federated continuous learning-based IDS scheme. Our proposed model facilitates decentralized training across diverse UAV swarms to ensure data heterogeneity and privacy. The performance evaluation of our model demonstrates significant improvements, with classification accuracies of 99.45% on UKM-IDS, 99.99% on UAV-IDS, 96.85% on TLM-UAV dataset, and 98.05% on Cyber-Physical datasets.

</details>


### [28] [A Game-Theoretic Approach for Adversarial Information Fusion in Distributed Sensor Networks](https://arxiv.org/abs/2511.23026)
*Kassem Kallas*

Main category: cs.CR

TL;DR: 该论文提出了一种基于博弈论的对抗信号处理框架，针对分布式传感器网络中的对抗攻击，开发了多种防御机制和优化融合策略。


<details>
  <summary>Details</summary>
Motivation: 数字系统中个人信息面临安全威胁，各种信号处理安全领域（如多媒体取证、数字水印、生物识别等）都面临对抗者攻击的共同问题。需要建立对抗信号处理的一般理论，特别关注分布式传感器网络中的对抗信息融合问题。

Method: 采用博弈论方法，针对分布式传感器网络中的拜占庭攻击，开发了：1）软隔离防御方案；2）最优决策融合策略；3）基于因子图的近最优消息传递算法降低复杂度；4）保护去中心化网络共识算法免受数据伪造攻击的防御机制。

Result: 提出了完整的对抗信号处理框架，包括多种针对拜占庭攻击的防御方案和优化融合策略，为分布式传感器网络的安全运行提供了系统性的解决方案。

Conclusion: 通过博弈论方法成功建立了对抗信号处理的理论框架，为分布式传感器网络中的对抗攻击提供了有效的防御机制和优化策略，推动了对抗信号处理领域的发展。

Abstract: Every day we share our personal information through digital systems which are constantly exposed to threats. For this reason, security-oriented disciplines of signal processing have received increasing attention in the last decades: multimedia forensics, digital watermarking, biometrics, network monitoring, steganography and steganalysis are just a few examples. Even though each of these fields has its own peculiarities, they all have to deal with a common problem: the presence of one or more adversaries aiming at making the system fail. Adversarial Signal Processing lays the basis of a general theory that takes into account the impact that the presence of an adversary has on the design of effective signal processing tools. By focusing on the application side of Adversarial Signal Processing, namely adversarial information fusion in distributed sensor networks, and adopting a game-theoretic approach, this thesis contributes to the above mission by addressing four issues. First, we address decision fusion in distributed sensor networks by developing a novel soft isolation defense scheme that protect the network from adversaries, specifically, Byzantines. Second, we develop an optimum decision fusion strategy in the presence of Byzantines. In the next step, we propose a technique to reduce the complexity of the optimum fusion by relying on a novel near-optimum message passing algorithm based on factor graphs. Finally, we introduce a defense mechanism to protect decentralized networks running consensus algorithm against data falsification attacks.

</details>


### [29] [Identification of Malicious Posts on the Dark Web Using Supervised Machine Learning](https://arxiv.org/abs/2511.23183)
*Sebastião Alves de Jesus Filho,Gustavo Di Giovanni Bernardo,Paulo Henrique Ribeiro Gabriel,Bruno Bogaz Zarpelão,Rodrigo Sanches Miani*

Main category: cs.CR

TL;DR: 该研究应用文本挖掘和机器学习技术分析巴西葡萄牙语的暗网论坛数据，以识别恶意帖子，创建了首个针对该语言的原创数据集，并开发了高性能检测模型。


<details>
  <summary>Details</summary>
Motivation: 随着网络攻击的不断增长和日益复杂化，传统的防御技术已不足以应对威胁。主动检测网络威胁变得至关重要，而网络威胁情报（CTI）在这方面发挥着关键作用。本研究针对巴西葡萄牙语内容，填补了该领域的研究空白。

Method: 1. 从暗网论坛收集巴西葡萄牙语数据；2. 创建三个原创数据集；3. 设计新颖的多阶段标注流程，结合妥协指标（IoCs）、上下文关键词和人工分析；4. 全面评估文本表示方法和分类器；5. 应用主题建模验证模型在未标注数据上的表现。

Result: 最佳性能模型（LightGBM + TF-IDF）能够以高准确率检测相关帖子。主题建模验证了模型在未标注数据上的鲁棒性，确认其在真实场景中的有效性。

Conclusion: 这是首个专注于巴西葡萄牙语暗网论坛内容的研究，提出的多阶段标注方法和机器学习模型为网络安全威胁检测提供了有效工具，特别是在非英语内容分析领域具有重要价值。

Abstract: Given the constant growth and increasing sophistication of cyberattacks, cybersecurity can no longer rely solely on traditional defense techniques and tools. Proactive detection of cyber threats has become essential to help security teams identify potential risks and implement effective mitigation measures. Cyber Threat Intelligence (CTI) plays a key role by providing security analysts with evidence-based knowledge about cyber threats. CTI information can be extracted using various techniques and data sources; however, machine learning has proven promising. As for data sources, social networks and online discussion forums are commonly explored. In this study, we apply text mining techniques and machine learning to data collected from Dark Web forums in Brazilian Portuguese to identify malicious posts. Our contributions include the creation of three original datasets, a novel multi-stage labeling process combining indicators of compromise (IoCs), contextual keywords, and manual analysis, and a comprehensive evaluation of text representations and classifiers. To our knowledge, this is the first study to focus specifically on Brazilian Portuguese content in this domain. The best-performing model, using LightGBM and TF-IDF, was able to detect relevant posts with high accuracy. We also applied topic modeling to validate the model's outputs on unlabeled data, confirming its robustness in real-world scenarios.

</details>


### [30] [Clustering Malware at Scale: A First Full-Benchmark Study](https://arxiv.org/abs/2511.23198)
*Martin Mocko,Jakub Ševcech,Daniela Chudá*

Main category: cs.CR

TL;DR: 该研究首次在完整恶意软件基准数据集上评估聚类性能，发现K-Means和BIRCH表现最佳，且加入良性样本不会显著降低聚类质量。


<details>
  <summary>Details</summary>
Motivation: 恶意软件聚类研究存在三个主要问题：1) 很少包含良性样本；2) 实验常使用小型数据集而非完整基准数据集；3) 当前最优聚类方法不明确。研究旨在填补这些空白。

Method: 在Bodmas和Ember两个大型公开恶意软件基准数据集上进行聚类评估，首次使用完整数据集而非子集。扩展任务包含良性样本，比较多种聚类算法性能。

Result: 1) 加入良性样本不会显著降低聚类质量；2) 不同数据集（Ember、Bodmas和私有数据集）的聚类质量存在显著差异；3) 与普遍认知相反，K-Means和BIRCH表现最佳，而DBSCAN和HAC落后。

Conclusion: 该研究首次在完整恶意软件基准数据集上建立了聚类性能基准，挑战了传统认知，表明K-Means和BIRCH是当前最优方法，且包含良性样本的聚类是可行的。

Abstract: Recent years have shown that malware attacks still happen with high frequency. Malware experts seek to categorize and classify incoming samples to confirm their trustworthiness or prove their maliciousness. One of the ways in which groups of malware samples can be identified is through malware clustering. Despite the efforts of the community, malware clustering which incorporates benign samples has been under-explored. Moreover, despite the availability of larger public benchmark malware datasets, malware clustering studies have avoided fully utilizing these datasets in their experiments, often resorting to small datasets with only a few families. Additionally, the current state-of-the-art solutions for malware clustering remain unclear. In our study, we evaluate malware clustering quality and establish the state-of-the-art on Bodmas and Ember - two large public benchmark malware datasets. Ours is the first study of malware clustering performed on whole malware benchmark datasets. Additionally, we extend the malware clustering task by incorporating benign samples. Our results indicate that incorporating benign samples does not significantly degrade clustering quality. We find that there are significant differences in the quality of the created clusters between Ember and Bodmas, as well as a private industry dataset. Contrary to popular opinion, our top clustering performers are K-Means and BIRCH, with DBSCAN and HAC falling behind.

</details>


### [31] [Quantifying the Privacy-Utility Trade-off in GPS-based Daily Stress Recognition using Semantic Features](https://arxiv.org/abs/2511.23200)
*Hoang Khang Phan,Nhat Tan Le*

Main category: cs.CR

TL;DR: 提出一个隐私增强的端到端框架，使用自托管OSM引擎和LLM引导的静态地图进行语义位置编码，用于远程压力识别，在保护隐私的同时保持性能


<details>
  <summary>Details</summary>
Motivation: 学生心理压力普遍且影响重大，现有远程压力识别方法依赖可穿戴设备或GPS聚类技术，存在隐私风险，需要开发隐私保护的替代方案

Method: 提出隐私增强的端到端框架，使用自托管OSM引擎和LLM引导的静态地图进行语义位置编码，严格量化隐私-效用权衡，采用留一受试者交叉验证

Result: 隐私感知模型性能与非隐私模型在统计上无显著差异，证明效用无需牺牲隐私；特征重要性分析显示娱乐活动时间、工作时间和旅行时间对压力识别有显著作用

Conclusion: 提出的隐私增强框架在保护用户位置隐私的同时，实现了与现有方法相当的压力识别性能，为远程心理健康监测提供了可行的隐私保护解决方案

Abstract: Psychological stress is a widespread issue that significantly impacts student well-being and academic performance. Effective remote stress recognition is crucial, yet existing methods often rely on wearable devices or GPS-based clustering techniques that pose privacy risks. In this study, we introduce a novel, end-to-end privacy-enhanced framework for semantic location encoding using a self-hosted OSM engine and an LLM-bootstrapped static map. We rigorously quantify the privacy-utility trade-off and demonstrate (via LOSO validation) that our Privacy-Aware (PA) model achieves performance statistically indistinguishable from a non-private model, proving that utility does not require sacrificing privacy. Feature importance analysis highlights that recreational activity time, working time, and travel time play a significant role in stress recognition.

</details>


### [32] [One-Shot Secure Aggregation: A Hybrid Cryptographic Protocol for Private Federated Learning in IoT](https://arxiv.org/abs/2511.23252)
*Imraul Emmaka,Tran Viet Xuan Phuong*

Main category: cs.CR

TL;DR: Hyb-Agg是一个轻量级、通信高效的联邦学习安全聚合协议，结合了多密钥CKKS同态加密和ECDH掩码技术，将安全聚合简化为单轮非交互传输，适用于物联网环境。


<details>
  <summary>Details</summary>
Motivation: 联邦学习在物联网环境中面临通信开销大的挑战，传统安全聚合协议需要多轮交互、大负载和每个客户端的高成本，不适合边缘部署。

Method: Hyb-Agg协议整合了多密钥CKKS同态加密和基于椭圆曲线Diffie-Hellman的加法掩码技术，将安全聚合过程简化为每轮单次非交互式客户端到服务器传输。

Result: 在包括树莓派4在内的设备上实现和评估，Hyb-Agg提供亚秒级执行时间，通信扩展因子约为明文大小的12倍，且保持恒定。

Conclusion: Hyb-Agg通过解决通信瓶颈，实现了可扩展、隐私保护的联邦学习，适用于实际物联网部署。

Abstract: Federated Learning (FL) offers a promising approach to collaboratively train machine learning models without centralizing raw data, yet its scalability is often throttled by excessive communication overhead. This challenge is magnified in Internet of Things (IoT) environments, where devices face stringent bandwidth, latency, and energy constraints. Conventional secure aggregation protocols, while essential for protecting model updates, frequently require multiple interaction rounds, large payload sizes, and per-client costs rendering them impractical for many edge deployments.
  In this work, we present Hyb-Agg, a lightweight and communication-efficient secure aggregation protocol that integrates Multi-Key CKKS (MK-CKKS) homomorphic encryption with Elliptic Curve Diffie-Hellman (ECDH)-based additive masking. Hyb-Agg reduces the secure aggregation process to a single, non-interactive client-to-server transmission per round, ensuring that per-client communication remains constant regardless of the number of participants. This design eliminates partial decryption exchanges, preserves strong privacy under the RLWE, CDH, and random oracle assumptions, and maintains robustness against collusion by the server and up to $N-2$ clients.
  We implement and evaluate Hyb-Agg on both high-performance and resource-constrained devices, including a Raspberry Pi 4, demonstrating that it delivers sub-second execution times while achieving a constant communication expansion factor of approximately 12x over plaintext size. By directly addressing the communication bottleneck, Hyb-Agg enables scalable, privacy-preserving federated learning that is practical for real-world IoT deployments.

</details>


### [33] [FedSGT: Exact Federated Unlearning via Sequential Group-based Training](https://arxiv.org/abs/2511.23393)
*Bokang Zhang,Hong Guan,Hong kyu Lee,Ruixuan Liu,Jia Zou,Li Xiong*

Main category: cs.CR

TL;DR: FedSGT：联邦学习中的精确遗忘框架，通过分组训练和参数高效微调模块实现即时遗忘，减少重训练需求


<details>
  <summary>Details</summary>
Motivation: 联邦学习支持隐私保护的协同训练，但实现"被遗忘权"面临挑战，现有精确遗忘方法需要频繁从头重训练，导致高通信成本和长服务停机时间

Method: 提出FedSGT框架：1) 将数据划分为均匀组，每个客户端可参与多个组；2) 训练多个参数高效微调(PEFT)模块序列，每个对应不同的组排列；3) 通过停用包含待遗忘数据组对应的模块实现即时精确遗忘

Result: 在各种任务上的实验表明，FedSGT在多次遗忘请求下显著延长服务维护时间，同时保持与其他精确遗忘基线相当的学习性能和训练效率

Conclusion: FedSGT通过分组训练和轻量级PEFT模块，实现了联邦学习中的高效精确遗忘，平衡了遗忘效率、模型效用和通信开销

Abstract: Federated Learning (FL) enables collaborative, privacy-preserving model training, but supporting the "Right to be Forgotten" is especially challenging because data influences the model through distributed and interleaved client updates. Existing exact unlearning methods typically require frequent retraining from scratch, resulting in high communication cost and long service downtime. To address this, we propose Federated Sequential Group-based Training (FedSGT), an exact unlearning framework for FL. FedSGT partitions the data into uniform groups, and each client may participate in multiple groups. To control communication overhead, each client can limit the number of groups it contributes to. FedSGT then trains multiple sequences of Parameter-Efficient Fine-Tuning (PEFT) modules, each corresponding to a different group permutation. Since the PEFT modules are lightweight and maintained server-side, FedSGT isolates the influence of different data groups into independent modules without incurring significant storage overhead and communication cost. Exact unlearning is thus achieved instantly by deactivating the modules corresponding to the group containing the unlearned data. Furthermore, using multiple training sequences helps maintain high model utility as deletion requests accumulate. We provide a rigorous theoretical analysis of both the deletion rate -- expected number of deletions before retraining is needed -- and the expected model performance. Experiments on various tasks demonstrate that FedSGT achieves a significantly longer service maintenance under multiple unlearning requests while maintaining comparable learning performance and training efficiency to other exact unlearning baselines. Extensive ablation studies validate the robustness of our method across a wide range of parameter settings.

</details>


### [34] [Evaluating LLMs for One-Shot Patching of Real and Artificial Vulnerabilities](https://arxiv.org/abs/2511.23408)
*Aayush Garg,Zanis Ali Khan,Renzo Degiovanni,Qiang Tang*

Main category: cs.CR

TL;DR: LLMs在真实漏洞修补上表现优于人工漏洞，不同模型在漏洞覆盖上存在显著差异和互补性


<details>
  <summary>Details</summary>
Motivation: 现有研究主要评估LLMs在公开漏洞上的修补能力，但对其在相关人工漏洞上的效果缺乏探索，需要全面评估LLMs在真实和人工漏洞上的修补效果和互补性

Method: 使用OpenAI GPT变体、LLaMA、DeepSeek和Mistral等多个主流LLMs，通过PoV（Proof-of-Vulnerability）测试执行来具体评估LLM生成的源代码是否成功修补漏洞

Result: LLMs修补真实漏洞比人工漏洞更有效；不同LLMs在漏洞覆盖上存在显著差异，既有重叠修补（多个模型修补相同漏洞），也有互补性（某些漏洞仅被单个模型修补）

Conclusion: 选择合适的LLMs对于有效漏洞修补至关重要，不同模型在漏洞覆盖上具有互补性，需要根据具体需求选择适当的模型

Abstract: Automated vulnerability patching is crucial for software security, and recent advancements in Large Language Models (LLMs) present promising capabilities for automating this task. However, existing research has primarily assessed LLMs using publicly disclosed vulnerabilities, leaving their effectiveness on related artificial vulnerabilities largely unexplored. In this study, we empirically evaluate the patching effectiveness and complementarity of several prominent LLMs, such as OpenAI's GPT variants, LLaMA, DeepSeek, and Mistral models, using both real and artificial vulnerabilities. Our evaluation employs Proof-of-Vulnerability (PoV) test execution to concretely assess whether LLM-generated source code successfully patches vulnerabilities. Our results reveal that LLMs patch real vulnerabilities more effectively compared to artificial ones. Additionally, our analysis reveals significant variability across LLMs in terms of overlapping (multiple LLMs patching the same vulnerabilities) and complementarity (vulnerabilities patched exclusively by a single LLM), emphasizing the importance of selecting appropriate LLMs for effective vulnerability patching.

</details>
