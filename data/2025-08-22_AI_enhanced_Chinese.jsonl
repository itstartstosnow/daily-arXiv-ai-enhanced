{"id": "2508.14925", "categories": ["cs.CR", "cs.LG"], "pdf": "https://arxiv.org/pdf/2508.14925", "abs": "https://arxiv.org/abs/2508.14925", "authors": ["Zhiqiang Wang", "Yichao Gao", "Yanting Wang", "Suyuan Liu", "Haifeng Sun", "Haoran Cheng", "Guanquan Shi", "Haohua Du", "Xiangyang Li"], "title": "MCPTox: A Benchmark for Tool Poisoning Attack on Real-World MCP Servers", "comment": null, "summary": "By providing a standardized interface for LLM agents to interact with\nexternal tools, the Model Context Protocol (MCP) is quickly becoming a\ncornerstone of the modern autonomous agent ecosystem. However, it creates novel\nattack surfaces due to untrusted external tools. While prior work has focused\non attacks injected through external tool outputs, we investigate a more\nfundamental vulnerability: Tool Poisoning, where malicious instructions are\nembedded within a tool's metadata without execution. To date, this threat has\nbeen primarily demonstrated through isolated cases, lacking a systematic,\nlarge-scale evaluation.\n  We introduce MCPTox, the first benchmark to systematically evaluate agent\nrobustness against Tool Poisoning in realistic MCP settings. MCPTox is\nconstructed upon 45 live, real-world MCP servers and 353 authentic tools. To\nachieve this, we design three distinct attack templates to generate a\ncomprehensive suite of 1312 malicious test cases by few-shot learning, covering\n10 categories of potential risks. Our evaluation on 20 prominent LLM agents\nsetting reveals a widespread vulnerability to Tool Poisoning, with o1-mini,\nachieving an attack success rate of 72.8\\%. We find that more capable models\nare often more susceptible, as the attack exploits their superior\ninstruction-following abilities. Finally, the failure case analysis reveals\nthat agents rarely refuse these attacks, with the highest refused rate\n(Claude-3.7-Sonnet) less than 3\\%, demonstrating that existing safety alignment\nis ineffective against malicious actions that use legitimate tools for\nunauthorized operation. Our findings create a crucial empirical baseline for\nunderstanding and mitigating this widespread threat, and we release MCPTox for\nthe development of verifiably safer AI agents. Our dataset is available at an\nanonymized repository: \\textit{https://anonymous.4open.science/r/AAAI26-7C02}.", "AI": {"tldr": "MCPTox\u57fa\u51c6\u6d4b\u8bd5\u7cfb\u7edf\u8bc4\u4f30\u4e86LLM\u4ee3\u7406\u5bf9\u5de5\u5177\u6295\u6bd2\u653b\u51fb\u7684\u8106\u5f31\u6027\uff0c\u53d1\u73b0\u4e3b\u6d41\u4ee3\u7406\u666e\u904d\u6613\u53d7\u653b\u51fb\uff0c\u653b\u51fb\u6210\u529f\u7387\u9ad8\u8fbe72.8%\uff0c\u73b0\u6709\u5b89\u5168\u5bf9\u9f50\u673a\u5236\u5bf9\u6b64\u7c7b\u653b\u51fb\u65e0\u6548\u3002", "motivation": "Model Context Protocol (MCP)\u4e3aLLM\u4ee3\u7406\u63d0\u4f9b\u4e86\u4e0e\u5916\u90e8\u5de5\u5177\u4ea4\u4e92\u7684\u6807\u51c6\u63a5\u53e3\uff0c\u4f46\u540c\u65f6\u4e5f\u5f15\u5165\u4e86\u65b0\u7684\u653b\u51fb\u9762\u3002\u73b0\u6709\u7814\u7a76\u4e3b\u8981\u5173\u6ce8\u901a\u8fc7\u5de5\u5177\u8f93\u51fa\u6ce8\u5165\u7684\u653b\u51fb\uff0c\u800c\u5ffd\u7565\u4e86\u66f4\u57fa\u672c\u7684\u6f0f\u6d1e\uff1a\u5de5\u5177\u6295\u6bd2\u653b\u51fb\uff0c\u5373\u5728\u5de5\u5177\u5143\u6570\u636e\u4e2d\u5d4c\u5165\u6076\u610f\u6307\u4ee4\u800c\u4e0d\u9700\u8981\u6267\u884c\u3002", "method": "\u6784\u5efaMCPTox\u57fa\u51c6\u6d4b\u8bd5\uff0c\u57fa\u4e8e45\u4e2a\u771f\u5b9eMCP\u670d\u52a1\u5668\u548c353\u4e2a\u771f\u5b9e\u5de5\u5177\uff0c\u8bbe\u8ba1\u4e09\u79cd\u653b\u51fb\u6a21\u677f\uff0c\u901a\u8fc7\u5c11\u6837\u672c\u5b66\u4e60\u751f\u62101312\u4e2a\u6076\u610f\u6d4b\u8bd5\u7528\u4f8b\uff0c\u8986\u76d610\u4e2a\u98ce\u9669\u7c7b\u522b\uff0c\u572820\u4e2a\u4e3b\u6d41LLM\u4ee3\u7406\u4e0a\u8fdb\u884c\u8bc4\u4f30\u3002", "result": "\u8bc4\u4f30\u663e\u793a\u4ee3\u7406\u666e\u904d\u6613\u53d7\u5de5\u5177\u6295\u6bd2\u653b\u51fb\uff0co1-mini\u653b\u51fb\u6210\u529f\u7387\u9ad8\u8fbe72.8%\u3002\u66f4\u6709\u80fd\u529b\u7684\u6a21\u578b\u5f80\u5f80\u66f4\u6613\u53d7\u653b\u51fb\uff0c\u56e0\u4e3a\u653b\u51fb\u5229\u7528\u4e86\u5176\u4f18\u8d8a\u7684\u6307\u4ee4\u9075\u5faa\u80fd\u529b\u3002\u73b0\u6709\u5b89\u5168\u5bf9\u9f50\u673a\u5236\u51e0\u4e4e\u65e0\u6548\uff0c\u6700\u9ad8\u62d2\u7edd\u7387(Claude-3.7-Sonnet)\u4e0d\u52303%\u3002", "conclusion": "\u5de5\u5177\u6295\u6bd2\u653b\u51fb\u662f\u4e00\u4e2a\u5e7f\u6cdb\u5b58\u5728\u7684\u5a01\u80c1\uff0c\u73b0\u6709\u5b89\u5168\u63aa\u65bd\u5bf9\u6b64\u7c7b\u653b\u51fb\u65e0\u6548\u3002MCPTox\u4e3a\u7406\u89e3\u548c\u7f13\u89e3\u8fd9\u4e00\u5a01\u80c1\u63d0\u4f9b\u4e86\u91cd\u8981\u7684\u5b9e\u8bc1\u57fa\u51c6\uff0c\u5e76\u53ef\u7528\u4e8e\u5f00\u53d1\u53ef\u9a8c\u8bc1\u66f4\u5b89\u5168\u7684AI\u4ee3\u7406\u3002"}}
{"id": "2508.15031", "categories": ["cs.CR", "cs.AI", "cs.LG"], "pdf": "https://arxiv.org/pdf/2508.15031", "abs": "https://arxiv.org/abs/2508.15031", "authors": ["Kaixiang Zhao", "Lincan Li", "Kaize Ding", "Neil Zhenqiang Gong", "Yue Zhao", "Yushun Dong"], "title": "A Systematic Survey of Model Extraction Attacks and Defenses: State-of-the-Art and Perspectives", "comment": null, "summary": "Machine learning (ML) models have significantly grown in complexity and\nutility, driving advances across multiple domains. However, substantial\ncomputational resources and specialized expertise have historically restricted\ntheir wide adoption. Machine-Learning-as-a-Service (MLaaS) platforms have\naddressed these barriers by providing scalable, convenient, and affordable\naccess to sophisticated ML models through user-friendly APIs. While this\naccessibility promotes widespread use of advanced ML capabilities, it also\nintroduces vulnerabilities exploited through Model Extraction Attacks (MEAs).\nRecent studies have demonstrated that adversaries can systematically replicate\na target model's functionality by interacting with publicly exposed interfaces,\nposing threats to intellectual property, privacy, and system security. In this\npaper, we offer a comprehensive survey of MEAs and corresponding defense\nstrategies. We propose a novel taxonomy that classifies MEAs according to\nattack mechanisms, defense approaches, and computing environments. Our analysis\ncovers various attack techniques, evaluates their effectiveness, and highlights\nchallenges faced by existing defenses, particularly the critical trade-off\nbetween preserving model utility and ensuring security. We further assess MEAs\nwithin different computing paradigms and discuss their technical, ethical,\nlegal, and societal implications, along with promising directions for future\nresearch. This systematic survey aims to serve as a valuable reference for\nresearchers, practitioners, and policymakers engaged in AI security and\nprivacy. Additionally, we maintain an online repository continuously updated\nwith related literature at https://github.com/kzhao5/ModelExtractionPapers.", "AI": {"tldr": "\u5bf9\u6a21\u578b\u63d0\u53d6\u653b\u51fb(MEAs)\u53ca\u5176\u9632\u5fa1\u7b56\u7565\u7684\u5168\u9762\u8c03\u67e5\uff0c\u63d0\u51fa\u4e86\u65b0\u7684\u5206\u7c7b\u6cd5\uff0c\u5206\u6790\u4e86\u653b\u51fb\u6280\u672f\u3001\u9632\u5fa1\u6311\u6218\u548c\u4e0d\u540c\u8ba1\u7b97\u73af\u5883\u4e0b\u7684\u5f71\u54cd", "motivation": "\u673a\u5668\u5b66\u4e60\u5373\u670d\u52a1(MLaaS)\u5e73\u53f0\u7684\u666e\u53ca\u4f7f\u5f97\u9ad8\u7ea7ML\u6a21\u578b\u66f4\u6613\u8bbf\u95ee\uff0c\u4f46\u4e5f\u5f15\u5165\u4e86\u6a21\u578b\u63d0\u53d6\u653b\u51fb\u7684\u6f0f\u6d1e\uff0c\u5a01\u80c1\u77e5\u8bc6\u4ea7\u6743\u3001\u9690\u79c1\u548c\u7cfb\u7edf\u5b89\u5168", "method": "\u63d0\u51fa\u65b0\u7684\u5206\u7c7b\u6cd5\uff0c\u6839\u636e\u653b\u51fb\u673a\u5236\u3001\u9632\u5fa1\u65b9\u6cd5\u548c\u8ba1\u7b97\u73af\u5883\u5bf9MEAs\u8fdb\u884c\u5206\u7c7b\uff0c\u5206\u6790\u5404\u79cd\u653b\u51fb\u6280\u672f\u7684\u6709\u6548\u6027\uff0c\u8bc4\u4f30\u73b0\u6709\u9632\u5fa1\u9762\u4e34\u7684\u6311\u6218", "result": "\u7cfb\u7edf\u6027\u5730\u8c03\u67e5\u4e86MEAs\u548c\u9632\u5fa1\u7b56\u7565\uff0c\u5f3a\u8c03\u4e86\u6a21\u578b\u6548\u7528\u4e0e\u5b89\u5168\u6027\u4e4b\u95f4\u7684\u5173\u952e\u6743\u8861\uff0c\u8bc4\u4f30\u4e86\u4e0d\u540c\u8ba1\u7b97\u8303\u5f0f\u4e0b\u7684\u6280\u672f\u3001\u4f26\u7406\u3001\u6cd5\u5f8b\u548c\u793e\u4f1a\u5f71\u54cd", "conclusion": "\u8be5\u8c03\u67e5\u4e3aAI\u5b89\u5168\u548c\u9690\u79c1\u9886\u57df\u7684\u7814\u7a76\u8005\u3001\u4ece\u4e1a\u8005\u548c\u653f\u7b56\u5236\u5b9a\u8005\u63d0\u4f9b\u4e86\u6709\u4ef7\u503c\u7684\u53c2\u8003\uff0c\u5e76\u7ef4\u62a4\u4e86\u6301\u7eed\u66f4\u65b0\u7684\u5728\u7ebf\u6587\u732e\u5e93"}}
{"id": "2508.15036", "categories": ["cs.CR", "cs.AI"], "pdf": "https://arxiv.org/pdf/2508.15036", "abs": "https://arxiv.org/abs/2508.15036", "authors": ["Ruyi Ding", "Tianhong Xu", "Xinyi Shen", "Aidong Adam Ding", "Yunsi Fei"], "title": "MoEcho: Exploiting Side-Channel Attacks to Compromise User Privacy in Mixture-of-Experts LLMs", "comment": "This paper will appear in CCS 2025", "summary": "The transformer architecture has become a cornerstone of modern AI, fueling\nremarkable progress across applications in natural language processing,\ncomputer vision, and multimodal learning. As these models continue to scale\nexplosively for performance, implementation efficiency remains a critical\nchallenge. Mixture of Experts (MoE) architectures, selectively activating\nspecialized subnetworks (experts), offer a unique balance between model\naccuracy and computational cost. However, the adaptive routing in MoE\narchitectures, where input tokens are dynamically directed to specialized\nexperts based on their semantic meaning inadvertently opens up a new attack\nsurface for privacy breaches. These input-dependent activation patterns leave\ndistinctive temporal and spatial traces in hardware execution, which\nadversaries could exploit to deduce sensitive user data. In this work, we\npropose MoEcho, discovering a side channel analysis based attack surface that\ncompromises user privacy on MoE based systems. Specifically, in MoEcho, we\nintroduce four novel architectural side channels on different computing\nplatforms, including Cache Occupancy Channels and Pageout+Reload on CPUs, and\nPerformance Counter and TLB Evict+Reload on GPUs, respectively. Exploiting\nthese vulnerabilities, we propose four attacks that effectively breach user\nprivacy in large language models (LLMs) and vision language models (VLMs) based\non MoE architectures: Prompt Inference Attack, Response Reconstruction Attack,\nVisual Inference Attack, and Visual Reconstruction Attack. MoEcho is the first\nruntime architecture level security analysis of the popular MoE structure\ncommon in modern transformers, highlighting a serious security and privacy\nthreat and calling for effective and timely safeguards when harnessing MoE\nbased models for developing efficient large scale AI services.", "AI": {"tldr": "MoEcho\u53d1\u73b0\u5e76\u5229\u7528MoE\u67b6\u6784\u4e2d\u7684\u4fa7\u4fe1\u9053\u6f0f\u6d1e\uff0c\u901a\u8fc7CPU\u548cGPU\u7684\u56db\u79cd\u65b0\u578b\u4fa7\u4fe1\u9053\u653b\u51fb\uff0c\u80fd\u591f\u4ece\u6fc0\u6d3b\u6a21\u5f0f\u63a8\u65ad\u7528\u6237\u8f93\u5165\u7684\u654f\u611f\u4fe1\u606f\uff0c\u5bf9\u57fa\u4e8eMoE\u7684LLM\u548cVLM\u6784\u6210\u4e25\u91cd\u9690\u79c1\u5a01\u80c1\u3002", "motivation": "\u968f\u7740MoE\u67b6\u6784\u5728Transformer\u6a21\u578b\u4e2d\u7684\u5e7f\u6cdb\u5e94\u7528\uff0c\u5176\u57fa\u4e8e\u8bed\u4e49\u7684\u52a8\u6001\u8def\u7531\u673a\u5236\u867d\u7136\u63d0\u9ad8\u4e86\u6548\u7387\uff0c\u4f46\u4e5f\u4ea7\u751f\u4e86\u65b0\u7684\u653b\u51fb\u9762\u3002\u8f93\u5165\u4f9d\u8d56\u7684\u6fc0\u6d3b\u6a21\u5f0f\u5728\u786c\u4ef6\u6267\u884c\u4e2d\u7559\u4e0b\u53ef\u89c2\u6d4b\u7684\u75d5\u8ff9\uff0c\u53ef\u80fd\u88ab\u653b\u51fb\u8005\u5229\u7528\u6765\u63a8\u65ad\u654f\u611f\u7528\u6237\u6570\u636e\u3002", "method": "\u63d0\u51fa\u4e86\u56db\u79cd\u65b0\u578b\u67b6\u6784\u4fa7\u4fe1\u9053\uff1aCPU\u4e0a\u7684\u7f13\u5b58\u5360\u7528\u4fe1\u9053\u548cPageout+Reload\uff0cGPU\u4e0a\u7684\u6027\u80fd\u8ba1\u6570\u5668\u548cTLB Evict+Reload\u3002\u5229\u7528\u8fd9\u4e9b\u6f0f\u6d1e\u8bbe\u8ba1\u4e86\u56db\u79cd\u653b\u51fb\u65b9\u6cd5\uff1a\u63d0\u793a\u63a8\u65ad\u653b\u51fb\u3001\u54cd\u5e94\u91cd\u6784\u653b\u51fb\u3001\u89c6\u89c9\u63a8\u65ad\u653b\u51fb\u548c\u89c6\u89c9\u91cd\u6784\u653b\u51fb\u3002", "result": "\u6210\u529f\u5728\u57fa\u4e8eMoE\u67b6\u6784\u7684\u5927\u578b\u8bed\u8a00\u6a21\u578b\u548c\u89c6\u89c9\u8bed\u8a00\u6a21\u578b\u4e0a\u5b9e\u73b0\u4e86\u9690\u79c1\u6cc4\u9732\u653b\u51fb\uff0c\u8bc1\u660e\u4e86MoE\u67b6\u6784\u5b58\u5728\u7684\u4e25\u91cd\u5b89\u5168\u6f0f\u6d1e\u3002", "conclusion": "\u8fd9\u662f\u5bf9\u73b0\u4ee3Transformer\u4e2d\u6d41\u884c\u7684MoE\u7ed3\u6784\u7684\u9996\u6b21\u8fd0\u884c\u65f6\u67b6\u6784\u7ea7\u5b89\u5168\u5206\u6790\uff0c\u63ed\u793a\u4e86\u4e25\u91cd\u7684\u5b89\u5168\u9690\u79c1\u5a01\u80c1\uff0c\u547c\u5401\u5728\u5f00\u53d1\u9ad8\u6548\u5927\u89c4\u6a21AI\u670d\u52a1\u65f6\u91c7\u53d6\u53ca\u65f6\u6709\u6548\u7684\u9632\u62a4\u63aa\u65bd\u3002"}}
{"id": "2508.15042", "categories": ["cs.CR"], "pdf": "https://arxiv.org/pdf/2508.15042", "abs": "https://arxiv.org/abs/2508.15042", "authors": ["Sima Arasteh", "Christophe Hauser"], "title": "When Machine Learning Meets Vulnerability Discovery: Challenges and Lessons Learned", "comment": null, "summary": "In recent years, machine learning has demonstrated impressive results in\nvarious fields, including software vulnerability detection. Nonetheless, using\nmachine learning to identify software vulnerabilities presents new challenges,\nespecially regarding the scale of data involved, which was not a factor in\ntraditional methods. Consequently, in spite of the rise of new\nmachine-learning-based approaches in that space, important shortcomings persist\nregarding their evaluation. First, researchers often fail to provide concrete\nstatistics about their training datasets, such as the number of samples for\neach type of vulnerability. Moreover, many methods rely on training with\nsemantically similar functions rather than directly on vulnerable programs.\nThis leads to uncertainty about the suitability of the datasets currently used\nfor training. Secondly, the choice of a model and the level of granularity at\nwhich models are trained also affect the effectiveness of such vulnerability\ndiscovery approaches.\n  In this paper, we explore the challenges of applying machine learning to\nvulnerability discovery. We also share insights from our two previous research\npapers, Bin2vec and BinHunter, which could enhance future research in this\nfield.", "AI": {"tldr": "\u672c\u6587\u63a2\u8ba8\u4e86\u673a\u5668\u5b66\u4e60\u5728\u8f6f\u4ef6\u6f0f\u6d1e\u68c0\u6d4b\u5e94\u7528\u4e2d\u7684\u6311\u6218\uff0c\u7279\u522b\u662f\u6570\u636e\u96c6\u89c4\u6a21\u3001\u8bc4\u4f30\u65b9\u6cd5\u548c\u6a21\u578b\u9009\u62e9\u65b9\u9762\u7684\u95ee\u9898\uff0c\u5e76\u5206\u4eab\u4e86\u4f5c\u8005\u5148\u524d\u7814\u7a76\u7684\u89c1\u89e3\u3002", "motivation": "\u673a\u5668\u5b66\u4e60\u5728\u8f6f\u4ef6\u6f0f\u6d1e\u68c0\u6d4b\u4e2d\u5c55\u73b0\u51fa\u6f5c\u529b\uff0c\u4f46\u9762\u4e34\u6570\u636e\u89c4\u6a21\u3001\u8bc4\u4f30\u6807\u51c6\u548c\u65b9\u6cd5\u9002\u7528\u6027\u7b49\u65b0\u6311\u6218\uff0c\u9700\u8981\u7cfb\u7edf\u6027\u5730\u5206\u6790\u548c\u6539\u8fdb\u73b0\u6709\u65b9\u6cd5\u3002", "method": "\u901a\u8fc7\u5206\u6790\u673a\u5668\u5b66\u4e60\u5728\u6f0f\u6d1e\u53d1\u73b0\u4e2d\u7684\u5e94\u7528\u6311\u6218\uff0c\u7ed3\u5408\u4f5c\u8005\u5148\u524d\u5f00\u53d1\u7684Bin2vec\u548cBinHunter\u4e24\u4e2a\u7814\u7a76\u9879\u76ee\u7684\u7ecf\u9a8c\u6559\u8bad\uff0c\u63d0\u51fa\u6539\u8fdb\u5efa\u8bae\u3002", "result": "\u8bc6\u522b\u51fa\u73b0\u6709\u673a\u5668\u5b66\u4e60\u6f0f\u6d1e\u68c0\u6d4b\u65b9\u6cd5\u5728\u6570\u636e\u96c6\u7edf\u8ba1\u900f\u660e\u5ea6\u3001\u8bad\u7ec3\u6570\u636e\u9002\u7528\u6027\u548c\u6a21\u578b\u7c92\u5ea6\u9009\u62e9\u7b49\u65b9\u9762\u7684\u91cd\u8981\u7f3a\u9677\u3002", "conclusion": "\u673a\u5668\u5b66\u4e60\u5728\u8f6f\u4ef6\u6f0f\u6d1e\u68c0\u6d4b\u9886\u57df\u9700\u8981\u66f4\u4e25\u8c28\u7684\u6570\u636e\u96c6\u6784\u5efa\u3001\u66f4\u900f\u660e\u7684\u8bc4\u4f30\u6807\u51c6\u4ee5\u53ca\u66f4\u5408\u9002\u7684\u6a21\u578b\u7c92\u5ea6\u9009\u62e9\uff0c\u4f5c\u8005\u7684\u524d\u671f\u7814\u7a76\u4e3a\u6b64\u63d0\u4f9b\u4e86\u6709\u4ef7\u503c\u7684\u89c1\u89e3\u3002"}}
{"id": "2508.15089", "categories": ["cs.CR"], "pdf": "https://arxiv.org/pdf/2508.15089", "abs": "https://arxiv.org/abs/2508.15089", "authors": ["Arun Ganesh"], "title": "Tighter Privacy Analysis for Truncated Poisson Sampling", "comment": null, "summary": "We give a new privacy amplification analysis for truncated Poisson sampling,\na Poisson sampling variant that truncates a batch if it exceeds a given maximum\nbatch size.", "AI": {"tldr": "\u5173\u4e8e\u622a\u65ad\u6cca\u677e\u91c7\u6837\u7684\u65b0\u9690\u79c1\u653e\u5927\u5206\u6790", "motivation": "\u7814\u7a76\u622a\u65ad\u6cca\u677e\u91c7\u6837\uff08\u4e00\u79cd\u5728\u6279\u91cf\u8d85\u8fc7\u6700\u5927\u6279\u91cf\u5927\u5c0f\u65f6\u8fdb\u884c\u622a\u65ad\u7684\u6cca\u677e\u91c7\u6837\u53d8\u4f53\uff09\u7684\u9690\u79c1\u4fdd\u62a4\u7279\u6027\uff0c\u65e8\u5728\u63d0\u4f9b\u66f4\u7cbe\u786e\u7684\u9690\u79c1\u653e\u5927\u5206\u6790", "method": "\u63d0\u51fa\u65b0\u7684\u5206\u6790\u65b9\u6cd5\u6765\u5206\u6790\u622a\u65ad\u6cca\u677e\u91c7\u6837\u7684\u9690\u79c1\u653e\u5927\u6548\u679c\uff0c\u8be5\u65b9\u6cd5\u8003\u8651\u4e86\u6279\u91cf\u622a\u65ad\u5bf9\u9690\u79c1\u4fdd\u62a4\u7684\u5f71\u54cd", "result": "\u83b7\u5f97\u4e86\u622a\u65ad\u6cca\u677e\u91c7\u6837\u7684\u6539\u8fdb\u9690\u79c1\u4fdd\u8bc1\uff0c\u63d0\u4f9b\u4e86\u66f4\u7d27\u81f4\u7684\u9690\u79c1\u653e\u5927\u8fb9\u754c", "conclusion": "\u65b0\u7684\u5206\u6790\u6846\u67b6\u4e3a\u622a\u65ad\u6cca\u677e\u91c7\u6837\u63d0\u4f9b\u4e86\u66f4\u597d\u7684\u9690\u79c1\u4fdd\u62a4\u7406\u8bba\u4fdd\u8bc1\uff0c\u6709\u52a9\u4e8e\u5728\u5b9e\u9645\u5dee\u5206\u9690\u79c1\u5e94\u7528\u4e2d\u66f4\u6709\u6548\u5730\u4f7f\u7528\u8fd9\u79cd\u91c7\u6837\u65b9\u6cd5"}}
{"id": "2508.15100", "categories": ["cs.CR", "cs.LG"], "pdf": "https://arxiv.org/pdf/2508.15100", "abs": "https://arxiv.org/abs/2508.15100", "authors": ["Ehssan Mousavipour", "Andrey Dimanchev", "Majid Ghaderi"], "title": "Adaptive Anomaly Detection in Evolving Network Environments", "comment": null, "summary": "Distribution shift, a change in the statistical properties of data over time,\nposes a critical challenge for deep learning anomaly detection systems.\nExisting anomaly detection systems often struggle to adapt to these shifts.\nSpecifically, systems based on supervised learning require costly manual\nlabeling, while those based on unsupervised learning rely on clean data, which\nis difficult to obtain, for shift adaptation. Both of these requirements are\nchallenging to meet in practice. In this paper, we introduce NetSight, a\nframework for supervised anomaly detection in network data that continually\ndetects and adapts to distribution shifts in an online manner. NetSight\neliminates manual intervention through a novel pseudo-labeling technique and\nuses a knowledge distillation-based adaptation strategy to prevent catastrophic\nforgetting. Evaluated on three long-term network datasets, NetSight\ndemonstrates superior adaptation performance compared to state-of-the-art\nmethods that rely on manual labeling, achieving F1-score improvements of up to\n11.72%. This proves its robustness and effectiveness in dynamic networks that\nexperience distribution shifts over time.", "AI": {"tldr": "NetSight\u662f\u4e00\u4e2a\u7528\u4e8e\u7f51\u7edc\u6570\u636e\u5f02\u5e38\u68c0\u6d4b\u7684\u76d1\u7763\u5b66\u4e60\u6846\u67b6\uff0c\u80fd\u591f\u5728\u7ebf\u6301\u7eed\u68c0\u6d4b\u548c\u9002\u5e94\u5206\u5e03\u504f\u79fb\uff0c\u65e0\u9700\u4eba\u5de5\u5e72\u9884\uff0c\u901a\u8fc7\u4f2a\u6807\u7b7e\u6280\u672f\u548c\u77e5\u8bc6\u84b8\u998f\u9632\u6b62\u707e\u96be\u6027\u9057\u5fd8\uff0c\u5728\u4e09\u4e2a\u957f\u671f\u7f51\u7edc\u6570\u636e\u96c6\u4e0a\u8868\u73b0\u4f18\u4e8e\u73b0\u6709\u65b9\u6cd5\u3002", "motivation": "\u5206\u5e03\u504f\u79fb\u662f\u6df1\u5ea6\u5b66\u4e60\u5f02\u5e38\u68c0\u6d4b\u7cfb\u7edf\u9762\u4e34\u7684\u5173\u952e\u6311\u6218\uff0c\u73b0\u6709\u65b9\u6cd5\u8981\u4e48\u9700\u8981\u6602\u8d35\u7684\u4eba\u5de5\u6807\u6ce8\uff0c\u8981\u4e48\u4f9d\u8d56\u96be\u4ee5\u83b7\u53d6\u7684\u5e72\u51c0\u6570\u636e\u6765\u8fdb\u884c\u504f\u79fb\u9002\u5e94\uff0c\u8fd9\u4e9b\u8981\u6c42\u5728\u73b0\u5b9e\u4e2d\u90fd\u96be\u4ee5\u6ee1\u8db3\u3002", "method": "NetSight\u91c7\u7528\u65b0\u9896\u7684\u4f2a\u6807\u7b7e\u6280\u672f\u6d88\u9664\u4eba\u5de5\u5e72\u9884\uff0c\u5e76\u4f7f\u7528\u57fa\u4e8e\u77e5\u8bc6\u84b8\u998f\u7684\u9002\u5e94\u7b56\u7565\u6765\u9632\u6b62\u707e\u96be\u6027\u9057\u5fd8\uff0c\u5b9e\u73b0\u5728\u7ebf\u6301\u7eed\u68c0\u6d4b\u548c\u9002\u5e94\u5206\u5e03\u504f\u79fb\u3002", "result": "\u5728\u4e09\u4e2a\u957f\u671f\u7f51\u7edc\u6570\u636e\u96c6\u4e0a\u7684\u8bc4\u4f30\u663e\u793a\uff0cNetSight\u76f8\u6bd4\u4f9d\u8d56\u4eba\u5de5\u6807\u6ce8\u7684\u6700\u5148\u8fdb\u65b9\u6cd5\u5177\u6709\u4f18\u8d8a\u7684\u9002\u5e94\u6027\u80fd\uff0cF1\u5206\u6570\u63d0\u5347\u9ad8\u8fbe11.72%\u3002", "conclusion": "NetSight\u8bc1\u660e\u4e86\u5176\u5728\u7ecf\u5386\u5206\u5e03\u504f\u79fb\u7684\u52a8\u6001\u7f51\u7edc\u4e2d\u5177\u6709\u9c81\u68d2\u6027\u548c\u6709\u6548\u6027\uff0c\u80fd\u591f\u6709\u6548\u89e3\u51b3\u5206\u5e03\u504f\u79fb\u5e26\u6765\u7684\u6311\u6218\u3002"}}
{"id": "2508.15172", "categories": ["cs.CR"], "pdf": "https://arxiv.org/pdf/2508.15172", "abs": "https://arxiv.org/abs/2508.15172", "authors": ["Zheng Li", "Xiaoyang Dong", "Xiaoyun Wang"], "title": "Conditional Cube Attack on Round-Reduced ASCON", "comment": null, "summary": "This paper evaluates the secure level of authenticated encryption\n\\textsc{Ascon} against cube-like method. \\textsc{Ascon} submitted by Dobraunig\n\\emph{et~al.} is one of 16 survivors of the 3rd round CAESAR competition. The\ncube-like method is first used by Dinur \\emph{et~al.} to analyze Keccak keyed\nmodes. At CT-RSA 2015, Dobraunig \\emph{et~al.} applied this method to 5/6-round\nreduced \\textsc{Ascon}, whose structure is similar to Keccak keyed modes.\nHowever, for \\textsc{Ascon} the non-linear layer is more complex and state is\nmuch smaller, which make it hard for the attackers to select enough cube\nvariables that do not multiply with each other after the first round. This\nseems to be the reason why the best previous key-recovery attack is on 6-round\n\\textsc{Ascon}, while for Keccak keyed modes (Keccak-MAC and Keyak) the\nattacked round is no less than 7-round.\n  In this paper, we generalize the conditional cube attack proposed by Huang\n\\emph{et~al.}, and find new cubes depending on some key bit conditions for\n5/6-round reduced \\textsc{Ascon}, and translate the previous theoretic 6-round\nattack with $2^{66}$ time complexity to a practical one with $2^{40}$ time\ncomplexity. Moreover, we propose the first 7-round key-recovery attack on\n\\textsc{Ascon}. By introducing \\emph{the cube-like key-subset technique}, we\ndivide the full key space into many subsets according to different key\nconditions. For each key subset, we launch the cube tester to determine if the\nkey falls into it. Finally, we recover the full key space by testing all the\nkey subsets. The total time complexity is about $2^{103.9}$. In addition, for a\nweak-key subset, whose size is $2^{117}$, the attack is more efficient and\ncosts only $2^{77}$ time complexity. Those attacks do not threaten the full\nround (12 rounds) \\textsc{Ascon}.", "AI": {"tldr": "\u672c\u6587\u8bc4\u4f30\u4e86\u8ba4\u8bc1\u52a0\u5bc6\u7b97\u6cd5Ascon\u5bf9\u7c7b\u7acb\u65b9\u4f53\u653b\u51fb\u7684\u5b89\u5168\u6027\uff0c\u63d0\u51fa\u4e86\u9488\u5bf95/6\u8f6e\u7f29\u51cfAscon\u7684\u65b0\u6761\u4ef6\u7acb\u65b9\u4f53\u653b\u51fb\u65b9\u6cd5\uff0c\u5e76\u9996\u6b21\u5b9e\u73b0\u4e86\u5bf97\u8f6eAscon\u7684\u5bc6\u94a5\u6062\u590d\u653b\u51fb", "motivation": "Ascon\u662fCAESAR\u7ade\u8d5b\u7b2c\u4e09\u8f6e\u768416\u4e2a\u5e78\u5b58\u7b97\u6cd5\u4e4b\u4e00\uff0c\u4e4b\u524d\u6700\u597d\u7684\u5bc6\u94a5\u6062\u590d\u653b\u51fb\u53ea\u80fd\u8fbe\u52306\u8f6e\uff0c\u800c\u7c7b\u4f3c\u7ed3\u6784\u7684Keccak\u5bc6\u94a5\u6a21\u5f0f\u653b\u51fb\u53ef\u8fbe7\u8f6e\u4ee5\u4e0a\uff0c\u9700\u8981\u7814\u7a76Ascon\u5bf9\u7c7b\u7acb\u65b9\u4f53\u653b\u51fb\u7684\u66f4\u5f3a\u5b89\u5168\u6027", "method": "\u63a8\u5e7f\u4e86\u6761\u4ef6\u7acb\u65b9\u4f53\u653b\u51fb\u65b9\u6cd5\uff0c\u5f15\u5165\u7acb\u65b9\u4f53\u7c7b\u5bc6\u94a5\u5b50\u96c6\u6280\u672f\uff0c\u6839\u636e\u4e0d\u540c\u7684\u5bc6\u94a5\u6761\u4ef6\u5c06\u5bc6\u94a5\u7a7a\u95f4\u5212\u5206\u4e3a\u591a\u4e2a\u5b50\u96c6\uff0c\u5bf9\u6bcf\u4e2a\u5b50\u96c6\u4f7f\u7528\u7acb\u65b9\u4f53\u6d4b\u8bd5\u5668\u8fdb\u884c\u6d4b\u8bd5", "result": "\u5c066\u8f6e\u653b\u51fb\u7684\u65f6\u95f4\u590d\u6742\u5ea6\u4ece\u7406\u8bba\u4e0a\u76842^66\u964d\u4f4e\u5230\u5b9e\u9645\u76842^40\uff0c\u9996\u6b21\u5b9e\u73b0\u4e86\u5bf97\u8f6eAscon\u7684\u5bc6\u94a5\u6062\u590d\u653b\u51fb\uff0c\u603b\u65f6\u95f4\u590d\u6742\u5ea6\u7ea6\u4e3a2^103.9\uff0c\u5bf9\u5f31\u5bc6\u94a5\u5b50\u96c6(\u5927\u5c0f2^117)\u7684\u653b\u51fb\u4ec5\u97002^77\u65f6\u95f4\u590d\u6742\u5ea6", "conclusion": "\u8fd9\u4e9b\u653b\u51fb\u4e0d\u4f1a\u5a01\u80c1\u5b8c\u657412\u8f6eAscon\u7684\u5b89\u5168\u6027\uff0c\u4f46\u5c55\u793a\u4e86\u5728\u7f29\u51cf\u8f6e\u6570\u4e0bAscon\u5bf9\u7c7b\u7acb\u65b9\u4f53\u653b\u51fb\u7684\u8106\u5f31\u6027\uff0c\u4e3a\u7b97\u6cd5\u5b89\u5168\u6027\u8bc4\u4f30\u63d0\u4f9b\u4e86\u91cd\u8981\u53c2\u8003"}}
{"id": "2508.15183", "categories": ["cs.CR", "cs.DS"], "pdf": "https://arxiv.org/pdf/2508.15183", "abs": "https://arxiv.org/abs/2508.15183", "authors": ["Badih Ghazi", "Pritish Kamath", "Alexander Knop", "Ravi Kumar", "Pasin Manurangsi", "Chiyuan Zhang"], "title": "Private Hyperparameter Tuning with Ex-Post Guarantee", "comment": null, "summary": "The conventional approach in differential privacy (DP) literature formulates\nthe privacy-utility trade-off with a \"privacy-first\" perspective: for a\npredetermined level of privacy, a certain utility is achievable. However,\npractitioners often operate under a \"utility-first\" paradigm, prioritizing a\ndesired level of utility and then determining the corresponding privacy cost.\n  Wu et al. [2019] initiated a formal study of this \"utility-first\" perspective\nby introducing ex-post DP. They demonstrated that by adding correlated Laplace\nnoise and progressively reducing it on demand, a sequence of increasingly\naccurate estimates of a private parameter can be generated, with the privacy\ncost attributed only to the least noisy iterate released. This led to a Laplace\nmechanism variant that achieves a specified utility with minimal privacy loss.\nHowever, their work, and similar findings by Whitehouse et al. [2022], are\nprimarily limited to simple mechanisms based on Laplace or Gaussian noise.\n  In this paper, we significantly generalize these results. In particular, we\nextend the work of Wu et al. [2019] and Liu and Talwar [2019] to support any\nsequence of private estimators, incurring at most a doubling of the original\nprivacy budget. Furthermore, we demonstrate that hyperparameter tuning for\nthese estimators, including the selection of an optimal privacy budget, can be\nperformed without additional privacy cost. Finally, we extend our results to\nex-post Renyi DP, further broadening the applicability of utility-first privacy\nmechanisms.", "AI": {"tldr": "\u672c\u6587\u6269\u5c55\u4e86\u6548\u7528\u4f18\u5148\u7684\u5dee\u5206\u9690\u79c1\u65b9\u6cd5\uff0c\u652f\u6301\u4efb\u610f\u79c1\u6709\u4f30\u8ba1\u5668\u5e8f\u5217\uff0c\u6700\u591a\u53ea\u9700\u539f\u59cb\u9690\u79c1\u9884\u7b97\u7684\u4e24\u500d\uff0c\u5e76\u80fd\u65e0\u989d\u5916\u9690\u79c1\u6210\u672c\u5730\u8fdb\u884c\u8d85\u53c2\u6570\u8c03\u4f18\uff0c\u5305\u62ec\u6269\u5c55\u5230ex-post Renyi DP\u3002", "motivation": "\u4f20\u7edf\u5dee\u5206\u9690\u79c1\u91c7\u7528\"\u9690\u79c1\u4f18\u5148\"\u89c6\u89d2\uff0c\u4f46\u5b9e\u8df5\u4e2d\u5f80\u5f80\u9700\u8981\"\u6548\u7528\u4f18\u5148\"\u2014\u2014\u5148\u786e\u5b9a\u6240\u9700\u6548\u7528\u6c34\u5e73\uff0c\u518d\u8ba1\u7b97\u76f8\u5e94\u7684\u9690\u79c1\u6210\u672c\u3002\u73b0\u6709\u7814\u7a76\u4e3b\u8981\u5c40\u9650\u4e8e\u57fa\u4e8e\u62c9\u666e\u62c9\u65af\u6216\u9ad8\u65af\u566a\u58f0\u7684\u7b80\u5355\u673a\u5236\u3002", "method": "\u6269\u5c55Wu\u7b49\u4eba[2019]\u548cLiu\u4e0eTalwar[2019]\u7684\u5de5\u4f5c\uff0c\u652f\u6301\u4efb\u610f\u79c1\u6709\u4f30\u8ba1\u5668\u5e8f\u5217\uff0c\u901a\u8fc7\u76f8\u5173\u566a\u58f0\u6dfb\u52a0\u548c\u6e10\u8fdb\u51cf\u5c11\u673a\u5236\uff0c\u5b9e\u73b0\u6700\u591a\u4e24\u500d\u539f\u59cb\u9690\u79c1\u9884\u7b97\u7684\u6548\u7528\u4f18\u5148\u9690\u79c1\u4fdd\u62a4\u3002", "result": "\u5b9e\u73b0\u4e86\u5bf9\u4efb\u610f\u4f30\u8ba1\u5668\u5e8f\u5217\u7684\u652f\u6301\uff0c\u9690\u79c1\u6210\u672c\u6700\u591a\u4e3a\u539f\u59cb\u9884\u7b97\u7684\u4e24\u500d\uff1b\u8d85\u53c2\u6570\u8c03\u4f18\uff08\u5305\u62ec\u6700\u4f18\u9690\u79c1\u9884\u7b97\u9009\u62e9\uff09\u65e0\u9700\u989d\u5916\u9690\u79c1\u6210\u672c\uff1b\u7ed3\u679c\u53ef\u6269\u5c55\u5230ex-post Renyi DP\u3002", "conclusion": "\u672c\u6587\u663e\u8457\u63a8\u5e7f\u4e86\u6548\u7528\u4f18\u5148\u5dee\u5206\u9690\u79c1\u673a\u5236\uff0c\u4f7f\u5176\u9002\u7528\u4e8e\u66f4\u5e7f\u6cdb\u7684\u4f30\u8ba1\u5668\u7c7b\u578b\u548c\u9690\u79c1\u5b9a\u4e49\uff0c\u4e3a\u5b9e\u9645\u5e94\u7528\u63d0\u4f9b\u4e86\u66f4\u7075\u6d3b\u7684\u9690\u79c1-\u6548\u7528\u6743\u8861\u6846\u67b6\u3002"}}
{"id": "2508.15252", "categories": ["cs.CR", "cs.CL", "cs.IR"], "pdf": "https://arxiv.org/pdf/2508.15252", "abs": "https://arxiv.org/abs/2508.15252", "authors": ["Shiyi Yang", "Xinshu Li", "Guanglin Zhou", "Chen Wang", "Xiwei Xu", "Liming Zhu", "Lina Yao"], "title": "Retrieval-Augmented Review Generation for Poisoning Recommender Systems", "comment": null, "summary": "Recent studies have shown that recommender systems (RSs) are highly\nvulnerable to data poisoning attacks, where malicious actors inject fake user\nprofiles, including a group of well-designed fake ratings, to manipulate\nrecommendations. Due to security and privacy constraints in practice, attackers\ntypically possess limited knowledge of the victim system and thus need to craft\nprofiles that have transferability across black-box RSs. To maximize the attack\nimpact, the profiles often remains imperceptible. However, generating such\nhigh-quality profiles with the restricted resources is challenging. Some works\nsuggest incorporating fake textual reviews to strengthen the profiles; yet, the\npoor quality of the reviews largely undermines the attack effectiveness and\nimperceptibility under the practical setting.\n  To tackle the above challenges, in this paper, we propose to enhance the\nquality of the review text by harnessing in-context learning (ICL) capabilities\nof multimodal foundation models. To this end, we introduce a demonstration\nretrieval algorithm and a text style transfer strategy to augment the navie\nICL. Specifically, we propose a novel practical attack framework named RAGAN to\ngenerate high-quality fake user profiles, which can gain insights into the\nrobustness of RSs. The profiles are generated by a jailbreaker and\ncollaboratively optimized on an instructional agent and a guardian to improve\nthe attack transferability and imperceptibility. Comprehensive experiments on\nvarious real-world datasets demonstrate that RAGAN achieves the\nstate-of-the-art poisoning attack performance.", "AI": {"tldr": "\u672c\u6587\u63d0\u51faRAGAN\u653b\u51fb\u6846\u67b6\uff0c\u5229\u7528\u591a\u6a21\u6001\u57fa\u7840\u6a21\u578b\u7684\u4e0a\u4e0b\u6587\u5b66\u4e60\u80fd\u529b\u751f\u6210\u9ad8\u8d28\u91cf\u865a\u5047\u7528\u6237\u914d\u7f6e\u6587\u4ef6\uff0c\u63d0\u5347\u63a8\u8350\u7cfb\u7edf\u7684\u6570\u636e\u6295\u6bd2\u653b\u51fb\u6548\u679c\u548c\u9690\u853d\u6027\u3002", "motivation": "\u63a8\u8350\u7cfb\u7edf\u6613\u53d7\u6570\u636e\u6295\u6bd2\u653b\u51fb\uff0c\u4f46\u73b0\u6709\u65b9\u6cd5\u751f\u6210\u7684\u865a\u5047\u8bc4\u8bba\u8d28\u91cf\u5dee\uff0c\u5728\u8d44\u6e90\u53d7\u9650\u7684\u9ed1\u76d2\u8bbe\u7f6e\u4e0b\u653b\u51fb\u6548\u679c\u548c\u9690\u853d\u6027\u4e0d\u8db3\u3002", "method": "\u63d0\u51faRAGAN\u6846\u67b6\uff1a1) \u4f7f\u7528\u6f14\u793a\u68c0\u7d22\u7b97\u6cd5\u548c\u6587\u672c\u98ce\u683c\u8f6c\u6362\u7b56\u7565\u589e\u5f3a\u4e0a\u4e0b\u6587\u5b66\u4e60\uff1b2) \u901a\u8fc7\u8d8a\u72f1\u5668\u751f\u6210\u914d\u7f6e\u6587\u4ef6\uff0c\u7531\u6307\u4ee4\u4ee3\u7406\u548c\u5b88\u62a4\u8005\u534f\u540c\u4f18\u5316\u653b\u51fb\u53ef\u8fc1\u79fb\u6027\u548c\u9690\u853d\u6027\u3002", "result": "\u5728\u591a\u4e2a\u771f\u5b9e\u6570\u636e\u96c6\u4e0a\u7684\u5b9e\u9a8c\u8868\u660e\uff0cRAGAN\u5b9e\u73b0\u4e86\u6700\u5148\u8fdb\u7684\u4e2d\u6bd2\u653b\u51fb\u6027\u80fd\u3002", "conclusion": "RAGAN\u6846\u67b6\u80fd\u751f\u6210\u9ad8\u8d28\u91cf\u7684\u865a\u5047\u7528\u6237\u914d\u7f6e\u6587\u4ef6\uff0c\u6709\u6548\u8bc4\u4f30\u63a8\u8350\u7cfb\u7edf\u7684\u9c81\u68d2\u6027\uff0c\u5728\u653b\u51fb\u6548\u679c\u548c\u9690\u853d\u6027\u65b9\u9762\u4f18\u4e8e\u73b0\u6709\u65b9\u6cd5\u3002"}}
{"id": "2508.15306", "categories": ["cs.CR"], "pdf": "https://arxiv.org/pdf/2508.15306", "abs": "https://arxiv.org/abs/2508.15306", "authors": ["Henrietta Hegyi", "Laszlo Erdodi"], "title": "Connected and Exposed: Cybersecurity Risks, Regulatory Gaps, and Public Perception in Internet-Connected Vehicles", "comment": null, "summary": "The rapid advancement of Internet-connected vehicle technologies has\nintroduced a new era of smart mobility, while simultaneously raising\nsignificant cybersecurity and privacy concerns. This paper explores the\nevolving threat landscape associated with connected vehicles, focusing on risks\nsuch as unauthorized remote access and the potential leakage of personal data.\nTo assess the current state of protection, we conducted a comprehensive\nanalysis of 16 international standards and regulations, evaluating them from\nmultiple perspectives including regulatory strength, technical specificity,\ntreatment of supply chain risks, and approaches to personal data handling.\n  In parallel, we carried out a user-focused survey designed to map consumer\nattitudes toward smart cars. The survey investigated which types of vehicles\nusers trust and prefer, the reasons behind rejecting certain car types, their\nawareness of data-related risks, and whether they feel adequately informed\nabout how their vehicles handle data. By combining regulatory analysis with\nuser perception insights, this study aims to contribute to a more holistic\nunderstanding of the challenges and expectations surrounding connected vehicle\necosystems.", "AI": {"tldr": "\u672c\u6587\u5206\u6790\u4e86\u8054\u7f51\u8f66\u8f86\u7684\u7f51\u7edc\u5b89\u5168\u548c\u9690\u79c1\u98ce\u9669\uff0c\u901a\u8fc7\u8bc4\u4f3016\u9879\u56fd\u9645\u6807\u51c6\u6cd5\u89c4\u548c\u7528\u6237\u8c03\u67e5\uff0c\u63ed\u793a\u4e86\u5f53\u524d\u4fdd\u62a4\u63aa\u65bd\u7684\u4e0d\u8db3\u4e0e\u6d88\u8d39\u8005\u8ba4\u77e5\u5dee\u8ddd", "motivation": "\u968f\u7740\u667a\u80fd\u7f51\u8054\u6c7d\u8f66\u7684\u5feb\u901f\u53d1\u5c55\uff0c\u7f51\u7edc\u5b89\u5168\u548c\u4e2a\u4eba\u9690\u79c1\u98ce\u9669\u65e5\u76ca\u7a81\u51fa\uff0c\u9700\u8981\u5168\u9762\u4e86\u89e3\u5f53\u524d\u4fdd\u62a4\u6807\u51c6\u548c\u7528\u6237\u8ba4\u77e5\u72b6\u51b5", "method": "\u91c7\u7528\u53cc\u91cd\u7814\u7a76\u65b9\u6cd5\uff1a1\uff09\u5bf916\u9879\u56fd\u9645\u6807\u51c6\u548c\u6cd5\u89c4\u8fdb\u884c\u591a\u7ef4\u5ea6\u5206\u6790\uff1b2\uff09\u5f00\u5c55\u7528\u6237\u8c03\u67e5\u4e86\u89e3\u6d88\u8d39\u8005\u5bf9\u667a\u80fd\u6c7d\u8f66\u7684\u6001\u5ea6\u548c\u98ce\u9669\u8ba4\u77e5", "result": "\u7814\u7a76\u53d1\u73b0\u5f53\u524d\u6807\u51c6\u5728\u76d1\u7ba1\u529b\u5ea6\u3001\u6280\u672f\u7ec6\u8282\u3001\u4f9b\u5e94\u94fe\u98ce\u9669\u5904\u7406\u7b49\u65b9\u9762\u5b58\u5728\u5dee\u5f02\uff0c\u540c\u65f6\u7528\u6237\u5bf9\u6570\u636e\u98ce\u9669\u7684\u8ba4\u77e5\u4e0d\u8db3\u4e14\u4fe1\u606f\u83b7\u53d6\u4e0d\u5145\u5206", "conclusion": "\u9700\u8981\u5236\u5b9a\u66f4\u5168\u9762\u7684\u6807\u51c6\u548c\u63d0\u9ad8\u7528\u6237\u6559\u80b2\uff0c\u4ee5\u5e94\u5bf9\u8054\u7f51\u8f66\u8f86\u751f\u6001\u7cfb\u7edf\u4e2d\u7684\u5b89\u5168\u548c\u9690\u79c1\u6311\u6218"}}
{"id": "2508.15310", "categories": ["cs.CR", "cs.AI", "cs.CL"], "pdf": "https://arxiv.org/pdf/2508.15310", "abs": "https://arxiv.org/abs/2508.15310", "authors": ["Hengyu An", "Jinghuai Zhang", "Tianyu Du", "Chunyi Zhou", "Qingming Li", "Tao Lin", "Shouling Ji"], "title": "IPIGuard: A Novel Tool Dependency Graph-Based Defense Against Indirect Prompt Injection in LLM Agents", "comment": "EMNLP 2025", "summary": "Large language model (LLM) agents are widely deployed in real-world\napplications, where they leverage tools to retrieve and manipulate external\ndata for complex tasks. However, when interacting with untrusted data sources\n(e.g., fetching information from public websites), tool responses may contain\ninjected instructions that covertly influence agent behaviors and lead to\nmalicious outcomes, a threat referred to as Indirect Prompt Injection (IPI).\nExisting defenses typically rely on advanced prompting strategies or auxiliary\ndetection models. While these methods have demonstrated some effectiveness,\nthey fundamentally rely on assumptions about the model's inherent security,\nwhich lacks structural constraints on agent behaviors. As a result, agents\nstill retain unrestricted access to tool invocations, leaving them vulnerable\nto stronger attack vectors that can bypass the security guardrails of the\nmodel. To prevent malicious tool invocations at the source, we propose a novel\ndefensive task execution paradigm, called IPIGuard, which models the agents'\ntask execution process as a traversal over a planned Tool Dependency Graph\n(TDG). By explicitly decoupling action planning from interaction with external\ndata, IPIGuard significantly reduces unintended tool invocations triggered by\ninjected instructions, thereby enhancing robustness against IPI attacks.\nExperiments on the AgentDojo benchmark show that IPIGuard achieves a superior\nbalance between effectiveness and robustness, paving the way for the\ndevelopment of safer agentic systems in dynamic environments.", "AI": {"tldr": "IPIGuard\u662f\u4e00\u79cd\u9632\u5fa1\u95f4\u63a5\u63d0\u793a\u6ce8\u5165\u653b\u51fb\u7684\u65b0\u65b9\u6cd5\uff0c\u901a\u8fc7\u5c06\u667a\u80fd\u4f53\u4efb\u52a1\u6267\u884c\u5efa\u6a21\u4e3a\u5de5\u5177\u4f9d\u8d56\u56fe\u904d\u5386\uff0c\u5206\u79bb\u884c\u52a8\u89c4\u5212\u4e0e\u5916\u90e8\u6570\u636e\u4ea4\u4e92\uff0c\u663e\u8457\u51cf\u5c11\u6076\u610f\u5de5\u5177\u8c03\u7528\u3002", "motivation": "\u73b0\u6709LLM\u667a\u80fd\u4f53\u9632\u5fa1\u65b9\u6cd5\u4f9d\u8d56\u4e8e\u6a21\u578b\u5185\u5728\u5b89\u5168\u6027\u5047\u8bbe\uff0c\u7f3a\u4e4f\u5bf9\u667a\u80fd\u4f53\u884c\u4e3a\u7684\u7ed3\u6784\u7ea6\u675f\uff0c\u5bfc\u81f4\u5728\u9762\u5bf9\u66f4\u5f3a\u653b\u51fb\u5411\u91cf\u65f6\u4ecd\u7136\u8106\u5f31\u3002", "method": "\u63d0\u51faIPIGuard\u9632\u5fa1\u6846\u67b6\uff0c\u5c06\u667a\u80fd\u4f53\u4efb\u52a1\u6267\u884c\u8fc7\u7a0b\u5efa\u6a21\u4e3a\u5de5\u5177\u4f9d\u8d56\u56fe(TDG)\u904d\u5386\uff0c\u660e\u786e\u5206\u79bb\u884c\u52a8\u89c4\u5212\u4e0e\u5916\u90e8\u6570\u636e\u4ea4\u4e92\u9636\u6bb5\u3002", "result": "\u5728AgentDojo\u57fa\u51c6\u6d4b\u8bd5\u4e2d\uff0cIPIGuard\u5728\u6709\u6548\u6027\u548c\u9c81\u68d2\u6027\u4e4b\u95f4\u5b9e\u73b0\u4e86\u4f18\u8d8a\u7684\u5e73\u8861\uff0c\u663e\u8457\u51cf\u5c11\u4e86\u7531\u6ce8\u5165\u6307\u4ee4\u89e6\u53d1\u7684\u610f\u5916\u5de5\u5177\u8c03\u7528\u3002", "conclusion": "IPIGuard\u4e3a\u52a8\u6001\u73af\u5883\u4e2d\u5f00\u53d1\u66f4\u5b89\u5168\u7684\u667a\u80fd\u4f53\u7cfb\u7edf\u94fa\u5e73\u4e86\u9053\u8def\uff0c\u901a\u8fc7\u7ed3\u6784\u5316\u7ea6\u675f\u4ece\u6839\u672c\u4e0a\u589e\u5f3a\u4e86\u5bf9\u6297\u95f4\u63a5\u63d0\u793a\u6ce8\u5165\u653b\u51fb\u7684\u9c81\u68d2\u6027\u3002"}}
{"id": "2508.15386", "categories": ["cs.CR", "cs.SE"], "pdf": "https://arxiv.org/pdf/2508.15386", "abs": "https://arxiv.org/abs/2508.15386", "authors": ["Sabine Houy", "Bruno Kreyssig", "Timothee Riom", "Alexandre Bartel", "Patrick McDaniel"], "title": "A Practical Guideline and Taxonomy to LLVM's Control Flow Integrity", "comment": null, "summary": "Memory corruption vulnerabilities remain one of the most severe threats to\nsoftware security. They often allow attackers to achieve arbitrary code\nexecution by redirecting a vulnerable program's control flow. While Control\nFlow Integrity (CFI) has gained traction to mitigate this exploitation path,\ndevelopers are not provided with any direction on how to apply CFI to\nreal-world software. In this work, we establish a taxonomy mapping LLVM's\nforward-edge CFI variants to memory corruption vulnerability classes, offering\nactionable guidance for developers seeking to deploy CFI incrementally in\nexisting codebases. Based on the Top 10 Known Exploited Vulnerabilities (KEV)\nlist, we identify four high-impact vulnerability categories and select one\nrepresentative CVE for each. We evaluate LLVM's CFI against each CVE and\nexplain why CFI blocks exploitation in two cases while failing in the other\ntwo, illustrating its potential and current limitations. Our findings support\ninformed deployment decisions and provide a foundation for improving the\npractical use of CFI in production systems.", "AI": {"tldr": "\u672c\u6587\u5efa\u7acb\u4e86LLVM\u524d\u5411\u8fb9CFI\u53d8\u4f53\u4e0e\u5185\u5b58\u635f\u574f\u6f0f\u6d1e\u7c7b\u522b\u7684\u5206\u7c7b\u6620\u5c04\uff0c\u4e3a\u5f00\u53d1\u8005\u5728\u73b0\u6709\u4ee3\u7801\u5e93\u4e2d\u9010\u6b65\u90e8\u7f72CFI\u63d0\u4f9b\u5b9e\u7528\u6307\u5bfc\u3002\u57fa\u4e8eTop 10\u5df2\u77e5\u88ab\u5229\u7528\u6f0f\u6d1e\u5217\u8868\uff0c\u8bc4\u4f30\u4e86LLVM CFI\u5bf9\u56db\u7c7b\u9ad8\u5f71\u54cd\u6f0f\u6d1e\u7684\u9632\u62a4\u6548\u679c\u3002", "motivation": "\u5185\u5b58\u635f\u574f\u6f0f\u6d1e\u4ecd\u7136\u662f\u8f6f\u4ef6\u5b89\u5168\u6700\u4e25\u91cd\u7684\u5a01\u80c1\u4e4b\u4e00\uff0c\u867d\u7136\u63a7\u5236\u6d41\u5b8c\u6574\u6027(CFI)\u53ef\u4ee5\u7f13\u89e3\u8fd9\u7c7b\u653b\u51fb\uff0c\u4f46\u5f00\u53d1\u8005\u7f3a\u4e4f\u5982\u4f55\u5728\u5b9e\u9645\u8f6f\u4ef6\u4e2d\u5e94\u7528CFI\u7684\u5177\u4f53\u6307\u5bfc\u3002", "method": "\u5efa\u7acbLLVM\u524d\u5411\u8fb9CFI\u53d8\u4f53\u4e0e\u6f0f\u6d1e\u7c7b\u522b\u7684\u5206\u7c7b\u6620\u5c04\uff0c\u57fa\u4e8eTop 10 KEV\u5217\u8868\u9009\u62e9\u56db\u7c7b\u9ad8\u5f71\u54cd\u6f0f\u6d1e\u7684\u4ee3\u8868\u6027CVE\uff0c\u8bc4\u4f30LLVM CFI\u5bf9\u6bcf\u4e2aCVE\u7684\u9632\u62a4\u6548\u679c\u3002", "result": "CFI\u5728\u4e24\u4e2a\u6848\u4f8b\u4e2d\u6210\u529f\u963b\u6b62\u4e86\u6f0f\u6d1e\u5229\u7528\uff0c\u4f46\u5728\u53e6\u5916\u4e24\u4e2a\u6848\u4f8b\u4e2d\u5931\u8d25\uff0c\u663e\u793a\u4e86\u5176\u6f5c\u529b\u548c\u5f53\u524d\u5c40\u9650\u6027\u3002", "conclusion": "\u7814\u7a76\u7ed3\u679c\u4e3aCFI\u7684\u90e8\u7f72\u51b3\u7b56\u63d0\u4f9b\u4e86\u4f9d\u636e\uff0c\u5e76\u4e3a\u6539\u8fdbCFI\u5728\u751f\u4ea7\u7cfb\u7edf\u4e2d\u7684\u5b9e\u9645\u5e94\u7528\u5960\u5b9a\u4e86\u57fa\u7840\u3002"}}
{"id": "2508.15541", "categories": ["cs.CR", "cs.LG"], "pdf": "https://arxiv.org/pdf/2508.15541", "abs": "https://arxiv.org/abs/2508.15541", "authors": ["Bingguang Lu", "Hongsheng Hu", "Yuantian Miao", "Shaleeza Sohail", "Chaoxiang He", "Shuo Wang", "Xiao Chen"], "title": "BadFU: Backdoor Federated Learning through Adversarial Machine Unlearning", "comment": null, "summary": "Federated learning (FL) has been widely adopted as a decentralized training\nparadigm that enables multiple clients to collaboratively learn a shared model\nwithout exposing their local data. As concerns over data privacy and regulatory\ncompliance grow, machine unlearning, which aims to remove the influence of\nspecific data from trained models, has become increasingly important in the\nfederated setting to meet legal, ethical, or user-driven demands. However,\nintegrating unlearning into FL introduces new challenges and raises largely\nunexplored security risks. In particular, adversaries may exploit the\nunlearning process to compromise the integrity of the global model. In this\npaper, we present the first backdoor attack in the context of federated\nunlearning, demonstrating that an adversary can inject backdoors into the\nglobal model through seemingly legitimate unlearning requests. Specifically, we\npropose BadFU, an attack strategy where a malicious client uses both backdoor\nand camouflage samples to train the global model normally during the federated\ntraining process. Once the client requests unlearning of the camouflage\nsamples, the global model transitions into a backdoored state. Extensive\nexperiments under various FL frameworks and unlearning strategies validate the\neffectiveness of BadFU, revealing a critical vulnerability in current federated\nunlearning practices and underscoring the urgent need for more secure and\nrobust federated unlearning mechanisms.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86BadFU\u653b\u51fb\uff0c\u9996\u6b21\u5728\u8054\u90a6\u5b66\u4e60\u9057\u5fd8\u573a\u666f\u4e2d\u5b9e\u73b0\u540e\u95e8\u653b\u51fb\uff0c\u6076\u610f\u5ba2\u6237\u7aef\u901a\u8fc7\u770b\u4f3c\u5408\u6cd5\u7684\u9057\u5fd8\u8bf7\u6c42\u5c06\u540e\u95e8\u6ce8\u5165\u5168\u5c40\u6a21\u578b\u3002", "motivation": "\u968f\u7740\u6570\u636e\u9690\u79c1\u548c\u76d1\u7ba1\u5408\u89c4\u8981\u6c42\u65e5\u76ca\u4e25\u683c\uff0c\u8054\u90a6\u5b66\u4e60\u4e2d\u7684\u673a\u5668\u9057\u5fd8\u6280\u672f\u53d8\u5f97\u91cd\u8981\uff0c\u4f46\u5c06\u9057\u5fd8\u6574\u5408\u5230\u8054\u90a6\u5b66\u4e60\u4e2d\u5e26\u6765\u4e86\u65b0\u7684\u5b89\u5168\u98ce\u9669\uff0c\u7279\u522b\u662f\u653b\u51fb\u8005\u53ef\u80fd\u5229\u7528\u9057\u5fd8\u8fc7\u7a0b\u7834\u574f\u5168\u5c40\u6a21\u578b\u7684\u5b8c\u6574\u6027\u3002", "method": "\u63d0\u51faBadFU\u653b\u51fb\u7b56\u7565\uff1a\u6076\u610f\u5ba2\u6237\u7aef\u5728\u8054\u90a6\u8bad\u7ec3\u8fc7\u7a0b\u4e2d\u4f7f\u7528\u540e\u95e8\u6837\u672c\u548c\u4f2a\u88c5\u6837\u672c\u6b63\u5e38\u8bad\u7ec3\u5168\u5c40\u6a21\u578b\uff0c\u5f53\u8bf7\u6c42\u9057\u5fd8\u4f2a\u88c5\u6837\u672c\u65f6\uff0c\u5168\u5c40\u6a21\u578b\u8f6c\u53d8\u4e3a\u540e\u95e8\u72b6\u6001\u3002", "result": "\u5728\u5404\u79cd\u8054\u90a6\u5b66\u4e60\u6846\u67b6\u548c\u9057\u5fd8\u7b56\u7565\u4e0b\u7684\u5e7f\u6cdb\u5b9e\u9a8c\u9a8c\u8bc1\u4e86BadFU\u7684\u6709\u6548\u6027\uff0c\u63ed\u793a\u4e86\u5f53\u524d\u8054\u90a6\u9057\u5fd8\u5b9e\u8df5\u4e2d\u7684\u5173\u952e\u6f0f\u6d1e\u3002", "conclusion": "\u8fd9\u9879\u5de5\u4f5c\u63ed\u793a\u4e86\u8054\u90a6\u9057\u5fd8\u673a\u5236\u4e2d\u7684\u4e25\u91cd\u5b89\u5168\u6f0f\u6d1e\uff0c\u5f3a\u8c03\u4e86\u5f00\u53d1\u66f4\u5b89\u5168\u3001\u66f4\u9c81\u68d2\u7684\u8054\u90a6\u9057\u5fd8\u673a\u5236\u7684\u7d27\u8feb\u9700\u6c42\u3002"}}
{"id": "2508.15606", "categories": ["cs.CR"], "pdf": "https://arxiv.org/pdf/2508.15606", "abs": "https://arxiv.org/abs/2508.15606", "authors": ["Yu Yang", "Zhenyuan Li", "Xiandong Ran", "Jiahao Liu", "Jiahui Wang", "Bo Yu", "Shouling Ji"], "title": "Towards Scalable and Interpretable Mobile App Risk Analysis via Large Language Models", "comment": null, "summary": "Mobile application marketplaces are responsible for vetting apps to identify\nand mitigate security risks. Current vetting processes are labor-intensive,\nrelying on manual analysis by security professionals aided by semi-automated\ntools. To address this inefficiency, we propose Mars, a system that leverages\nLarge Language Models (LLMs) for automated risk identification and profiling.\nMars is designed to concurrently analyze multiple applications across diverse\nrisk categories with minimal human intervention. To enhance analytical\nprecision and operational efficiency, Mars leverages a pre-constructed risk\nidentification tree to extract relevant indicators from high-dimensional\napplication features. This initial step filters the data, reducing the input\nvolume for the LLM and mitigating the potential for model hallucination induced\nby irrelevant features. The extracted indicators are then subjected to LLM\nanalysis for final risk determination. Furthermore, Mars automatically\ngenerates a comprehensive evidence chain for each assessment, documenting the\nanalytical process to provide transparent justification. These chains are\ndesigned to facilitate subsequent manual review and to inform enforcement\ndecisions, such as application delisting. The performance of Mars was evaluated\non a real-world dataset from a partner Android marketplace. The results\ndemonstrate that Mars attained an F1-score of 0.838 in risk identification and\nan F1-score of 0.934 in evidence retrieval. To assess its practical\napplicability, a user study involving 20 expert analysts was conducted, which\nindicated that Mars yielded a substantial efficiency gain, ranging from 60% to\n90%, over conventional manual analysis.", "AI": {"tldr": "Mars\u662f\u4e00\u4e2a\u57fa\u4e8e\u5927\u8bed\u8a00\u6a21\u578b\u7684\u81ea\u52a8\u5316\u79fb\u52a8\u5e94\u7528\u5b89\u5168\u98ce\u9669\u8bc4\u4f30\u7cfb\u7edf\uff0c\u901a\u8fc7\u98ce\u9669\u8bc6\u522b\u6811\u63d0\u53d6\u5173\u952e\u6307\u6807\uff0c\u51cf\u5c11LLM\u8f93\u5165\u5e76\u964d\u4f4e\u5e7b\u89c9\u98ce\u9669\uff0c\u5728\u771f\u5b9e\u6570\u636e\u96c6\u4e0a\u8fbe\u52300.838\u7684F1\u5206\u6570\uff0c\u6548\u7387\u63d0\u534760-90%\u3002", "motivation": "\u5f53\u524d\u79fb\u52a8\u5e94\u7528\u5e02\u573a\u7684\u5b89\u5168\u5ba1\u6838\u8fc7\u7a0b\u4f9d\u8d56\u4eba\u5de5\u5206\u6790\uff0c\u6548\u7387\u4f4e\u4e0b\u4e14\u52b3\u52a8\u5bc6\u96c6\uff0c\u9700\u8981\u81ea\u52a8\u5316\u89e3\u51b3\u65b9\u6848\u6765\u63d0\u9ad8\u5ba1\u6838\u6548\u7387\u548c\u51c6\u786e\u6027\u3002", "method": "\u6784\u5efa\u98ce\u9669\u8bc6\u522b\u6811\u4ece\u9ad8\u7ef4\u5e94\u7528\u7279\u5f81\u4e2d\u63d0\u53d6\u76f8\u5173\u6307\u6807\uff0c\u51cf\u5c11LLM\u8f93\u5165\u91cf\uff1b\u4f7f\u7528LLM\u8fdb\u884c\u6700\u7ec8\u98ce\u9669\u5224\u5b9a\uff1b\u81ea\u52a8\u751f\u6210\u5305\u542b\u5206\u6790\u8fc7\u7a0b\u7684\u8bc1\u636e\u94fe\u4ee5\u652f\u6301\u4eba\u5de5\u5ba1\u6838\u3002", "result": "\u5728\u771f\u5b9eAndroid\u5e02\u573a\u6570\u636e\u96c6\u4e0a\uff0c\u98ce\u9669\u8bc6\u522bF1\u5206\u6570\u8fbe0.838\uff0c\u8bc1\u636e\u68c0\u7d22F1\u5206\u6570\u8fbe0.934\uff1b\u7528\u6237\u7814\u7a76\u8868\u660e\u6548\u7387\u6bd4\u4f20\u7edf\u4eba\u5de5\u5206\u6790\u63d0\u534760-90%\u3002", "conclusion": "Mars\u7cfb\u7edf\u6210\u529f\u5b9e\u73b0\u4e86\u79fb\u52a8\u5e94\u7528\u5b89\u5168\u98ce\u9669\u8bc4\u4f30\u7684\u81ea\u52a8\u5316\uff0c\u5728\u4fdd\u6301\u9ad8\u51c6\u786e\u6027\u7684\u540c\u65f6\u663e\u8457\u63d0\u5347\u4e86\u6548\u7387\uff0c\u4e3a\u5e94\u7528\u5e02\u573a\u5ba1\u6838\u63d0\u4f9b\u4e86\u53ef\u884c\u7684\u81ea\u52a8\u5316\u89e3\u51b3\u65b9\u6848\u3002"}}
