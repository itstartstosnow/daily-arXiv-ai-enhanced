<div id=toc></div>

# Table of Contents

- [cs.CR](#cs.CR) [Total: 24]


<div id='cs.CR'></div>

# cs.CR [[Back]](#toc)

### [1] [A Robust Pipeline for Differentially Private Federated Learning on Imbalanced Clinical Data using SMOTETomek and FedProx](https://arxiv.org/abs/2508.10017)
*Rodrigo Tertulino*

Main category: cs.CR

TL;DR: 该研究通过结合联邦学习（FL）和差分隐私（DP）解决医疗数据中的隐私与临床效用之间的权衡问题，并针对类别不平衡问题优化了模型。


<details>
  <summary>Details</summary>
Motivation: 医疗数据隐私保护和临床效用之间的冲突，以及医疗数据中常见的类别不平衡问题。

Method: 采用FL框架，结合SMOTETomek处理类别不平衡，并优化FedProx算法处理非独立同分布数据。

Result: 在隐私预算（epsilon）为9.0时，模型召回率超过77%，实现了隐私与效用的平衡。

Conclusion: 研究为实际医疗数据提供了高效、安全且准确的诊断工具开发方法。

Abstract: Federated Learning (FL) presents a groundbreaking approach for collaborative
health research, allowing model training on decentralized data while
safeguarding patient privacy. FL offers formal security guarantees when
combined with Differential Privacy (DP). The integration of these technologies,
however, introduces a significant trade-off between privacy and clinical
utility, a challenge further complicated by the severe class imbalance often
present in medical datasets. The research presented herein addresses these
interconnected issues through a systematic, multi-stage analysis. An FL
framework was implemented for cardiovascular risk prediction, where initial
experiments showed that standard methods struggled with imbalanced data,
resulting in a recall of zero. To overcome such a limitation, we first
integrated the hybrid Synthetic Minority Over-sampling Technique with Tomek
Links (SMOTETomek) at the client level, successfully developing a clinically
useful model. Subsequently, the framework was optimized for non-IID data using
a tuned FedProx algorithm. Our final results reveal a clear, non-linear
trade-off between the privacy budget (epsilon) and model recall, with the
optimized FedProx consistently out-performing standard FedAvg. An optimal
operational region was identified on the privacy-utility frontier, where strong
privacy guarantees (with epsilon 9.0) can be achieved while maintaining high
clinical utility (recall greater than 77%). Ultimately, our study provides a
practical methodological blueprint for creating effective, secure, and accurate
diagnostic tools that can be applied to real-world, heterogeneous healthcare
data.

</details>


### [2] [A Comparative Performance Evaluation of Kyber, sntrup761, and FrodoKEM for Post-Quantum Cryptography](https://arxiv.org/abs/2508.10023)
*Samet Ünsal*

Main category: cs.CR

TL;DR: 本文比较了后量子密码学中的主要算法（如Kyber、sntrup761和FrodoKEM），分析了其安全性、性能和实际应用性，并探讨了从经典系统过渡到后量子系统的挑战。


<details>
  <summary>Details</summary>
Motivation: 量子计算机的发展对传统密码学构成威胁，因此需要研究后量子密码学算法以确保未来的安全性。

Method: 通过比较Kyber、sntrup761和FrodoKEM等算法的安全性、性能和适用性，评估其优劣势。

Result: 分析了各算法的优缺点，并提出了未来研究方向。

Conclusion: 后量子密码学在当前和未来的量子计算时代具有重要意义，但仍需解决过渡挑战和行业影响。

Abstract: Post-quantum cryptography (PQC) aims to develop cryptographic algorithms that
are secure against attacks from quantum computers. This paper compares the
leading postquantum cryptographic algorithms, such as Kyber, sntrup761, and
FrodoKEM, in terms of their security, performance, and real-world
applicability. The review highlights the strengths and weaknesses of each
algorithm and provides insights into future research directions. We also
discuss the challenges of transitioning from classical to post-quantum systems
and the potential impacts on various industries. This paper serves as a
foundation for understanding the current state of post-quantum cryptography and
its future prospects in the quantum computing era.

</details>


### [3] [Context Misleads LLMs: The Role of Context Filtering in Maintaining Safe Alignment of LLMs](https://arxiv.org/abs/2508.10031)
*Jinhwa Kim,Ian G. Harris*

Main category: cs.CR

TL;DR: 提出了一种名为Context Filtering的新防御机制，通过预处理输入过滤不可信内容，同时识别用户真实意图，以提升LLMs的安全性而不影响性能。


<details>
  <summary>Details</summary>
Motivation: 解决LLMs因恶意用户利用对抗性上下文生成有害回复的安全和伦理风险，同时避免影响良性用户体验。

Method: 设计输入预处理方法Context Filtering，过滤不可靠上下文并识别真实意图，无需微调模型即可应用于所有LLMs。

Result: 在六种攻击下，攻击成功率降低达88%，同时保持LLMs原有性能，安全性和实用性均达最佳水平。

Conclusion: Context Filtering是一种即插即用的防御机制，能有效提升LLMs安全性，适用于各类模型，且不影响其原有性能。

Abstract: While Large Language Models (LLMs) have shown significant advancements in
performance, various jailbreak attacks have posed growing safety and ethical
risks. Malicious users often exploit adversarial context to deceive LLMs,
prompting them to generate responses to harmful queries. In this study, we
propose a new defense mechanism called Context Filtering model, an input
pre-processing method designed to filter out untrustworthy and unreliable
context while identifying the primary prompts containing the real user intent
to uncover concealed malicious intent. Given that enhancing the safety of LLMs
often compromises their helpfulness, potentially affecting the experience of
benign users, our method aims to improve the safety of the LLMs while
preserving their original performance. We evaluate the effectiveness of our
model in defending against jailbreak attacks through comparative analysis,
comparing our approach with state-of-the-art defense mechanisms against six
different attacks and assessing the helpfulness of LLMs under these defenses.
Our model demonstrates its ability to reduce the Attack Success Rates of
jailbreak attacks by up to 88% while maintaining the original LLMs'
performance, achieving state-of-the-art Safety and Helpfulness Product results.
Notably, our model is a plug-and-play method that can be applied to all LLMs,
including both white-box and black-box models, to enhance their safety without
requiring any fine-tuning of the models themselves. We will make our model
publicly available for research purposes.

</details>


### [4] [Cognitive Cybersecurity for Artificial Intelligence: Guardrail Engineering with CCS-7](https://arxiv.org/abs/2508.10033)
*Yuksel Aydin*

Main category: cs.CR

TL;DR: 论文提出CCS-7分类法，揭示语言模型存在类似人类的认知漏洞，并通过实验验证了不同架构模型对干预措施的响应差异。


<details>
  <summary>Details</summary>
Motivation: 传统行为对齐方法无法解决语言模型的认知漏洞，需研究模型特定的认知安全问题。

Method: 提出CCS-7分类法，通过人类实验和12,180次模型实验评估干预措施效果。

Result: 人类干预效果稳定，但模型响应差异显著，某些漏洞干预后错误率上升135%。

Conclusion: 认知安全需针对模型架构定制测试，通用干预可能无效或有害。

Abstract: Language models exhibit human-like cognitive vulnerabilities, such as
emotional framing, that escape traditional behavioral alignment. We present
CCS-7 (Cognitive Cybersecurity Suite), a taxonomy of seven vulnerabilities
grounded in human cognitive security research. To establish a human benchmark,
we ran a randomized controlled trial with 151 participants: a "Think First,
Verify Always" (TFVA) lesson improved cognitive security by +7.9% overall. We
then evaluated TFVA-style guardrails across 12,180 experiments on seven diverse
language model architectures. Results reveal architecture-dependent risk
patterns: some vulnerabilities (e.g., identity confusion) are almost fully
mitigated, while others (e.g., source interference) exhibit escalating
backfire, with error rates increasing by up to 135% in certain models. Humans,
in contrast, show consistent moderate improvement. These findings reframe
cognitive safety as a model-specific engineering problem: interventions
effective in one architecture may fail, or actively harm, another, underscoring
the need for architecture-aware cognitive safety testing before deployment.

</details>


### [5] [Neural Network-Based Detection and Multi-Class Classification of FDI Attacks in Smart Grid Home Energy Systems](https://arxiv.org/abs/2508.10035)
*Varsha Sen,Biswash Basnet*

Main category: cs.CR

TL;DR: 论文提出了一种基于机器学习的框架，用于检测和分类智能电网中的虚假数据注入攻击（FDIAs），通过轻量级人工神经网络（ANN）和双向LSTM实现实时检测与分类。


<details>
  <summary>Details</summary>
Motivation: 虚假数据注入攻击（FDIAs）对智能电网构成严重威胁，尤其是家庭区域网络（HANs），因其安全控制较弱且广泛可用，成为攻击者操纵需求模式的入口。

Method: 使用轻量级ANN进行实时检测，提取能耗、成本和时间等关键特征；通过双向LSTM分类不同攻击类型（如梯形和S形攻击）。实验基于合成的家庭行为时间序列数据。

Result: 实验表明，所提模型能有效识别和分类FDIAs，为增强电网边缘弹性提供了可扩展方案。

Conclusion: 该研究为智能电网网络安全提供了数据驱动的防御机制，从住宅端点加强了防护。

Abstract: False Data Injection Attacks (FDIAs) pose a significant threat to smart grid
infrastructures, particularly Home Area Networks (HANs), where real-time
monitoring and control are highly adopted. Owing to the comparatively less
stringent security controls and widespread availability of HANs, attackers view
them as an attractive entry point to manipulate aggregated demand patterns,
which can ultimately propagate and disrupt broader grid operations. These
attacks undermine the integrity of smart meter data, enabling malicious actors
to manipulate consumption values without activating conventional alarms,
thereby creating serious vulnerabilities across both residential and
utility-scale infrastructures. This paper presents a machine learning-based
framework for both the detection and classification of FDIAs using residential
energy data. A real-time detection is provided by the lightweight Artificial
Neural Network (ANN), which works by using the most vital features of energy
consumption, cost, and time context. For the classification of different attack
types, a Bidirectional LSTM is trained to recognize normal, trapezoidal, and
sigmoid attack shapes through learning sequential dependencies in the data. A
synthetic time-series dataset was generated to emulate realistic household
behaviour. Experimental results demonstrate that the proposed models are
effective in identifying and classifying FDIAs, offering a scalable solution
for enhancing grid resilience at the edge. This work contributes toward
building intelligent, data-driven defence mechanisms that strengthen smart grid
cybersecurity from residential endpoints.

</details>


### [6] [Certifiably robust malware detectors by design](https://arxiv.org/abs/2508.10038)
*Pierre-Francois Gimenez,Sarath Sivaprasad,Mario Fritz*

Main category: cs.CR

TL;DR: 论文提出了一种新的模型架构（ERDALT），用于设计可证明鲁棒的恶意软件检测方法，并通过分解鲁棒检测器的结构，实现了在脆弱特征上的经验鲁棒性。


<details>
  <summary>Details</summary>
Motivation: 静态恶意软件分析依赖机器学习技术，但容易被对抗样本欺骗。需要一种方法在不改变软件功能的情况下实现鲁棒检测。

Method: 提出了一种新的模型架构和框架ERDALT，通过分解鲁棒检测器的结构，学习经验鲁棒检测器。

Result: 验证了该方法在机器学习恶意软件检测中的有效性，实现了鲁棒检测且性能损失有限。

Conclusion: ERDALT框架为恶意软件检测提供了一种可证明鲁棒的设计方法，适用于脆弱特征。

Abstract: Malware analysis involves analyzing suspicious software to detect malicious
payloads. Static malware analysis, which does not require software execution,
relies increasingly on machine learning techniques to achieve scalability.
Although such techniques obtain very high detection accuracy, they can be
easily evaded with adversarial examples where a few modifications of the sample
can dupe the detector without modifying the behavior of the software. Unlike
other domains, such as computer vision, creating an adversarial example of
malware without altering its functionality requires specific transformations.
We propose a new model architecture for certifiably robust malware detection by
design. In addition, we show that every robust detector can be decomposed into
a specific structure, which can be applied to learn empirically robust malware
detectors, even on fragile features. Our framework ERDALT is based on this
structure. We compare and validate these approaches with machine-learning-based
malware detection methods, allowing for robust detection with limited reduction
of detection performance.

</details>


### [7] [Multi-task Adversarial Attacks against Black-box Model with Few-shot Queries](https://arxiv.org/abs/2508.10039)
*Wenqiang Wang,Yan Xiao,Hao Lin,Yangshijie Zhang,Xiaochun Cao*

Main category: cs.CR

TL;DR: CEMA是一种黑盒多任务文本对抗攻击方法，利用对抗文本的跨任务可转移性，通过少量查询实现高效攻击。


<details>
  <summary>Details</summary>
Motivation: 现有方法依赖共享内部特征和大量查询，难以应对黑盒API、查询限制或多任务场景。

Method: 使用深度级替代模型，以即插即用方式训练，将多任务攻击转化为分类攻击，生成多个对抗候选并选择最有效的。

Result: 在涉及2至6个任务的实验中，CEMA仅需100次查询即可实现高攻击成功率，并能针对商业API和大模型。

Conclusion: CEMA在现实场景中表现出高效性和通用性，适用于多种任务和模型。

Abstract: Current multi-task adversarial text attacks rely on abundant access to shared
internal features and numerous queries, often limited to a single task type. As
a result, these attacks are less effective against practical scenarios
involving black-box feedback APIs, limited queries, or multiple task types. To
bridge this gap, we propose \textbf{C}luster and \textbf{E}nsemble
\textbf{M}ulti-task Text Adversarial \textbf{A}ttack (\textbf{CEMA}), an
effective black-box attack that exploits the transferability of adversarial
texts across different tasks. CEMA simplifies complex multi-task scenarios by
using a \textit{deep-level substitute model} trained in a
\textit{plug-and-play} manner for text classification, enabling attacks without
mimicking the victim model. This approach requires only a few queries for
training, converting multi-task attacks into classification attacks and
allowing attacks across various tasks.
  CEMA generates multiple adversarial candidates using different text
classification methods and selects the one that most effectively attacks
substitute models.
  In experiments involving multi-task models with two, three, or six
tasks--spanning classification, translation, summarization, and text-to-image
generation--CEMA demonstrates significant attack success with as few as 100
queries. Furthermore, CEMA can target commercial APIs (e.g., Baidu and Google
Translate), large language models (e.g., ChatGPT 4o), and image-generation
models (e.g., Stable Diffusion V2), showcasing its versatility and
effectiveness in real-world applications.

</details>


### [8] [Quantum Prime Factorization: A Novel Approach Based on Fermat Method](https://arxiv.org/abs/2508.10041)
*Julien Mellaerts*

Main category: cs.CR

TL;DR: 论文提出了一种新的量子算法，用于分解合数，改进了经典的费马方法，并成功在量子设备上分解了大数。


<details>
  <summary>Details</summary>
Motivation: 研究旨在通过量子算法改进传统的费马分解方法，降低计算复杂度，并探索量子设备在数论问题中的应用。

Method: 结合经典费马方法的改进与量子退火技术，将分解问题转化为优化问题。

Result: 计算复杂度降低四倍，并在量子设备上成功分解了8,689,739这一大数。

Conclusion: 该量子算法在分解合数方面具有显著潜力，为量子计算在数论中的应用提供了新思路。

Abstract: In this paper, we introduce a novel quantum algorithm for the factorization
of composite odd numbers. This work makes two significant contributions. First,
we present a new improvement to the classical Fermat method, fourfold reducing
the computational complexity of factoring. Second, we reformulate Fermat
factorization method as an optimization problem suitable for Quantum Annealers
which allowed us to factorize 8,689,739, the biggest number ever factorized
using a quantum device to our knowledge.

</details>


### [9] [FIDELIS: Blockchain-Enabled Protection Against Poisoning Attacks in Federated Learning](https://arxiv.org/abs/2508.10042)
*Jane Carney,Kushal Upreti,Gaby G. Dagher,Tim Andersen*

Main category: cs.CR

TL;DR: 本文提出了一种基于区块链的联邦学习数据投毒检测框架（\Sys），通过分散全局服务器角色和引入共识验证的法官模型，有效抵御投毒攻击。


<details>
  <summary>Details</summary>
Motivation: 联邦学习虽保护隐私，但易受投毒攻击，现有检测方法缺乏标准化或过度依赖信任。

Method: 提出\Sys框架，分散全局服务器功能，引入由客户端生成并共识验证的法官模型。

Result: 实验表明\Sys能有效抵御投毒攻击，且法官模型具有可扩展性。

Conclusion: \Sys为联邦学习提供了一种去中心化、可扩展的投毒检测解决方案。

Abstract: Federated learning enhances traditional deep learning by enabling the joint
training of a model with the use of IoT device's private data. It ensures
privacy for clients, but is susceptible to data poisoning attacks during
training that degrade model performance and integrity. Current poisoning
detection methods in federated learning lack a standardized detection method or
take significant liberties with trust. In this paper, we present \Sys, a novel
blockchain-enabled poison detection framework in federated learning. The
framework decentralizes the role of the global server across participating
clients. We introduce a judge model used to detect data poisoning in model
updates. The judge model is produced by each client and verified to reach
consensus on a single judge model. We implement our solution to show \Sys is
robust against data poisoning attacks and the creation of our judge model is
scalable.

</details>


### [10] [Securing Agentic AI: Threat Modeling and Risk Analysis for Network Monitoring Agentic AI System](https://arxiv.org/abs/2508.10043)
*Pallavi Zambare,Venkata Nikhil Thanikella,Ying Liu*

Main category: cs.CR

TL;DR: 论文研究了结合大型语言模型（LLMs）与自主代理在网络监控和决策系统中的安全风险，提出了MAESTRO框架，通过七层威胁建模架构暴露和消除漏洞，并验证了两种实际威胁案例。


<details>
  <summary>Details</summary>
Motivation: 研究动机在于揭示LLMs与自主代理结合时可能引发的安全问题，并提出解决方案以增强系统可靠性。

Method: 采用MAESTRO框架，构建原型系统（Python、LangChain、WebSockets），包含推理、内存、参数调优和异常检测模块，并通过实际案例验证威胁。

Result: 确认两种威胁案例：资源拒绝服务和内存污染，导致性能下降；提出多层防御策略（内存隔离、实时异常响应等）。

Conclusion: MAESTRO框架有效用于威胁映射和风险评分，强调内存完整性、逻辑监控和跨层通信保护对代理AI可靠性的重要性。

Abstract: When combining Large Language Models (LLMs) with autonomous agents, used in
network monitoring and decision-making systems, this will create serious
security issues. In this research, the MAESTRO framework consisting of the
seven layers threat modeling architecture in the system was used to expose,
evaluate, and eliminate vulnerabilities of agentic AI. The prototype agent
system was constructed and implemented, using Python, LangChain, and telemetry
in WebSockets, and deployed with inference, memory, parameter tuning, and
anomaly detection modules. Two practical threat cases were confirmed as
follows: (i) resource denial of service by traffic replay denial-of-service,
and (ii) memory poisoning by tampering with the historical log file maintained
by the agent. These situations resulted in measurable levels of performance
degradation, i.e. telemetry updates were delayed, and computational loads were
increased, as a result of poor system adaptations. It was suggested to use a
multilayered defense-in-depth approach with memory isolation, validation of
planners and anomaly response systems in real-time. These findings verify that
MAESTRO is viable in operational threat mapping, prospective risk scoring, and
the basis of the resilient system design. The authors bring attention to the
importance of the enforcement of memory integrity, paying attention to the
adaptation logic monitoring, and cross-layer communication protection that
guarantee the agentic AI reliability in adversarial settings.

</details>


### [11] [Generative AI for Cybersecurity of Energy Management Systems: Methods, Challenges, and Future Directions](https://arxiv.org/abs/2508.10044)
*Aydin Zaboli,Junho Hong*

Main category: cs.CR

TL;DR: 论文提出了一种针对能源管理系统（EMS）的安全框架，结合生成式AI和多模态分析，以应对网络安全漏洞和系统问题。


<details>
  <summary>Details</summary>
Motivation: 现代能源管理系统面临复杂的网络安全威胁和系统错误，需要一种综合性的解决方案。

Method: 提出多点多点攻击/错误模型和生成式AI异常检测系统，并结合视觉标记的多模态分析框架（SoM-GI）。

Result: 在IEEE 14-Bus系统上的验证表明，该框架能有效识别漏洞和视觉异常。

Conclusion: 该框架通过结合数值分析和视觉模式识别，为EMS提供了全面的安全保护。

Abstract: This paper elaborates on an extensive security framework specifically
designed for energy management systems (EMSs), which effectively tackles the
dynamic environment of cybersecurity vulnerabilities and/or system problems
(SPs), accomplished through the incorporation of novel methodologies. A
comprehensive multi-point attack/error model is initially proposed to
systematically identify vulnerabilities throughout the entire EMS data
processing pipeline, including post state estimation (SE) stealth attacks, EMS
database manipulation, and human-machine interface (HMI) display corruption
according to the real-time database (RTDB) storage. This framework acknowledges
the interconnected nature of modern attack vectors, which utilize various
phases of supervisory control and data acquisition (SCADA) data flow. Then,
generative AI (GenAI)-based anomaly detection systems (ADSs) for EMSs are
proposed for the first time in the power system domain to handle the scenarios.
Further, a set-of-mark generative intelligence (SoM-GI) framework, which
leverages multimodal analysis by integrating visual markers with rules
considering the GenAI capabilities, is suggested to overcome inherent spatial
reasoning limitations. The SoM-GI methodology employs systematic visual
indicators to enable accurate interpretation of segmented HMI displays and
detect visual anomalies that numerical methods fail to identify. Validation on
the IEEE 14-Bus system shows the framework's effectiveness across scenarios,
while visual analysis identifies inconsistencies. This integrated approach
combines numerical analysis with visual pattern recognition and linguistic
rules to protect against cyber threats and system errors.

</details>


### [12] [NetMoniAI: An Agentic AI Framework for Network Security & Monitoring](https://arxiv.org/abs/2508.10052)
*Pallavi Zambare,Venkata Nikhil Thanikella,Nikhil Padmanabh Kottur,Sree Akhil Akula,Ying Liu*

Main category: cs.CR

TL;DR: NetMoniAI是一个用于自动网络监控和安全的AI框架，结合了分散分析和轻量级集中协调。


<details>
  <summary>Details</summary>
Motivation: 解决网络监控中资源受限和冗余问题，提高响应时间和准确性。

Method: 采用两层设计：节点上的自主微代理进行本地分析，中央控制器聚合信息以检测协同攻击。

Result: 在测试和模拟中验证了框架的可扩展性，减少了冗余并提高了响应时间。

Conclusion: 框架开源，便于研究和实践中的复制与扩展。

Abstract: In this paper, we present NetMoniAI, an agentic AI framework for automatic
network monitoring and security that integrates decentralized analysis with
lightweight centralized coordination. The framework consists of two layers:
autonomous micro-agents at each node perform local traffic analysis and anomaly
detection. A central controller then aggregates insights across nodes to detect
coordinated attacks and maintain system-wide situational awareness. We
evaluated NetMoniAI on a local micro-testbed and through NS-3 simulations.
Results confirm that the two-tier agentic-AI design scales under resource
constraints, reduces redundancy, and improves response time without
compromising accuracy. To facilitate broader adoption and reproducibility, the
complete framework is available as open source. This enables researchers and
practitioners to replicate, validate, and extend it across diverse network
environments and threat scenarios. Github link:
https://github.com/pzambare3/NetMoniAI

</details>


### [13] [Invisible Watermarks, Visible Gains: Steering Machine Unlearning with Bi-Level Watermarking Design](https://arxiv.org/abs/2508.10065)
*Yuhao Sun,Yihua Zhang,Gaowen Liu,Hongtao Xie,Sijia Liu*

Main category: cs.CR

TL;DR: 论文提出了一种基于数字水印的机器遗忘（MU）新方法Water4MU，通过数据级调整优化遗忘过程，提升模型在敏感数据移除中的效果。


<details>
  <summary>Details</summary>
Motivation: 随着‘被遗忘权’需求的增加，机器遗忘成为提升信任和合规性的重要工具，但现有方法多依赖模型权重调整，数据级调整的潜力未被充分探索。

Method: 提出Water4MU框架，结合数字水印和双层优化（BLO），上层优化水印网络以降低遗忘难度，下层独立训练模型。

Result: 实验表明，Water4MU在图像分类和生成任务中均有效，尤其在‘挑战性遗忘’场景中优于现有方法。

Conclusion: Water4MU通过数据级水印优化，为机器遗忘提供了一种高效且可控的解决方案。

Abstract: With the increasing demand for the right to be forgotten, machine unlearning
(MU) has emerged as a vital tool for enhancing trust and regulatory compliance
by enabling the removal of sensitive data influences from machine learning (ML)
models. However, most MU algorithms primarily rely on in-training methods to
adjust model weights, with limited exploration of the benefits that data-level
adjustments could bring to the unlearning process. To address this gap, we
propose a novel approach that leverages digital watermarking to facilitate MU
by strategically modifying data content. By integrating watermarking, we
establish a controlled unlearning mechanism that enables precise removal of
specified data while maintaining model utility for unrelated tasks. We first
examine the impact of watermarked data on MU, finding that MU effectively
generalizes to watermarked data. Building on this, we introduce an
unlearning-friendly watermarking framework, termed Water4MU, to enhance
unlearning effectiveness. The core of Water4MU is a bi-level optimization (BLO)
framework: at the upper level, the watermarking network is optimized to
minimize unlearning difficulty, while at the lower level, the model itself is
trained independently of watermarking. Experimental results demonstrate that
Water4MU is effective in MU across both image classification and image
generation tasks. Notably, it outperforms existing methods in challenging MU
scenarios, known as "challenging forgets".

</details>


### [14] [An Architecture for Distributed Digital Identities in the Physical World](https://arxiv.org/abs/2508.10185)
*René Mayrhofer,Michael Roland,Tobias Höller,Philipp Hofer,Mario Lins*

Main category: cs.CR

TL;DR: 论文提出了一种分布式数字身份架构，用于物理世界交易，解决了集中式身份管理的隐私和可用性问题。


<details>
  <summary>Details</summary>
Motivation: 集中式身份管理存在单点故障和隐私风险，需要一种去中心化的解决方案。

Method: 设计了结合传感器、身份机构、属性验证器和个人身份代理（PIA）的分布式架构，并提出了协议。

Result: 协议通过形式化验证满足安全需求，概念验证实现展示了可行性。

Conclusion: 分布式架构在容忍几秒延迟的应用中具有实用潜力。

Abstract: Digital identities are increasingly important for mediating not only digital
but also physical service transactions. Managing such identities through
centralized providers can cause both availability and privacy concerns: single
points of failure and control are ideal targets for global attacks on
technical, organizational, or legal fronts. We design, analyze, and build a
distributed digital identity architecture for physical world transactions in
common scenarios like unlocking doors, public transport, or crossing country
borders. This architecture combines (biometric and other) sensors, (established
and upcoming) identity authorities, attribute verifiers, and a new core
component we call the \emph{Personal Identity Agent (PIA)} that represents
individuals with their identity attributes in the digital domain. All
transactions are conducted in a completely decentralized manner, and the
components for which we currently assume central coordination are optional and
only used for assisting with service discovery and latency reduction. We
present a first protocol between these parties and formally verify that it
achieves relevant security properties based on a realistic threat model
including strong global adversaries. A proof-of-concept implementation
demonstrates practical feasibility of both architecture and initial protocol
for applications that can tolerate end-to-end latencies in the range of a few
seconds.

</details>


### [15] [Detecting Untargeted Attacks and Mitigating Unreliable Updates in Federated Learning for Underground Mining Operations](https://arxiv.org/abs/2508.10212)
*Md Sazedur Rahman,Mohamed Elmahallawy,Sanjay Madria,Samuel Frimpong*

Main category: cs.CR

TL;DR: 论文提出MineDetect，一种防御性联邦学习框架，用于地下采矿中检测和隔离受攻击模型，同时减少低质量数据的影响。


<details>
  <summary>Details</summary>
Motivation: 地下采矿依赖分布式传感器网络收集数据，但传输原始数据存在隐私风险。联邦学习（FL）虽能保护数据隐私，但面临模型被攻击和低质量数据的问题。

Method: MineDetect通过历史感知机制检测受攻击模型，并识别和消除不可靠模型对FL训练的影响。

Result: 实验表明，MineDetect在鲁棒性和准确性上优于现有方法，尤其在非独立同分布数据场景中表现突出。

Conclusion: MineDetect在提高地下采矿安全性和操作效率方面具有重要意义。

Abstract: Underground mining operations rely on distributed sensor networks to collect
critical data daily, including mine temperature, toxic gas concentrations, and
miner movements for hazard detection and operational decision-making. However,
transmitting raw sensor data to a central server for training deep learning
models introduces significant privacy risks, potentially exposing sensitive
mine-specific information. Federated Learning (FL) offers a transformative
solution by enabling collaborative model training while ensuring that raw data
remains localized at each mine. Despite its advantages, FL in underground
mining faces key challenges: (i) An attacker may compromise a mine's local
model by employing techniques such as sign-flipping attacks or additive noise,
leading to erroneous predictions; (ii) Low-quality (yet potentially valuable)
data, caused by poor lighting conditions or sensor inaccuracies in mines may
degrade the FL training process. In response, this paper proposes MineDetect, a
defense FL framework that detects and isolates the attacked models while
mitigating the impact of mines with low-quality data. MineDetect introduces two
key innovations: (i) Detecting attacked models (maliciously manipulated) by
developing a history-aware mechanism that leverages local and global averages
of gradient updates; (ii) Identifying and eliminating adversarial influences
from unreliable models (generated by clients with poor data quality) on the FL
training process. Comprehensive simulations across diverse datasets demonstrate
that MineDetect outperforms existing methods in both robustness and accuracy,
even in challenging non-IID data scenarios. Its ability to counter adversarial
influences while maintaining lower computational efficiency makes it a vital
advancement for improving safety and operational effectiveness in underground
mining.

</details>


### [16] [BERTector: Intrusion Detection Based on Joint-Dataset Learning](https://arxiv.org/abs/2508.10327)
*Haoyang Hu,Xun Huang,Chenyu Wu,Shiwen Liu,Zhichao Lian,Shuangquan Zhang*

Main category: cs.CR

TL;DR: 提出了一种基于BERT的IDS框架BERTector，通过联合数据集训练和高效组件提升检测精度、泛化能力和鲁棒性。


<details>
  <summary>Details</summary>
Motivation: 解决IDS因网络流量异构性和攻击模式多样性导致的泛化和鲁棒性问题。

Method: 提出BERTector框架，包含NSS-Tokenizer、监督微调和LoRA高效训练。

Result: 实验表明BERTector在检测精度、跨数据集泛化和对抗扰动鲁棒性上表现优异。

Conclusion: 为复杂动态网络环境中的IDS提供了统一高效的解决方案。

Abstract: Intrusion detection systems (IDS) are facing challenges in generalization and
robustness due to the heterogeneity of network traffic and the diversity of
attack patterns. To address this issue, we propose a new joint-dataset training
paradigm for IDS and propose a scalable BERTector framework based on BERT.
BERTector integrates three key components: NSS-Tokenizer for traffic-aware
semantic tokenization, supervised fine-tuning with a hybrid dataset, and
low-rank adaptation (LoRA) for efficient training. Extensive experiments show
that BERTector achieves state-of-the-art detection accuracy, strong
cross-dataset generalization capabilities, and excellent robustness to
adversarial perturbations. This work establishes a unified and efficient
solution for modern IDS in complex and dynamic network environments.

</details>


### [17] [Yet Another Mirage of Breaking MIRAGE: Debunking Occupancy-based Side-Channel Attacks on Fully Associative Randomized Caches](https://arxiv.org/abs/2508.10431)
*Chris Cao,Gururaj Saileshwar*

Main category: cs.CR

TL;DR: 研究发现USENIX Security 2025提出的MIRAGE随机化缓存攻击存在建模缺陷，攻击成功源于错误的固定随机种子设置，实际随机化操作下攻击失效。


<details>
  <summary>Details</summary>
Motivation: 验证USENIX Security 2025中关于MIRAGE缓存攻击的结论是否成立，揭示其建模中的问题。

Method: 通过对比固定随机种子和实际随机化操作的MIRAGE实现，分析攻击的有效性。

Result: 固定种子导致虚假的可重复时序模式，实际随机化操作下攻击失效。

Conclusion: 报告的漏洞源于建模错误，MIRAGE在实际操作中无此漏洞。

Abstract: Recent work presented at USENIX Security 2025 claims that occupancy-based
attacks can recover AES keys from the MIRAGE randomized cache. In this paper,
we examine these claims and find that they arise from fundamental modeling
flaws. Most critically, the authors' simulation of MIRAGE uses a constant seed
to initialize the random number generator used for global evictions in MIRAGE,
causing every AES encryption they trace to evict the same deterministic
sequence of cache lines. This artificially creates a highly repeatable timing
pattern that is not representative of a realistic implementation of MIRAGE,
where eviction sequences vary randomly between encryptions. When we instead
randomize the eviction seed for each run, reflecting realistic operation, the
correlation between AES T-table accesses and attacker runtimes disappears, and
the attack fails. These findings show that the reported leakage is an artifact
of incorrect modeling, and not an actual vulnerability in MIRAGE.

</details>


### [18] [AlDBaran: Towards Blazingly Fast State Commitments for Blockchains](https://arxiv.org/abs/2508.10493)
*Bernhard Kauer,Aleksandr Petrosyan,Benjamin Livshits*

Main category: cs.CR

TL;DR: AlDBaran是一种高性能的认证数据库，通过优化磁盘I/O、预取策略和Merkle树更新机制，支持高吞吐量区块链系统，性能显著优于现有方案。


<details>
  <summary>Details</summary>
Motivation: 现有认证数据库无法满足高吞吐量区块链系统的需求，AlDBaran旨在解决这一问题。

Method: 通过消除磁盘I/O、实施预取策略和改进Merkle树更新机制，设计高效认证数据结构。

Result: AlDBaran支持50 Gbps网络吞吐量，每秒4800万次更新，性能远超现有方案。

Conclusion: AlDBaran为高吞吐量区块链提供了高效、可扩展的解决方案，支持新颖应用如轻客户端和rollups。

Abstract: The fundamental basis for maintaining integrity within contemporary
blockchain systems is provided by authenticated databases. Our analysis
indicates that a significant portion of the approaches applied in this domain
fail to sufficiently meet the stringent requirements of systems processing
transactions at rates of multi-million TPS. AlDBaran signifies a substantial
advancement in authenticated databases. By eliminating disk I/O operations from
the critical path, implementing prefetching strategies, and refining the update
mechanism of the Merkle tree, we have engineered an authenticated data
structure capable of handling state updates efficiently at a network throughput
of 50 Gbps. This throughput capacity significantly surpasses any empirically
documented blockchain throughput, guaranteeing the ability of even the most
high-throughput blockchains to generate state commitments effectively.
  AlDBaran provides support for historical state proofs, which facilitates a
wide array of novel applications. For instance, the deployment of AlDBaran
could enable blockchains that do not currently support state commitments to
offer functionalities for light clients and/or implement rollups.
  When benchmarked against alternative authenticated data structure projects,
AlDBaran exhibits superior performance and simplicity. In particular, AlDBaran
achieves speeds of approximately 48 million updates per second using an
identical machine configuration. This characteristic renders AlDBaran an
attractive solution for resource-limited environments, as its historical data
capabilities can be modularly isolated (and deactivated), which further
enhances performance. On consumer-level portable hardware, it achieves
approximately 8 million updates/s in an in-memory setting and 5 million
updates/s with snapshots at sub-second intervals, illustrating compelling and
cost-effective scalability.

</details>


### [19] [Codes on any Cayley Graph have an Interactive Oracle Proof of Proximity](https://arxiv.org/abs/2508.10510)
*Hugo Delavenne,Louise Lallemand*

Main category: cs.CR

TL;DR: 本文提出了一种将特定Tanner码的开花IOPP协议推广到更广泛代码的方法，基于Cayley图的边索引符号，保留了较低的soundness参数，并允许应用于具有恒定速率和最小距离的代码。


<details>
  <summary>Details</summary>
Motivation: 扩展开花IOPP协议的适用范围，使其能应用于更多类型的代码，同时保持较低的soundness参数和较好的复杂度。

Method: 利用Cayley图的良好扩展性质，将开花IOPP协议推广到边索引符号的代码上。

Result: 提出的推广方法保留了较低的soundness参数，复杂度略有下降，适用于具有恒定速率和最小距离的代码。

Conclusion: 通过Cayley图的扩展性质，成功推广了开花IOPP协议，为更广泛的代码提供了高效的IOPP解决方案。

Abstract: Interactive Oracle Proofs of Proximity (IOPP) are at the heart of code-based
SNARKs, a family of zeroknowledge protocols. The first and most famous one is
the FRI protocol [BBHR18a], that efficiently tests proximity to Reed-Solomon
codes. This paper generalizes the flowering IOPP introduced in [DMR25] for some
specific (2, n)-regular Tanner codes to a much broader variety of codes: any
code with symbols indexed on the edges of a Cayley graph. The flowering
protocol of [DMR25] had a soundness parameter much lower than the FRI protocol
[BCI + 23], and complexity parameters that could compete with the FRI
[BBHR18a]. The lower soundness and the absence of restriction on the base field
may lead to other practical speedups, however the codes considered in [DMR25]
have an o(1) minimum distance. The generalization proposed in this paper
preserves the soundness parameter with a slight decrease of the complexity
parameters, while allowing being applied on codes with constant rate and
constant minimum distance thanks to the good expansion properties of some
families of Cayley graphs.

</details>


### [20] [A Transformer-Based Approach for DDoS Attack Detection in IoT Networks](https://arxiv.org/abs/2508.10636)
*Sandipan Dey,Payal Santosh Kate,Vatsala Upadhyay,Abhishek Vaish*

Main category: cs.CR

TL;DR: 论文提出了一种基于Transformer模型的新方法，用于检测IoT设备上的DDoS攻击，优于传统机器学习方法。


<details>
  <summary>Details</summary>
Motivation: IoT设备因资源受限易受DDoS攻击，传统检测方法无法应对动态网络和高流量等挑战。

Method: 使用Transformer模型提取网络流量特征，并通过自注意力机制处理数据。

Result: 实验表明，该方法在准确性、精确率、召回率和F1分数上优于传统技术。

Conclusion: Transformer模型是检测IoT设备DDoS攻击的有效解决方案，具有实际部署潜力。

Abstract: DDoS attacks have become a major threat to the security of IoT devices and
can cause severe damage to the network infrastructure. IoT devices suffer from
the inherent problem of resource constraints and are therefore susceptible to
such resource-exhausting attacks. Traditional methods for detecting DDoS
attacks are not efficient enough to cope with the dynamic nature of IoT
networks, as well as the scalability of the attacks, diversity of protocols,
high volume of traffic, and variability in device behavior, and variability of
protocols like MQTT, CoAP, making it hard to implement security across all the
protocols. In this paper, we propose a novel approach, i.e., the use of
Transformer models, which have shown remarkable performance in natural language
processing tasks, for detecting DDoS attacks on IoT devices. The proposed model
extracts features from network traffic data and processes them using a
self-attention mechanism. Experiments conducted on a real-world dataset
demonstrate that the proposed approach outperforms traditional machine learning
techniques, which can be validated by comparing both approaches' accuracy,
precision, recall, and F1-score. The results of this study show that the
Transformer models can be an effective solution for detecting DDoS attacks on
IoT devices and have the potential to be deployed in real-world IoT
environments.

</details>


### [21] [MirGuard: Towards a Robust Provenance-based Intrusion Detection System Against Graph Manipulation Attacks](https://arxiv.org/abs/2508.10639)
*Anyuan Sang,Lu Zhou,Li Yang,Junbo Jia,Huipeng Yang,Pengbin Feng,Jianfeng Ma*

Main category: cs.CR

TL;DR: 本文提出MirGuard框架，通过逻辑感知的多视图增强和对比表示学习，提升基于学习的溯源入侵检测系统（PIDSes）对图操纵攻击的鲁棒性。


<details>
  <summary>Details</summary>
Motivation: 现有的PIDSes易受图操纵攻击，缺乏鲁棒解决方案，限制了其实际应用。

Method: 结合逻辑感知噪声注入（LNI）生成语义有效的图视图，并通过逻辑保持对比学习框架学习鲁棒表示。

Result: 在多溯源数据集上，MirGuard显著优于现有检测器，对抗攻击鲁棒性提升且不影响检测性能。

Conclusion: MirGuard首次针对PIDSes的对抗威胁提供鲁棒解决方案，为现代网络安全挑战提供有效应对。

Abstract: Learning-based Provenance-based Intrusion Detection Systems (PIDSes) have
become essential tools for anomaly detection in host systems due to their
ability to capture rich contextual and structural information, as well as their
potential to detect unknown attacks. However, recent studies have shown that
these systems are vulnerable to graph manipulation attacks, where attackers
manipulate the graph structure to evade detection. While some previous
approaches have discussed this type of attack, none have fully addressed it
with a robust detection solution, limiting the practical applicability of
PIDSes.
  To address this challenge, we propose MirGuard, a robust anomaly detection
framework that combines logic-aware multi-view augmentation with contrastive
representation learning. Rather than applying arbitrary structural
perturbations, MirGuard introduces Logic-Aware Noise Injection (LNI) to
generate semantically valid graph views, ensuring that all augmentations
preserve the underlying causal semantics of the provenance data. These views
are then used in a Logic-Preserving Contrastive Learning framework, which
encourages the model to learn representations that are invariant to benign
transformations but sensitive to adversarial inconsistencies. Comprehensive
evaluations on multiple provenance datasets demonstrate that MirGuard
significantly outperforms state-of-the-art detectors in robustness against
various graph manipulation attacks without sacrificing detection performance
and efficiency. Our work represents the first targeted study to enhance PIDS
against such adversarial threats, providing a robust and effective solution to
modern cybersecurity challenges.

</details>


### [22] [A Novel Study on Intelligent Methods and Explainable AI for Dynamic Malware Analysis](https://arxiv.org/abs/2508.10652)
*Richa Dasila,Vatsala Upadhyay,Samo Bobek,Abhishek Vaish*

Main category: cs.CR

TL;DR: 该研究通过可解释AI（XAI）技术提升深度学习模型在恶意软件检测中的透明度和可信度，探索了MLP、CNN、RNN和CNN-LSTM等模型在动态分析中的效果。


<details>
  <summary>Details</summary>
Motivation: 深度学习模型在恶意软件检测中表现出色，但其决策过程不透明，难以理解和信任。

Method: 研究采用XAI技术，结合MLP、CNN、RNN和CNN-LSTM模型，进行动态恶意软件分析和分类。

Result: 通过XAI技术，模型的可解释性和透明度得到提升，为恶意软件检测提供了更可信的预测能力。

Conclusion: 该研究为深度学习模型在网络安全中的应用提供了更透明的解决方案，增强了其可信度。

Abstract: Deep learning models are one of the security strategies, trained on extensive
datasets, and play a critical role in detecting and responding to these threats
by recognizing complex patterns in malicious code. However, the opaque nature
of these models-often described as "black boxes"-makes their decision-making
processes difficult to understand, even for their creators. This research
addresses these challenges by integrating Explainable AI (XAI) techniques to
enhance the interpretability and trustworthiness of malware detection models.
In this research, the use of Multi-Layer Perceptrons (MLP) for dynamic malware
analysis has been considered, a less explored area, and its efficacy in
detecting Metamorphic Malware, and further the effectiveness and transparency
of MLPs, CNNs, RNNs, and CNN-LSTM models in malware classification, evaluating
these models through the lens of Explainable AI (XAI). This comprehensive
approach aims to demystify the internal workings of deep learning models,
promoting a better understanding and trust in their predictive capabilities in
cybersecurity contexts. Such in-depth analysis and implementation haven't been
done to the best of our knowledge.

</details>


### [23] [Advancing Autonomous Incident Response: Leveraging LLMs and Cyber Threat Intelligence](https://arxiv.org/abs/2508.10677)
*Amine Tellache,Abdelaziz Amara Korba,Amdjed Mokhtari,Horea Moldovan,Yacine Ghamri-Doudane*

Main category: cs.CR

TL;DR: 提出了一种基于检索增强生成（RAG）的框架，利用大型语言模型（LLM）自动化和增强事件响应（IR），通过动态检索网络威胁情报（CTI）来减轻安全团队的工作负担。


<details>
  <summary>Details</summary>
Motivation: 安全团队面临警报疲劳、高误报率和大量非结构化CTI文档的挑战，手动分析耗时且资源密集。

Method: 采用混合检索机制，结合NLP相似性搜索和标准化查询外部CTI平台，利用LLM生成上下文相关的缓解策略。

Result: 实证验证表明，该方法提高了IR的准确性、上下文化和效率，减轻了分析师负担并缩短了响应时间。

Conclusion: LLM驱动的CTI融合在推进自主安全操作和建立智能自适应网络安全框架方面具有潜力。

Abstract: Effective incident response (IR) is critical for mitigating cyber threats,
yet security teams are overwhelmed by alert fatigue, high false-positive rates,
and the vast volume of unstructured Cyber Threat Intelligence (CTI) documents.
While CTI holds immense potential for enriching security operations, its
extensive and fragmented nature makes manual analysis time-consuming and
resource-intensive. To bridge this gap, we introduce a novel
Retrieval-Augmented Generation (RAG)-based framework that leverages Large
Language Models (LLMs) to automate and enhance IR by integrating dynamically
retrieved CTI. Our approach introduces a hybrid retrieval mechanism that
combines NLP-based similarity searches within a CTI vector database with
standardized queries to external CTI platforms, facilitating context-aware
enrichment of security alerts. The augmented intelligence is then leveraged by
an LLM-powered response generation module, which formulates precise,
actionable, and contextually relevant incident mitigation strategies. We
propose a dual evaluation paradigm, wherein automated assessment using an
auxiliary LLM is systematically cross-validated by cybersecurity experts.
Empirical validation on real-world and simulated alerts demonstrates that our
approach enhances the accuracy, contextualization, and efficiency of IR,
alleviating analyst workload and reducing response latency. This work
underscores the potential of LLM-driven CTI fusion in advancing autonomous
security operations and establishing a foundation for intelligent, adaptive
cybersecurity frameworks.

</details>


### [24] [Searching for Privacy Risks in LLM Agents via Simulation](https://arxiv.org/abs/2508.10880)
*Yanzhe Zhang,Diyi Yang*

Main category: cs.CR

TL;DR: 论文提出了一种基于搜索的框架，通过模拟隐私关键代理交互来发现和防御LLM代理中的隐私威胁。


<details>
  <summary>Details</summary>
Motivation: LLM代理的广泛部署可能引发隐私威胁，恶意代理通过多轮交互提取敏感信息，动态对话的适应性攻击策略难以手动预测。

Method: 采用搜索框架，模拟数据主体、发送者和接收者的交互，利用LLM优化并行搜索，迭代改进攻击和防御指令。

Result: 发现攻击策略从直接请求升级为复杂多轮战术（如冒充和伪造同意），防御从规则约束发展为身份验证状态机。

Conclusion: 该方法在不同场景和模型中具有实用价值，有助于构建隐私感知代理。

Abstract: The widespread deployment of LLM-based agents is likely to introduce a
critical privacy threat: malicious agents that proactively engage others in
multi-turn interactions to extract sensitive information. These dynamic
dialogues enable adaptive attack strategies that can cause severe privacy
violations, yet their evolving nature makes it difficult to anticipate and
discover sophisticated vulnerabilities manually. To tackle this problem, we
present a search-based framework that alternates between improving attacker and
defender instructions by simulating privacy-critical agent interactions. Each
simulation involves three roles: data subject, data sender, and data recipient.
While the data subject's behavior is fixed, the attacker (data recipient)
attempts to extract sensitive information from the defender (data sender)
through persistent and interactive exchanges. To explore this interaction space
efficiently, our search algorithm employs LLMs as optimizers, using parallel
search with multiple threads and cross-thread propagation to analyze simulation
trajectories and iteratively propose new instructions. Through this process, we
find that attack strategies escalate from simple direct requests to
sophisticated multi-turn tactics such as impersonation and consent forgery,
while defenses advance from rule-based constraints to identity-verification
state machines. The discovered attacks and defenses transfer across diverse
scenarios and backbone models, demonstrating strong practical utility for
building privacy-aware agents.

</details>
