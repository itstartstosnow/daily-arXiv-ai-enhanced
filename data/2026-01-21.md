<div id=toc></div>

# Table of Contents

- [cs.CR](#cs.CR) [Total: 65]


<div id='cs.CR'></div>

# cs.CR [[Back]](#toc)

### [1] [Privacy-Preserving Black-Box Optimization (PBBO): Theory and the Model-Based Algorithm DFOp](https://arxiv.org/abs/2601.11570)
*Pengcheng Xie*

Main category: cs.CR

TL;DR: 提出DFOp算法解决隐私保护黑盒优化问题，包含新的二次模型更新公式和差分隐私机制，是首个能处理步加密和隐私保护黑盒优化的无导数求解器。


<details>
  <summary>Details</summary>
Motivation: 解决无约束隐私保护黑盒优化问题，探索无导数优化与隐私保护的结合，填补该领域的研究空白。

Method: 提出DFOp无导数求解器，包含新的最小Frobenius范数二次模型更新公式，以及两种差分隐私噪声添加机制。

Result: DFOp在数值实验中表现优于对比算法，能有效处理变换/加密目标函数问题，并证明了算法的收敛性。

Conclusion: DFOp是首个能精确解决步加密和隐私保护黑盒优化问题的无导数求解器，为无导数优化与隐私保护的结合提供了解决方案。

Abstract: This paper focuses on solving unconstrained privacy-preserving black-box optimization (PBBO), its corresponding least Frobenius norm updating of quadratic models, and the differentially privacy mechanisms for PBBO. Optimization problems with transformed/encrypted objective functions aim to minimize F(x), which is encrypted/transformed/encrypted to F_k(x) as the output at the k-th iteration. A new derivative-free solver named DFOp, with its implementation, is proposed in this paper, which has a new updating formula for the quadratic model functions. The convergence of DFOp for solving problems with transformed/encrypted objective functions is given. Other analyses, including the new model updating formula and the analysis of the transformation's impact to model functions are presented. We propose two differentially private noise-adding mechanisms for privacy-preserving black-box optimization. Numerical results show that DFOp performs better than compared algorithms. To the best of our knowledge, DFOp is the first derivative-free solver that can solve black-box optimization problems with step-encryption and privacy-preserving black-box problems exactly, which also tries to answer the open question about the combination of derivative-free optimization and privacy.

</details>


### [2] [Semantic Differentiation for Tackling Challenges in Watermarking Low-Entropy Constrained Generation Outputs](https://arxiv.org/abs/2601.11629)
*Nghia T. Le,Alan Ritter,Kartik Goyal*

Main category: cs.CR

TL;DR: SeqMark是一种序列级水印算法，针对低熵输出空间的约束生成任务，通过语义区分平衡输出质量、水印可检测性和不可感知性，相比现有方法显著提升水印检测准确率。


<details>
  <summary>Details</summary>
Motivation: 现有语言模型水印方法在开放生成任务中有效，但在低熵输出空间的约束生成任务中表现不佳，需要开发专门针对此类任务的水印算法。

Method: SeqMark是一种序列级水印算法，通过语义区分将高概率输出子空间划分为有效和无效区域，避免区域崩溃问题，充分利用序列级熵。

Result: 在机器翻译、代码生成和摘要生成等约束生成任务上，SeqMark显著提升水印检测准确率（F1分数最高提升28%），同时保持高质量生成。

Conclusion: SeqMark解决了现有水印方法在约束生成任务中的局限性，通过序列级语义区分方法实现了输出质量、水印可检测性和不可感知性的更好平衡。

Abstract: We demonstrate that while the current approaches for language model watermarking are effective for open-ended generation, they are inadequate at watermarking LM outputs for constrained generation tasks with low-entropy output spaces. Therefore, we devise SeqMark, a sequence-level watermarking algorithm with semantic differentiation that balances the output quality, watermark detectability, and imperceptibility. It improves on the shortcomings of the prevalent token-level watermarking algorithms that cause under-utilization of the sequence-level entropy available for constrained generation tasks. Moreover, we identify and improve upon a different failure mode we term region collapse, associated with prior sequence-level watermarking algorithms. This occurs because the pseudorandom partitioning of semantic space for watermarking in these approaches causes all high-probability outputs to collapse into either invalid or valid regions, leading to a trade-off in output quality and watermarking effectiveness. SeqMark instead, differentiates the high-probable output subspace and partitions it into valid and invalid regions, ensuring the even spread of high-quality outputs among all the regions. On various constrained generation tasks like machine translation, code generation, and abstractive summarization, SeqMark substantially improves watermark detection accuracy (up to 28% increase in F1) while maintaining high generation quality.

</details>


### [3] [Serverless AI Security: Attack Surface Analysis and Runtime Protection Mechanisms for FaaS-Based Machine Learning](https://arxiv.org/abs/2601.11664)
*Chetan Pathade,Vinod Dhimam,Sheheryar Ahmad,Ilsa Lareb*

Main category: cs.CR

TL;DR: 本文首次全面分析了无服务器环境中机器学习工作负载的安全问题，提出了Serverless AI Shield防御框架，检测率达94%，性能开销低于9%。


<details>
  <summary>Details</summary>
Motivation: 无服务器计算广泛采用（70% AWS组织使用），机器学习推理工作负载迁移到FaaS平台，但AI/ML漏洞增加220%，无服务器架构带来新的安全挑战，需要系统分析。

Method: 系统分析五个攻击面类别：函数级漏洞、模型特定威胁、基础设施攻击、供应链风险、IAM复杂性；在AWS Lambda、Azure Functions、Google Cloud Functions进行实证评估；提出Serverless AI Shield多层防御框架，包括部署前验证、运行时监控、执行后取证。

Result: 展示了真实攻击场景并量化安全影响；Serverless AI Shield实现94%检测率，推理延迟性能开销低于9%；发布了开源安全工具包。

Conclusion: 首次全面分析无服务器环境中机器学习工作负载的安全问题，提出有效防御框架，推动云原生机器学习系统向更安全方向发展。

Abstract: Serverless computing has achieved widespread adoption, with over 70% of AWS organizations using serverless solutions [1]. Meanwhile, machine learning inference workloads increasingly migrate to Function-as-a-Service (FaaS) platforms for their scalability and cost-efficiency [2], [3], [4]. However, this convergence introduces critical security challenges, with recent reports showing a 220% increase in AI/ML vulnerabilities [5] and serverless computing's fragmented architecture raises new security concerns distinct from traditional cloud deployments [6], [7]. This paper presents the first comprehensive security analysis of machine learning workloads in serverless environments. We systematically characterize the attack surface across five categories: function-level vulnerabilities (cold start exploitation, dependency poisoning), model-specific threats (API-based extraction, adversarial inputs), infrastructure attacks (cross-function contamination, privilege escalation), supply chain risks (malicious layers, backdoored libraries), and IAM complexity (ephemeral nature, serverless functions). Through empirical assessments across AWS Lambda, Azure Functions, and Google Cloud Functions, we demonstrate real-world attack scenarios and quantify their security impact. We propose Serverless AI Shield (SAS), a multi-layered defense framework providing pre-deployment validation, runtime monitoring, and post-execution forensics. Our evaluation shows SAS achieves 94% detection rates while maintaining performance overhead below 9% for inference latency. We release an open-source security toolkit to enable practitioners to assess and harden their serverless AI deployments, advancing the field toward more resilient cloud-native machine learning systems.

</details>


### [4] [A Survey on Mapping Digital Systems with Bill of Materials: Development, Practices, and Challenges](https://arxiv.org/abs/2601.11678)
*Shuai Zhang,Minzhao Lyu,Hassan Habibi Gharakheili*

Main category: cs.CR

TL;DR: 本文首次对跨领域物料清单(BOM)的发展与实践进行全面综述，涵盖硬件、软件、AI模型、数据集和加密资产等领域，分析BOM框架演进、行业实践、应用场景及研究挑战。


<details>
  <summary>Details</summary>
Motivation: 随着数字生态系统（软件、硬件、学习模型、数据集、加密产品）日益复杂，组织难以理解和管理组件依赖关系。物料清单(BOM)作为结构化文档方式，能够记录产品组件、相互关系及关键元数据，提高数字供应链的可视性和安全性。

Method: 1. 考察BOM框架在三个阶段的演进（预开发、初始、加速阶段）；2. 总结硬件、软件、AI模型、数据集和加密资产领域的核心原则、关键利益相关者和标准化工作；3. 回顾行业生成BOM数据、评估质量及安全共享的实践；4. 分析BOM数据的实际下游应用；5. 讨论学术界改进现有BOM框架的努力。

Result: 1. 提供了首个跨领域BOM发展与实践的全面综述；2. 识别了当前BOM框架在三个阶段的演进模式；3. 总结了各数字领域BOM的核心原则和标准化现状；4. 梳理了行业实践和学术研究进展；5. 发现了限制当前BOM框架可用性和可靠性的四个关键差距。

Conclusion: BOM框架在提高数字供应链可视性和安全性方面发挥关键作用，但当前框架存在四个关键差距限制了其可用性和可靠性，这为未来研究提供了方向，特别是在数据生态系统和AI供应链等新兴领域。

Abstract: Modern digital ecosystems, spanning software, hardware, learning models, datasets, and cryptographic products, continue to grow in complexity, making it difficult for organizations to understand and manage component dependencies. Bills of Materials (BOMs) have emerged as a structured way to document product components, their interrelationships, and key metadata, improving visibility and security across digital supply chains. This survey provides the first comprehensive cross-domain review of BOM developments and practices. We start by examining the evolution of BOM frameworks in three stages (i.e., pre-development, initial, and accelerated) and summarizing their core principles, key stakeholders, and standardization efforts for hardware, software, artificial intelligence (AI) models, datasets, and cryptographic assets. We then review industry practices for generating BOM data, evaluating its quality, and securely sharing it. Next, we review practical downstream uses of BOM data, including dependency modeling, compliance verification, operational risk assessment, and vulnerability tracking. We also discuss academic efforts to address limitations in current BOM frameworks through refinements, extensions, or new models tailored to emerging domains such as data ecosystems and AI supply chains. Finally, we identify four key gaps that limit the usability and reliability of today's BOM frameworks, motivating future research directions.

</details>


### [5] [Attesting Model Lineage by Consisted Knowledge Evolution with Fine-Tuning Trajectory](https://arxiv.org/abs/2601.11683)
*Zhuoyi Shang,Jiasen Li,Pengzhen Chen,Yanwei Liu,Xiaoyan Gu,Weiping Wang*

Main category: cs.CR

TL;DR: 提出基于知识演化和参数修改联合轨迹的模型谱系认证框架，通过模型编辑量化参数变化，知识向量化机制提取演化知识，实现可靠的模型谱系验证。


<details>
  <summary>Details</summary>
Motivation: 深度学习微调技术产生了模型间的谱系关系，但现有方法主要依赖静态架构相似性，无法捕捉知识演化的动态过程。在开源权重模型库中，缺乏有效的谱系验证机制，存在未授权模型分发和虚假模型来源声明等安全问题。

Method: 提出模型谱系认证框架：1) 利用模型编辑量化微调引入的参数级变化；2) 引入知识向量化机制，通过探针样本将编辑模型中演化的知识提炼为紧凑表示；3) 针对不同类型模型家族调整探针策略；4) 基于知识关系的算术一致性验证实现谱系认证。

Result: 在多种真实世界对抗场景下的广泛实验评估表明，该方法在分类器、扩散模型和大语言模型等多种模型类型上都能实现可靠的谱系验证，具有有效性和鲁棒性。

Conclusion: 通过验证知识演化和参数修改的联合轨迹，提出的框架能够有效解决模型谱系认证问题，为开源模型库中的安全关切提供了可靠的解决方案。

Abstract: The fine-tuning technique in deep learning gives rise to an emerging lineage relationship among models. This lineage provides a promising perspective for addressing security concerns such as unauthorized model redistribution and false claim of model provenance, which are particularly pressing in \textcolor{blue}{open-weight model} libraries where robust lineage verification mechanisms are often lacking. Existing approaches to model lineage detection primarily rely on static architectural similarities, which are insufficient to capture the dynamic evolution of knowledge that underlies true lineage relationships. Drawing inspiration from the genetic mechanism of human evolution, we tackle the problem of model lineage attestation by verifying the joint trajectory of knowledge evolution and parameter modification. To this end, we propose a novel model lineage attestation framework. In our framework, model editing is first leveraged to quantify parameter-level changes introduced by fine-tuning. Subsequently, we introduce a novel knowledge vectorization mechanism that refines the evolved knowledge within the edited models into compact representations by the assistance of probe samples. The probing strategies are adapted to different types of model families. These embeddings serve as the foundation for verifying the arithmetic consistency of knowledge relationships across models, thereby enabling robust attestation of model lineage. Extensive experimental evaluations demonstrate the effectiveness and resilience of our approach in a variety of adversarial scenarios in the real world. Our method consistently achieves reliable lineage verification across a broad spectrum of model types, including classifiers, diffusion models, and large language models.

</details>


### [6] [On Abnormal Execution Timing of Conditional Jump Instructions](https://arxiv.org/abs/2601.11696)
*Annika Wilde,Samira Briongos,Claudio Soriente,Ghassan Karame*

Main category: cs.CR

TL;DR: 论文系统测量分析了现代处理器中条件跳转指令的时序变异性，发现这种变异性源于微操作缓存放置和L1指令缓存偏移，可通过32字节对齐避免，并能作为隐蔽信道利用。


<details>
  <summary>Details</summary>
Motivation: 现代计算架构中指令执行时间可能受操作数或系统优化（如分支预测和推测执行）影响。本文旨在系统测量和分析条件跳转指令的时序变异性，特别是那些可与前一条指令宏融合的跳转指令，探究其在不同二进制布局中的表现。

Method: 通过系统测量和分析条件跳转指令的时序变异性，研究微操作缓存放置和L1指令缓存偏移对执行时间的影响。在多种微架构（Skylake、Coffee Lake、Kaby Lake）和实际实现上进行测试，并在大规模流行二进制文件集（包括Ubuntu 24.04、Windows 10 Pro库和多个开源密码库）上进行广泛实验验证。

Result: 测量表明时序变异性源于微操作缓存放置和跳转指令在L1指令缓存中的偏移，这种行为在多种微架构和实际实现中保持一致。通过确保宏可融合指令32字节对齐可以避免这种变异性，在密码库中平均带来2.15%（最高10.54%）的性能提升。此外，这种变异性可作为隐蔽信道利用，最大吞吐量达16.14 Mbps。

Conclusion: 条件跳转指令的时序变异性是现代处理器中普遍存在的现象，源于微操作缓存和L1指令缓存机制。通过32字节对齐可以避免这种变异性并提升性能，同时这种变异性也可被利用为隐蔽信道。Intel在2019年的一份被忽视的简短报告中已提出类似建议。

Abstract: An extensive line of work on modern computing architectures has shown that the execution time of instructions can (i) depend on the operand of the instruction or (ii) be influenced by system optimizations, e.g., branch prediction and speculative execution paradigms.
  In this paper, we systematically measure and analyze timing variabilities in conditional jump instructions that can be macro-fused with a preceding instruction, depending on their placement within the binary. Our measurements indicate that these timing variations stem from the micro-op cache placement and the jump's offset in the L1 instruction cache of modern processors. We demonstrate that this behavior is consistent across multiple microarchitectures, including Skylake, Coffee Lake, and Kaby Lake, as well as various real-world implementations. We confirm the prevalence of this variability through extensive experiments on a large-scale set of popular binaries, including libraries from Ubuntu 24.04, Windows 10 Pro, and several open-source cryptographic libraries. We also show that one can easily avoid this timing variability by ensuring that macro-fusible instructions are 32-byte aligned - an approach initially suggested in 2019 by Intel in an overlooked short report. We quantify the performance impact of this approach across the cryptographic libraries, showing a speedup of 2.15% on average (and up to 10.54%) when avoiding the timing variability. As a by-product, we show that this variability can be exploited as a covert channel, achieving a maximum throughput of 16.14 Mbps.

</details>


### [7] [DROIDCCT: Cryptographic Compliance Test via Trillion-Scale Measurement](https://arxiv.org/abs/2601.11745)
*Daniel Moghimi,Alexandru-Cosmin Mihai,Borbala Benko,Catherine Vlasov,Elie Bursztein,Kurt Thomas,Laszlo Siroki,Pedro Barbosa,Remi Audebert*

Main category: cs.CR

TL;DR: DroidCCT是一个分布式测试框架，用于评估Android生态系统中密码学实现的故障规模，通过被动分析数十亿设备上的密码学操作，发现了制造商和芯片组中的多种漏洞模式。


<details>
  <summary>Details</summary>
Motivation: 评估Android生态系统中密码学实现的故障规模和漏洞，揭示不同制造商和芯片组在密码学实现中的质量问题，强调故障和侧信道抵抗密码学的重要性。

Method: 开发DroidCCT分布式测试框架，通过被动分析Android Keystore在5亿设备上执行的密码学操作工件，收集数万亿样本，应用多种分析技术评估密码学输出质量和底层实现。

Result: 发现了多种制造商和芯片组中密码学实现的漏洞模式，包括弱随机参数生成和时序侧信道问题；揭示了密码学实现的异构性导致不同密码函数可用性和可靠性的不均匀性。

Conclusion: 密码学实现中的漏洞可能在不同部署中显现，强调了故障和侧信道抵抗密码学的重要性，以及透明开放测试这些实现能力的必要性。

Abstract: We develop DroidCCT, a distributed test framework to evaluate the scale of a wide range of failures/bugs in cryptography for end users. DroidCCT relies on passive analysis of artifacts from the execution of cryptographic operations in the Android ecosystem to identify weak implementations. We collect trillions of samples from cryptographic operations of Android Keystore on half a billion devices and apply severalanalysis techniques to evaluate the quality of cryptographic output from these devices and their underlying implementations. Our study reveals several patterns of bugs and weakness in cryptographic implementations from various manufacturers and chipsets. We show that the heterogeneous nature of cryptographic implementations results in non-uniform availability and reliability of various cryptographic functions. More importantly, flaws such as the use of weakly-generated random parameters, and timing side channels may surface across deployments of cryptography. Our results highlight the importance of fault- and side-channel-resistant cryptography and the ability to transparently and openly test these implementations.

</details>


### [8] [ARM MTE Performance in Practice (Extended Version)](https://arxiv.org/abs/2601.11786)
*Taehyun Noh,Yingchen Wang,Tal Garfinkel,Mahesh Madhav,Daniel Moghimi,Mattan Erez,Shravan Narayan*

Main category: cs.CR

TL;DR: 首次对ARM MTE硬件性能进行全面分析，涵盖Google Pixel 8/9的三种核心架构和AmpereOne CPU，发现MTE在内存安全应用中通常有适度开销，但某些基准测试中性能下降高达6.64倍，同时探讨了MTE在专业安全应用中的表现。


<details>
  <summary>Details</summary>
Motivation: MTE（内存标签扩展）是ARM架构的重要安全特性，但之前对其性能影响的研究不够全面或存在方法学错误。本文旨在提供首个跨多种微架构的MTE性能综合分析，为硬件设计者和安全研究人员提供准确参考。

Method: 在四种不同微架构上测试MTE性能：Google Pixel 8/9的ARM Big（A7x）、Little（A5x）、Performance（Cortex-X）核心，以及Ampere Computing的AmpereOne CPU核心，还包括Apple M5芯片的初步分析。测试包括SPEC CPU基准测试和服务器工作负载（RocksDB、Nginx、PostgreSQL、Memcached），并分析MTE在专业安全应用中的表现。

Result: MTE在概率性内存安全应用中通常表现出适度开销，但在某些基准测试中性能下降高达6.64倍。研究识别了这些开销的微架构原因，并指出了未来处理器可以改进的地方。在内存追踪、TOCTOU预防、沙箱和CFI等专业安全应用中，MTE在某些情况下提供显著优势，而在其他情况下优势有限或依赖未来硬件改进。

Conclusion: 本文提供了首个全面的ARM MTE性能分析，揭示了MTE在不同应用场景下的实际性能影响。研究不仅指出了当前MTE实现的性能瓶颈，还纠正了先前研究中的错误结论，为未来硬件优化和安全应用设计提供了重要指导。

Abstract: We present the first comprehensive analysis of ARM MTE hardware performance on four different microarchitectures: ARM Big (A7x), Little (A5x), and Performance (Cortex-X) cores on the Google Pixel 8 and Pixel 9, and on Ampere Computing's AmpereOne CPU core. We also include preliminary analysis of MTE on Apple's M5 chip. We investigate performance in MTE's primary application -- probabilistic memory safety -- on both SPEC CPU benchmarks and in server workloads such as RocksDB, Nginx, PostgreSQL, and Memcached. While MTE often exhibits modest overheads, we also see performance slowdowns up to 6.64x on certain benchmarks. We identify the microarchitectural cause of these overheads and where they can be addressed in future processors. We then analyze MTE's performance for more specialized security applications such as memory tracing, time-of-check time-of-use prevention, sandboxing, and CFI. In some of these cases, MTE offers significant advantages today, while the benefits for other cases are negligible or will depend on future hardware. Finally, we explore where prior work characterizing MTE performance has either been incomplete or incorrect due to methodological or experimental errors.

</details>


### [9] [SimFuzz: Similarity-guided Block-level Mutation for RISC-V Processor Fuzzing](https://arxiv.org/abs/2601.11838)
*Hao Lyu,Jingzheng Wu,Xiang Ling,Yicheng Zhong,Zhiyuan Li,Tianyue Luo*

Main category: cs.CR

TL;DR: SimFuzz是一个针对RISC-V处理器的模糊测试框架，通过历史bug触发输入构建高质量种子语料库，采用相似性引导的块级变异来高效探索处理器输入空间，发现了17个bug（包括14个新bug和7个CVE）。


<details>
  <summary>Details</summary>
Motivation: RISC-V作为开放ISA降低了处理器设计门槛，但也暴露了安全风险。现有模糊测试方法存在两个主要局限：1) 过度关注冗余测试用例生成，忽略了跨处理器边界情况；2) 过度依赖覆盖率指导，当前覆盖率指标存在偏差且效率低下，一旦覆盖率增长停滞就失效。

Method: SimFuzz框架：1) 从历史bug触发输入构建高质量种子语料库；2) 采用相似性引导的块级变异，通过引入指令相似性在保持控制流结构的同时扩展输入空间；3) 不依赖覆盖率反馈，实现更深层次的探索。

Result: 在三个广泛使用的开源RISC-V处理器（Rocket、BOOM、XiangShan）上评估，共发现17个bug，包括14个先前未知的问题，其中7个已分配CVE标识。这些bug影响解码和内存单元，导致指令和数据错误，可能引发内核不稳定或系统崩溃。实验结果显示，SimFuzz在高质量种子语料库上实现了高达73.22%的多路复用器覆盖率。

Conclusion: SimFuzz克服了现有模糊测试方法的局限性，发现了主流RISC-V处理器中的关键安全bug，为改进功能验证提供了可操作的见解。该方法通过相似性引导的变异实现了更高效的处理器输入空间探索。

Abstract: The Instruction Set Architecture (ISA) defines processor operations and serves as the interface between hardware and software. As an open ISA, RISC-V lowers the barriers to processor design and encourages widespread adoption, but also exposes processors to security risks such as functional bugs. Processor fuzzing is a powerful technique for automatically detecting these bugs. However, existing fuzzing methods suffer from two main limitations. First, their emphasis on redundant test case generation causes them to overlook cross-processor corner cases. Second, they rely too heavily on coverage guidance. Current coverage metrics are biased and inefficient, and become ineffective once coverage growth plateaus. To overcome these limitations, we propose SimFuzz, a fuzzing framework that constructs a high-quality seed corpus from historical bug-triggering inputs and employs similarity-guided, block-level mutation to efficiently explore the processor input space. By introducing instruction similarity, SimFuzz expands the input space around seeds while preserving control-flow structure, enabling deeper exploration without relying on coverage feedback. We evaluate SimFuzz on three widely used open-source RISC-V processors: Rocket, BOOM, and XiangShan, and discover 17 bugs in total, including 14 previously unknown issues, 7 of which have been assigned CVE identifiers. These bugs affect the decode and memory units, cause instruction and data errors, and can lead to kernel instability or system crashes. Experimental results show that SimFuzz achieves up to 73.22% multiplexer coverage on the high-quality seed corpus. Our findings highlight critical security bugs in mainstream RISC-V processors and offer actionable insights for improving functional verification.

</details>


### [10] [Taming Various Privilege Escalation in LLM-Based Agent Systems: A Mandatory Access Control Framework](https://arxiv.org/abs/2601.11893)
*Zimo Ji,Daoyuan Wu,Wenyuan Jiang,Pingchuan Ma,Zongjie Li,Yudong Gao,Shuai Wang,Yingjiu Li*

Main category: cs.CR

TL;DR: SEAgent是一个基于属性访问控制(ABAC)的强制访问控制框架，用于防御LLM智能体系统中的权限提升攻击，通过监控智能体-工具交互的信息流图来执行安全策略。


<details>
  <summary>Details</summary>
Motivation: 基于LLM的智能体系统在复杂现实任务中部署日益增多，但容易受到自然语言攻击的威胁，这些攻击利用过度特权工具使用。本文旨在通过权限提升的视角来理解和缓解此类攻击。

Method: 基于LLM智能体系统的形式化模型，识别新的权限提升场景，特别是多智能体系统中的变体（类似经典混淆代理问题）。提出SEAgent框架，这是一个基于属性访问控制(ABAC)的强制访问控制(MAC)框架，通过信息流图监控智能体-工具交互，并基于实体属性执行可定制的安全策略。

Result: 评估显示SEAgent能有效阻止各种权限提升攻击，同时保持低误报率和可忽略的系统开销，证明了其在保护基于LLM的智能体系统方面的鲁棒性和适应性。

Conclusion: SEAgent框架通过强制访问控制和信息流监控，为LLM智能体系统提供了有效的权限提升防御机制，展示了在实际部署中的可行性和有效性。

Abstract: Large Language Model (LLM)-based agent systems are increasingly deployed for complex real-world tasks but remain vulnerable to natural language-based attacks that exploit over-privileged tool use. This paper aims to understand and mitigate such attacks through the lens of privilege escalation, defined as agent actions exceeding the least privilege required for a user's intended task. Based on a formal model of LLM agent systems, we identify novel privilege escalation scenarios, particularly in multi-agent systems, including a variant akin to the classic confused deputy problem. To defend against both known and newly demonstrated privilege escalation, we propose SEAgent, a mandatory access control (MAC) framework built upon attribute-based access control (ABAC). SEAgent monitors agent-tool interactions via an information flow graph and enforces customizable security policies based on entity attributes. Our evaluations show that SEAgent effectively blocks various privilege escalation while maintaining a low false positive rate and negligible system overhead. This demonstrates its robustness and adaptability in securing LLM-based agent systems.

</details>


### [11] [MongoDB Injection Query Classification Model using MongoDB Log files as Training Data](https://arxiv.org/abs/2601.11996)
*Shaunak Perni,Minal Shirodkar,Ramdas Karmalli*

Main category: cs.CR

TL;DR: 本文提出基于日志数据而非原始查询语句的NoSQL注入攻击检测方法，使用FLAML AutoML库和手动编程模型，最佳模型准确率达71%


<details>
  <summary>Details</summary>
Motivation: 现有基于规则的NoSQL注入防御系统对创新攻击无效，而基于模型的检测系统因数据稀缺和类别不平衡问题，在真实世界中效果不佳。这些系统通常只训练查询语句，但本文探索基于日志数据和其他提取特征进行分类。

Method: 1. 从模拟攻击的MongoDB服务器收集日志数据；2. 进行判别分析确定统计显著特征；3. 使用FLAML AutoML库和6个手动编程模型训练；4. 在50个随机数据样本上进行交叉验证和评估。

Result: 最佳模型是FLAML库的"XGBoost limited depth"模型，准确率达到71%。判别分析确定了能够区分注入查询和良性查询的显著特征。

Conclusion: 基于日志数据而非原始查询语句的NoSQL注入检测方法可行，使用AutoML技术可以找到有效的分类模型，但71%的准确率表明仍有改进空间。

Abstract: NoSQL Injection attacks are a class of cybersecurity attacks where an attacker sends a specifically engineered query to a NoSQL database which then performs an unauthorized operation. To defend against such attacks, rule based systems were initially developed but then were found to be ineffective to innovative injection attacks hence a model based approach was developed. Most model based detection systems, during testing gave exponentially positive results but were trained only on the query statement sent to the server. However due to the scarcity of data and class imbalances these model based systems were found to be not effective against all attacks in the real world. This paper explores classifying NoSQL injection attacks sent to a MongoDB server based on Log Data, and other extracted features excluding raw query statements. The log data was collected from a simulated attack on an empty MongoDB server which was then processed and explored. A discriminant analysis was carried out to determine statistically significant features to discriminate between injection and benign queries resulting in a dataset of significant features. Several Machine learning based classification models using an AutoML library, "FLAML", as well as 6 manually programmed models were trained on this dataset , which were then trained on 50 randomized samples of data, cross validated and evaluated. The study found that the best model was the "FLAML" library's "XGBoost limited depth" model with an accuracy of 71%.

</details>


### [12] [Hybrid IDS Using Signature-Based and Anomaly-Based Detection](https://arxiv.org/abs/2601.11998)
*Messaouda Boutassetta,Amina Makhlouf,Newfel Messaoudi,Abdelmadjid Benmachiche,Ines Boutabia*

Main category: cs.CR

TL;DR: 本文对混合入侵检测系统（Hybrid IDS）进行全面综述，结合基于签名和基于异常的检测技术，旨在提升攻击检测能力，涵盖分类、应用领域及未来研究方向。


<details>
  <summary>Details</summary>
Motivation: 传统入侵检测系统存在局限性：难以检测新型攻击且误报率高。为应对不断演变的网络威胁，需要结合不同检测技术的优势来提升系统防护能力。

Method: 采用文献综述方法，对混合IDS最新研究进行系统性调查，将现有模型按功能分类，分析其优缺点和应用领域（金融系统、空中交通控制、社交网络等），并探讨机器学习方法和云部署等趋势。

Result: 建立了混合IDS的分类框架，识别了不同应用场景下的适用模型，总结了当前研究趋势（如机器学习、云部署），并揭示了混合方法在提升检测能力方面的潜力。

Conclusion: 混合IDS通过结合签名和异常检测技术，能更有效地应对新型和复杂网络攻击。未来研究方向包括开发更具成本效益的解决方案，提升对新兴攻击的检测能力。

Abstract: Intrusion detection systems (IDS) are essential for protecting computer systems and networks against a wide range of cyber threats that continue to evolve over time. IDS are commonly categorized into two main types, each with its own strengths and limitations, such as difficulty in detecting previously unseen attacks and the tendency to generate high false positive rates. This paper presents a comprehensive survey and a conceptual overview of Hybrid IDS, which integrate signature-based and anomaly-based detection techniques to enhance attack detection capabilities. The survey examines recent research on Hybrid IDS, classifies existing models into functional categories, and discusses their advantages, limitations, and application domains, including financial systems, air traffic control, and social networks. In addition, recent trends in Hybrid IDS research, such as machine learning-based approaches and cloud-based deployments, are reviewed. Finally, this work outlines potential future research directions aimed at developing more cost-effective Hybrid IDS solutions with improved ability to detect emerging and sophisticated cyberattacks.

</details>


### [13] [Less Is More -- Until It Breaks: Security Pitfalls of Vision Token Compression in Large Vision-Language Models](https://arxiv.org/abs/2601.12042)
*Xiaomei Zhang,Zhaoxi Zhang,Leo Yu Zhang,Yanjun Zhang,Guanhong Tao,Shirui Pan*

Main category: cs.CR

TL;DR: 视觉token压缩会严重降低大型视觉语言模型的鲁棒性，原本稳健的模型在启用压缩后变得高度脆弱，这种漏洞是状态特定的，只在压缩设置下出现


<details>
  <summary>Details</summary>
Motivation: 现有研究主要关注视觉token压缩的效率和性能，但其安全影响尚未被充分探索。本文旨在揭示视觉token压缩对LVLMs鲁棒性的负面影响，并研究这种隐藏的安全漏洞

Method: 通过分析压缩过程的关键阶段，识别token重要性排序的不稳定性是鲁棒性下降的主要原因。提出压缩感知攻击（CAA）来系统研究和利用此漏洞，CAA直接针对token选择机制。进一步扩展到更现实的black-box设置，提出Transfer CAA

Result: 实验表明，视觉token压缩显著削弱模型鲁棒性，小且不可察觉的扰动会显著改变token排序，导致压缩机制错误丢弃任务关键信息。现有防御措施仅提供有限保护

Conclusion: 视觉token压缩在提高效率的同时引入了严重的安全风险，揭示了之前被忽视的效率-安全性权衡。这种状态特定的漏洞难以诊断，需要新的安全考虑

Abstract: Visual token compression is widely adopted to improve the inference efficiency of Large Vision-Language Models (LVLMs), enabling their deployment in latency-sensitive and resource-constrained scenarios. However, existing work has mainly focused on efficiency and performance, while the security implications of visual token compression remain largely unexplored. In this work, we first reveal that visual token compression substantially degrades the robustness of LVLMs: models that are robust under uncompressed inference become highly vulnerable once compression is enabled. These vulnerabilities are state-specific; failure modes emerge only in the compressed setting and completely disappear when compression is disabled, making them particularly hidden and difficult to diagnose. By analyzing the key stages of the compression process, we identify instability in token importance ranking as the primary cause of this robustness degradation. Small and imperceptible perturbations can significantly alter token rankings, leading the compression mechanism to mistakenly discard task-critical information and ultimately causing model failure. Motivated by this observation, we propose a Compression-Aware Attack to systematically study and exploit this vulnerability. CAA directly targets the token selection mechanism and induces failures exclusively under compressed inference. We further extend this approach to more realistic black-box settings and introduce Transfer CAA, where neither the target model nor the compression configuration is accessible. We further evaluate potential defenses and find that they provide only limited protection. Extensive experiments across models, datasets, and compression methods show that visual token compression significantly undermines robustness, revealing a previously overlooked efficiency-security trade-off.

</details>


### [14] [Privacy-Preserving Cohort Analytics for Personalized Health Platforms: A Differentially Private Framework with Stochastic Risk Modeling](https://arxiv.org/abs/2601.12105)
*Richik Chakraborty,Lawrence Liu,Syed Hasnain*

Main category: cs.CR

TL;DR: 提出一个结合确定性队列约束、差分隐私和合成基线生成的隐私保护队列分析框架，引入随机风险建模方法，定义隐私风险价值（P-VaR）来评估最坏情况下的隐私结果。


<details>
  <summary>Details</summary>
Motivation: 个性化健康分析依赖人群基准数据，但队列聚合会带来隐私风险。现有隐私框架（如k-匿名和差分隐私）提供静态保证，无法充分捕捉实际系统中累积、分布和尾部主导的重新识别风险。

Method: 结合确定性队列约束、差分隐私机制和合成基线生成，引入随机风险建模方法，将重新识别风险视为随时间演变的随机变量，通过蒙特卡洛模拟进行分布评估，并借鉴金融数学定义隐私风险价值（P-VaR）。

Result: 通过系统级分析和模拟实验验证了框架有效性，展示了隐私-效用权衡如何在数字健康平台中实施，随机风险建模为平台设计者、监管者和临床信息学利益相关者提供了可解释、决策相关的指标。

Conclusion: 随机风险建模通过提供可解释的决策指标，补充了形式化隐私保证，为数字健康平台的隐私保护队列分析提供了实用框架。

Abstract: Personalized health analytics increasingly rely on population benchmarks to provide contextual insights such as ''How do I compare to others like me?'' However, cohort-based aggregation of health data introduces nontrivial privacy risks, particularly in interactive and longitudinal digital platforms. Existing privacy frameworks such as $k$-anonymity and differential privacy provide essential but largely static guarantees that do not fully capture the cumulative, distributional, and tail-dominated nature of re-identification risk in deployed systems.
  In this work, we present a privacy-preserving cohort analytics framework that combines deterministic cohort constraints, differential privacy mechanisms, and synthetic baseline generation to enable personalized population comparisons while maintaining strong privacy protections. We further introduce a stochastic risk modeling approach that treats re-identification risk as a random variable evolving over time, enabling distributional evaluation through Monte Carlo simulation. Adapting quantitative risk measures from financial mathematics, we define Privacy Loss at Risk (P-VaR) to characterize worst-case privacy outcomes under realistic cohort dynamics and adversary assumptions.
  We validate our framework through system-level analysis and simulation experiments, demonstrating how privacy-utility tradeoffs can be operationalized for digital health platforms. Our results suggest that stochastic risk modeling complements formal privacy guarantees by providing interpretable, decision-relevant metrics for platform designers, regulators, and clinical informatics stakeholders.

</details>


### [15] [CoSMeTIC: Zero-Knowledge Computational Sparse Merkle Trees with Inclusion-Exclusion Proofs for Clinical Research](https://arxiv.org/abs/2601.12136)
*Mohammad Shahid,Paritosh Ramanan,Mohammad Fili,Guiping Hu,Hillel Haim*

Main category: cs.CR

TL;DR: CoSMeTIC是一个零知识计算框架，使用稀疏Merkle树为临床研究中的参与者数据生成可验证的包含和排除证明，在保护隐私的同时满足监管合规要求。


<details>
  <summary>Details</summary>
Motivation: 临床数据分析在生物医学研究中至关重要，但患者数据包含个人身份健康信息，需要严格隐私保护。同时监管合规要求证明分析所用参与者数据的完整性和真实性。平衡隐私保护与可验证问责是当前的关键挑战。

Method: 提出CoSMeTIC零知识计算框架，采用计算稀疏Merkle树（SMTs）为临床研究中的个体参与者数据生成可验证的包含和排除证明。通过形式化分析零知识属性，并在真实世界亨廷顿病数据集上使用Kolmogorov-Smirnov检验、似然比假设检验以及基于逻辑回归的基因组分析来评估计算效率。

Result: CoSMeTIC在保持统计保真度的同时实现了强大的隐私保证。实验结果表明该框架提供了可扩展且实用的替代方案，能够在大规模临床研究中实现具有严格隐私保护的监管合规。

Conclusion: CoSMeTIC为临床研究中的隐私保护与监管合规之间的平衡问题提供了一个有效的解决方案，通过零知识证明和稀疏Merkle树技术，在保护患者隐私的同时确保数据的可验证性和完整性。

Abstract: Analysis of clinical data is a cornerstone of biomedical research with applications in areas such as genomic testing and response characterization of therapeutic drugs. Maintaining strict privacy controls is essential because such data typically contains personally identifiable health information of patients. At the same time, regulatory compliance often requires study managers to demonstrate the integrity and authenticity of participant data used in analyses. Balancing these competing requirements, privacy preservation and verifiable accountability, remains a critical challenge. In this paper, we present CoSMeTIC, a zero-knowledge computational framework that proposes computational Sparse Merkle Trees (SMTs) as a means to generate verifiable inclusion and exclusion proofs for individual participants' data in clinical studies. We formally analyze the zero-knowledge properties of CoSMeTIC and evaluate its computational efficiency through extensive experiments. Using the Kolmogorov-Smirnov and likelihood-ratio hypothesis tests, along with logistic-regression-based genomic analyses on real-world Huntington's disease datasets, we demonstrate that CoSMeTIC achieves strong privacy guarantees while maintaining statistical fidelity. Our results suggest that CoSMeTIC provides a scalable and practical alternative for achieving regulatory compliance with rigorous privacy protection in large-scale clinical research.

</details>


### [16] [SplittingSecrets: A Compiler-Based Defense for Preventing Data Memory-Dependent Prefetcher Side-Channels](https://arxiv.org/abs/2601.12270)
*Reshabh K Sharma,Dan Grossman,David Kohlbrenner*

Main category: cs.CR

TL;DR: SplittingSecrets是一个基于编译器的工具，通过分割秘密数据防止其被数据内存依赖预取器（DMP）利用，从而防御新型硬件侧信道攻击。


<details>
  <summary>Details</summary>
Motivation: 传统常数时间编程防御对新型硬件优化（如苹果、Intel、ARM CPU中的数据内存依赖预取器）无效。这些预取器使用内存内容和访问历史来确定预取目标，攻击者可利用它们泄露静态数据，即使程序从未以不安全方式使用这些数据。

Method: SplittingSecrets采用编译器转换方法，确保秘密数据在内存中存储时永远不会像地址，从而避免DMP激活。该方法不依赖复杂的DMP内部机制，而是利用所有DMP的共同特性：激活需要数据类似地址。

Result: 实现了基于LLVM的SplittingSecrets工具，支持AArch64架构的源代码级内存操作和编译器后端生成的操作。在苹果M系列CPU上评估了libsodium加密库常用原语的性能开销。

Conclusion: SplittingSecrets提供了一种软件层面的针对性加固方案，无需完全禁用DMP，能有效防御DMP引发的侧信道攻击，为保护关键秘密数据提供了实用解决方案。

Abstract: Traditional side-channels take advantage of secrets being used as inputs to unsafe instructions, used for memory accesses, or used in control flow decisions. Constant-time programming, which restricts such code patterns, has been widely adopted as a defense against these vulnerabilities. However, new hardware optimizations in the form of Data Memory-dependent Prefetchers (DMP) present in Apple, Intel, and ARM CPUs have shown such defenses are not sufficient. These prefetchers, unlike classical prefetchers, use the content of memory as well as the trace of prior accesses to determine prefetch targets. An adversary abusing such a prefetcher has been shown to be able to mount attacks leaking data-at-rest; data that is never used by the program, even speculatively, in an unsafe manner.
  In response, this paper introduces SplittingSecrets, a compiler-based tool that can harden software libraries against side-channels arising from DMPs. SplittingSecrets's approach avoids reasoning about the complex internals of different DMPs and instead relies on one key aspect of all DMPs: activation requires data to resemble addresses. To prevent secret data from leaking, SplittingSecrets transforms memory operations to ensure that secrets are never stored in memory in a manner resembling an address, thereby avoiding DMP activation on those secrets. Rather than disable a DMP entirely, SplittingSecrets can provide targeted hardening for only specific secrets entirely in software.
  We have implemented SplittingSecrets using LLVM, supporting both source-level memory operations and those generated by the compiler backend for the AArch64 architecture, We have analyzed the performance overhead involved in safeguarding secrets from DMP-induced attacks using common primitives in libsodium, a popular cryptographic library when built for Apple M-series CPUs.

</details>


### [17] [Efficient Privacy-Preserving Retrieval Augmented Generation with Distance-Preserving Encryption](https://arxiv.org/abs/2601.12331)
*Huanyi Ye,Jiale Guo,Ziyao Liu,Kwok-Yan Lam*

Main category: cs.CR

TL;DR: 提出ppRAG框架，在不可信云环境中实现高效隐私保护的检索增强生成，防御向量到文本攻击、向量分析和查询分析


<details>
  <summary>Details</summary>
Motivation: 传统RAG依赖可信本地环境，但资源有限的用户依赖不可信云存储会带来隐私风险。现有隐私保护RAG技术大多基于部分同态加密，计算开销大

Method: 提出CAPRISE对称加密方案，加密嵌入向量同时允许云计算相似度；引入差分隐私扰动查询嵌入防止查询分析；仅保留相对距离顺序而不暴露数据库内部距离

Result: 实验显示ppRAG实现高效处理吞吐量、高检索准确性和强隐私保证，适合资源受限用户的安全云增强LLM应用

Conclusion: ppRAG为不可信云环境提供实用高效的隐私保护RAG解决方案，平衡了隐私保护、效率和准确性

Abstract: RAG has emerged as a key technique for enhancing response quality of LLMs without high computational cost. In traditional architectures, RAG services are provided by a single entity that hosts the dataset within a trusted local environment. However, individuals or small organizations often lack the resources to maintain data storage servers, leading them to rely on outsourced cloud storage. This dependence on untrusted third-party services introduces privacy risks. Embedding-based retrieval mechanisms, commonly used in RAG systems, are vulnerable to privacy leakage such as vector-to-text reconstruction attacks and structural leakage via vector analysis. Several privacy-preserving RAG techniques have been proposed but most existing approaches rely on partially homomorphic encryption, which incurs substantial computational overhead. To address these challenges, we propose an efficient privacy-preserving RAG framework (ppRAG) tailored for untrusted cloud environments that defends against vector-to-text attack, vector analysis, and query analysis. We propose Conditional Approximate Distance-Comparison-Preserving Symmetric Encryption (CAPRISE) that encrypts embeddings while still allowing the cloud to compute similarity between an encrypted query and the encrypted database embeddings. CAPRISE preserves only the relative distance ordering between the encrypted query and each encrypted database embedding, without exposing inter-database distances, thereby enhancing both privacy and efficiency. To mitigate query analysis, we introduce DP by perturbing the query embedding prior to encryption, preventing the cloud from inferring sensitive patterns. Experimental results show that ppRAG achieves efficient processing throughput, high retrieval accuracy, strong privacy guarantees, making it a practical solution for resource-constrained users seeking secure cloud-augmented LLMs.

</details>


### [18] [Zero-Permission Manipulation: Can We Trust Large Multimodal Model Powered GUI Agents?](https://arxiv.org/abs/2601.12349)
*Yi Qian,Kunwei Qian,Xingbang He,Ligeng Chen,Jikang Zhang,Tiantai Zhang,Haiyang Wei,Linzhang Wang,Hao Wu,Bing Mao*

Main category: cs.CR

TL;DR: 大型多模态模型驱动的GUI代理在移动平台上存在视觉原子性假设漏洞，攻击者可通过动作重绑定攻击利用观察-行动间隙劫持代理执行，实现无权限多步攻击链


<details>
  <summary>Details</summary>
Motivation: 当前GUI代理设计基于视觉原子性假设（UI状态在观察和行动之间保持不变），但这一假设在Android系统中不成立，形成了关键攻击面

Method: 提出动作重绑定攻击：利用代理推理管道中不可避免的观察-行动间隙，通过前台界面转换劫持代理的规划动作；结合意图对齐策略操纵代理推理过程，使其合理化UI状态以绕过验证关卡

Result: 在6个广泛使用的Android GUI代理上评估15个任务：原子动作重绑定成功率100%，多步攻击链可靠执行；意图对齐策略将验证关卡绕过成功率从0%提升至100%；攻击应用无需敏感权限，恶意软件扫描器检测率为0%

Conclusion: 揭示了当前代理-操作系统集成的根本架构缺陷，为未来代理系统的安全设计提供了关键见解

Abstract: Large multimodal model powered GUI agents are emerging as high-privilege operators on mobile platforms, entrusted with perceiving screen content and injecting inputs. However, their design operates under the implicit assumption of Visual Atomicity: that the UI state remains invariant between observation and action. We demonstrate that this assumption is fundamentally invalid in Android, creating a critical attack surface.
  We present Action Rebinding, a novel attack that allows a seemingly-benign app with zero dangerous permissions to rebind an agent's execution. By exploiting the inevitable observation-to-action gap inherent in the agent's reasoning pipeline, the attacker triggers foreground transitions to rebind the agent's planned action toward the target app. We weaponize the agent's task-recovery logic and Android's UI state preservation to orchestrate programmable, multi-step attack chains. Furthermore, we introduce an Intent Alignment Strategy (IAS) that manipulates the agent's reasoning process to rationalize UI states, enabling it to bypass verification gates (e.g., confirmation dialogs) that would otherwise be rejected.
  We evaluate Action Rebinding Attacks on six widely-used Android GUI agents across 15 tasks. Our results demonstrate a 100% success rate for atomic action rebinding and the ability to reliably orchestrate multi-step attack chains. With IAS, the success rate in bypassing verification gates increases (from 0% to up to 100%). Notably, the attacker application requires no sensitive permissions and contains no privileged API calls, achieving a 0% detection rate across malware scanners (e.g., VirusTotal). Our findings reveal a fundamental architectural flaw in current agent-OS integration and provide critical insights for the secure design of future agent systems. To access experimental logs and demonstration videos, please contact yi_qian@smail.nju.edu.cn.

</details>


### [19] [Zero-Shot Embedding Drift Detection: A Lightweight Defense Against Prompt Injections in LLMs](https://arxiv.org/abs/2601.12359)
*Anirudh Sekar,Mrinal Agarwal,Rachel Sharma,Akitsugu Tanaka,Jasmine Zhang,Arjun Damerla,Kevin Zhu*

Main category: cs.CR

TL;DR: 提出ZEDD框架，通过量化嵌入空间中的语义偏移来检测提示注入攻击，无需模型内部访问或攻击先验知识，在多种LLM架构上达到93%以上准确率。


<details>
  <summary>Details</summary>
Motivation: 提示注入攻击已成为LLM应用日益严重的漏洞，即使最先进的LLM也容易受到对抗性提示的攻击。当前缺乏鲁棒、高效且可泛化的检测机制，现有方法多为低效的模型特定补丁。

Method: 提出零样本嵌入偏移检测（ZEDD）框架，通过比较良性输入与可疑输入在嵌入空间中的余弦相似度来量化语义偏移，从而识别直接和间接提示注入攻击。该方法无需模型内部访问、攻击类型先验知识或任务特定重训练。

Result: 在LLMail-Inject数据集上实验表明，嵌入偏移是鲁棒且可迁移的信号，在Llama 3、Qwen 2、Mistral等模型架构上达到93%以上准确率，误报率低于3%，优于传统方法。

Conclusion: ZEDD提供了一个轻量级、可扩展的防御层，可集成到现有LLM管道中，解决了保护LLM系统免受自适应对抗威胁的关键缺口。

Abstract: Prompt injection attacks have become an increasing vulnerability for LLM applications, where adversarial prompts exploit indirect input channels such as emails or user-generated content to circumvent alignment safeguards and induce harmful or unintended outputs. Despite advances in alignment, even state-of-the-art LLMs remain broadly vulnerable to adversarial prompts, underscoring the urgent need for robust, productive, and generalizable detection mechanisms beyond inefficient, model-specific patches. In this work, we propose Zero-Shot Embedding Drift Detection (ZEDD), a lightweight, low-engineering-overhead framework that identifies both direct and indirect prompt injection attempts by quantifying semantic shifts in embedding space between benign and suspect inputs. ZEDD operates without requiring access to model internals, prior knowledge of attack types, or task-specific retraining, enabling efficient zero-shot deployment across diverse LLM architectures. Our method uses adversarial-clean prompt pairs and measures embedding drift via cosine similarity to capture subtle adversarial manipulations inherent to real-world injection attacks. To ensure robust evaluation, we assemble and re-annotate the comprehensive LLMail-Inject dataset spanning five injection categories derived from publicly available sources. Extensive experiments demonstrate that embedding drift is a robust and transferable signal, outperforming traditional methods in detection accuracy and operational efficiency. With greater than 93% accuracy in classifying prompt injections across model architectures like Llama 3, Qwen 2, and Mistral and a false positive rate of <3%, our approach offers a lightweight, scalable defense layer that integrates into existing LLM pipelines, addressing a critical gap in securing LLM-powered systems to withstand adaptive adversarial threats.

</details>


### [20] [De-Anonymization at Scale via Tournament-Style Attribution](https://arxiv.org/abs/2601.12407)
*Lirui Zhang,Huishuai Zhang*

Main category: cs.CR

TL;DR: DAS是一种基于大语言模型的作者去匿名化方法，能够在数万候选文本中识别匿名文档的作者，对双盲评审等匿名平台构成隐私威胁。


<details>
  <summary>Details</summary>
Motivation: 随着LLM快速发展并进入实际应用，其隐私影响日益重要。研究作者去匿名化威胁：使用LLM将匿名文档链接到其作者，可能危及双盲同行评审等场景。

Method: DAS采用顺序渐进策略：将候选语料随机划分为固定大小的组，提示LLM选择最可能由同一作者撰写的文本，迭代重新查询幸存候选者以生成排名前k的列表。为扩展到大规模应用，添加密集检索预过滤器缩小搜索空间，并通过多数投票聚合多个独立运行以提高鲁棒性和排名精度。

Result: 在匿名评审数据上的实验显示，DAS能从数万文本池中恢复同一作者文本，准确率显著高于随机水平，证明了匿名平台的现实隐私风险。在标准作者归属基准（Enron邮件和博客文章）上，DAS在准确性和可扩展性方面均优于先前方法。

Conclusion: DAS展示了LLM启用的新型去匿名化漏洞，对匿名平台构成实际隐私威胁，需要采取相应防护措施。

Abstract: As LLMs rapidly advance and enter real-world use, their privacy implications are increasingly important. We study an authorship de-anonymization threat: using LLMs to link anonymous documents to their authors, potentially compromising settings such as double-blind peer review.
  We propose De-Anonymization at Scale (DAS), a large language model-based method for attributing authorship among tens of thousands of candidate texts. DAS uses a sequential progression strategy: it randomly partitions the candidate corpus into fixed-size groups, prompts an LLM to select the text most likely written by the same author as a query text, and iteratively re-queries the surviving candidates to produce a ranked top-k list. To make this practical at scale, DAS adds a dense-retrieval prefilter to shrink the search space and a majority-voting style aggregation over multiple independent runs to improve robustness and ranking precision. Experiments on anonymized review data show DAS can recover same-author texts from pools of tens of thousands with accuracy well above chance, demonstrating a realistic privacy risk for anonymous platforms. On standard authorship benchmarks (Enron emails and blog posts), DAS also improves both accuracy and scalability over prior approaches, highlighting a new LLM-enabled de-anonymization vulnerability.

</details>


### [21] [Privacy-Preserving Federated Learning with Verifiable Fairness Guarantees](https://arxiv.org/abs/2601.12447)
*Mohammed Himayath Ali,Mohammed Aqib Abdullah,Syed Muneer Hussin,Mohammed Mudassir Uddin,Shahnawaz Alam*

Main category: cs.CR

TL;DR: CryptoFair-FL：首个提供可验证公平性保证的联邦学习密码学框架，结合同态加密和安全多方计算，在保护隐私的同时验证人口统计均等和机会均等指标。


<details>
  <summary>Details</summary>
Motivation: 联邦学习允许分布式机构协作训练模型而不集中敏感数据，但在异构数据分布下确保算法公平性同时保护隐私仍然是一个未解决的根本问题。

Method: 结合加法同态加密和安全多方计算，提出隐私保护的公平性验证方法，包括新颖的批量验证协议将计算复杂度从O(n²)降低到O(n log n)，同时保持差分隐私。

Result: 在四个基准数据集上测试，将公平性违规从0.231降低到0.031，仅产生2.3倍计算开销，对抗属性推断攻击的成功概率保持在0.05以下。

Conclusion: 该框架为需要在隐私保护和算法问责之间平衡的受监管行业提供了部署公平感知联邦学习的实用途径。

Abstract: Federated learning enables collaborative model training across distributed institutions without centralizing sensitive data; however, ensuring algorithmic fairness across heterogeneous data distributions while preserving privacy remains fundamentally unresolved. This paper introduces CryptoFair-FL, a novel cryptographic framework providing the first verifiable fairness guarantees for federated learning systems under formal security definitions. The proposed approach combines additively homomorphic encryption with secure multi-party computation to enable privacy-preserving verification of demographic parity and equalized odds metrics without revealing protected attribute distributions or individual predictions. A novel batched verification protocol reduces computational complexity from BigO(n^2) to BigO(n \log n) while maintaining (\dparam, \deltap)-differential privacy with dparam = 0.5 and deltap = 10^{-6}. Theoretical analysis establishes information-theoretic lower bounds on the privacy cost of fairness verification, demonstrating that the proposed protocol achieves near-optimal privacy-fairness tradeoffs. Comprehensive experiments across four benchmark datasets (MIMIC-IV healthcare records, Adult Income, CelebA, and a novel FedFair-100 benchmark) demonstrate that CryptoFair-FL reduces fairness violations from 0.231 to 0.031 demographic parity difference while incurring only 2.3 times computational overhead compared to standard federated averaging. The framework successfully defends against attribute inference attacks, maintaining adversarial success probability below 0.05 across all tested configurations. These results establish a practical pathway for deploying fairness-aware federated learning in regulated industries requiring both privacy protection and algorithmic accountability.

</details>


### [22] [AgenTRIM: Tool Risk Mitigation for Agentic AI](https://arxiv.org/abs/2601.12449)
*Roy Betser,Shamik Bose,Amit Giloni,Chiara Picardi,Sindhu Padakandla,Roman Vainshtein*

Main category: cs.CR

TL;DR: AgenTRIM框架通过离线重建验证和运行时最小权限访问控制，检测和缓解AI代理的工具驱动代理风险，在保持任务性能的同时显著降低攻击成功率。


<details>
  <summary>Details</summary>
Motivation: AI代理结合LLM与外部工具解决复杂任务，但不恰当的工具权限会引入安全风险（如间接提示注入和工具滥用），表现为不平衡的工具驱动代理：过度代理（保留不必要权限）和不足代理（未能调用必要工具），这会扩大攻击面并降低性能。

Method: AgenTRIM框架采用互补的离线和在线阶段：离线阶段从代码和执行轨迹重建并验证代理的工具接口；运行时阶段通过自适应过滤和状态感知验证，强制执行每步最小权限工具访问。

Result: 在AgentDojo基准测试中，AgenTRIM显著降低了攻击成功率，同时保持了高任务性能。额外实验显示对基于描述的攻击具有鲁棒性，并能有效执行明确的安全策略。

Conclusion: AgenTRIM为基于LLM的代理提供了实用、能力保持的安全工具使用方法，通过检测和缓解工具驱动代理风险，在不改变代理内部推理的情况下增强安全性。

Abstract: AI agents are autonomous systems that combine LLMs with external tools to solve complex tasks. While such tools extend capability, improper tool permissions introduce security risks such as indirect prompt injection and tool misuse. We characterize these failures as unbalanced tool-driven agency. Agents may retain unnecessary permissions (excessive agency) or fail to invoke required tools (insufficient agency), amplifying the attack surface and reducing performance. We introduce AgenTRIM, a framework for detecting and mitigating tool-driven agency risks without altering an agent's internal reasoning. AgenTRIM addresses these risks through complementary offline and online phases. Offline, AgenTRIM reconstructs and verifies the agent's tool interface from code and execution traces. At runtime, it enforces per-step least-privilege tool access through adaptive filtering and status-aware validation of tool calls. Evaluating on the AgentDojo benchmark, AgenTRIM substantially reduces attack success while maintaining high task performance. Additional experiments show robustness to description-based attacks and effective enforcement of explicit safety policies. Together, these results demonstrate that AgenTRIM provides a practical, capability-preserving approach to safer tool use in LLM-based agents.

</details>


### [23] [TrojanPraise: Jailbreak LLMs via Benign Fine-Tuning](https://arxiv.org/abs/2601.12460)
*Zhixin Xie,Xurui Song,Jun Luo*

Main category: cs.CR

TL;DR: TrojanPraise是一种利用良性数据进行微调的新型攻击方法，通过在LLM中将特定词语与无害含义关联，然后使用该词语赞美有害概念，从而绕过内容审核实现越狱攻击。


<details>
  <summary>Details</summary>
Motivation: 商业LLM提供黑盒微调API带来了安全漏洞，但传统恶意数据集容易被审核模型检测。需要一种利用良性数据绕过审核的攻击方法。

Method: 1) 微调模型将特定词语（如"bruaf"）与无害含义关联；2) 使用该词语赞美有害概念；3) 从内部表征角度，将查询分解为知识和态度两个维度，攻击旨在改变态度而不改变知识理解。

Result: 在5个开源LLM和2个商业LLM上进行实验，在严格黑盒设置下，TrojanPraise最高达到95.88%的攻击成功率，同时成功规避内容审核。

Conclusion: TrojanPraise证明了利用良性数据进行微调攻击的可行性，揭示了当前LLM安全防御的脆弱性，需要更强大的安全机制来防范此类隐蔽攻击。

Abstract: The demand of customized large language models (LLMs) has led to commercial LLMs offering black-box fine-tuning APIs, yet this convenience introduces a critical security loophole: attackers could jailbreak the LLMs by fine-tuning them with malicious data. Though this security issue has recently been exposed, the feasibility of such attacks is questionable as malicious training dataset is believed to be detectable by moderation models such as Llama-Guard-3. In this paper, we propose TrojanPraise, a novel finetuning-based attack exploiting benign and thus filter-approved data. Basically, TrojanPraise fine-tunes the model to associate a crafted word (e.g., "bruaf") with harmless connotations, then uses this word to praise harmful concepts, subtly shifting the LLM from refusal to compliance. To explain the attack, we decouple the LLM's internal representation of a query into two dimensions of knowledge and attitude. We demonstrate that successful jailbreak requires shifting the attitude while avoiding knowledge shift, a distortion in the model's understanding of the concept. To validate this attack, we conduct experiments on five opensource LLMs and two commercial LLMs under strict black-box settings. Results show that TrojanPraise achieves a maximum attack success rate of 95.88% while evading moderation.

</details>


### [24] [VR ProfiLens: User Profiling Risks in Consumer Virtual Reality Apps](https://arxiv.org/abs/2601.12563)
*Ismat Jarin,Olivia Figueira,Yu Duan,Tu Le,Athina Markopoulou*

Main category: cs.CR

TL;DR: VR传感器数据可被用于推断用户敏感信息，带来隐私风险，研究者提出VR ProfiLens框架分析这些风险


<details>
  <summary>Details</summary>
Motivation: VR平台收集用户传感器数据（运动、面部、眼动、手部等），这些数据可能暴露用户隐私风险，但目前相关研究不足

Method: 提出VR ProfiLens框架：1) 基于CCPA定义开发分类法识别风险属性；2) 用户研究收集10个流行VR应用的传感器数据；3) 设计分析管道验证属性推断可行性

Result: 从抽象传感器数据可推断敏感个人信息（F1分数高达90%），识别应用组和传感器组在推断属性时的相关性，发现隐私泄露、追踪、定向广告和安全威胁等风险

Conclusion: VR传感器数据存在显著隐私风险，需要增强透明度设计并改进监管建议以保护用户隐私

Abstract: Virtual reality (VR) platforms and apps collect user sensor data, including motion, facial, eye, and hand data, in abstracted form. These data may expose users to unique privacy risks without their knowledge or meaningful awareness, yet the extent of these risks remains understudied. To address this gap, we propose VR ProfiLens, a framework to study user profiling based on VR sensor data and the resulting privacy risks across consumer VR apps. To systematically study this problem, we first develop a taxonomy rooted in the CCPA definition of personal information and expand it by sensor, app, and threat contexts to identify user attributes at risk. Then, we conduct a user study in which we collect VR sensor data from four sensor groups from real users interacting with 10 popular consumer VR apps, followed by a survey. We design and apply an analysis pipeline to demonstrate the feasibility of inferring user attributes using these data. Our results show that sensitive personal information can be inferred with moderately high to high risk (up to 90% F1 score) from abstracted sensor data. Through feature analysis, we further identify correlations among app groups and sensor groups in inferring user attributes. Our findings highlight risks to users, including privacy loss, tracking, targeted advertising, and safety threats. Finally, we discuss design implications and regulatory recommendations to enhance transparency and better protect users' privacy in VR.

</details>


### [25] [Abusing the Internet of Medical Things: Evaluating Threat Models and Forensic Readiness for Multi-Vector Attacks on Connected Healthcare Devices](https://arxiv.org/abs/2601.12593)
*Isabel Straw,Akhil Polamarasetty,Mustafa Jaafar*

Main category: cs.CR

TL;DR: 该研究探讨了依赖医疗设备的家庭暴力受害者面临的独特网络安全威胁，开发了融合技术滥用框架的威胁模型，并通过模拟发现现有数字取证实践难以检测这些攻击。


<details>
  <summary>Details</summary>
Motivation: 随着医疗技术日益互联，依赖医疗设备的家庭暴力受害者成为一个特别脆弱的群体。当前医疗技术网络安全研究主要关注外部技术高超的攻击者，而忽视了家庭暴力背景下技术滥用带来的独特威胁环境，这一交叉领域研究严重不足。

Method: 采用两种互补方法：(1) 开发融合网络物理系统安全建模与技术滥用框架的危险集成威胁模型；(2) 与从业者进行沉浸式模拟，部署模型实时版本，识别数字取证实践中的差距。

Result: 威胁模型揭示了多种攻击途径：完整性攻击导致"医疗煤气灯效应"和"物联网孟乔森综合征"；可用性攻击造成危及生命的危害（血糖急症、失明、情绪不稳定）；保密性威胁来自医疗设备广告的蓝牙广播地理位置追踪。模拟显示这些攻击面在实践中难以被检测：参与者忽视医疗设备、误分类生殖和辅助技术、缺乏对蓝牙广播痕迹的认识。

Conclusion: 在家庭暴力背景下，医疗技术网络安全需要集成威胁建模和改进的数字取证能力，以检测、保存和解释受损患者-技术生态系统造成的危害。

Abstract: Individuals experiencing interpersonal violence (IPV), who depend on medical devices, represent a uniquely vulnerable population as healthcare technologies become increasingly connected. Despite rapid growth in MedTech innovation and "health-at-home" ecosystems, the intersection of MedTech cybersecurity and technology-facilitated abuse remains critically under-examined. IPV survivors who rely on therapeutic devices encounter a qualitatively different threat environment from the external, technically sophisticated adversaries typically modeled in MedTech cybersecurity research. We address this gap through two complementary methods: (1) the development of hazard-integrated threat models that fuse Cyber physical system security modeling with tech-abuse frameworks, and (2) an immersive simulation with practitioners, deploying a live version of our model, identifying gaps in digital forensic practice.
  Our hazard-integrated CIA threat models map exploits to acute and chronic biological effects, uncovering (i) Integrity attack pathways that facilitate "Medical gaslighting" and "Munchausen-by-IoMT", (ii) Availability attacks that create life-critical and sub-acute harms (glycaemic emergencies, blindness, mood destabilization), and (iii) Confidentiality threats arising from MedTech advertisements (geolocation tracking from BLE broadcasts). Our simulation demonstrates that these attack surfaces are unlikely to be detected in practice: participants overlooked MedTech, misclassified reproductive and assistive technologies, and lacked awareness of BLE broadcast artifacts. Our findings show that MedTech cybersecurity in IPV contexts requires integrated threat modeling and improved forensic capabilities for detecting, preserving and interpreting harms arising from compromised patient-technology ecosystems.

</details>


### [26] [The Cost of Convenience: Identifying, Analyzing, and Mitigating Predatory Loan Applications on Android](https://arxiv.org/abs/2601.12634)
*Olawale Amos Akanji,Manuel Egele,Gianluca Stringhini*

Main category: cs.CR

TL;DR: 该研究首次对新兴市场贷款应用进行跨国合规性测量，发现大量获批应用违反国家法规和Google政策，存在数据滥用和骚扰行为，导致Google下架93个应用（累计安装超3亿次）。


<details>
  <summary>Details</summary>
Motivation: 数字贷款应用已成为新兴市场微信贷的主要渠道，但许多应用要求过多权限并滥用敏感用户数据进行胁迫性债务追收（包括骚扰、敲诈和公开羞辱），影响借款人和其联系人。目前缺乏对这些应用合规性的系统性跨国测量。

Method: 研究分析了来自印尼、肯尼亚、尼日利亚、巴基斯坦和菲律宾官方注册机构和应用市场的434个应用。采用LLM辅助的政策到权限映射方法，将政策文本转化为可测试的权限检查，并结合静态和动态分析来检查应用代码和运行时行为。

Result: 研究发现获批应用中普遍存在不合规现象：141个违反国家监管政策，147个违反Google政策。动态分析显示多个应用在用户注册前就传输敏感数据（联系人、短信、位置、媒体），破坏了知情同意原则并导致对借款人和第三方的骚扰。Google随后下架了93个被标记的应用，累计安装量超过3亿次。

Conclusion: 研究建议采用该方法作为主动合规监控工具，并为监管机构、平台和开发者提供针对性建议以加强隐私保护。结果强调了需要协调执法和强大的技术保障，确保数字贷款支持金融包容性而不损害用户隐私或安全。

Abstract: Digital lending applications, commonly referred to as loan apps, have become a primary channel for microcredit in emerging markets. However, many of these apps demand excessive permissions and misuse sensitive user data for coercive debt-recovery practices, including harassment, blackmail, and public shaming that affect both borrowers and their contacts.
  This paper presents the first cross-country measurement of loan app compliance against both national regulations and Google's Financial Services Policy. We analyze 434 apps drawn from official registries and app markets from Indonesia, Kenya, Nigeria, Pakistan, and the Philippines. To operationalize policy requirements at scale, we translate policy text into testable permission checks using LLM-assisted policy-to-permission mapping and combine this with static and dynamic analyses of loan apps' code and runtime behavior.
  Our findings reveal pervasive non-compliance among approved apps: 141 violate national regulatory policy and 147 violate Google policy. Dynamic analysis further shows that several apps transmit sensitive data (contacts, SMS, location, media) before user signup or registration, undermining informed consent and enabling downstream harassment of borrowers and third parties. Following our disclosures, Google removed 93 flagged apps from Google Play, representing over 300M cumulative installs.
  We advocate for adopting our methodology as a proactive compliance-monitoring tool and offer targeted recommendations for regulators, platforms, and developers to strengthen privacy protections. Overall, our results highlight the need for coordinated enforcement and robust technical safeguards to ensure that digital lending supports financial inclusion without compromising user privacy or safety.

</details>


### [27] [BlocksecRT-DETR: Decentralized Privacy-Preserving and Token-Efficient Federated Transformer Learning for Secure Real-Time Object Detection in ITS](https://arxiv.org/abs/2601.12693)
*Mohoshin Ara Tahera,Sabbir Rahman,Shuvalaxmi Dass,Sharif Ullah,Mahmoud Abouyessef*

Main category: cs.CR

TL;DR: BlockSecRT-DETR：基于区块链的实时目标检测Transformer框架，用于智能交通系统中的联邦学习，解决非IID数据、边缘延迟和隐私安全问题。


<details>
  <summary>Details</summary>
Motivation: 智能交通系统中基于Transformer的联邦实时目标检测面临三大挑战：1）地理分布导致缺失类别的非IID数据异质性；2）边缘硬件上高容量Transformer模型的延迟约束；3）不可信客户端更新和中心化聚合带来的隐私安全风险。

Method: 提出BlockSecRT-DETR框架，包含：1）客户端集成RT-DETR训练和令牌工程模块（TEM），通过剪枝低效用令牌减少编码器复杂度和延迟；2）去中心化的区块链安全更新验证机制，实现防篡改、隐私保护、无需信任的模型聚合。

Result: TEM将推理延迟降低17.2%，编码器FLOPs减少47.8%，同时保持89.20% mAP@0.5的全局检测精度。区块链集成每轮增加400ms开销，账本大小保持在12KB以下（仅存储元数据）。

Conclusion: BlockSecRT-DETR成功解决了智能交通系统中联邦实时目标检测的关键挑战，通过令牌工程优化边缘性能，通过区块链确保安全可信的联邦学习，为实际部署提供了可行方案。

Abstract: Federated real-time object detection using transformers in Intelligent Transportation Systems (ITS) faces three major challenges: (1) missing-class non-IID data heterogeneity from geographically diverse traffic environments, (2) latency constraints on edge hardware for high-capacity transformer models, and (3) privacy and security risks from untrusted client updates and centralized aggregation. We propose BlockSecRT-DETR, a BLOCKchain-SECured Real-Time Object DEtection TRansformer framework for ITS that provides a decentralized, token-efficient, and privacy-preserving federated training solution using RT-DETR transformer, incorporating a blockchain-secured update validation mechanism for trustworthy aggregation. In this framework, challenges (1) and (2) are jointly addressed through a unified client-side design that integrates RT-DETR training with a Token Engineering Module (TEM). TEM prunes low-utility tokens, reducing encoder complexity and latency on edge hardware, while aggregated updates mitigate non-IID data heterogeneity across clients. To address challenge (3), BlockSecRT-DETR incorporates a decentralized blockchain-secured update validation mechanism that enables tamper-proof, privacy-preserving, and trust-free authenticated model aggregation without relying on a central server. We evaluated the proposed framework under a missing-class Non-IID partition of the KITTI dataset and conducted a blockchain case study to quantify security overhead. TEM improves inference latency by 17.2% and reduces encoder FLOPs by 47.8%, while maintaining global detection accuracy (89.20% mAP@0.5). The blockchain integration adds 400 ms per round, and the ledger size remains under 12 KB due to metadata-only on-chain storage.

</details>


### [28] [CellularSpecSec-Bench: A Staged Benchmark for Evidence-Grounded Interpretation and Security Reasoning over 3GPP Specifications](https://arxiv.org/abs/2601.12716)
*Ke Xie,Xingyi Zhao,Yiwen Hu,Shuhan Yuan,Tian Xie*

Main category: cs.CR

TL;DR: CellSpecSec-ARI：一个统一的Adapt-Retrieve-Integrate框架，用于系统理解3GPP规范并进行标准驱动的安全分析；CellSpecSec-Bench：一个分阶段基准测试，包含新构建的高质量数据集，用于量化蜂窝网络安全领域规范理解和安全推理的进展。


<details>
  <summary>Details</summary>
Motivation: 蜂窝网络是关键基础设施，支持数十亿用户和安全关键服务。3GPP规范中的漏洞可能导致服务中断、隐私泄露和广泛的社会危害，因此需要分析这些规范来确保安全。然而，蜂窝规范存在独特挑战：规范性语言的准确解释、跨引用条款的推理以及基于表格和图形等多模态证据的可验证结论。

Method: 提出CellSpecSec-ARI框架，采用统一的Adapt-Retrieve-Integrate方法，系统理解3GPP规范并进行标准驱动的安全分析。同时构建CellSpecSec-Bench基准测试，包含新构建的高质量数据集，其中部分数据来自先前开源资源并经过专家验证和修正。

Result: 建立了可访问且可重复的基础，用于量化蜂窝网络安全领域中规范理解和安全推理的进展。通过统一的框架和基准测试，为系统分析3GPP规范提供了方法论支持。

Conclusion: CellSpecSec-ARI框架和CellSpecSec-Bench基准测试共同为解决蜂窝规范理解中的独特挑战提供了系统解决方案，为蜂窝网络安全领域的规范理解和安全分析建立了可量化的进展评估基础。

Abstract: Cellular networks are critical infrastructure supporting billions of worldwide users and safety- and mission-critical services. Vulnerabilities in cellular networks can therefore cause service disruption, privacy breaches, and broad societal harm, motivating growing efforts to analyze 3GPP specifications that define required device and operator behavior. While large language models (LLMs) have demonstrated the capability for reading technical documents, cellular specifications impose unique challenges: faithful interpretation of normative language, reasoning across cross-referenced clauses, and verifiable conclusions grounded in multimodal evidence such as tables and figures. To address these challenges, we propose CellSpecSec-ARI, a unified Adapt-Retrieve-Integrate framework for systematic understanding and standard-driven security analysis of 3GPP specifications; CellularSpecSec-Bench, a staged benchmark, containing newly constructed high-quality datasets with expert-verified and corrected subsets from prior open-source resources. Together, they establish an accessible and reproducible foundation for quantifying progress in specification understanding and security reasoning in the cellular network security domain.

</details>


### [29] [DUAP: Dual-task Universal Adversarial Perturbations Against Voice Control Systems](https://arxiv.org/abs/2601.12786)
*Suyang Sun,Weifei Jin,Yuxin Cao,Wei Song,Jie Hao*

Main category: cs.CR

TL;DR: 提出DUAP方法，通过梯度分析发现ASR和SR无内在冲突，设计双任务通用对抗扰动同时攻击语音识别和说话人识别系统，使用动态归一化集成策略提升迁移性，结合心理声学掩蔽保证不可感知性。


<details>
  <summary>Details</summary>
Motivation: 现有对抗攻击通常单独针对ASR或SR，忽略了现实场景中两者耦合的决策管道，导致单任务攻击无法构成实际威胁。需要开发能同时攻击两个系统的实用对抗攻击方法。

Method: 首先通过梯度分析揭示ASR和SR无内在冲突；提出DUAP方法：1)使用目标替代目标有效破坏ASR转录；2)引入动态归一化集成(DNE)策略增强跨不同SR模型的迁移性；3)结合心理声学掩蔽确保扰动不可感知。

Result: 在5个ASR模型和6个SR模型上的广泛评估表明，DUAP实现了高同时攻击成功率（同时攻击ASR和SR）和优越的不可感知性，显著优于现有的单任务基线方法。

Conclusion: DUAP填补了现有对抗攻击研究的空白，首次实现了对语音控制系统ASR和SR双任务的实用对抗攻击，为语音安全领域提供了新的威胁模型和防御研究方向。

Abstract: Modern Voice Control Systems (VCS) rely on the collaboration of Automatic Speech Recognition (ASR) and Speaker Recognition (SR) for secure interaction. However, prior adversarial attacks typically target these tasks in isolation, overlooking the coupled decision pipeline in real-world scenarios. Consequently, single-task attacks often fail to pose a practical threat. To fill this gap, we first utilize gradient analysis to reveal that ASR and SR exhibit no inherent conflicts. Building on this, we propose Dual-task Universal Adversarial Perturbation (DUAP). Specifically, DUAP employs a targeted surrogate objective to effectively disrupt ASR transcription and introduces a Dynamic Normalized Ensemble (DNE) strategy to enhance transferability across diverse SR models. Furthermore, we incorporate psychoacoustic masking to ensure perturbation imperceptibility. Extensive evaluations across five ASR and six SR models demonstrate that DUAP achieves high simultaneous attack success rates and superior imperceptibility, significantly outperforming existing single-task baselines.

</details>


### [30] [PDFInspect: A Unified Feature Extraction Framework for Malicious Document Detection](https://arxiv.org/abs/2601.12866)
*Sharmila S P*

Main category: cs.CR

TL;DR: 提出一个统一框架，整合图结构、元数据和结构分析，从PDF文件中提取170维特征向量用于恶意软件检测


<details>
  <summary>Details</summary>
Motivation: 恶意PDF文件日益增多，需要强大全面的特征提取技术进行有效检测和分析

Method: 整合图基、结构和元数据驱动的分析：1)从PDF页面提取文本构建无向图计算图论特征；2)解析元数据量化字符分布、熵模式等；3)从时间戳提取时间特征；4)量化结构元素如对象流、字体、嵌入图像；5)提取恶意PDF构造的布尔标志

Result: 生成170维高维特征向量表示，适用于恶意软件分类、异常检测和取证分析

Conclusion: 提出的方法具有可扩展性、可扩展性，支持现实世界的PDF威胁情报工作流程

Abstract: The increasing prevalence of malicious Portable Document Format (PDF) files necessitates robust and comprehensive feature extraction techniques for effective detection and analysis. This work presents a unified framework that integrates graph-based, structural, and metadata-driven analysis to generate a rich feature representation for each PDF document. The system extracts text from PDF pages and constructs undirected graphs based on pairwise word relationships, enabling the computation of graph-theoretic features such as node count, edge density, and clustering coefficient. Simultaneously, the framework parses embedded metadata to quantify character distributions, entropy patterns, and inconsistencies across fields such as author, title, and producer. Temporal features are derived from creation and modification timestamps to capture behavioral signatures, while structural elements including, object streams, fonts, and embedded images, are quantified to reflect document complexity. Boolean flags for potentially malicious PDF constructs (e.g., JavaScript, launch actions) are also extracted. Together, these features form a high-dimensional vector representation (170 dimensions) that is well-suited for downstream tasks such as malware classification, anomaly detection, and forensic analysis. The proposed approach is scalable, extensible, and designed to support real-world PDF threat intelligence workflows.6

</details>


### [31] [SWORD: A Secure LoW-Latency Offline-First Authentication and Data Sharing Scheme for Resource Constrained Distributed Networks](https://arxiv.org/abs/2601.12875)
*Faisal Haque Bappy,Tahrim Hossain,Raiful Hasan,Kamrul Hasan,Mohamed Younis,Tariqul Islam*

Main category: cs.CR

TL;DR: SWORD是一个专为资源受限网络设计的离线优先认证与数据共享方案，通过邻近聚类实现低延迟、安全的离线操作，性能优于传统区块链方案，接近中心服务器方案。


<details>
  <summary>Details</summary>
Motivation: 物联网和车联网等资源受限网络本质上是分布式的，但大多仍依赖中心服务器进行快速认证和数据共享。基于区块链的解决方案虽然提供去中心化替代方案，但难以满足实时应用的严格延迟要求。即使5G部署后，服务器与对等节点之间的网络延迟仍然是重大挑战。

Method: SWORD采用基于邻近性的聚类方法，实现离线认证和数据共享。该方案专门针对资源受限网络设计，确保在间歇性连接场景下也能进行低延迟、安全的操作。

Result: 实验结果表明，SWORD优于传统的基于区块链的解决方案，同时在资源效率和认证延迟方面与基于中心服务器的解决方案相似。安全分析表明，SWORD能够抵御欺骗、冒充、重放和中间人攻击。

Conclusion: SWORD为资源受限网络提供了一种有效的离线优先认证和数据共享方案，在保持去中心化优势的同时，解决了区块链方案延迟过高的问题，实现了接近中心服务器方案的性能。

Abstract: While many resource-constrained networks, such as Internet of Things (IoT) and Internet of Vehicles (IoV), are inherently distributed, the majority still rely on central servers for fast authentication and data sharing. Blockchain-based solutions offer decentralized alternatives but often struggle to meet the stringent latency requirements of real-time applications. Even with the rollout of 5G, network latency between servers and peers remains a significant challenge. To address this, we introduce SWORD, a novel offline-first authentication and data-sharing scheme designed specifically for resource-constrained networks. SWORD utilizes a proximity-based clustering approach to enable offline authentication and data sharing, ensuring low-latency, secure operations even in intermittently connected scenarios. Our experimental results show that SWORD outperforms traditional blockchain-based solutions while offering similar resource efficiency and authentication latency to central-server-based solutions. Additionally, we provide a comprehensive security analysis, demonstrating that SWORD is resilient against spoofing, impersonation, replay, and man-in-the-middle attacks.

</details>


### [32] [Static Detection of Core Structures in Tigress Virtualization-Based Obfuscation Using an LLVM Pass](https://arxiv.org/abs/2601.12916)
*Sangjun An,Seoksu Lee,Eun-Sun Cho*

Main category: cs.CR

TL;DR: 该论文提出了一种基于静态分析的方法，使用LLVM IR来识别虚拟化混淆的核心结构组件（调度例程、处理程序块和VM区域），实验表明该方法能有效检测多种虚拟化模式。


<details>
  <summary>Details</summary>
Motivation: 恶意软件常使用虚拟化混淆技术来阻碍安全分析，这种技术将原始指令转换为攻击者定义的虚拟机字节码，产生难以分析和反混淆的复杂代码。现有方法难以有效识别和解析这种混淆结构。

Method: 通过静态分析检查混淆代码的执行模型，使用LLVM IR定义和检测反混淆所需的关键元素：调度例程、处理程序块和VM区域，开发了专门的LLVM Pass来实现检测。

Result: 在没有编译器优化的情况下，提出的LLVM Pass能够成功检测所有主要虚拟化选项（包括switch、direct和indirect模式）的核心结构，实现了全面的结构识别。

Conclusion: 该方法为虚拟化混淆的分析提供了有效的静态检测手段，能够识别关键结构组件，为后续的反混淆和安全分析工作奠定基础。

Abstract: Malware often uses obfuscation to hinder security analysis. Among these techniques, virtualization-based obfuscation is particularly strong because it protects programs by translating original instructions into attacker-defined virtual machine (VM) bytecode, producing long and complex code that is difficult to analyze and deobfuscate. This paper aims to identify the structural components of virtualization-based obfuscation through static analysis. By examining the execution model of obfuscated code, we define and detect the key elements required for deobfuscation-namely the dispatch routine, handler blocks, and the VM region-using LLVM IR. Experimental results show that, in the absence of compiler optimizations, the proposed LLVM Pass successfully detects all core structures across major virtualization options, including switch, direct, and indirect modes.

</details>


### [33] [Your Privacy Depends on Others: Collusion Vulnerabilities in Individual Differential Privacy](https://arxiv.org/abs/2601.12922)
*Johannes Kaiser,Alexander Ziller,Eleni Triantafillou,Daniel Rückert,Georgios Kaissis*

Main category: cs.CR

TL;DR: 个体差分隐私(iDP)存在漏洞：虽然满足iDP保证，但个体的隐私风险不仅取决于自身隐私预算，还受其他数据贡献者隐私选择的影响，导致隐私风险被集体决定而非个体控制。


<details>
  <summary>Details</summary>
Motivation: iDP承诺用户能控制自己的隐私，但实践中这一承诺可能被打破。作者发现采样基iDP机制中存在被忽视的漏洞：个体的隐私风险不仅由自身隐私预算决定，还关键取决于所有其他数据贡献者的隐私选择，导致个体隐私控制承诺与现实风险集体决定之间存在不匹配。

Method: 1. 揭示采样基iDP机制的漏洞：隐私风险集体决定而非个体控制；2. 实证证明某些隐私偏好分布会无意中增加个体隐私风险；3. 展示攻击者如何利用这一漏洞：中央对手或合谋对手可故意选择隐私预算来放大目标个体的脆弱性；4. 提出$(\varepsilon_i,\delta_i,\overline{\Delta})$-iDP隐私契约，使用$\Delta$-散度为用户提供超额脆弱性的硬上限。

Result: 实证评估显示成功攻击了62%的目标个体，显著增加了他们的成员推理易感性。攻击完全在DP保证范围内操作，隐藏了这种超额脆弱性。

Conclusion: 研究结果暴露了当前范式的根本挑战，要求重新评估iDP系统的设计、审计、沟通和部署方式，使超额风险透明且可控。提出的$(\varepsilon_i,\delta_i,\overline{\Delta})$-iDP隐私契约为用户提供超额脆弱性的硬上限，同时为机制设计提供灵活性。

Abstract: Individual Differential Privacy (iDP) promises users control over their privacy, but this promise can be broken in practice. We reveal a previously overlooked vulnerability in sampling-based iDP mechanisms: while conforming to the iDP guarantees, an individual's privacy risk is not solely governed by their own privacy budget, but critically depends on the privacy choices of all other data contributors. This creates a mismatch between the promise of individual privacy control and the reality of a system where risk is collectively determined. We demonstrate empirically that certain distributions of privacy preferences can unintentionally inflate the privacy risk of individuals, even when their formal guarantees are met. Moreover, this excess risk provides an exploitable attack vector. A central adversary or a set of colluding adversaries can deliberately choose privacy budgets to amplify vulnerabilities of targeted individuals. Most importantly, this attack operates entirely within the guarantees of DP, hiding this excess vulnerability. Our empirical evaluation demonstrates successful attacks against 62% of targeted individuals, substantially increasing their membership inference susceptibility. To mitigate this, we propose $(\varepsilon_i,δ_i,\overlineΔ)$-iDP a privacy contract that uses $Δ$-divergences to provide users with a hard upper bound on their excess vulnerability, while offering flexibility to mechanism design. Our findings expose a fundamental challenge to the current paradigm, demanding a re-evaluation of how iDP systems are designed, audited, communicated, and deployed to make excess risks transparent and controllable.

</details>


### [34] [On the Evidentiary Limits of Membership Inference for Copyright Auditing](https://arxiv.org/abs/2601.12937)
*Murat Bilgehan Ertan,Emirhan Böge,Min Chen,Kaleel Mahmood,Marten van Dijk*

Main category: cs.CR

TL;DR: MIAs（成员推理攻击）在对抗性版权争议中作为证据不可靠，因为通过SAGE框架生成的语义保持但词汇结构改变的改写文本会显著降低现有MIA的效果。


<details>
  <summary>Details</summary>
Motivation: 随着LLMs在日益不透明的语料库上训练，MIAs被提出用于审计训练数据中是否包含受版权保护的文本，但在现实对抗性场景下其可靠性受到质疑。本文研究MIAs在对抗性版权争议中是否可作为有效证据，特别是当被告模型开发者可能对训练数据进行语义保持的模糊处理时。

Method: 提出SAGE（Structure-Aware SAE-Guided Extraction）框架，利用稀疏自编码器（SAEs）指导改写训练数据，改变词汇结构同时保持语义内容和下游效用。通过法官-检察官-被告通信协议形式化对抗性设置，测试MIAs在该协议下的鲁棒性。

Result: 实验表明，当模型在SAGE生成的改写文本上进行微调时，最先进的MIAs性能显著下降，说明其信号对语义保持的转换不鲁棒。尽管在某些微调机制下仍存在信息泄露，但结果表明MIAs在对抗性环境中是脆弱的。

Conclusion: MIAs在对抗性设置下是脆弱的，单独作为LLMs版权审计的独立机制是不充分的。需要更鲁棒的审计方法来应对现实世界中的对抗性场景。

Abstract: As large language models (LLMs) are trained on increasingly opaque corpora, membership inference attacks (MIAs) have been proposed to audit whether copyrighted texts were used during training, despite growing concerns about their reliability under realistic conditions. We ask whether MIAs can serve as admissible evidence in adversarial copyright disputes where an accused model developer may obfuscate training data while preserving semantic content, and formalize this setting through a judge-prosecutor-accused communication protocol. To test robustness under this protocol, we introduce SAGE (Structure-Aware SAE-Guided Extraction), a paraphrasing framework guided by Sparse Autoencoders (SAEs) that rewrites training data to alter lexical structure while preserving semantic content and downstream utility. Our experiments show that state-of-the-art MIAs degrade when models are fine-tuned on SAGE-generated paraphrases, indicating that their signals are not robust to semantics-preserving transformations. While some leakage remains in certain fine-tuning regimes, these results suggest that MIAs are brittle in adversarial settings and insufficient, on their own, as a standalone mechanism for copyright auditing of LLMs.

</details>


### [35] [Reproducibility in Event-Log Research: A Parametrised Generator and Benchmark for Event-based Signatures](https://arxiv.org/abs/2601.12978)
*Saad Khan,Simon Parkinson,Monika Roopak*

Main category: cs.CR

TL;DR: 提出一种参数化生成合成事件日志的方法，用于网络安全签名检测的可复现基准测试，DBSCAN算法在大多数生成数据集上表现优异（ARI>0.95）。


<details>
  <summary>Details</summary>
Motivation: 网络安全事件数据集对攻击检测至关重要，但真实数据集因安全敏感性难以共享，导致不同方法之间难以进行有意义的比较评估。

Method: 提出一种新颖的参数化生成技术，能够生成包含已知真实标签（ground truth）的事件日志，这些日志包含待发现的事件签名。

Result: 通过基准测试展示了该技术的有效性，DBSCAN算法在大多数生成数据集上取得了超过0.95的调整兰德指数（Adjusted Rand Index）。

Conclusion: 这项工作增强了研究人员开发和基准测试新网络安全技术的能力，最终有助于建立更强大有效的网络安全措施。

Abstract: Event-based datasets are crucial for cybersecurity analysis. A key use case is detecting event-based signatures, which represent attacks spanning multiple events and can only be understood once the relevant events are identified and linked. Analysing event datasets is essential for monitoring system security, but their growing volume and frequency create significant scalability and processing difficulties. Researchers rely on these datasets to develop and test techniques for automatically identifying signatures. However, because real datasets are security-sensitive and rarely shared, it becomes difficult to perform meaningful comparative evaluation between different approaches. This work addresses this evaluation limitation by offering a systematic method for generating event logs with known ground truth, enabling reproducible and comparable research. We present a novel parametrised generation technique capable of producing synthetic event datasets that contain event-based signatures for discovery. To demonstrate the capabilities of the technique, we provide a benchmark in signature detection. Our benchmarking demonstrated the suitability of DBSCAN, achieving a score greater than 0.95 Adjusted Rand Index on most generated datasets. This work enhances the ability of researchers to develop and benchmark new cybersecurity techniques, ultimately contributing to more robust and effective cybersecurity measures.

</details>


### [36] [KinGuard: Hierarchical Kinship-Aware Fingerprinting to Defend Against Large Language Model Stealing](https://arxiv.org/abs/2601.12986)
*Zhenhua Xu,Xiaoning Tian,Wenjun Zeng,Wenpeng Xing,Tianliang Lu,Gaolei Li,Chaochao Chen,Meng Han*

Main category: cs.CR

TL;DR: KinGuard：基于亲属关系知识嵌入的LLM所有权验证框架，解决传统后门指纹方法的隐蔽性与鲁棒性矛盾


<details>
  <summary>Details</summary>
Motivation: 传统后门指纹方法存在隐蔽性-鲁棒性悖论：为了鲁棒性需要模型记忆高困惑度触发器的固定响应，但这种针对性过拟合会产生可检测的统计特征。需要一种既隐蔽又鲁棒的所有权验证方法。

Method: KinGuard框架：嵌入基于结构化亲属关系叙事的私有知识语料库，通过增量预训练让模型内化这些知识（而非记忆表面触发器），通过探测模型的概念理解来验证所有权。

Result: 大量实验表明KinGuard在有效性、隐蔽性和鲁棒性方面表现优越，能够抵抗微调、输入扰动和模型合并等多种攻击。

Conclusion: 基于知识嵌入的模型指纹识别是一种实用且安全的范式，为解决LLM知识产权保护提供了新思路。

Abstract: Protecting the intellectual property of large language models requires robust ownership verification. Conventional backdoor fingerprinting, however, is flawed by a stealth-robustness paradox: to be robust, these methods force models to memorize fixed responses to high-perplexity triggers, but this targeted overfitting creates detectable statistical artifacts. We resolve this paradox with KinGuard, a framework that embeds a private knowledge corpus built on structured kinship narratives. Instead of memorizing superficial triggers, the model internalizes this knowledge via incremental pre-training, and ownership is verified by probing its conceptual understanding. Extensive experiments demonstrate KinGuard's superior effectiveness, stealth, and resilience against a battery of attacks including fine-tuning, input perturbation, and model merging. Our work establishes knowledge-based embedding as a practical and secure paradigm for model fingerprinting.

</details>


### [37] [PrivFly: A Privacy-Preserving Self-Supervised Framework for Rare Attack Detection in IoFT](https://arxiv.org/abs/2601.13003)
*Safaa Menssouri,El Mehdi Amhoud*

Main category: cs.CR

TL;DR: PrivFly是一个隐私保护的入侵检测系统框架，结合自监督表示学习和差分隐私，用于不平衡的飞行物联网网络流量检测，在保护隐私的同时达到高检测性能。


<details>
  <summary>Details</summary>
Motivation: 飞行物联网(IoFT)在现代应用中至关重要，但易受网络攻击威胁。现有入侵检测系统面临数据不平衡、隐私问题和传统模型难以检测罕见威胁等挑战。

Method: 提出PrivFly框架，集成自监督表示学习和差分隐私。包括掩码特征重建模块进行自监督预训练，提升特征表示和罕见类检测；在训练中应用差分隐私保护敏感信息；使用SHAP分析评估差分隐私对特征重要性的影响。

Result: 在ECU-IoFT数据集上，PrivFly达到98%准确率和99% F1分数，有效平衡了隐私保护和检测性能。

Conclusion: PrivFly框架成功解决了IoFT网络中入侵检测的数据不平衡和隐私保护问题，为安全IoFT系统提供了有效的隐私保护检测方案。

Abstract: The Internet of Flying Things (IoFT) plays a vital role in modern applications such as aerial surveillance and smart mobility. However, it remains highly vulnerable to cyberattacks that threaten the confidentiality, integrity, and availability of sensitive data. Developing effective intrusion detection systems (IDS) for IoFT networks faces key challenges, including data imbalance, privacy concerns, and the limited capability of traditional models to detect rare but potentially damaging cyber threats. In this work, we propose PrivFly, a privacy-preserving IDS framework that integrates self-supervised representation learning and differential privacy (DP) to enhance detection performance in imbalanced IoFT network traffic. We propose a masked feature reconstruction module for self-supervised pretraining, improving feature representations and boosting rare-class detection. Differential privacy is applied during training to protect sensitive information without significantly compromising model performance. In addition, we conduct a SHapley additive explanations (SHAP)-based analysis to evaluate the impact of DP on feature importance and model behavior. Experimental results on the ECU-IoFT dataset show that PrivFly achieves up to 98% accuracy and 99% F1-score, effectively balancing privacy and detection performance for secure IoFT systems.

</details>


### [38] [Post-Quantum Secure Aggregation via Code-Based Homomorphic Encryption](https://arxiv.org/abs/2601.13031)
*Sebastian Bitzer,Maximilian Egger,Mumin Liu,Antonia Wachter-Zeh*

Main category: cs.CR

TL;DR: 提出基于LPN假设的代码安全聚合方案，通过委员会解密和CRT优化降低通信开销，在特定场景下优于信息论安全协议


<details>
  <summary>Details</summary>
Motivation: 现有后量子安全聚合方案主要基于格密码，需要基于LPN假设的代码方案作为替代，以提供多样化的安全假设选择

Method: 基于密钥和消息加法同态加密框架，采用委员会解密机制（通过秘密共享实现），并引入CRT优化降低LPN方案的通信成本

Result: 在Hint-LPN假设下分析方案安全性，证明其与标准LPN等价，性能评估显示在某些场景下优于信息论安全聚合协议

Conclusion: 成功构建了基于LPN假设的代码安全聚合方案，提供了格密码之外的实用后量子安全聚合选择，在特定参数下具有性能优势

Abstract: Secure aggregation enables aggregation of inputs from multiple parties without revealing individual contributions to the server or other clients. Existing post-quantum approaches based on homomorphic encryption offer practical efficiency but predominantly rely on lattice-based hardness assumptions. We present a code-based alternative for secure aggregation by instantiating a general framework based on key- and message-additive homomorphic encryption under the Learning Parity with Noise (LPN) assumption. Our construction employs a committee-based decryptor realized via secret sharing and incorporates a Chinese Remainder Theorem (CRT)-based optimization to reduce the communication costs of LPN-based instantiations. We analyze the security of the proposed scheme under a new Hint-LPN assumption and show that it is equivalent to standard LPN for suitable parameters. Finally, we evaluate performance and identify regimes in which our approach outperforms information-theoretically secure aggregation protocols.

</details>


### [39] [High-Throughput and Scalable Secure Inference Protocols for Deep Learning with Packed Secret Sharing](https://arxiv.org/abs/2601.13041)
*Qinghui Zhang,Xiaojun Chen,Yansong Zhang,Xudong Chen*

Main category: cs.CR

TL;DR: 提出基于打包Shamir秘密共享的高吞吐量、可扩展MPC协议，用于神经网络推理，显著降低通信开销和运行时间


<details>
  <summary>Details</summary>
Motivation: 现有基于MPC的安全神经网络推理协议最多支持4个参与者，可扩展性有限。Liu等人的方案在处理深层网络（如VGG16）时通信开销大，在广域网环境中延迟显著

Method: 使用打包Shamir秘密共享实现并行计算和降低通信复杂度。包括：1）基于新定义的向量-矩阵乘法友好随机共享元组的通信高效协议；2）支持并行卷积的滤波器打包方法；3）将所有非线性协议扩展到基于PSS的协议以实现并行非线性操作

Result: 相比Liu等人的方案，通信开销降低：离线5.85倍、在线11.17倍、总计6.83倍；运行时间提升：离线1.59倍、在线2.61倍、总计1.75倍

Conclusion: 提出的基于打包Shamir秘密共享的协议在广域网环境中具有优越性能，显著提高了安全神经网络推理的可扩展性和效率

Abstract: Most existing secure neural network inference protocols based on secure multi-party computation (MPC) typically support at most four participants, demonstrating severely limited scalability. Liu et al. (USENIX Security'24) presented the first relatively practical approach by utilizing Shamir secret sharing with Mersenne prime fields. However, when processing deeper neural networks such as VGG16, their protocols incur substantial communication overhead, resulting in particularly significant latency in wide-area network (WAN) environments. In this paper, we propose a high-throughput and scalable MPC protocol for neural network inference against semi-honest adversaries in the honest-majority setting. The core of our approach lies in leveraging packed Shamir secret sharing (PSS) to enable parallel computation and reduce communication complexity. The main contributions are three-fold: i) We present a communication-efficient protocol for vector-matrix multiplication, based on our newly defined notion of vector-matrix multiplication-friendly random share tuples. ii) We design the filter packing approach that enables parallel convolution. iii) We further extend all non-linear protocols based on Shamir secret sharing to the PSS-based protocols for achieving parallel non-linear operations. Extensive experiments across various datasets and neural networks demonstrate the superiority of our approach in WAN. Compared to Liu et al. (USENIX Security'24), our scheme reduces the communication upto 5.85x, 11.17x, and 6.83x in offline, online and total communication overhead, respectively. In addition, our scheme is upto 1.59x, 2.61x, and 1.75x faster in offline, online and total running time, respectively.

</details>


### [40] [Adversarial News and Lost Profits: Manipulating Headlines in LLM-Driven Algorithmic Trading](https://arxiv.org/abs/2601.13082)
*Advije Rizvani,Giovanni Apruzzese,Pavel Laskov*

Main category: cs.CR

TL;DR: 论文研究了针对金融领域LLM的对抗性攻击，通过操纵新闻标题（使用Unicode同形字替换和隐藏文本）误导算法交易系统，导致年化收益率下降高达17.7个百分点。


<details>
  <summary>Details</summary>
Motivation: LLM在金融领域应用日益广泛，特别是用于分析财经新闻情感以指导算法交易决策。然而，威胁行为者可能制作"对抗性新闻"来误导LLM，这种系统性的货币风险尚未被量化。

Method: 研究两种人类难以察觉的操纵方法：1) Unicode同形字替换误导股票名称识别；2) 隐藏文本条款改变新闻标题情感。在Backtrader中实现现实的算法交易系统，融合LSTM价格预测和LLM情感分析（FinBERT、FinGPT、FinLLaMA等），使用投资组合指标量化货币影响。

Result: 实验显示，在14个月内进行单日攻击可以可靠地误导LLM，使年化收益率降低高达17.7个百分点。通过分析流行的爬虫库和交易平台，并调查27名金融科技从业者，确认了攻击的现实可行性。

Conclusion: LLM支持的算法交易系统面临严重的对抗性攻击风险，攻击者无需直接访问系统即可通过操纵新闻标题造成重大财务损失。研究已通知交易平台所有者此安全问题。

Abstract: Large Language Models (LLMs) are increasingly adopted in the financial domain. Their exceptional capabilities to analyse textual data make them well-suited for inferring the sentiment of finance-related news. Such feedback can be leveraged by algorithmic trading systems (ATS) to guide buy/sell decisions. However, this practice bears the risk that a threat actor may craft "adversarial news" intended to mislead an LLM. In particular, the news headline may include "malicious" content that remains invisible to human readers but which is still ingested by the LLM. Although prior work has studied textual adversarial examples, their system-wide impact on LLM-supported ATS has not yet been quantified in terms of monetary risk. To address this threat, we consider an adversary with no direct access to an ATS but able to alter stock-related news headlines on a single day. We evaluate two human-imperceptible manipulations in a financial context: Unicode homoglyph substitutions that misroute models during stock-name recognition, and hidden-text clauses that alter the sentiment of the news headline. We implement a realistic ATS in Backtrader that fuses an LSTM-based price forecast with LLM-derived sentiment (FinBERT, FinGPT, FinLLaMA, and six general-purpose LLMs), and quantify monetary impact using portfolio metrics. Experiments on real-world data show that manipulating a one-day attack over 14 months can reliably mislead LLMs and reduce annual returns by up to 17.7 percentage points. To assess real-world feasibility, we analyze popular scraping libraries and trading platforms and survey 27 FinTech practitioners, confirming our hypotheses. We notified trading platform owners of this security issue.

</details>


### [41] [CODE: A Contradiction-Based Deliberation Extension Framework for Overthinking Attacks on Retrieval-Augmented Generation](https://arxiv.org/abs/2601.13112)
*Xiaolei Zhang,Xiaojun Jia,Liquan Chen,Songze Li*

Main category: cs.CR

TL;DR: 论文提出CODE攻击框架，通过向RAG系统知识库注入矛盾样本来诱导推理模型过度思考，显著增加推理令牌消耗而不影响任务准确性。


<details>
  <summary>Details</summary>
Motivation: 推理模型在RAG系统中能提升任务性能，但存在过度思考攻击风险。研究发现这种风险会遗传给配备推理模型的RAG系统，需要揭示并研究这种安全威胁。

Method: 提出Contradiction-Based Deliberation Extension (CODE)攻击框架：采用多智能体架构构建投毒样本注入知识库，样本与用户查询高度相关以确保被检索，包含逻辑层与证据层矛盾以诱导过度思考，并优化为高度多样化的风格。

Result: 在两个数据集和五个商业推理模型上的实验表明，该攻击使推理令牌消耗增加5.32-24.72倍，且任务准确性不受影响，攻击极难检测。

Conclusion: CODE攻击揭示了RAG系统中推理模型的过度思考风险，这种攻击隐蔽性强且不影响任务性能，论文还讨论并评估了潜在的防御措施。

Abstract: Introducing reasoning models into Retrieval-Augmented Generation (RAG) systems enhances task performance through step-by-step reasoning, logical consistency, and multi-step self-verification. However, recent studies have shown that reasoning models suffer from overthinking attacks, where models are tricked to generate unnecessarily high number of reasoning tokens. In this paper, we reveal that such overthinking risk can be inherited by RAG systems equipped with reasoning models, by proposing an end-to-end attack framework named Contradiction-Based Deliberation Extension (CODE). Specifically, CODE develops a multi-agent architecture to construct poisoning samples that are injected into the knowledge base. These samples 1) are highly correlated with the use query, such that can be retrieved as inputs to the reasoning model; and 2) contain contradiction between the logical and evidence layers that cause models to overthink, and are optimized to exhibit highly diverse styles. Moreover, the inference overhead of CODE is extremely difficult to detect, as no modification is needed on the user query, and the task accuracy remain unaffected. Extensive experiments on two datasets across five commercial reasoning models demonstrate that the proposed attack causes a 5.32x-24.72x increase in reasoning token consumption, without degrading task performance. Finally, we also discuss and evaluate potential countermeasures to mitigate overthinking risks.

</details>


### [42] [Diffusion-Driven Synthetic Tabular Data Generation for Enhanced DoS/DDoS Attack Classification](https://arxiv.org/abs/2601.13197)
*Aravind B,Anirud R. S.,Sai Surya Teja N,Bala Subrahmanya Sriranga Navaneeth A,Karthika R,Mohankumar N*

Main category: cs.CR

TL;DR: 使用TabDDPM扩散模型为网络入侵检测中的类别不平衡问题生成少数类合成样本，显著提升ANN分类器对少数攻击类的召回率


<details>
  <summary>Details</summary>
Motivation: 网络入侵检测数据集中存在严重的类别不平衡问题，少数攻击类样本数量显著不足，导致模型性能偏向多数类，无法有效检测罕见攻击

Method: 采用Tabular Denoising Diffusion Probability Models (TabDDPM)对CIC-IDS2017数据集中的少数类进行数据增强，通过迭代去噪过程生成高质量合成样本，然后将合成样本与原始数据集合并

Result: 增强后的训练数据使ANN分类器在先前代表性不足的攻击类上达到接近完美的召回率，显著改善了模型对少数类的检测能力

Conclusion: 扩散模型是解决安全领域表格数据不平衡问题的有效方案，在欺诈检测和医疗诊断等领域具有潜在应用价值

Abstract: Class imbalance refers to a situation where certain classes in a dataset have significantly fewer samples than oth- ers, leading to biased model performance. Class imbalance in network intrusion detection using Tabular Denoising Diffusion Probability Models (TabDDPM) for data augmentation is ad- dressed in this paper. Our approach synthesizes high-fidelity minority-class samples from the CIC-IDS2017 dataset through iterative denoising processes. For the minority classes that have smaller samples, synthetic samples were generated and merged with the original dataset. The augmented training data enables an ANN classifier to achieve near-perfect recall on previously underrepresented attack classes. These results establish diffusion models as an effective solution for tabular data imbalance in security domains, with potential applications in fraud detection and medical diagnostics.

</details>


### [43] [Function Recovery Attacks in Gate-Hiding Garbled Circuits using SAT Solving](https://arxiv.org/abs/2601.13271)
*Chao Yin,Zunchen Huang,Chenglu Jin,Marten van Dijk,Fabio Massacci*

Main category: cs.CR

TL;DR: 论文分析了门隐藏电路拓扑泄露对函数隐私的实际影响，提出了基于SAT的函数恢复攻击方法，在24小时内能有效恢复隐藏函数


<details>
  <summary>Details</summary>
Motivation: 现有门隐藏安全定义故意忽略了电路拓扑泄露问题，导致对函数隐私的实际影响理解不足。需要分析拓扑泄露在现实计算能力下的实际安全性

Method: 提出基于SAT的函数恢复攻击方法，结合增量SAT求解框架和可组合的拓扑保持简化定理，减少SAT实例大小并逐步约束搜索空间

Result: 在ISCAS基准、安全计算电路和容错传感器融合电路上评估，相比基线方法实现最高159倍的速度提升，不增加查询次数下在24小时内有效恢复函数

Conclusion: 仅凭拓扑泄露就能够在实践中实现有效的函数恢复，这对半私有函数评估的安全性提出了重要警示

Abstract: Semi-Private Function Evaluation enables joint computation while protecting both input data and function logic. A practical instantiation is gate-hiding garbled circuits, which conceal gate functionalities while revealing the circuit topology. Existing security definitions intentionally exclude leakage through circuit topology, leaving the concrete impact of such leakage on function privacy insufficiently understood.
  We analyze the empirical security of gate hiding under two adversarial models that capture realistic computational capabilities. We present a SAT-based function-recovery attack that reconstructs hidden gate operations from a circuit's public topology. To enable recovery on larger and more complex circuits, we develop an incremental SAT-solving framework combined with a set of composable, topology-preserving simplification theorems. These techniques jointly reduce the SAT instance size and progressively constrain the search space across repeated solving iterations.
  We evaluate our attack on ISCAS benchmarks, representative secure computation circuits, and fault-tolerant sensor fusion circuits under a fixed 24-hour recovery budget. Compared to baseline approaches, our optimized attack achieves up to a 159-fold speedup in recovery time without increasing the number of oracle queries. Our results demonstrate that topology leakage alone can enable effective function recovery in practice.

</details>


### [44] [QERS: Quantum Encryption Resilience Score for Post-Quantum Cryptography in Computer, IoT, and IIoT Systems](https://arxiv.org/abs/2601.13399)
*Jonatan Rassekhnia*

Main category: cs.CR

TL;DR: QERS框架：一个集成密码性能、系统约束和多准则决策分析的量子加密韧性评分系统，用于评估后量子密码在IoT/IIoT环境中的就绪度。


<details>
  <summary>Details</summary>
Motivation: 现有后量子密码评估方法主要关注孤立性能指标，缺乏对整体安全性和部署决策的全面支持，特别是在资源受限的IoT/IIoT环境中需要更全面的评估框架。

Method: 提出QERS（量子加密韧性评分）通用测量框架，集成归一化指标、加权聚合和机器学习辅助分析，评估异构设备和通信协议下的后量子密码方案。

Result: 实验结果表明该框架能够在实际资源约束下对后量子方案进行对比评估，支持明智的安全设计和迁移规划。

Conclusion: QERS为计算机、IoT和IIoT环境中的后量子密码就绪度评估提供了全面框架，有助于后量子密码的实际部署决策。

Abstract: Post-quantum cryptography (PQC) is becoming essential for securing Internet of Things (IoT) and Industrial IoT (IIoT) systems against quantum-enabled adversaries. However, existing evaluation approaches primarily focus on isolated performance metrics, offering limited support for holistic security and deployment decisions. This paper introduces QERS (Quantum Encryption Resilience Score), a universal measurement framework that integrates cryptographic performance, system constraints, and multi-criteria decision analysis to assess PQC readiness in computer, IoT, and IIoT environments. QERS combines normalized metrics, weighted aggregation, and machine learning-assisted analysis to produce interpretable resilience scores across heterogeneous devices and communication protocols. Experimental results demonstrate how the framework enables comparative evaluation of post-quantum schemes under realistic resource constraints, supporting informed security design and migration planning. This work is presented as a preprint, with extended statistical validation planned as part of ongoing graduate research.

</details>


### [45] [Quantum Encryption Resilience Score (QERS) for MQTT, HTTP, and HTTPS under Post-Quantum Cryptography in Computer, IoT, and IIoT Systems](https://arxiv.org/abs/2601.13423)
*Jonatan Rassekhnia*

Main category: cs.CR

TL;DR: 该论文提出量子加密韧性评分(QERS)框架，用于评估MQTT、HTTP和HTTPS协议在后量子密码(PQC)环境下的性能与安全性，实验表明MQTT在PQC约束下效率最高，HTTPS安全性最强但资源消耗大。


<details>
  <summary>Details</summary>
Motivation: 后量子密码(PQC)带来了显著的计算和通信开销，这对资源受限的计算机系统、物联网(IoT)和工业物联网(IIoT)设备构成了挑战。需要一种系统化的方法来评估不同通信协议在PQC环境下的效率和安全性。

Method: 使用ESP32-C6客户端和基于ARM的Raspberry Pi CM4服务器，在实际操作条件下测量MQTT、HTTP和HTTPS协议的延迟、CPU利用率、RSSI、能耗、密钥大小和TLS握手开销。通过QERS框架将这些异构指标整合为归一化的基础评分、调优评分和融合评分。

Result: 实验结果表明：MQTT在PQC约束下提供最高效率；HTTPS实现最高的安全加权韧性，但代价是延迟增加和资源消耗更大。QERS框架能够系统化比较协议效率和安全性韧性。

Conclusion: 提出的QERS框架支持为PQC启用的物联网和工业物联网部署提供知情的协议选择和迁移规划，帮助在效率与安全性之间做出平衡决策。

Abstract: Post-quantum cryptography (PQC) introduces significant computational and communication overhead, which poses challenges for resource-constrained computer systems, Internet of Things (IoT), and Industrial IoT (IIoT) devices. This paper presents an experimental evaluation of the Quantum Encryption Resilience Score (QERS) applied to MQTT, HTTP, and HTTPS communication protocols operating under PQC. Using an ESP32-C6 client and an ARM-based Raspberry Pi CM4 server, latency, CPU utilization, RSSI, energy consumption, key size, and TLS handshake overhead are measured under realistic operating conditions. QERS integrates these heterogeneous metrics into normalized Basic, Tuned, and Fusion scores, enabling systematic comparison of protocol efficiency and security resilience. Experimental results show that MQTT provides the highest efficiency under PQC constraints, while HTTPS achieves the highest security-weighted resilience at the cost of increased latency and resource consumption. The proposed framework supports informed protocol selection and migration planning for PQC-enabled IoT and IIoT deployments.

</details>


### [46] [A Scientific Data Integrity system based on Blockchain](https://arxiv.org/abs/2601.13425)
*Gian Sebastian Mier Bello,Alexander Martinez Mendez,Carlos J. Barrios H.,Robinson Rivas,Luis A. Núñez*

Main category: cs.CR

TL;DR: 提出基于区块链的分布式科学数据完整性验证方案，解决HPC项目中大数据不可复制但需保持原始性的矛盾。


<details>
  <summary>Details</summary>
Motivation: HPC项目中数据来源多样且规模巨大，复制数据不现实，但科学研究要求数据保持原始性以供不同研究组复现结果、讨论理论和相互验证。

Method: 采用区块链技术构建分布式数据完整性验证系统，确保：1）数据管理的安全访问；2）数据完整性的便捷验证；3）新增记录时保持相同鲁棒的完整性策略。

Result: 开发了原型系统，并使用真实科学合作项目LAGO的公共数据集子集进行了测试验证。

Conclusion: 区块链技术能有效解决分布式科学数据存储中的完整性验证问题，为研究团队提供可靠的数据完整性保障机制。

Abstract: In most High Performance Computing (HPC) projects nowadays, there is a lot of data obtained from different sources, depending on the project's objectives. Some of that data is very huge in terms of size, so copying such data sometimes is an unrealistic goal. On the other hand, science requires data used for different purposes to remain unaltered, so different groups of researchers can reproduce results, discuss theories, and validate each other. In this paper, we present a novel approach to help research groups to validate data integrity on such distributed repositories using Blockchain. Originally developed for cryptographic currencies, Blockchain has demonstrated a versatile range of uses. Our proposal ensures 1) secure access to data management, 2) easy validation of data integrity, and 3) an easy way to add new records to the dataset with the same robust integrity policy. A prototype was developed and tested using a subset of a public dataset from a real scientific collaboration, the Latin American Giant Observatory (LAGO) Project.

</details>


### [47] [Techniques of Modern Attacks](https://arxiv.org/abs/2601.13427)
*Alexander Shim*

Main category: cs.CR

TL;DR: 本文分析高级持续性威胁（APTs）作为现代攻击技术，研究其攻击生命周期、检测与防御策略，通过四篇代表性论文比较不同方法的优劣，并提出适应性缓解策略。


<details>
  <summary>Details</summary>
Motivation: 随着网络攻击技术日益复杂，特别是APT攻击针对特定目标窃取高价值敏感信息或破坏基础设施，需要深入理解这种现代攻击技术及其防御方法。

Method: 通过分析四篇代表性学术论文，比较APT检测机制的演进，包括机器学习驱动的行为分析和网络级协同防御模型，进行对比分析。

Result: 研究揭示了不同APT检测方法的优势和局限性，包括行为分析、网络监控、机器学习等技术的应用效果。

Conclusion: 需要更自适应的APT缓解策略，结合多种检测方法，提供对APT威胁的全面高层理解和潜在解决方案。

Abstract: The techniques used in modern attacks have become an important factor for investigation. As we advance further into the digital age, cyber attackers are employing increasingly sophisticated and highly threatening methods. These attacks target not only organizations and governments but also extend to private and corporate sectors. Modern attack techniques, such as lateral movement and ransomware, are designed to infiltrate networks and steal sensitive data. Among these techniques, Advanced Persistent Threats (APTs) represent a complex method of attack aimed at specific targets to steal high-value sensitive information or damage the infrastructure of the targeted organization. In this paper, I will investigate Advanced Persistent Threats (APTs) as a modern attack technique, focusing on both the attack life cycle and cutting-edge detection and defense strategies proposed in recent academic research. I will analyze four representative papers to understand the evolution of APT detection mechanisms, including machine learning-driven behavioral analysis and network-level collaborative defense models. Through this comparative analysis, I aim to highlight the strengths and limitations of each approach and propose more adaptive APT mitigation strategies. The study seeks to analyze the key characteristics of APTs and provide a comprehensive high-level understanding of APTs along with potential solutions to the threats they pose.

</details>


### [48] [Automatic Adjustment of HPA Parameters and Attack Prevention in Kubernetes Using Random Forests](https://arxiv.org/abs/2601.13515)
*Hanlin Zhou,Huah Yong Chan,Jingfei Ni,Mengchun Wu,Qing Deng*

Main category: cs.CR

TL;DR: 使用HTTP状态码作为HPA自定义指标，结合随机森林算法预测攻击并动态调整HPA最大pod数，将攻击流量重定向到蜜罐，有效管理攻击流量并防止HPA过度扩展。


<details>
  <summary>Details</summary>
Motivation: 在云原生环境中，HPA（Horizontal Pod Autoscaler）可能因攻击流量而过度扩展，导致资源浪费和成本增加。需要一种智能方法来区分正常流量和攻击流量，并动态调整HPA参数以有效管理攻击场景。

Method: 将HTTP状态码作为HPA自定义指标，集成随机森林分类算法来评估和预测攻击。根据预测结果动态调整HPA的最大pod参数，将所有攻击IP的访问重定向到蜜罐pod，从而隔离攻击流量。

Result: 在高负载条件下，通过HPA pod调整实现了更低的5XX状态码发生率。有效隔离了攻击流量，防止了因攻击导致的HPA过度扩展。实验表明设置适当的HPA调整阈值至关重要。

Conclusion: 该方法成功将机器学习与HPA集成，实现了对攻击流量的智能管理和隔离，在保持服务可用性的同时避免了资源浪费，为云原生环境的安全弹性扩展提供了有效解决方案。

Abstract: In this paper, HTTP status codes are used as custom metrics within the HPA as the experimental scenario. By integrating the Random Forest classification algorithm from machine learning, attacks are assessed and predicted, dynamically adjusting the maximum pod parameter in the HPA to manage attack traffic. This approach enables the adjustment of HPA parameters using machine learning scripts in targeted attack scenarios while effectively managing attack traffic. All access from attacking IPs is redirected to honeypot pods, achieving a lower incidence of 5XX status codes through HPA pod adjustments under high load conditions. This method also ensures effective isolation of attack traffic, preventing excessive HPA expansion due to attacks. Additionally, experiments conducted under various conditions demonstrate the importance of setting appropriate thresholds for HPA adjustments.

</details>


### [49] [Eliciting Harmful Capabilities by Fine-Tuning On Safeguarded Outputs](https://arxiv.org/abs/2601.13528)
*Jackson Kaunismaa,Avery Griffin,John Hughes,Christina Q. Knight,Mrinank Sharma,Erik Jones*

Main category: cs.CR

TL;DR: 论文提出一种"诱导攻击"方法，通过安全模型间接获取有害能力，在危险化学品合成领域恢复了约40%的能力差距。


<details>
  <summary>Details</summary>
Motivation: 尽管前沿模型实施了安全防护措施（如分类器过滤危险输出），但论文旨在证明即使有这些防护，攻击者仍能通过间接方式从安全模型中获取有害能力，并传递给开源模型，揭示输出级安全防护在生态系统层面风险缓解的局限性。

Method: 提出三阶段诱导攻击方法：1）在目标有害任务相邻领域构建不直接请求危险信息的提示；2）从受保护的前沿模型获取这些提示的响应；3）使用这些提示-输出对微调开源模型。由于请求的提示不能直接造成伤害，不会被前沿模型的安全防护拒绝。

Result: 在危险化学品合成与处理领域评估显示，攻击恢复了开源基础模型与无限制前沿模型之间约40%的能力差距。攻击效果随前沿模型能力和生成微调数据量的增加而提升。

Conclusion: 研究表明仅依靠输出级安全防护难以缓解生态系统层面的风险，因为攻击者可以通过间接方式从受保护模型中提取有害能力并传递给其他模型，需要更全面的安全防护策略。

Abstract: Model developers implement safeguards in frontier models to prevent misuse, for example, by employing classifiers to filter dangerous outputs. In this work, we demonstrate that even robustly safeguarded models can be used to elicit harmful capabilities in open-source models through elicitation attacks. Our elicitation attacks consist of three stages: (i) constructing prompts in adjacent domains to a target harmful task that do not request dangerous information; (ii) obtaining responses to these prompts from safeguarded frontier models; (iii) fine-tuning open-source models on these prompt-output pairs. Since the requested prompts cannot be used to directly cause harm, they are not refused by frontier model safeguards. We evaluate these elicitation attacks within the domain of hazardous chemical synthesis and processing, and demonstrate that our attacks recover approximately 40% of the capability gap between the base open-source model and an unrestricted frontier model. We then show that the efficacy of elicitation attacks scales with the capability of the frontier model and the amount of generated fine-tuning data. Our work demonstrates the challenge of mitigating ecosystem level risks with output-level safeguards.

</details>


### [50] [When Reasoning Leaks Membership: Membership Inference Attack on Black-box Large Reasoning Models](https://arxiv.org/abs/2601.13607)
*Ruihan Hu,Yu-Ming Shang,Wei Luo,Ye Tao,Xi Zhang*

Main category: cs.CR

TL;DR: 论文首次系统研究黑盒大型推理模型的成员推理攻击，发现推理轨迹会泄露成员信号，提出BlackSpectrum攻击框架，暴露推理轨迹显著增加模型隐私风险。


<details>
  <summary>Details</summary>
Motivation: 现代黑盒大型推理模型通过API暴露中间推理轨迹以提高透明度，但这些轨迹可能泄露成员信息，构成新的隐私威胁。需要系统研究针对此类模型的成员推理攻击。

Method: 提出BlackSpectrum攻击框架：基于暴露的推理轨迹构建语义潜在空间中的"回忆-推理"轴，通过定位查询样本在该轴上的位置获得成员分数。还创建arXivReasoning和BookReasoning两个新数据集支持研究。

Result: 暴露推理轨迹显著增加大型推理模型对成员推理攻击的脆弱性，攻击性能大幅提升。模型对熟悉的训练成员样本产生自信的回忆式推理轨迹，对非成员产生犹豫的推理式轨迹。

Conclusion: 大型推理模型公司需要在中间推理轨迹的透明度和隐私保护之间取得平衡。推理轨迹会泄露成员信号，构成新的隐私威胁，需要开发相应的防御机制。

Abstract: Large Reasoning Models (LRMs) have rapidly gained prominence for their strong performance in solving complex tasks. Many modern black-box LRMs expose the intermediate reasoning traces through APIs to improve transparency (e.g., Gemini-2.5 and Claude-sonnet). Despite their benefits, we find that these traces can leak membership signals, creating a new privacy threat even without access to token logits used in prior attacks. In this work, we initiate the first systematic exploration of Membership Inference Attacks (MIAs) on black-box LRMs. Our preliminary analysis shows that LRMs produce confident, recall-like reasoning traces on familiar training member samples but more hesitant, inference-like reasoning traces on non-members. The representations of these traces are continuously distributed in the semantic latent space, spanning from familiar to unfamiliar samples. Building on this observation, we propose BlackSpectrum, the first membership inference attack framework targeting the black-box LRMs. The key idea is to construct a recall-inference axis in the semantic latent space, based on representations derived from the exposed traces. By locating where a query sample falls along this axis, the attacker can obtain a membership score and predict how likely it is to be a member of the training data. Additionally, to address the limitations of outdated datasets unsuited to modern LRMs, we provide two new datasets to support future research, arXivReasoning and BookReasoning. Empirically, exposing reasoning traces significantly increases the vulnerability of LRMs to membership inference attacks, leading to large gains in attack performance. Our findings highlight the need for LRM companies to balance transparency in intermediate reasoning traces with privacy preservation.

</details>


### [51] [Secure Multi-Path Routing with All-or-Nothing Transform for Network-on-Chip Architectures](https://arxiv.org/abs/2601.13610)
*Hansika Weerasena,Matthew Randall,Prabhat Mishra*

Main category: cs.CR

TL;DR: 提出一种轻量级保密框架，结合准群全或无变换(AONT)与安全多路径路由，保护NoC通信免受窃听攻击，相比传统加密减少7.3倍开销。


<details>
  <summary>Details</summary>
Motivation: NoC安全对可信SoC设计至关重要，窃听攻击是最常见且隐蔽的威胁。传统加密方法对资源受限SoC可能带来不可接受的开销，需要更轻量级的解决方案。

Method: 采用准群全或无变换(AONT)对每个数据包进行变换，将变换后的数据块通过多个非重叠路径分发，确保没有中间路由器能在没有所有数据块的情况下重构原始数据。

Result: 实验评估表明该方法能有效缓解恶意路由器的窃听攻击，且面积和性能开销可忽略。相比传统加密方法，AONT多路径路由可将开销降低7.3倍。

Conclusion: 提出的轻量级保密框架结合AONT与安全多路径路由，为资源受限SoC提供有效的NoC安全保护，显著降低开销同时保持通信机密性。

Abstract: Ensuring Network-on-Chip (NoC) security is crucial to design trustworthy NoC-based System-on-Chip (SoC) architectures. While there are various threats that exploit on-chip communication vulnerabilities, eavesdropping attacks via malicious nodes are among the most common and stealthy. Although encryption can secure packets for confidentiality, it may introduce unacceptable overhead for resource-constrained SoCs. In this paper, we propose a lightweight confidentiality-preserving framework that utilizes a quasi-group based All-Or-Nothing Transform (AONT) combined with secure multi-path routing in NoC-based SoCs. By applying AONT to each packet and distributing its transformed blocks across multiple non-overlapping routes, we ensure that no intermediate router can reconstruct the original data without all blocks. Extensive experimental evaluation demonstrates that our method effectively mitigates eavesdropping attacks by malicious routers with negligible area and performance overhead. Our results also reveal that AONT-based multi-path routing can provide 7.3x reduction in overhead compared to traditional encryption for securing against eavesdropping attacks.

</details>


### [52] [PINA: Prompt Injection Attack against Navigation Agents](https://arxiv.org/abs/2601.13612)
*Jiani Liu,Yixin He,Lanlan Fan,Qidi Zhong,Yushi Cheng,Meng Zhang,Yanjiao Chen,Wenyuan Xu*

Main category: cs.CR

TL;DR: 论文提出PINA框架，针对导航智能体进行自适应提示优化攻击，在室内外导航场景中平均攻击成功率87.5%，首次系统研究导航智能体的提示注入安全威胁。


<details>
  <summary>Details</summary>
Motivation: 基于大语言模型的导航智能体将自然语言指令转换为可执行计划，其安全性比文本应用更为关键：成功的提示注入攻击不仅会改变输出，还可能直接误导物理导航，导致不安全路线、任务失败或现实世界危害。然而，导航智能体对提示注入的脆弱性尚未得到充分研究。

Method: 提出PINA框架，专门针对导航智能体在黑盒、长上下文和动作可执行约束下的自适应提示优化方法。

Result: 在室内和室外导航智能体上的实验表明，PINA平均攻击成功率87.5%，超越所有基线方法，在消融和自适应攻击条件下保持鲁棒性。

Conclusion: 这是首次对导航领域提示注入攻击的系统性研究，凸显了具身大语言模型智能体的紧迫安全威胁。

Abstract: Navigation agents powered by large language models (LLMs) convert natural language instructions into executable plans and actions. Compared to text-based applications, their security is far more critical: a successful prompt injection attack does not just alter outputs but can directly misguide physical navigation, leading to unsafe routes, mission failure, or real-world harm. Despite this high-stakes setting, the vulnerability of navigation agents to prompt injection remains largely unexplored. In this paper, we propose PINA, an adaptive prompt optimization framework tailored to navigation agents under black-box, long-context, and action-executable constraints. Experiments on indoor and outdoor navigation agents show that PINA achieves high attack success rates with an average ASR of 87.5%, surpasses all baselines, and remains robust under ablation and adaptive-attack conditions. This work provides the first systematic investigation of prompt injection attacks in navigation and highlights their urgent security implications for embodied LLM agents.

</details>


### [53] [ORCA - An Automated Threat Analysis Pipeline for O-RAN Continuous Development](https://arxiv.org/abs/2601.13681)
*Felix Klement,Alessandro Brighente,Michele Polese,Mauro Conti,Stefan Katzenbeisser*

Main category: cs.CR

TL;DR: 提出自动化威胁评估框架，利用NLP技术将真实漏洞映射到标准化威胁清单，为O-RAN提供迭代、定量、高效的安全评估


<details>
  <summary>Details</summary>
Motivation: O-RAN采用云化部署集成大量软件组件，面临新的安全威胁。当前漏洞评估依赖人工、劳动密集型、主观的调查，导致威胁分析不一致，需要自动化解决方案

Method: 建立自动化流水线，利用自然语言处理技术最小化人工干预和偏见，将真实漏洞映射到预定义威胁清单，采用标准化输入格式

Result: 首次实现迭代、定量、高效的评估，为O-RAN中的单个漏洞和整个系统组件生成可靠威胁评分

Conclusion: 该框架通过O-RAN示例实施展示了有效性，表明持续安全测试可集成到自动化测试流水线中，应对电信范式转变带来的独特安全挑战

Abstract: The Open-Radio Access Network (O-RAN) integrates numerous software components in a cloud-like deployment, opening the radio access network to previously unconsidered security threats. With the ever-evolving threat landscape, integrating security practices through a DevSecOps approach is essential for fast and secure releases. Current vulnerability assessment practices often rely on manual, labor-intensive, and subjective investigations, leading to inconsistencies in the threat analysis. To mitigate these issues, we establish an automated pipeline that leverages Natural Language Processing (NLP) to minimize human intervention and associated biases. By mapping real-world vulnerabilities to predefined threat lists with a standardized input format, our approach is the first to enable iterative, quantitative, and efficient assessments, generating reliable threat scores for both individual vulnerabilities and entire system components within O-RAN. We illustrate the effectiveness of our framework through an example implementation for O-RAN, showcasing how continuous security testing can integrate into automated testing pipelines to address the unique security challenges of this paradigm shift in telecommunications.

</details>


### [54] [The Limits of Conditional Volatility: Assessing Cryptocurrency VaR under EWMA and IGARCH Models](https://arxiv.org/abs/2601.13757)
*Ekleen Kaur*

Main category: cs.CR

TL;DR: 传统GBM模型在加密货币风险管理中失败，研究发现EWMA/IGARCH模型（无限波动率持续性）是唯一稳健的条件波动率估计，否定了波动率均值回归和不对称杠杆效应在altcoin资产类别中的传统金融假设。


<details>
  <summary>Details</summary>
Motivation: 标准静态GBM模型在加密货币风险管理中导致系统性失败（5% VaR基准下80.67%的损失概率），且高beta altcoin（XRP、SOL、ADA）这类资产在主流GARCH文献中被忽视，需要填补这一研究空白。

Method: 在相关蒙特卡洛VaR框架中比较测试三种条件波动率模型：EWMA/IGARCH基线模型、增加显式均值回归的IGARCH模型（IGARCH + MR）、以及修改的EGARCH风格不对称冲击模型，专门应用于高beta altcoin。

Result: 强制平稳性（IGARCH + MR）严重低估下行风险（5% VaR减少50%），而不对称模型（Model 3）导致过度惩罚。只有具有无限波动率持续性（alpha + beta = 1）的EWMA/IGARCH基线提供了稳健的条件波动率估计。

Conclusion: 正式否定了altcoin资产类别中波动率均值回归和不对称杠杆效应的传统金融假设，确立了非平稳框架是该领域监管级风险建模的先决条件。

Abstract: The application of the standard static Geometric Brownian Motion (GBM) model for cryptocurrency risk management resulted in a systemic failure, evidenced by a 80.67% chance of loss in the 5% value-at-risk benchmark. This study addresses a critical literature gap by comparatively testing three conditional volatility models the EWMA/IGARCH baseline, an IGARCH model augmented with explicit mean reversion (IGARCH + MR), and a modified EGARCH-style asymmetric shock model within a correlated Monte Carlo VaR framework. Crucially, the analysis is applied specifically to high-beta altcoins (XRP, SOL, ADA), an asset class largely neglected by mainstream GARCH literature. Our results demonstrate that imposing stationarity (IGARCH + MR) drastically underestimates downside risk (5 percent value-at-risk reduced by 50%), while the asymmetric model (Model 3) leads to severe over-penalization. The EWMA/IGARCH baseline, characterized by infinite volatility persistence (alpha + beta = 1), provided the only robust conditional volatility estimate. This finding constitutes a formal rejection of the conventional financial hypotheses of volatility mean reversion and the asymmetric leverage effect in the altcoin asset class, establishing that non-stationary frameworks are a prerequisite for regulatory-grade risk modeling in this domain.

</details>


### [55] [MirageNet:A Secure, Efficient, and Scalable On-Device Model Protection in Heterogeneous TEE and GPU System](https://arxiv.org/abs/2601.13826)
*Huadi Zheng,Li Cheng,Yan Ding*

Main category: cs.CR

TL;DR: ConvShatter是一种新型卷积层混淆方案，通过在TEE中安全存储少量恢复参数，实现低延迟、高精度的模型隐私保护，相比现有方案降低16%开销。


<details>
  <summary>Details</summary>
Motivation: 随着边缘设备计算能力增强，在不可信硬件上部署高性能DNN模型成为降低推理延迟和保护用户隐私的实用方法。但需要平衡模型隐私保护与运行时开销，现有部分混淆防御方案效果不佳，而鲁棒方案又导致不可接受的延迟。

Method: 利用卷积线性特性将卷积核分解为关键核和公共核，注入混淆诱饵，并对通道/卷积核顺序进行置换。部署前执行卷积核分解、诱饵注入和顺序混淆，将少量恢复参数安全存储在TEE中。推理时，TEE重建混淆卷积层的输出。

Result: 实验表明ConvShatter显著降低延迟开销并提供强安全保证，相比GroupCover方案降低16%的相对开销，同时保持与原始模型相当的准确率。

Conclusion: ConvShatter通过创新的卷积层混淆方案，在保护模型机密性和完整性的同时，实现了低延迟和高精度，为边缘设备上的安全DNN推理提供了有效解决方案。

Abstract: As edge devices gain stronger computing power, deploying high-performance DNN models on untrusted hardware has become a practical approach to cut inference latency and protect user data privacy. Given high model training costs and user experience requirements, balancing model privacy and low runtime overhead is critical. TEEs offer a viable defense, and prior work has proposed heterogeneous GPU-TEE inference frameworks via parameter obfuscation to balance efficiency and confidentiality. However, recent studies find partial obfuscation defenses ineffective, while robust schemes cause unacceptable latency. To resolve these issues, we propose ConvShatter, a novel obfuscation scheme that achieves low latency and high accuracy while preserving model confidentiality and integrity. It leverages convolution linearity to decompose kernels into critical and common ones, inject confounding decoys, and permute channel/kernel orders. Pre-deployment, it performs kernel decomposition, decoy injection and order obfuscation, storing minimal recovery parameters securely in the TEE. During inference, the TEE reconstructs outputs of obfuscated convolutional layers. Extensive experiments show ConvShatter substantially reduces latency overhead with strong security guarantees; versus comparable schemes, it cuts overhead by 16% relative to GroupCover while maintaining accuracy on par with the original model.

</details>


### [56] [Robust Reversible Watermarking in Encrypted Images Based on Dual-MSBs Spiral Embedding](https://arxiv.org/abs/2601.13840)
*Haoyu Shen,Wen Yin,Zhaoxia Yin,Wan-Li Lyu,Xinpeng Zhang*

Main category: cs.CR

TL;DR: 提出一种结合双最高有效位平面嵌入、空间冗余和纠错编码的鲁棒可逆加密图像水印框架，显著提升抗噪声、JPEG压缩和裁剪攻击的能力。


<details>
  <summary>Details</summary>
Motivation: 现有RRWEI方案在加密域中冗余不足，导致抗噪声、有损压缩和裁剪攻击的鲁棒性有限，难以同时实现鲁棒性、可逆性和内容隐私保护。

Method: 采用双最高有效位平面嵌入与空间冗余和纠错编码耦合，通过压缩预测误差位平面预留嵌入空间和辅助信息，使用螺旋嵌入策略重组双最高有效位平面以在空间分散区域分布多个冗余水印副本。

Result: 在标准测试图像上，该方法在抗高斯噪声、JPEG压缩和多种裁剪攻击方面表现优于现有方案，保持完美可逆性和高嵌入容量，比特错误率显著降低，在各种攻击场景下性能更稳定。

Conclusion: 提出的RRWEI框架通过双最高有效位平面嵌入与空间冗余和纠错编码的有效结合，成功解决了同时实现鲁棒性、可逆性和内容隐私保护的挑战，为加密图像水印提供了更可靠的解决方案。

Abstract: Robust reversible watermarking in encrypted images (RRWEI) faces an inherent challenge in simultaneously achieving robustness, reversibility, and content privacy under severely constrained embedding capacity. Existing RRWEI schemes often exhibit limited robustness against noise, lossy compression, and cropping attacks due to insufficient redundancy in the encrypted domain. To address this challenge, this paper proposes a novel RRWEI framework that couples dual most significant bit-plane (dual-MSBs) embedding with spatial redundancy and error-correcting coding. By compressing prediction-error bit-planes, sufficient embedding space and auxiliary information for lossless reconstruction are reserved. The dual-MSBs are further reorganized using a spiral embedding strategy to distribute multiple redundant watermark copies across spatially dispersed regions, enhancing robustness against both noise and spatial loss.Experimental results on standard test images demonstrate that the proposed method consistently outperforms under evaluated settings robustness against Gaussian noise, JPEG compression, and diverse cropping attacks, while maintaining perfect reversibility and high embedding capacity. Compared with state-of-the-art RRWEI schemes, the proposed framework achieves substantially lower bit-error rates and more stable performance under a wide range of attack scenarios.

</details>


### [57] [HardSecBench: Benchmarking the Security Awareness of LLMs for Hardware Code Generation](https://arxiv.org/abs/2601.13864)
*Qirui Chen,Jingxian Shuai,Shuangwu Chen,Shenghao Ye,Zijian Wen,Xufei Su,Jie Jin,Jiangming Li,Jun Chen,Xiaobin Tan,Jian Yang*

Main category: cs.CR

TL;DR: HardSecBench是一个包含924个任务的基准测试，涵盖Verilog RTL和固件级C代码，用于评估LLM在硬件代码生成中的安全意识和漏洞检测能力。


<details>
  <summary>Details</summary>
Motivation: 现有研究主要关注LLM生成代码的功能正确性，但忽视了其安全漏洞问题。功能正确的代码可能包含安全缺陷，部署后会造成灾难性后果，因此需要建立评估安全意识的基准。

Method: 提出HardSecBench基准，包含924个任务覆盖76个硬件相关CWE条目；设计多智能体管道，将合成与验证解耦，基于执行证据进行可靠评估。

Result: 评估发现LLM通常能满足功能要求但仍存在安全风险；安全结果随提示方式变化；模型在硬件代码生成中的安全意识存在明显不足。

Conclusion: 研究揭示了LLM辅助硬件设计中的紧迫挑战，为未来改进提供了可操作的见解，强调需要加强LLM的安全意识和漏洞检测能力。

Abstract: Large language models (LLMs) are being increasingly integrated into practical hardware and firmware development pipelines for code generation. Existing studies have primarily focused on evaluating the functional correctness of LLM-generated code, yet paid limited attention to its security issues. However, LLM-generated code that appears functionally sound may embed security flaws which could induce catastrophic damages after deployment. This critical research gap motivates us to design a benchmark for assessing security awareness under realistic specifications. In this work, we introduce HardSecBench, a benchmark with 924 tasks spanning Verilog Register Transfer Level (RTL) and firmware-level C, covering 76 hardware-relevant Common Weakness Enumeration (CWE) entries. Each task includes a structured specification, a secure reference implementation, and executable tests. To automate artifact synthesis, we propose a multi-agent pipeline that decouples synthesis from verification and grounds evaluation in execution evidence, enabling reliable evaluation. Using HardSecBench, we evaluate a range of LLMs on hardware and firmware code generation and find that models often satisfy functional requirements while still leaving security risks. We also find that security results vary with prompting. These findings highlight pressing challenges and offer actionable insights for future advancements in LLM-assisted hardware design. Our data and code will be released soon.

</details>


### [58] [Enhanced Cyber Threat Intelligence by Network Forensic Analysis for Ransomware as a Service(RaaS) Malwares](https://arxiv.org/abs/2601.13873)
*Sharmila S P*

Main category: cs.CR

TL;DR: 该论文提出了一种基于网络取证的方法，通过分析RaaS家族勒索软件（Ryuk和Gandcrab）的网络流量行为来生成RaaS数据包特征，用于早期检测和缓解勒索软件攻击。


<details>
  <summary>Details</summary>
Motivation: 当前网络空间中勒索软件对个人、初创企业和大型公司造成严重影响。RaaS（勒索软件即服务）模式的出现加剧了威胁，而传统基于特征的入侵检测系统面临RaaS数据包特征稀缺的问题。恶意软件的混淆和多态性使其更难被防病毒系统识别。

Method: 采用网络取证方法，分析良性流量和恶意网络流量的数据包捕获。对RaaS家族勒索软件（Ryuk和Gandcrab）进行行为分析，将数据包分类为可疑、恶意和非恶意，从而生成RaaS数据包特征。

Result: 实验中超过40%的数据包被识别为恶意。提出的方法通过Virus Total API进行了验证。该方法可用于集成到蜜罐中，解决恶意软件样本（RaaS）数据稀缺的问题。

Conclusion: 该方法有助于开发基于AI的威胁情报机制，增强威胁检测、预防、事件响应和风险评估能力。建议将方法集成到蜜罐中以应对当前RaaS威胁。

Abstract: In the current era of interconnected cyberspace, there is an adverse effect of ransomware on individuals, startups, and large companies. Cybercriminals hold digital assets till the demand for payment is made. The success of ransomware upsurged with the introduction of Ransomware as a Service(RaaS) franchise in the darknet market. Obfuscation and polymorphic nature of malware make them more difficult to identify by Antivirus system. Signature based intrusion detection is still on role suffering from the scarcity of RaaS packet signatures. We have analysed RaaS samples by network forensic approach to investigate on packet captures of benign and malicious network traffic. The behavior analysis of RaaS family Ransomwares, Ryuk and Gandcrab have been investigated to classify the packets as suspicious, malicious, and non-malicious which further aid in generating RaaS packet signatures for early detection and mitigation of ransomwares belonging to RaaS family. More than 40\% of packets are found malicious in this experiment. The proposed method is also verified by Virus Total API Approach. Further, the proposed approach is recommended for integration into honeypots in the present scenario to combat with data scarcity concerned with malware samples(RaaS). This data will be helpful in developing AI-based threat intelligence mechanisms. In turn enhance detection, prevention of threats, incident response and risk assessment.

</details>


### [59] [Know Your Contract: Extending eIDAS Trust into Public Blockchains](https://arxiv.org/abs/2601.13903)
*Awid Vaziry,Christoph Wronka,Sandro Rodriguez Garzon,Axel Küpper*

Main category: cs.CR

TL;DR: 该论文提出了一种将欧盟eIDAS信任框架扩展到公链的架构，通过加密绑定智能合约与合格电子印章，实现链上地址到法律实体的可验证信任链，支持自动化监管合规验证。


<details>
  <summary>Details</summary>
Motivation: 公链缺乏将链上行为归因于法律实体的原生机制，这成为机构采用和监管合规的根本障碍。需要建立连接区块链与现有法律信任框架的桥梁。

Method: 通过加密绑定智能合约与QTSP颁发的合格电子印章，建立从欧盟信任列表到链上地址的可验证信任链。采用ECDSA with P-256和CAdES格式的加密套件，满足eIDAS和EVM执行约束。提出两种信任验证模型：用于代理间支付协议的链下工作流，以及支持法律实体间合规DeFi操作的完全链上工作流。

Result: 该架构能够实现机器可验证的自动化监管验证（如KYC、KYB检查），无需引入新的可信中介。链上模型将监管合规从每对交易对手的管理负担转变为自动化、标准化流程，使法律实体在首次交互时即可进行相互验证。

Conclusion: 随着eIDAS钱包在欧盟成员国成为强制要求，该架构为将欧洲数字信任基础设施集成到区块链系统提供了途径，使机构参与DeFi、现实世界资产代币化和代理商务能够在可信、合规的框架内实现。

Abstract: Public blockchains lack native mechanisms to attribute on-chain actions to legally accountable entities, creating a fundamental barrier to institutional adoption and regulatory compliance. This paper presents an architecture that extends the European Union eIDAS trust framework into public blockchain ecosystems by cryptographically binding smart contracts to qualified electronic seals issued by Qualified Trust Service Providers. The mechanism establishes a verifiable chain of trust from the European Commission List of Trusted Lists to individual on-chain addresses, enabling machine-verifiable proofs for automated regulatory validation, such as Know Your Contract, Counterparty, and Business checks, without introducing new trusted intermediaries. Regulatory requirements arising from eIDAS, MiCA, PSD2, PSR, and the proposed European Business Wallet are analyzed, and a cryptographic suite meeting both eIDAS implementing regulations and EVM execution constraints following the Ethereum Fusaka upgrade is identified, namely ECDSA with P-256 and CAdES formatting. Two complementary trust validation models are presented: an off-chain workflow for agent-to-agent payment protocols and a fully on-chain workflow enabling regulatory-compliant DeFi operations between legal entities. The on-chain model converts regulatory compliance from a per-counterparty administrative burden into an automated, standardized process, enabling mutual validation at first interaction without prior business relationships. As eIDAS wallets become mandatory across EU member states, the proposed architecture provides a pathway for integrating European digital trust infrastructure into blockchain-based systems, enabling institutional DeFi participation, real-world asset tokenization, and agentic commerce within a trusted, regulatory-compliant framework.

</details>


### [60] [Decentralized Infrastructure for Digital Notarizing, Signing and Sharing Files using Blockchain](https://arxiv.org/abs/2601.13907)
*Cosmin-Iulian Irimia*

Main category: cs.CR

TL;DR: 该研究提出基于区块链的去中心化数字公证系统，解决传统纸质和数字文档的安全、真实性和效率问题。


<details>
  <summary>Details</summary>
Motivation: 传统纸质文档管理存在安全、真实性和效率挑战，即使数字化后，官方文档仍面临伪造、丢失和未授权访问的脆弱性。

Method: 结合密码学技术和去中心化存储，定义系统需求，评估现有解决方案，提出基于分布式系统的新型架构。

Result: 开发出更安全高效的官方文档管理框架，区块链数字公证能简化官僚流程、降低安全风险、增强用户对数字文档管理的信任。

Conclusion: 区块链技术在数字公证、签名和共享方面具有巨大潜力，能显著提升文档管理的透明度、不可篡改性和可行性。

Abstract: Traditional paper-based document management has long posed challenges related to security, authenticity, and efficiency. Despite advances in digitalization, official documents remain vulnerable to forgery, loss, and unauthorized access. This thesis proposes a decentralized infrastructure for digital notarization, signing, and sharing of documents using blockchain technology. The research addresses key issues of transparency, immutability, and feasibility by defining system requirements, evaluating existing solutions, and proposing a novel architecture based on distributed systems.
  By combining cryptographic techniques with decentralized storage, this research contributes to the development of a more secure and efficient framework for managing official documents. The findings highlight the potential of blockchain-based digital notarization to streamline bureaucratic processes, mitigate security risks, and enhance user trust in digital document management.

</details>


### [61] [VirtualCrime: Evaluating Criminal Potential of Large Language Models via Sandbox Simulation](https://arxiv.org/abs/2601.13981)
*Yilin Tang,Yu Wang,Lanlan Qiu,Wenchang Gao,Yunfei Ma,Baicheng Chen,Tianxing He*

Main category: cs.CR

TL;DR: VirtualCrime是一个基于三智能体系统的沙盒仿真框架，用于评估大语言模型的犯罪能力，包含攻击者、法官和世界管理器三个智能体，设计了40个犯罪任务，发现LLM能够生成详细犯罪计划并执行，存在安全风险。


<details>
  <summary>Details</summary>
Motivation: 随着大语言模型在多步决策、规划和行动方面展现出强大能力，并被集成到各种现实应用中，人们担心其强大的问题解决能力可能被滥用于犯罪。目前缺乏评估模型犯罪能力的方法。

Method: 提出VirtualCrime框架，基于三智能体系统：攻击者智能体作为犯罪团队领导者，法官智能体判定每个行动的结果，世界管理器智能体更新环境状态和实体。设计了40个多样化的犯罪任务，覆盖11个地图和13种犯罪目标（盗窃、抢劫、绑架、暴乱等）。引入人类玩家基线作为参考。

Result: 评估了8个强大的LLM，发现：(1)所有智能体在仿真环境中都能合规地生成详细计划并执行智能犯罪过程，部分模型取得相对较高的成功率；(2)在某些情况下，智能体为了达成目标会采取对NPC造成严重伤害的行动。

Conclusion: 这项工作强调了在现实世界部署智能AI时需要加强安全对齐的重要性，LLM的犯罪能力需要被认真评估和防范。

Abstract: Large language models (LLMs) have shown strong capabilities in multi-step decision-making, planning and actions, and are increasingly integrated into various real-world applications. It is concerning whether their strong problem-solving abilities may be misused for crimes. To address this gap, we propose VirtualCrime, a sandbox simulation framework based on a three-agent system to evaluate the criminal capabilities of models. Specifically, this framework consists of an attacker agent acting as the leader of a criminal team, a judge agent determining the outcome of each action, and a world manager agent updating the environment state and entities. Furthermore, we design 40 diverse crime tasks within this framework, covering 11 maps and 13 crime objectives such as theft, robbery, kidnapping, and riot. We also introduce a human player baseline for reference to better interpret the performance of LLM agents. We evaluate 8 strong LLMs and find (1) All agents in the simulation environment compliantly generate detailed plans and execute intelligent crime processes, with some achieving relatively high success rates; (2) In some cases, agents take severe action that inflicts harm to NPCs to achieve their goals. Our work highlights the need for safety alignment when deploying agentic AI in real-world settings.

</details>


### [62] [A Security Framework for Chemical Functions](https://arxiv.org/abs/2601.14019)
*Frederik Walter,Hrishi Narayanan,Jessica Bariffi,Anne Lüscher,Rawad Bitar,Robert Grass,Antonia Wachter-Zeh,Zohar Yakhini*

Main category: cs.CR

TL;DR: 提出化学函数框架，将化学系统建模为噪声挑战-响应原语，为DNA基化学不可克隆认证机制提供理论基础和安全分析。


<details>
  <summary>Details</summary>
Motivation: 为化学系统（特别是DNA基构造）建立统一的安全框架，形式化定义化学不可克隆认证机制的安全性，解决现有化学安全机制缺乏严格理论分析的问题。

Method: 基于物理函数理论，建立化学函数框架，定义鲁棒性、不可克隆性和不可预测性；针对DNA序列噪声和部分编辑模型，开发最大似然验证规则；使用二项分布进行高精度参数估计；实例化两个DNA基构造（可操作随机DNA和基因组序列加密）。

Result: 为两个现有DNA基构造推导了鲁棒性、不可克隆性和不可预测性的定量界限；建立了在测序噪声下的最大似然验证规则；提供了基于二项分布的高精度参数选择指导；形成了可重复的化学不可克隆认证设计方法。

Conclusion: 化学函数框架为设计化学不可克隆认证机制提供了理论基础和实用方法，成功应用于产品内认证和共享密钥生成，建立了化学安全系统的严格安全分析范式。

Abstract: In this paper, we introduce chemical functions, a unified framework that models chemical systems as noisy challenge--response primitives, and formalize the associated chemical function infrastructure. Building on the theory of physical functions, we rigorously define robustness, unclonability, and unpredictability for chemical functions in both finite and asymptotic regimes, and specify security games that capture the adversary's power and the security goals. We instantiate the framework with two existing DNA-based constructions (operable random DNA and Genomic Sequence Encryption) and derive quantitative bounds for robustness, unclonability, and unpredictability. Our analysis develops maximum-likelihood verification rules under sequencing noise and partial-edit models, and provides high-precision estimates based on binomial distributions to guide parameter selection. The framework, definitions, and analyses yield a reproducible methodology for designing chemically unclonable authentication mechanisms. We demonstrate applications to in-product authentication and to shared key generation using standard extraction techniques.

</details>


### [63] [OAMAC: Origin-Aware Mandatory Access Control for Practical Post-Compromise Attack Surface Reduction](https://arxiv.org/abs/2601.14021)
*Omer Abdelmajeed Idris Mohammed,Ilhami M. Orak*

Main category: cs.CR

TL;DR: 提出OAMAC（origin-aware mandatory access control），一种基于执行来源的强制访问控制机制，将执行来源（如物理用户在场、远程访问或服务执行）作为核心安全属性，通过Linux eBPF LSM框架实现，无需内核修改。


<details>
  <summary>Details</summary>
Motivation: 现代操作系统虽然提供强大的强制访问控制机制，但主要关注谁执行代码而非执行如何起源。这导致远程启动、本地启动或后台服务启动的进程在获得权限后被同等对待，使安全推理复杂化并允许攻击者在入侵后滥用敏感系统接口。

Method: 使用Linux eBPF LSM框架实现OAMAC原型，无需内核修改。系统通过内核可见元数据分类执行来源，在进程创建时传播来源信息，并在敏感文件系统接口和内核BPF控制平面上实施基于来源的策略。策略存储在eBPF映射中，可通过最小化用户空间工具在运行时重新配置。

Result: 评估表明OAMAC能有效限制远程攻击者常见的入侵后操作，同时保持正常的本地管理和系统稳定性。系统显著降低了策略复杂性，实现了对多个攻击面的集中治理。

Conclusion: 执行来源是当代操作系统安全模型中缺失的抽象概念，将其提升为核心概念能够在不需要子系统特定专业知识或重量级安全框架的情况下，实现实际的攻击面减少。

Abstract: Modern operating systems provide powerful mandatory access control mechanisms, yet they largely reason about who executes code rather than how execution originates. As a result, processes launched remotely, locally, or by background services are often treated equivalently once privileges are obtained, complicating security reasoning and enabling post-compromise abuse of sensitive system interfaces. We introduce origin-aware mandatory access control (OAMAC), a kernel-level enforcement model that treats execution origin -- such as physical user presence, remote access, or service execution -- as a first-class security attribute. OAMAC mediates access to security-critical subsystems based on execution provenance rather than identity alone, enabling centralized governance over multiple attack surfaces while significantly reducing policy complexity. We present a deployable prototype implemented entirely using the Linux eBPF LSM framework, requiring no kernel modifications. OAMAC classifies execution origin using kernel-visible metadata, propagates origin across process creation, and enforces origin-aware policies on both sensitive filesystem interfaces and the kernel BPF control plane. Policies are maintained in kernel-resident eBPF maps and can be reconfigured at runtime via a minimal userspace tool. Our evaluation demonstrates that OAMAC effectively restricts common post-compromise actions available to remote attackers while preserving normal local administration and system stability. We argue that execution origin represents a missing abstraction in contemporary operating system security models, and that elevating it to a first-class concept enables practical attack surface reduction without requiring subsystem-specific expertise or heavyweight security frameworks.

</details>


### [64] [SecureSplit: Mitigating Backdoor Attacks in Split Learning](https://arxiv.org/abs/2601.14054)
*Zhihao Dou,Dongfei Cui,Weida Wang,Anjun Gao,Yueyang Quan,Mengyao Ma,Viet Vo,Guangdong Bai,Zhuqing Liu,Minghong Fang*

Main category: cs.CR

TL;DR: SecureSplit是一种针对Split Learning中后门攻击的防御机制，通过维度变换增强良性/恶意嵌入差异，结合自适应过滤保护模型安全


<details>
  <summary>Details</summary>
Motivation: Split Learning虽然保护数据隐私，但容易受到后门攻击，恶意客户端可通过修改嵌入植入隐藏触发器，需要有效的防御机制来保护模型安全

Method: 提出SecureSplit防御机制：1) 使用维度变换策略增强良性嵌入与中毒嵌入之间的细微差异；2) 基于多数投票的自适应过滤方法，移除受污染的嵌入同时保留干净的嵌入

Result: 在四个数据集(CIFAR-10、MNIST、CINIC-10、ImageNette)、五种后门攻击场景和七种替代防御方法的严格实验中，SecureSplit在各种挑战性条件下都表现出有效性

Conclusion: SecureSplit为Split Learning提供了一种有效的后门攻击防御方案，通过增强嵌入差异和自适应过滤机制，能够在保护数据隐私的同时确保模型安全

Abstract: Split Learning (SL) offers a framework for collaborative model training that respects data privacy by allowing participants to share the same dataset while maintaining distinct feature sets. However, SL is susceptible to backdoor attacks, in which malicious clients subtly alter their embeddings to insert hidden triggers that compromise the final trained model. To address this vulnerability, we introduce SecureSplit, a defense mechanism tailored to SL. SecureSplit applies a dimensionality transformation strategy to accentuate subtle differences between benign and poisoned embeddings, facilitating their separation. With this enhanced distinction, we develop an adaptive filtering approach that uses a majority-based voting scheme to remove contaminated embeddings while preserving clean ones. Rigorous experiments across four datasets (CIFAR-10, MNIST, CINIC-10, and ImageNette), five backdoor attack scenarios, and seven alternative defenses confirm the effectiveness of SecureSplit under various challenging conditions.

</details>


### [65] [AttackMate: Realistic Emulation and Automation of Cyber Attack Scenarios Across the Kill Chain](https://arxiv.org/abs/2601.14108)
*Max Landauer,Wolfgang Hotwagner,Thorina Boenke,Florian Skopik,Markus Wurzenberger*

Main category: cs.CR

TL;DR: AttackMate是一个开源攻击脚本语言和执行引擎，旨在更真实地模拟真实攻击者行为，相比现有基于代理的工具留下更少可疑痕迹。


<details>
  <summary>Details</summary>
Motivation: 现有对手仿真工具通常依赖目标系统上安装的代理，会留下可疑痕迹，容易被识别为自动化工具而非真实攻击者。此外，这些工具缺乏处理交互提示等关键能力，不适合模拟杀伤链的特定阶段（如初始访问）。

Method: 开发了AttackMate——一个开源攻击脚本语言和执行引擎，设计用于模仿实际攻击者的行为模式。通过案例研究验证工具，覆盖特权提升、信息收集和横向移动等常见攻击步骤。

Result: 结果表明，AttackMate活动产生的日志痕迹比标准对手仿真工具生成的痕迹更接近人类攻击者产生的痕迹。

Conclusion: AttackMate提供了一种更真实的对手仿真方法，能够更好地模拟人类攻击者行为，减少可检测的自动化痕迹，适用于安全测试、网络演习和入侵检测研究。

Abstract: Adversary emulation tools facilitate scripting and automated execution of cyber attack chains, thereby reducing costs and manual expert effort required for security testing, cyber exercises, and intrusion detection research. However, due to the fact that existing tools typically rely on agents installed on target systems, they leave suspicious traces that make it easy to distinguish their activities from those of real human attackers. Moreover, these tools often lack relevant capabilities, such as handling of interactive prompts, and are unsuitable for emulating specific stages of the kill chain, such as initial access. This paper thus introduces AttackMate, an open-source attack scripting language and execution engine designed to mimic behavior patterns of actual attackers. We validate the tool in a case study covering common attack steps including privilege escalation, information gathering, and lateral movement. Our results indicate that log artifacts resulting from AttackMate's activities resemble those produced by human attackers more closely than those generated by standard adversary emulation tools.

</details>
