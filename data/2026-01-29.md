<div id=toc></div>

# Table of Contents

- [cs.CR](#cs.CR) [Total: 17]


<div id='cs.CR'></div>

# cs.CR [[Back]](#toc)

### [1] [What is the AGI in Offensive Security ?](https://arxiv.org/abs/2601.19968)
*Youngwoong Cho*

Main category: cs.CR

TL;DR: 该论文提出将攻击性安全任务形式化为符号语言操作问题，并探讨大型语言模型能否处理此类任务


<details>
  <summary>Details</summary>
Motivation: 探讨通用人工智能在攻击性安全领域的应用可能性，研究是否所有攻击性安全任务都能简化为符号语言操作，以及大型语言模型是否足以处理这些符号操作

Method: 将目标系统形式化为状态机，将黑客建模为交互式符号代理，证明攻击性交互可以被编码为有限字符串，提供定义、引理和开放讨论

Result: 建立了攻击性安全的形式化模型，证明了所有攻击性交互都可以编码为有限字符串，为使用语言模型处理安全任务提供了理论基础

Conclusion: 攻击性安全任务可以形式化为符号语言操作问题，这为使用大型语言模型处理安全任务提供了理论框架，但仍需进一步研究验证实际可行性

Abstract: What is the AGI in Offensive Security? One can break it down into two questions : (1) any offensive security tasks could be reduced into symbolic language manipulation (language representation + reasoning), (2) powerful language model (LLM) are enough to "deal with" any symbolic language manipulation. This paper can formally model a target system as a state machine and a hacker as an interactive symbolic agent. And it shows that every interaction in an offensive engagement can be encoded as a finite string. This paper provides definitions, short lemmas, and open discussion.

</details>


### [2] [Benchmarking LLAMA Model Security Against OWASP Top 10 For LLM Applications](https://arxiv.org/abs/2601.19970)
*Nourin Shahin,Izzat Alsmadi*

Main category: cs.CR

TL;DR: 该研究评估了不同Llama模型在OWASP LLM安全威胁检测中的表现，发现小型专用安全模型（Llama-Guard-3-1B）比大型通用模型（Llama-3.1-8B）表现更好，检测率达76%且延迟更低。


<details>
  <summary>Details</summary>
Motivation: 随着大语言模型从研究原型转向企业系统，其安全漏洞对数据隐私和系统完整性构成严重风险，需要系统评估不同模型的安全性能。

Method: 使用FABRIC测试平台和NVIDIA A30 GPU，测试了5个标准Llama模型和5个Llama Guard变体，使用100个对抗性提示覆盖10个OWASP LLM漏洞类别，评估威胁检测准确率、响应安全性和计算开销。

Result: 紧凑型Llama-Guard-3-1B模型达到最高检测率76%，延迟仅0.165秒；而基础模型如Llama-3.1-8B检测率为0%，延迟0.754秒。发现模型大小与安全有效性呈反比关系。

Conclusion: 小型专用安全模型在安全任务上通常优于大型通用模型，研究提供了开源基准数据集支持AI安全可重复研究，强调需要专门的安全评估框架。

Abstract: As large language models (LLMs) move from research prototypes to enterprise systems, their security vulnerabilities pose serious risks to data privacy and system integrity. This study benchmarks various Llama model variants against the OWASP Top 10 for LLM Applications framework, evaluating threat detection accuracy, response safety, and computational overhead. Using the FABRIC testbed with NVIDIA A30 GPUs, we tested five standard Llama models and five Llama Guard variants on 100 adversarial prompts covering ten vulnerability categories. Our results reveal significant differences in security performance: the compact Llama-Guard-3-1B model achieved the highest detection rate of 76% with minimal latency (0.165s per test), whereas base models such as Llama-3.1-8B failed to detect threats (0% accuracy) despite longer inference times (0.754s). We observe an inverse relationship between model size and security effectiveness, suggesting that smaller, specialized models often outperform larger general-purpose ones in security tasks. Additionally, we provide an open-source benchmark dataset including adversarial prompts, threat labels, and attack metadata to support reproducible research in AI security, [1].

</details>


### [3] [Reference-Free Spectral Analysis of EM Side-Channels for Always-on Hardware Trojan Detection](https://arxiv.org/abs/2601.20163)
*Mahsa Tahghigh,Hassan Salmani*

Main category: cs.CR

TL;DR: 提出一种无需参考模型的硬件木马检测方法，结合时频电磁分析和高斯混合模型，通过多窗口STFT分析电路电磁特征，区分正常电路波动和硬件木马持久特征


<details>
  <summary>Details</summary>
Motivation: 常开硬件木马对可信微电子构成严重威胁，但现有侧信道检测方法大多依赖难以获得的黄金参考模型，需要开发无需参考的检测方案

Method: 采用参考自由的检测方法，结合时频电磁分析和高斯混合模型。通过应用多窗口大小的短时傅里叶变换分析电磁信号，利用GMM建模信号统计特征，通过混合成分数量区分正常电路和硬件木马

Result: 在AES-128上的实验结果表明该方法可行，无需参考模型。正常电路表现出波动的统计结构，而常开硬件木马留下持久特征，具有更少、更一致的混合成分

Conclusion: 提出的参考自由方法能够有效检测常开硬件木马，通过时频电磁分析和GMM建模，为硬件安全提供了一种实用的检测方案

Abstract: Always-on hardware Trojans (HTs) pose a critical risk to trusted microelectronics, yet most side-channel detection methods rely on unavailable golden references. We present a reference-free approach that combines time-frequency EM analysis with Gaussian Mixture Models (GMMs). By applying Short-Time Fourier Transform (STFT) at multiple window sizes, we show that HT-free circuits exhibit fluctuating statistical structure, while always-on HTs leave persistent footprints with fewer, more consistent mixture components. Results on AES-128 demonstrate feasibility without requiring reference models.

</details>


### [4] [Securing AI Agents in Cyber-Physical Systems: A Survey of Environmental Interactions, Deepfake Threats, and Defenses](https://arxiv.org/abs/2601.20184)
*Mohsen Hatami,Van Tuan Pham,Hozefa Lakadawala,Yu Chen*

Main category: cs.CR

TL;DR: 该论文综述了AI代理在信息物理系统中的安全威胁，重点关注环境交互、深度伪造攻击和MCP协议漏洞，提出了SENTINEL框架并基于智能电网案例进行定量分析。


<details>
  <summary>Details</summary>
Motivation: 随着AI代理在信息物理系统中的集成增加，出现了超越传统网络或物理威胁模型的新型安全风险，特别是生成式AI带来的深度伪造和语义操纵攻击，以及MCP协议扩展的攻击面，需要系统性的安全分析框架。

Method: 采用SENTINEL框架（生命周期感知方法），整合威胁特征化、CPS约束下的可行性分析、防御选择与持续验证，并通过基于真实世界智能电网部署的端到端案例研究进行定量分析。

Result: 定量分析显示时序、噪声和误报成本限制了可部署的防御措施，单纯检测机制在安全关键CPS中作为决策权威是不充分的，需要基于来源和物理基础的信任机制以及深度防御架构。

Conclusion: 论文强调了基于来源和物理基础的信任机制与深度防御架构的重要性，并概述了实现可信AI使能信息物理系统的开放挑战，为未来研究提供了系统性框架。

Abstract: The increasing integration of AI agents into cyber-physical systems (CPS) introduces new security risks that extend beyond traditional cyber or physical threat models. Recent advances in generative AI enable deepfake and semantic manipulation attacks that can compromise agent perception, reasoning, and interaction with the physical environment, while emerging protocols such as the Model Context Protocol (MCP) further expand the attack surface through dynamic tool use and cross-domain context sharing. This survey provides a comprehensive review of security threats targeting AI agents in CPS, with a particular focus on environmental interactions, deepfake-driven attacks, and MCP-mediated vulnerabilities. We organize the literature using the SENTINEL framework, a lifecycle-aware methodology that integrates threat characterization, feasibility analysis under CPS constraints, defense selection, and continuous validation. Through an end-to-end case study grounded in a real-world smart grid deployment, we quantitatively illustrate how timing, noise, and false-positive costs constrain deployable defenses, and why detection mechanisms alone are insufficient as decision authorities in safety-critical CPS. The survey highlights the role of provenance- and physics-grounded trust mechanisms and defense-in-depth architectures, and outlines open challenges toward trustworthy AI-enabled CPS.

</details>


### [5] [Eliciting Least-to-Most Reasoning for Phishing URL Detection](https://arxiv.org/abs/2601.20270)
*Holly Trikilis,Pasindu Marasinghe,Fariza Rashid,Suranga Seneviratne*

Main category: cs.CR

TL;DR: 提出基于Least-to-Most提示框架的钓鱼URL检测方法，通过答案敏感度机制增强推理能力，在少量训练数据下达到与监督模型相当的性能


<details>
  <summary>Details</summary>
Motivation: 钓鱼攻击持续高发，URL准确分类至关重要。虽然大语言模型在钓鱼URL检测中表现良好，但其推理能力尚未充分探索，需要更有效的提示策略来提升检测性能

Method: 提出Least-to-Most提示框架，引入"答案敏感度"机制指导迭代推理过程，使用三个URL数据集和四个SOTA大语言模型进行评估，与单次提示和监督模型对比

Result: 框架在显著减少训练数据的情况下，性能优于单次提示基线，达到与监督模型相当的水平，迭代推理和答案敏感度机制是性能提升的关键

Conclusion: Least-to-Most提示策略简单而强大，在最小化训练或少量指导的情况下，持续优于单次提示和监督方法，为钓鱼URL检测提供了有效的解决方案

Abstract: Phishing continues to be one of the most prevalent attack vectors, making accurate classification of phishing URLs essential. Recently, large language models (LLMs) have demonstrated promising results in phishing URL detection. However, their reasoning capabilities that enabled such performance remain underexplored. To this end, in this paper, we propose a Least-to-Most prompting framework for phishing URL detection. In particular, we introduce an "answer sensitivity" mechanism that guides Least-to-Most's iterative approach to enhance reasoning and yield higher prediction accuracy. We evaluate our framework using three URL datasets and four state-of-the-art LLMs, comparing against a one-shot approach and a supervised model. We demonstrate that our framework outperforms the one-shot baseline while achieving performance comparable to that of the supervised model, despite requiring significantly less training data. Furthermore, our in-depth analysis highlights how the iterative reasoning enabled by Least-to-Most, and reinforced by our answer sensitivity mechanism, drives these performance gains. Overall, we show that this simple yet powerful prompting strategy consistently outperforms both one-shot and supervised approaches, despite requiring minimal training or few-shot guidance. Our experimental setup can be found in our Github repository github.sydney.edu.au/htri0928/least-to-most-phishing-detection.

</details>


### [6] [SemBind: Binding Diffusion Watermarks to Semantics Against Black-Box Forgery Attacks](https://arxiv.org/abs/2601.20310)
*Xin Zhang,Zijin Yang,Kejiang Chen,Linfeng Ma,Weiming Zhang,Nenghai Yu*

Main category: cs.CR

TL;DR: SemBind是首个防御潜在水印黑盒伪造攻击的框架，通过学习语义掩码器将潜在信号绑定到图像语义上，显著降低伪造攻击的误接受率，同时保持图像质量基本不变。


<details>
  <summary>Details</summary>
Motivation: 潜在水印虽然简化了生成图像的检测和溯源，但面临黑盒伪造攻击的威胁：攻击者只需一张水印图像和黑盒访问模型，就能将提供商的水印嵌入非提供商生成的图像中，严重威胁溯源和信任体系。

Method: 提出SemBind框架，通过学习语义掩码器将潜在信号绑定到图像语义。使用对比学习训练掩码器，使相同提示生成近不变代码，不同提示生成近正交代码；这些代码经过重塑和排列后调制目标潜在信号，然后应用标准潜在水印。框架兼容现有潜在水印方案，通过掩码比率参数可调节抗伪造强度与鲁棒性之间的权衡。

Result: 在四种主流潜在水印方法上，SemBind增强的抗伪造变体显著降低了黑盒伪造攻击下的误接受率，同时提供了可控的鲁棒性-安全性平衡，图像质量基本保持不变。

Conclusion: SemBind是首个有效防御潜在水印黑盒伪造攻击的框架，通过语义绑定机制增强了水印的安全性，同时保持了与现有方案的兼容性和图像质量，为数字内容溯源提供了更可靠的保护。

Abstract: Latent-based watermarks, integrated into the generation process of latent diffusion models (LDMs), simplify detection and attribution of generated images. However, recent black-box forgery attacks, where an attacker needs at least one watermarked image and black-box access to the provider's model, can embed the provider's watermark into images not produced by the provider, posing outsized risk to provenance and trust. We propose SemBind, the first defense framework for latent-based watermarks that resists black-box forgery by binding latent signals to image semantics via a learned semantic masker. Trained with contrastive learning, the masker yields near-invariant codes for the same prompt and near-orthogonal codes across prompts; these codes are reshaped and permuted to modulate the target latent before any standard latent-based watermark. SemBind is generally compatible with existing latent-based watermarking schemes and keeps image quality essentially unchanged, while a simple mask-ratio parameter offers a tunable trade-off between anti-forgery strength and robustness. Across four mainstream latent-based watermark methods, our SemBind-enabled anti-forgery variants markedly reduce false acceptance under black-box forgery while providing a controllable robustness-security balance.

</details>


### [7] [UnlearnShield: Shielding Forgotten Privacy against Unlearning Inversion](https://arxiv.org/abs/2601.20325)
*Lulu Xue,Shengshan Hu,Wei Lu,Ziqi Zhou,Yufei Song,Jianhong Cheng,Minghui Li,Yanjun Zhang,Leo Yu Zhang*

Main category: cs.CR

TL;DR: UnlearnShield是首个针对机器学习遗忘反转攻击的防御方法，通过在余弦表示空间引入定向扰动并约束模块，在保护隐私的同时保持模型准确性和遗忘效果。


<details>
  <summary>Details</summary>
Motivation: 机器学习遗忘技术旨在从训练模型中移除特定数据影响以增强隐私保护，但近期研究发现存在隐私漏洞，攻击者可利用遗忘反转重建本应被删除的数据。目前缺乏专门的防御机制来应对这种威胁。

Method: UnlearnShield在余弦表示空间引入定向扰动，并通过约束模块进行调节，共同保持模型准确性和遗忘效果，从而降低反转风险同时保持实用性。

Result: 实验表明UnlearnShield在隐私保护、准确性和遗忘效果之间实现了良好的平衡。

Conclusion: UnlearnShield是首个专门针对遗忘反转攻击的防御方法，有效解决了机器学习遗忘中的隐私漏洞问题。

Abstract: Machine unlearning is an emerging technique that aims to remove the influence of specific data from trained models, thereby enhancing privacy protection. However, recent research has uncovered critical privacy vulnerabilities, showing that adversaries can exploit unlearning inversion to reconstruct data that was intended to be erased. Despite the severity of this threat, dedicated defenses remain lacking. To address this gap, we propose UnlearnShield, the first defense specifically tailored to counter unlearning inversion. UnlearnShield introduces directional perturbations in the cosine representation space and regulates them through a constraint module to jointly preserve model accuracy and forgetting efficacy, thereby reducing inversion risk while maintaining utility. Experiments demonstrate that it achieves a good trade-off among privacy protection, accuracy, and forgetting.

</details>


### [8] [Multimodal Multi-Agent Ransomware Analysis Using AutoGen](https://arxiv.org/abs/2601.20346)
*Asifullah Khan,Aimen Wadood,Mubashar Iqbal,Umme Zahoora*

Main category: cs.CR

TL;DR: 提出多模态多智能体勒索软件分析框架，结合静态、动态和网络数据，通过智能体交互反馈机制优化特征表示，实现勒索软件家族分类，性能优于单模态方法。


<details>
  <summary>Details</summary>
Motivation: 传统勒索软件检测方法（静态分析、启发式扫描、行为分析）单独使用时效果有限，需要更有效的综合检测方案来应对日益严重的网络安全威胁。

Method: 多模态多智能体架构：专门智能体处理静态、动态和网络数据，使用自编码器特征提取；融合智能体整合特征；基于Transformer的分类器识别勒索软件家族；智能体间通过反馈机制迭代优化特征表示。

Result: 在大规模数据集上评估，相比单模态和非自适应融合基线，家族分类的Macro-F1提升达0.936，降低校准误差；智能体反馈循环稳定收敛，智能体质量绝对提升超过0.75，最终综合得分约0.88。

Conclusion: 该方法为改进实际勒索软件防御系统提供了实用有效路径，置信度感知的弃权机制支持可靠的实际部署，但零日勒索软件检测仍受多态性和模态干扰影响。

Abstract: Ransomware has become one of the most serious cybersecurity threats causing major financial losses and operational disruptions worldwide.Traditional detection methods such as static analysis, heuristic scanning and behavioral analysis often fall short when used alone. To address these limitations, this paper presents multimodal multi agent ransomware analysis framework designed for ransomware classification. Proposed multimodal multiagent architecture combines information from static, dynamic and network sources. Each data type is handled by specialized agent that uses auto encoder based feature extraction. These representations are then integrated through a fusion agent. After that fused representation are used by transformer based classifier. It identifies the specific ransomware family. The agents interact through an interagent feedback mechanism that iteratively refines feature representations by suppressing low confidence information. The framework was evaluated on large scale datasets containing thousands of ransomware and benign samples. Multiple experiments were conducted on ransomware dataset. It outperforms single modality and nonadaptive fusion baseline achieving improvement of up to 0.936 in Macro-F1 for family classification and reducing calibration error. Over 100 epochs, the agentic feedback loop displays a stable monotonic convergence leading to over +0.75 absolute improvement in terms of agent quality and a final composite score of around 0.88 without fine tuning of the language models. Zeroday ransomware detection remains family dependent on polymorphism and modality disruptions. Confidence aware abstention enables reliable real world deployment by favoring conservativeand trustworthy decisions over forced classification. The findings indicate that proposed approach provides a practical andeffective path toward improving real world ransomware defense systems.

</details>


### [9] [LIFT: Byzantine Resilient Hub-Sampling](https://arxiv.org/abs/2601.20368)
*Mohamed Amine Legheraba,Nour Rachdi,Maria Gradinariu Potop-Butucaru,Sébastien Tixeuil*

Main category: cs.CR

TL;DR: Elevator协议构建去中心化网络拓扑，但易受拜占庭攻击；LIFT协议通过安全随机数生成器增强安全性，可抵御10%拜占庭节点。


<details>
  <summary>Details</summary>
Motivation: Elevator协议虽然能快速构建去中心化网络拓扑，但其对拜占庭攻击的抵抗力尚未研究。本文旨在评估Elevator在拜占庭攻击下的脆弱性，并提出更安全的替代方案。

Method: 首先评估Elevator协议在拜占庭攻击下的表现，发现其脆弱性。然后提出LIFT协议，使用密码学安全伪随机数生成器（PRNG）进行中心节点选择，防止拜占庭节点操纵网络拓扑。

Result: Elevator协议即使只有2%的拜占庭节点就足以破坏网络。而LIFT协议能够抵御高达10%的拜占庭节点攻击，显著提升了网络的安全性。

Conclusion: 去中心化网络拓扑构建需要安全的随机性机制来抵御拜占庭攻击。LIFT协议通过安全随机数生成器提供了更可靠的拜占庭弹性去中心化系统构建模块。

Abstract: Recently, a novel peer sampling protocol, Elevator, was introduced to construct network topologies tailored for emerging decentralized applications such as federated learning and blockchain. Elevator builds hub-based topologies in a fully decentralized manner, randomly selecting hubs among participating nodes. These hubs, acting as central nodes connected to the entire network, can be leveraged to accelerate message dissemination. Simulation results have shown that Elevator converges rapidly (within 3--4 cycles) and exhibits robustness against crash failures and churn. However, its resilience to Byzantine adversaries has not been investigated. In this work, we provide the first evaluation of Elevator under Byzantine adversaries and show that even a small fraction (2%) of Byzantine nodes is sufficient to subvert the network. As a result, we introduce LIFT, a new protocol that extends Elevator by employing a cryptographically secure pseudo-random number generator (PRNG) for hub selection, thereby mitigating Byzantine manipulation. In contrast, LIFT withstands adversarial infiltration and remains robust with up to 10% Byzantine nodes. These results highlight the necessity of secure randomness in decentralized hub formation and position LIFT as a more reliable building block for Byzantine-resilient decentralized systems.

</details>


### [10] [A High-Performance Fractal Encryption Framework and Modern Innovations for Secure Image Transmission](https://arxiv.org/abs/2601.20374)
*Sura Khalid Salsal,Eman Shaker Mahmood,Farah Tawfiq Abdul Hussien,Maryam Mahdi Alhusseini,Azhar Naji Alyahya,Nikolai Safiullin*

Main category: cs.CR

TL;DR: 本文提出了一种基于傅里叶变换的分形图像加密方法，相比传统方法在安全性、图像保真度和计算效率方面都有显著提升。


<details>
  <summary>Details</summary>
Motivation: 当前数字时代数据安全威胁日益增长，需要强大的图像加密技术。传统加密算法在安全性、图像保真度和计算效率之间存在权衡，需要改进。

Method: 提出基于傅里叶变换的分形加密方法，利用最先进技术实现图像加密。该方法结合分形理论和傅里叶变换，并与传统方法进行对比分析。

Result: 相比传统加密方法，该方法显著提升了加密/解密时间效率和图像保真度，填补了先前研究的空白。

Conclusion: 基于傅里叶变换的分形加密方法在图像加密中表现出优越性能，为未来研究提供了方向和改进空间。

Abstract: The current digital era, driven by growing threats to data security, requires a robust image encryption technique. Classical encryption algorithms suffer from a trade-off among security, image fidelity, and computational efficiency. This paper aims to enhance the performance and efficiency of image encryption. This is done by proposing Fractal encryption based on Fourier transforms as a new method of image encryption, leveraging state-of-the-art technology. The new approach considered here intends to enhance both security and efficiency in image encryption by comparing Fractal Encryption with basic methods. The suggested system also aims to optimise encryption/ decryption times and preserve image quality. This paper provides an introduction to Image Encryption using the fractal-based method, its mathematical formulation, and its comparative efficiency against publicly known traditional encryption methods. As a result, after filling the gaps identified in previous research, it has significantly improved both its encryption/decryption time and image fidelity compared to other techniques. In this paper, directions for future research and possible improvements are outlined for attention.

</details>


### [11] [Towards Quantum-Safe O-RAN -- Experimental Evaluation of ML-KEM-Based IPsec on the E2 Interface](https://arxiv.org/abs/2601.20378)
*Mario Perera,Michael Mackay,Max Hashem Eiza,Alessandro Raschellà,Nathan Shone,Mukesh Kumar Maheshwari*

Main category: cs.CR

TL;DR: 该论文实验评估了在O-RAN E2接口上集成后量子密码学ML-KEM对IPsec隧道建立延迟和RIC控制性能的影响，发现仅增加3-5ms开销，证明量子安全迁移具有可行性。


<details>
  <summary>Details</summary>
Motivation: 随着O-RAN部署扩展和攻击者采用"现在存储、以后解密"策略，运营商需要关于将关键控制接口迁移到后量子密码学的成本实证数据。特别是需要评估在gNB与Near-RT RIC之间的E2接口上集成后量子密码学的实际影响。

Method: 使用开源测试床（srsRAN、Open5GS、FlexRIC和strongSwan with liboqs）比较三种配置：无IPsec、基于经典ECDH的IPsec、基于ML-KEM的IPsec。研究重点评估IPsec隧道建立延迟和Near-RT RIC xApps在真实信令负载下的运行时行为。

Result: ML-KEM集成仅对隧道建立增加约3-5ms的小幅开销（相比经典IPsec），xApp操作和RIC控制循环在实验中保持稳定。重复自动化运行结果一致。

Conclusion: 基于ML-KEM的IPsec在E2接口上实际可行，这些发现为O-RAN部署的量子安全迁移策略提供了重要参考依据。

Abstract: As Open Radio Access Network (O-RAN) deployments expand and adversaries adopt 'store-now, decrypt-later' strategies, operators need empirical data on the cost of migrating critical control interfaces to post-quantum cryptography (PQC). This paper experimentally evaluates the impact of integrating a NIST-aligned module-lattice KEM (ML-KEM, CRYSTALS-Kyber) into IKEv2/IPsec protecting the E2 interface between the 5G Node B (gNB) and the Near-Real-Time RAN Intelligent Controller (Near-RT RIC). Using an open-source testbed built from srsRAN, Open5GS, FlexRIC and strongSwan (with liboqs), we compare three configurations: no IPsec, classical ECDH-based IPsec, and ML-KEM-based IPsec. The study focuses on IPsec tunnel-setup latency and the runtime behaviour of Near-RT RIC xApps under realistic signalling workloads. Results from repeated, automated runs show that ML-KEM integration adds a small overhead to tunnel establishment, which is approximately 3~5 ms in comparison to classical IPsec, while xApp operation and RIC control loops remain stable in our experiments. These findings indicate that ML-KEM based IPsec on the E2 interface is practically feasible and inform quantum-safe migration strategies for O-RAN deployments.

</details>


### [12] [Fuzzy Private Set Union via Oblivious Key Homomorphic Encryption Retrieval](https://arxiv.org/abs/2601.20400)
*Jean-Guillaume Dumas,Aude Maignan,Luiza Soezima*

Main category: cs.CR

TL;DR: 提出模糊私有集合并（FPSU）协议，使用新的OKHER子协议改进OKVR技术，支持近似匹配而非精确匹配，通信复杂度优化至O(dm log(δn))到O(d^2m log(δ^2n))。


<details>
  <summary>Details</summary>
Motivation: 传统私有集合计算（PSU/PSI）要求精确匹配，但在许多实际应用中（如生物特征识别、近似匹配场景），需要支持模糊/近似匹配。现有模糊PSI协议已存在，但缺乏高效的模糊PSU协议。

Method: 引入新的OKHER（Oblivious Key Homomorphic Encryption Retrieval）子协议改进OKVR技术；使用l∞距离定义模糊匹配；将接收方集合X替换为以X中点为球心、δ为半径的d维球体并集；基于同态加密构建FPSU协议。

Result: 提出了首个正式的FPSU功能定义和安全属性；开发了多个针对球体模式的协议；通信复杂度优化至O(dm log(δn))到O(d^2m log(δ^2n))，具体取决于接收方数据集结构。

Conclusion: 成功设计了高效的模糊私有集合并协议，通过OKHER技术和同态加密实现了近似匹配下的安全联合计算，填补了模糊PSU协议的研究空白。

Abstract: Private Set Multi-Party Computations are protocols that allow parties to jointly and securely compute functions: apart from what is deducible from the output of the function, the input sets are kept private. Then, a Private Set Union (PSU), resp. Intersection (PSI), is a protocol that allows parties to jointly compute the union, resp. the intersection, between their private sets. Now a structured PSI, is a PSI where some structure of the sets can allow for more efficient protocols. For instance in Fuzzy PSI, elements only need to be close enough, instead of equal, to be part of the intersection. We present in this paper, Fuzzy PSU protocols (FPSU), able to efficiently take into account approximations in the union. For this, we introduce a new efficient sub-protocol, called Oblivious Key Homomorphic Encryption Retrieval (OKHER), improving on Oblivious Key-Value Retrieval (OKVR) techniques in our setting. In the fuzzy context, the receiver set $X=\{x_i\}_{1..n}$ is replaced by ${\mathcal B}_δ(X)$, the union of $n$ balls of dimension $d$ with radius $δ$, centered at the $x_i$. The sender set is just its $m$ points of dimension $d$. Then the FPSU functionality corresponds to $X \sqcup \{y \in Y, y \notin {\mathcal B}_δ(X)\}$. Thus, we formally define the FPSU functionality and security properties, and propose several protocols tuned to the patterns of the balls using the $l_\infty$ distance. Using our OKHER routine and homomorphic encryption, we are for instance able to obtain a FPSU protocols with an asymptotic communication volume bound ranging from $O(dm\log(δ{n}))$ to $O(d^2m\log(δ^2n))$, depending on the receiver data set structure.

</details>


### [13] [TÄMU: Emulating Trusted Applications at the (GlobalPlatform)-API Layer](https://arxiv.org/abs/2601.20507)
*Philipp Mao,Li Shi,Marcel Busch,Mathias Payer*

Main category: cs.CR

TL;DR: TÄMU是一个TEE可信应用动态分析平台，通过API层拦截实现模糊测试和调试，发现了17个零日漏洞


<details>
  <summary>Details</summary>
Motivation: 移动设备依赖TEE执行安全关键代码，但TEE的闭源性和碎片化严重阻碍了可信应用(TA)的动态分析，现有测试主要局限于静态分析

Method: 提出TÄMU重托管平台，利用GlobalPlatform标准化的TEE API，对非标准API采用贪婪高级仿真技术，优先处理能获得最大模糊测试覆盖率的API

Result: 实现了67个TA在4个不同TEE上的仿真，模糊测试发现了11个TA中的17个零日漏洞，表明TEE生态系统缺乏动态分析能力

Conclusion: TÄMU通过为移动TEE领域带来有效实用的动态分析，有望填补这一技术空白，即使有源代码的厂商也未能解锁这些能力

Abstract: Mobile devices rely on Trusted Execution Environments (TEEs) to execute security-critical code and protect sensitive assets. This security-critical code is modularized in components known as Trusted Applications (TAs). Vulnerabilities in TAs can compromise the TEE and, thus, the entire system. However, the closed-source nature and fragmentation of mobile TEEs severely hinder dynamic analysis of TAs, limiting testing efforts to mostly static analyses. This paper presents TÄMU, a rehosting platform enabling dynamic analysis of TAs, specifically fuzzing and debugging, by interposing their execution at the API layer. To scale to many TAs across different TEEs, TÄMU leverages the standardization of TEE APIs, driven by the GlobalPlatform specifications. For the remaining TEE-specific APIs not shared across different TEEs, TÄMU introduces the notion of greedy high-level emulation, a technique that allows prioritizing manual rehosting efforts based on the potential coverage gain during fuzzing. We implement TÄMU and use it to emulate 67 TAs across four TEEs. Our fuzzing campaigns yielded 17 zero-day vulnerabilities across 11 TAs. These results indicate a deficit of dynamic analysis capabilities across the TEE ecosystem, where not even vendors with source code unlocked these capabilities for themselves. TÄMU promises to close this gap by bringing effective and practical dynamic analysis to the mobile TEE domain.

</details>


### [14] [IoT Device Identification with Machine Learning: Common Pitfalls and Best Practices](https://arxiv.org/abs/2601.20548)
*Kahraman Kostas,Rabia Yasa Kostas*

Main category: cs.CR

TL;DR: 论文批判性分析机器学习设备识别过程，指出现有文献常见陷阱，分析识别方法权衡、数据异质性、特征提取挑战和评估指标，提供增强物联网安全模型可复现性和泛化性的指南


<details>
  <summary>Details</summary>
Motivation: 现有物联网设备识别研究存在多种常见陷阱，包括数据增强不当、会话标识符误导等问题，导致模型可复现性和泛化性不足，需要系统分析这些问题并提供改进指南

Method: 通过批判性分析现有文献，系统研究设备识别过程中的关键问题：识别方法权衡（唯一识别 vs 类别识别）、数据异质性处理、特征提取挑战、评估指标选择，并具体分析常见错误类型

Result: 识别出设备识别研究中的具体错误模式，包括不当数据增强、误导性会话标识符使用等，提出了增强物联网安全模型可复现性和泛化性的系统指南

Conclusion: 论文为物联网设备识别研究提供了实用的改进指南，帮助研究人员避免常见陷阱，提升模型的可复现性和泛化能力，从而增强物联网安全模型的可靠性

Abstract: This paper critically examines the device identification process using machine learning, addressing common pitfalls in existing literature. We analyze the trade-offs between identification methods (unique vs. class based), data heterogeneity, feature extraction challenges, and evaluation metrics. By highlighting specific errors, such as improper data augmentation and misleading session identifiers, we provide a robust guideline for researchers to enhance the reproducibility and generalizability of IoT security models.

</details>


### [15] [/dev/SDB: Software Defined Boot -- A novel standard for diskless booting anywhere and everywhere](https://arxiv.org/abs/2601.20629)
*Aditya Mitra,Hamza Haroon,Amaan Rais Shah,Mohammad Elham Rasooli,Bogdan Itsam Dorantes Nikolaev,Tuğçe Ballı*

Main category: cs.CR

TL;DR: 提出/dev/SDB系统，通过Wi-Fi和蜂窝网络实现全球范围的远程操作系统访问，让用户无需物理接触硬件即可使用授权操作系统


<details>
  <summary>Details</summary>
Motivation: 随着操作系统复杂性和多样性增加，企业环境中不同用户需要不同操作系统，但网络启动仅限于有线连接，限制了地理范围。需要让员工能在任何地方工作，同时遵守操作系统策略，避免冗余硬件

Method: 开发/dev/SDB标准，通过Wi-Fi和蜂窝网络实现远程操作系统访问，用户无需在企业网络内即可访问授权操作系统

Result: 提出了一种新的系统标准，使全球任何用户都能通过无线网络访问授权操作系统，实现真正的"随处工作"

Conclusion: /dev/SDB系统解决了传统网络启动的地理限制问题，通过无线连接使员工能在全球任何地方安全访问所需操作系统，提高工作灵活性同时遵守企业策略

Abstract: A computer is nothing but a device that processes the instructions supplied to it. However, as computers evolved, the instructions or codes started to be more complicated. As computers started to be used by non-technical people, it became imperative that the users be able to use the machine without having underlying knowledge of the code or the hardware. And operating system became the backbone for translating the inputs from the user to actual operation on the hardware. With the increasing complexity and the choices of operating system, it became clear that different groups of people, especially in an enterprise scenario, required different operating systems. Installing them all on a single machine, for shared computers became a difficult task, giving rise to network-based booting. But network-based booting was confined to only wired connectivity, keeping it restricted to very small geographical areas. The proposed system, /dev/SDB, is aimed at creating a standard where any user, anyone on the globe, can access the operating system authorized to them without having to be on the corporate network. It aims to offer the same over Wi-Fi as well as cellular connectivity, ensuring employees can truly work from anywhere, while following the policies for operating systems and without redundant hardware.

</details>


### [16] [Supply Chain Insecurity: Exposing Vulnerabilities in iOS Dependency Management Systems](https://arxiv.org/abs/2601.20638)
*David Schmidt,Sebastian Schrittwieser,Edgar Weippl*

Main category: cs.CR

TL;DR: iOS依赖管理系统（特别是CocoaPods）存在安全漏洞，攻击者可通过依赖混淆攻击和废弃域名劫持实现远程代码执行，影响数百万用户。


<details>
  <summary>Details</summary>
Motivation: iOS应用开发中广泛使用依赖管理系统（CocoaPods、Carthage、SwiftPM），但其安全性研究不足。这些系统存在配置错误和恶意攻击风险，可能导致供应链攻击，而iOS生态中的这一问题尚未得到充分关注。

Method: 研究聚焦CocoaPods，同时考察Carthage和SwiftPM。通过分析9,212个iOS应用，发现它们暴露内部包名和版本信息。攻击者可利用此漏洞注册未声明的依赖，实现RCE攻击。同时研究通过废弃域名和GitHub URL劫持依赖的方法。还检查了公共GitHub仓库中易受攻击依赖的使用情况，并与Cargo、Go modules等其他包管理器进行对比分析。

Result: 1. 流行iOS应用暴露内部依赖信息，使依赖混淆攻击成为可能；2. 通过劫持单个废弃CocoaPod域名可影响63个iOS应用，波及数百万用户；3. 分析了iOS依赖管理系统与其他主流包管理器的安全差异。

Conclusion: iOS依赖管理系统存在严重安全漏洞，特别是CocoaPods的依赖混淆和域名劫持风险。需要采取缓解策略来保护开发者机器和构建服务器免受供应链攻击。

Abstract: Dependency management systems are a critical component in software development, enabling projects to incorporate existing functionality efficiently. However, misconfigurations and malicious actors in these systems pose severe security risks, leading to supply chain attacks. Despite the widespread use of smartphone apps, the security of dependency management systems in the iOS software supply chain has received limited attention. In this paper, we focus on CocoaPods, one of the most widely used dependency management systems for iOS app development, but also examine the security of Carthage and Swift Package Manager (SwiftPM). We demonstrate that iOS apps expose internal package names and versions. Attackers can exploit this leakage to register previously unclaimed dependencies in CocoaPods, enabling remote code execution (RCE) on developer machines and build servers. Additionally, we show that attackers can compromise dependencies by reclaiming abandoned domains and GitHub URLs. Analyzing a dataset of 9,212 apps, we quantify how many apps are susceptible to these vulnerabilities. Further, we inspect the use of vulnerable dependencies within public GitHub repositories. Our findings reveal that popular apps disclose internal dependency information, enabling dependency confusion attacks. Furthermore, we show that hijacking a single CocoaPod library through an abandoned domain could compromise 63 iOS apps, affecting millions of users. Finally, we compare iOS dependency management systems with Cargo, Go modules, Maven, npm, and pip to discuss mitigation strategies for the identified threats.

</details>


### [17] [Decentralized Identity in Practice: Benchmarking Latency, Cost, and Privacy](https://arxiv.org/abs/2601.20716)
*Abylay Satybaldy,Kamil Tylinski,Jiahua Xu*

Main category: cs.CR

TL;DR: 对以太坊、Hedera和XRP Ledger三种分布式账本DID方法的实证基准研究，测量延迟、交易成本和元数据泄露，揭示不同架构在性能与隐私间的权衡。


<details>
  <summary>Details</summary>
Motivation: 虽然去中心化标识符(DID)在分布式账本上部署日益增多，但缺乏跨平台的系统性实证数据来了解其实际运行行为。需要为DID系统的选择和配置提供基于证据的见解。

Method: 使用统一的实验设置，通过参考软件开发工具包(SDK)对三种主流账本DID方法（以太坊、Hedera、XRP Ledger）进行实证基准测试。测量延迟、交易成本和链上元数据暴露，延迟按各平台的区块或共识间隔归一化，成本按原生价值转移费用归一化。使用基于熵的元数据泄露分数(MLS)量化隐私泄露。

Result: 以太坊支持近即时、离链的DID创建，但链上生命周期操作延迟和成本最高；XRPL提供确定稳定的延迟和固定低费用，但交易负载更详细导致元数据泄露更高；Hedera实现最低链上延迟和低费用，元数据泄露最小，但SDK端处理和确认管道偶尔产生方差。

Conclusion: 账本架构和SDK工作流程对DID延迟、成本和元数据暴露有重要影响，补充了底层共识机制的效果。研究结果为在性能和隐私约束下选择和配置DID系统提供了实证依据。

Abstract: Decentralized Identifiers (DIDs) are increasingly deployed on distributed ledgers, yet systematic cross-platform evidence on their operational behavior remains limited. We present an empirical benchmarking study of three prominent ledger-based DID methods - Ethereum, Hedera, and XRP Ledger - using reference Software Development Kits (SDKs) under a unified experimental setup. We measure latency, transaction cost, and on-chain metadata exposure, normalizing latency by each platform's block or consensus interval and cost by its native value transfer fee. Privacy leakage is quantified using a Metadata-Leakage Score (MLS), an entropy-based measure expressed in bits per operation.
  Our results reveal distinct architectural trade-offs. Ethereum enables near-instant, off-chain DID creation, but incurs the highest latency and cost for on-chain lifecycle operations. XRPL delivers deterministic and stable latency with fixed, low fees, yet exhibits higher metadata leakage due to more verbose transaction payloads. Hedera achieves the lowest on-chain latency and low fees with minimal metadata leakage, while occasional variance arises from SDK-side processing and confirmation pipelines.
  Overall, the findings show that ledger architecture and SDK workflows play a major role in shaping DID latency, cost, and metadata exposure, complementing the effects of the underlying consensus mechanism. These results provide evidence-based insights to support informed selection and configuration of DID systems under performance and privacy constraints.

</details>
