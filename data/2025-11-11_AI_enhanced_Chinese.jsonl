{"id": "2511.05598", "categories": ["cs.CR", "eess.IV"], "pdf": "https://arxiv.org/pdf/2511.05598", "abs": "https://arxiv.org/abs/2511.05598", "authors": ["Wenkai Fu", "Finn Carter", "Yue Wang", "Emily Davis", "Bo Zhang"], "title": "Diffusion-Based Image Editing: An Unforeseen Adversary to Robust Invisible Watermarks", "comment": "Preprint", "summary": "Robust invisible watermarking aims to embed hidden messages into images such that they survive various manipulations while remaining imperceptible. However, powerful diffusion-based image generation and editing models now enable realistic content-preserving transformations that can inadvertently remove or distort embedded watermarks. In this paper, we present a theoretical and empirical analysis demonstrating that diffusion-based image editing can effectively break state-of-the-art robust watermarks designed to withstand conventional distortions. We analyze how the iterative noising and denoising process of diffusion models degrades embedded watermark signals, and provide formal proofs that under certain conditions a diffusion model's regenerated image retains virtually no detectable watermark information. Building on this insight, we propose a diffusion-driven attack that uses generative image regeneration to erase watermarks from a given image. Furthermore, we introduce an enhanced \\emph{guided diffusion} attack that explicitly targets the watermark during generation by integrating the watermark decoder into the sampling loop. We evaluate our approaches on multiple recent deep learning watermarking schemes (e.g., StegaStamp, TrustMark, and VINE) and demonstrate that diffusion-based editing can reduce watermark decoding accuracy to near-zero levels while preserving high visual fidelity of the images. Our findings reveal a fundamental vulnerability in current robust watermarking techniques against generative model-based edits, underscoring the need for new watermarking strategies in the era of generative AI.", "AI": {"tldr": "\u6269\u6563\u6a21\u578b\u80fd\u591f\u6709\u6548\u79fb\u9664\u56fe\u50cf\u4e2d\u7684\u9690\u5f62\u6c34\u5370\uff0c\u672c\u6587\u5206\u6790\u4e86\u6269\u6563\u7f16\u8f91\u5982\u4f55\u7834\u574f\u73b0\u6709\u6c34\u5370\u6280\u672f\uff0c\u5e76\u63d0\u51fa\u4e24\u79cd\u57fa\u4e8e\u6269\u6563\u7684\u653b\u51fb\u65b9\u6cd5\uff0c\u53ef\u5c06\u6c34\u5370\u89e3\u7801\u51c6\u786e\u7387\u964d\u81f3\u63a5\u8fd1\u96f6\u3002", "motivation": "\u968f\u7740\u6269\u6563\u6a21\u578b\u7684\u5f3a\u5927\u751f\u6210\u548c\u7f16\u8f91\u80fd\u529b\uff0c\u73b0\u6709\u9c81\u68d2\u6c34\u5370\u6280\u672f\u9762\u4e34\u88ab\u65e0\u610f\u4e2d\u79fb\u9664\u6216\u626d\u66f2\u7684\u98ce\u9669\uff0c\u9700\u8981\u5206\u6790\u8fd9\u79cd\u65b0\u578b\u5a01\u80c1\u5e76\u63ed\u793a\u5176\u6839\u672c\u8106\u5f31\u6027\u3002", "method": "1. \u7406\u8bba\u5206\u6790\u6269\u6563\u6a21\u578b\u7684\u8fed\u4ee3\u53bb\u566a\u8fc7\u7a0b\u5982\u4f55\u964d\u89e3\u6c34\u5370\u4fe1\u53f7\uff1b2. \u63d0\u51fa\u6269\u6563\u9a71\u52a8\u653b\u51fb\uff0c\u4f7f\u7528\u751f\u6210\u56fe\u50cf\u518d\u751f\u6765\u64e6\u9664\u6c34\u5370\uff1b3. \u5f15\u5165\u5f15\u5bfc\u6269\u6563\u653b\u51fb\uff0c\u5728\u91c7\u6837\u5faa\u73af\u4e2d\u96c6\u6210\u6c34\u5370\u89e3\u7801\u5668\u6765\u9488\u5bf9\u6027\u79fb\u9664\u6c34\u5370\u3002", "result": "\u5728\u591a\u79cd\u6df1\u5ea6\u5b66\u4e60\u6c34\u5370\u65b9\u6848\uff08StegaStamp\u3001TrustMark\u3001VINE\uff09\u4e0a\u7684\u8bc4\u4f30\u663e\u793a\uff0c\u6269\u6563\u7f16\u8f91\u53ef\u5c06\u6c34\u5370\u89e3\u7801\u51c6\u786e\u7387\u964d\u81f3\u63a5\u8fd1\u96f6\uff0c\u540c\u65f6\u4fdd\u6301\u56fe\u50cf\u7684\u9ad8\u89c6\u89c9\u4fdd\u771f\u5ea6\u3002", "conclusion": "\u5f53\u524d\u9c81\u68d2\u6c34\u5370\u6280\u672f\u5bf9\u57fa\u4e8e\u751f\u6210\u6a21\u578b\u7684\u7f16\u8f91\u5b58\u5728\u6839\u672c\u8106\u5f31\u6027\uff0c\u5728\u751f\u6210AI\u65f6\u4ee3\u9700\u8981\u5f00\u53d1\u65b0\u7684\u6c34\u5370\u7b56\u7565\u3002"}}
{"id": "2511.06064", "categories": ["cs.CR", "cs.AI"], "pdf": "https://arxiv.org/pdf/2511.06064", "abs": "https://arxiv.org/abs/2511.06064", "authors": ["Yusaku Negoya", "Feifei Cui", "Zilong Zhang", "Miao Pan", "Tomoaki Ohtsuki", "Aohan Li"], "title": "A Privacy-Preserving Federated Learning Method with Homomorphic Encryption in Omics Data", "comment": "6 pages, 4 figures", "summary": "Omics data is widely employed in medical research to identify disease mechanisms and contains highly sensitive personal information. Federated Learning (FL) with Differential Privacy (DP) can ensure the protection of omics data privacy against malicious user attacks. However, FL with the DP method faces an inherent trade-off: stronger privacy protection degrades predictive accuracy due to injected noise. On the other hand, Homomorphic Encryption (HE) allows computations on encrypted data and enables aggregation of encrypted gradients without DP-induced noise can increase the predictive accuracy. However, it may increase the computation cost. To improve the predictive accuracy while considering the computational ability of heterogeneous clients, we propose a Privacy-Preserving Machine Learning (PPML)-Hybrid method by introducing HE. In the proposed PPML-Hybrid method, clients distributed select either HE or DP based on their computational resources, so that HE clients contribute noise-free updates while DP clients reduce computational overhead. Meanwhile, clients with high computational resources clients can flexibly adopt HE or DP according to their privacy needs. Performance evaluation on omics datasets show that our proposed method achieves comparable predictive accuracy while significantly reducing computation time relative to HE-only. Additionally, it outperforms DP-only methods under equivalent or stricter privacy budgets.", "AI": {"tldr": "\u63d0\u51faPPML-Hybrid\u65b9\u6cd5\uff0c\u7ed3\u5408\u540c\u6001\u52a0\u5bc6\u548c\u5dee\u5206\u9690\u79c1\uff0c\u8ba9\u5ba2\u6237\u7aef\u6839\u636e\u8ba1\u7b97\u8d44\u6e90\u9009\u62e9\u9690\u79c1\u4fdd\u62a4\u65b9\u5f0f\uff0c\u5728\u4fdd\u8bc1\u9690\u79c1\u7684\u540c\u65f6\u63d0\u9ad8\u9884\u6d4b\u51c6\u786e\u7387\u548c\u8ba1\u7b97\u6548\u7387\u3002", "motivation": "\u89e3\u51b3\u8054\u90a6\u5b66\u4e60\u4e2d\u5dee\u5206\u9690\u79c1\u65b9\u6cd5\u5728\u4fdd\u62a4\u9690\u79c1\u65f6\u56e0\u6ce8\u5165\u566a\u58f0\u5bfc\u81f4\u9884\u6d4b\u51c6\u786e\u7387\u4e0b\u964d\u7684\u95ee\u9898\uff0c\u540c\u65f6\u907f\u514d\u540c\u6001\u52a0\u5bc6\u65b9\u6cd5\u8ba1\u7b97\u6210\u672c\u8fc7\u9ad8\u7684\u95ee\u9898\u3002", "method": "\u63d0\u51fa\u6df7\u5408\u9690\u79c1\u4fdd\u62a4\u65b9\u6cd5\uff0c\u8ba9\u5ba2\u6237\u7aef\u6839\u636e\u8ba1\u7b97\u8d44\u6e90\u9009\u62e9\u4f7f\u7528\u540c\u6001\u52a0\u5bc6\u6216\u5dee\u5206\u9690\u79c1\uff0cHE\u5ba2\u6237\u7aef\u63d0\u4f9b\u65e0\u566a\u58f0\u66f4\u65b0\uff0cDP\u5ba2\u6237\u7aef\u964d\u4f4e\u8ba1\u7b97\u5f00\u9500\u3002", "result": "\u5728\u7ec4\u5b66\u6570\u636e\u96c6\u4e0a\u7684\u8bc4\u4f30\u663e\u793a\uff0c\u8be5\u65b9\u6cd5\u5728\u4fdd\u6301\u53ef\u6bd4\u9884\u6d4b\u51c6\u786e\u7387\u7684\u540c\u65f6\u663e\u8457\u51cf\u5c11\u8ba1\u7b97\u65f6\u95f4\uff0c\u5728\u76f8\u540c\u6216\u66f4\u4e25\u683c\u9690\u79c1\u9884\u7b97\u4e0b\u4f18\u4e8e\u7eafDP\u65b9\u6cd5\u3002", "conclusion": "PPML-Hybrid\u65b9\u6cd5\u5728\u9690\u79c1\u4fdd\u62a4\u3001\u9884\u6d4b\u51c6\u786e\u7387\u548c\u8ba1\u7b97\u6548\u7387\u4e4b\u95f4\u5b9e\u73b0\u4e86\u66f4\u597d\u7684\u5e73\u8861\uff0c\u9002\u7528\u4e8e\u5f02\u6784\u5ba2\u6237\u7aef\u7684\u5b9e\u9645\u5e94\u7528\u573a\u666f\u3002"}}
{"id": "2511.06192", "categories": ["cs.CR", "cs.AR"], "pdf": "https://arxiv.org/pdf/2511.06192", "abs": "https://arxiv.org/abs/2511.06192", "authors": ["Michael Jaemin Kim", "Seungmin Baek", "Jumin Kim", "Hwayong Nam", "Nam Sung Kim", "Jung Ho Ahn"], "title": "SoK: Systematizing a Decade of Architectural RowHammer Defenses Through the Lens of Streaming Algorithms", "comment": "Accepted at IEEE S&P 2026", "summary": "A decade after its academic introduction, RowHammer (RH) remains a moving target that continues to challenge both the industry and academia. With its potential to serve as a critical attack vector, the ever-decreasing RH threshold now threatens DRAM process technology scaling, with a superlinearly increasing cost of RH protection solutions. Due to their generality and relatively lower performance costs, architectural RH solutions are the first line of defense against RH. However, the field is fragmented with varying views of the problem, terminologies, and even threat models.\n  In this paper, we systematize architectural RH defenses from the last decade through the lens of streaming algorithms. We provide a taxonomy that encompasses 48 different works. We map multiple architectural RH defenses to the classical streaming algorithms, which extends to multiple proposals that did not identify this link. We also provide two practitioner guides. The first guide analyzes which algorithm best fits a given RHTH, location, process technology, storage type, and mitigative action. The second guide encourages future research to consult existing algorithms when architecting RH defenses. We illustrate this by demonstrating how Reservoir-Sampling can improve related RH defenses, and also introduce StickySampling that can provide mathematical security that related studies do not guarantee.", "AI": {"tldr": "\u672c\u6587\u7cfb\u7edf\u5316\u5206\u6790\u4e86\u8fc7\u53bb\u5341\u5e74\u95f4\u9488\u5bf9RowHammer\u653b\u51fb\u7684\u67b6\u6784\u9632\u5fa1\u65b9\u6848\uff0c\u901a\u8fc7\u6d41\u7b97\u6cd5\u89c6\u89d2\u63d0\u4f9b\u5206\u7c7b\u6cd5\uff0c\u5e76\u63d0\u51fa\u4e86\u4e24\u4e2a\u5b9e\u7528\u6307\u5357\u6765\u5e2e\u52a9\u9009\u62e9\u6700\u4f73\u9632\u5fa1\u7b97\u6cd5\u548c\u6307\u5bfc\u672a\u6765\u7814\u7a76\u3002", "motivation": "RowHammer\u653b\u51fb\u5341\u5e74\u540e\u4ecd\u7136\u662f\u79fb\u52a8\u76ee\u6807\uff0c\u4e0d\u65ad\u5a01\u80c1DRAM\u5de5\u827a\u6280\u672f\u6269\u5c55\u3002\u7531\u4e8e\u67b6\u6784\u9632\u5fa1\u65b9\u6848\u5177\u6709\u901a\u7528\u6027\u548c\u76f8\u5bf9\u8f83\u4f4e\u7684\u6027\u80fd\u6210\u672c\uff0c\u662f\u9632\u5fa1RowHammer\u7684\u7b2c\u4e00\u9053\u9632\u7ebf\uff0c\u4f46\u8be5\u9886\u57df\u5b58\u5728\u89c2\u70b9\u3001\u672f\u8bed\u548c\u5a01\u80c1\u6a21\u578b\u7684\u5206\u6b67\u3002", "method": "\u901a\u8fc7\u6d41\u7b97\u6cd5\u89c6\u89d2\u7cfb\u7edf\u5316\u5206\u679048\u4e2a\u4e0d\u540c\u7684\u67b6\u6784RowHammer\u9632\u5fa1\u5de5\u4f5c\uff0c\u5c06\u591a\u4e2a\u67b6\u6784\u9632\u5fa1\u6620\u5c04\u5230\u7ecf\u5178\u6d41\u7b97\u6cd5\uff0c\u5e76\u63d0\u51fa\u4e86\u4e24\u4e2a\u5b9e\u7528\u6307\u5357\uff1a\u7b97\u6cd5\u9009\u62e9\u6307\u5357\u548c\u7814\u7a76\u6307\u5bfc\u6307\u5357\u3002", "result": "\u63d0\u4f9b\u4e86\u6db5\u76d648\u4e2a\u5de5\u4f5c\u7684\u5206\u7c7b\u6cd5\uff0c\u5c55\u793a\u4e86Reservoir-Sampling\u5982\u4f55\u6539\u8fdb\u76f8\u5173\u9632\u5fa1\uff0c\u5e76\u5f15\u5165\u4e86StickySampling\u6765\u63d0\u4f9b\u6570\u5b66\u5b89\u5168\u6027\u4fdd\u8bc1\u3002", "conclusion": "\u901a\u8fc7\u6d41\u7b97\u6cd5\u6846\u67b6\u7cfb\u7edf\u5316RowHammer\u9632\u5fa1\u7814\u7a76\uff0c\u4e3a\u5b9e\u8df5\u8005\u63d0\u4f9b\u7b97\u6cd5\u9009\u62e9\u6307\u5bfc\uff0c\u5e76\u4e3a\u672a\u6765\u7814\u7a76\u63d0\u4f9b\u57fa\u4e8e\u73b0\u6709\u7b97\u6cd5\u7684\u67b6\u6784\u9632\u5fa1\u8bbe\u8ba1\u65b9\u6cd5\u3002"}}
{"id": "2511.06197", "categories": ["cs.CR", "cs.AI", "cs.CL", "cs.LG", "cs.NI"], "pdf": "https://arxiv.org/pdf/2511.06197", "abs": "https://arxiv.org/abs/2511.06197", "authors": ["Dilli Prasad Sharma", "Liang Xue", "Xiaowei Sun", "Xiaodong Lin", "Pulei Xiong"], "title": "Enhancing Adversarial Robustness of IoT Intrusion Detection via SHAP-Based Attribution Fingerprinting", "comment": null, "summary": "The rapid proliferation of Internet of Things (IoT) devices has transformed numerous industries by enabling seamless connectivity and data-driven automation. However, this expansion has also exposed IoT networks to increasingly sophisticated security threats, including adversarial attacks targeting artificial intelligence (AI) and machine learning (ML)-based intrusion detection systems (IDS) to deliberately evade detection, induce misclassification, and systematically undermine the reliability and integrity of security defenses. To address these challenges, we propose a novel adversarial detection model that enhances the robustness of IoT IDS against adversarial attacks through SHapley Additive exPlanations (SHAP)-based fingerprinting. Using SHAP's DeepExplainer, we extract attribution fingerprints from network traffic features, enabling the IDS to reliably distinguish between clean and adversarially perturbed inputs. By capturing subtle attribution patterns, the model becomes more resilient to evasion attempts and adversarial manipulations. We evaluated the model on a standard IoT benchmark dataset, where it significantly outperformed a state-of-the-art method in detecting adversarial attacks. In addition to enhanced robustness, this approach improves model transparency and interpretability, thereby increasing trust in the IDS through explainable AI.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8eSHAP\u6307\u7eb9\u8bc6\u522b\u7684\u5bf9\u6297\u6027\u68c0\u6d4b\u6a21\u578b\uff0c\u589e\u5f3a\u7269\u8054\u7f51\u5165\u4fb5\u68c0\u6d4b\u7cfb\u7edf\u5bf9\u5bf9\u6297\u653b\u51fb\u7684\u9c81\u68d2\u6027\uff0c\u901a\u8fc7\u63d0\u53d6\u7f51\u7edc\u6d41\u91cf\u7279\u5f81\u7684\u53ef\u89e3\u91ca\u6307\u7eb9\u6765\u533a\u5206\u6b63\u5e38\u548c\u5bf9\u6297\u6027\u8f93\u5165\u3002", "motivation": "\u7269\u8054\u7f51\u8bbe\u5907\u6fc0\u589e\u5e26\u6765\u4e86\u5b89\u5168\u5a01\u80c1\uff0c\u7279\u522b\u662f\u9488\u5bf9AI/ML\u5165\u4fb5\u68c0\u6d4b\u7cfb\u7edf\u7684\u5bf9\u6297\u653b\u51fb\uff0c\u8fd9\u4e9b\u653b\u51fb\u4f1a\u9003\u907f\u68c0\u6d4b\u3001\u5bfc\u81f4\u8bef\u5206\u7c7b\uff0c\u7834\u574f\u5b89\u5168\u9632\u5fa1\u7684\u53ef\u9760\u6027\u3002", "method": "\u4f7f\u7528SHAP\u7684DeepExplainer\u4ece\u7f51\u7edc\u6d41\u91cf\u7279\u5f81\u4e2d\u63d0\u53d6\u5f52\u56e0\u6307\u7eb9\uff0c\u4f7f\u5165\u4fb5\u68c0\u6d4b\u7cfb\u7edf\u80fd\u591f\u53ef\u9760\u533a\u5206\u5e72\u51c0\u8f93\u5165\u548c\u5bf9\u6297\u6027\u6270\u52a8\u8f93\u5165\uff0c\u901a\u8fc7\u6355\u6349\u7ec6\u5fae\u7684\u5f52\u56e0\u6a21\u5f0f\u589e\u5f3a\u7cfb\u7edf\u97e7\u6027\u3002", "result": "\u5728\u6807\u51c6\u7269\u8054\u7f51\u57fa\u51c6\u6570\u636e\u96c6\u4e0a\u7684\u8bc4\u4f30\u663e\u793a\uff0c\u8be5\u6a21\u578b\u5728\u68c0\u6d4b\u5bf9\u6297\u653b\u51fb\u65b9\u9762\u663e\u8457\u4f18\u4e8e\u6700\u5148\u8fdb\u7684\u65b9\u6cd5\uff0c\u540c\u65f6\u63d0\u9ad8\u4e86\u6a21\u578b\u900f\u660e\u5ea6\u548c\u53ef\u89e3\u91ca\u6027\u3002", "conclusion": "\u8be5\u65b9\u6cd5\u4e0d\u4ec5\u589e\u5f3a\u4e86\u5165\u4fb5\u68c0\u6d4b\u7cfb\u7edf\u5bf9\u5bf9\u6297\u653b\u51fb\u7684\u9c81\u68d2\u6027\uff0c\u8fd8\u901a\u8fc7\u53ef\u89e3\u91caAI\u63d0\u9ad8\u4e86\u7cfb\u7edf\u53ef\u4fe1\u5ea6\uff0c\u4e3a\u7269\u8054\u7f51\u5b89\u5168\u63d0\u4f9b\u4e86\u66f4\u53ef\u9760\u7684\u9632\u5fa1\u673a\u5236\u3002"}}
{"id": "2511.06212", "categories": ["cs.CR", "cs.AI"], "pdf": "https://arxiv.org/pdf/2511.06212", "abs": "https://arxiv.org/abs/2511.06212", "authors": ["Seif Ikbarieh", "Kshitiz Aryal", "Maanak Gupta"], "title": "RAG-targeted Adversarial Attack on LLM-based Threat Detection and Mitigation Framework", "comment": null, "summary": "The rapid expansion of the Internet of Things (IoT) is reshaping communication and operational practices across industries, but it also broadens the attack surface and increases susceptibility to security breaches. Artificial Intelligence has become a valuable solution in securing IoT networks, with Large Language Models (LLMs) enabling automated attack behavior analysis and mitigation suggestion in Network Intrusion Detection Systems (NIDS). Despite advancements, the use of LLMs in such systems further expands the attack surface, putting entire networks at risk by introducing vulnerabilities such as prompt injection and data poisoning. In this work, we attack an LLM-based IoT attack analysis and mitigation framework to test its adversarial robustness. We construct an attack description dataset and use it in a targeted data poisoning attack that applies word-level, meaning-preserving perturbations to corrupt the Retrieval-Augmented Generation (RAG) knowledge base of the framework. We then compare pre-attack and post-attack mitigation responses from the target model, ChatGPT-5 Thinking, to measure the impact of the attack on model performance, using an established evaluation rubric designed for human experts and judge LLMs. Our results show that small perturbations degrade LLM performance by weakening the linkage between observed network traffic features and attack behavior, and by reducing the specificity and practicality of recommended mitigations for resource-constrained devices.", "AI": {"tldr": "\u672c\u7814\u7a76\u5bf9\u57fa\u4e8eLLM\u7684\u7269\u8054\u7f51\u653b\u51fb\u5206\u6790\u6846\u67b6\u8fdb\u884c\u5bf9\u6297\u6027\u653b\u51fb\u6d4b\u8bd5\uff0c\u901a\u8fc7\u6570\u636e\u6295\u6bd2\u653b\u51fb\u7834\u574fRAG\u77e5\u8bc6\u5e93\uff0c\u7ed3\u679c\u663e\u793a\u5fae\u5c0f\u6270\u52a8\u4f1a\u663e\u8457\u964d\u4f4eLLM\u6027\u80fd\u3002", "motivation": "\u968f\u7740\u7269\u8054\u7f51\u5feb\u901f\u53d1\u5c55\uff0cAI\u7279\u522b\u662fLLM\u88ab\u7528\u4e8e\u7f51\u7edc\u5b89\u5168\u9632\u62a4\uff0c\u4f46LLM\u672c\u8eab\u4e5f\u5e26\u6765\u4e86\u65b0\u7684\u653b\u51fb\u9762\uff0c\u5982\u63d0\u793a\u6ce8\u5165\u548c\u6570\u636e\u6295\u6bd2\u7b49\u6f0f\u6d1e\uff0c\u9700\u8981\u6d4b\u8bd5\u5176\u5bf9\u6297\u9c81\u68d2\u6027\u3002", "method": "\u6784\u5efa\u653b\u51fb\u63cf\u8ff0\u6570\u636e\u96c6\uff0c\u5b9e\u65bd\u6709\u9488\u5bf9\u6027\u7684\u6570\u636e\u6295\u6bd2\u653b\u51fb\uff0c\u5bf9RAG\u77e5\u8bc6\u5e93\u8fdb\u884c\u8bcd\u7ea7\u3001\u610f\u4e49\u4fdd\u6301\u7684\u6270\u52a8\uff0c\u6bd4\u8f83\u653b\u51fb\u524d\u540eChatGPT-5 Thinking\u7684\u7f13\u89e3\u54cd\u5e94\u3002", "result": "\u5fae\u5c0f\u6270\u52a8\u4f1a\u524a\u5f31\u7f51\u7edc\u6d41\u91cf\u7279\u5f81\u4e0e\u653b\u51fb\u884c\u4e3a\u4e4b\u95f4\u7684\u5173\u8054\uff0c\u964d\u4f4e\u8d44\u6e90\u53d7\u9650\u8bbe\u5907\u7f13\u89e3\u5efa\u8bae\u7684\u5177\u4f53\u6027\u548c\u5b9e\u7528\u6027\uff0c\u4ece\u800c\u663e\u8457\u964d\u4f4eLLM\u6027\u80fd\u3002", "conclusion": "LLM\u5728\u7269\u8054\u7f51\u5b89\u5168\u5e94\u7528\u4e2d\u5bf9\u6570\u636e\u6295\u6bd2\u653b\u51fb\u5f88\u8106\u5f31\uff0c\u9700\u8981\u66f4\u5f3a\u7684\u9632\u5fa1\u673a\u5236\u6765\u786e\u4fdd\u5176\u5728\u7f51\u7edc\u5b89\u5168\u7cfb\u7edf\u4e2d\u7684\u53ef\u9760\u6027\u3002"}}
{"id": "2511.06220", "categories": ["cs.CR", "cs.SE"], "pdf": "https://arxiv.org/pdf/2511.06220", "abs": "https://arxiv.org/abs/2511.06220", "authors": ["Mohammad Farhad", "Sabbir Rahman", "Shuvalaxmi Dass"], "title": "HYDRA: A Hybrid Heuristic-Guided Deep Representation Architecture for Predicting Latent Zero-Day Vulnerabilities in Patched Functions", "comment": null, "summary": "Software security testing, particularly when enhanced with deep learning models, has become a powerful approach for improving software quality, enabling faster detection of known flaws in source code. However, many approaches miss post-fix latent vulnerabilities that remain even after patches typically due to incomplete fixes or overlooked issues may later lead to zero-day exploits. In this paper, we propose $HYDRA$, a $Hy$brid heuristic-guided $D$eep $R$epresentation $A$rchitecture for predicting latent zero-day vulnerabilities in patched functions that combines rule-based heuristics with deep representation learning to detect latent risky code patterns that may persist after patches. It integrates static vulnerability rules, GraphCodeBERT embeddings, and a Variational Autoencoder (VAE) to uncover anomalies often missed by symbolic or neural models alone. We evaluate HYDRA in an unsupervised setting on patched functions from three diverse real-world software projects: Chrome, Android, and ImageMagick. Our results show HYDRA predicts 13.7%, 20.6%, and 24% of functions from Chrome, Android, and ImageMagick respectively as containing latent risks, including both heuristic matches and cases without heuristic matches ($None$) that may lead to zero-day vulnerabilities. It outperforms baseline models that rely solely on regex-derived features or their combination with embeddings, uncovering truly risky code variants that largely align with known heuristic patterns. These results demonstrate HYDRA's capability to surface hidden, previously undetected risks, advancing software security validation and supporting proactive zero-day vulnerabilities discovery.", "AI": {"tldr": "HYDRA\u662f\u4e00\u4e2a\u6df7\u5408\u542f\u53d1\u5f0f\u5f15\u5bfc\u7684\u6df1\u5ea6\u8868\u793a\u67b6\u6784\uff0c\u7528\u4e8e\u9884\u6d4b\u5df2\u4fee\u8865\u51fd\u6570\u4e2d\u7684\u6f5c\u5728\u96f6\u65e5\u6f0f\u6d1e\uff0c\u7ed3\u5408\u57fa\u4e8e\u89c4\u5219\u7684\u542f\u53d1\u5f0f\u65b9\u6cd5\u548c\u6df1\u5ea6\u8868\u793a\u5b66\u4e60\u6765\u68c0\u6d4b\u8865\u4e01\u540e\u53ef\u80fd\u6301\u7eed\u5b58\u5728\u7684\u98ce\u9669\u4ee3\u7801\u6a21\u5f0f\u3002", "motivation": "\u8bb8\u591a\u8f6f\u4ef6\u5b89\u5168\u6d4b\u8bd5\u65b9\u6cd5\u4f1a\u9057\u6f0f\u8865\u4e01\u540e\u7684\u6f5c\u5728\u6f0f\u6d1e\uff0c\u8fd9\u4e9b\u6f0f\u6d1e\u901a\u5e38\u7531\u4e8e\u4e0d\u5b8c\u6574\u7684\u4fee\u590d\u6216\u88ab\u5ffd\u89c6\u7684\u95ee\u9898\u5bfc\u81f4\uff0c\u53ef\u80fd\u540e\u6765\u6f14\u53d8\u4e3a\u96f6\u65e5\u6f0f\u6d1e\u3002", "method": "HYDRA\u7ed3\u5408\u9759\u6001\u6f0f\u6d1e\u89c4\u5219\u3001GraphCodeBERT\u5d4c\u5165\u548c\u53d8\u5206\u81ea\u7f16\u7801\u5668(VAE)\uff0c\u5728\u65e0\u76d1\u7763\u8bbe\u7f6e\u4e0b\u68c0\u6d4b\u7b26\u53f7\u6216\u795e\u7ecf\u6a21\u578b\u5355\u72ec\u4f7f\u7528\u65f6\u7ecf\u5e38\u9057\u6f0f\u7684\u5f02\u5e38\u3002", "result": "\u5728Chrome\u3001Android\u548cImageMagick\u4e09\u4e2a\u771f\u5b9e\u4e16\u754c\u8f6f\u4ef6\u9879\u76ee\u4e2d\uff0cHYDRA\u5206\u522b\u9884\u6d4b13.7%\u300120.6%\u548c24%\u7684\u51fd\u6570\u5305\u542b\u6f5c\u5728\u98ce\u9669\uff0c\u5305\u62ec\u542f\u53d1\u5f0f\u5339\u914d\u548c\u65e0\u542f\u53d1\u5f0f\u5339\u914d\u7684\u60c5\u51b5\u3002", "conclusion": "HYDRA\u80fd\u591f\u53d1\u73b0\u9690\u85cf\u7684\u3001\u5148\u524d\u672a\u68c0\u6d4b\u5230\u7684\u98ce\u9669\uff0c\u63a8\u8fdb\u8f6f\u4ef6\u5b89\u5168\u9a8c\u8bc1\u5e76\u652f\u6301\u4e3b\u52a8\u7684\u96f6\u65e5\u6f0f\u6d1e\u53d1\u73b0\u3002"}}
{"id": "2511.06305", "categories": ["cs.CR", "cs.LG"], "pdf": "https://arxiv.org/pdf/2511.06305", "abs": "https://arxiv.org/abs/2511.06305", "authors": ["Edwige Cyffers"], "title": "Setting $\\varepsilon$ is not the Issue in Differential Privacy", "comment": "Accepted to NeurIPS Position Paper track", "summary": "This position paper argues that setting the privacy budget in differential privacy should not be viewed as an important limitation of differential privacy compared to alternative methods for privacy-preserving machine learning. The so-called problem of interpreting the privacy budget is often presented as a major hindrance to the wider adoption of differential privacy in real-world deployments and is sometimes used to promote alternative mitigation techniques for data protection. We believe this misleads decision-makers into choosing unsafe methods. We argue that the difficulty in interpreting privacy budgets does not stem from the definition of differential privacy itself, but from the intrinsic difficulty of estimating privacy risks in context, a challenge that any rigorous method for privacy risk assessment face. Moreover, we claim that any sound method for estimating privacy risks should, given the current state of research, be expressible within the differential privacy framework or justify why it cannot.", "AI": {"tldr": "\u672c\u6587\u8ba4\u4e3a\u5dee\u5206\u9690\u79c1\u7684\u9690\u79c1\u9884\u7b97\u4e0d\u5e94\u88ab\u89c6\u4e3a\u5176\u76f8\u5bf9\u4e8e\u5176\u4ed6\u9690\u79c1\u4fdd\u62a4\u65b9\u6cd5\u7684\u91cd\u8981\u9650\u5236\uff0c\u6307\u51fa\u9690\u79c1\u9884\u7b97\u89e3\u91ca\u56f0\u96be\u6e90\u4e8e\u9690\u79c1\u98ce\u9669\u8bc4\u4f30\u7684\u5185\u5728\u6311\u6218\uff0c\u800c\u975e\u5dee\u5206\u9690\u79c1\u5b9a\u4e49\u672c\u8eab\u3002", "motivation": "\u53cd\u9a73\u5c06\u9690\u79c1\u9884\u7b97\u89e3\u91ca\u95ee\u9898\u4f5c\u4e3a\u5dee\u5206\u9690\u79c1\u4e3b\u8981\u9650\u5236\u7684\u89c2\u70b9\uff0c\u9632\u6b62\u51b3\u7b56\u8005\u56e0\u6b64\u9009\u62e9\u4e0d\u5b89\u5168\u7684\u66ff\u4ee3\u65b9\u6cd5\uff0c\u6f84\u6e05\u9690\u79c1\u98ce\u9669\u8bc4\u4f30\u7684\u56fa\u6709\u56f0\u96be\u3002", "method": "\u901a\u8fc7\u7acb\u573a\u8bba\u8bc1\uff0c\u5206\u6790\u9690\u79c1\u9884\u7b97\u89e3\u91ca\u56f0\u96be\u7684\u672c\u8d28\u6839\u6e90\uff0c\u6307\u51fa\u4efb\u4f55\u4e25\u8c28\u7684\u9690\u79c1\u98ce\u9669\u8bc4\u4f30\u65b9\u6cd5\u90fd\u4f1a\u9762\u4e34\u7c7b\u4f3c\u6311\u6218\u3002", "result": "\u8bba\u8bc1\u4e86\u9690\u79c1\u9884\u7b97\u89e3\u91ca\u56f0\u96be\u5e76\u975e\u5dee\u5206\u9690\u79c1\u7279\u6709\uff0c\u800c\u662f\u9690\u79c1\u98ce\u9669\u8bc4\u4f30\u7684\u666e\u904d\u6311\u6218\uff0c\u4e14\u4efb\u4f55\u5408\u7406\u7684\u9690\u79c1\u98ce\u9669\u4f30\u8ba1\u65b9\u6cd5\u90fd\u5e94\u80fd\u5728\u5dee\u5206\u9690\u79c1\u6846\u67b6\u5185\u8868\u8fbe\u3002", "conclusion": "\u5dee\u5206\u9690\u79c1\u6846\u67b6\u4ecd\u7136\u662f\u9690\u79c1\u4fdd\u62a4\u7684\u4e25\u8c28\u65b9\u6cd5\uff0c\u9690\u79c1\u9884\u7b97\u4e0d\u5e94\u88ab\u89c6\u4e3a\u5176\u5e94\u7528\u7684\u4e3b\u8981\u969c\u788d\uff0c\u51b3\u7b56\u8005\u4e0d\u5e94\u56e0\u6b64\u9009\u62e9\u4e0d\u5b89\u5168\u7684\u66ff\u4ee3\u65b9\u6848\u3002"}}
{"id": "2511.06336", "categories": ["cs.CR"], "pdf": "https://arxiv.org/pdf/2511.06336", "abs": "https://arxiv.org/abs/2511.06336", "authors": ["Chengcai Liu", "Siwei Chen", "Zejun Xiang", "Shasha Zhang", "Xiangyong Zeng"], "title": "Enhancing Deep Learning-Based Rotational-XOR Attacks on Lightweight Block Ciphers Simon32/64 and Simeck32/64", "comment": null, "summary": "At CRYPTO 2019, Gohr pioneered neural cryptanalysis by introducing differential-based neural distinguishers to attack Speck32/64, establishing a novel paradigm combining deep learning with differential cryptanalysis.Since then, constructing neural distinguishers has become a significant approach to achieving the deep learning-based cryptanalysis for block ciphers.This paper advances rotational-XOR (RX) attacks through neural networks, focusing on optimizing distinguishers and presenting key-recovery attacks for the lightweight block ciphers Simon32/64 and Simeck32/64.In particular, we first construct the fundamental data formats specially designed for training RX-neural distinguishers by refining the existing data formats for differential-neural distinguishers. Based on these data formats, we systematically identify optimal RX-differences with Hamming weights 1 and 2 that develop high-accuracy RX-neural distinguishers. Then, through innovative application of the bit sensitivity test, we achieve significant compression of data format without sacrificing the distinguisher accuracy. This optimization enables us to add more multi-ciphertext pairs into the data formats, further strengthening the performance of RX-neural distinguishers. As an application, we obtain 14- and 17-round RX-neural distinguishers for Simon32/64 and Simeck32/64, which improves the previous ones by 3 and 2 rounds, respectively.In addition, we propose two novel techniques, key bit sensitivity test and the joint wrong key response, to tackle the challenge of applying Bayesian's key-recovery strategy to the target cipher that adopts nonlinear key schedule in the related-key setting without considering of weak-key space. By this, we can straightforwardly mount a 17-round key-recovery attack on Simeck32/64 based on the improved 16-round RX-nerual distinguisher. To the best of our knowledge, the presented RX-neural......", "AI": {"tldr": "\u672c\u6587\u901a\u8fc7\u795e\u7ecf\u7f51\u7edc\u63a8\u8fdb\u65cb\u8f6c\u5f02\u6216(RX)\u653b\u51fb\uff0c\u9488\u5bf9\u8f7b\u91cf\u7ea7\u5206\u7ec4\u5bc6\u7801Simon32/64\u548cSimeck32/64\u4f18\u5316\u533a\u5206\u5668\u5e76\u5b9e\u73b0\u5bc6\u94a5\u6062\u590d\u653b\u51fb\u3002", "motivation": "\u81eaGohr\u5728CRYPTO 2019\u5f00\u521b\u795e\u7ecf\u5bc6\u7801\u5206\u6790\u4ee5\u6765\uff0c\u6784\u5efa\u795e\u7ecf\u533a\u5206\u5668\u5df2\u6210\u4e3a\u5b9e\u73b0\u57fa\u4e8e\u6df1\u5ea6\u5b66\u4e60\u7684\u5bc6\u7801\u5206\u6790\u7684\u91cd\u8981\u65b9\u6cd5\u3002\u672c\u6587\u65e8\u5728\u901a\u8fc7\u795e\u7ecf\u7f51\u7edc\u63a8\u8fdbRX\u653b\u51fb\uff0c\u63d0\u9ad8\u5bf9\u8f7b\u91cf\u7ea7\u5206\u7ec4\u5bc6\u7801\u7684\u5206\u6790\u80fd\u529b\u3002", "method": "1. \u4e13\u95e8\u8bbe\u8ba1\u8bad\u7ec3RX\u795e\u7ecf\u533a\u5206\u5668\u7684\u6570\u636e\u683c\u5f0f\uff1b2. \u7cfb\u7edf\u8bc6\u522bHamming\u6743\u91cd\u4e3a1\u548c2\u7684\u6700\u4f18RX\u5dee\u5f02\uff1b3. \u5e94\u7528\u6bd4\u7279\u654f\u611f\u5ea6\u6d4b\u8bd5\u538b\u7f29\u6570\u636e\u683c\u5f0f\uff1b4. \u63d0\u51fa\u5bc6\u94a5\u6bd4\u7279\u654f\u611f\u5ea6\u6d4b\u8bd5\u548c\u8054\u5408\u9519\u8bef\u5bc6\u94a5\u54cd\u5e94\u6280\u672f\u3002", "result": "\u83b7\u5f97\u4e86Simon32/64\u768414\u8f6e\u548cSimeck32/64\u768417\u8f6eRX\u795e\u7ecf\u533a\u5206\u5668\uff0c\u5206\u522b\u6bd4\u4e4b\u524d\u63d0\u9ad8\u4e863\u8f6e\u548c2\u8f6e\u3002\u57fa\u4e8e\u6539\u8fdb\u768416\u8f6eRX\u795e\u7ecf\u533a\u5206\u5668\uff0c\u5bf9Simeck32/64\u5b9e\u73b0\u4e8617\u8f6e\u5bc6\u94a5\u6062\u590d\u653b\u51fb\u3002", "conclusion": "\u672c\u6587\u6210\u529f\u5c06\u795e\u7ecf\u7f51\u7edc\u5e94\u7528\u4e8eRX\u5bc6\u7801\u5206\u6790\uff0c\u663e\u8457\u63d0\u9ad8\u4e86\u5bf9Simon32/64\u548cSimeck32/64\u7684\u5206\u6790\u80fd\u529b\uff0c\u5e76\u63d0\u51fa\u4e86\u514b\u670d\u975e\u7ebf\u6027\u5bc6\u94a5\u8c03\u5ea6\u6311\u6218\u7684\u65b0\u6280\u672f\u3002"}}
{"id": "2511.06390", "categories": ["cs.CR", "cs.AI"], "pdf": "https://arxiv.org/pdf/2511.06390", "abs": "https://arxiv.org/abs/2511.06390", "authors": ["Suqing Wang", "Ziyang Ma", "Xinyi Li", "Zuchao Li"], "title": "Ghost in the Transformer: Tracing LLM Lineage with SVD-Fingerprint", "comment": "Accepted at AAAI 2026 (Oral)", "summary": "Large Language Models (LLMs) have rapidly advanced and are widely adopted across diverse fields. Due to the substantial computational cost and data requirements of training from scratch, many developers choose to fine-tune or modify existing open-source models. While most adhere to open-source licenses, some falsely claim original training despite clear derivation from public models. This raises pressing concerns about intellectual property protection and highlights the need for reliable methods to verify model provenance. In this paper, we propose GhostSpec, a lightweight yet effective method for verifying LLM lineage without access to training data or modification of model behavior. Our approach constructs compact and robust fingerprints by applying singular value decomposition (SVD) to invariant products of internal attention weight matrices, effectively capturing the structural identity of a model. Unlike watermarking or output-based methods, GhostSpec is fully data-free, non-invasive, and computationally efficient. It demonstrates strong robustness to sequential fine-tuning, pruning, block expansion, and even adversarial transformations. Extensive experiments show that GhostSpec can reliably trace the lineage of transformed models with minimal overhead. By offering a practical solution for model verification and reuse tracking, our method contributes to the protection of intellectual property and fosters a transparent, trustworthy ecosystem for large-scale language models.", "AI": {"tldr": "GhostSpec\u662f\u4e00\u79cd\u8f7b\u91cf\u7ea7\u65b9\u6cd5\uff0c\u901a\u8fc7SVD\u5206\u89e3\u5185\u90e8\u6ce8\u610f\u529b\u6743\u91cd\u77e9\u9635\u7684\u4e0d\u53d8\u79ef\u6765\u6784\u5efa\u6a21\u578b\u6307\u7eb9\uff0c\u65e0\u9700\u8bad\u7ec3\u6570\u636e\u5373\u53ef\u9a8c\u8bc1LLM\u7684\u8840\u7edf\uff0c\u4fdd\u62a4\u77e5\u8bc6\u4ea7\u6743\u3002", "motivation": "\u7531\u4e8e\u8bb8\u591a\u5f00\u53d1\u8005\u57fa\u4e8e\u73b0\u6709\u5f00\u6e90\u6a21\u578b\u8fdb\u884c\u5fae\u8c03\u4f46\u865a\u5047\u58f0\u79f0\u539f\u521b\u8bad\u7ec3\uff0c\u9700\u8981\u53ef\u9760\u7684\u65b9\u6cd5\u6765\u9a8c\u8bc1\u6a21\u578b\u6765\u6e90\uff0c\u4fdd\u62a4\u77e5\u8bc6\u4ea7\u6743\u3002", "method": "\u5e94\u7528\u5947\u5f02\u503c\u5206\u89e3(SVD)\u5230\u5185\u90e8\u6ce8\u610f\u529b\u6743\u91cd\u77e9\u9635\u7684\u4e0d\u53d8\u79ef\uff0c\u6784\u5efa\u7d27\u51d1\u4e14\u9c81\u68d2\u7684\u6a21\u578b\u6307\u7eb9\uff0c\u6355\u6349\u6a21\u578b\u7684\u7ed3\u6784\u7279\u5f81\u3002", "result": "\u5b9e\u9a8c\u8868\u660eGhostSpec\u80fd\u53ef\u9760\u8ffd\u8e2a\u7ecf\u8fc7\u5fae\u8c03\u3001\u526a\u679d\u3001\u5757\u6269\u5c55\u751a\u81f3\u5bf9\u6297\u6027\u53d8\u6362\u7684\u6a21\u578b\u8840\u7edf\uff0c\u8ba1\u7b97\u5f00\u9500\u6781\u5c0f\u3002", "conclusion": "GhostSpec\u4e3a\u6a21\u578b\u9a8c\u8bc1\u548c\u91cd\u7528\u8ffd\u8e2a\u63d0\u4f9b\u4e86\u5b9e\u7528\u89e3\u51b3\u65b9\u6848\uff0c\u6709\u52a9\u4e8e\u4fdd\u62a4\u77e5\u8bc6\u4ea7\u6743\u5e76\u4fc3\u8fdb\u900f\u660e\u53ef\u4fe1\u7684LLM\u751f\u6001\u7cfb\u7edf\u3002"}}
{"id": "2511.06429", "categories": ["cs.CR"], "pdf": "https://arxiv.org/pdf/2511.06429", "abs": "https://arxiv.org/abs/2511.06429", "authors": ["Felipe Casta\u00f1o", "Constantinos Patsakis", "Francesco Zola", "Fran Casino"], "title": "Inside LockBit: Technical, Behavioral, and Financial Anatomy of a Ransomware Empire", "comment": "Accepted for publication in eCrime 2025", "summary": "LockBit has evolved from an obscure Ransomware-as-a-Service newcomer in 2019 to the most prolific ransomware franchise of 2024. Leveraging a recently leaked MySQL dump of the gang's management panel, this study offers an end-to-end reconstruction of LockBit's technical, behavioral, and financial apparatus. We recall the family's version timeline and map its tactics, techniques, and procedures to MITRE ATT&CK, highlighting the incremental hardening that distinguishes LockBit 3.0 from its predecessors. We then analyze 51 negotiation chat logs using natural-language embeddings and clustering to infer a canonical interaction playbook, revealing recurrent rhetorical stages that underpin the double-extortion strategy. Finally, we trace 19 Bitcoin addresses related to ransom payment chains, revealing two distinct patterns based on different laundering phases. In both cases, a small portion of the ransom is immediately split into long-lived addresses (presumably retained by the group as profit and to finance further operations) while the remainder is ultimately aggregated into two high-volume addresses before likely being sent to the affiliate. These two collector addresses appear to belong to distinct exchanges, each processing over 200k BTC. The combined evidence portrays LockBit as a tightly integrated criminal service whose resilience rests on rapid code iteration, script-driven social engineering, and industrial-scale cash-out pipelines.", "AI": {"tldr": "LockBit\u4ece2019\u5e74\u7684\u65b0\u5174\u52d2\u7d22\u8f6f\u4ef6\u5373\u670d\u52a1\u53d1\u5c55\u4e3a2024\u5e74\u6700\u6d3b\u8dc3\u7684\u52d2\u7d22\u8f6f\u4ef6\u5bb6\u65cf\uff0c\u7814\u7a76\u901a\u8fc7\u5206\u6790\u5176\u7ba1\u7406\u9762\u677f\u6570\u636e\u3001\u8c08\u5224\u804a\u5929\u8bb0\u5f55\u548c\u6bd4\u7279\u5e01\u652f\u4ed8\u94fe\uff0c\u63ed\u793a\u4e86\u5176\u6280\u672f\u6f14\u8fdb\u3001\u793e\u4ea4\u5de5\u7a0b\u7b56\u7565\u548c\u8d44\u91d1\u6d17\u94b1\u6a21\u5f0f\u3002", "motivation": "\u7814\u7a76LockBit\u5982\u4f55\u4ece\u65b0\u5174\u52d2\u7d22\u8f6f\u4ef6\u53d1\u5c55\u4e3a\u6700\u6d3b\u8dc3\u7684\u72af\u7f6a\u670d\u52a1\uff0c\u5206\u6790\u5176\u6280\u672f\u8fed\u4ee3\u3001\u793e\u4ea4\u5de5\u7a0b\u7b56\u7565\u548c\u8d44\u91d1\u6d17\u94b1\u673a\u5236\uff0c\u4ee5\u7406\u89e3\u5176\u72af\u7f6a\u751f\u6001\u7cfb\u7edf\u7684\u8fd0\u4f5c\u6a21\u5f0f\u3002", "method": "\u4f7f\u7528\u6cc4\u9732\u7684MySQL\u7ba1\u7406\u9762\u677f\u6570\u636e\u8fdb\u884c\u7aef\u5230\u7aef\u91cd\u5efa\uff0c\u5206\u679051\u4e2a\u8c08\u5224\u804a\u5929\u8bb0\u5f55\u7684\u81ea\u7136\u8bed\u8a00\u5d4c\u5165\u548c\u805a\u7c7b\uff0c\u8ffd\u8e2a19\u4e2a\u6bd4\u7279\u5e01\u5730\u5740\u7684\u652f\u4ed8\u94fe\u6a21\u5f0f\u3002", "result": "\u53d1\u73b0LockBit 3.0\u76f8\u6bd4\u524d\u4ee3\u6709\u663e\u8457\u6280\u672f\u5f3a\u5316\uff0c\u8c08\u5224\u8fc7\u7a0b\u9075\u5faa\u6807\u51c6\u5316\u7684\u4fee\u8f9e\u9636\u6bb5\uff0c\u8d44\u91d1\u6d17\u94b1\u5448\u73b0\u4e24\u79cd\u4e0d\u540c\u6a21\u5f0f\uff1a\u5c0f\u90e8\u5206\u8d44\u91d1\u957f\u671f\u7559\u5b58\u7528\u4e8e\u8fd0\u8425\uff0c\u5927\u90e8\u5206\u8d44\u91d1\u6700\u7ec8\u6c47\u96c6\u5230\u4e24\u4e2a\u9ad8\u4ea4\u6613\u91cf\u5730\u5740\u3002", "conclusion": "LockBit\u662f\u4e00\u4e2a\u9ad8\u5ea6\u6574\u5408\u7684\u72af\u7f6a\u670d\u52a1\uff0c\u5176\u97e7\u6027\u4f9d\u8d56\u4e8e\u5feb\u901f\u4ee3\u7801\u8fed\u4ee3\u3001\u811a\u672c\u5316\u793e\u4ea4\u5de5\u7a0b\u548c\u5de5\u4e1a\u89c4\u6a21\u7684\u8d44\u91d1\u6d17\u94b1\u6e20\u9053\u3002"}}
{"id": "2511.06512", "categories": ["cs.CR", "cs.LG"], "pdf": "https://arxiv.org/pdf/2511.06512", "abs": "https://arxiv.org/abs/2511.06512", "authors": ["Haonan Shi", "Guoli Wang", "Tu Ouyang", "An Wang"], "title": "EASE: Practical and Efficient Safety Alignment for Small Language Models", "comment": "Accepted to AAAI 2026", "summary": "Small language models (SLMs) are increasingly deployed on edge devices, making their safety alignment crucial yet challenging. Current shallow alignment methods that rely on direct refusal of malicious queries fail to provide robust protection, particularly against adversarial jailbreaks. While deliberative safety reasoning alignment offers deeper alignment for defending against sophisticated attacks, effectively implanting such reasoning capability in SLMs with limited capabilities remains an open challenge. Moreover, safety reasoning incurs significant computational overhead as models apply reasoning to nearly all queries, making it impractical for resource-constrained edge deployment scenarios that demand rapid responses. We propose EASE, a novel framework that enables practical and Efficient safety Alignment for Small languagE models. Our approach first identifies the optimal safety reasoning teacher that can effectively distill safety reasoning capabilities to SLMs. We then align models to selectively activate safety reasoning for dangerous adversarial jailbreak queries while providing direct responses to straightforward malicious queries and general helpful tasks. This selective mechanism enables small models to maintain robust safety guarantees against sophisticated attacks while preserving computational efficiency for benign interactions. Experimental results demonstrate that EASE reduces jailbreak attack success rates by up to 17% compared to shallow alignment methods while reducing inference overhead by up to 90% compared to deliberative safety reasoning alignment, making it practical for SLMs real-world edge deployments.", "AI": {"tldr": "EASE\u6846\u67b6\u4e3a\u5c0f\u578b\u8bed\u8a00\u6a21\u578b\u63d0\u4f9b\u9ad8\u6548\u5b89\u5168\u5bf9\u9f50\uff0c\u901a\u8fc7\u9009\u62e9\u6027\u6fc0\u6d3b\u5b89\u5168\u63a8\u7406\u673a\u5236\uff0c\u5728\u4fdd\u6301\u5b89\u5168\u6027\u7684\u540c\u65f6\u663e\u8457\u964d\u4f4e\u8ba1\u7b97\u5f00\u9500\u3002", "motivation": "\u5f53\u524d\u6d45\u5c42\u5bf9\u9f50\u65b9\u6cd5\u65e0\u6cd5\u6709\u6548\u9632\u5fa1\u5bf9\u6297\u6027\u8d8a\u72f1\u653b\u51fb\uff0c\u800c\u6df1\u601d\u719f\u8651\u7684\u5b89\u5168\u63a8\u7406\u5bf9\u9f50\u867d\u7136\u6548\u679c\u66f4\u597d\u4f46\u8ba1\u7b97\u5f00\u9500\u8fc7\u5927\uff0c\u4e0d\u9002\u5408\u8d44\u6e90\u53d7\u9650\u7684\u8fb9\u7f18\u8bbe\u5907\u90e8\u7f72\u3002", "method": "\u9996\u5148\u8bc6\u522b\u6700\u4f18\u5b89\u5168\u63a8\u7406\u6559\u5e08\u6a21\u578b\uff0c\u7136\u540e\u8bad\u7ec3\u5c0f\u578b\u6a21\u578b\u9009\u62e9\u6027\u6fc0\u6d3b\u5b89\u5168\u63a8\u7406\u673a\u5236\uff1a\u4ec5\u5bf9\u5371\u9669\u5bf9\u6297\u6027\u67e5\u8be2\u8fdb\u884c\u5b89\u5168\u63a8\u7406\uff0c\u5bf9\u76f4\u63a5\u6076\u610f\u67e5\u8be2\u548c\u4e00\u822c\u4efb\u52a1\u63d0\u4f9b\u76f4\u63a5\u54cd\u5e94\u3002", "result": "\u76f8\u6bd4\u6d45\u5c42\u5bf9\u9f50\u65b9\u6cd5\uff0cEASE\u5c06\u8d8a\u72f1\u653b\u51fb\u6210\u529f\u7387\u964d\u4f4e\u9ad8\u8fbe17%\uff1b\u76f8\u6bd4\u6df1\u601d\u719f\u8651\u5b89\u5168\u63a8\u7406\u5bf9\u9f50\uff0c\u63a8\u7406\u5f00\u9500\u964d\u4f4e\u9ad8\u8fbe90%\u3002", "conclusion": "EASE\u6846\u67b6\u4e3a\u5c0f\u578b\u8bed\u8a00\u6a21\u578b\u63d0\u4f9b\u4e86\u5b9e\u7528\u9ad8\u6548\u7684\u5b89\u5168\u5bf9\u9f50\u65b9\u6848\uff0c\u65e2\u4fdd\u6301\u4e86\u5bf9\u590d\u6742\u653b\u51fb\u7684\u9c81\u68d2\u5b89\u5168\u4fdd\u8bc1\uff0c\u53c8\u6ee1\u8db3\u4e86\u8fb9\u7f18\u90e8\u7f72\u573a\u666f\u5bf9\u8ba1\u7b97\u6548\u7387\u7684\u8981\u6c42\u3002"}}
{"id": "2511.06540", "categories": ["cs.CR", "cs.NI"], "pdf": "https://arxiv.org/pdf/2511.06540", "abs": "https://arxiv.org/abs/2511.06540", "authors": ["Sirus Shahini", "Robert Ricci"], "title": "CYPRESS: Transferring Secrets in the Shadow of Visible Packets", "comment": null, "summary": "Network steganography and covert communication channels have been studied extensively in the past. However, prior works offer minimal practical use for their proposed techniques and are limited to specific use cases and network protocols. In this paper, we show that covert channels in networking have a much greater potential for practical secret communication than what has been discussed before. We present a covert channel framework, CYPRESS, that creates a reliable hidden communication channel by mounting packets from secret network entities on regular packets that flow through the network, effectively transmitting a separate network traffic without generating new packets for it. CYPRESS establishes a consolidated decentralized framework in which different covert channels for various protocols are defined with their custom handler code that are plugged into the system and updated on-demand to evade detection. CYPRESS then chooses at run-time how and in what order the covert channels should be used for fragmentation and hidden transmission of data. We can reach up to 1.6MB/s of secret bandwidth in a network of ten users connected to the Internet. We demonstrate the robustness and reliability of our approach in secret communication through various security-sensitive real-world experiments. Our evaluations show that network protocols provide a notable opportunity for unconventional storage and hidden transmission of data to bypass different types of security measures and to hide the source of various cyber attacks.", "AI": {"tldr": "CYPRESS\u662f\u4e00\u4e2a\u9690\u853d\u901a\u4fe1\u6846\u67b6\uff0c\u901a\u8fc7\u5728\u5e38\u89c4\u7f51\u7edc\u6570\u636e\u5305\u4e0a\u642d\u8f7d\u79d8\u5bc6\u7f51\u7edc\u5b9e\u4f53\u7684\u6570\u636e\u5305\u6765\u521b\u5efa\u53ef\u9760\u7684\u9690\u853d\u901a\u4fe1\u901a\u9053\uff0c\u65e0\u9700\u4e3a\u79d8\u5bc6\u901a\u4fe1\u751f\u6210\u65b0\u7684\u6570\u636e\u5305\u3002", "motivation": "\u73b0\u6709\u7684\u7f51\u7edc\u9690\u5199\u548c\u9690\u853d\u901a\u4fe1\u901a\u9053\u7814\u7a76\u5b9e\u7528\u6027\u6709\u9650\uff0c\u4ec5\u9650\u4e8e\u7279\u5b9a\u7528\u4f8b\u548c\u7f51\u7edc\u534f\u8bae\u3002\u672c\u6587\u65e8\u5728\u5c55\u793a\u7f51\u7edc\u9690\u853d\u901a\u9053\u5728\u5b9e\u9645\u79d8\u5bc6\u901a\u4fe1\u4e2d\u5177\u6709\u6bd4\u4ee5\u5f80\u8ba8\u8bba\u66f4\u5927\u7684\u6f5c\u529b\u3002", "method": "CYPRESS\u5efa\u7acb\u4e86\u4e00\u4e2a\u7edf\u4e00\u7684\u53bb\u4e2d\u5fc3\u5316\u6846\u67b6\uff0c\u4e3a\u4e0d\u540c\u534f\u8bae\u5b9a\u4e49\u81ea\u5b9a\u4e49\u5904\u7406\u7a0b\u5e8f\u7684\u9690\u853d\u901a\u9053\uff0c\u5e76\u5728\u8fd0\u884c\u65f6\u9009\u62e9\u5982\u4f55\u4ee5\u53ca\u6309\u4ec0\u4e48\u987a\u5e8f\u4f7f\u7528\u8fd9\u4e9b\u901a\u9053\u8fdb\u884c\u6570\u636e\u5206\u7247\u548c\u9690\u85cf\u4f20\u8f93\u3002", "result": "\u572810\u4e2a\u7528\u6237\u8fde\u63a5\u5230\u4e92\u8054\u7f51\u7684\u7f51\u7edc\u4e2d\uff0c\u53ef\u4ee5\u8fbe\u5230\u9ad8\u8fbe1.6MB/s\u7684\u79d8\u5bc6\u5e26\u5bbd\u3002\u901a\u8fc7\u5404\u79cd\u5b89\u5168\u654f\u611f\u7684\u771f\u5b9e\u4e16\u754c\u5b9e\u9a8c\u8bc1\u660e\u4e86\u8be5\u65b9\u6cd5\u7684\u9c81\u68d2\u6027\u548c\u53ef\u9760\u6027\u3002", "conclusion": "\u7f51\u7edc\u534f\u8bae\u4e3a\u975e\u5e38\u89c4\u6570\u636e\u5b58\u50a8\u548c\u9690\u85cf\u4f20\u8f93\u63d0\u4f9b\u4e86\u663e\u8457\u673a\u4f1a\uff0c\u53ef\u4ee5\u7ed5\u8fc7\u4e0d\u540c\u7c7b\u578b\u7684\u5b89\u5168\u63aa\u65bd\u5e76\u9690\u85cf\u5404\u79cd\u7f51\u7edc\u653b\u51fb\u7684\u6765\u6e90\u3002"}}
{"id": "2511.06573", "categories": ["cs.CR", "cs.AI"], "pdf": "https://arxiv.org/pdf/2511.06573", "abs": "https://arxiv.org/abs/2511.06573", "authors": ["Biswajit Kumar Sahoo", "Pedro Machado", "Isibor Kennedy Ihianle", "Andreas Oikonomou", "Srinivas Boppu"], "title": "SteganoSNN: SNN-Based Audio-in-Image Steganography with Encryption", "comment": null, "summary": "Secure data hiding remains a fundamental challenge in digital communication, requiring a careful balance between computational efficiency and perceptual transparency. The balance between security and performance is increasingly fragile with the emergence of generative AI systems capable of autonomously generating and optimising sophisticated cryptanalysis and steganalysis algorithms, thereby accelerating the exposure of vulnerabilities in conventional data-hiding schemes.\n  This work introduces SteganoSNN, a neuromorphic steganographic framework that exploits spiking neural networks (SNNs) to achieve secure, low-power, and high-capacity multimedia data hiding. Digitised audio samples are converted into spike trains using leaky integrate-and-fire (LIF) neurons, encrypted via a modulo-based mapping scheme, and embedded into the least significant bits of RGBA image channels using a dithering mechanism to minimise perceptual distortion. Implemented in Python using NEST and realised on a PYNQ-Z2 FPGA, SteganoSNN attains real-time operation with an embedding capacity of 8 bits per pixel. Experimental evaluations on the DIV2K 2017 dataset demonstrate image fidelity between 40.4 dB and 41.35 dB in PSNR and SSIM values consistently above 0.97, surpassing SteganoGAN in computational efficiency and robustness. SteganoSNN establishes a foundation for neuromorphic steganography, enabling secure, energy-efficient communication for Edge-AI, IoT, and biomedical applications.", "AI": {"tldr": "SteganoSNN\u662f\u4e00\u4e2a\u57fa\u4e8e\u8109\u51b2\u795e\u7ecf\u7f51\u7edc\u7684\u9690\u5199\u6846\u67b6\uff0c\u80fd\u591f\u5728RGBA\u56fe\u50cf\u4e2d\u9690\u85cf\u97f3\u9891\u6570\u636e\uff0c\u5b9e\u73b0\u5b9e\u65f6\u3001\u4f4e\u529f\u8017\u3001\u9ad8\u5bb9\u91cf\u7684\u5b89\u5168\u901a\u4fe1\u3002", "motivation": "\u4f20\u7edf\u6570\u636e\u9690\u85cf\u65b9\u6848\u9762\u4e34\u751f\u6210\u5f0fAI\u7cfb\u7edf\u5e26\u6765\u7684\u5b89\u5168\u5a01\u80c1\uff0c\u9700\u8981\u5728\u8ba1\u7b97\u6548\u7387\u548c\u611f\u77e5\u900f\u660e\u5ea6\u4e4b\u95f4\u627e\u5230\u5e73\u8861\u3002", "method": "\u5c06\u6570\u5b57\u97f3\u9891\u6837\u672c\u901a\u8fc7LIF\u795e\u7ecf\u5143\u8f6c\u6362\u4e3a\u8109\u51b2\u5e8f\u5217\uff0c\u4f7f\u7528\u6a21\u6620\u5c04\u65b9\u6848\u52a0\u5bc6\uff0c\u5e76\u901a\u8fc7\u6296\u52a8\u673a\u5236\u5d4c\u5165\u5230RGBA\u56fe\u50cf\u901a\u9053\u7684\u6700\u4f4e\u6709\u6548\u4f4d\u4e2d\u3002", "result": "\u5728DIV2K 2017\u6570\u636e\u96c6\u4e0a\uff0cPSNR\u8fbe\u523040.4-41.35 dB\uff0cSSIM\u503c\u6301\u7eed\u9ad8\u4e8e0.97\uff0c\u8ba1\u7b97\u6548\u7387\u548c\u9c81\u68d2\u6027\u4f18\u4e8eSteganoGAN\u3002", "conclusion": "SteganoSNN\u4e3a\u795e\u7ecf\u5f62\u6001\u9690\u5199\u5b66\u5960\u5b9a\u4e86\u57fa\u7840\uff0c\u4e3a\u8fb9\u7f18AI\u3001\u7269\u8054\u7f51\u548c\u751f\u7269\u533b\u5b66\u5e94\u7528\u63d0\u4f9b\u5b89\u5168\u3001\u8282\u80fd\u7684\u901a\u4fe1\u65b9\u6848\u3002"}}
{"id": "2511.06659", "categories": ["cs.CR"], "pdf": "https://arxiv.org/pdf/2511.06659", "abs": "https://arxiv.org/abs/2511.06659", "authors": ["Jiawei Huang", "Aimin Wang", "Geng Sun", "Jiahui Li", "Jiacheng Wang", "Weijie Yuan", "Dusit Niyato", "Xianbin Wang"], "title": "Secure Low-altitude Maritime Communications via Intelligent Jamming", "comment": null, "summary": "Low-altitude wireless networks (LAWNs) have emerged as a viable solution for maritime communications. In these maritime LAWNs, unmanned aerial vehicles (UAVs) serve as practical low-altitude platforms for wireless communications due to their flexibility and ease of deployment. However, the open and clear UAV communication channels make maritime LAWNs vulnerable to eavesdropping attacks. Existing security approaches often assume eavesdroppers follow predefined trajectories, which fails to capture the dynamic movement patterns of eavesdroppers in realistic maritime environments. To address this challenge, we consider a low-altitude maritime communication system that employs intelligent jamming to counter dynamic eavesdroppers with uncertain positioning to enhance the physical layer security. Since such a system requires balancing the conflicting performance metrics of the secrecy rate and energy consumption of UAVs, we formulate a secure and energy-efficient maritime communication multi-objective optimization problem (SEMCMOP). To solve this dynamic and long-term optimization problem, we first reformulate it as a partially observable Markov decision process (POMDP). We then propose a novel soft actor-critic with conditional variational autoencoder (SAC-CVAE) algorithm, which is a deep reinforcement learning algorithm improved by generative artificial intelligence. Specifically, the SAC-CVAE algorithm employs advantage-conditioned latent representations to disentangle and optimize policies, while enhancing computational efficiency by reducing the state space dimension. Simulation results demonstrate that our proposed intelligent jamming approach achieves secure and energy-efficient maritime communications.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8eSAC-CVAE\u7b97\u6cd5\u7684\u667a\u80fd\u5e72\u6270\u65b9\u6cd5\uff0c\u7528\u4e8e\u4fdd\u62a4\u6d77\u4e0a\u4f4e\u7a7a\u65e0\u7ebf\u7f51\u7edc\u514d\u53d7\u52a8\u6001\u7a83\u542c\u8005\u653b\u51fb\uff0c\u5b9e\u73b0\u5b89\u5168\u4e14\u8282\u80fd\u7684\u901a\u4fe1\u3002", "motivation": "\u6d77\u4e0aLAWNs\u4e2d\u7684\u65e0\u4eba\u673a\u901a\u4fe1\u4fe1\u9053\u5f00\u653e\u4e14\u6e05\u6670\uff0c\u5bb9\u6613\u53d7\u5230\u7a83\u542c\u653b\u51fb\u3002\u73b0\u6709\u5b89\u5168\u65b9\u6cd5\u5047\u8bbe\u7a83\u542c\u8005\u9075\u5faa\u9884\u5b9a\u8f68\u8ff9\uff0c\u65e0\u6cd5\u6355\u6349\u771f\u5b9e\u6d77\u6d0b\u73af\u5883\u4e2d\u7a83\u542c\u8005\u7684\u52a8\u6001\u79fb\u52a8\u6a21\u5f0f\u3002", "method": "\u5c06\u95ee\u9898\u5efa\u6a21\u4e3a\u90e8\u5206\u53ef\u89c2\u6d4b\u9a6c\u5c14\u53ef\u592b\u51b3\u7b56\u8fc7\u7a0b(POMDP)\uff0c\u63d0\u51faSAC-CVAE\u7b97\u6cd5\uff08\u57fa\u4e8e\u6761\u4ef6\u53d8\u5206\u81ea\u7f16\u7801\u5668\u6539\u8fdb\u7684\u8f6f\u6f14\u5458-\u8bc4\u8bba\u5bb6\u7b97\u6cd5\uff09\uff0c\u5229\u7528\u4f18\u52bf\u6761\u4ef6\u6f5c\u5728\u8868\u793a\u6765\u89e3\u8026\u548c\u4f18\u5316\u7b56\u7565\uff0c\u5e76\u901a\u8fc7\u964d\u4f4e\u72b6\u6001\u7a7a\u95f4\u7ef4\u5ea6\u63d0\u9ad8\u8ba1\u7b97\u6548\u7387\u3002", "result": "\u4eff\u771f\u7ed3\u679c\u8868\u660e\uff0c\u6240\u63d0\u51fa\u7684\u667a\u80fd\u5e72\u6270\u65b9\u6cd5\u80fd\u591f\u5b9e\u73b0\u5b89\u5168\u4e14\u8282\u80fd\u7684\u6d77\u4e0a\u901a\u4fe1\u3002", "conclusion": "SAC-CVAE\u7b97\u6cd5\u6709\u6548\u89e3\u51b3\u4e86\u52a8\u6001\u7a83\u542c\u8005\u5b9a\u4f4d\u4e0d\u786e\u5b9a\u7684\u95ee\u9898\uff0c\u5728\u4fdd\u5bc6\u7387\u548c\u65e0\u4eba\u673a\u80fd\u8017\u4e4b\u95f4\u53d6\u5f97\u4e86\u826f\u597d\u5e73\u8861\uff0c\u4e3a\u6d77\u4e0a\u4f4e\u7a7a\u65e0\u7ebf\u7f51\u7edc\u5b89\u5168\u63d0\u4f9b\u4e86\u53ef\u884c\u89e3\u51b3\u65b9\u6848\u3002"}}
{"id": "2511.06742", "categories": ["cs.CR"], "pdf": "https://arxiv.org/pdf/2511.06742", "abs": "https://arxiv.org/abs/2511.06742", "authors": ["Adam Piaseczny", "Eric Ruzomberka", "Rohit Parasnis", "Christopher G. Brinton"], "title": "Adversarial Node Placement in Decentralized Federated Learning: Maximum Spanning-Centrality Strategy and Performance Analysis", "comment": "IEEE Internet of Things Journal", "summary": "As Federated Learning (FL) becomes more widespread, there is growing interest in its decentralized variants. Decentralized FL leverages the benefits of fast and energy-efficient device-to-device communications to obviate the need for a central server. However, this opens the door to new security vulnerabilities as well. While FL security has been a popular research topic, the role of adversarial node placement in decentralized FL remains largely unexplored. This paper addresses this gap by evaluating the impact of various coordinated adversarial node placement strategies on decentralized FL's model training performance. We adapt two threads of placement strategies to this context: maximum span-based algorithms, and network centrality-based approaches. Building on them, we propose a novel attack strategy, MaxSpAN-FL, which is a hybrid between these paradigms that adjusts node placement probabilistically based on network topology characteristics. Numerical experiments demonstrate that our attack consistently induces the largest degradation in decentralized FL models compared with baseline schemes across various network configurations and numbers of coordinating adversaries. We also provide theoretical support for why eigenvector centrality-based attacks are suboptimal in decentralized FL. Overall, our findings provide valuable insights into the vulnerabilities of decentralized FL systems, setting the stage for future research aimed at developing more secure and robust decentralized FL frameworks.", "AI": {"tldr": "\u672c\u6587\u7814\u7a76\u4e86\u53bb\u4e2d\u5fc3\u5316\u8054\u90a6\u5b66\u4e60\u4e2d\u5bf9\u6297\u6027\u8282\u70b9\u653e\u7f6e\u7b56\u7565\u7684\u5f71\u54cd\uff0c\u63d0\u51fa\u4e86\u4e00\u79cd\u6df7\u5408\u653b\u51fb\u65b9\u6cd5MaxSpAN-FL\uff0c\u5e76\u8bc1\u660e\u4e86\u5176\u5728\u5404\u79cd\u7f51\u7edc\u914d\u7f6e\u4e0b\u5bf9\u6a21\u578b\u6027\u80fd\u7684\u7834\u574f\u6548\u679c\u6700\u5927\u3002", "motivation": "\u968f\u7740\u8054\u90a6\u5b66\u4e60\u7684\u666e\u53ca\uff0c\u5176\u53bb\u4e2d\u5fc3\u5316\u53d8\u4f53\u53d7\u5230\u5173\u6ce8\uff0c\u4f46\u53bb\u4e2d\u5fc3\u5316FL\u5f15\u5165\u4e86\u65b0\u7684\u5b89\u5168\u6f0f\u6d1e\uff0c\u7279\u522b\u662f\u5bf9\u6297\u6027\u8282\u70b9\u653e\u7f6e\u7b56\u7565\u7684\u5f71\u54cd\u5c1a\u672a\u88ab\u5145\u5206\u63a2\u7d22\u3002", "method": "\u91c7\u7528\u4e86\u4e24\u79cd\u8282\u70b9\u653e\u7f6e\u7b56\u7565\uff1a\u57fa\u4e8e\u6700\u5927\u8de8\u5ea6\u7684\u7b97\u6cd5\u548c\u57fa\u4e8e\u7f51\u7edc\u4e2d\u5fc3\u6027\u7684\u65b9\u6cd5\uff0c\u5e76\u63d0\u51fa\u4e86\u6df7\u5408\u653b\u51fb\u7b56\u7565MaxSpAN-FL\uff0c\u8be5\u7b56\u7565\u6839\u636e\u7f51\u7edc\u62d3\u6251\u7279\u5f81\u6982\u7387\u6027\u5730\u8c03\u6574\u8282\u70b9\u653e\u7f6e\u3002", "result": "\u6570\u503c\u5b9e\u9a8c\u8868\u660e\uff0c\u4e0e\u57fa\u7ebf\u65b9\u6848\u76f8\u6bd4\uff0cMaxSpAN-FL\u653b\u51fb\u5728\u5404\u79cd\u7f51\u7edc\u914d\u7f6e\u548c\u5bf9\u6297\u8005\u6570\u91cf\u4e0b\u90fd\u80fd\u5bf9\u53bb\u4e2d\u5fc3\u5316FL\u6a21\u578b\u9020\u6210\u6700\u5927\u7684\u6027\u80fd\u4e0b\u964d\u3002", "conclusion": "\u7814\u7a76\u63ed\u793a\u4e86\u53bb\u4e2d\u5fc3\u5316FL\u7cfb\u7edf\u7684\u8106\u5f31\u6027\uff0c\u4e3a\u672a\u6765\u5f00\u53d1\u66f4\u5b89\u5168\u3001\u66f4\u9c81\u68d2\u7684\u53bb\u4e2d\u5fc3\u5316FL\u6846\u67b6\u5960\u5b9a\u4e86\u57fa\u7840\u3002"}}
{"id": "2511.06852", "categories": ["cs.CR", "cs.AI", "cs.LG", "cs.SE"], "pdf": "https://arxiv.org/pdf/2511.06852", "abs": "https://arxiv.org/abs/2511.06852", "authors": ["Peng Zhang", "peijie sun"], "title": "Differentiated Directional Intervention A Framework for Evading LLM Safety Alignment", "comment": "AAAI-26-AIA", "summary": "Safety alignment instills in Large Language Models (LLMs) a critical capacity to refuse malicious requests. Prior works have modeled this refusal mechanism as a single linear direction in the activation space. We posit that this is an oversimplification that conflates two functionally distinct neural processes: the detection of harm and the execution of a refusal. In this work, we deconstruct this single representation into a Harm Detection Direction and a Refusal Execution Direction. Leveraging this fine-grained model, we introduce Differentiated Bi-Directional Intervention (DBDI), a new white-box framework that precisely neutralizes the safety alignment at critical layer. DBDI applies adaptive projection nullification to the refusal execution direction while suppressing the harm detection direction via direct steering. Extensive experiments demonstrate that DBDI outperforms prominent jailbreaking methods, achieving up to a 97.88\\% attack success rate on models such as Llama-2. By providing a more granular and mechanistic framework, our work offers a new direction for the in-depth understanding of LLM safety alignment.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u65b0\u7684\u5b89\u5168\u5bf9\u9f50\u89e3\u6784\u65b9\u6cd5\uff0c\u5c06\u62d2\u7edd\u673a\u5236\u5206\u89e3\u4e3a\u4f24\u5bb3\u68c0\u6d4b\u548c\u62d2\u7edd\u6267\u884c\u4e24\u4e2a\u72ec\u7acb\u65b9\u5411\uff0c\u5e76\u5f00\u53d1\u4e86DBDI\u6846\u67b6\u6765\u7cbe\u786e\u7ed5\u8fc7LLM\u7684\u5b89\u5168\u9632\u62a4\u3002", "motivation": "\u73b0\u6709\u7814\u7a76\u5c06LLM\u7684\u62d2\u7edd\u673a\u5236\u7b80\u5316\u4e3a\u6fc0\u6d3b\u7a7a\u95f4\u4e2d\u7684\u5355\u4e00\u7ebf\u6027\u65b9\u5411\uff0c\u8fd9\u79cd\u8fc7\u5ea6\u7b80\u5316\u6df7\u6dc6\u4e86\u4f24\u5bb3\u68c0\u6d4b\u548c\u62d2\u7edd\u6267\u884c\u4e24\u4e2a\u4e0d\u540c\u7684\u795e\u7ecf\u8fc7\u7a0b\u3002", "method": "\u63d0\u51fa\u4e86\u533a\u5206\u6027\u53cc\u5411\u5e72\u9884\uff08DBDI\uff09\u6846\u67b6\uff0c\u901a\u8fc7\u81ea\u9002\u5e94\u6295\u5f71\u6d88\u9664\u6765\u4e2d\u548c\u62d2\u7edd\u6267\u884c\u65b9\u5411\uff0c\u540c\u65f6\u901a\u8fc7\u76f4\u63a5\u5f15\u5bfc\u6291\u5236\u4f24\u5bb3\u68c0\u6d4b\u65b9\u5411\u3002", "result": "\u5728Llama-2\u7b49\u6a21\u578b\u4e0a\u5b9e\u73b0\u4e86\u9ad8\u8fbe97.88%\u7684\u653b\u51fb\u6210\u529f\u7387\uff0c\u663e\u8457\u4f18\u4e8e\u73b0\u6709\u7684\u8d8a\u72f1\u65b9\u6cd5\u3002", "conclusion": "\u901a\u8fc7\u63d0\u4f9b\u66f4\u7ec6\u7c92\u5ea6\u7684\u673a\u5236\u6846\u67b6\uff0c\u4e3a\u6df1\u5165\u7406\u89e3LLM\u5b89\u5168\u5bf9\u9f50\u63d0\u4f9b\u4e86\u65b0\u65b9\u5411\u3002"}}
{"id": "2511.06871", "categories": ["cs.CR", "cs.DS"], "pdf": "https://arxiv.org/pdf/2511.06871", "abs": "https://arxiv.org/abs/2511.06871", "authors": ["Ethan Leeman", "Pasin Manurangsi"], "title": "Nearly-Optimal Private Selection via Gaussian Mechanism", "comment": null, "summary": "Steinke (2025) recently asked the following intriguing open question: Can we solve the differentially private selection problem with nearly-optimal error by only (adaptively) invoking Gaussian mechanism on low-sensitivity queries? We resolve this question positively. In particular, for a candidate set $\\mathcal{Y}$, we achieve error guarantee of $\\tilde{O}(\\log |\\mathcal{Y}|)$, which is within a factor of $(\\log \\log |\\mathcal{Y}|)^{O(1)}$ of the exponential mechanism (McSherry and Talwar, 2007). This improves on Steinke's mechanism which achieves an error of $O(\\log^{3/2} |\\mathcal{Y}|)$.", "AI": {"tldr": "\u672c\u6587\u89e3\u51b3\u4e86Steinke(2025)\u63d0\u51fa\u7684\u5f00\u653e\u6027\u95ee\u9898\uff1a\u4ec5\u901a\u8fc7\uff08\u81ea\u9002\u5e94\u5730\uff09\u8c03\u7528\u9ad8\u65af\u673a\u5236\u5904\u7406\u4f4e\u654f\u611f\u5ea6\u67e5\u8be2\uff0c\u80fd\u5426\u5b9e\u73b0\u8fd1\u4f3c\u6700\u4f18\u8bef\u5dee\u7684\u5dee\u5206\u9690\u79c1\u9009\u62e9\u95ee\u9898\u3002\u4f5c\u8005\u7ed9\u51fa\u4e86\u80af\u5b9a\u7b54\u6848\uff0c\u5b9e\u73b0\u4e86$\\tilde{O}(\\log |\\mathcal{Y}|)$\u7684\u8bef\u5dee\u4fdd\u8bc1\uff0c\u6539\u8fdb\u4e86Steinke\u673a\u5236$O(\\log^{3/2} |\\mathcal{Y}|)$\u7684\u8bef\u5dee\u3002", "motivation": "\u89e3\u51b3Steinke(2025)\u63d0\u51fa\u7684\u5f00\u653e\u6027\u95ee\u9898\uff1a\u662f\u5426\u4ec5\u901a\u8fc7\u81ea\u9002\u5e94\u8c03\u7528\u9ad8\u65af\u673a\u5236\u5904\u7406\u4f4e\u654f\u611f\u5ea6\u67e5\u8be2\u5c31\u80fd\u5b9e\u73b0\u8fd1\u4f3c\u6700\u4f18\u8bef\u5dee\u7684\u5dee\u5206\u9690\u79c1\u9009\u62e9\u95ee\u9898\u3002", "method": "\u4f7f\u7528\u81ea\u9002\u5e94\u8c03\u7528\u9ad8\u65af\u673a\u5236\u5904\u7406\u4f4e\u654f\u611f\u5ea6\u67e5\u8be2\u7684\u65b9\u6cd5\uff0c\u9488\u5bf9\u5019\u9009\u96c6$\\mathcal{Y}$\u8fdb\u884c\u5dee\u5206\u9690\u79c1\u9009\u62e9\u3002", "result": "\u5b9e\u73b0\u4e86$\\tilde{O}(\\log |\\mathcal{Y}|)$\u7684\u8bef\u5dee\u4fdd\u8bc1\uff0c\u8fd9\u6bd4\u6307\u6570\u673a\u5236(McSherry\u548cTalwar, 2007)\u4ec5\u591a$(\\log \\log |\\mathcal{Y}|)^{O(1)}$\u56e0\u5b50\uff0c\u663e\u8457\u6539\u8fdb\u4e86Steinke\u673a\u5236\u7684$O(\\log^{3/2} |\\mathcal{Y}|)$\u8bef\u5dee\u3002", "conclusion": "\u6210\u529f\u89e3\u51b3\u4e86Steinke\u7684\u5f00\u653e\u6027\u95ee\u9898\uff0c\u8bc1\u660e\u4e86\u4ec5\u901a\u8fc7\u81ea\u9002\u5e94\u8c03\u7528\u9ad8\u65af\u673a\u5236\u5904\u7406\u4f4e\u654f\u611f\u5ea6\u67e5\u8be2\u5c31\u80fd\u5b9e\u73b0\u8fd1\u4f3c\u6700\u4f18\u8bef\u5dee\u7684\u5dee\u5206\u9690\u79c1\u9009\u62e9\uff0c\u4e3a\u5dee\u5206\u9690\u79c1\u7b97\u6cd5\u8bbe\u8ba1\u63d0\u4f9b\u4e86\u65b0\u7684\u601d\u8def\u3002"}}
{"id": "2511.07033", "categories": ["cs.CR"], "pdf": "https://arxiv.org/pdf/2511.07033", "abs": "https://arxiv.org/abs/2511.07033", "authors": ["Yuanheng Li", "Zhuoyang Chen", "Xiaoyun Liu", "Yuhao Wang", "Mingwei Liu", "Yang Shi", "Kaifeng Huang", "Shengjie Zhao"], "title": "Uncovering Pretraining Code in LLMs: A Syntax-Aware Attribution Approach", "comment": "Paper has been accepted by AAAI 2026", "summary": "As large language models (LLMs) become increasingly capable, concerns over the unauthorized use of copyrighted and licensed content in their training data have grown, especially in the context of code. Open-source code, often protected by open source licenses (e.g, GPL), poses legal and ethical challenges when used in pretraining. Detecting whether specific code samples were included in LLM training data is thus critical for transparency, accountability, and copyright compliance. We propose SynPrune, a syntax-pruned membership inference attack method tailored for code. Unlike prior MIA approaches that treat code as plain text, SynPrune leverages the structured and rule-governed nature of programming languages. Specifically, it identifies and excludes consequent tokens that are syntactically required and not reflective of authorship, from attribution when computing membership scores. Experimental results show that SynPrune consistently outperforms the state-of-the-arts. Our method is also robust across varying function lengths and syntax categories.", "AI": {"tldr": "SynPrune\u662f\u4e00\u79cd\u9488\u5bf9\u4ee3\u7801\u7684\u8bed\u6cd5\u526a\u679d\u6210\u5458\u63a8\u7406\u653b\u51fb\u65b9\u6cd5\uff0c\u901a\u8fc7\u5229\u7528\u7f16\u7a0b\u8bed\u8a00\u7684\u7ed3\u6784\u5316\u7279\u6027\uff0c\u8bc6\u522b\u5e76\u6392\u9664\u8bed\u6cd5\u5fc5\u9700\u7684\u540e\u7eed\u6807\u8bb0\uff0c\u5728\u8ba1\u7b97\u6210\u5458\u5206\u6570\u65f6\u63d0\u9ad8\u68c0\u6d4b\u8bad\u7ec3\u6570\u636e\u4e2d\u7279\u5b9a\u4ee3\u7801\u6837\u672c\u7684\u51c6\u786e\u6027\u3002", "motivation": "\u968f\u7740\u5927\u8bed\u8a00\u6a21\u578b\u80fd\u529b\u7684\u589e\u5f3a\uff0c\u5728\u8bad\u7ec3\u6570\u636e\u4e2d\u672a\u7ecf\u6388\u6743\u4f7f\u7528\u53d7\u7248\u6743\u548c\u8bb8\u53ef\u4fdd\u62a4\u7684\u5185\u5bb9\uff08\u7279\u522b\u662f\u4ee3\u7801\uff09\u5f15\u53d1\u6cd5\u5f8b\u548c\u9053\u5fb7\u62c5\u5fe7\u3002\u68c0\u6d4b\u7279\u5b9a\u4ee3\u7801\u6837\u672c\u662f\u5426\u5305\u542b\u5728LLM\u8bad\u7ec3\u6570\u636e\u4e2d\u5bf9\u900f\u660e\u5ea6\u3001\u95ee\u8d23\u5236\u548c\u7248\u6743\u5408\u89c4\u81f3\u5173\u91cd\u8981\u3002", "method": "SynPrune\u5229\u7528\u7f16\u7a0b\u8bed\u8a00\u7684\u7ed3\u6784\u5316\u548c\u89c4\u5219\u7ea6\u675f\u7279\u6027\uff0c\u8bc6\u522b\u5e76\u6392\u9664\u8bed\u6cd5\u5fc5\u9700\u7684\u540e\u7eed\u6807\u8bb0\uff08\u8fd9\u4e9b\u6807\u8bb0\u4e0d\u53cd\u6620\u4f5c\u8005\u8eab\u4efd\uff09\uff0c\u5728\u8ba1\u7b97\u6210\u5458\u5206\u6570\u65f6\u8fdb\u884c\u8bed\u6cd5\u526a\u679d\u3002", "result": "\u5b9e\u9a8c\u7ed3\u679c\u8868\u660e\uff0cSynPrune\u5728\u6027\u80fd\u4e0a\u6301\u7eed\u4f18\u4e8e\u73b0\u6709\u6700\u5148\u8fdb\u65b9\u6cd5\uff0c\u5e76\u4e14\u5728\u4e0d\u540c\u51fd\u6570\u957f\u5ea6\u548c\u8bed\u6cd5\u7c7b\u522b\u4e0b\u90fd\u5177\u6709\u9c81\u68d2\u6027\u3002", "conclusion": "SynPrune\u901a\u8fc7\u5229\u7528\u4ee3\u7801\u7684\u8bed\u6cd5\u7ed3\u6784\u7279\u6027\uff0c\u4e3a\u68c0\u6d4b\u8bad\u7ec3\u6570\u636e\u4e2d\u7684\u4ee3\u7801\u6837\u672c\u63d0\u4f9b\u4e86\u4e00\u79cd\u6709\u6548\u7684\u6210\u5458\u63a8\u7406\u653b\u51fb\u65b9\u6cd5\uff0c\u5728\u51c6\u786e\u6027\u548c\u9c81\u68d2\u6027\u65b9\u9762\u5747\u8868\u73b0\u4f18\u5f02\u3002"}}
{"id": "2511.07123", "categories": ["cs.CR"], "pdf": "https://arxiv.org/pdf/2511.07123", "abs": "https://arxiv.org/abs/2511.07123", "authors": ["Shuangqing Xu", "Yifeng Zheng", "Zhongyun Hua"], "title": "Harnessing Sparsification in Federated Learning: A Secure, Efficient, and Differentially Private Realization", "comment": "Accepted by CCS'2025", "summary": "Federated learning (FL) enables multiple clients to jointly train a model by sharing only gradient updates for aggregation instead of raw data. Due to the transmission of very high-dimensional gradient updates from many clients, FL is known to suffer from a communication bottleneck. Meanwhile, the gradients shared by clients as well as the trained model may also be exploited for inferring private local datasets, making privacy still a critical concern in FL. We present Clover, a novel system framework for communication-efficient, secure, and differentially private FL. To tackle the communication bottleneck in FL, Clover follows a standard and commonly used approach-top-k gradient sparsification, where each client sparsifies its gradient update such that only k largest gradients (measured by magnitude) are preserved for aggregation. Clover provides a tailored mechanism built out of a trending distributed trust setting involving three servers, which allows to efficiently aggregate multiple sparse vectors (top-k sparsified gradient updates) into a dense vector while hiding the values and indices of non-zero elements in each sparse vector. This mechanism outperforms a baseline built on the general distributed ORAM technique by several orders of magnitude in server-side communication and runtime, with also smaller client communication cost. We further integrate this mechanism with a lightweight distributed noise generation mechanism to offer differential privacy (DP) guarantees on the trained model. To harden Clover with security against a malicious server, we devise a series of lightweight mechanisms for integrity checks on the server-side computation. Extensive experiments show that Clover can achieve utility comparable to vanilla FL with central DP, with promising performance.", "AI": {"tldr": "Clover\u662f\u4e00\u4e2a\u8054\u90a6\u5b66\u4e60\u7cfb\u7edf\u6846\u67b6\uff0c\u901a\u8fc7top-k\u68af\u5ea6\u7a00\u758f\u5316\u89e3\u51b3\u901a\u4fe1\u74f6\u9888\uff0c\u4f7f\u7528\u4e09\u670d\u52a1\u5668\u5206\u5e03\u5f0f\u4fe1\u4efb\u8bbe\u7f6e\u4fdd\u62a4\u9690\u79c1\uff0c\u5e76\u63d0\u4f9b\u5dee\u5206\u9690\u79c1\u4fdd\u8bc1\u548c\u6076\u610f\u670d\u52a1\u5668\u5b89\u5168\u9632\u62a4\u3002", "motivation": "\u8054\u90a6\u5b66\u4e60\u9762\u4e34\u901a\u4fe1\u74f6\u9888\u548c\u9690\u79c1\u6cc4\u9732\u98ce\u9669\uff0c\u9700\u8981\u540c\u65f6\u89e3\u51b3\u9ad8\u6548\u901a\u4fe1\u548c\u5b89\u5168\u9690\u79c1\u4fdd\u62a4\u7684\u95ee\u9898\u3002", "method": "\u91c7\u7528top-k\u68af\u5ea6\u7a00\u758f\u5316\u51cf\u5c11\u901a\u4fe1\u91cf\uff0c\u6784\u5efa\u4e09\u670d\u52a1\u5668\u5206\u5e03\u5f0f\u4fe1\u4efb\u673a\u5236\u9690\u85cf\u7a00\u758f\u68af\u5ea6\u503c\u548c\u7d22\u5f15\uff0c\u96c6\u6210\u8f7b\u91cf\u7ea7\u5206\u5e03\u5f0f\u566a\u58f0\u751f\u6210\u63d0\u4f9b\u5dee\u5206\u9690\u79c1\uff0c\u8bbe\u8ba1\u5b8c\u6574\u6027\u68c0\u67e5\u673a\u5236\u9632\u5fa1\u6076\u610f\u670d\u52a1\u5668\u3002", "result": "\u76f8\u6bd4\u57fa\u4e8e\u5206\u5e03\u5f0fORAM\u7684\u57fa\u7ebf\u65b9\u6cd5\uff0c\u670d\u52a1\u5668\u7aef\u901a\u4fe1\u548c\u8fd0\u884c\u65f6\u6027\u80fd\u63d0\u5347\u6570\u4e2a\u6570\u91cf\u7ea7\uff0c\u5ba2\u6237\u7aef\u901a\u4fe1\u6210\u672c\u66f4\u5c0f\uff0c\u80fd\u591f\u8fbe\u5230\u4e0e\u4e2d\u5fc3\u5dee\u5206\u9690\u79c1\u7684\u666e\u901a\u8054\u90a6\u5b66\u4e60\u76f8\u5f53\u7684\u6548\u7528\u3002", "conclusion": "Clover\u6846\u67b6\u5728\u4fdd\u6301\u8054\u90a6\u5b66\u4e60\u6548\u7528\u7684\u540c\u65f6\uff0c\u6709\u6548\u89e3\u51b3\u4e86\u901a\u4fe1\u6548\u7387\u3001\u9690\u79c1\u4fdd\u62a4\u548c\u5b89\u5168\u6027\u95ee\u9898\uff0c\u5177\u6709\u5b9e\u9645\u5e94\u7528\u524d\u666f\u3002"}}
{"id": "2511.07242", "categories": ["cs.CR"], "pdf": "https://arxiv.org/pdf/2511.07242", "abs": "https://arxiv.org/abs/2511.07242", "authors": ["Tianle Song", "Chenhao Lin", "Yang Cao", "Zhengyu Zhao", "Jiahao Sun", "Chong Zhang", "Le Yang", "Chao Shen"], "title": "Privacy on the Fly: A Predictive Adversarial Transformation Network for Mobile Sensor Data", "comment": null, "summary": "Mobile motion sensors such as accelerometers and gyroscopes are now ubiquitously accessible by third-party apps via standard APIs. While enabling rich functionalities like activity recognition and step counting, this openness has also enabled unregulated inference of sensitive user traits, such as gender, age, and even identity, without user consent. Existing privacy-preserving techniques, such as GAN-based obfuscation or differential privacy, typically require access to the full input sequence, introducing latency that is incompatible with real-time scenarios. Worse, they tend to distort temporal and semantic patterns, degrading the utility of the data for benign tasks like activity recognition. To address these limitations, we propose the Predictive Adversarial Transformation Network (PATN), a real-time privacy-preserving framework that leverages historical signals to generate adversarial perturbations proactively. The perturbations are applied immediately upon data acquisition, enabling continuous protection without disrupting application functionality. Experiments on two datasets demonstrate that PATN substantially degrades the performance of privacy inference models, achieving Attack Success Rate (ASR) of 40.11% and 44.65% (reducing inference accuracy to near-random) and increasing the Equal Error Rate (EER) from 8.30% and 7.56% to 41.65% and 46.22%. On ASR, PATN outperforms baseline methods by 16.16% and 31.96%, respectively.", "AI": {"tldr": "\u63d0\u51fa\u4e86PATN\u6846\u67b6\uff0c\u901a\u8fc7\u5386\u53f2\u4fe1\u53f7\u751f\u6210\u5bf9\u6297\u6027\u6270\u52a8\u6765\u5b9e\u65f6\u4fdd\u62a4\u79fb\u52a8\u8fd0\u52a8\u4f20\u611f\u5668\u6570\u636e\u7684\u9690\u79c1\uff0c\u540c\u65f6\u4fdd\u6301\u826f\u6027\u4efb\u52a1\u7684\u5b9e\u7528\u6027\u3002", "motivation": "\u79fb\u52a8\u8fd0\u52a8\u4f20\u611f\u5668\u6570\u636e\u6613\u88ab\u7b2c\u4e09\u65b9\u5e94\u7528\u63a8\u65ad\u654f\u611f\u7528\u6237\u7279\u5f81\uff0c\u73b0\u6709\u9690\u79c1\u4fdd\u62a4\u6280\u672f\u5b58\u5728\u5ef6\u8fdf\u9ad8\u3001\u7834\u574f\u6570\u636e\u5b9e\u7528\u6027\u7684\u95ee\u9898\u3002", "method": "\u4f7f\u7528\u9884\u6d4b\u6027\u5bf9\u6297\u53d8\u6362\u7f51\u7edc\uff0c\u5229\u7528\u5386\u53f2\u4fe1\u53f7\u4e3b\u52a8\u751f\u6210\u5bf9\u6297\u6027\u6270\u52a8\uff0c\u5728\u6570\u636e\u91c7\u96c6\u65f6\u7acb\u5373\u5e94\u7528\u3002", "result": "\u5728\u4e24\u4e2a\u6570\u636e\u96c6\u4e0a\uff0cPATN\u663e\u8457\u964d\u4f4e\u4e86\u9690\u79c1\u63a8\u65ad\u6a21\u578b\u7684\u6027\u80fd\uff0c\u653b\u51fb\u6210\u529f\u7387\u964d\u81f340.11%\u548c44.65%\uff0c\u7b49\u9519\u8bef\u7387\u4ece8.30%\u548c7.56%\u63d0\u5347\u81f341.65%\u548c46.22%\u3002", "conclusion": "PATN\u6846\u67b6\u80fd\u591f\u5b9e\u65f6\u4fdd\u62a4\u79fb\u52a8\u4f20\u611f\u5668\u6570\u636e\u9690\u79c1\uff0c\u540c\u65f6\u4fdd\u6301\u826f\u6027\u5e94\u7528\u7684\u5b9e\u7528\u6027\uff0c\u4f18\u4e8e\u73b0\u6709\u57fa\u7ebf\u65b9\u6cd5\u3002"}}
{"id": "2511.07315", "categories": ["cs.CR"], "pdf": "https://arxiv.org/pdf/2511.07315", "abs": "https://arxiv.org/abs/2511.07315", "authors": ["Yuxuan Zhou", "Yang Bai", "Kuofeng Gao", "Tao Dai", "Shu-Tao Xia"], "title": "JPRO: Automated Multimodal Jailbreaking via Multi-Agent Collaboration Framework", "comment": null, "summary": "The widespread application of large VLMs makes ensuring their secure deployment critical. While recent studies have demonstrated jailbreak attacks on VLMs, existing approaches are limited: they require either white-box access, restricting practicality, or rely on manually crafted patterns, leading to poor sample diversity and scalability. To address these gaps, we propose JPRO, a novel multi-agent collaborative framework designed for automated VLM jailbreaking. It effectively overcomes the shortcomings of prior methods in attack diversity and scalability. Through the coordinated action of four specialized agents and its two core modules: Tactic-Driven Seed Generation and Adaptive Optimization Loop, JPRO generates effective and diverse attack samples. Experimental results show that JPRO achieves over a 60\\% attack success rate on multiple advanced VLMs, including GPT-4o, significantly outperforming existing methods. As a black-box attack approach, JPRO not only uncovers critical security vulnerabilities in multimodal models but also offers valuable insights for evaluating and enhancing VLM robustness.", "AI": {"tldr": "JPRO\u662f\u4e00\u4e2a\u591a\u667a\u80fd\u4f53\u534f\u4f5c\u6846\u67b6\uff0c\u7528\u4e8e\u81ea\u52a8\u5316\u653b\u51fb\u89c6\u89c9\u8bed\u8a00\u6a21\u578b(VLMs)\uff0c\u901a\u8fc7\u534f\u8c03\u56db\u4e2a\u4e13\u4e1a\u667a\u80fd\u4f53\u548c\u4e24\u4e2a\u6838\u5fc3\u6a21\u5757\uff0c\u5728\u591a\u79cd\u5148\u8fdbVLM\u4e0a\u5b9e\u73b0\u4e86\u8d85\u8fc760%\u7684\u653b\u51fb\u6210\u529f\u7387\u3002", "motivation": "\u73b0\u6709VLM\u8d8a\u72f1\u653b\u51fb\u65b9\u6cd5\u5b58\u5728\u5c40\u9650\u6027\uff1a\u8981\u4e48\u9700\u8981\u767d\u76d2\u8bbf\u95ee(\u4e0d\u5b9e\u7528)\uff0c\u8981\u4e48\u4f9d\u8d56\u4eba\u5de5\u8bbe\u8ba1\u6a21\u5f0f(\u6837\u672c\u591a\u6837\u6027\u548c\u53ef\u6269\u5c55\u6027\u5dee)\uff0c\u9700\u8981\u89e3\u51b3\u8fd9\u4e9b\u7f3a\u9677\u3002", "method": "\u63d0\u51faJPRO\u591a\u667a\u80fd\u4f53\u534f\u4f5c\u6846\u67b6\uff0c\u5305\u542b\u56db\u4e2a\u4e13\u4e1a\u667a\u80fd\u4f53\u548c\u4e24\u4e2a\u6838\u5fc3\u6a21\u5757\uff1a\u7b56\u7565\u9a71\u52a8\u7684\u79cd\u5b50\u751f\u6210\u548c\u81ea\u9002\u5e94\u4f18\u5316\u5faa\u73af\uff0c\u751f\u6210\u6709\u6548\u4e14\u591a\u6837\u5316\u7684\u653b\u51fb\u6837\u672c\u3002", "result": "\u5b9e\u9a8c\u7ed3\u679c\u663e\u793a\uff0cJPRO\u5728\u5305\u62ecGPT-4o\u5728\u5185\u7684\u591a\u79cd\u5148\u8fdbVLM\u4e0a\u5b9e\u73b0\u4e86\u8d85\u8fc760%\u7684\u653b\u51fb\u6210\u529f\u7387\uff0c\u663e\u8457\u4f18\u4e8e\u73b0\u6709\u65b9\u6cd5\u3002", "conclusion": "\u4f5c\u4e3a\u9ed1\u76d2\u653b\u51fb\u65b9\u6cd5\uff0cJPRO\u4e0d\u4ec5\u63ed\u793a\u4e86\u591a\u6a21\u6001\u6a21\u578b\u7684\u5173\u952e\u5b89\u5168\u6f0f\u6d1e\uff0c\u8fd8\u4e3a\u8bc4\u4f30\u548c\u589e\u5f3aVLM\u9c81\u68d2\u6027\u63d0\u4f9b\u4e86\u5b9d\u8d35\u89c1\u89e3\u3002"}}
