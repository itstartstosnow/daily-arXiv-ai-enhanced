{"id": "2510.07452", "categories": ["cs.CR", "cs.CL"], "pdf": "https://arxiv.org/pdf/2510.07452", "abs": "https://arxiv.org/abs/2510.07452", "authors": ["Anthony Hughes", "Vasisht Duddu", "N. Asokan", "Nikolaos Aletras", "Ning Ma"], "title": "PATCH: Mitigating PII Leakage in Language Models with Privacy-Aware Targeted Circuit PatcHing", "comment": null, "summary": "Language models (LMs) may memorize personally identifiable information (PII)\nfrom training data, enabling adversaries to extract it during inference.\nExisting defense mechanisms such as differential privacy (DP) reduce this\nleakage, but incur large drops in utility. Based on a comprehensive study using\ncircuit discovery to identify the computational circuits responsible PII\nleakage in LMs, we hypothesize that specific PII leakage circuits in LMs should\nbe responsible for this behavior. Therefore, we propose PATCH (Privacy-Aware\nTargeted Circuit PatcHing), a novel approach that first identifies and\nsubsequently directly edits PII circuits to reduce leakage. PATCH achieves\nbetter privacy-utility trade-off than existing defenses, e.g., reducing recall\nof PII leakage from LMs by up to 65%. Finally, PATCH can be combined with DP to\nreduce recall of residual leakage of an LM to as low as 0.01%. Our analysis\nshows that PII leakage circuits persist even after the application of existing\ndefense mechanisms. In contrast, PATCH can effectively mitigate their impact."}
{"id": "2510.07457", "categories": ["cs.CR", "cs.LG"], "pdf": "https://arxiv.org/pdf/2510.07457", "abs": "https://arxiv.org/abs/2510.07457", "authors": ["Kalyan Cheerla", "Lotfi Ben Othmane", "Kirill Morozov"], "title": "Comparison of Fully Homomorphic Encryption and Garbled Circuit Techniques in Privacy-Preserving Machine Learning Inference", "comment": "8 pages, 9 figures, 2 tables, 32 references", "summary": "Machine Learning (ML) is making its way into fields such as healthcare,\nfinance, and Natural Language Processing (NLP), and concerns over data privacy\nand model confidentiality continue to grow. Privacy-preserving Machine Learning\n(PPML) addresses this challenge by enabling inference on private data without\nrevealing sensitive inputs or proprietary models. Leveraging Secure Computation\ntechniques from Cryptography, two widely studied approaches in this domain are\nFully Homomorphic Encryption (FHE) and Garbled Circuits (GC). This work\npresents a comparative evaluation of FHE and GC for secure neural network\ninference. A two-layer neural network (NN) was implemented using the CKKS\nscheme from the Microsoft SEAL library (FHE) and the TinyGarble2.0 framework\n(GC) by IntelLabs. Both implementations are evaluated under the semi-honest\nthreat model, measuring inference output error, round-trip time, peak memory\nusage, communication overhead, and communication rounds. Results reveal a\ntrade-off: modular GC offers faster execution and lower memory consumption,\nwhile FHE supports non-interactive inference."}
{"id": "2510.07462", "categories": ["cs.CR"], "pdf": "https://arxiv.org/pdf/2510.07462", "abs": "https://arxiv.org/abs/2510.07462", "authors": ["Maryam Ataei Nezhad", "Hamid Barati", "Ali Barati"], "title": "A Secure Authentication-Driven Protected Data Collection Protocol in Internet of Things", "comment": null, "summary": "Internet of Things means connecting different devices through the Internet.\nThe Internet of things enables humans to remotely manage and control the\nobjects they use with the Internet infrastructure. After the advent of the\nInternet of Things in homes, organizations, and private companies, privacy and\ninformation security are the biggest concern. This issue has challenged the\nspread of the Internet of things as news of the users theft of information by\nhackers intensified. The proposed method in this paper consists of three\nphases. In the first phase, a star structure is constructed within each\ncluster, and a unique key is shared between each child and parent to encrypt\nand secure subsequent communications. The second phase is for intracluster\ncommunications, in which members of the cluster send their data to the cluster\nhead in a multi hop manner. Also, in this phase, the data is encrypted with\ndifferent keys in each hop, and at the end of each connection, the keys are\nupdated to ensure data security. The third phase is to improve the security of\ninter cluster communications using an authentication protocol. In this way, the\ncluster heads are authenticated before sending information to prevent malicious\nnodes in the network. The proposed method is also simulated using NS2 software.\nThe results showed that the proposed method has improved in terms of energy\nconsumption, end-to-end delay, flexibility, packet delivery rate, and the\nnumber of alive nodes compared to other methods."}
{"id": "2510.07479", "categories": ["cs.CR", "cs.IT", "math.IT"], "pdf": "https://arxiv.org/pdf/2510.07479", "abs": "https://arxiv.org/abs/2510.07479", "authors": ["Alain Couvreur", "Thomas Debris-Alazard", "Philippe Gaborit", "Adrien Vinçotte"], "title": "MIRANDA: short signatures from a leakage-free full-domain-hash scheme", "comment": null, "summary": "We present $\\mathsf{Miranda}$, the first family of full-domain-hash\nsignatures based on matrix codes. This signature scheme fulfils the paradigm of\nGentry, Peikert and Vaikuntanathan ($\\mathsf{GPV}$), which gives strong\nsecurity guarantees. Our trapdoor is very simple and generic: if we propose it\nwith matrix codes, it can actually be instantiated in many other ways since it\nonly involves a subcode of a decodable code (or lattice) in a unique decoding\nregime of parameters. Though $\\mathsf{Miranda}$ signing algorithm relies on a\ndecoding task where there is exactly one solution, there are many possible\nsignatures given a message to sign and we ensure that signatures are not\nleaking information on their underlying trapdoor by means of a very simple\nprocedure involving the drawing of a small number of uniform bits. In\nparticular $\\mathsf{Miranda}$ does not use a rejection sampling procedure which\nmakes its implementation a very simple task contrary to other\n$\\mathsf{GPV}$-like signatures schemes such as $\\mathsf{Falcon}$ or even\n$\\mathsf{Wave}$.\n  We instantiate $\\mathsf{Miranda}$ with the famous family of Gabidulin codes\nrepresented as spaces of matrices and we study thoroughly its security (in the\nEUF-CMA security model). For~$128$ bits of classical security, the signature\nsizes are as low as~$90$ bytes and the public key sizes are in the order\nof~$2.6$ megabytes."}
{"id": "2510.07533", "categories": ["cs.CR"], "pdf": "https://arxiv.org/pdf/2510.07533", "abs": "https://arxiv.org/abs/2510.07533", "authors": ["Haowen Xu", "Tianya Zhao", "Xuyu Wang", "Lei Ma", "Jun Dai", "Alexander Wyglinski", "Xiaoyan Sun"], "title": "EMPalm: Exfiltrating Palm Biometric Data via Electromagnetic Side-Channels", "comment": null, "summary": "Palm recognition has emerged as a dominant biometric authentication\ntechnology in critical infrastructure. These systems operate in either\nsingle-modal form, using palmprint or palmvein individually, or dual-modal\nform, fusing the two modalities. Despite this diversity, they share similar\nhardware architectures that inadvertently emit electromagnetic (EM) signals\nduring operation. Our research reveals that these EM emissions leak palm\nbiometric information, motivating us to develop EMPalm--an attack framework\nthat covertly recovers both palmprint and palmvein images from eavesdropped EM\nsignals. Specifically, we first separate the interleaved transmissions of the\ntwo modalities, identify and combine their informative frequency bands, and\nreconstruct the images. To further enhance fidelity, we employ a diffusion\nmodel to restore fine-grained biometric features unique to each domain.\nEvaluations on seven prototype and two commercial palm acquisition devices show\nthat EMPalm can recover palm biometric information with high visual fidelity,\nachieving SSIM scores up to 0.79, PSNR up to 29.88 dB, and FID scores as low as\n6.82 across all tested devices, metrics that collectively demonstrate strong\nstructural similarity, high signal quality, and low perceptual discrepancy. To\nassess the practical implications of the attack, we further evaluate it against\nfour state-of-the-art palm recognition models, achieving a model-wise average\nspoofing success rate of 65.30% over 6,000 samples from 100 distinct users."}
{"id": "2510.07584", "categories": ["cs.CR"], "pdf": "https://arxiv.org/pdf/2510.07584", "abs": "https://arxiv.org/abs/2510.07584", "authors": ["Thomas Debris-Alazard", "Philippe Gaborit", "Romaric Neveu", "Olivier Ruatta"], "title": "A Minrank-based Encryption Scheme à la Alekhnovich-Regev", "comment": null, "summary": "Introduced in 2003 and 2005, Alekhnovich and Regev' schemes were the first\npublic-key encryptions whose security is only based on the average hardness of\ndecoding random linear codes and LWE, without other security assumptions. Such\nsecurity guarantees made them very popular, being at the origin of the now\nstandardized HQC or Kyber.\n  We present an adaptation of Alekhnovich and Regev' encryption scheme whose\nsecurity is only based on the hardness of a slight variation of MinRank, the\nso-called stationary-MinRank problem. We succeeded to reach this strong\nsecurity guarantee by showing that stationary-MinRank benefits from a\nsearch-to-decision reduction. Our scheme therefore brings a partial answer to\nthe long-standing open question of building an encryption scheme whose security\nrelies solely on the hardness of MinRank.\n  Finally, we show after a thoroughly security analysis that our scheme is\npractical and competitive with other encryption schemes admitting such strong\nsecurity guarantees. Our scheme is slightly less efficient than FrodoKEM, but\nmuch more efficient than Alekhnovich and Regev' original schemes, with\npossibilities of improvements by considering more structure, in the same way as\nHQC and Kyber."}
{"id": "2510.07697", "categories": ["cs.CR", "cs.AI"], "pdf": "https://arxiv.org/pdf/2510.07697", "abs": "https://arxiv.org/abs/2510.07697", "authors": ["Man Hu", "Xinyi Wu", "Zuofeng Suo", "Jinbo Feng", "Linghui Meng", "Yanhao Jia", "Anh Tuan Luu", "Shuai Zhao"], "title": "Rethinking Reasoning: A Survey on Reasoning-based Backdoors in LLMs", "comment": null, "summary": "With the rise of advanced reasoning capabilities, large language models\n(LLMs) are receiving increasing attention. However, although reasoning improves\nLLMs' performance on downstream tasks, it also introduces new security risks,\nas adversaries can exploit these capabilities to conduct backdoor attacks.\nExisting surveys on backdoor attacks and reasoning security offer comprehensive\noverviews but lack in-depth analysis of backdoor attacks and defenses targeting\nLLMs' reasoning abilities. In this paper, we take the first step toward\nproviding a comprehensive review of reasoning-based backdoor attacks in LLMs by\nanalyzing their underlying mechanisms, methodological frameworks, and\nunresolved challenges. Specifically, we introduce a new taxonomy that offers a\nunified perspective for summarizing existing approaches, categorizing\nreasoning-based backdoor attacks into associative, passive, and active. We also\npresent defense strategies against such attacks and discuss current challenges\nalongside potential directions for future research. This work offers a novel\nperspective, paving the way for further exploration of secure and trustworthy\nLLM communities."}
{"id": "2510.07806", "categories": ["cs.CR"], "pdf": "https://arxiv.org/pdf/2510.07806", "abs": "https://arxiv.org/abs/2510.07806", "authors": ["Yihao Peng", "Biao Ma", "Hai Wan", "Xibin Zhao"], "title": "ANCORA: Accurate Intrusion Recovery for Web Applications", "comment": null, "summary": "Modern web application recovery presents a critical dilemma. Coarse-grained\nsnapshot rollbacks cause unacceptable data loss for legitimate users.\nSurgically removing an attack's impact is hindered by a fundamental challenge\nin high-concurrency environments: it is difficult to attribute resulting file\nand database modifications to a specific attack-related request. We present\nANCORA, a system for precise intrusion recovery in web applications without\ninvasive instrumentation. ANCORA first isolates the full sequence of syscalls\ntriggered by a single malicious request. Based on this sequence, ANCORA\naddresses file and database modifications separately. To trace file changes, it\nbuilds a provenance graph that reveals all modifications, including those by\nexploit-spawned processes. To attribute database operations, a more difficult\nchallenge due to connection pooling, ANCORA introduces a novel spatiotemporal\nanchor. This anchor uses the request's network connection tuple and active time\nwindow to pinpoint exact database operations. With all malicious file and\ndatabase operations precisely identified, ANCORA performs a unified rewind and\nselective replay recovery. It reverts the system to a clean snapshot taken\nbefore the attack, then selectively re-applies only legitimate operations to\nboth the file system and database. This completely removes the attack's effects\nwhile preserving concurrent legitimate data. We evaluated ANCORA on 10 web\napplications and 20 CVE-based attack scenarios with concurrency up to 150\nconnections. Experiments demonstrate ANCORA achieves 99.9% recovery accuracy\nwith manageable overhead: up to 19.8% response latency increase and 17.8% QPS\ndecrease in worst cases, and recovery throughput of 110.7 database operations\nper second and 27.2 affected files per second, effectively preserving\nlegitimate data."}
{"id": "2510.07809", "categories": ["cs.CR", "cs.AI"], "pdf": "https://arxiv.org/pdf/2510.07809", "abs": "https://arxiv.org/abs/2510.07809", "authors": ["Renhua Ding", "Xiao Yang", "Zhengwei Fang", "Jun Luo", "Kun He", "Jun Zhu"], "title": "Effective and Stealthy One-Shot Jailbreaks on Deployed Mobile Vision-Language Agents", "comment": null, "summary": "Large vision-language models (LVLMs) enable autonomous mobile agents to\noperate smartphone user interfaces, yet vulnerabilities to UI-level attacks\nremain critically understudied. Existing research often depends on conspicuous\nUI overlays, elevated permissions, or impractical threat models, limiting\nstealth and real-world applicability. In this paper, we present a practical and\nstealthy one-shot jailbreak attack that leverages in-app prompt injections:\nmalicious applications embed short prompts in UI text that remain inert during\nhuman interaction but are revealed when an agent drives the UI via ADB (Android\nDebug Bridge). Our framework comprises three crucial components: (1)\nlow-privilege perception-chain targeting, which injects payloads into malicious\napps as the agent's visual inputs; (2) stealthy user-invisible activation, a\ntouch-based trigger that discriminates agent from human touches using physical\ntouch attributes and exposes the payload only during agent operation; and (3)\none-shot prompt efficacy, a heuristic-guided, character-level\niterative-deepening search algorithm (HG-IDA*) that performs one-shot,\nkeyword-level detoxification to evade on-device safety filters. We evaluate\nacross multiple LVLM backends, including closed-source services and\nrepresentative open-source models within three Android applications, and we\nobserve high planning and execution hijack rates in single-shot scenarios\n(e.g., GPT-4o: 82.5% planning / 75.0% execution). These findings expose a\nfundamental security vulnerability in current mobile agents with immediate\nimplications for autonomous smartphone operation."}
{"id": "2510.07901", "categories": ["cs.CR", "cs.DC"], "pdf": "https://arxiv.org/pdf/2510.07901", "abs": "https://arxiv.org/abs/2510.07901", "authors": ["Georgios Diamantopoulos", "Nikos Tziritas", "Rami Bahsoon", "Georgios Theodoropoulos"], "title": "Decentralised Blockchain Management Through Digital Twins", "comment": "Accepted for publication in the proceedings of the 24th Asia\n  Simulation Conference 2025", "summary": "The necessity of blockchain systems to remain decentralised limits current\nsolutions to blockchain governance and dynamic management, forcing a trade-off\nbetween control and decentralisation. In light of the above, this work proposes\na dynamic and decentralised blockchain management mechanism based on digital\ntwins. To ensure decentralisation, the proposed mechanism utilises multiple\ndigital twins that the system's stakeholders control. To facilitate\ndecentralised decision-making, the twins are organised in a secondary\nblockchain system that orchestrates agreement on, and propagation of decisions\nto the managed blockchain. This enables the management of blockchain systems\nwithout centralised control. A preliminary evaluation of the performance and\nimpact of the overheads introduced by the proposed mechanism is conducted\nthrough simulation. The results demonstrate the proposed mechanism's ability to\nreach consensus on decisions quickly and reconfigure the primary blockchain\nwith minimal overhead."}
{"id": "2510.07968", "categories": ["cs.CR"], "pdf": "https://arxiv.org/pdf/2510.07968", "abs": "https://arxiv.org/abs/2510.07968", "authors": ["Xiangtao Meng", "Tianshuo Cong", "Li Wang", "Wenyu Chen", "Zheng Li", "Shanqing Guo", "Xiaoyun Wang"], "title": "From Defender to Devil? Unintended Risk Interactions Induced by LLM Defenses", "comment": null, "summary": "Large Language Models (LLMs) have shown remarkable performance across various\napplications, but their deployment in sensitive domains raises significant\nconcerns. To mitigate these risks, numerous defense strategies have been\nproposed. However, most existing studies assess these defenses in isolation,\noverlooking their broader impacts across other risk dimensions. In this work,\nwe take the first step in investigating unintended interactions caused by\ndefenses in LLMs, focusing on the complex interplay between safety, fairness,\nand privacy. Specifically, we propose CrossRiskEval, a comprehensive evaluation\nframework to assess whether deploying a defense targeting one risk\ninadvertently affects others. Through extensive empirical studies on 14\ndefense-deployed LLMs, covering 12 distinct defense strategies, we reveal\nseveral alarming side effects: 1) safety defenses may suppress direct responses\nto sensitive queries related to bias or privacy, yet still amplify indirect\nprivacy leakage or biased outputs; 2) fairness defenses increase the risk of\nmisuse and privacy leakage; 3) privacy defenses often impair safety and\nexacerbate bias. We further conduct a fine-grained neuron-level analysis to\nuncover the underlying mechanisms of these phenomena. Our analysis reveals the\nexistence of conflict-entangled neurons in LLMs that exhibit opposing\nsensitivities across multiple risk dimensions. Further trend consistency\nanalysis at both task and neuron levels confirms that these neurons play a key\nrole in mediating the emergence of unintended behaviors following defense\ndeployment. We call for a paradigm shift in LLM risk evaluation, toward\nholistic, interaction-aware assessment of defense strategies."}
{"id": "2510.08013", "categories": ["cs.CR", "physics.data-an"], "pdf": "https://arxiv.org/pdf/2510.08013", "abs": "https://arxiv.org/abs/2510.08013", "authors": ["Yurang R. Kuang"], "title": "Composition Law of Conjugate Observables in Random Permutation Sorting Systems", "comment": null, "summary": "We present the discovery of a fundamental composition law governing conjugate\nobservables in the Random Permutation Sorting System (RPSS). The law links the\ndiscrete permutation count Np and the continuous elapsed time T through a\nfunctional relation connecting the characteristic function of timing\ndistributions to the probability generating function of permutation counts.\nThis framework enables entropy purification, transforming microarchitectural\ntiming fluctuations into uniform randomness via geometric convergence. We\nestablish convergence theorems with explicit bounds and validate the results\nexperimentally, achieving Shannon entropy above 7.9998 bits per byte and\nchi-square uniformity across diverse platforms. The composition law provides a\nuniversal foundation for generating provably uniform randomness from\ngeneral-purpose computation, securing cryptographic purity from emergent\ncomputational dynamics."}
{"id": "2510.08084", "categories": ["cs.CR", "cs.AI", "cs.LG"], "pdf": "https://arxiv.org/pdf/2510.08084", "abs": "https://arxiv.org/abs/2510.08084", "authors": ["Hikmat A. M. Abdeljaber", "Md. Alamgir Hossain", "Sultan Ahmad", "Ahmed Alsanad", "Md Alimul Haque", "Sudan Jha", "Jabeen Nazeer"], "title": "A Novel Ensemble Learning Approach for Enhanced IoT Attack Detection: Redefining Security Paradigms in Connected Systems", "comment": "14 pages, 5 fiugres, 7 tables", "summary": "The rapid expansion of Internet of Things (IoT) devices has transformed\nindustries and daily life by enabling widespread connectivity and data\nexchange. However, this increased interconnection has introduced serious\nsecurity vulnerabilities, making IoT systems more exposed to sophisticated\ncyber attacks. This study presents a novel ensemble learning architecture\ndesigned to improve IoT attack detection. The proposed approach applies\nadvanced machine learning techniques, specifically the Extra Trees Classifier,\nalong with thorough preprocessing and hyperparameter optimization. It is\nevaluated on several benchmark datasets including CICIoT2023, IoTID20,\nBotNeTIoT L01, ToN IoT, N BaIoT, and BoT IoT. The results show excellent\nperformance, achieving high recall, accuracy, and precision with very low error\nrates. These outcomes demonstrate the model efficiency and superiority compared\nto existing approaches, providing an effective and scalable method for securing\nIoT environments. This research establishes a solid foundation for future\nprogress in protecting connected devices from evolving cyber threats."}
{"id": "2510.08101", "categories": ["cs.CR"], "pdf": "https://arxiv.org/pdf/2510.08101", "abs": "https://arxiv.org/abs/2510.08101", "authors": ["Simone Bozzolan", "Stefano Calzavara", "Lorenzo Cazzaro"], "title": "LLM-Assisted Web Measurements", "comment": "12 pages, 4 figures, 4 tables", "summary": "Web measurements are a well-established methodology for assessing the\nsecurity and privacy landscape of the Internet. However, existing top lists of\npopular websites commonly used as measurement targets are unlabeled and lack\nsemantic information about the nature of the sites they include. This\nlimitation makes targeted measurements challenging, as researchers often need\nto rely on ad-hoc techniques to bias their datasets toward specific categories\nof interest. In this paper, we investigate the use of Large Language Models\n(LLMs) as a means to enable targeted web measurement studies through their\nsemantic understanding capabilities. Building on prior literature, we identify\nkey website classification tasks relevant to web measurements and construct\ndatasets to systematically evaluate the performance of different LLMs on these\ntasks. Our results demonstrate that LLMs may achieve strong performance across\nmultiple classification scenarios. We then conduct LLM-assisted web measurement\nstudies inspired by prior work and rigorously assess the validity of the\nresulting research inferences. Our results demonstrate that LLMs can serve as a\npractical tool for analyzing security and privacy trends on the Web."}
{"id": "2510.08225", "categories": ["cs.CR"], "pdf": "https://arxiv.org/pdf/2510.08225", "abs": "https://arxiv.org/abs/2510.08225", "authors": ["Daniel Pressensé", "Elisavet Kozyri"], "title": "TracE2E: Easily Deployable Middleware for Decentralized Data Traceability", "comment": null, "summary": "This paper presents TracE2E, a middleware written in Rust, that can provide\nboth data explainability and compliance across multiple nodes. By mediating\ninputs and outputs of processes, TracE2E records provenance information and\nenforces data-protection policies (e.g., confidentiality, integrity) that\ndepend on the recorded provenance. Unlike existing approaches that necessitate\nsubstantial application modifications, TracE2E is designed for easy integration\ninto existing and future applications through a wrapper of the Rust standard\nlibrary's IO module. We describe how TracE2E consistently records provenance\ninformation across nodes, and we demonstrate how the compliance layer of\nTracE2E can accommodate the enforcement of multiple policies."}
{"id": "2510.08272", "categories": ["cs.CR"], "pdf": "https://arxiv.org/pdf/2510.08272", "abs": "https://arxiv.org/abs/2510.08272", "authors": ["Cédrick Austa", "Jan Tobias Mühlberg", "Jean-Michel Dricot"], "title": "Systematic Assessment of Cache Timing Vulnerabilities on RISC-V Processors", "comment": null, "summary": "While interest in the open RISC-V instruction set architecture is growing,\ntools to assess the security of concrete processor implementations are lacking.\nThere are dedicated tools and benchmarks for common microarchitectural\nside-channel vulnerabilities for popular processor families such as Intel\nx86-64 or ARM, but not for RISC-V. In this paper we describe our efforts in\nporting an Intel x86-64 benchmark suite for cache-based timing vulnerabilities\nto RISC-V. We then use this benchmark to evaluate the security of three\ncommercially available RISC-V processors, the T-Head C910 and the SiFive U54\nand U74 cores. We observe that the C910 processor exhibits more distinct timing\ntypes than the other processors, leading to the assumption that code running on\nthe C910 would be exposed to more microarchitectural vulnerability sources. In\naddition, our evaluation reveals that $37.5\\%$ of the vulnerabilities covered\nby the benchmark exist in all processors, while only $6.8\\%$ are absent from\nall cores. Our work, in particular the ported benchmark, aims to support RISC-V\nprocessor designers to identify leakage sources early in their designs and to\nsupport the development of countermeasures."}
{"id": "2510.08333", "categories": ["cs.CR", "cs.LG"], "pdf": "https://arxiv.org/pdf/2510.08333", "abs": "https://arxiv.org/abs/2510.08333", "authors": ["Mikaëla Ngamboé", "Jean-Simon Marrocco", "Jean-Yves Ouattara", "José M. Fernandez", "Gabriela Nicolescu"], "title": "New Machine Learning Approaches for Intrusion Detection in ADS-B", "comment": "This is the author's version of the work accepted for publication\n  Digital Avionics Systems Conference (DASC) 2025. The final version will be\n  available via IEEE Xplore", "summary": "With the growing reliance on the vulnerable Automatic Dependent\nSurveillance-Broadcast (ADS-B) protocol in air traffic management (ATM),\nensuring security is critical. This study investigates emerging machine\nlearning models and training strategies to improve AI-based intrusion detection\nsystems (IDS) for ADS-B. Focusing on ground-based ATM systems, we evaluate two\ndeep learning IDS implementations: one using a transformer encoder and the\nother an extended Long Short-Term Memory (xLSTM) network, marking the first\nxLSTM-based IDS for ADS-B. A transfer learning strategy was employed, involving\npre-training on benign ADS-B messages and fine-tuning with labeled data\ncontaining instances of tampered messages. Results show this approach\noutperforms existing methods, particularly in identifying subtle attacks that\nprogressively undermine situational awareness. The xLSTM-based IDS achieves an\nF1-score of 98.9%, surpassing the transformer-based model at 94.3%. Tests on\nunseen attacks validated the generalization ability of the xLSTM model.\nInference latency analysis shows that the 7.26-second delay introduced by the\nxLSTM-based IDS fits within the Secondary Surveillance Radar (SSR) refresh\ninterval (5-12 s), although it may be restrictive for time-critical operations.\nWhile the transformer-based IDS achieves a 2.1-second latency, it does so at\nthe cost of lower detection performance."}
{"id": "2510.08343", "categories": ["cs.CR"], "pdf": "https://arxiv.org/pdf/2510.08343", "abs": "https://arxiv.org/abs/2510.08343", "authors": ["Anne Müller", "Mohd Kashif", "Nico Döttling"], "title": "A Haskell to FHE Transpiler", "comment": null, "summary": "Fully Homomorphic Encryption (FHE) enables the evaluation of programs\ndirectly on encrypted data. However, because only basic operations can be\nperformed on ciphertexts, programs must be expressed as boolean or arithmetic\ncircuits. This low-level representation makes implementing applications for FHE\nsignificantly more cumbersome than writing code in a high-level language. To\nreduce this burden, several transpilers have been developed that translate\nhigh-level code into circuit representations. In this work, we extend the range\nof high-level languages that can target FHE by introducing a transpiler for\nHaskell, which converts Haskell programs into Boolean circuits suitable for\nhomomorphic evaluation. Our second contribution is the automatic\nparallelization of these generated circuits. We implement an evaluator that\nexecutes gates in parallel by parallelizing each layer of the circuit. We\ndemonstrate the effectiveness of our approach on two key applications: Private\nInformation Retrieval (PIR) and the AES encryption standard. Prior work has\nparallelized AES encryption manually. We demonstrate that the automated method\noutperforms some but not all manual parallelizations of AES evaluations under\nFHE. We achieve an evaluation time of 28 seconds for a parallel execution with\n16 threads and an evaluation time of 8 seconds for a parallel execution with\n100 threads"}
{"id": "2510.08355", "categories": ["cs.CR"], "pdf": "https://arxiv.org/pdf/2510.08355", "abs": "https://arxiv.org/abs/2510.08355", "authors": ["Kaustabh Barman", "Fabian Piper", "Sanjeet Raj Pandey", "Axel Kuepper"], "title": "ExPrESSO: Zero-Knowledge backed Extensive Privacy Preserving Single Sign-on", "comment": null, "summary": "User authentication is one of the most important aspects for secure\ncommunication between services and end-users over the Internet. Service\nproviders leverage Single-Sign On (SSO) to make it easier for their users to\nauthenticate themselves. However, standardized systems for SSO, such as OIDC,\ndo not guarantee user privacy as identity providers can track user activities.\nWe propose a zero-knowledge-based mechanism that integrates with OIDC to let\nusers authenticate through SSO without revealing information about the service\nprovider. Our system leverages Groth's zk-SNARK to prove membership of\nsubscribed service providers without revealing their identity. We adopt a\ndecentralized and verifiable approach to set up the prerequisites of our\nconstruction that further secures and establishes trust in the system. We set\nup high security targets and achieve them with minimal storage and latency\ncost, proving that our research can be adopted for production."}
{"id": "2510.08479", "categories": ["cs.CR", "cs.OS"], "pdf": "https://arxiv.org/pdf/2510.08479", "abs": "https://arxiv.org/abs/2510.08479", "authors": ["Jinsong Mao", "Benjamin E. Ujcich", "Shiqing Ma"], "title": "Rethinking Provenance Completeness with a Learning-Based Linux Scheduler", "comment": null, "summary": "Provenance plays a critical role in maintaining traceability of a system's\nactions for root cause analysis of security threats and impacts. Provenance\ncollection is often incorporated into the reference monitor of systems to\nensure that an audit trail exists of all events, that events are completely\ncaptured, and that logging of such events cannot be bypassed. However, recent\nresearch has questioned whether existing state-of-the-art provenance collection\nsystems fail to ensure the security guarantees of a true reference monitor due\nto the 'super producer threat' in which provenance generation can overload a\nsystem to force the system to drop security-relevant events and allow an\nattacker to hide their actions. One approach towards solving this threat is to\nenforce resource isolation, but that does not fully solve the problems\nresulting from hardware dependencies and performance limitations.\n  In this paper, we show how an operating system's kernel scheduler can\nmitigate this threat, and we introduce Venus, a learned scheduler for Linux\nspecifically designed for provenance. Unlike conventional schedulers that\nignore provenance completeness requirements, Venus leverages reinforcement\nlearning to learn provenance task behavior and to dynamically optimize resource\nallocation. We evaluate Venus's efficacy and show that Venus significantly\nimproves both the completeness and efficiency of provenance collection systems\ncompared to traditional scheduling, while maintaining reasonable overheads and\neven improving overall runtime in certain cases compared to the default Linux\nscheduler."}
{"id": "2510.08496", "categories": ["cs.CR"], "pdf": "https://arxiv.org/pdf/2510.08496", "abs": "https://arxiv.org/abs/2510.08496", "authors": ["Akid Abrar", "Sagar Dasgupta", "Mizanur Rahman", "Ahmad Alsharif"], "title": "AI-Driven Post-Quantum Cryptography for Cyber-Resilient V2X Communication in Transportation Cyber-Physical Systems", "comment": null, "summary": "Transportation Cyber-Physical Systems (TCPS) integrate physical elements,\nsuch as transportation infrastructure and vehicles, with cyber elements via\nadvanced communication technologies, allowing them to interact seamlessly. This\nintegration enhances the efficiency, safety, and sustainability of\ntransportation systems. TCPS rely heavily on cryptographic security to protect\nsensitive information transmitted between vehicles, transportation\ninfrastructure, and other entities within the transportation ecosystem,\nensuring data integrity, confidentiality, and authenticity. Traditional\ncryptographic methods have been employed to secure TCPS communications, but the\nadvent of quantum computing presents a significant threat to these existing\nsecurity measures. Therefore, integrating Post-Quantum Cryptography (PQC) into\nTCPS is essential to maintain secure and resilient communications. While PQC\noffers a promising approach to developing cryptographic algorithms resistant to\nquantum attacks, artificial intelligence (AI) can enhance PQC by optimizing\nalgorithm selection, resource allocation, and adapting to evolving threats in\nreal-time. AI-driven PQC approaches can improve the efficiency and\neffectiveness of PQC implementations, ensuring robust security without\ncompromising system performance. This chapter introduces TCPS communication\nprotocols, discusses the vulnerabilities of corresponding communications to\ncyber-attacks, and explores the limitations of existing cryptographic methods\nin the quantum era. By examining how AI can strengthen PQC solutions, the\nchapter presents cyber-resilient communication strategies for TCPS."}
