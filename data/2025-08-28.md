<div id=toc></div>

# Table of Contents

- [cs.CR](#cs.CR) [Total: 33]


<div id='cs.CR'></div>

# cs.CR [[Back]](#toc)

### [1] [Tight Quantum-Security Bounds and Parameter Optimization for SPHINCS+ and NTRU](https://arxiv.org/abs/2508.19250)
*Ruopengyu Xu,Chenglian Liu*

Main category: cs.CR

TL;DR: 本文为SPHINCS+和NTRU两种后量子密码算法建立了严格的安全边界，通过量子攻击模型和改进的熵集中不等式，显著提升了安全参数效率。


<details>
  <summary>Details</summary>
Motivation: 量子计算的威胁迫切需要量子抗性密码系统，需要对NIST后量子密码决赛算法进行严格的安全分析。

Method: 建立包含退相干效应和并行化限制的量子攻击模型，改进熵集中不等式，优化量子格熵参数，并改进NTRU到LWE的归约证明。

Result: SPHINCS+参数减少15-20%，NTRU格参数得到优化，归约证明获得多项式因子改进，安全性能显著提升。

Conclusion: 研究成果为标准化提供了可实现的参数配置，显著增强了现有构造的安全性。

Abstract: The imminent threat of quantum computing necessitates quantum-resistant
cryptosystems. This paper establishes tight security bounds for two NIST PQC
finalists: SPHINCS+ (hash-based) and NTRU (lattice-based). Our key
contributions include: (1) A quantum attack model incorporating decoherence
effects ($\tau_d$) and parallelization limits; (2) Improved entropy
concentration inequalities reducing SPHINCS+ parameters by 15-20\%; (3)
Optimized NTRU lattice parameters via quantum lattice entropy $H_Q(\Lambda)$;
(4) Tightened NTRU-to-LWE reduction with polynomial-factor improvement.
Theoretical results demonstrate significant security enhancement over existing
constructions, providing implementable parameters for standardization.

</details>


### [2] [The Aegis Protocol: A Foundational Security Framework for Autonomous AI Agents](https://arxiv.org/abs/2508.19267)
*Sai Teja Reddy Adapala,Yashwanth Reddy Alugubelly*

Main category: cs.CR

TL;DR: Aegis协议是一个分层安全框架，为自主AI多智能体系统提供强安全保证，结合去中心化身份、后量子密码学和零知识证明技术，在模拟测试中成功防御了所有攻击。


<details>
  <summary>Details</summary>
Motivation: 随着自主AI智能体的普及，传统网络安全范式无法应对多智能体系统中的系统性安全风险，如控制流劫持和级联故障，需要新的安全解决方案。

Method: 提出Aegis协议，集成三个技术支柱：1) 基于W3C去中心化标识符(DIDs)的不可欺骗智能体身份；2) 基于NIST后量子密码学(PQC)的通信完整性；3) 使用Halo2零知识证明系统(ZKP)的可验证、隐私保护策略合规性。

Result: 通过离散事件模拟对1000个智能体进行测试，在20,000次攻击试验中成功率为0%。策略验证的中位证明生成延迟为2.79秒，为该类安全技术建立了性能基准。

Conclusion: 虽然评估基于模拟且处于早期阶段，但Aegis协议为安全、可扩展的自主AI系统奠定了基础，并为未来实证研究提供了可复现的基准。

Abstract: The proliferation of autonomous AI agents marks a paradigm shift toward
complex, emergent multi-agent systems. This transition introduces systemic
security risks, including control-flow hijacking and cascading failures, that
traditional cybersecurity paradigms are ill-equipped to address. This paper
introduces the Aegis Protocol, a layered security framework designed to provide
strong security guarantees for open agentic ecosystems. The protocol integrates
three technological pillars: (1) non-spoofable agent identity via W3C
Decentralized Identifiers (DIDs); (2) communication integrity via
NIST-standardized post-quantum cryptography (PQC); and (3) verifiable,
privacy-preserving policy compliance using the Halo2 zero-knowledge proof (ZKP)
system. We formalize an adversary model extending Dolev-Yao for agentic threats
and validate the protocol against the STRIDE framework. Our quantitative
evaluation used a discrete-event simulation, calibrated against cryptographic
benchmarks, to model 1,000 agents. The simulation showed a 0 percent success
rate across 20,000 attack trials. For policy verification, analysis of the
simulation logs reported a median proof-generation latency of 2.79 seconds,
establishing a performance baseline for this class of security. While the
evaluation is simulation-based and early-stage, it offers a reproducible
baseline for future empirical studies and positions Aegis as a foundation for
safe, scalable autonomous AI.

</details>


### [3] [MixGAN: A Hybrid Semi-Supervised and Generative Approach for DDoS Detection in Cloud-Integrated IoT Networks](https://arxiv.org/abs/2508.19273)
*Tongxi Wu,Chenwei Xu,Jin Yang*

Main category: cs.CR

TL;DR: MixGAN是一种混合检测方法，结合条件生成、半监督学习和鲁棒特征提取，用于解决云集成IoT系统中的DDoS攻击检测问题，在准确率和检测性能上优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 云集成IoT系统的普及增加了DDoS攻击风险，但由于复杂流量动态、严重类别不平衡和标记数据稀缺，现有检测方法在有限监督和动态流量条件下泛化能力不足。

Method: 使用1-D WideResNet骨干网络捕获流量序列中的局部突发模式；采用预训练CTGAN生成合成少数类样本缓解类别不平衡；提出MixUp-Average-Sharpen策略处理噪声伪标签。

Result: 在NSL-KDD、BoT-IoT和CICIoT2023数据集上，MixGAN相比最先进方法准确率提升2.5%，TPR和TNR均提升4%，证明其在大规模IoT-云环境中的鲁棒性。

Conclusion: MixGAN通过集成多种技术有效解决了IoT-云环境中DDoS检测的挑战，在准确性和鲁棒性方面表现优异，为实际部署提供了可行解决方案。

Abstract: The proliferation of cloud-integrated IoT systems has intensified exposure to
Distributed Denial of Service (DDoS) attacks due to the expanded attack
surface, heterogeneous device behaviors, and limited edge protection. However,
DDoS detection in this context remains challenging because of complex traffic
dynamics, severe class imbalance, and scarce labeled data. While recent methods
have explored solutions to address class imbalance, many still struggle to
generalize under limited supervision and dynamic traffic conditions. To
overcome these challenges, we propose MixGAN, a hybrid detection method that
integrates conditional generation, semi-supervised learning, and robust feature
extraction. Specifically, to handle complex temporal traffic patterns, we
design a 1-D WideResNet backbone composed of temporal convolutional layers with
residual connections, which effectively capture local burst patterns in traffic
sequences. To alleviate class imbalance and label scarcity, we use a pretrained
CTGAN to generate synthetic minority-class (DDoS attack) samples that
complement unlabeled data. Furthermore, to mitigate the effect of noisy
pseudo-labels, we introduce a MixUp-Average-Sharpen (MAS) strategy that
constructs smoothed and sharpened targets by averaging predictions over
augmented views and reweighting them towards high-confidence classes.
Experiments on NSL-KDD, BoT-IoT, and CICIoT2023 demonstrate that MixGAN
achieves up to 2.5% higher accuracy and 4% improvement in both TPR and TNR
compared to state-of-the-art methods, confirming its robustness in large-scale
IoT-cloud environments. The source code is publicly available at
https://github.com/0xCavaliers/MixGAN.

</details>


### [4] [Towards Production-Worthy Simulation for Autonomous Cyber Operations](https://arxiv.org/abs/2508.19278)
*Konur Tholl,Mariam El Mezouar,Ranwa Al Mallah*

Main category: cs.CR

TL;DR: 本研究扩展了CybORG的Cage Challenge 2环境，增加了Patch、Isolate和Unisolate三个新动作，改进了奖励信号和特征空间设计，验证了DQN和PPO智能体的训练效果。


<details>
  <summary>Details</summary>
Motivation: 模拟环境在自主网络操作中至关重要，但需要准确表示网络安全场景并提供有效的训练信号。现有环境需要扩展以更好地反映真实世界中人类操作员的能力。

Method: 扩展CybORG环境添加三个新动作，改进奖励信号和智能体特征空间设计，使用DQN和PPO算法在更新后的环境中进行训练验证。

Result: 研究表明CybORG可以成功扩展额外的现实功能，同时保持其生成有效RL训练信号的能力。

Conclusion: 该框架证明了模拟环境可以通过功能扩展来更好地支持自主网络操作中的强化学习训练，为网络安全领域的RL应用提供了有价值的改进。

Abstract: Simulated environments have proven invaluable in Autonomous Cyber Operations
(ACO) where Reinforcement Learning (RL) agents can be trained without the
computational overhead of emulation. These environments must accurately
represent cybersecurity scenarios while producing the necessary signals to
support RL training. In this study, we present a framework where we first
extend CybORG's Cage Challenge 2 environment by implementing three new actions:
Patch, Isolate, and Unisolate, to better represent the capabilities available
to human operators in real-world settings. We then propose a design for agent
development where we modify the reward signals and the agent's feature space to
enhance training performance. To validate these modifications, we train DQN and
PPO agents in the updated environment. Our study demonstrates that CybORG can
be extended with additional realistic functionality, while maintaining its
ability to generate informative training signals for RL agents.

</details>


### [5] [CORTEX: Composite Overlay for Risk Tiering and Exposure in Operational AI Systems](https://arxiv.org/abs/2508.19281)
*Aoun E Muhammad,Kin Choong Yow,Jamel Baili,Yongwon Cho,Yunyoung Nam*

Main category: cs.CR

TL;DR: CORTEX是一个多层AI风险评分框架，基于1200多个AI事故分析，将故障模式分为29个技术漏洞组，通过五层架构进行综合风险评估。


<details>
  <summary>Details</summary>
Motivation: 随着AI系统在高风险领域的部署增加，系统故障的可能性从理论风险演变为实际的系统性风险，需要有效的风险评估框架。

Method: 基于AI事故数据库的实证分析，开发五层评分架构：效用调整的似然性×影响计算、治理和监管框架对齐、技术表面评分、环境和残余修正、贝叶斯风险聚合和蒙特卡洛模拟。

Result: 提出了CORTEX框架，能够生成复合风险评分，可用于AI风险登记、模型审计、合规检查和动态治理仪表板。

Conclusion: CORTEX提供了一个可操作的多层风险评分框架，能够全面评估AI系统漏洞，支持监管合规和风险管理。

Abstract: As the deployment of Artificial Intelligence (AI) systems in high-stakes
sectors - like healthcare, finance, education, justice, and infrastructure has
increased - the possibility and impact of failures of these systems have
significantly evolved from being a theoretical possibility to practical
recurring, systemic risk. This paper introduces CORTEX (Composite Overlay for
Risk Tiering and Exposure), a multi-layered risk scoring framework proposed to
assess and score AI system vulnerabilities, developed on empirical analysis of
over 1,200 incidents documented in the AI Incident Database (AIID), CORTEX
categorizes failure modes into 29 technical vulnerability groups. Each
vulnerability is scored through a five-tier architecture that combines: (1)
utility-adjusted Likelihood x Impact calculations; (2) governance + contextual
overlays aligned with regulatory frameworks, such as the EU AI Act, NIST RMF,
OECD principles; (3) technical surface scores, covering exposure vectors like
drift, traceability, and adversarial risk; (4) environmental and residual
modifiers tailored to context of where these systems are being deployed to use;
and (5) a final layered assessment via Bayesian risk aggregation and Monte
Carlo simulation to model volatility and long-tail risks. The resulting
composite score can be operationalized across AI risk registers, model audits,
conformity checks, and dynamic governance dashboards.

</details>


### [6] [Rethinking Denial-of-Service: A Conditional Taxonomy Unifying Availability and Sustainability Threats](https://arxiv.org/abs/2508.19283)
*Mark Dorsett,Scott Man,Tim Koussas*

Main category: cs.CR

TL;DR: 提出了一个基于条件的统一框架，用于分类传统和云时代的拒绝服务攻击，包含条件树分类法、层次格结构和维恩图三个模型，通过六个可观察条件实现一致攻击分类。


<details>
  <summary>Details</summary>
Motivation: 为了解决传统DoS攻击分类方法在云时代环境中的局限性，特别是对可持续性攻击识别不足的问题，需要一个统一的理论框架来系统分类各种拒绝服务攻击。

Method: 开发了三个相互关联的模型：基于六个可观察条件（C0-C5）的形式化条件树分类法、基于序理论的层次格结构、以及概念性维恩图，这些条件包括源分布、流量规模、基础设施目标等实际攻击行为特征。

Result: 该框架能够一致地分类已知攻击类型（如DoS、DDoS、LDoS等），支持识别新兴或混合变种，在云原生和无服务器环境中特别有效，为威胁建模和缓解策略设计提供了强大分析工具。

Conclusion: 通过提供具有理论基础和实际应用性的结构化分类法，这项工作推进了对拒绝攻击的理解，为防御者、研究人员和云架构师提供了共享词汇表来解释和缓解不断演变的威胁向量。

Abstract: This paper proposes a unified, condition-based framework for classifying both
legacy and cloud-era denial-of-service (DoS) attacks. The framework comprises
three interrelated models: a formal conditional tree taxonomy, a hierarchical
lattice structure based on order theory, and a conceptual Venn diagram. At its
core, the taxonomy introduces six observable conditions (C0-C5) grounded in
real-world attack behaviours, including source distribution, traffic volume,
infrastructure targeting, and financial exploitation. These conditions enable
consistent classification of known attacks-such as DoS, DDoS, LDoS, LDDoS,
EDoS, DoW, and DDoW, while supporting identification of emerging or hybrid
variants. The lattice structure captures the cumulative satisfaction of
conditions, allowing hierarchical reasoning across denial attack classes. The
Venn diagram highlights conceptual overlaps between availability- and
sustainability-focused attacks, improving comparative insight. Together, these
models provide a robust analytical lens for threat modeling, mitigation
strategy design, and attacker intent classification. The framework is
particularly relevant in cloud-native and serverless environments, where
sustainability-based attacks are increasingly impactful yet under-recognised.
Its extensibility also permits future integration of socio-technical or
behavioural dimensions. By offering a structured taxonomy with theoretical
grounding and real-world applicability, this work advances denial attack
comprehension and equips defenders, researchers, and cloud architects with a
shared vocabulary for interpreting and mitigating evolving threat vectors.

</details>


### [7] [A Comprehensive Review of Denial of Wallet Attacks in Serverless Architectures](https://arxiv.org/abs/2508.19284)
*Mark Dorsett,Scott Mann,Jabed Chowdhury,Abdun Mahmood*

Main category: cs.CR

TL;DR: 本文是关于钱包拒绝(DoW)攻击的系统性文献综述，分析了这种针对无服务器架构的新型攻击方式，重点介绍了攻击分类、检测方法和缓解策略的研究进展。


<details>
  <summary>Details</summary>
Motivation: 钱包拒绝攻击(DoW)对基于FaaS模型的无服务器架构构成独特威胁，通过利用按使用付费的计费模式来增加应用所有者的财务负担，与传统DoS攻击不同，DoW攻击在不影响服务可用性的情况下增加成本。

Method: 通过系统文献综述方法，追踪DoW研究的发展历程，包括攻击分类（如Blast DDoW、Continual Inconspicuous DDoW、Background Chained DDoW）、模拟工具（如DoWTS）的开发，以及机器学习方法（如Gringotts和DoWNet系统）的应用。

Result: 研究提供了首个专门针对钱包拒绝攻击的全面文献综述，深入分析了财务影响、攻击技术、缓解策略和检测机制，并首次详细研究了用于DoW研究的模拟和数据生成工具。

Conclusion: 尽管取得了显著进展，但仍面临缺乏真实世界数据和需要自适应计费模型等挑战。本研究为保护按使用付费云环境的未来研究和行业努力提供了基础资源。

Abstract: The Denial of Wallet (DoW) attack poses a unique and growing threat to
serverless architectures that rely on Function-as-a-Service (FaaS) models,
exploiting the cost structure of pay-as-you-go billing to financially burden
application owners. Unlike traditional Denial of Service (DoS) attacks, which
aim to exhaust resources and disrupt service availability, DoW attacks focus on
escalating costs without impacting service operation. This review traces the
evolution of DoW research, from initial awareness and attack classification to
advancements in detection and mitigation strategies. Key developments include
the categorisation of attack types-such as Blast DDoW, Continual Inconspicuous
DDoW, and Background Chained DDoW-and the creation of simulation tools like
DoWTS, which enable safe experimentation and data generation. Recent
advancements highlight machine learning approaches, including systems like
Gringotts and DoWNet, which leverage deep learning and anomaly detection to
identify malicious traffic patterns. Although substantial progress has been
made, challenges persist, notably the lack of real-world data and the need for
adaptive billing models. This is the first comprehensive literature review
dedicated strictly to Denial of Wallet attacks, providing an in-depth analysis
of their financial impacts, attack techniques, mitigation strategies, and
detection mechanisms within serverless computing. The paper also presents the
first detailed examination of simulation and data generation tools used for DoW
research, addressing a critical gap in existing cybersecurity literature. By
synthesising these key areas, this study serves as a foundational resource for
future research and industry efforts in securing pay-as-you-go cloud
environments.

</details>


### [8] [RL-Finetuned LLMs for Privacy-Preserving Synthetic Rewriting](https://arxiv.org/abs/2508.19286)
*Zhan Shi,Yefeng Yuan,Yuhong Liu,Liang Cheng,Yi Fang*

Main category: cs.CR

TL;DR: 提出基于强化学习的框架，通过复合奖励函数优化LLM，在保持语义质量的同时增强隐私保护，实现隐私保护数据生成。


<details>
  <summary>Details</summary>
Motivation: 大规模机器学习系统需要高质量数据集，但这些数据包含敏感个人信息。传统匿名化技术可能降低性能且无法有效防御推理攻击，需要更强大的隐私保护方案。

Method: 使用强化学习框架微调大语言模型，采用复合奖励函数联合优化显性和隐性隐私、语义保真度和输出多样性。隐私奖励结合语义线索和基于潜在表示最小生成树的结构模式。

Result: 实证结果显示该方法显著增强作者混淆和隐私指标，同时不降低语义质量。

Conclusion: 该方法为大规模语言模型时代提供了可扩展且模型无关的隐私保护数据生成解决方案。

Abstract: The performance of modern machine learning systems depends on access to
large, high-quality datasets, often sourced from user-generated content or
proprietary, domain-specific corpora. However, these rich datasets inherently
contain sensitive personal information, raising significant concerns about
privacy, data security, and compliance with regulatory frameworks. While
conventional anonymization techniques can remove explicit identifiers, such
removal may result in performance drop in downstream machine learning tasks.
More importantly, simple anonymization may not be effective against inference
attacks that exploit implicit signals such as writing style, topical focus, or
demographic cues, highlighting the need for more robust privacy safeguards
during model training. To address the challenging issue of balancing user
privacy and data utility, we propose a reinforcement learning framework that
fine-tunes a large language model (LLM) using a composite reward function that
jointly optimizes for explicit and implicit privacy, semantic fidelity, and
output diversity. To effectively capture population level regularities, the
privacy reward combines semantic cues with structural patterns derived from a
minimum spanning tree (MST) over latent representations. By modeling these
privacy-sensitive signals in their distributional context, the proposed
approach guides the model to generate synthetic rewrites that preserve utility
while mitigating privacy risks. Empirical results show that the proposed method
significantly enhances author obfuscation and privacy metrics without degrading
semantic quality, providing a scalable and model-agnostic solution for privacy
preserving data generation in the era of large language models.

</details>


### [9] [Prompt-in-Content Attacks: Exploiting Uploaded Inputs to Hijack LLM Behavior](https://arxiv.org/abs/2508.19287)
*Zhuotao Lian,Weiyu Wang,Qingkui Zeng,Toru Nakanishi,Teruaki Kitasuka,Chunhua Su*

Main category: cs.CR

TL;DR: 论文发现了一种新的LLM攻击方式——内容注入提示攻击，通过在看似良性的输入中嵌入对抗性指令来操纵模型输出，无需用户察觉或系统入侵。


<details>
  <summary>Details</summary>
Motivation: 随着LLM在文档摘要、问答等应用中的广泛部署，用户提交的内容可能包含隐藏的恶意指令，导致模型产生有偏见的摘要、虚假声明或误导性建议，需要识别和防范这种新型威胁。

Method: 通过在实际流行平台上演示此类攻击的可行性，分析其根本原因（包括提示连接和输入隔离不足），并讨论相应的缓解策略。

Result: 研究证实了内容注入提示攻击在现实世界LLM工作流程中的实际威胁，展示了这种隐蔽但有效的攻击方式。

Conclusion: 论文揭示了一种微妙但实用的LLM安全威胁，强调了在LLM应用中需要加强输入隔离和提示处理的安全性，以防止恶意内容注入攻击。

Abstract: Large Language Models (LLMs) are widely deployed in applications that accept
user-submitted content, such as uploaded documents or pasted text, for tasks
like summarization and question answering. In this paper, we identify a new
class of attacks, prompt in content injection, where adversarial instructions
are embedded in seemingly benign inputs. When processed by the LLM, these
hidden prompts can manipulate outputs without user awareness or system
compromise, leading to biased summaries, fabricated claims, or misleading
suggestions. We demonstrate the feasibility of such attacks across popular
platforms, analyze their root causes including prompt concatenation and
insufficient input isolation, and discuss mitigation strategies. Our findings
reveal a subtle yet practical threat in real-world LLM workflows.

</details>


### [10] [Tricking LLM-Based NPCs into Spilling Secrets](https://arxiv.org/abs/2508.19288)
*Kyohei Shiomi,Zhuotao Lian,Toru Nakanishi,Teruaki Kitasuka*

Main category: cs.CR

TL;DR: 研究探讨对抗性提示注入是否能导致基于LLM的游戏NPC泄露本应保密的背景信息


<details>
  <summary>Details</summary>
Motivation: 随着大型语言模型越来越多地用于生成游戏NPC的动态对话，其集成带来了新的安全隐患，需要研究对抗性攻击对NPC保密信息的影响

Method: 通过对抗性提示注入技术测试LLM-based NPCs

Result: 研究发现对抗性提示注入确实能够导致NPC泄露隐藏的背景秘密

Conclusion: LLM在游戏NPC中的应用需要加强安全防护措施，防止敏感信息通过对抗性攻击被泄露

Abstract: Large Language Models (LLMs) are increasingly used to generate dynamic
dialogue for game NPCs. However, their integration raises new security
concerns. In this study, we examine whether adversarial prompt injection can
cause LLM-based NPCs to reveal hidden background secrets that are meant to
remain undisclosed.

</details>


### [11] [Stand on The Shoulders of Giants: Building JailExpert from Previous Attack Experience](https://arxiv.org/abs/2508.19292)
*Xi Wang,Songlei Jian,Shasha Li,Xiaopeng Li,Bin Ji,Jun Ma,Xiaodong Liu,Jing Wang,Feilong Bao,Jianfeng Zhang,Baosheng Wang,Jie Yu*

Main category: cs.CR

TL;DR: JailExpert是一个自动化越狱框架，通过结构化表示和语义分组利用历史攻击经验，显著提升LLM越狱攻击的成功率和效率


<details>
  <summary>Details</summary>
Motivation: 现有越狱方法忽视历史攻击经验的价值，导致效率低下和重复优化，需要更好地整合过去经验来辅助当前越狱尝试

Method: 提出JailExpert框架，首次实现经验结构的正式表示、基于语义漂移的经验分组，并支持经验池的动态更新

Result: 相比当前最先进的黑盒越狱方法，攻击成功率平均提升17%，攻击效率提高2.7倍

Conclusion: JailExpert通过有效利用历史攻击经验，显著改善了LLM越狱攻击的效果和效率，为识别LLM漏洞和开发鲁棒安全框架提供了有力工具

Abstract: Large language models (LLMs) generate human-aligned content under certain
safety constraints. However, the current known technique ``jailbreak prompt''
can circumvent safety-aligned measures and induce LLMs to output malicious
content. Research on Jailbreaking can help identify vulnerabilities in LLMs and
guide the development of robust security frameworks. To circumvent the issue of
attack templates becoming obsolete as models evolve, existing methods adopt
iterative mutation and dynamic optimization to facilitate more automated
jailbreak attacks. However, these methods face two challenges: inefficiency and
repetitive optimization, as they overlook the value of past attack experiences.
To better integrate past attack experiences to assist current jailbreak
attempts, we propose the \textbf{JailExpert}, an automated jailbreak framework,
which is the first to achieve a formal representation of experience structure,
group experiences based on semantic drift, and support the dynamic updating of
the experience pool. Extensive experiments demonstrate that JailExpert
significantly improves both attack effectiveness and efficiency. Compared to
the current state-of-the-art black-box jailbreak methods, JailExpert achieves
an average increase of 17\% in attack success rate and 2.7 times improvement in
attack efficiency. Our implementation is available at
\href{https://github.com/xiZAIzai/JailExpert}{XiZaiZai/JailExpert}

</details>


### [12] [Leveraging 3D Technologies for Hardware Security: Opportunities and Challenges](https://arxiv.org/abs/2508.19309)
*Peng Gu,Shuangchen Li,Dylan Stow,Russell Barnes,Liu Liu,Yuan Xie,Eren Kursshan*

Main category: cs.CR

TL;DR: 本文探讨了利用2.5D和3D集成电路技术特性来增强系统安全性的新方法，包括侧信道防护、安全制造和内存计算安全等创新设计


<details>
  <summary>Details</summary>
Motivation: 当前2.5D/3D集成技术面临侧信道攻击、硬件木马、安全制造和IP盗版等新兴安全挑战，需要利用这些技术的固有特性来设计更安全的系统

Method: 提出了四种安全设计方案：1）用于屏蔽侧信道信息的3D架构；2）使用有源中介层的分割制造；3）单片3D IC上的电路伪装技术；4）基于3D IC的安全内存计算（PIM）

Result: 新设计能够改进现有安全威胁的对抗措施，并提供新的安全特性，展示了2.5D/3D技术在安全应用方面的优势

Conclusion: 2.5D和3D集成电路技术为解决现代硬件安全挑战提供了新的机遇，通过利用其固有特性可以设计出更强大的安全防护系统

Abstract: 3D die stacking and 2.5D interposer design are promising technologies to
improve integration density, performance and cost. Current approaches face
serious issues in dealing with emerging security challenges such as side
channel attacks, hardware trojans, secure IC manufacturing and IP piracy. By
utilizing intrinsic characteristics of 2.5D and 3D technologies, we propose
novel opportunities in designing secure systems. We present: (i) a 3D
architecture for shielding side-channel information; (ii) split fabrication
using active interposers; (iii) circuit camouflage on monolithic 3D IC, and
(iv) 3D IC-based security processing-in-memory (PIM). Advantages and challenges
of these designs are discussed, showing that the new designs can improve
existing countermeasures against security threats and further provide new
security features.

</details>


### [13] [An Investigation on Group Query Hallucination Attacks](https://arxiv.org/abs/2508.19321)
*Kehao Miao,Xiaolong Jin*

Main category: cs.CR

TL;DR: 本文提出了Group Query Attack攻击方法，通过同时向大语言模型提交多个查询来模拟真实用户交互场景，发现该方法能显著降低微调模型的性能并可能触发潜在后门。


<details>
  <summary>Details</summary>
Motivation: 随着大语言模型的广泛应用，理解其在用户交互中的潜在失败模式至关重要。用户经常在单次对话中提出多个问题，因此需要研究连续提示的累积上下文如何影响模型输出。

Method: 提出Group Query Attack技术，通过同时向LLMs提交查询组来模拟多问题交互场景，研究累积上下文对模型输出的影响。

Result: Group Query Attack显著降低了特定任务微调模型的性能，可能触发LLMs的潜在后门，且在数学推理和代码生成等推理任务中对预训练和对齐模型也有效。

Conclusion: Group Query Attack揭示了LLMs在多查询交互场景中的脆弱性，强调了在实际应用中需要考虑累积上下文对模型安全性和性能的影响。

Abstract: With the widespread use of large language models (LLMs), understanding their
potential failure modes during user interactions is essential. In practice,
users often pose multiple questions in a single conversation with LLMs.
Therefore, in this study, we propose Group Query Attack, a technique that
simulates this scenario by presenting groups of queries to LLMs simultaneously.
We investigate how the accumulated context from consecutive prompts influences
the outputs of LLMs. Specifically, we observe that Group Query Attack
significantly degrades the performance of models fine-tuned on specific tasks.
Moreover, we demonstrate that Group Query Attack induces a risk of triggering
potential backdoors of LLMs. Besides, Group Query Attack is also effective in
tasks involving reasoning, such as mathematical reasoning and code generation
for pre-trained and aligned models.

</details>


### [14] [A Technical Review on Comparison and Estimation of Steganographic Tools](https://arxiv.org/abs/2508.19323)
*Ms. Preeti P. Bhatt,Rakesh R. Savant*

Main category: cs.CR

TL;DR: 该论文对六种常用图像隐写工具进行了比较分析，基于图像特征评估了不同工具在文本嵌入方面的性能表现。


<details>
  <summary>Details</summary>
Motivation: 随着隐写技术的发展，市场上出现了多种图像隐写工具，需要对这些工具的性能进行系统评估和比较，以确定最佳工具选择。

Method: 选择了六种常用隐写工具，使用相同的输入图像和嵌入文本进行测试，基于图像大小、尺寸、像素值和直方图差异等特征进行分析比较。

Result: 实验结果显示六种工具性能水平相近，但某些软件在效率方面表现更好，性能差异主要基于图像特征的不同。

Conclusion: 所有测试工具都能有效执行隐写任务，但选择时应考虑具体的图像特征要求，不同工具在不同场景下各有优势。

Abstract: Steganography is technique of hiding a data under cover media using different
steganography tools. Image steganography is hiding of data
(Text/Image/Audio/Video) under a cover as Image. This review paper presents
classification of image steganography and the comparison of various Image
steganography tools using different image formats. Analyzing numerous tools on
the basis of Image features and extracting the best one. Some of the tools
available in the market were selected based on the frequent use; these tools
were tested using the same input on all of them. Specific text was embedded
within all host images for each of the six Steganography tools selected. The
results of the experiment reveal that all the six tools were relatively
performing at the same level, though some software performs better than others
through efficiency. And it was based on the image features like size,
dimensions, and pixel value and histogram differentiation.

</details>


### [15] [Just Dork and Crawl: Measuring Illegal Online Gambling Defacement in Indonesian Websites](https://arxiv.org/abs/2508.19368)
*Luqman Muhammad Zagi,Girindro Pringgo Digdo,Wervyan Shalannanda*

Main category: cs.CR

TL;DR: 本研究使用关键词搜索和爬虫技术，在一个月内识别了453个被非法在线赌博推广者篡改的印尼网站，揭示了篡改行为的多样性和网站响应不一致的问题。


<details>
  <summary>Details</summary>
Motivation: 调查印尼网站被非法在线赌博推广者篡改的情况，了解篡改行为的规模、持续性和动态特征，为加强网络安全防御提供依据。

Method: 采用轻量级方法，结合关键词驱动的搜索和系统化爬虫技术，通过关键词计数可靠区分真假阳性结果。

Result: 发现453个被篡改网页，识别出重复篡改(150例)、固定实例(129例)、关键词修改(55例)和重定向等多种行为，捕获8,837个第三方URL，平均响应时间75.3小时。

Conclusion: 简单可复现的技术能够有效洞察网站篡改的规模和动态，强调持续监测对于防御在线赌博活动的重要性。

Abstract: This study investigates the defacement of Indonesian websites by actors
promoting illegal online gambling. Using a lightweight methodology that
combines keyword-driven dorking with systematic crawling, we identified 453
defaced webpages within one month. Although dorking alone yielded a false
positive rate of approximately 20.3\%, the integration of crawling and
keyword-counting enabled reliable differentiation between true and false
positives. Our measurements revealed diverse defacement behaviors, including
repeat defacements (150 cases), fixed instances (129), keyword modifications
(55), and redirections or hidden URL injections. In total, 8,837 unique
third-party URLs spanning 5,930 domains were captured, with a small subset
recurring across multiple sites. Website responses were inconsistent, with an
average reaction time of 75.3 hours. These findings demonstrate that simple,
reproducible techniques can provide meaningful insights into the scale,
persistence, and dynamics of defacement, highlighting the importance of
continuous measurement for strengthening defenses against online gambling
activities.

</details>


### [16] [A NIS2 pan-European registry for identifying and classifying essential and important entities](https://arxiv.org/abs/2508.19395)
*Fabian Aude Steen,Daniel Assani Shabani*

Main category: cs.CR

TL;DR: 该论文分析NIS2指令并将其法律条款转化为技术需求，设计了一个模块化的注册系统，支持欧盟成员国自动化实体注册、分类和监管流程。


<details>
  <summary>Details</summary>
Motivation: NIS2指令要求欧盟成员国建立网络安全治理框架，但缺乏具体的技术实施方案。论文旨在将复杂的法律条款转化为可执行的技术系统，减轻行政负担。

Method: 采用设计科学研究方法，将法律条款转化为结构化工作流、确定性分类算法和交互式仪表板，开发模块化注册系统。

Result: 成功开发了一个支持自动和手动注册的系统，包含情境标签系统处理边缘案例，实现了关键监管流程的自动化。

Conclusion: 论文提供了一个可重用的框架，连接法律解释和技术实施，为NIS2网络安全治理提供了可扩展的解决方案，并指出了未来研究方向。

Abstract: The NIS2 Directive establishes a common cybersecurity governance model across
the European Union, requiring member states to identify, classify, and
supervise essential and important entities. As part of a broader governance
network, member states are also obligated to notify the European Commission,
the Cooperation Group, and ENISA about their cybersecurity infrastructure
landscape. This thesis presents an analysis of the NIS2 Directive in this
context and translates its provisions into concrete technical requirements.
These requirements inform the design and implementation of a modular, legally
grounded registry system intended to support competent authorities across the
EU in meeting their obligations. Using the Design Science Research methodology,
the thesis transforms complex legal provisions into structured workflows,
deterministic classification algorithms, and interactive dashboards. The
resulting system automates key regulatory processes, including entity
registration, classification, and notification, while enabling context-aware
supervision and reducing administrative burden. It supports both automated and
manual registration methods and introduces a contextual labeling system to
handle edge cases, risk factors, and cross-directive dependencies. Although
developed for the Norwegian regulatory ecosystem, the system is designed for
adaptation by other member states with minimal modification. This thesis
contributes a reusable framework that bridges legal interpretation and
technical implementation, offering a scalable solution for national and
EU-level NIS2 cybersecurity governance. It also identifies key limitations and
outlines opportunities for future research and development.

</details>


### [17] [Formal Verification of Physical Layer Security Protocols for Next-Generation Communication Networks](https://arxiv.org/abs/2508.19430)
*Kangfeng Ye,Roberto Metere,Jim Woodcock,Poonam Yadav*

Main category: cs.CR

TL;DR: 本文提出基于Isabelle形式化方法重新建模Needham-Schroeder协议，克服ProVerif验证局限，实现交互式安全协议验证，支持密码学和物理层安全技术，发现真实性在所有场景下保持完整的新结论。


<details>
  <summary>Details</summary>
Motivation: 现有基于ProVerif的验证方法限制了安全理解的深度，无法超越验证结果进行更深入的分析，需要开发更强大的形式化验证框架。

Method: 使用Isabelle形式化方法重新建模协议，生成可靠的动画验证，支持交互式和自动化验证，构建通用可配置的验证框架，整合密码学和物理层安全技术（水印和干扰）。

Result: 成功复现并加强了先前关于保密性的结果，发现了一个罕见但预期的结果：在所有检查场景中（包括保密性受损的情况）真实性都得以保持，提出的基于物理层安全的Diffie-Hellman协议在会话密钥推导和认证方面安全。

Conclusion: 新方法在形式化验证安全属性方面展现出超越传统方法的鲁棒性优势，为安全协议验证提供了更强大的分析能力。

Abstract: Formal verification is crucial for ensuring the robustness of security
protocols against adversarial attacks. The Needham-Schroeder protocol, a
foundational authentication mechanism, has been extensively studied, including
its integration with Physical Layer Security (PLS) techniques such as
watermarking and jamming. Recent research has used ProVerif to verify these
mechanisms in terms of secrecy. However, the ProVerif-based approach limits the
ability to improve understanding of security beyond verification results. To
overcome these limitations, we re-model the same protocol using an Isabelle
formalism that generates sound animation, enabling interactive and automated
formal verification of security protocols. Our modelling and verification
framework is generic and highly configurable, supporting both cryptography and
PLS. For the same protocol, we have conducted a comprehensive analysis (secrecy
and authenticity in four different eavesdropper locations under both passive
and active attacks) using our new web interface. Our findings not only
successfully reproduce and reinforce previous results on secrecy but also
reveal an uncommon but expected outcome: authenticity is preserved across all
examined scenarios, even in cases where secrecy is compromised. We have
proposed a PLS-based Diffie-Hellman protocol that integrates watermarking and
jamming, and our analysis shows that it is secure for deriving a session key
with required authentication. These highlight the advantages of our novel
approach, demonstrating its robustness in formally verifying security
properties beyond conventional methods.

</details>


### [18] [CITADEL: Continual Anomaly Detection for Enhanced Learning in IoT Intrusion Detection](https://arxiv.org/abs/2508.19450)
*Elvin Li,Onat Gungor,Zhengli Shang,Tajana Rosing*

Main category: cs.CR

TL;DR: CITADEL是一个自监督持续学习框架，通过将表格数据转换为图像、使用记忆感知掩码自编码器和新颖性检测组件，有效解决IoT入侵检测中的灾难性遗忘问题，在多个数据集上比VLAD方法提升72.9%


<details>
  <summary>Details</summary>
Motivation: IoT设备互联性强但计算资源有限，容易受到网络威胁。传统机器学习入侵检测系统(ML-IDS)在面对新兴威胁时适应性差，且在持续学习中存在灾难性遗忘问题

Method: 提出CITADEL框架：1)表格到图像转换模块；2)记忆感知掩码自编码器进行自监督表示学习；3)新颖性检测组件，无需标记攻击数据即可识别异常

Result: 在多个入侵检测数据集上的实验表明，CITADEL在关键检测和保留指标上比基于VAE的终身异常检测器(VLAD)提升高达72.9%

Conclusion: CITADEL能够增量适应新兴行为同时保持检测已知威胁的能力，在动态IoT环境中表现出色

Abstract: The Internet of Things (IoT), with its high degree of interconnectivity and
limited computational resources, is particularly vulnerable to a wide range of
cyber threats. Intrusion detection systems (IDS) have been extensively studied
to enhance IoT security, and machine learning-based IDS (ML-IDS) show
considerable promise for detecting malicious activity. However, their
effectiveness is often constrained by poor adaptability to emerging threats and
the issue of catastrophic forgetting during continuous learning. To address
these challenges, we propose CITADEL, a self-supervised continual learning
framework designed to extract robust representations from benign data while
preserving long-term knowledge through optimized memory consolidation
mechanisms. CITADEL integrates a tabular-to-image transformation module, a
memory-aware masked autoencoder for self-supervised representation learning,
and a novelty detection component capable of identifying anomalies without
dependence on labeled attack data. Our design enables the system to
incrementally adapt to emerging behaviors while retaining its ability to detect
previously observed threats. Experiments on multiple intrusion datasets
demonstrate that CITADEL achieves up to a 72.9% improvement over the VAE-based
lifelong anomaly detector (VLAD) in key detection and retention metrics,
highlighting its effectiveness in dynamic IoT environments.

</details>


### [19] [ReLATE+: Unified Framework for Adversarial Attack Detection, Classification, and Resilient Model Selection in Time-Series Classification](https://arxiv.org/abs/2508.19456)
*Cagla Ipek Kocal,Onat Gungor,Tajana Rosing,Baris Aksanli*

Main category: cs.CR

TL;DR: ReLATE+是一个对抗性攻击检测和分类框架，通过数据集相似性自适应选择深度学习模型，显著减少计算开销和重训练成本，同时保持强大性能。


<details>
  <summary>Details</summary>
Motivation: 时间序列分类中深度学习模型计算开销大，对抗性攻击进一步加剧了挑战，需要既能确保鲁棒性能又能高效选择模型的解决方案。

Method: ReLATE+首先检测输入数据是否为对抗性攻击并分类攻击类型，然后基于数据集相似性从知识库中选择最佳性能模型进行重用，避免重新训练。

Result: 实验显示ReLATE+平均减少77.68%的计算开销，在对抗性韧性方面表现优异，性能仅比Oracle低2.02%。

Conclusion: 该框架在保持高性能的同时显著降低了计算成本和重训练需求，具有良好的跨领域泛化能力，适用于不同数据分布和特征空间的时间序列分类任务。

Abstract: Minimizing computational overhead in time-series classification, particularly
in deep learning models, presents a significant challenge due to the high
complexity of model architectures and the large volume of sequential data that
must be processed in real time. This challenge is further compounded by
adversarial attacks, emphasizing the need for resilient methods that ensure
robust performance and efficient model selection. To address this challenge, we
propose ReLATE+, a comprehensive framework that detects and classifies
adversarial attacks, adaptively selects deep learning models based on
dataset-level similarity, and thus substantially reduces retraining costs
relative to conventional methods that do not leverage prior knowledge, while
maintaining strong performance. ReLATE+ first checks whether the incoming data
is adversarial and, if so, classifies the attack type, using this insight to
identify a similar dataset from a repository and enable the reuse of the
best-performing associated model. This approach ensures strong performance
while reducing the need for retraining, and it generalizes well across
different domains with varying data distributions and feature spaces.
Experiments show that ReLATE+ reduces computational overhead by an average of
77.68%, enhancing adversarial resilience and streamlining robust model
selection, all without sacrificing performance, within 2.02% of Oracle.

</details>


### [20] [Addressing Weak Authentication like RFID, NFC in EVs and EVCs using AI-powered Adaptive Authentication](https://arxiv.org/abs/2508.19465)
*Onyinye Okoye*

Main category: cs.CR

TL;DR: 本文提出了一种AI驱动的自适应认证框架，用于解决电动汽车充电系统的网络安全问题，替代传统的RFID和NFC等易受攻击的静态认证机制。


<details>
  <summary>Details</summary>
Motivation: 电动汽车和充电系统的快速发展带来了新的网络安全挑战，传统认证机制（如RFID和NFC）使用静态标识符和弱加密，容易受到克隆、中继攻击和信号拦截等攻击向量的威胁。

Method: 研究探索了一种AI驱动的自适应认证框架，整合机器学习、异常检测、行为分析和上下文风险评估，基于零信任架构原则，强调持续验证、最小权限访问和安全通信。

Result: 通过全面的文献综述，研究评估了当前漏洞，并强调了AI驱动解决方案能够提供可扩展、弹性和主动防御的能力。

Conclusion: 采用AI驱动的自适应认证对于保障电动出行未来安全和加强整个生态系统的数字信任具有战略必要性。

Abstract: The rapid expansion of the Electric Vehicles (EVs) and Electric Vehicle
Charging Systems (EVCs) has introduced new cybersecurity challenges,
specifically in authentication protocols that protect vehicles, users, and
energy infrastructure. Although widely adopted for convenience, traditional
authentication mechanisms like Radio Frequency Identification (RFID) and Near
Field Communication (NFC) rely on static identifiers and weak encryption,
making them highly vulnerable to attack vectors such as cloning, relay attacks,
and signal interception. This study explores an AI-powered adaptive
authentication framework designed to overcome these shortcomings by integrating
machine learning, anomaly detection, behavioral analytics, and contextual risk
assessment. Grounded in the principles of Zero Trust Architecture, the proposed
framework emphasizes continuous verification, least privilege access, and
secure communication. Through a comprehensive literature review, this research
evaluates current vulnerabilities and highlights AI-driven solutions to provide
a scalable, resilient, and proactive defense. Ultimately, the research findings
conclude that adopting AI-powered adaptive authentication is a strategic
imperative for securing the future of electric mobility and strengthening
digital trust across the ecosystem. Keywords: weak authentication, RFID, NFC,
ML, AI-powered adaptive authentication, relay attacks, cloning, eavesdropping,
MITM attacks, Zero Trust Architecture

</details>


### [21] [SIExVulTS: Sensitive Information Exposure Vulnerability Detection System using Transformer Models and Static Analysis](https://arxiv.org/abs/2508.19472)
*Kyler Katz,Sara Moshtari,Ibrahim Mujhid,Mehdi Mirakhorli,Derek Garcia*

Main category: cs.CR

TL;DR: SIExVulTS是一个结合Transformer模型和静态分析的漏洞检测系统，专门用于检测Java应用中的敏感信息泄露漏洞(CWE-200)，在多个数据集上表现出色并发现了新的CVE漏洞。


<details>
  <summary>Details</summary>
Motivation: 敏感信息泄露漏洞(CWE-200)是软件系统中持续存在且未被充分解决的威胁，现有检测工具很少针对CWE-200的多样化子类别或提供代码级数据流的上下文感知分析。

Method: 采用三阶段架构：(1)攻击面检测引擎使用句子嵌入识别敏感变量、字符串、注释和接收器；(2)暴露分析引擎实例化与CWE-200层次结构对齐的CodeQL查询；(3)流验证引擎利用GraphCodeBERT语义验证源到接收器流。使用三个策划数据集进行评估。

Result: 攻击面检测引擎平均F1分数超过93%，暴露分析引擎F1分数85.71%，流验证引擎将精度从22.61%提升至87.23%。成功发现了Apache主要项目中的6个先前未知的CVE漏洞。

Conclusion: SIExVulTS在检测和验证CWE-200漏洞方面有效且实用，解决了现有工具的局限性，能够提高软件安全性对抗敏感数据泄露。

Abstract: Sensitive Information Exposure (SIEx) vulnerabilities (CWE-200) remain a
persistent and under-addressed threat across software systems, often leading to
serious security breaches. Existing detection tools rarely target the diverse
subcategories of CWE-200 or provide context-aware analysis of code-level data
flows.
  Aims: This paper aims to present SIExVulTS, a novel vulnerability detection
system that integrates transformer-based models with static analysis to
identify and verify sensitive information exposure in Java applications.
  Method: SIExVulTS employs a three-stage architecture: (1) an Attack Surface
Detection Engine that uses sentence embeddings to identify sensitive variables,
strings, comments, and sinks; (2) an Exposure Analysis Engine that instantiates
CodeQL queries aligned with the CWE-200 hierarchy; and (3) a Flow Verification
Engine that leverages GraphCodeBERT to semantically validate source-to-sink
flows. We evaluate SIExVulTS using three curated datasets, including real-world
CVEs, a benchmark set of synthetic CWE-200 examples, and labeled flows from 31
open-source projects.
  Results: The Attack Surface Detection Engine achieved an average F1 score
greater than 93\%, the Exposure Analysis Engine achieved an F1 score of
85.71\%, and the Flow Verification Engine increased precision from 22.61\% to
87.23\%. Moreover, SIExVulTS successfully uncovered six previously unknown CVEs
in major Apache projects.
  Conclusions: The results demonstrate that SIExVulTS is effective and
practical for improving software security against sensitive data exposure,
addressing limitations of existing tools in detecting and verifying CWE-200
vulnerabilities.

</details>


### [22] [Mind the Third Eye! Benchmarking Privacy Awareness in MLLM-powered Smartphone Agents](https://arxiv.org/abs/2508.19493)
*Zhixin Lin,Jungang Li,Shidong Pan,Yibo Shi,Yue Yao,Dongliang Xu*

Main category: cs.CR

TL;DR: 首个大规模智能手机助手隐私意识测识基准，包含7138个场景，发现底层助手隐私意识能力不足（平均不超60%），闭源模型表现更佳


<details>
  <summary>Details</summary>
Motivation: 智能手机助手在自动化任务时获得大量敏感个人信息，必须研究其隐私意识能力以保护用户隐私

Method: 构建包含7138个场景的大规模基准测试集，注释隐私类型、敏感度等级和位置信息，对比测诅7款主流智能手机助手

Result: 所有测试助手隐私意识能力都不满意（RA<60%），闭源助手表现更好，Gemini 2.0-flash最佳（67%），敏感度越高的场景识别率越高

Conclusion: 智能手机助手在功能性与隐私保护间存在不平衡，需重新思考这种交换关系，研究社群应提高助手的隐私意识能力

Abstract: Smartphones bring significant convenience to users but also enable devices to
extensively record various types of personal information. Existing smartphone
agents powered by Multimodal Large Language Models (MLLMs) have achieved
remarkable performance in automating different tasks. However, as the cost,
these agents are granted substantial access to sensitive users' personal
information during this operation. To gain a thorough understanding of the
privacy awareness of these agents, we present the first large-scale benchmark
encompassing 7,138 scenarios to the best of our knowledge. In addition, for
privacy context in scenarios, we annotate its type (e.g., Account Credentials),
sensitivity level, and location. We then carefully benchmark seven available
mainstream smartphone agents. Our results demonstrate that almost all
benchmarked agents show unsatisfying privacy awareness (RA), with performance
remaining below 60% even with explicit hints. Overall, closed-source agents
show better privacy ability than open-source ones, and Gemini 2.0-flash
achieves the best, achieving an RA of 67%. We also find that the agents'
privacy detection capability is highly related to scenario sensitivity level,
i.e., the scenario with a higher sensitivity level is typically more
identifiable. We hope the findings enlighten the research community to rethink
the unbalanced utility-privacy tradeoff about smartphone agents. Our code and
benchmark are available at https://zhixin-l.github.io/SAPA-Bench.

</details>


### [23] [Servant, Stalker, Predator: How An Honest, Helpful, And Harmless (3H) Agent Unlocks Adversarial Skills](https://arxiv.org/abs/2508.19500)
*David Noever*

Main category: cs.CR

TL;DR: 本文识别并分析了基于模型上下文协议(MCP)的智能体系统中的新型漏洞类别，展示了如何通过编排良性授权任务产生有害的涌现行为。


<details>
  <summary>Details</summary>
Motivation: 研究MCP智能体系统中存在的组合攻击漏洞，揭示服务隔离安全假设在多域协调场景下的失效问题。

Method: 使用MITRE ATLAS框架进行系统分析，测试95个具有多种服务访问权限的智能体，包括浏览器自动化、金融分析、位置跟踪和代码部署等服务。

Result: 发现智能体能够将合法操作链接成复杂的攻击序列，突破单个服务的安全边界，实现数据窃取、金融操纵和基础设施破坏等目标。

Conclusion: 当前MCP架构缺乏跨域安全措施，随着能力增加攻击面呈指数级增长，需要新的安全框架来应对组合攻击威胁。

Abstract: This paper identifies and analyzes a novel vulnerability class in Model
Context Protocol (MCP) based agent systems. The attack chain describes and
demonstrates how benign, individually authorized tasks can be orchestrated to
produce harmful emergent behaviors. Through systematic analysis using the MITRE
ATLAS framework, we demonstrate how 95 agents tested with access to multiple
services-including browser automation, financial analysis, location tracking,
and code deployment-can chain legitimate operations into sophisticated attack
sequences that extend beyond the security boundaries of any individual service.
These red team exercises survey whether current MCP architectures lack
cross-domain security measures necessary to detect or prevent a large category
of compositional attacks. We present empirical evidence of specific attack
chains that achieve targeted harm through service orchestration, including data
exfiltration, financial manipulation, and infrastructure compromise. These
findings reveal that the fundamental security assumption of service isolation
fails when agents can coordinate actions across multiple domains, creating an
exponential attack surface that grows with each additional capability. This
research provides a barebones experimental framework that evaluate not whether
agents can complete MCP benchmark tasks, but what happens when they complete
them too well and optimize across multiple services in ways that violate human
expectations and safety constraints. We propose three concrete experimental
directions using the existing MCP benchmark suite.

</details>


### [24] [Breaking the Layer Barrier: Remodeling Private Transformer Inference with Hybrid CKKS and MPC](https://arxiv.org/abs/2508.19525)
*Tianshi Xu,Wen-jie Lu,Jiangrui Yu,Chen Yi,Chenqi Lin,Runsheng Wang,Meng Li*

Main category: cs.CR

TL;DR: BLB框架结合同态加密和安全多方计算，通过细粒度算子分解和线性算子融合，显著降低了Transformer私有推理的通信开销和延迟。


<details>
  <summary>Details</summary>
Motivation: 现有方法在同态加密(HE)和安全多方计算(MPC)之间转换时产生高通信成本，需要更高效的隐私保护推理方案。

Method: 提出BLB框架：1）将层分解为细粒度算子并融合相邻线性算子；2）提出首个CKKS与MPC间的安全转换协议；3）设计高效的矩阵乘法协议用于融合计算。

Result: 在BERT-base、BERT-large和GPT2-base上评估，相比BOLT通信开销降低21倍，相比Bumblebee降低2倍；延迟分别降低13倍和1.8倍。

Conclusion: BLB通过算子融合和安全协议创新，显著提升了私有Transformer推理的效率，为隐私保护深度学习提供了实用解决方案。

Abstract: This paper presents an efficient framework for private Transformer inference
that combines Homomorphic Encryption (HE) and Secure Multi-party Computation
(MPC) to protect data privacy. Existing methods often leverage HE for linear
layers (e.g., matrix multiplications) and MPC for non-linear layers (e.g.,
Softmax activation functions), but the conversion between HE and MPC introduces
significant communication costs. The proposed framework, dubbed BLB, overcomes
this by breaking down layers into fine-grained operators and further fusing
adjacent linear operators, reducing the need for HE/MPC conversions. To manage
the increased ciphertext bit width from the fused linear operators, BLB
proposes the first secure conversion protocol between CKKS and MPC and enables
CKKS-based computation of the fused operators. Additionally, BLB proposes an
efficient matrix multiplication protocol for fused computation in Transformers.
Extensive evaluations on BERT-base, BERT-large, and GPT2-base show that BLB
achieves a $21\times$ reduction in communication overhead compared to BOLT
(S\&P'24) and a $2\times$ reduction compared to Bumblebee (NDSS'25), along with
latency reductions of $13\times$ and $1.8\times$, respectively, when leveraging
GPU acceleration.

</details>


### [25] [Intellectual Property in Graph-Based Machine Learning as a Service: Attacks and Defenses](https://arxiv.org/abs/2508.19641)
*Lincan Li,Bolin Shen,Chenxi Zhao,Yuxiang Sun,Kaixiang Zhao,Shirui Pan,Yushun Dong*

Main category: cs.CR

TL;DR: 这篇论文系统性评估图机器学习(GML)中的知识产权保护问题，提出了威胁和防御方法的分类法，并开源了PyGIP库来支持相关研究。


<details>
  <summary>Details</summary>
Motivation: 因为图机器学习模型训练资源强度大，GMLaaS服务模式带来敏感数据泄漏和模型盗用的安全风险，需要系统性的知识产权保护方案。

Method: 构建了GML模型和图结构数据层面的威胁与防御分类法，设计系统性评估框架，编译多领域的标准数据集，并开发了PyGIP库来支持攻防技术的实现和评测。

Result: 提供了首个专门针对GML知识产权保护的综述性研究，建立了完整的分类体系和评估标准，并通过PyGIP库为社区提供了实用工具。

Conclusion: 该研究在GML知识产权保护领域发挥基础性作用，为社区提供了实用的解决方案和研究工具，并指明了未来的研究挑战和方向。

Abstract: Graph-structured data, which captures non-Euclidean relationships and
interactions between entities, is growing in scale and complexity. As a result,
training state-of-the-art graph machine learning (GML) models have become
increasingly resource-intensive, turning these models and data into invaluable
Intellectual Property (IP). To address the resource-intensive nature of model
training, graph-based Machine-Learning-as-a-Service (GMLaaS) has emerged as an
efficient solution by leveraging third-party cloud services for model
development and management. However, deploying such models in GMLaaS also
exposes them to potential threats from attackers. Specifically, while the APIs
within a GMLaaS system provide interfaces for users to query the model and
receive outputs, they also allow attackers to exploit and steal model
functionalities or sensitive training data, posing severe threats to the safety
of these GML models and the underlying graph data. To address these challenges,
this survey systematically introduces the first taxonomy of threats and
defenses at the level of both GML model and graph-structured data. Such a
tailored taxonomy facilitates an in-depth understanding of GML IP protection.
Furthermore, we present a systematic evaluation framework to assess the
effectiveness of IP protection methods, introduce a curated set of benchmark
datasets across various domains, and discuss their application scopes and
future challenges. Finally, we establish an open-sourced versatile library
named PyGIP, which evaluates various attack and defense techniques in GMLaaS
scenarios and facilitates the implementation of existing benchmark methods. The
library resource can be accessed at: https://labrai.github.io/PyGIP. We believe
this survey will play a fundamental role in intellectual property protection
for GML and provide practical recipes for the GML community.

</details>


### [26] [Safety Alignment Should Be Made More Than Just A Few Attention Heads](https://arxiv.org/abs/2508.19697)
*Chao Huang,Zefeng Zhang,Juewei Yue,Quangang Li,Chuang Zhang,Tingwen Liu*

Main category: cs.CR

TL;DR: 本文发现LLM安全机制过度依赖少数注意力头，提出RDSHA方法识别关键安全头，并开发AHD训练策略来分散安全能力，显著提升模型抗攻击能力。


<details>
  <summary>Details</summary>
Motivation: 当前大语言模型的安全对齐存在漏洞，对抗性提示可以绕过安全措施。研究发现安全机制主要依赖有限的注意力头，移除这些头会严重损害模型安全性。

Method: 提出RDSHA方法利用模型的拒绝方向来识别负责安全行为的关键注意力头；开发AHD训练策略，促进安全相关行为在多个注意力头中的分布式编码。

Result: 实验表明AHD成功将安全相关能力分散到更多注意力头中；在多种主流越狱攻击下，AHD训练的模型展现出显著更强的安全鲁棒性，同时保持整体功能效用。

Conclusion: 通过分布式编码安全行为到多个注意力头，可以有效提升大语言模型的安全鲁棒性，为解决当前安全对齐的脆弱性提供了有效方案。

Abstract: Current safety alignment for large language models(LLMs) continues to present
vulnerabilities, given that adversarial prompting can effectively bypass their
safety measures.Our investigation shows that these safety mechanisms
predominantly depend on a limited subset of attention heads: removing or
ablating these heads can severely compromise model safety. To identify and
evaluate these safety-critical components, we introduce RDSHA, a targeted
ablation method that leverages the model's refusal direction to pinpoint
attention heads mostly responsible for safety behaviors. Further analysis shows
that existing jailbreak attacks exploit this concentration by selectively
bypassing or manipulating these critical attention heads. To address this
issue, we propose AHD, a novel training strategy designed to promote the
distributed encoding of safety-related behaviors across numerous attention
heads. Experimental results demonstrate that AHD successfully distributes
safety-related capabilities across more attention heads. Moreover, evaluations
under several mainstream jailbreak attacks show that models trained with AHD
exhibit considerably stronger safety robustness, while maintaining overall
functional utility.

</details>


### [27] [Addressing Deepfake Issue in Selfie banking through camera based authentication](https://arxiv.org/abs/2508.19714)
*Subhrojyoti Mukherjee,Manoranjan Mohanty*

Main category: cs.CR

TL;DR: 利用现有的法医识别系统（原用于图片相机定位）来检测deepfake伪造的自拍银行图像


<details>
  <summary>Details</summary>
Motivation: 深度学习技术能够生成高度逼真的假身份，欺诈者利用这些技术绕过在线银行的面部识别等生物识别系统，自拍银行中的假图像威胁日益严重

Method: 探索使用已建立的法医识别系统（原本用于图片相机定位）来进行深度伪造检测

Result: 未在摘要中明确说明具体结果

Conclusion: 将现有的法医分析技术应用于deepfake检测领域具有潜在价值

Abstract: Fake images in selfie banking are increasingly becoming a threat. Previously,
it was just Photoshop, but now deep learning technologies enable us to create
highly realistic fake identities, which fraudsters exploit to bypass biometric
systems such as facial recognition in online banking. This paper explores the
use of an already established forensic recognition system, previously used for
picture camera localization, in deepfake detection.

</details>


### [28] [The Art of Hide and Seek: Making Pickle-Based Model Supply Chain Poisoning Stealthy Again](https://arxiv.org/abs/2508.19774)
*Tong Liu,Guozhu Meng,Peng Zhou,Zizhuang Deng,Shuaiyin Yao,Kai Chen*

Main category: cs.CR

TL;DR: 本文系统性地揭示了Python pickle反序列化漏洞在AI/ML模型共享平台中的严重安全隐患，发现了现有扫描器的重大检测盲区，并提出了可绕过所有扫描器的攻击技术。


<details>
  <summary>Details</summary>
Motivation: 尽管pickle反序列化漏洞长期存在且风险显著，但许多AI/ML框架仍使用pickle作为模型序列化协议。随着开源模型生态的发展，模型共享平台如Hugging Face的普及，pickle漏洞的现实风险被显著放大，而现有扫描器对攻击面的理解不完整导致检测逻辑脆弱。

Method: 从模型加载和危险函数两个角度系统分析pickle-based模型投毒攻击面。识别了5个主流AI/ML框架中的22种pickle模型加载路径，开发了名为"异常导向编程(EOP)"的绕过技术，并发现了133个可利用的gadget。

Result: 发现19个加载路径被现有扫描器完全忽略，开发了9个EOP实例（其中7个可绕过所有扫描器），133个可利用gadget的绕过率接近100%，即使对最佳扫描器也保持89%的绕过率。

Conclusion: 研究揭示了pickle-based模型投毒攻击面的系统性漏洞，实现了对现实世界扫描器的实用且强大的绕过，相关发现已负责任地披露给厂商并获得认可和6000美元漏洞奖金。

Abstract: Pickle deserialization vulnerabilities have persisted throughout Python's
history, remaining widely recognized yet unresolved. Due to its ability to
transparently save and restore complex objects into byte streams, many AI/ML
frameworks continue to adopt pickle as the model serialization protocol despite
its inherent risks. As the open-source model ecosystem grows, model-sharing
platforms such as Hugging Face have attracted massive participation,
significantly amplifying the real-world risks of pickle exploitation and
opening new avenues for model supply chain poisoning. Although several
state-of-the-art scanners have been developed to detect poisoned models, their
incomplete understanding of the poisoning surface leaves the detection logic
fragile and allows attackers to bypass them. In this work, we present the first
systematic disclosure of the pickle-based model poisoning surface from both
model loading and risky function perspectives. Our research demonstrates how
pickle-based model poisoning can remain stealthy and highlights critical gaps
in current scanning solutions. On the model loading surface, we identify 22
distinct pickle-based model loading paths across five foundational AI/ML
frameworks, 19 of which are entirely missed by existing scanners. We further
develop a bypass technique named Exception-Oriented Programming (EOP) and
discover 9 EOP instances, 7 of which can bypass all scanners. On the risky
function surface, we discover 133 exploitable gadgets, achieving almost a 100%
bypass rate. Even against the best-performing scanner, these gadgets maintain
an 89% bypass rate. By systematically revealing the pickle-based model
poisoning surface, we achieve practical and robust bypasses against real-world
scanners. We responsibly disclose our findings to corresponding vendors,
receiving acknowledgments and a $6000 bug bounty.

</details>


### [29] [From Research to Reality: Feasibility of Gradient Inversion Attacks in Federated Learning](https://arxiv.org/abs/2508.19819)
*Viktor Valadi,Mattias Åkesson,Johan Östman,Salman Toor,Andreas Hellander*

Main category: cs.CR

TL;DR: 本文系统分析了联邦学习中梯度反演攻击的可行性，发现在推理模式下攻击更容易成功，而在训练模式下需要特定架构条件。作者提出了两种新攻击方法，并首次攻击了生产级目标检测模型，提供了架构选择和操作模式对隐私影响的全面分析。


<details>
  <summary>Details</summary>
Motivation: 现有研究大多关注推理模式下的梯度反演攻击，忽略了训练模式下的实际场景。本文旨在系统分析不同架构和训练行为对隐私漏洞的影响，提供更现实的攻击可行性评估。

Method: 1) 系统分析推理模式和训练模式下架构对漏洞的影响；2) 提出两种针对训练模式模型的新攻击方法；3) 首次对生产级目标检测模型进行攻击测试；4) 建立架构选择与操作模式对隐私影响的综合映射。

Result: 发现推理模式下攻击显著简化，训练模式下成功攻击需要同时满足多个架构条件：模型必须浅而宽、使用跳跃连接、关键要采用预激活归一化。新攻击方法在现实训练条件下达到最先进性能，生产级模型需要大量架构修改才能实现可识别泄漏。

Conclusion: 本文重新定义了梯度反演风险评估框架，提供了模型何时易受攻击、何时表现鲁棒以及细微泄漏可能存在的全面指导，为未来研究和部署场景中的隐私风险评估提供了重要见解。

Abstract: Gradient inversion attacks have garnered attention for their ability to
compromise privacy in federated learning. However, many studies consider
attacks with the model in inference mode, where training-time behaviors like
dropout are disabled and batch normalization relies on fixed statistics. In
this work, we systematically analyze how architecture and training behavior
affect vulnerability, including the first in-depth study of inference-mode
clients, which we show dramatically simplifies inversion. To assess attack
feasibility under more realistic conditions, we turn to clients operating in
standard training mode. In this setting, we find that successful attacks are
only possible when several architectural conditions are met simultaneously:
models must be shallow and wide, use skip connections, and, critically, employ
pre-activation normalization. We introduce two novel attacks against models in
training-mode with varying attacker knowledge, achieving state-of-the-art
performance under realistic training conditions. We extend these efforts by
presenting the first attack on a production-grade object-detection model. Here,
to enable any visibly identifiable leakage, we revert to the lenient inference
mode setting and make multiple architectural modifications to increase model
vulnerability, with the extent of required changes highlighting the strong
inherent robustness of such architectures. We conclude this work by offering
the first comprehensive mapping of settings, clarifying which combinations of
architectural choices and operational modes meaningfully impact privacy. Our
analysis provides actionable insight into when models are likely vulnerable,
when they appear robust, and where subtle leakage may persist. Together, these
findings reframe how gradient inversion risk should be assessed in future
research and deployment scenarios.

</details>


### [30] [Every Keystroke You Make: A Tech-Law Measurement and Analysis of Event Listeners for Wiretapping](https://arxiv.org/abs/2508.19825)
*Shaoor Munir,Nurullah Demir,Qian Li,Konrad Kollnig,Zubair Shafiq*

Main category: cs.CR

TL;DR: 该研究将美国历史悠久的窃听法应用于网络跟踪技术，发现38.52%的网站使用第三方事件监听器拦截击键，其中3.18%将拦截信息传输给第三方服务器，符合窃听法标准。


<details>
  <summary>Details</summary>
Motivation: 现有研究主要关注GDPR和CCPA等新隐私法律的合规性，但缺乏有效执法。研究者希望通过技术-法律分析，将美国已有的窃听法应用于网络跟踪，为隐私保护提供更有力的法律依据。

Method: 使用仪器化浏览器爬取前百万网站样本，分析JavaScript事件监听器的使用情况，特别是用于实时击键拦截的第三方跟踪器，并根据联邦和加州窃听法标准进行评估。

Result: 发现38.52%的网站安装第三方事件监听器拦截击键，3.18%的网站将拦截信息传输给第三方服务器，符合窃听法标准。证据表明拦截的电子邮件地址被用于未经请求的电子邮件营销。

Conclusion: 研究成功将技术测量与美国窃听法相结合，揭示了广泛存在的潜在非法跟踪行为。需要进一步的法律研究来确定观察到的窃听行为何时构成违法。

Abstract: The privacy community has a long track record of investigating emerging types
of web tracking techniques. Recent work has focused on compliance of web
trackers with new privacy laws such as Europe's GDPR and California's CCPA.
Despite the growing body of research documenting widespread lack of compliance
with new privacy laws, there is a lack of robust enforcement. Different from
prior work, we conduct a tech-law analysis to map decades-old U.S. laws about
interception of electronic communications--so-called wiretapping--to web
tracking. Bridging the tech-law gap for older wiretapping laws is important and
timely because, in cases where legal harm to privacy is proven, they can
provide statutory private right of action, are at the forefront of recent
privacy enforcement, and could ultimately lead to a meaningful change in the
web tracking landscape.
  In this paper, we focus on a particularly invasive tracking technique: the
use of JavaScript event listeners by third-party trackers for real-time
keystroke interception on websites. We use an instrumented web browser to crawl
a sample of the top-million websites to investigate the use of event listeners
that aligns with the criteria for wiretapping, according to U.S. wiretapping
law at the federal level and in California. We find evidence that 38.52%
websites installed third-party event listeners to intercept keystrokes, and
that at least 3.18% websites transmitted intercepted information to a
third-party server, which aligns with the criteria for wiretapping. We further
find evidence that the intercepted information such as email addresses typed
into form fields are used for unsolicited email marketing. Beyond our work that
maps the intersection between technical measurement and U.S. wiretapping law,
additional future legal research is required to determine when the wiretapping
observed in our paper passes the threshold for illegality.

</details>


### [31] [SoK: Large Language Model Copyright Auditing via Fingerprinting](https://arxiv.org/abs/2508.19843)
*Shuo Shao,Yiming Li,Yu He,Hongwei Yao,Wenyuan Yang,Dacheng Tao,Zhan Qin*

Main category: cs.CR

TL;DR: 这篇论文是首个大型语言模型指纹识别的系统性研究，提出了统一框架和标准化评测基准LeaFBench，用于评估在实际部署场景下的模型指纹识别效果。


<details>
  <summary>Details</summary>
Motivation: 大型语言模型作为重要知识产权容易受到版权侵权和模型盗用的威胁，而模型指纹技术作为非侵入性的版权审计方案可能性不确定，需要系统性评估。

Method: 提出了统一框架和形式分类法，将现有方法分为白盒和黑盒方法，并构建LeaFBench标准化评测基准，包含149个不同模型实例和13种代表性后编辑技术。

Result: 通过在LeaFBench上的大规模实验，揭示了现有模型指纹识别方法的优缺点，为该领域的未来研究指明了方向。

Conclusion: 该研究为LLM指纹识别领域提供了系统性的分析框架和标准化评测方法，显示了现有技术的限制和挑战，为保护大型语言模型知识产权提供了重要技术支撑。

Abstract: The broad capabilities and substantial resources required to train Large
Language Models (LLMs) make them valuable intellectual property, yet they
remain vulnerable to copyright infringement, such as unauthorized use and model
theft. LLM fingerprinting, a non-intrusive technique that extracts and compares
the distinctive features from LLMs to identify infringements, offers a
promising solution to copyright auditing. However, its reliability remains
uncertain due to the prevalence of diverse model modifications and the lack of
standardized evaluation. In this SoK, we present the first comprehensive study
of LLM fingerprinting. We introduce a unified framework and formal taxonomy
that categorizes existing methods into white-box and black-box approaches,
providing a structured overview of the state of the art. We further propose
LeaFBench, the first systematic benchmark for evaluating LLM fingerprinting
under realistic deployment scenarios. Built upon mainstream foundation models
and comprising 149 distinct model instances, LeaFBench integrates 13
representative post-development techniques, spanning both parameter-altering
methods (e.g., fine-tuning, quantization) and parameter-independent mechanisms
(e.g., system prompts, RAG). Extensive experiments on LeaFBench reveal the
strengths and weaknesses of existing methods, thereby outlining future research
directions and critical open problems in this emerging field. The code is
available at https://github.com/shaoshuo-ss/LeaFBench.

</details>


### [32] [SCAMPER -- Synchrophasor Covert chAnnel for Malicious and Protective ERrands](https://arxiv.org/abs/2508.20051)
*Prashanth Krishnamurthy,Ramesh Karri,Farshad Khorrami*

Main category: cs.CR

TL;DR: SCAMPER框架利用IEEE C37.118同步相量通信协议中时间戳字段的过度配置特性，建立隐蔽信道，既可进行恶意攻击也可用于防御目的。


<details>
  <summary>Details</summary>
Motivation: 发现同步相量通信协议中的时间戳字段存在过度配置问题，可能被滥用于建立隐蔽信道，需要研究其安全影响和防护措施。

Method: 开发SCAMPER框架，通过修改时间戳字段建立隐蔽通信，在硬件在环测试平台上进行实验验证。

Result: 证明SCAMPER能够在不影响电力系统运行的情况下实现设备间的隐蔽通信，既可用于触发恶意攻击，也可作为加密数据完整性机制检测虚假数据注入攻击。

Conclusion: 同步相量通信协议中的过度配置字段存在安全风险，但通过SCAMPER框架可以将其转化为防御工具，为电力系统安全提供新的保护机制。

Abstract: We note that constituent fields (notably the fraction-of-seconds timestamp
field) in the data payload structure of the synchrophasor communication
protocol (IEEE C37.118 standard) are overprovisioned relative to real-world
usage and needs, lending themselves to abuse for embedding of covert channels.
We develop the SCAMPER (Synchrophasor Covert Channel for Malicious and
Protective ERrands) framework to exploit these overprovisioned fields for
covert communication and show that SCAMPER can be applied for both malicious
(attack) and protective (defense) purposes. Through modifications of the
timestamp field, we demonstrate that SCAMPER enables an attacker to accomplish
surreptitious communications between devices in the power system to trigger a
variety of malicious actions. These timestamp modifications can be performed
without having any impact on the operation of the power system. However, having
recognized the potential for this covert channel, we show that SCAMPER can
instead be applied for defensive security purposes as an integrated
cryptographic data integrity mechanism that can facilitate detection of false
data injection (FDI) attacks. We perform experimental studies of the proposed
methods on two Hardware-in-the-Loop (HIL) testbeds to demonstrate the
effectiveness of the proposed SCAMPER framework for both malicious and
protective purposes.

</details>


### [33] [Disabling Self-Correction in Retrieval-Augmented Generation via Stealthy Retriever Poisoning](https://arxiv.org/abs/2508.20083)
*Yanbo Dai,Zhenlan Ji,Zongjie Li,Kuan Li,Shuai Wang*

Main category: cs.CR

TL;DR: DisarmRAG是一种针对RAG系统的新型攻击方法，通过毒化检索器本身来绕过LLMs的自我纠正能力，实现攻击者指定的恶意输出生成。


<details>
  <summary>Details</summary>
Motivation: 现有RAG攻击主要针对知识库，但现代LLMs的自我纠正能力(SCA)可以拒绝虚假上下文，这使得传统攻击方法失效。因此需要开发新的攻击范式来绕过SCA。

Method: 提出基于对比学习的模型编辑技术，对检索器进行局部隐蔽编辑，使其仅在特定查询时返回恶意指令；设计迭代协同优化框架自动发现能绕过提示防御的鲁棒指令。

Result: 在6个LLMs和3个QA基准测试中，恶意指令检索成功率接近完美，攻击成功率超过90%，且编辑后的检索器在多种检测方法下保持隐蔽性。

Conclusion: DisarmRAG攻击揭示了RAG系统检索器层面的安全漏洞，强调了开发检索器中心防御机制的紧迫性。

Abstract: Retrieval-Augmented Generation (RAG) has become a standard approach for
improving the reliability of large language models (LLMs). Prior work
demonstrates the vulnerability of RAG systems by misleading them into
generating attacker-chosen outputs through poisoning the knowledge base.
However, this paper uncovers that such attacks could be mitigated by the strong
\textit{self-correction ability (SCA)} of modern LLMs, which can reject false
context once properly configured. This SCA poses a significant challenge for
attackers aiming to manipulate RAG systems.
  In contrast to previous poisoning methods, which primarily target the
knowledge base, we introduce \textsc{DisarmRAG}, a new poisoning paradigm that
compromises the retriever itself to suppress the SCA and enforce
attacker-chosen outputs. This compromisation enables the attacker to
straightforwardly embed anti-SCA instructions into the context provided to the
generator, thereby bypassing the SCA. To this end, we present a
contrastive-learning-based model editing technique that performs localized and
stealthy edits, ensuring the retriever returns a malicious instruction only for
specific victim queries while preserving benign retrieval behavior. To further
strengthen the attack, we design an iterative co-optimization framework that
automatically discovers robust instructions capable of bypassing prompt-based
defenses. We extensively evaluate DisarmRAG across six LLMs and three QA
benchmarks. Our results show near-perfect retrieval of malicious instructions,
which successfully suppress SCA and achieve attack success rates exceeding 90\%
under diverse defensive prompts. Also, the edited retriever remains stealthy
under several detection methods, highlighting the urgent need for
retriever-centric defenses.

</details>
