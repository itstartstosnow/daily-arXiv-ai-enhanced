<div id=toc></div>

# Table of Contents

- [cs.CR](#cs.CR) [Total: 39]


<div id='cs.CR'></div>

# cs.CR [[Back]](#toc)

### [1] [Pro-ZD: A Transferable Graph Neural Network Approach for Proactive Zero-Day Threats Mitigation](https://arxiv.org/abs/2602.07073)
*Nardine Basta,Firas Ben Hmida,Houssem Jmal,Muhammad Ikram,Mohamed Ali Kaafar,Andy Walker*

Main category: cs.CR

TL;DR: 提出Pro-ZD框架，使用图神经网络识别加权最短路径，检测网络配置错误和高风险连接路径，自动调整防火墙规则以防止零日攻击。


<details>
  <summary>Details</summary>
Motivation: 企业网络面临流量增加和架构多样化的挑战，自动化工具生成防火墙规则和访问策略，但动态生成策略带来的风险（特别是关键资产暴露）难以有效管理，加上远程办公、自带设备和云集成等趋势使网络结构不断演变。

Method: 提出新颖的图神经网络模型识别加权最短路径，构建Pro-ZD框架，采用主动方法自动微调防火墙规则和访问策略，处理高风险连接并防止未授权访问。

Result: 实验结果显示Pro-ZD具有鲁棒性和可迁移性，在检测高风险连接方面平均准确率超过95%。

Conclusion: Pro-ZD框架能有效识别网络配置错误和高风险连接路径，自动调整安全策略，为防范零日攻击提供主动防护方案。

Abstract: In today's enterprise network landscape, the combination of perimeter and distributed firewall rules governs connectivity. To address challenges arising from increased traffic and diverse network architectures, organizations employ automated tools for firewall rule and access policy generation. Yet, effectively managing risks arising from dynamically generated policies, especially concerning critical asset exposure, remains a major challenge. This challenge is amplified by evolving network structures due to trends like remote users, bring-your-own devices, and cloud integration. This paper introduces a novel graph neural network model for identifying weighted shortest paths. The model aids in detecting network misconfigurations and high-risk connectivity paths that threaten critical assets, potentially exploited in zero-day attacks -- cyber-attacks exploiting undisclosed vulnerabilities. The proposed Pro-ZD framework adopts a proactive approach, automatically fine-tuning firewall rules and access policies to address high-risk connections and prevent unauthorized access. Experimental results highlight the robustness and transferability of Pro-ZD, achieving over 95% average accuracy in detecting high-risk connections. \

</details>


### [2] [Concept-Aware Privacy Mechanisms for Defending Embedding Inversion Attacks](https://arxiv.org/abs/2602.07090)
*Yu-Che Tsai,Hsiang Hsiao,Kuan-Yu Chen,Shou-De Lin*

Main category: cs.CR

TL;DR: SPARSE是一个用户中心的文本嵌入隐私保护框架，通过可微分掩码学习识别隐私敏感维度，并使用马氏机制注入椭圆噪声，在保护用户定义概念隐私的同时保持下游任务性能。


<details>
  <summary>Details</summary>
Motivation: 文本嵌入面临严重的隐私风险，现有的差分隐私防御方法假设所有维度具有均匀敏感性，导致噪声过大和效用下降。需要一种能够针对特定概念提供隐私保护的方法。

Method: SPARSE框架结合两个核心技术：1）可微分掩码学习，识别用户定义概念的隐私敏感维度；2）马氏机制，根据维度敏感性注入椭圆噪声，选择性扰动隐私敏感维度。

Result: 在六个数据集、三种嵌入模型和多种攻击场景下的评估表明，SPARSE能持续减少隐私泄露，同时在多个下游任务上优于现有差分隐私方法。

Conclusion: SPARSE提供了一种有效的概念特定隐私保护方法，通过选择性扰动隐私敏感维度，在保护隐私的同时保持了文本嵌入的实用性。

Abstract: Text embeddings enable numerous NLP applications but face severe privacy risks from embedding inversion attacks, which can expose sensitive attributes or reconstruct raw text. Existing differential privacy defenses assume uniform sensitivity across embedding dimensions, leading to excessive noise and degraded utility. We propose SPARSE, a user-centric framework for concept-specific privacy protection in text embeddings. SPARSE combines (1) differentiable mask learning to identify privacy-sensitive dimensions for user-defined concepts, and (2) the Mahalanobis mechanism that applies elliptical noise calibrated by dimension sensitivity. Unlike traditional spherical noise injection, SPARSE selectively perturbs privacy-sensitive dimensions while preserving non-sensitive semantics. Evaluated across six datasets with three embedding models and attack scenarios, SPARSE consistently reduces privacy leakage while achieving superior downstream performance compared to state-of-the-art DP methods.

</details>


### [3] [ShallowJail: Steering Jailbreaks against Large Language Models](https://arxiv.org/abs/2602.07107)
*Shang Liu,Hanyu Pei,Zeyan Liu*

Main category: cs.CR

TL;DR: ShallowJail是一种利用LLMs浅层对齐漏洞的新型攻击方法，通过操纵推理过程中的初始token来误导模型产生有害输出，相比现有方法更高效且隐蔽。


<details>
  <summary>Details</summary>
Motivation: 尽管LLMs经过对齐训练以防止有害输出，但它们仍然容易受到越狱攻击。现有攻击方法要么是黑盒的（使用精心设计但不隐蔽的提示），要么是白盒的（需要大量计算资源），因此需要一种更高效且隐蔽的攻击方法。

Method: ShallowJail通过利用LLMs的浅层对齐漏洞，在推理过程中操纵初始token来误导模型响应。这种方法不需要复杂的提示工程或大量计算资源。

Result: 通过大量实验证明，ShallowJail能显著降低最先进LLMs的安全性，有效引导模型产生有害输出。

Conclusion: ShallowJail揭示了LLMs浅层对齐的脆弱性，为理解和防御越狱攻击提供了新视角，表明需要更深入的对齐方法来确保模型安全。

Abstract: Large Language Models(LLMs) have been successful in numerous fields. Alignment has usually been applied to prevent them from harmful purposes. However, aligned LLMs remain vulnerable to jailbreak attacks that deliberately mislead them into producing harmful outputs. Existing jailbreaks are either black-box, using carefully crafted, unstealthy prompts, or white-box, requiring resource-intensive computation. In light of these challenges, we introduce ShallowJail, a novel attack that exploits shallow alignment in LLMs. ShallowJail can misguide LLMs' responses by manipulating the initial tokens during inference. Through extensive experiments, we demonstrate the effectiveness of~\shallow, which substantially degrades the safety of state-of-the-art LLM responses.

</details>


### [4] [Trojans in Artificial Intelligence (TrojAI) Final Report](https://arxiv.org/abs/2602.07152)
*Kristopher W. Reese,Taylor Kulp-McDowall,Michael Majurski,Tim Blattner,Derek Juba,Peter Bajcsy,Antonio Cardone,Philippe Dessauw,Alden Dima,Anthony J. Kearsley,Melinda Kleczynski,Joel Vasanth,Walid Keyrouz,Chace Ashcraft,Neil Fendley,Ted Staley,Trevor Stout,Josh Carney,Greg Canal,Will Redman,Aurora Schmidt,Cameron Hickert,William Paul,Jared Markowitz,Nathan Drenkow,David Shriver,Marissa Connor,Keltin Grimes,Marco Christiani,Hayden Moore,Jordan Widjaja,Kasimir Gabert,Uma Balakrishnan,Satyanadh Gundimada,John Jacobellis,Sandya Lakkur,Vitus Leung,Jon Roose,Casey Battaglino,Farinaz Koushanfar,Greg Fields,Xihe Gu,Yaman Jandali,Xinqiao Zhang,Akash Vartak,Tim Oates,Ben Erichson,Michael Mahoney,Rauf Izmailov,Xiangyu Zhang,Guangyu Shen,Siyuan Cheng,Shiqing Ma,XiaoFeng Wang,Haixu Tang,Di Tang,Xiaoyi Chen,Zihao Wang,Rui Zhu,Susmit Jha,Xiao Lin,Manoj Acharya,Wenchao Li,Chao Chen*

Main category: cs.CR

TL;DR: IARPA TrojAI项目旨在应对AI木马威胁，通过多年研究探索威胁本质、开发检测方法并识别未解决挑战，为AI安全领域提供关键见解。


<details>
  <summary>Details</summary>
Motivation: 应对现代人工智能中新兴的AI木马威胁，这些恶意后门被故意嵌入AI模型中，可能导致系统意外失败或被恶意行为者劫持。

Method: 通过权重分析和触发器反演等检测方法，以及部署模型的木马风险缓解方法，进行综合测试和评估。

Result: 项目绘制了威胁的复杂性质，开创了基础检测方法，识别了需要持续关注的未解决挑战，并提供了检测器性能、敏感性和"自然"木马普遍性的评估结果。

Conclusion: 报告总结了经验教训，并提出了推进AI安全研究的建议，强调需要持续关注这一新兴威胁领域。

Abstract: The Intelligence Advanced Research Projects Activity (IARPA) launched the TrojAI program to confront an emerging vulnerability in modern artificial intelligence: the threat of AI Trojans. These AI trojans are malicious, hidden backdoors intentionally embedded within an AI model that can cause a system to fail in unexpected ways, or allow a malicious actor to hijack the AI model at will. This multi-year initiative helped to map out the complex nature of the threat, pioneered foundational detection methods, and identified unsolved challenges that require ongoing attention by the burgeoning AI security field. This report synthesizes the program's key findings, including methodologies for detection through weight analysis and trigger inversion, as well as approaches for mitigating Trojan risks in deployed models. Comprehensive test and evaluation results highlight detector performance, sensitivity, and the prevalence of "natural" Trojans. The report concludes with lessons learned and recommendations for advancing AI security research.

</details>


### [5] [Lite-BD: A Lightweight Black-box Backdoor Defense via Reviving Multi-Stage Image Transformations](https://arxiv.org/abs/2602.07197)
*Abdullah Arafat Miah,Yu Bi*

Main category: cs.CR

TL;DR: Lite-BD：一种轻量级两阶段黑盒后门防御方法，通过下上采样和频带滤波有效破坏后门触发器


<details>
  <summary>Details</summary>
Motivation: 深度神经网络易受后门攻击，现有黑盒防御方法存在局限性：缺乏特定变换的合理性、数据集依赖、计算开销大、忽视频域变换。需要更有效、轻量级的黑盒防御方案。

Method: 提出Lite-BD两阶段防御：1）基于超分辨率的下上采样阶段破坏空间触发器；2）基于查询的频带滤波阶段移除特定频带中的隐藏触发器

Result: 在对抗最先进攻击的广泛实验中，Lite-BD展现出鲁棒且高效的防御效果，代码已开源

Conclusion: Lite-BD通过结合空间和频域变换，为黑盒后门防御提供了有效且轻量级的解决方案，解决了现有方法的多个局限性

Abstract: Deep Neural Networks (DNNs) are vulnerable to backdoor attacks. Due to the nature of Machine Learning as a Service (MLaaS) applications, black-box defenses are more practical than white-box methods, yet existing purification techniques suffer from key limitations: a lack of justification for specific transformations, dataset dependency, high computational overhead, and a neglect of frequency-domain transformations. This paper conducts a preliminary study on various image transformations, identifying down-upscaling as the most effective backdoor trigger disruption technique. We subsequently propose \texttt{Lite-BD}, a lightweight two-stage blackbox backdoor defense. \texttt{Lite-BD} first employs a super-resolution-based down-upscaling stage to neutralize spatial triggers. A secondary stage utilizes query-based band-by-band frequency filtering to remove triggers hidden in specific bands. Extensive experiments against state-of-the-art attacks demonstrate that \texttt{Lite-BD} provides robust and efficient protection. Codes can be found at https://github.com/SiSL-URI/Lite-BD.

</details>


### [6] [BadSNN: Backdoor Attacks on Spiking Neural Networks via Adversarial Spiking Neuron](https://arxiv.org/abs/2602.07200)
*Abdullah Arafat Miah,Kevin Vu,Yu Bi*

Main category: cs.CR

TL;DR: BadSNN是一种针对脉冲神经网络的新型后门攻击，利用脉冲神经元超参数变化注入后门行为，并通过触发器优化实现更好的攻击性能和隐蔽性。


<details>
  <summary>Details</summary>
Motivation: 脉冲神经网络（SNNs）作为深度神经网络（DNNs）的能量高效对应物具有高生物合理性，但如何利用SNNs的独特特性进行后门攻击尚未充分探索。现有研究主要关注DNNs的后门攻击，而SNNs的特殊神经元模型（如LIF）包含重要超参数，这为攻击提供了新机会。

Method: BadSNN通过利用脉冲神经元的超参数变化（如膜电位阈值和膜时间常数）向模型中注入后门行为。进一步提出触发器优化过程，在提高攻击性能的同时使触发模式更不易察觉。攻击在各种数据集和架构上进行了验证。

Result: BadSNN在多个数据集和架构上展现出优越的攻击性能，相比最先进的数据投毒后门攻击表现更好。同时，该攻击对常见的后门缓解技术具有鲁棒性。

Conclusion: BadSNN成功展示了如何利用SNNs的独特特性进行高效后门攻击，揭示了SNNs在安全方面的脆弱性，为未来SNNs安全研究提供了重要参考。

Abstract: Spiking Neural Networks (SNNs) are energy-efficient counterparts of Deep Neural Networks (DNNs) with high biological plausibility, as information is transmitted through temporal spiking patterns. The core element of an SNN is the spiking neuron, which converts input data into spikes following the Leaky Integrate-and-Fire (LIF) neuron model. This model includes several important hyperparameters, such as the membrane potential threshold and membrane time constant. Both the DNNs and SNNs have proven to be exploitable by backdoor attacks, where an adversary can poison the training dataset with malicious triggers and force the model to behave in an attacker-defined manner. Yet, how an adversary can exploit the unique characteristics of SNNs for backdoor attacks remains underexplored. In this paper, we propose \textit{BadSNN}, a novel backdoor attack on spiking neural networks that exploits hyperparameter variations of spiking neurons to inject backdoor behavior into the model. We further propose a trigger optimization process to achieve better attack performance while making trigger patterns less perceptible. \textit{BadSNN} demonstrates superior attack performance on various datasets and architectures, as well as compared with state-of-the-art data poisoning-based backdoor attacks and robustness against common backdoor mitigation techniques. Codes can be found at https://github.com/SiSL-URI/BadSNN.

</details>


### [7] [Hydra: Robust Hardware-Assisted Malware Detection](https://arxiv.org/abs/2602.07240)
*Eli Propp,Seyed Majid Zahedi*

Main category: cs.CR

TL;DR: Hydra提出了一种通过时间切片和特征集调度来提升基于硬件性能计数器的恶意软件检测性能的方法，通过循环使用互补特征集来克服硬件监控限制。


<details>
  <summary>Details</summary>
Motivation: 硬件性能计数器(HPCs)只能同时监控有限数量的事件，这导致检测盲点。现有工作主要关注为单一静态事件集优化机器学习模型，但鲁棒性需要多样化的特征集来捕获更广泛的程序行为。

Method: Hydra将执行轨迹划分为时间切片，学习特征集和相应分类器的有效调度策略。通过循环使用互补特征集，缓解固定监控视角的限制。

Result: 实验评估显示，Hydra显著优于最先进的单特征集基线方法，F1分数提高了19.32%，误报率降低了60.23%。

Conclusion: 特征集多样性对于硬件辅助恶意软件检测至关重要，战略性多特征集调度是提升检测鲁棒性的有效原则。

Abstract: Malware detection using Hardware Performance Counters (HPCs) offers a promising, low-overhead approach for monitoring program behavior. However, a fundamental architectural constraint, that only a limited number of hardware events can be monitored concurrently, creates a significant bottleneck, leading to detection blind spots. Prior work has primarily focused on optimizing machine learning models for a single, statically chosen event set, or on ensembling models over the same feature set. We argue that robustness requires diversifying not only the models, but also the underlying feature sets (i.e., the monitored hardware events) in order to capture a broader spectrum of program behavior. This observation motivates the following research question: Can detection performance be improved by trading temporal granularity for broader coverage, via the strategic scheduling of different feature sets over time? To answer this question, we propose Hydra, a novel detection mechanism that partitions execution traces into time slices and learns an effective schedule of feature sets and corresponding classifiers for deployment. By cycling through complementary feature sets, Hydra mitigates the limitations of a fixed monitoring perspective. Our experimental evaluation shows that Hydra significantly outperforms state-of-the-art single-feature-set baselines, achieving a 19.32% improvement in F1 score and a 60.23% reduction in false positive rate. These results underscore the importance of feature-set diversity and establish strategic multi-feature-set scheduling as an effective principle for robust, hardware-assisted malware detection.

</details>


### [8] [Beyond Crash: Hijacking Your Autonomous Vehicle for Fun and Profit](https://arxiv.org/abs/2602.07249)
*Qi Sun,Ahmed Abdo,Luis Burbano,Ziyang Li,Yaxing Yao,Alvaro Cardenas,Yinzhi Cao*

Main category: cs.CR

TL;DR: JackZebra框架首次实现对视觉端到端自动驾驶系统的路线级劫持攻击，通过物理可实现的攻击车辆和可重构显示屏，逐步将受害车辆引导至攻击者选择的目的地。


<details>
  <summary>Details</summary>
Motivation: 现有物理对抗攻击主要针对即时安全故障（如碰撞、违规、短暂偏离车道），但本文揭示了一种新的风险：长期路线完整性破坏，攻击者可以逐渐将受害车辆从预定路线引导至攻击者选择的目的地，而车辆看似"正常"行驶，这对车辆本身和乘客都构成威胁。

Method: 设计并实现JackZebra框架，使用物理可实现的攻击车辆，在车尾安装可重构显示屏显示对抗性补丁。核心创新是将路线劫持视为闭环控制问题，将对抗性补丁转化为转向原语，通过交互调整循环在线选择。对抗性补丁针对最坏情况背景和传感器变化进行精心设计。

Result: 评估显示JackZebra能够成功劫持受害车辆偏离原始路线，并以高成功率在对抗性目的地停车。攻击在视角变化、光照、天气、交通和受害者持续重新规划等挑战下保持有效。

Conclusion: 本文首次展示了视觉端到端自动驾驶系统存在长期路线完整性破坏风险，JackZebra框架成功实现了物理可行的路线级劫持攻击，揭示了自动驾驶系统在对抗环境中需要更强的鲁棒性保障。

Abstract: Autonomous Vehicles (AVs), especially vision-based AVs, are rapidly being deployed without human operators. As AVs operate in safety-critical environments, understanding their robustness in an adversarial environment is an important research problem. Prior physical adversarial attacks on vision-based autonomous vehicles predominantly target immediate safety failures (e.g., a crash, a traffic-rule violation, or a transient lane departure) by inducing a short-lived perception or control error. This paper shows a qualitatively different risk: a long-horizon route integrity compromise, where an attacker gradually steers a victim AV away from its intended route and into an attacker-chosen destination while the victim continues to drive "normally." This will not pose a danger to the victim vehicle itself, but also to potential passengers sitting inside the vehicle.
  In this paper, we design and implement the first adversarial framework, called JackZebra, that performs route-level hijacking of a vision-based end-to-end driving stack using a physically plausible attacker vehicle with a reconfigurable display mounted on the rear. The central challenge is temporal persistence: adversarial influence must remain effective in changing viewpoints, lighting, weather, traffic, and the victim's continual replanning -- without triggering conspicuous failures. Our key insight is to treat route hijacking as a closed-loop control problem and to convert adversarial patches into steering primitives that can be selected online via an interactive adjustment loop. Our adversarial patches are also carefully designed against worst-case background and sensor variations so that the adversarial impacts on the victim. Our evaluation shows that JackZebra can successfully hijack victim vehicles to deviate from original routes and stop at adversarial destinations with a high success rate.

</details>


### [9] [Patch-to-PoC: A Systematic Study of Agentic LLM Systems for Linux Kernel N-Day Reproduction](https://arxiv.org/abs/2602.07287)
*Juefei Pu,Xingyu Li,Haonan Li,Zhengchuan Liang,Jonathan Cox,Yifan Wu,Kareem Shehada,Arrdya Srivastav,Zhiyun Qian*

Main category: cs.CR

TL;DR: K-Repro：首个基于LLM的Linux内核漏洞自主复现系统，在100个真实漏洞中成功复现超过50%


<details>
  <summary>Details</summary>
Motivation: 目前缺乏对LLM在Linux内核漏洞复现方面的系统性研究。由于内核规模大、复杂度高且涉及底层代码，这类任务对现有LLM方法特别具有挑战性，需要评估其实际效果。

Method: 开发了K-Repro系统，这是一个基于LLM的代理系统，具备受控代码浏览、虚拟机管理、交互和调试能力。系统以内核安全补丁作为输入，自动化端到端的Linux内核N-day漏洞复现。

Result: 在从KernelCTF收集的100个真实可利用Linux内核漏洞数据集上，K-Repro能够生成PoC复现超过50%的案例，且具有实际的时间和金钱成本。

Conclusion: 研究不仅提供了成功率数据，还深入分析了有效性、效率、稳定性和影响因素，为构建更可靠的自主安全代理以及从攻防双方评估现实N-day风险提供了实用指导。

Abstract: Autonomous large language model (LLM) based systems have recently shown promising results across a range of cybersecurity tasks. However, there is no systematic study on their effectiveness in autonomously reproducing Linux kernel vulnerabilities with concrete proofs-of-concept (PoCs). Owing to the size, complexity, and low-level nature of the Linux kernel, such tasks are widely regarded as particularly challenging for current LLM-based approaches.
  In this paper, we present the first large-scale study of LLM-based Linux kernel vulnerability reproduction. For this purpose, we develop K-Repro, an LLM-based agentic system equipped with controlled code-browsing, virtual machine management, interaction, and debugging capabilities. Using kernel security patches as input, K-Repro automates end-to-end bug reproduction of N-day vulnerabilities in the Linux kernel. On a dataset of 100 real-world exploitable Linux kernel vulnerabilities collected from KernelCTF, our results show that K-Repro can generate PoCs that reproduce over 50\% of the cases with practical time and monetary cost.
  Beyond aggregate success rates, we perform an extensive study of effectiveness, efficiency, stability, and impact factors to explain when agentic reproduction succeeds, where it fails, and which components drive performance. These findings provide actionable guidance for building more reliable autonomous security agents and for assessing real-world N-day risk from both offensive and defensive perspectives.

</details>


### [10] [ACORN-IDS: Adaptive Continual Novelty Detection for Intrusion Detection Systems](https://arxiv.org/abs/2602.07291)
*Sean Fuhrman,Onat Gungor,Tajana Rosing*

Main category: cs.CR

TL;DR: ACORN-IDS是一个自适应持续新颖性检测框架，专门用于入侵检测系统，能够在无标签攻击数据的情况下持续适应非平稳数据流，显著提升检测性能。


<details>
  <summary>Details</summary>
Motivation: 现实世界中的入侵检测系统面临两大挑战：良性流量模式的快速演变和新型网络攻击（包括零日攻击）的持续出现。现有机器学习方法要么假设静态数据分布，要么依赖标记的攻击样本，这在真实部署中适用性有限。

Method: ACORN-IDS整合了持续特征提取器（使用重建和度量学习目标，基于聚类的伪标签训练）和基于PCA的重建模块（用于异常评分）。该框架仅从正常数据学习，利用演化无标签数据流的固有结构。

Result: 在五种现实入侵数据集上的评估显示，ACORN-IDS相比最先进的非监督持续学习基线，F1分数平均提升62%，零日攻击检测提升58%。同时表现出接近零遗忘和最小推理开销。

Conclusion: ACORN-IDS为动态真实环境中的入侵检测系统提供了一个实用、标签高效的解决方案，能够构建自适应且鲁棒的检测系统。

Abstract: Intrusion Detection Systems (IDS) must maintain reliable detection performance under rapidly evolving benign traffic patterns and the continual emergence of cyberattacks, including zero-day threats with no labeled data available. However, most machine learning-based IDS approaches either assume static data distributions or rely on labeled attack samples, substantially limiting their applicability in real-world deployments. This setting naturally motivates continual novelty detection, which enables IDS models to incrementally adapt to non-stationary data streams without labeled attack data. In this work, we introduce ACORN-IDS, an adaptive continual novelty detection framework that learns exclusively from normal data while exploiting the inherent structure of an evolving unlabeled data stream. ACORN-IDS integrates a continual feature extractor, trained using reconstruction and metric learning objectives with clustering-based pseudo-labels, alongside a PCA-based reconstruction module for anomaly scoring. This design allows ACORN-IDS to continuously adapt to distributional shifts in both benign and malicious traffic. We conduct an extensive evaluation of ACORN-IDS on five realistic intrusion datasets under two continual learning scenarios: (i) Evolving Attacks and (ii) Evolving Normal and Attack Distributions. ACORN-IDS achieves, on average, a 62% improvement in F1-score and a 58% improvement in zero-day attack detection over the state-of-the-art unsupervised continual learning baseline. It also outperforms existing state-of-the-art novelty detection approaches while exhibiting near-zero forgetting and imposing minimal inference overhead. These results demonstrate that ACORN-IDS offers a practical, label-efficient solution for building adaptive and robust IDS in dynamic, real-world environments. We plan to release the code upon acceptance.

</details>


### [11] [Aegis: Towards Governance, Integrity, and Security of AI Voice Agents](https://arxiv.org/abs/2602.07379)
*Xiang Li,Pin-Yu Chen,Wenqi Wei*

Main category: cs.CR

TL;DR: Aegis是一个针对语音代理的红队测试框架，用于评估其在银行、客服等高风险领域部署时的安全漏洞，发现即使有访问控制，语音代理仍易受行为攻击，需要多层防御策略。


<details>
  <summary>Details</summary>
Motivation: 随着音频大语言模型（ALLMs）在银行、客服等高风险领域的快速部署，语音代理的安全漏洞尚未得到充分探索。现有研究主要关注ALLMs的有害内容生成和幻觉问题，但缺乏对语音代理系统性的安全评估。

Method: 提出Aegis红队测试框架，模拟语音代理的实际部署流程，设计结构化对抗场景来评估关键风险，包括隐私泄露、权限提升、资源滥用等。通过银行呼叫中心、IT支持和物流等案例研究进行评估。

Result: 评估显示，虽然访问控制能缓解数据级风险，但语音代理仍易受行为攻击，这些攻击无法仅通过访问限制来解决。不同模型家族存在系统性差异，开源权重模型表现出更高的易受攻击性。

Conclusion: 需要结合访问控制、策略执行和行为监控的多层防御策略来保护下一代语音代理的安全，特别是在高风险部署场景中。

Abstract: With the rapid advancement and adoption of Audio Large Language Models (ALLMs), voice agents are now being deployed in high-stakes domains such as banking, customer service, and IT support. However, their vulnerabilities to adversarial misuse still remain unexplored. While prior work has examined aspects of trustworthiness in ALLMs, such as harmful content generation and hallucination, systematic security evaluations of voice agents are still lacking. To address this gap, we propose Aegis, a red-teaming framework for the governance, integrity, and security of voice agents. Aegis models the realistic deployment pipeline of voice agents and designs structured adversarial scenarios of critical risks, including privacy leakage, privilege escalation, resource abuse, etc. We evaluate the framework through case studies in banking call centers, IT Support, and logistics. Our evaluation shows that while access controls mitigate data-level risks, voice agents remain vulnerable to behavioral attacks that cannot be addressed through access restrictions alone, even under strict access controls. We observe systematic differences across model families, with open-weight models exhibiting higher susceptibility, underscoring the need for layered defenses that combine access control, policy enforcement, and behavioral monitoring to secure next-generation voice agents.

</details>


### [12] [AgentSys: Secure and Dynamic LLM Agents Through Explicit Hierarchical Memory Management](https://arxiv.org/abs/2602.07398)
*Ruoyao Wen,Hao Li,Chaowei Xiao,Ning Zhang*

Main category: cs.CR

TL;DR: AgentSys通过分层内存隔离防御间接提示注入攻击，将攻击成功率降至0.78-4.25%


<details>
  <summary>Details</summary>
Motivation: 传统LLM代理将所有工具输出和推理痕迹都存储在上下文窗口中，导致两个关键漏洞：注入指令持续存在提供多次攻击机会，冗长非必要内容降低决策能力。现有防御方法接受臃肿内存并专注于保持韧性，而非减少不必要积累来预防攻击。

Method: 受操作系统进程内存隔离启发，AgentSys采用分层代理架构：主代理为工具调用生成工作代理，每个工作代理在隔离上下文中运行并可生成嵌套工作代理处理子任务。外部数据和子任务痕迹从不进入主代理内存，只有经过模式验证的返回值能通过确定性JSON解析跨越边界。

Result: 在AgentDojo和ASB基准测试中，AgentSys将攻击成功率分别降至0.78%和4.25%，同时略微提高了良性效用。仅隔离机制就能将攻击成功率降至2.19%，添加验证器/清理器后防御效果进一步提升，其开销随操作而非上下文长度扩展。

Conclusion: 显式内存管理能够实现安全、动态的LLM代理架构，AgentSys对自适应攻击者和多种基础模型保持鲁棒性，表明通过减少不必要内存积累而非仅增强韧性来防御间接提示注入是有效方法。

Abstract: Indirect prompt injection threatens LLM agents by embedding malicious instructions in external content, enabling unauthorized actions and data theft. LLM agents maintain working memory through their context window, which stores interaction history for decision-making. Conventional agents indiscriminately accumulate all tool outputs and reasoning traces in this memory, creating two critical vulnerabilities: (1) injected instructions persist throughout the workflow, granting attackers multiple opportunities to manipulate behavior, and (2) verbose, non-essential content degrades decision-making capabilities. Existing defenses treat bloated memory as given and focus on remaining resilient, rather than reducing unnecessary accumulation to prevent the attack.
  We present AgentSys, a framework that defends against indirect prompt injection through explicit memory management. Inspired by process memory isolation in operating systems, AgentSys organizes agents hierarchically: a main agent spawns worker agents for tool calls, each running in an isolated context and able to spawn nested workers for subtasks. External data and subtask traces never enter the main agent's memory; only schema-validated return values can cross boundaries through deterministic JSON parsing. Ablations show isolation alone cuts attack success to 2.19%, and adding a validator/sanitizer further improves defense with event-triggered checks whose overhead scales with operations rather than context length.
  On AgentDojo and ASB, AgentSys achieves 0.78% and 4.25% attack success while slightly improving benign utility over undefended baselines. It remains robust to adaptive attackers and across multiple foundation models, showing that explicit memory management enables secure, dynamic LLM agent architectures. Our code is available at: https://github.com/ruoyaow/agentsys-memory.

</details>


### [13] [Secure Code Generation via Online Reinforcement Learning with Vulnerability Reward Model](https://arxiv.org/abs/2602.07422)
*Tianyi Wu,Mingzhe Du,Yue Liu,Chengran Yang,Terry Yue Zhuo,Jiaheng Zhang,See-Kiong Ng*

Main category: cs.CR

TL;DR: SecCoderX是一个基于在线强化学习的框架，用于生成既安全又保持功能性的代码，解决了现有安全代码对齐方法中功能性与安全性之间的矛盾。


<details>
  <summary>Details</summary>
Motivation: 大型语言模型在软件开发中应用日益广泛，但其生成不安全代码的倾向阻碍了实际部署。现有安全代码对齐方法存在功能-安全悖论，即提高安全性往往以显著降低功能实用性为代价。

Method: SecCoderX采用在线强化学习框架，通过两种方式利用成熟的漏洞检测资源：1)合成多样化、基于现实的漏洞诱导编码任务用于在线RL展开；2)训练基于推理的漏洞奖励模型，提供可扩展且可靠的安全监督。这些组件在在线RL循环中统一，以对齐代码LLMs生成安全且功能完整的代码。

Result: 实验表明SecCoderX达到最先进性能，将有效安全率(ESR)比未对齐模型提高约10%，而先前方法通常使ESR降低14-54%。

Conclusion: SecCoderX成功解决了功能-安全悖论，通过在线强化学习框架实现了功能保持的安全代码生成，显著优于现有方法。

Abstract: Large language models (LLMs) are increasingly used in software development, yet their tendency to generate insecure code remains a major barrier to real-world deployment. Existing secure code alignment methods often suffer from a functionality--security paradox, improving security at the cost of substantial utility degradation. We propose SecCoderX, an online reinforcement learning framework for functionality-preserving secure code generation. SecCoderX first bridges vulnerability detection and secure code generation by repurposing mature detection resources in two ways: (i) synthesizing diverse, reality-grounded vulnerability-inducing coding tasks for online RL rollouts, and (ii) training a reasoning-based vulnerability reward model that provides scalable and reliable security supervision. Together, these components are unified in an online RL loop to align code LLMs to generate secure and functional code. Extensive experiments demonstrate that SecCoderX achieves state-of-the-art performance, improving Effective Safety Rate (ESR) by approximately 10% over unaligned models, whereas prior methods often degrade ESR by 14-54%. We release our code, dataset and model checkpoints at https://github.com/AndrewWTY/SecCoderX.

</details>


### [14] [SPECA: Specification-to-Checklist Agentic Auditing for Multi-Implementation Systems -- A Case Study on Ethereum Clients](https://arxiv.org/abs/2602.07513)
*Masato Kamba,Akiyoshi Sannai*

Main category: cs.CR

TL;DR: SPECA框架将规范要求转化为检查清单，支持多实现审计中的跨实现复用，在以太坊Fusaka升级安全审计竞赛中验证了有效性。


<details>
  <summary>Details</summary>
Motivation: 在多实现系统中，差异测试在实现一致时信号有限，需要解决规范模糊性导致的集体错误解释问题。

Method: SPECA框架将规范要求转化为检查清单，映射到实现位置，支持跨实现复用检查。

Result: 在以太坊Fusaka升级审计中，76.5%的有效发现来自跨实现检查；改进后的代理在关键漏洞上达到27.3%召回率，超过96%的人类审计者。

Conclusion: 早期明确的威胁建模对减少误报和聚焦审计工作至关重要，代理驱动流程使专家验证和提交平均仅需40分钟。

Abstract: Multi-implementation systems are increasingly audited against natural-language specifications. Differential testing scales well when implementations disagree, but it provides little signal when all implementations converge on the same incorrect interpretation of an ambiguous requirement. We present SPECA, a Specification-to-Checklist Auditing framework that turns normative requirements into checklists, maps them to implementation locations, and supports cross-implementation reuse.
  We instantiate SPECA in an in-the-wild security audit contest for the Ethereum Fusaka upgrade, covering 11 production clients. Across 54 submissions, 17 were judged valid by the contest organizers. Cross-implementation checks account for 76.5 percent (13 of 17) of valid findings, suggesting that checklist-derived one-to-many reuse is a practical scaling mechanism in multi-implementation audits. To understand false positives, we manually coded the 37 invalid submissions and find that threat model misalignment explains 56.8 percent (21 of 37): reports that rely on assumptions about trust boundaries or scope that contradict the audit's rules. We detected no High or Medium findings in the V1 deployment; misses concentrated in specification details and implicit assumptions (57.1 percent), timing and concurrency issues (28.6 percent), and external library dependencies (14.3 percent). Our improved agent, evaluated against the ground truth of a competitive audit, achieved a strict recall of 27.3 percent on high-impact vulnerabilities, placing it in the top 4 percent of human auditors and outperforming 49 of 51 contestants on critical issues. These results, though from a single deployment, suggest that early, explicit threat modeling is essential for reducing false positives and focusing agentic auditing effort. The agent-driven process enables expert validation and submission in about 40 minutes on average.

</details>


### [15] [MemPot: Defending Against Memory Extraction Attack with Optimized Honeypots](https://arxiv.org/abs/2602.07517)
*Yuhao Wang,Shengfang Zhai,Guanghao Jin,Yinpeng Dong,Linyi Yang,Jiaheng Zhang*

Main category: cs.CR

TL;DR: MemPot是一个针对LLM智能体内存提取攻击的防御框架，通过注入优化的蜜罐文档来检测攻击，在保持零额外推理延迟的同时显著提升检测性能。


<details>
  <summary>Details</summary>
Motivation: LLM智能体使用外部和内部内存系统处理复杂任务，但这也使其面临严重的内存提取攻击，而目前缺乏有效的防御机制。

Method: 提出MemPot防御框架，通过两阶段优化过程生成蜜罐文档：最大化攻击者检索概率同时保持对正常用户的隐蔽性，并使用Wald序列概率比检验进行检测。

Result: MemPot显著优于现有基线方法，检测AUROC提升50%，在低误报率约束下真阳性率提高80%，且保持零额外在线推理延迟和智能体任务性能。

Conclusion: MemPot是首个经过理论验证的内存提取攻击防御框架，在安全性、无害性和效率方面具有优越性，为LLM智能体安全提供了有效解决方案。

Abstract: Large Language Model (LLM)-based agents employ external and internal memory systems to handle complex, goal-oriented tasks, yet this exposes them to severe extraction attacks, and effective defenses remain lacking. In this paper, we propose MemPot, the first theoretically verified defense framework against memory extraction attacks by injecting optimized honeypots into the memory. Through a two-stage optimization process, MemPot generates trap documents that maximize the retrieval probability for attackers while remaining inconspicuous to benign users. We model the detection process as Wald's Sequential Probability Ratio Test (SPRT) and theoretically prove that MemPot achieves a lower average number of sampling rounds compared to optimal static detectors. Empirically, MemPot significantly outperforms state-of-the-art baselines, achieving a 50% improvement in detection AUROC and an 80% increase in True Positive Rate under low False Positive Rate constraints. Furthermore, our experiments confirm that MemPot incurs zero additional online inference latency and preserves the agent's utility on standard tasks, verifying its superiority in safety, harmlessness, and efficiency.

</details>


### [16] [SoK: Credential-Based Trust Management in Decentralized Ledger Systems](https://arxiv.org/abs/2602.07572)
*Yanna Jiang,Haiyu Deng,Qin Wang,Guangsheng Yu,Xu Wang,Yilin Sai,Shiping Chen,Wei Ni,Ren Ping Liu*

Main category: cs.CR

TL;DR: 对基于凭证的去中心化信任管理系统进行系统性综述，分析架构设计、凭证机制和信任评估模型，建立分类体系和评估标准，识别关键挑战和研究方向


<details>
  <summary>Details</summary>
Motivation: 随着去中心化系统和区块链的兴起，基于凭证的去中心化信任管理系统变得日益重要，但理论与实践之间存在差距，需要进行系统性梳理和分析

Method: 通过系统性综述方法，从多个维度分析现有DTMS解决方案，包括架构设计、凭证机制和信任评估模型，建立详细的分类体系和全面的评估标准

Result: 提供了基于凭证的DTMS方法的详细分类，建立了评估DTMS实施的综合标准，通过广泛分析现有系统和实现，识别了该领域的关键挑战和有前景的研究方向

Conclusion: 该综述为DTMS研究人员和从业者提供了宝贵见解，特别是在访问控制、声誉系统和基于区块链的信任框架等领域，有助于弥合理论与实践之间的差距

Abstract: Trust management systems (TMS) are crucial for managing trust in distributed environments. The rise of decentralized systems and blockchain has sparked interest in credential-based decentralized trust management systems (DTMS). This paper bridges the gap between theory and practice through a systematic review of credential-based DTMS. We analyze existing DTMS solutions through multiple dimensions, including their architectural designs, credential mechanisms, and trust evaluation models. Our survey provides a detailed taxonomy of credential-based DTMS approaches and establishes comprehensive evaluation criteria for assessing DTMS implementations. Through extensive analysis of current systems and implementations, we identify critical challenges and promising research directions in the field. Our examination offers valuable insights for researchers and practitioners working on DTMS, particularly in areas such as access control, reputation systems, and blockchain-based trust frameworks.

</details>


### [17] [Agent-Fence: Mapping Security Vulnerabilities Across Deep Research Agents](https://arxiv.org/abs/2602.07652)
*Sai Puppala,Ismail Hossain,Md Jahangir Alam,Yoonpyo Lee,Jay Yoo,Tanzim Ahad,Syed Bahauddin Alam,Sajedul Talukder*

Main category: cs.CR

TL;DR: AgentFence是一个评估大型语言模型代理安全性的架构中心框架，定义了14种信任边界攻击类别，发现不同代理架构的安全漏洞率差异显著（0.29-0.51），操作类攻击风险最高。


<details>
  <summary>Details</summary>
Motivation: 随着大型语言模型越来越多地被部署为能够规划、维护状态和调用外部工具的深度代理，安全故障从文本不安全转向轨迹不安全。需要评估代理在长期交互中是否保持在目标和权限范围内。

Method: 提出AgentFence架构中心安全评估框架，定义了14种信任边界攻击类别（涵盖规划、记忆、检索、工具使用和委托），通过可追溯对话中断检测安全故障，评估8种代理架构在持续多轮交互中的表现。

Result: 不同代理架构的平均安全中断率差异显著：LangGraph最低（0.29±0.04），AutoGPT最高（0.51±0.07）。风险最高的攻击类别是操作类：钱包拒绝（0.62±0.08）、授权混淆（0.54±0.10）、检索污染（0.47±0.09）和规划操纵（0.44±0.11）。边界违规占主导地位（SIV 31%、WPA 27%、UTI+UTA 24%、ATD 18%）。

Conclusion: AgentFence将代理安全重新定义为代理是否能在长期运行中保持在目标和权限范围内，强调操作层面的安全评估比传统的提示中心方法更重要。

Abstract: Large language models are increasingly deployed as *deep agents* that plan, maintain persistent state, and invoke external tools, shifting safety failures from unsafe text to unsafe *trajectories*. We introduce **AgentFence**, an architecture-centric security evaluation that defines 14 trust-boundary attack classes spanning planning, memory, retrieval, tool use, and delegation, and detects failures via *trace-auditable conversation breaks* (unauthorized or unsafe tool use, wrong-principal actions, state/objective integrity violations, and attack-linked deviations). Holding the base model fixed, we evaluate eight agent archetypes under persistent multi-turn interaction and observe substantial architectural variation in mean security break rate (MSBR), ranging from $0.29 \pm 0.04$ (LangGraph) to $0.51 \pm 0.07$ (AutoGPT). The highest-risk classes are operational: Denial-of-Wallet ($0.62 \pm 0.08$), Authorization Confusion ($0.54 \pm 0.10$), Retrieval Poisoning ($0.47 \pm 0.09$), and Planning Manipulation ($0.44 \pm 0.11$), while prompt-centric classes remain below $0.20$ under standard settings. Breaks are dominated by boundary violations (SIV 31%, WPA 27%, UTI+UTA 24%, ATD 18%), and authorization confusion correlates with objective and tool hijacking ($ρ\approx 0.63$ and $ρ\approx 0.58$). AgentFence reframes agent security around what matters operationally: whether an agent stays within its goal and authority envelope over time.

</details>


### [18] [AirCatch: Effectively tracing advanced tag-based trackers](https://arxiv.org/abs/2602.07656)
*Abhishek Kumar Mishra,Swadeep,Guevara Noubir,Mathieu Cunche*

Main category: cs.CR

TL;DR: AirCatch是一个被动检测系统，利用物理层约束检测恶意蓝牙跟踪器，即使它们快速轮换标识符也能有效识别。


<details>
  <summary>Details</summary>
Motivation: 现有的基于协议的防御方法假设标识符稳定或信标可预测，但无法应对高级恶意跟踪器快速轮换标识符的攻击。需要一种能应对标识符轮换的检测方案。

Method: 1) 提出调制感知的载波频率偏移指纹，增强设备区分度；2) 基于高核心密度和持久性的跟踪检测算法，通过按标识符分段抵抗污染和逃避；3) 构建低成本BLE SDR接收器BlePhasyr，约10美元。

Result: 在Apple、Google、Tile、Samsung标签家族的多小时捕获中评估，系统压力测试显示零误报，在各种现实移动轨迹中实现早期检测，仅在极端低速率场景下性能下降。

Conclusion: AirCatch通过物理层指纹识别有效检测恶意蓝牙跟踪器，即使面对标识符快速轮换的攻击也能保持高检测率和低误报率，为资源受限部署提供实用解决方案。

Abstract: Tag-based tracking ecosystems help users locate lost items, but can be leveraged for unwanted tracking and stalking. Existing protocol-driven defenses and prior academic solutions largely assume stable identifiers or predictable beaconing. However, identifier-based defenses fundamentally break down against advanced rogue trackers that aggressively rotate identifiers. We present AirCatch, a passive detection system that exploits a physical-layer constraint: while logical identifiers can change arbitrarily fast, the transmitter's analog imprint remains stable and reappears as a compact and persistently occupied region in Carrier Frequency Offset (CFO) feature space. AirCatch advances the state of the art along three axes: (i) a novel, modulation-aware CFO fingerprint that augments packet-level CFO with content-independent CFO components that amplify device distinctiveness; (ii) a new tracking detection algorithm based on high core density and persistence that is robust to contamination and evasion through per-identifier segmentation; and (iii) an ultra-low-cost receiver, an approximately 10 dollar BLE SDR named BlePhasyr, built from commodity components, that makes RF fingerprinting based detection practical in resource-constrained deployments. We evaluate AirCatch across Apple, Google, Tile, and Samsung tag families in multi-hour captures, systematically stress-test evasion using a scenario generator over a grid of transmission and rotation periods, and validate in diverse real-world mobility traces including home and office commutes, public transport, car travel, and airport journeys while sweeping background tag density. Across these stress tests, AirCatch achieves no false positives and early detection over a wide range of adversarial configurations and environments, degrading gracefully only in extreme low-rate regimes that also reduce attacker utility.

</details>


### [19] [SoK: DARPA's AI Cyber Challenge (AIxCC): Competition Design, Architectures, and Lessons Learned](https://arxiv.org/abs/2602.07666)
*Cen Zhang,Younggi Park,Fabian Fleischer,Yu-Fu Fu,Jiho Kim,Dongkwan Kim,Youngjoon Kim,Qingxiao Xu,Andrew Chin,Ze Sheng,Hanqing Zhao,Brian J. Lee,Joshua Wang,Michael Pelican,David J. Musliner,Jeff Huang,Jon Silliman,Mikel Mcdaniel,Jefferson Casavant,Isaac Goldthwaite,Nicholas Vidovich,Matthew Lehman,Taesoo Kim*

Main category: cs.CR

TL;DR: 本文系统分析了DARPA AI网络挑战赛(AIxCC)，这是迄今为止最大的自主网络推理系统竞赛，旨在利用AI特别是大语言模型发现和修复开源软件漏洞。


<details>
  <summary>Details</summary>
Motivation: AIxCC是DARPA举办的最大规模自主网络推理系统竞赛，旨在推动利用AI特别是大语言模型进行漏洞发现和修复的技术发展。本文旨在对该竞赛进行首次系统性分析，理解其设计、参赛系统架构和实际效果。

Method: 通过分析竞赛设计文档、源代码、执行轨迹，以及与组织者和参赛团队的讨论，系统性地研究了竞赛结构、关键设计决策、决赛系统的架构方法，并超越了最终得分板进行深入结果分析。

Result: 分析揭示了真正驱动CRS性能的因素，识别了团队实现的技术进步，并暴露了仍需未来研究解决的局限性。研究发现超越了简单的排名结果，提供了对系统实际能力的深入理解。

Conclusion: 本文总结了组织未来竞赛的经验教训，并为实际部署自主网络推理系统提供了更广泛的见解。研究为理解AI在网络安全领域的应用进展和挑战提供了重要参考。

Abstract: DARPA's AI Cyber Challenge (AIxCC, 2023--2025) is the largest competition to date for building fully autonomous cyber reasoning systems (CRSs) that leverage recent advances in AI -- particularly large language models (LLMs) -- to discover and remediate vulnerabilities in real-world open-source software. This paper presents the first systematic analysis of AIxCC. Drawing on design documents, source code, execution traces, and discussions with organizers and competing teams, we examine the competition's structure and key design decisions, characterize the architectural approaches of finalist CRSs, and analyze competition results beyond the final scoreboard. Our analysis reveals the factors that truly drove CRS performance, identifies genuine technical advances achieved by teams, and exposes limitations that remain open for future research. We conclude with lessons for organizing future competitions and broader insights toward deploying autonomous CRSs in practice.

</details>


### [20] [IPBAC: Interaction Provenance-Based Access Control for Secure and Privacy-Aware Systems](https://arxiv.org/abs/2602.07722)
*Sharif Noor Zisad,Ragib Hasan*

Main category: cs.CR

TL;DR: IPBAC模型通过整合交互溯源与访问控制，解决传统RBAC系统在角色定义、动态场景处理和可追溯性方面的局限性，提供更强的安全保护和审计支持。


<details>
  <summary>Details</summary>
Motivation: 传统访问控制系统（如RBAC）存在角色定义不灵活、难以处理动态场景、缺乏详细问责和可追溯性等显著局限性。需要一种新的访问控制模型来解决这些问题。

Method: 提出基于交互溯源的访问控制（IPBAC）模型，将交互溯源与访问控制相结合。交互溯源详细记录系统中的操作和交互，捕获包括执行者身份、操作时间、上下文等全面元数据。

Result: IPBAC能够提供更强的未授权访问防护，增强审计和合规的可追溯性，并支持自适应安全策略。这种基于溯源的访问控制不仅增强了安全性，还为审计和合规提供了稳健框架。

Conclusion: 交互溯源与访问控制的整合能够有效克服传统访问控制系统的局限性，IPBAC模型为系统安全、审计和合规提供了更强大的解决方案。

Abstract: Traditional access control systems, including RBAC, face significant limitations such as inflexible role definitions, difficulty handling dynamic scenarios, and lack of detailed accountability and traceability. To this end, we introduce the Interaction Provenance-based Access Control (IPBAC) model. In this paper, we explore the integration of interaction provenance with access control to overcome these limitations. Interaction provenance refers to the detailed recording of actions and interactions within a system, capturing comprehensive metadata such as the identity of the actor, the time of an action, and the context. IPBAC ensures stronger protection against unauthorized access, enhances traceability for auditing and compliance, and supports adaptive security policies. This provenance-based access control not only strengthens security, but also provides a robust framework for auditing and compliance.

</details>


### [21] [Leveraging the Power of Ensemble Learning for Secure Low Altitude Economy](https://arxiv.org/abs/2602.07725)
*Yaoqi Yang,Yong Chen,Jiacheng Wang,Geng Sun,Dusit Niyato,Zhu Han*

Main category: cs.CR

TL;DR: 本文探讨了在低空经济（LAE）安全中应用集成学习进行恶意飞机入侵检测，通过结合多个模型的优势来提高检测准确性、适应性和资源利用率。


<details>
  <summary>Details</summary>
Motivation: 低空经济（LAE）对社会福祉和经济增长具有巨大潜力，但面临恶意飞机入侵攻击的安全威胁。现有的入侵检测系统（IDS）由于LAE环境的异构数据、动态变化和资源受限设备，在检测准确性、适应性和资源利用率方面面临挑战。

Method: 采用集成学习方法，通过结合多个模型的集体知识来增强异常检测的鲁棒性和多样性。论文首先建立集成学习的理论基础，然后回顾研究领域和潜在解决方案，最后提出了一个集成学习支持的恶意飞机跟踪框架，并通过案例研究验证其可行性和有效性。

Result: 通过案例研究验证了集成学习框架在LAE安全中的可行性和有效性。集成学习方法能够提高入侵检测系统的准确性、鲁棒性和效率，从而更好地防御恶意飞机入侵攻击。

Conclusion: 集成学习在保障低空经济安全方面具有显著优势，能够解决当前入侵检测系统面临的挑战。论文为集成学习在LAE安全中的应用提供了理论基础和实用框架，并指出了未来进一步推进集成学习在安全LAE中应用的研究方向。

Abstract: Low Altitude Economy (LAE) holds immense promise for enhancing societal well-being and driving economic growth. However, this burgeoning field is vulnerable to security threats, particularly malicious aircraft intrusion attacks. To address the above concerns, intrusion detection systems (IDS) can be used to defend against malicious aircraft intrusions in LAE. Whereas, due to the heterogeneous data, dynamic environment, and resource-constrained devices within LAE, current IDS face challenges in detection accuracy, adaptability, and resource utilization ratio. In this regard, due to the inherent ability to combine the strengths of multiple models, ensemble learning can realize more robust and diverse anomaly detection further enhance IDS accuracy, thereby improving robustness and efficiency of the secure LAE. Unlike single-model approaches, ensemble learning can leverage the collective knowledge of its constituent models to effectively defend the malicious aircraft intrusion attacks. Specifically, this paper investigates ensemble learning for secure LAE, covering research focuses, solutions, and a case study. We first establish the rationale for ensemble learning and then review research areas and potential solutions, demonstrating the necessities and benefits of applying ensemble learning to secure LAE. Subsequently, we propose a framework of ensemble learning-enabled malicious aircrafts tracking in the secure LAE, where its feasibility and effectiveness are evaluated by the designed case study. Finally, we conclude by outlining promising future research directions for further advancing the ensemble learning-enabled secure LAE.

</details>


### [22] [Rethinking Latency Denial-of-Service: Attacking the LLM Serving Framework, Not the Model](https://arxiv.org/abs/2602.07878)
*Tianyi Wang,Huawei Fan,Yuanchao Shu,Peng Cheng,Cong Wang*

Main category: cs.CR

TL;DR: 论文揭示现有算法延迟攻击对现代LLM服务系统无效，提出新的"填充与挤压"系统层攻击策略，通过操纵调度器状态转换实现更高效的延迟攻击。


<details>
  <summary>Details</summary>
Motivation: LLM推理成本高昂，轻微延迟即可导致巨大运营成本和可用性风险。现有研究主要关注算法复杂度攻击，但发现这些攻击对现代LLM服务系统效果有限，需要转向系统层攻击。

Method: 提出"填充与挤压"攻击策略：1)"填充"阶段耗尽全局KV缓存引发队头阻塞；2)"挤压"阶段迫使系统进入重复抢占状态。结合简单文本提示和复杂提示工程操纵输出长度，利用内存状态侧信道探测，在黑盒设置下实施攻击。

Result: 攻击效果显著：首令牌时间平均减慢20-280倍，输出令牌时间平均减慢1.5-4倍，相比现有攻击成本降低30-40%。

Conclusion: 系统层攻击比算法复杂度攻击更有效，现代LLM服务系统的优化(如连续批处理)虽然能缓解算法攻击，但为系统层攻击创造了新漏洞，需要重新审视LLM服务系统的安全设计。

Abstract: Large Language Models face an emerging and critical threat known as latency attacks. Because LLM inference is inherently expensive, even modest slowdowns can translate into substantial operating costs and severe availability risks. Recently, a growing body of research has focused on algorithmic complexity attacks by crafting inputs to trigger worst-case output lengths. However, we report a counter-intuitive finding that these algorithmic latency attacks are largely ineffective against modern LLM serving systems. We reveal that system-level optimization such as continuous batching provides a logical isolation to mitigate contagious latency impact on co-located users. To this end, in this paper, we shift the focus from the algorithm to the system layer, and introduce a new Fill and Squeeze attack strategy targeting the state transition of the scheduler. "Fill" first exhausts the global KV cache to induce Head-of-Line blocking, while "Squeeze" forces the system into repetitive preemption. By manipulating output lengths using methods from simple plain-text prompts to more complex prompt engineering, and leveraging side-channel probing of memory status, we demonstrate that the attack can be orchestrated in a black-box setting with much less cost. Extensive evaluations indicate by up to 20-280x average slowdown on Time to First Token and 1.5-4x average slowdown on Time Per Output Token compared to existing attacks with 30-40% lower attack cost.

</details>


### [23] [CausalArmor: Efficient Indirect Prompt Injection Guardrails via Causal Attribution](https://arxiv.org/abs/2602.07918)
*Minbeom Kim,Mihir Parmar,Phillip Wallis,Lesly Miculicich,Kyomin Jung,Krishnamurthy Dj Dvijotham,Long T. Le,Tomas Pfister*

Main category: cs.CR

TL;DR: CausalArmor：基于因果归因的选择性防御框架，通过检测不信任内容对AI代理决策的过度影响来防御间接提示注入攻击，在保持安全性的同时减少过度防御问题。


<details>
  <summary>Details</summary>
Motivation: 现有防御机制存在过度防御困境：无论实际威胁如何都采用昂贵的持续净化措施，导致在良性场景下也降低效用和增加延迟。需要一种更智能的选择性防御方法。

Method: 1) 在特权决策点计算轻量级的留一消融归因；2) 仅当不信任内容主导用户意图时才触发目标净化；3) 使用追溯性思维链掩码防止代理基于"中毒"推理轨迹行动。

Result: 在AgentDojo和DoomArena上的实验表明，CausalArmor在保持攻击防御能力的同时，提高了可解释性，并保留了AI代理的效用和延迟性能。

Conclusion: CausalArmor通过因果归因的选择性防御有效解决了间接提示注入攻击，在安全性和实用性之间取得了良好平衡，为AI代理安全提供了理论保证的解决方案。

Abstract: AI agents equipped with tool-calling capabilities are susceptible to Indirect Prompt Injection (IPI) attacks. In this attack scenario, malicious commands hidden within untrusted content trick the agent into performing unauthorized actions. Existing defenses can reduce attack success but often suffer from the over-defense dilemma: they deploy expensive, always-on sanitization regardless of actual threat, thereby degrading utility and latency even in benign scenarios. We revisit IPI through a causal ablation perspective: a successful injection manifests as a dominance shift where the user request no longer provides decisive support for the agent's privileged action, while a particular untrusted segment, such as a retrieved document or tool output, provides disproportionate attributable influence. Based on this signature, we propose CausalArmor, a selective defense framework that (i) computes lightweight, leave-one-out ablation-based attributions at privileged decision points, and (ii) triggers targeted sanitization only when an untrusted segment dominates the user intent. Additionally, CausalArmor employs retroactive Chain-of-Thought masking to prevent the agent from acting on ``poisoned'' reasoning traces. We present a theoretical analysis showing that sanitization based on attribution margins conditionally yields an exponentially small upper bound on the probability of selecting malicious actions. Experiments on AgentDojo and DoomArena demonstrate that CausalArmor matches the security of aggressive defenses while improving explainability and preserving utility and latency of AI agents.

</details>


### [24] [Privacy-Preserving Covert Communication Using Encrypted Wearable Gesture Recognition](https://arxiv.org/abs/2602.07936)
*Tasnia Ashrafi Heya,Sayed Erfan Arefin*

Main category: cs.CR

TL;DR: 提出首个基于可穿戴设备的隐私保护隐蔽通信系统，使用同态加密直接在加密运动数据上进行手势识别，防止第三方获取原始传感器信号、学习特征或分类输出。


<details>
  <summary>Details</summary>
Motivation: 在隐蔽和安全关键场景中，传统语音通信可能暴露用户意图或操作上下文。现有可穿戴手势通信系统会泄露运动数据、中间表示或推理输出给不可信基础设施，导致意图推断、行为生物特征泄露和内部攻击。

Method: 采用多方同态学习管道，直接在加密运动数据上进行手势识别，防止对手推断手势语义、重放传感器轨迹或访问中间表示。设计了触觉和视觉反馈机制用于隐蔽信号传递。

Result: 在商用智能手表收集的600个手势样本上评估，分类准确率超过94.44%，证明了系统的可行性，并展示了从高性能系统到资源受限边缘设备的实际部署能力。

Conclusion: 这是首个在可穿戴设备隐蔽通信场景中应用加密手势识别的工作，实现了隐私保护的隐蔽通信，确保原始传感器信号、学习特征和分类输出都不会暴露给任何第三方。

Abstract: Secure communication is essential in covert and safety-critical settings where verbal interactions may expose user intent or operational context. Wearable gesture-based communication enables low-effort, nonverbal interaction, but existing systems leak motion data, intermediate representations, or inference outputs to untrusted infrastructure, enabling intent inference, behavioral biometric leakage, and insider attacks. This work proposes a privacy-preserving gesture-based covert communication system that ensures, no raw sensor signals, learned features, or classification outputs are exposed to any third-party. The system employs a multi-party homomorphic learning pipeline for gesture recognition directly over encrypted motion data, preventing adversaries from inferring gesture semantics, replaying sensor traces, or accessing intermediate representations. To our knowledge, this work is the first to apply encrypted gesture recognition in a wearable-based covert communication setting. We design and evaluate haptic and visual feedback mechanisms for covert signal delivery and evaluate the system using 600 gesture samples from a commodity smartwatch, achieving over 94.44% classification accuracy and demonstrating the feasibility of the proposed system with practical deployability from high-performance systems to resource-constrained edge devices.

</details>


### [25] [ICBAC: an Intelligent Contract-Based Access Control framework for supply chain management by integrating blockchain and federated learning](https://arxiv.org/abs/2602.08014)
*Sadegh Sohani,Salar Ghazi,Farnaz Kamranfar,Sahar Pilehvar Moakhar,Mohammad Allahbakhsh,Haleh Amintoosi,Kaiwen Zhang*

Main category: cs.CR

TL;DR: ICBAC是一个基于智能合约的访问控制框架，将许可区块链与联邦学习结合，为去中心化供应链提供动态、隐私保护的访问控制，通过游戏论客户端选择机制形成稳定的联邦学习联盟。


<details>
  <summary>Details</summary>
Motivation: 现代供应链涉及多个独立竞争组织，现有访问控制方案存在静态集中化、无法应对内部威胁和动态环境变化的问题。区块链虽能去中心化但缺乏行为智能，而集中式机器学习需要聚合敏感数据，违反隐私保护要求。

Method: ICBAC框架整合许可区块链（Hyperledger Fabric）与联邦学习，采用多通道架构和三个智能合约（资产管理、基线访问控制、动态撤销）。每个通道部署AI代理监控活动并动态限制异常访问。引入基于享乐联盟形成的游戏论客户端选择机制，使供应链能够形成稳定、策略证明的联邦学习联盟。

Result: 在Fabric测试平台上使用真实数据集进行的广泛实验表明，ICBAC实现了与静态框架相当的区块链性能，在IID和非IID数据下提供有效的异常检测，且无需共享原始数据。

Conclusion: ICBAC为去中心化供应链提供了一种实用、可扩展的动态隐私保护访问控制解决方案，能够应对内部威胁和动态环境变化，同时保护各组织的敏感数据隐私。

Abstract: This paper addresses the critical challenge of access control in modern supply chains, which operate across multiple independent and competing organizations. Existing access control is static and centralized, unable to adapt to insider threats or evolving contexts. Blockchain improves decentralization but lacks behavioral intelligence, while centralized machine learning for anomaly detection requires aggregating sensitive data, violating privacy.
  The proposed solution is ICBAC, an intelligent contract-based access control framework. It integrates permissioned blockchain (Hyperledger Fabric) with federated learning (FL). Built on Fabric, ICBAC uses a multi-channel architecture and three smart contracts for asset management, baseline access control, and dynamic revocation. To counter insider misuse, each channel deploys an AI agent that monitors activity and dynamically restricts access for anomalies. Federated learning allows these agents to collaboratively improve detection models without sharing raw data.
  For heterogeneous, competitive environments, ICBAC introduces a game-theoretic client selection mechanism using hedonic coalition formation. This enables supply chains to form stable, strategy-proof FL coalitions via preference-based selection without disclosing sensitive criteria. Extensive experiments on a Fabric testbed with a real-world dataset show ICBAC achieves blockchain performance comparable to static frameworks and provides effective anomaly detection under IID and non-IID data with zero raw-data sharing. ICBAC thus offers a practical, scalable solution for dynamic, privacy-preserving access control in decentralized supply chains.

</details>


### [26] [CyberExplorer: Benchmarking LLM Offensive Security Capabilities in a Real-World Attacking Simulation Environment](https://arxiv.org/abs/2602.08023)
*Nanda Rani,Kimberly Milner,Minghao Shao,Meet Udeshi,Haoran Xi,Venkata Sai Charan Putrevu,Saksham Aggarwal,Sandeep K. Shukla,Prashanth Krishnamurthy,Farshad Khorrami,Muhammad Shafique,Ramesh Karri*

Main category: cs.CR

TL;DR: CyberExplorer是一个用于评估LLM攻击性代理的开放环境基准测试套件，包含基于真实CTF挑战构建的虚拟机和反应式多智能体框架，支持无预定义目标的动态探索。


<details>
  <summary>Details</summary>
Motivation: 现实世界的攻击性安全操作本质上是开放式的，攻击者需要探索未知的攻击面、在不确定性下修正假设，且没有保证的成功。现有的基于LLM的攻击性代理评估依赖于具有预定义目标和二元成功标准的封闭世界设置，存在与现实场景的差距。

Method: CyberExplorer包含两个核心组件：(1) 基于虚拟机构建的开放环境基准测试，该虚拟机托管40个源自真实世界CTF挑战的易受攻击Web服务，代理可以在没有漏洞位置先验知识的情况下自主执行侦察、目标选择和利用；(2) 支持无预定义计划的动态探索的反应式多智能体框架。

Result: CyberExplorer能够进行超越标志恢复的细粒度评估，捕捉交互动态、协调行为、失败模式和漏洞发现信号，弥合了基准测试与现实多目标攻击场景之间的差距。

Conclusion: 该研究提出了一个更贴近现实攻击场景的评估框架，通过开放环境和多智能体动态探索，为LLM攻击性代理提供了更全面、真实的评估能力，填补了现有评估方法的空白。

Abstract: Real-world offensive security operations are inherently open-ended: attackers explore unknown attack surfaces, revise hypotheses under uncertainty, and operate without guaranteed success. Existing LLM-based offensive agent evaluations rely on closed-world settings with predefined goals and binary success criteria. To address this gap, we introduce CyberExplorer, an evaluation suite with two core components: (1) an open-environment benchmark built on a virtual machine hosting 40 vulnerable web services derived from real-world CTF challenges, where agents autonomously perform reconnaissance, target selection, and exploitation without prior knowledge of vulnerability locations; and (2) a reactive multi-agent framework supporting dynamic exploration without predefined plans. CyberExplorer enables fine-grained evaluation beyond flag recovery, capturing interaction dynamics, coordination behavior, failure modes, and vulnerability discovery signals-bridging the gap between benchmarks and realistic multi-target attack scenarios.

</details>


### [27] [IssueGuard: Real-Time Secret Leak Prevention Tool for GitHub Issue Reports](https://arxiv.org/abs/2602.08072)
*Md Nafiu Rahman,Sadif Ahmed,Zahin Wahab,Gias Uddin,Rifat Shahriyar*

Main category: cs.CR

TL;DR: IssueGuard是一个Chrome扩展工具，用于实时检测和防止GitHub/GitLab问题报告中意外泄露API密钥等敏感信息，结合正则表达式和微调CodeBERT模型，F1分数达92.70%


<details>
  <summary>Details</summary>
Motivation: GitHub和GitLab等协作平台的issue跟踪系统包含大量非结构化文本（日志、代码片段、配置示例），存在意外泄露API密钥和凭证的风险，但这些平台没有提供提交前的警告机制

Method: 实现为Chrome扩展，实时分析用户输入文本，结合基于正则表达式的候选提取和微调的CodeBERT模型进行上下文分类，有效区分真实密钥和误报

Result: 在基准数据集上达到92.70%的F1分数，优于传统的基于正则表达式的扫描器，工具直接集成到Web界面中，持续分析问题编辑器并提供清晰的视觉警告

Conclusion: IssueGuard能有效检测和防止issue报告中的秘密泄露，源代码和演示视频已公开，为开发者提供了实用的安全防护工具

Abstract: GitHub and GitLab are widely used collaborative platforms whose issue-tracking systems contain large volumes of unstructured text, including logs, code snippets, and configuration examples. This creates a significant risk of accidental secret exposure, such as API keys and credentials, yet these platforms provide no mechanism to warn users before submission. We present \textsc{IssueGuard}, a tool for real-time detection and prevention of secret leaks in issue reports. Implemented as a Chrome extension, \textsc{IssueGuard} analyzes text as users type and combines regex-based candidate extraction with a fine-tuned CodeBERT model for contextual classification. This approach effectively separates real secrets from false positives and achieves an F1-score of 92.70\% on a benchmark dataset, outperforming traditional regex-based scanners. \textsc{IssueGuard} integrates directly into the web interface and continuously analyzes the issue editor, presenting clear visual warnings to help users avoid submitting sensitive data. The source code is publicly available at \href{https://github.com/nafiurahman00/IssueGuard}{https://github.com/nafiurahman00/IssueGuard}, and a demonstration video is available at \href{https://youtu.be/kvbWA8rr9cU}{https://youtu.be/kvbWA8rr9cU}.

</details>


### [28] [A Transfer Learning Approach to Unveil the Role of Windows Common Configuration Enumerations in IEC 62443 Compliance](https://arxiv.org/abs/2602.08165)
*Miguel Bicudo,Estevão Rabello,Daniel Menasché,Paulo Segal,Claudio Segal,Anton Kocheturov,Priyanjan Sharma*

Main category: cs.CR

TL;DR: 提出一种迁移学习方法，将Windows配置枚举映射到IEC 62443-3-3安全要求，利用Linux标注数据集实现自动化合规检查


<details>
  <summary>Details</summary>
Motivation: 工业控制系统环境异构（Linux、专有实时系统、Windows共存），IEC 62443-3-3标准虽提供安全框架，但将要求转化为具体配置检查（特别是Windows平台）仍具挑战

Method: 采用迁移学习方法，将Windows通用配置枚举映射到IEC 62443-3-3系统安全要求，利用已标注的Linux数据集进行知识迁移

Result: 生成标注数据集，支持自动化合规检查、需求流行度分析，识别跨平台相似性和差异性，证明CCE可作为抽象标准与具体配置间的桥梁

Conclusion: 该方法推进了Windows环境中IEC 62443-3-3合规的自动化、可追溯性和清晰度，为异构工业控制系统安全配置提供实用解决方案

Abstract: Industrial control systems (ICS) depend on highly heterogeneous environments where Linux, proprietary real-time operating systems, and Windows coexist. Although the IEC 62443-3-3 standard provides a comprehensive framework for securing such systems, translating its requirements into concrete configuration checks remains challenging, especially for Windows platforms. In this paper, we propose a transfer learning methodology that maps Windows Common Configuration Enumerations (CCEs) to IEC 62443-3-3 System Security Requirements by leveraging labeled Linux datasets. The resulting labeled dataset enables automated compliance checks, analysis of requirement prevalence, and identification of cross-platform similarities and divergences. Our results highlight the role of CCEs as a bridge between abstract standards and concrete configurations, advancing automation, traceability, and clarity in IEC 62443-3-3 compliance for Windows environments.

</details>


### [29] [Evasion of IoT Malware Detection via Dummy Code Injection](https://arxiv.org/abs/2602.08170)
*Sahar Zargarzadeh,Mohammad Islam*

Main category: cs.CR

TL;DR: 该论文提出了一种针对基于功率侧信道分析的恶意软件检测系统的对抗攻击方法，通过在Mirai僵尸网络扫描阶段注入结构化虚拟代码来动态扰动功率特征，从而逃避AI/ML异常检测。


<details>
  <summary>Details</summary>
Motivation: 物联网设备的快速扩张带来了严重的安全漏洞，使其成为恶意软件（如Mirai僵尸网络）的攻击目标。虽然功率侧信道分析已成为检测恶意软件活动的有前景技术，但这类检测系统在对抗性操纵下的鲁棒性尚未得到充分研究。

Method: 提出了一种新颖的对抗策略：在Mirai僵尸网络的扫描阶段注入结构化虚拟代码，动态扰动功率特征以逃避AI/ML异常检测，同时不破坏核心功能。该方法系统分析了隐蔽性、执行开销和逃避效果之间的权衡，并在来自不同制造商智能手机的自定义数据集上测试了多种最先进的侧信道分析模型。

Result: 实验结果表明，对抗性修改平均攻击成功率达到75.2%，揭示了基于功率的入侵检测框架存在实际漏洞。

Conclusion: 该研究展示了基于功率侧信道的恶意软件检测系统在对抗性攻击下的脆弱性，强调了在物联网安全中开发更鲁棒检测机制的必要性。

Abstract: The Internet of Things (IoT) has revolutionized connectivity by linking billions of devices worldwide. However, this rapid expansion has also introduced severe security vulnerabilities, making IoT devices attractive targets for malware such as the Mirai botnet. Power side-channel analysis has recently emerged as a promising technique for detecting malware activity based on device power consumption patterns. However, the resilience of such detection systems under adversarial manipulation remains underexplored.
  This work presents a novel adversarial strategy against power side-channel-based malware detection. By injecting structured dummy code into the scanning phase of the Mirai botnet, we dynamically perturb power signatures to evade AI/ML-based anomaly detection without disrupting core functionality. Our approach systematically analyzes the trade-offs between stealthiness, execution overhead, and evasion effectiveness across multiple state-of-the-art models for side-channel analysis, using a custom dataset collected from smartphones of diverse manufacturers. Experimental results show that our adversarial modifications achieve an average attack success rate of 75.2\%, revealing practical vulnerabilities in power-based intrusion detection frameworks.

</details>


### [30] [Towards Real-World Industrial-Scale Verification: LLM-Driven Theorem Proving on seL4](https://arxiv.org/abs/2602.08384)
*Jianyu Zhang,Fuyuan Zhang,Jiayi Lu,Jilin Hu,Xiaoyi Yin,Long Zhang,Feng Yang,Yongwang Zhao*

Main category: cs.CR

TL;DR: AutoReal：基于LLM的定理证明方法，针对工业级系统验证，支持轻量级本地部署，在seL4验证项目中达到51.67%的证明成功率


<details>
  <summary>Details</summary>
Motivation: 形式化方法可靠但成本高昂，需要专家多年努力。现有LLM定理证明研究多集中于数学基准测试，对工业级验证项目评估有限，且大多依赖无法本地部署的大型闭源模型

Method: 提出AutoReal方法：1) 基于思维链的证明训练，教授LLM证明步骤背后的推理过程；2) 上下文增强，利用项目中的证明上下文提升LLM驱动证明能力。基于此方法微调得到7B参数的AutoReal-Prover模型

Result: 在seL4验证项目中，AutoReal-Prover在660个重要定理上达到51.67%的证明成功率，显著优于之前的27.06%。在AFP三个安全相关项目的451个定理上达到53.88%的证明成功率

Conclusion: AutoReal推动了LLM驱动的定理证明在真实工业级验证中的应用，通过轻量级本地部署和针对性的训练方法，显著提升了工业级系统验证的自动化水平

Abstract: Formal methods (FM) are reliable but costly to apply, often requiring years of expert effort in industrial-scale projects such as seL4, especially for theorem proving. Recent advances in large language models (LLMs) have made automated theorem proving increasingly feasible. However, most prior work focuses on mathematics-oriented benchmarks such as miniF2F, with limited evaluation on real-world verification projects. The few studies that consider industrial-scale verification mostly rely on closed-source models with hundreds of billions of parameters, which cannot be locally deployed and incur substantial usage costs. In this paper, we propose AutoReal, an LLM-driven theorem proving method for real-world industrial-scale systems with support for lightweight local deployment. We evaluate AutoReal on the seL4-Isabelle verification project as a representative and challenging case study. AutoReal incorporates two key improvements: (1) chain-of-thought (CoT)-based proof training, which teaches the LLM the reasoning behind proof steps and enables step-wise explanations alongside proofs, and (2) context augmentation, which leverages proof context from the project to enhance LLM-driven proving. Based on the AutoReal methodology, we fine-tune a base model to obtain AutoReal-Prover, a compact 7B-scale prover for industrial-scale theorem proving. AutoReal-Prover achieves a 51.67% proof success rate on 660 theorems from seL4-designated Important Theories across all 10 seL4 proof categories, substantially outperforming prior attempts on seL4 (27.06%). To evaluate generalization, we further apply AutoReal-Prover to three security-related projects from the Archive of Formal Proofs (AFP), covering all 451 theorems and achieving a proof success rate of 53.88%. Overall, this work advances the application of LLM-driven theorem proving in real-world industrial-scale verification.

</details>


### [31] [LLMs + Security = Trouble](https://arxiv.org/abs/2602.08422)
*Benjamin Livshits*

Main category: cs.CR

TL;DR: 论文主张：当前使用概率AI检查器来保护AI生成代码的方法无法解决安全漏洞的长尾问题，建议通过约束解码在代码生成过程中直接强制执行安全约束，而非依赖事后检测修复。


<details>
  <summary>Details</summary>
Motivation: 当前AI辅助开发中"以火攻火"的方法（使用概率AI检查器保护概率生成的代码）无法解决安全漏洞的长尾问题，系统仍可能暴露于零日漏洞。神经符号方法虽然理论上吸引人，但与"氛围编码"工作流程难以协调，需要人工干预会破坏安全构造保证。

Method: 提出在代码生成过程中强制执行安全约束（如通过约束解码），而不是依赖事后检测和修复。特别关注扩散式代码模型，其方法为模块化、分层安全执行提供了自然优雅的机会，可以结合低延迟生成技术与安全构造代码生成。

Result: 论文提出了一种新的安全代码生成方向，强调在生成过程中直接集成安全约束，这为获得更强的安全保证提供了有前景的途径。

Conclusion: 通过约束解码在代码生成过程中强制执行安全约束，比依赖事后检测修复能提供更强的安全保证。扩散式代码模型特别适合这种方法，可以实现模块化、分层的安全执行，同时保持低延迟生成。

Abstract: We argue that when it comes to producing secure code with AI, the prevailing "fighting fire with fire" approach -- using probabilistic AI-based checkers or attackers to secure probabilistically generated code -- fails to address the long tail of security bugs. As a result, systems may remain exposed to zero-day vulnerabilities that can be discovered by better-resourced or more persistent adversaries.
  While neurosymbolic approaches that combine LLMs with formal methods are attractive in principle, we argue that they are difficult to reconcile with the "vibe coding" workflow common in LLM-assisted development: unless the end-to-end verification pipeline is fully automated, developers are repeatedly asked to validate specifications, resolve ambiguities, and adjudicate failures, making the human-in-the-loop a likely point of weakness, compromising secure-by-construction guarantees.
  In this paper we argue that stronger security guarantees can be obtained by enforcing security constraints during code generation (e.g., via constrained decoding), rather than relying solely on post-hoc detection and repair. This direction is particularly promising for diffusion-style code models, whose approach provides a natural elegant opportunity for modular, hierarchical security enforcement, allowing us to combine lower-latency generation techniques with generating secure-by-construction code.

</details>


### [32] [Retrieval Pivot Attacks in Hybrid RAG: Measuring and Mitigating Amplified Leakage from Vector Seeds to Graph Expansion](https://arxiv.org/abs/2602.08668)
*Scott Thornton*

Main category: cs.CR

TL;DR: 混合RAG管道结合向量检索和知识图谱扩展，但存在安全风险：向量检索的"种子"块可通过实体链接访问敏感图谱邻域，导致跨租户数据泄露。


<details>
  <summary>Details</summary>
Motivation: 混合检索增强生成(RAG)管道结合向量相似性搜索和知识图谱扩展进行多跳推理，但这种组合引入了独特的安全故障模式：向量检索的"种子"块可以通过实体链接访问敏感图谱邻域，导致向量单独检索中不存在的跨租户数据泄露风险。

Method: 形式化这种风险为检索枢轴风险(RPR)，引入Leakage@k、放大因子和枢轴深度(PD)等指标来量化泄露程度和遍历结构。提出七种检索枢轴攻击，利用向量到图谱的边界，展示即使没有对抗性注入，自然共享的实体也会有机地创建跨租户枢轴路径。在合成多租户企业语料库和Enron邮件语料库上进行实验。

Result: 未防御的混合管道表现出高枢轴风险(RPR高达0.95)，每个查询返回多个未经授权的项目。泄露一致出现在PD=2处，这归因于二分块-实体拓扑结构。在图谱扩展边界强制执行授权可以消除测量到的泄露(RPR接近0)，在所有语料库、所有攻击变体和高达10%的标签伪造率下都有效，且开销最小。

Conclusion: 根本原因是边界强制执行问题，而不是固有的复杂防御：两个单独安全的检索组件可以组合成一个不安全的系统，除非在过渡点重新检查授权。在向量到图谱的边界强制执行授权是消除跨租户数据泄露的有效解决方案。

Abstract: Hybrid Retrieval-Augmented Generation (RAG) pipelines combine vector similarity search with knowledge graph expansion for multi-hop reasoning. We show that this composition introduces a distinct security failure mode: a vector-retrieved "seed" chunk can pivot via entity links into sensitive graph neighborhoods, causing cross-tenant data leakage that does not occur in vector-only retrieval. We formalize this risk as Retrieval Pivot Risk (RPR) and introduce companion metrics Leakage@k, Amplification Factor, and Pivot Depth (PD) to quantify leakage magnitude and traversal structure.
  We present seven Retrieval Pivot Attacks that exploit the vector-to-graph boundary and show that adversarial injection is not required: naturally shared entities create cross-tenant pivot paths organically. Across a synthetic multi-tenant enterprise corpus and the Enron email corpus, the undefended hybrid pipeline exhibits high pivot risk (RPR up to 0.95) with multiple unauthorized items returned per query. Leakage consistently appears at PD=2, which we attribute to the bipartite chunk-entity topology and formalize as a proposition.
  We then show that enforcing authorization at a single location, the graph expansion boundary, eliminates measured leakage (RPR near 0) across both corpora, all attack variants, and label forgery rates up to 10 percent, with minimal overhead. Our results indicate the root cause is boundary enforcement, not inherently complex defenses: two individually secure retrieval components can compose into an insecure system unless authorization is re-checked at the transition point.

</details>


### [33] [Large Language Lobotomy: Jailbreaking Mixture-of-Experts via Expert Silencing](https://arxiv.org/abs/2602.08741)
*Jona te Lintelo,Lichao Wu,Stjepan Picek*

Main category: cs.CR

TL;DR: 提出L³攻击方法，通过分析MoE LLMs中安全行为集中在少数专家的现象，学习拒绝模式并沉默最相关的安全专家，实现无需训练的攻击，显著提升攻击成功率


<details>
  <summary>Details</summary>
Motivation: MoE架构通过仅激活部分参数提高扩展效率，但其路由结构引入了新的安全攻击面。研究发现MoE LLMs中的安全关键行为（如拒绝）集中在少数专家而非均匀分布，这为攻击提供了机会

Method: 提出Large Language Lobotomy (L³)攻击：1) 学习与拒绝行为相关的路由模式；2) 将安全行为归因于特定专家；3) 自适应地沉默最相关的安全专家直到产生有害输出。该方法无需训练且与架构无关

Result: 在8个最先进的开源MoE LLMs上评估，自适应专家沉默将平均攻击成功率从7.3%提升到70.4%，最高达86.3%，优于现有无需训练的MoE越狱方法。绕过防护通常只需沉默少于20%的层专家，同时基本保留语言能力

Conclusion: MoE设计中的效率驱动与鲁棒安全对齐存在根本性冲突。研究揭示了MoE LLMs的安全脆弱性，并建议未来应通过架构和路由感知方法更鲁棒地分布安全机制

Abstract: The rapid adoption of Mixture-of-Experts (MoE) architectures marks a major shift in the deployment of Large Language Models (LLMs). MoE LLMs improve scaling efficiency by activating only a small subset of parameters per token, but their routing structure introduces new safety attack surfaces. We find that safety-critical behaviors in MoE LLMs (e.g., refusal) are concentrated in a small set of experts rather than being uniformly distributed. Building on this, we propose Large Language Lobotomy (L$^3$), a training-free, architecture-agnostic attack that compromises safety alignment by exploiting expert routing dynamics. L$^3$ learns routing patterns that correlate with refusal, attributes safety behavior to specific experts, and adaptively silences the most safety-relevant experts until harmful outputs are produced. We evaluate L$^3$ on eight state-of-the-art open-source MoE LLMs and show that our adaptive expert silencing increases average attack success from 7.3% to 70.4%, reaching up to 86.3%, outperforming prior training-free MoE jailbreak methods. Moreover, bypassing guardrails typically requires silencing fewer than 20% of layer-wise experts while largely preserving general language utility. These results reveal a fundamental tension between efficiency-driven MoE design and robust safety alignment and motivate distributing safety mechanisms more robustly in future MoE LLMs with architecture- and routing-aware methods.

</details>


### [34] [Empirical Evaluation of SMOTE in Android Malware Detection with Machine Learning: Challenges and Performance in CICMalDroid 2020](https://arxiv.org/abs/2602.08744)
*Diego Ferreira Duarte,Andre Augusto Bortoli*

Main category: cs.CR

TL;DR: 该研究测试了多种机器学习算法在Android恶意软件检测中的性能，发现SMOTE数据平衡技术在该场景下效果不佳，而基于树的集成模型（如XGBoost）表现最优。


<details>
  <summary>Details</summary>
Motivation: Android设备广泛普及，恶意软件威胁日益严重，需要自动化检测方法。机器学习在恶意软件检测中具有潜力，但数据类别不平衡问题需要解决。

Method: 使用CICMalDroid2020数据集（动态获取的Android恶意软件行为样本），测试XGBoost、朴素贝叶斯、支持向量机和随机森林算法，并评估SMOTE技术对模型性能的影响。

Result: 在75%的测试配置中，SMOTE导致性能下降或仅有边际改进，平均损失6.14个百分点。基于树的算法（XGBoost和随机森林）表现最佳，加权召回率超过94%。

Conclusion: SMOTE在Android恶意软件检测中效果有限，可能由于动态特征的复杂性和稀疏性。基于树的集成模型更稳健，在某些网络安全场景中，算法数据平衡方法可能比生成合成实例更有效。

Abstract: Malware, malicious software designed to damage computer systems and perpetrate scams, is proliferating at an alarming rate, with thousands of new threats emerging daily. Android devices, prevalent in smartphones, smartwatches, tablets, and IoTs, represent a vast attack surface, making malware detection crucial. Although advanced analysis techniques exist, Machine Learning (ML) emerges as a promising tool to automate and accelerate the discovery of these threats. This work tests ML algorithms in detecting malicious code from dynamic execution characteristics. For this purpose, the CICMalDroid2020 dataset, composed of dynamically obtained Android malware behavior samples, was used with the algorithms XGBoost, Naıve Bayes (NB), Support Vector Classifier (SVC), and Random Forest (RF). The study focused on empirically evaluating the impact of the SMOTE technique, used to mitigate class imbalance in the data, on the performance of these models. The results indicate that, in 75% of the tested configurations, the application of SMOTE led to performance degradation or only marginal improvements, with an average loss of 6.14 percentage points. Tree-based algorithms, such as XGBoost and Random Forest, consistently outperformed the others, achieving weighted recall above 94%. It is inferred that SMOTE, although widely used, did not prove beneficial for Android malware detection in the CICMalDroid2020 dataset, possibly due to the complexity and sparsity of dynamic characteristics or the nature of malicious relationships. This work highlights the robustness of tree-ensemble models, such as XGBoost, and suggests that algorithmic data balancing approaches may be more effective than generating synthetic instances in certain cybersecurity scenarios

</details>


### [35] [DyMA-Fuzz: Dynamic Direct Memory Access Abstraction for Re-hosted Monolithic Firmware Fuzzing](https://arxiv.org/abs/2602.08750)
*Guy Farrelly,Michael Chesser,Seyit Camtepe,Damith C. Ranasinghe*

Main category: cs.CR

TL;DR: DyMA-Fuzz：首个针对嵌入式固件中DMA接口的模糊测试框架，通过运行时分析自动推断DMA访问模式并注入测试数据，显著提升了代码覆盖率和漏洞发现能力。


<details>
  <summary>Details</summary>
Motivation: 智能设备在关键领域（汽车、医疗、工业）的普及需要强大的固件测试。虽然基于重托管环境的固件模糊测试是有前景的自动化测试方法，但由于代码与微控制器外设的紧密耦合而困难重重。现有模糊测试框架主要解决内存映射I/O或中断的输入挑战，但忽略了直接内存访问（DMA）这一绕过CPU的关键高吞吐量接口。

Method: DyMA-Fuzz将基于流的模糊测试输入注入技术扩展到重托管环境中的DMA驱动接口。它使用运行时分析技术来推断DMA内存访问模式，并自动将模糊测试数据注入目标缓冲区，无需手动配置或数据手册。该方法解决了供应商特定描述符、异构DMA设计和不同描述符位置等关键挑战。

Result: 在94个固件样本和8个DMA保护的CVE基准测试中，DyMA-Fuzz发现了现有最先进工具遗漏的漏洞和执行路径，实现了高达122%的代码覆盖率提升。

Conclusion: DyMA-Fuzz是自动化固件测试领域的实用有效进展，为模糊测试复杂嵌入式系统提供了可扩展的解决方案，显著提升了DMA接口的测试覆盖能力。

Abstract: The rise of smart devices in critical domains--including automotive, medical, industrial--demands robust firmware testing. Fuzzing firmware in re-hosted environments is a promising method for automated testing at scale, but remains difficult due to the tight coupling of code with a microcontroller's peripherals. Existing fuzzing frameworks primarily address input challenges in providing inputs for Memory-Mapped I/O or interrupts, but largely overlook Direct Memory Access (DMA), a key high-throughput interface used that bypasses the CPU. We introduce DyMA-Fuzz to extend recent advances in stream-based fuzz input injection to DMA-driven interfaces in re-hosted environments. It tackles key challenges--vendor-specific descriptors, heterogeneous DMA designs, and varying descriptor locations--using runtime analysis techniques to infer DMA memory access patterns and automatically inject fuzzing data into target buffers, without manual configuration or datasheets. Evaluated on 94 firmware samples and 8 DMA-guarded CVE benchmarks, DyMA-Fuzz reveals vulnerabilities and execution paths missed by state-of-the-art tools and achieves up to 122% higher code coverage. These results highlight DyMA-Fuzz as a practical and effective advancement in automated firmware testing and a scalable solution for fuzzing complex embedded systems.

</details>


### [36] [CryptoGen: Secure Transformer Generation with Encrypted KV-Cache Reuse](https://arxiv.org/abs/2602.08798)
*Hedong Zhang,Neusha Javidnia,Shweta Pardeshi,Qian Lou,Farinaz Koushanfar*

Main category: cs.CR

TL;DR: CryptoGen是首个支持可扩展隐私保护神经生成的系统，通过持久化加密KV缓存复用实现近线性扩展，相比现有安全推理系统在自回归生成中降低4.4-7.6倍延迟。


<details>
  <summary>Details</summary>
Motivation: 云托管生成模型的广泛部署带来了基本挑战：如何在不可信环境中实现高效的自回归生成，同时保护用户提示和模型参数的隐私。现有基于判别任务的安全推理系统在适应自回归解码时，由于缺乏原生加密KV缓存支持，会导致二次方延迟和内存增长。

Method: CryptoGen整合同态加密和秘密共享，支持预填充和生成阶段。关键技术包括：统一的加密KV缓存框架、针对不同阶段的异构SIMD编码、优化的密文-密文矩阵-矩阵和矩阵-向量操作、高效的噪声刷新和密文拼接机制。

Result: 在WikiText-2、PTB和LAMBADA数据集训练的生成Transformer模型上评估，对于128-512个token的输入长度，CryptoGen相比最先进的判别安全推理系统实现了4.4-7.6倍的单token延迟降低，同时保持近线性的延迟和内存扩展，序列越长优势越明显。

Conclusion: CryptoGen是首个实现可扩展隐私保护神经生成的系统，通过安全复用和更新加密KV缓存实现近线性扩展，显著优于现有方法，并已作为开源库发布。

Abstract: The widespread deployment of cloud-hosted generative models raises a fundamental challenge: enabling efficient autoregressive generation while preserving the privacy of both user prompts and model parameters in untrusted environments. We address this challenge in a client-server setting where an untrusted server hosts an autoregressive Transformer and the client requires cryptographic protection for both inputs and inference. We present CryptoGen, the first system to enable scalable privacy-preserving neural generation with persistent encrypted key-value (KV) cache reuse. Discriminative-task secure inference systems incur quadratic latency and memory growth when adapted to autoregressive decoding due to the lack of native encrypted KV-cache support. In contrast, CryptoGen achieves near-linear scaling by securely reusing and updating encrypted KV caches throughout generation. CryptoGen integrates homomorphic encryption and secret sharing to support both prefilling and generation. Key techniques include a unified encrypted KV-cache framework, heterogeneous SIMD encodings for different phases, optimized cipher-cipher matrix-matrix and matrix-vector operations, and efficient noise refresh and ciphertext concatenation mechanisms. Evaluation on generative Transformer models trained on WikiText-2, PTB, and LAMBADA shows that for input lengths of 128-512 tokens, CryptoGen achieves 4.4x-7.6x lower per-token latency than state-of-the-art discriminative secure inference systems, while maintaining near-linear latency and memory scaling, with advantages increasing for longer sequences. CryptoGen is released as an open-source library.

</details>


### [37] [ZK-Rollup for Hyperledger Fabric: Architecture and Performance Evaluation](https://arxiv.org/abs/2602.08870)
*Sania Siddiqui,Neha,Hari Babu K*

Main category: cs.CR

TL;DR: 为Hyperledger Fabric设计并实现基于ZK Rollups的Layer-2扩容方案，将吞吐量提升近10倍，延迟降低80%


<details>
  <summary>Details</summary>
Motivation: 区块链平台面临在保持用户隐私的同时实现可扩展性的挑战。Hyperledger Fabric的基线架构由于背书、排序和验证阶段的限制，吞吐量仅为5-7 TPS，平均延迟4秒，需要解决这些可扩展性限制

Method: 提出Layer-2扩容方案，采用ZK Rollups技术。设计离链排序器立即接受交易，将其批量处理到基于Merkle树的rollup中，使用ZK证明来验证整个批次的正确性和可验证性。将交易接收与实际链上结算解耦

Result: Layer-2方案实现了70-100 TPS的接收吞吐量，相比基线提升近10倍。客户端感知延迟降低近80%，达到700-1000毫秒。在保持许可区块链网络安全保证的同时显著提升了可扩展性

Conclusion: 在Hyperledger Fabric中集成ZK Rollups可以有效增强可扩展性，同时不损害许可区块链网络的安全保证。该工作证明了Layer-2解决方案在解决区块链可扩展性挑战方面的有效性

Abstract: A big challenge posed in blockchain centric platforms is achieving scalability while also preserving user privacy. This report details the design, implementation and evaluation of a Layer-2 scaling solution for Hyperledger Fabric using Zero Knowledge Rollups (ZK Rollups). The proposed architecture introduces an off chain sequencer that accepts transactions immediately and sends them for batching into a Merkle tree based rollup, using ZK proofs to attest to the correctness and verifiability of the entire batch.
  The design aims to decouple transaction ingestion from actual on chain settlements to address Fabric scalability limitations and increase throughput under high load conditions. The baseline architecture in Hyperledger Fabric constrains transaction requests due to endorsement, ordering and validation phases, leading to a throughput of 5 to 7 TPS with an average latency of 4 seconds. Our Layer-2 solution achieves an ingestion throughput of 70 to 100 TPS, leading to an increase of nearly ten times due to the sequencer immediate acceptance of each transaction and reducing client perceived latency by nearly eighty percent to 700 to 1000 milliseconds. This work demonstrates that integrating ZK Rollups in Hyperledger Fabric enhances scalability while not compromising the security guarantees of a permissioned blockchain network.

</details>


### [38] [Reverse Online Guessing Attacks on PAKE Protocols](https://arxiv.org/abs/2602.08993)
*Eloise Christian,Tejas Gadwalkar,Arthur Azevedo de Amorim,Edward V. Zieglar*

Main category: cs.CR

TL;DR: 该论文重新评估PAKE协议模型，指出缺乏PKI或服务器认证机制使协议易受反向在线猜测攻击，建议默认采用比密码更严格的服务器认证措施


<details>
  <summary>Details</summary>
Motivation: 虽然PAKE协议因抵抗猜测攻击和无需PKI而受到标准化关注，但作者发现缺乏PKI或服务器认证机制会使协议易受反向在线猜测攻击，这种攻击将检测负担转移到客户端，使现有防御措施失效

Method: 通过分析PAKE协议模型，识别反向在线猜测攻击的漏洞，研究攻击在钓鱼、密码喷洒攻击以及WPA3-SAE等场景中的有效性，并提出安全建议

Result: 研究发现反向猜测攻击在攻击者无差别攻击客户端时特别有效，如钓鱼攻击或密码喷洒攻击，或在具有自动化登录流程或通用密码的应用中（如WPA3-SAE）

Conclusion: 利益相关者应默认使用比用户密码更严格的措施来认证服务器，密码仅模式应作为其他认证机制不可用时的最后手段，以应对灾难性安全故障

Abstract: Though not yet widely deployed, password-authenticated key exchange (PAKE) protocols have been the subject of several recent standardization efforts, partly because of their resistance against various guessing attacks, but also because they do not require a public-key infrastructure (PKI), making them naturally resistant against PKI failures. The goal of this paper is to reevaluate the PAKE model by noting that the absence of a PKI -- or, more generally, of a mechanism aside from the password for authenticating the server -- makes such protocols vulnerable to reverse online guessing attacks, in which an adversary attempts to validate password guesses by impersonating a server. While their logic is similar to traditional guessing, where the attacker impersonates a client, reverse guessing poses a unique risk because the burden of detection is shifted to the clients, rendering existing defenses against traditional guessing moot. Our results demonstrate that reverse guessing is particularly effective when an adversary attacks clients indiscriminately, such as in phishing or password-spraying attacks, or for applications with automated login processes or a universal password, such as WPA3-SAE. Our analysis suggests that stakeholders should, by default, authenticate the server using more stringent measures than just the user's password, and that a password-only mode of operation should be a last resort against catastrophic security failures when other authentication mechanisms are not available.

</details>


### [39] [CIC-Trap4Phish: A Unified Multi-Format Dataset for Phishing and Quishing Attachment Detection](https://arxiv.org/abs/2602.09015)
*Fatemeh Nejati,Mahdi Rabbani,Mansur Mirani,Gunjan Piya,Igor Opushnyev,Ali A. Ghorbani,Sajjad Dadkhah*

Main category: cs.CR

TL;DR: 提出了CIC-Trap4Phish多格式钓鱼数据集和检测框架，涵盖Word、Excel、PDF、HTML和QR码五种常见钓鱼文件类型，使用静态特征提取和轻量级机器学习模型实现高精度检测。


<details>
  <summary>Details</summary>
Motivation: 钓鱼攻击是网络攻击的主要手段之一，恶意邮件附件因其灵活性成为攻击者首选载体。现有研究面临缺乏统一全面数据集的挑战，且安全措施常被绕过。

Method: 1) 创建CIC-Trap4Phish多格式数据集，包含恶意和良性样本；2) 对前四种文件类型提出无执行静态特征管道，提取结构、词汇和元数据特征；3) 使用SHAP分析和特征重要性进行特征选择；4) 采用轻量级机器学习模型评估；5) 对QR码钓鱼使用CNN图像检测和轻量级语言模型URL分析。

Result: 所有模型在不同文件格式上都表现出高检测准确率。特征选择产生了紧凑、有区分度的特征子集，轻量级模型实现了有效检测。

Conclusion: CIC-Trap4Phish数据集填补了钓鱼检测研究的数据空白，提出的静态特征管道和轻量级模型框架为多格式钓鱼附件检测提供了有效解决方案，特别针对QR码钓鱼提出了双重检测方法。

Abstract: Phishing attacks represents one of the primary attack methods which is used by cyber attackers. In many cases, attackers use deceptive emails along with malicious attachments to trick users into giving away sensitive information or installing malware while compromising entire systems. The flexibility of malicious email attachments makes them stand out as a preferred vector for attackers as they can embed harmful content such as malware or malicious URLs inside standard document formats. Although phishing email defenses have improved a lot, attackers continue to abuse attachments, enabling malicious content to bypass security measures. Moreover, another challenge that researches face in training advance models, is lack of an unified and comprehensive dataset that covers the most prevalent data types. To address this gap, we generated CIC-Trap4Phish, a multi-format dataset containing both malicious and benign samples across five categories commonly used in phishing campaigns: Microsoft Word documents, Excel spreadsheets, PDF files, HTML pages, and QR code images. For the first four file types, a set of execution-free static feature pipeline was proposed, designed to capture structural, lexical, and metadata-based indicators without the need to open or execute files. Feature selection was performed using a combination of SHAP analysis and feature importance, yielding compact, discriminative feature subsets for each file type. The selected features were evaluated by using lightweight machine learning models, including Random Forest, XGBoost, and Decision Tree. All models demonstrate high detection accuracy across formats. For QR code-based phishing (quishing), two complementary methods were implemented: image-based detection by employing Convolutional Neural Networks (CNNs) and lexical analysis of decoded URLs using recent lightweight language models.

</details>
