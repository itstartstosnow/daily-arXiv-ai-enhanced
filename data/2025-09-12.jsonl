{"id": "2509.08992", "categories": ["cs.CR"], "pdf": "https://arxiv.org/pdf/2509.08992", "abs": "https://arxiv.org/abs/2509.08992", "authors": ["Anqi Chen", "Riccardo Preatoni", "Alessandro Brighente", "Mauro Conti", "Cristina Nita-Rotaru"], "title": "Cross-Service Token: Finding Attacks in 5G Core Networks", "comment": null, "summary": "5G marks a major departure from previous cellular architectures, by\ntransitioning from a monolithic design of the core network to a Service-Based\nArchitecture (SBA) where services are modularized as Network Functions (NFs)\nwhich communicate with each other via standard-defined HTTP-based APIs called\nService-Based Interfaces (SBIs). These NFs are deployed in private and public\ncloud infrastructure, and an access control framework based on OAuth restricts\nhow they communicate with each other and obtain access to resources. Given the\nincreased vulnerabilities of clouds to insiders, it is important to study the\nsecurity of the 5G Core services for vulnerabilities that allow attackers to\nuse compromised NFs to obtain unauthorized access to resources.\n  We present FivGeeFuzz, a grammar-based fuzzing framework designed to uncover\nsecurity flaws in 5G core SBIs. FivGeeFuzz automatically derives grammars from\n3GPP API specifications to generate malformed, unexpected, or semantically\ninconsistent inputs, and it integrates automated bug detection with manual\nvalidation and root-cause analysis. We evaluate our approach on free5GC, the\nonly open-source 5G core implementing Release 17-compliant SBIs with an access\ncontrol mechanism. Using FivGeeFuzz, we discovered 8 previously unknown\nvulnerabilities in free5GC, leading to runtime crashes, improper error\nhandling, and unauthorized access to resources, including a very severe attack\nwe call Cross-Service Token Attack. All bugs were confirmed by the free5GC\nteam, 7 have already been patched, and the remaining one has a patch under\ndevelopment."}
{"id": "2509.08995", "categories": ["cs.CR"], "pdf": "https://arxiv.org/pdf/2509.08995", "abs": "https://arxiv.org/abs/2509.08995", "authors": ["Sichen Zhu", "Hoyeung Leung", "Xiaoyi Wang", "Jia Wei", "Honghui Xu"], "title": "When FinTech Meets Privacy: Securing Financial LLMs with Differential Private Fine-Tuning", "comment": null, "summary": "The integration of Large Language Models (LLMs) into financial technology\n(FinTech) has revolutionized the analysis and processing of complex financial\ndata, driving advancements in real-time decision-making and analytics. With the\ngrowing trend of deploying AI models on edge devices for financial\napplications, ensuring the privacy of sensitive financial data has become a\nsignificant challenge. To address this, we propose DPFinLLM, a\nprivacy-enhanced, lightweight LLM specifically designed for on-device financial\napplications. DPFinLLM combines a robust differential privacy mechanism with a\nstreamlined architecture inspired by state-of-the-art models, enabling secure\nand efficient processing of financial data. This proposed DPFinLLM can not only\nsafeguard user data from privacy breaches but also ensure high performance\nacross diverse financial tasks. Extensive experiments on multiple financial\nsentiment datasets validate the effectiveness of DPFinLLM, demonstrating its\nability to achieve performance comparable to fully fine-tuned models, even\nunder strict privacy constraints."}
{"id": "2509.09089", "categories": ["cs.CR"], "pdf": "https://arxiv.org/pdf/2509.09089", "abs": "https://arxiv.org/abs/2509.09089", "authors": ["Mengfei Xie", "Yan Lin", "Hongtao Wu", "Jianming Fu", "Chenke Luo", "Guojun Peng"], "title": "Beyond Tag Collision: Cluster-based Memory Management for Tag-based Sanitizers", "comment": "This paper has been accepted to the 2025 ACM SIGSAC Conference on\n  Computer and Communications Security (CCS'25)", "summary": "Tag-based sanitizers attach a small \"key\" to each pointer and a matching\n\"lock\" tag to its target memory object, enabling runtime verification of\npointer-object consistency and helping developers to detect potential memory\nviolations. However, the limited tag encoding space challenges existing studies\nin assigning distinct tags to memory objects across temporal and spatial\ndimensions, leading to potential tag collisions. In this paper, we present\nClusterTag, a novel cluster-based memory allocator aimed at simultaneously\nmitigating tag collisions in both temporal and spatial dimensions. The core\ndesign of ClusterTag effectively balances the significant mismatch between tag\nencoding space and memory objects: it divides memory objects into multiple\nindependent clusters, thereby limiting tag collisions to finite chunks within\neach cluster. To mitigate tag collisions across clusters, we design a\ncluster-grained heap randomization scheme. This approach introduces random\naddress intervals between clusters and further breaks the entropy limitation of\nthe tag space. ClusterTag has been implemented as an independent memory\nallocator that seamlessly integrates with tag-based sanitizers such as HWASan,\nand maintains comparable performance overhead (within 1%) at various\nrandomization densities. Security evaluations on the Juliet dataset indicate\nthat ClusterTag exhibits deterministic results across 500 repeated tests (5,652\nreported and 1,530 missed), while the existing three types of tag assignment\nstrategies all exhibit probabilistic false negatives due to tag collisions.\nQuantitative analysis across three tag collision distance metrics-minimum,\naverage, and unpredictability-demonstrates that ClusterTag achieves balanced\nimprovements across all three, whereas prior tag assignment schemes (random,\nstaggered, fixed) show significant trade-offs in at least one metric."}
{"id": "2509.09091", "categories": ["cs.CR", "cs.AI"], "pdf": "https://arxiv.org/pdf/2509.09091", "abs": "https://arxiv.org/abs/2509.09091", "authors": ["Honglan Yu", "Yibin Wang", "Feifei Dai", "Dong Liu", "Haihui Fan", "Xiaoyan Gu"], "title": "Towards Confidential and Efficient LLM Inference with Dual Privacy Protection", "comment": "Accepted by DASFAA2025", "summary": "CPU-based trusted execution environments (TEEs) and differential privacy (DP)\nhave gained wide applications for private inference. Due to high inference\nlatency in TEEs, researchers use partition-based approaches that offload linear\nmodel components to GPUs. However, dense nonlinear layers of large language\nmodels (LLMs) result in significant communication overhead between TEEs and\nGPUs. DP-based approaches apply random noise to protect data privacy, but this\ncompromises LLM performance and semantic understanding. To overcome the above\ndrawbacks, this paper proposes CMIF, a Confidential and efficient Model\nInference Framework. CMIF confidentially deploys the embedding layer in the\nclient-side TEE and subsequent layers on GPU servers. Meanwhile, it optimizes\nthe Report-Noisy-Max mechanism to protect sensitive inputs with a slight\ndecrease in model performance. Extensive experiments on Llama-series models\ndemonstrate that CMIF reduces additional inference overhead in TEEs while\npreserving user data privacy."}
{"id": "2509.09097", "categories": ["cs.CR", "cs.AI"], "pdf": "https://arxiv.org/pdf/2509.09097", "abs": "https://arxiv.org/abs/2509.09097", "authors": ["Honghui Xu", "Shiva Shrestha", "Wei Chen", "Zhiyuan Li", "Zhipeng Cai"], "title": "DP-FedLoRA: Privacy-Enhanced Federated Fine-Tuning for On-Device Large Language Models", "comment": null, "summary": "As on-device large language model (LLM) systems become increasingly\nprevalent, federated fine-tuning enables advanced language understanding and\ngeneration directly on edge devices; however, it also involves processing\nsensitive, user-specific data, raising significant privacy concerns within the\nfederated learning framework. To address these challenges, we propose\nDP-FedLoRA, a privacy-enhanced federated fine-tuning framework that integrates\nLoRA-based adaptation with differential privacy in a communication-efficient\nsetting. Each client locally clips and perturbs its LoRA matrices using\nGaussian noise to satisfy ($\\epsilon$, $\\delta$)-differential privacy. We\nfurther provide a theoretical analysis demonstrating the unbiased nature of the\nupdates and deriving bounds on the variance introduced by noise, offering\npractical guidance for privacy-budget calibration. Experimental results across\nmainstream benchmarks show that DP-FedLoRA delivers competitive performance\nwhile offering strong privacy guarantees, paving the way for scalable and\nprivacy-preserving LLM deployment in on-device environments."}
{"id": "2509.09103", "categories": ["cs.CR"], "pdf": "https://arxiv.org/pdf/2509.09103", "abs": "https://arxiv.org/abs/2509.09103", "authors": ["Chanti Raju Mylay", "Bobin Deng", "Zhipeng Cai", "Honghui Xu"], "title": "AgriSentinel: Privacy-Enhanced Embedded-LLM Crop Disease Alerting System", "comment": null, "summary": "Crop diseases pose significant threats to global food security, agricultural\nproductivity, and sustainable farming practices, directly affecting farmers'\nlivelihoods and economic stability. To address the growing need for effective\ncrop disease management, AI-based disease alerting systems have emerged as\npromising tools by providing early detection and actionable insights for timely\nintervention. However, existing systems often overlook critical aspects such as\ndata privacy, market pricing power, and farmer-friendly usability, leaving\nfarmers vulnerable to privacy breaches and economic exploitation. To bridge\nthese gaps, we propose AgriSentinel, the first Privacy-Enhanced Embedded-LLM\nCrop Disease Alerting System. AgriSentinel incorporates a differential privacy\nmechanism to protect sensitive crop image data while maintaining classification\naccuracy. Its lightweight deep learning-based crop disease classification model\nis optimized for mobile devices, ensuring accessibility and usability for\nfarmers. Additionally, the system includes a fine-tuned, on-device large\nlanguage model (LLM) that leverages a curated knowledge pool to provide farmers\nwith specific, actionable suggestions for managing crop diseases, going beyond\nsimple alerting. Comprehensive experiments validate the effectiveness of\nAgriSentinel, demonstrating its ability to safeguard data privacy, maintain\nhigh classification performance, and deliver practical, actionable disease\nmanagement strategies. AgriSentinel offers a robust, farmer-friendly solution\nfor automating crop disease alerting and management, ultimately contributing to\nimproved agricultural decision-making and enhanced crop productivity."}
{"id": "2509.09107", "categories": ["cs.CR", "cs.LG"], "pdf": "https://arxiv.org/pdf/2509.09107", "abs": "https://arxiv.org/abs/2509.09107", "authors": ["Pritam Sen", "Yao Ma", "Cristian Borcea"], "title": "CryptGNN: Enabling Secure Inference for Graph Neural Networks", "comment": null, "summary": "We present CryptGNN, a secure and effective inference solution for\nthird-party graph neural network (GNN) models in the cloud, which are accessed\nby clients as ML as a service (MLaaS). The main novelty of CryptGNN is its\nsecure message passing and feature transformation layers using distributed\nsecure multi-party computation (SMPC) techniques. CryptGNN protects the\nclient's input data and graph structure from the cloud provider and the\nthird-party model owner, and it protects the model parameters from the cloud\nprovider and the clients. CryptGNN works with any number of SMPC parties, does\nnot require a trusted server, and is provably secure even if P-1 out of P\nparties in the cloud collude. Theoretical analysis and empirical experiments\ndemonstrate the security and efficiency of CryptGNN."}
{"id": "2509.09112", "categories": ["cs.CR", "cs.AI"], "pdf": "https://arxiv.org/pdf/2509.09112", "abs": "https://arxiv.org/abs/2509.09112", "authors": ["Zhaoxi Zhang", "Xiaomei Zhang", "Yanjun Zhang", "He Zhang", "Shirui Pan", "Bo Liu", "Asif Qumer Gill", "Leo Yu Zhang"], "title": "Character-Level Perturbations Disrupt LLM Watermarks", "comment": null, "summary": "Large Language Model (LLM) watermarking embeds detectable signals into\ngenerated text for copyright protection, misuse prevention, and content\ndetection. While prior studies evaluate robustness using watermark removal\nattacks, these methods are often suboptimal, creating the misconception that\neffective removal requires large perturbations or powerful adversaries.\n  To bridge the gap, we first formalize the system model for LLM watermark, and\ncharacterize two realistic threat models constrained on limited access to the\nwatermark detector. We then analyze how different types of perturbation vary in\ntheir attack range, i.e., the number of tokens they can affect with a single\nedit. We observe that character-level perturbations (e.g., typos, swaps,\ndeletions, homoglyphs) can influence multiple tokens simultaneously by\ndisrupting the tokenization process. We demonstrate that character-level\nperturbations are significantly more effective for watermark removal under the\nmost restrictive threat model. We further propose guided removal attacks based\non the Genetic Algorithm (GA) that uses a reference detector for optimization.\nUnder a practical threat model with limited black-box queries to the watermark\ndetector, our method demonstrates strong removal performance. Experiments\nconfirm the superiority of character-level perturbations and the effectiveness\nof the GA in removing watermarks under realistic constraints. Additionally, we\nargue there is an adversarial dilemma when considering potential defenses: any\nfixed defense can be bypassed by a suitable perturbation strategy. Motivated by\nthis principle, we propose an adaptive compound character-level attack.\nExperimental results show that this approach can effectively defeat the\ndefenses. Our findings highlight significant vulnerabilities in existing LLM\nwatermark schemes and underline the urgency for the development of new robust\nmechanisms."}
{"id": "2509.09158", "categories": ["cs.CR"], "pdf": "https://arxiv.org/pdf/2509.09158", "abs": "https://arxiv.org/abs/2509.09158", "authors": ["Priyanka Rushikesh Chaudhary", "Rajib Ranjan Maiti"], "title": "IoTFuzzSentry: A Protocol Guided Mutation Based Fuzzer for Automatic Vulnerability Testing in Commercial IoT Devices", "comment": null, "summary": "Protocol fuzzing is a scalable and cost-effective technique for identifying\nsecurity vulnerabilities in deployed Internet of Things devices. During their\noperational phase, IoT devices often run lightweight servers to handle user\ninteractions, such as video streaming or image capture in smart cameras.\nImplementation flaws in transport or application-layer security mechanisms can\nexpose IoT devices to a range of threats, including unauthorized access and\ndata leakage. This paper addresses the challenge of uncovering such\nvulnerabilities by leveraging protocol fuzzing techniques that inject crafted\ntransport and application-layer packets into IoT communications. We present a\nmutation-based fuzzing tool, named IoTFuzzSentry, to identify specific\nnon-trivial vulnerabilities in commercial IoT devices. We further demonstrate\nhow these vulnerabilities can be exploited in real-world scenarios. We\nintegrated our fuzzing tool into a well-known testing tool Cotopaxi and\nevaluated it with commercial-off-the-shelf IoT devices such as IP cameras and\nSmart Plug. Our evaluation revealed vulnerabilities categorized into 4 types\n(IoT Access Credential Leakage, Sneak IoT Live Video Stream, Creep IoT Live\nImage, IoT Command Injection) and we show their exploits using three IoT\ndevices. We have responsibly disclosed all these vulnerabilities to the\nrespective vendors. So far, we have published two CVEs, CVE-2024-41623 and\nCVE-2024-42531, and one is awaiting. To extend the applicability, we have\ninvestigated the traffic of six additional IoT devices and our analysis shows\nthat these devices can have similar vulnerabilities, due to the presence of a\nsimilar set of application protocols. We believe that IoTFuzzSentry has the\npotential to discover unconventional security threats and allow IoT vendors to\nstrengthen the security of their commercialized IoT devices automatically with\nnegligible overhead."}
{"id": "2509.09185", "categories": ["cs.CR"], "pdf": "https://arxiv.org/pdf/2509.09185", "abs": "https://arxiv.org/abs/2509.09185", "authors": ["Jihane Najar", "Marinos Tsantekidis", "Aris Sotiropoulos", "Vassilis Prevelakis"], "title": "Enhancing Cyber Threat Hunting -- A Visual Approach with the Forensic Visualization Toolkit", "comment": "2023 IEEE International Conference on Big Data (BigData)", "summary": "In today's dynamic cyber threat landscape, organizations must take proactive\nsteps to bolster their cybersecurity defenses. Cyber threat hunting is a\nproactive and iterative process aimed at identifying and mitigating advanced\nthreats that may go undetected by traditional security measures. Rather than\nwaiting for automated security systems to flag potential threats, threat\nhunting involves actively searching for signs of malicious activity within an\norganization's network. In this paper, we present the Forensic Visualization\nToolkit, a powerful tool designed for digital forensics investigations,\nanalysis of digital evidence, and advanced visualizations to enhance\ncybersecurity situational awareness and risk management and empower security\nanalysts with an intuitive and interactive tool. Through practical, real-world\nscenarios, we demonstrate how FVT significantly amplifies the capabilities of\ncybersecurity professionals, enabling them to effectively identify, analyze,\nand respond to threats. Furthermore, it is important to highlight that FVT has\nbeen integrated into, utilized, and continually enhanced within various\nEU-funded research projects over recent years."}
{"id": "2509.09207", "categories": ["cs.CR"], "pdf": "https://arxiv.org/pdf/2509.09207", "abs": "https://arxiv.org/abs/2509.09207", "authors": ["Wuyuao Mai", "Geng Hong", "Qi Liu", "Jinsong Chen", "Jiarun Dai", "Xudong Pan", "Yuan Zhang", "Min Yang"], "title": "Shell or Nothing: Real-World Benchmarks and Memory-Activated Agents for Automated Penetration Testing", "comment": null, "summary": "Penetration testing is critical for identifying and mitigating security\nvulnerabilities, yet traditional approaches remain expensive, time-consuming,\nand dependent on expert human labor. Recent work has explored AI-driven\npentesting agents, but their evaluation relies on oversimplified\ncapture-the-flag (CTF) settings that embed prior knowledge and reduce\ncomplexity, leading to performance estimates far from real-world practice. We\nclose this gap by introducing the first real-world, agent-oriented pentesting\nbenchmark, TermiBench, which shifts the goal from 'flag finding' to achieving\nfull system control. The benchmark spans 510 hosts across 25 services and 30\nCVEs, with realistic environments that require autonomous reconnaissance,\ndiscrimination between benign and exploitable services, and robust exploit\nexecution. Using this benchmark, we find that existing systems can hardly\nobtain system shells under realistic conditions.\n  To address these challenges, we propose TermiAgent, a multi-agent penetration\ntesting framework. TermiAgent mitigates long-context forgetting with a Located\nMemory Activation mechanism and builds a reliable exploit arsenal via\nstructured code understanding rather than naive retrieval. In evaluations, our\nwork outperforms state-of-the-art agents, exhibiting stronger penetration\ntesting capability, reducing execution time and financial cost, and\ndemonstrating practicality even on laptop-scale deployments. Our work delivers\nboth the first open-source benchmark for real-world autonomous pentesting and a\nnovel agent framework that establishes a milestone for AI-driven penetration\ntesting."}
{"id": "2509.09222", "categories": ["cs.CR", "cs.NI"], "pdf": "https://arxiv.org/pdf/2509.09222", "abs": "https://arxiv.org/abs/2509.09222", "authors": ["Muhammad Azmi Umer", "Zhan Xuna", "Yan Lin Aung", "Aditya P. Mathur", "Jianying Zhou"], "title": "A Cyber-Twin Based Honeypot for Gathering Threat Intelligence", "comment": null, "summary": "Critical Infrastructure (CI) is prone to cyberattacks. Several techniques\nhave been developed to protect CI against such attacks. In this work, we\ndescribe a honeypot based on a cyber twin for a water treatment plant. The\nhoneypot is intended to serve as a realistic replica of a water treatment plant\nthat attracts potential attackers. The attacks launched on the honeypot are\nrecorded and analyzed for threat intelligence. The intelligence so obtained is\nshared with the management of water treatment plants, who in turn may use it to\nimprove plant protection systems. The honeypot used here is operational and has\nbeen attacked on several occasions using, for example, a ransomware attack that\nis described in detail."}
{"id": "2509.09291", "categories": ["cs.CR", "cs.NI"], "pdf": "https://arxiv.org/pdf/2509.09291", "abs": "https://arxiv.org/abs/2509.09291", "authors": ["Biwei Yan", "Yue Zhang", "Minghui Xu", "Runyu Pan", "Jinku Li", "Xiuzhen Cheng"], "title": "What You Code Is What We Prove: Translating BLE App Logic into Formal Models with LLMs for Vulnerability Detection", "comment": null, "summary": "The application layer of Bluetooth Low Energy (BLE) is a growing source of\nsecurity vulnerabilities, as developers often neglect to implement critical\nprotections such as encryption, authentication, and freshness. While formal\nverification offers a principled way to check these properties, the manual\neffort of constructing formal models makes it impractical for large-scale\nanalysis. This paper introduces a key insight: BLE application security\nanalysis can be reframed as a semantic translation problem, i.e., from\nreal-world code to formal models. We leverage large language models (LLMs) not\nto directly detect vulnerabilities, but to serve as translators that convert\nBLE-specific code into process models verifiable by tools like ProVerif. We\nimplement this idea in VerifiaBLE, a system that combines static analysis,\nprompt-guided LLM translation, and symbolic verification to check three core\nsecurity features: encryption, randomness, and authentication. Applied to 1,050\nAndroid BLE apps, VerifiaBLE uncovers systemic weaknesses: only 10.2\\% of apps\nimplement all three protections, while 53.9\\% omit them entirely. Our work\ndemonstrates that using LLMs as structured translators can lower the barrier to\nformal methods, unlocking scalable verification across security-critical\ndomains."}
{"id": "2509.09331", "categories": ["cs.CR"], "pdf": "https://arxiv.org/pdf/2509.09331", "abs": "https://arxiv.org/abs/2509.09331", "authors": ["Fabian Bäumer", "Marcus Brinkmann", "Maximilian Radoy", "Jörg Schwenk", "Juraj Somorovsky"], "title": "On the Security of SSH Client Signatures", "comment": "15 pages, 5 figures, accepted at ACM CCS 2025", "summary": "Administrators and developers use SSH client keys and signatures for\nauthentication, for example, to access internet backbone servers or to commit\nnew code on platforms like GitHub. However, unlike servers, SSH clients cannot\nbe measured through internet scans. We close this gap in two steps. First, we\ncollect SSH client public keys. Such keys are regularly published by their\nowners on open development platforms like GitHub and GitLab. We systematize\nprevious non-academic work by subjecting these keys to various security tests\nin a longitudinal study. Second, in a series of black-box lab experiments, we\nanalyze the implementations of algorithms for SSH client signatures in 24\npopular SSH clients for Linux, Windows, and macOS.\n  We extracted 31,622,338 keys from three public sources in two scans. Compared\nto previous work, we see a clear tendency to abandon RSA signatures in favor of\nEdDSA signatures. Still, in January 2025, we found 98 broken short keys, 139\nkeys generated from weak randomness, and 149 keys with common or small\nfactors-the large majority of the retrieved keys exposed no weakness.\n  Weak randomness can not only compromise a secret key through its public key,\nbut also through signatures. It is well-known that a bias in random nonces in\nECDSA can reveal the secret key through public signatures. For the first time,\nwe show that the use of deterministic nonces in ECDSA can also be dangerous:\nThe private signing key of a PuTTY client can be recovered from just 58 valid\nsignatures if ECDSA with NIST curve P-521 is used. PuTTY acknowledged our\nfinding in CVE-2024-31497, and they subsequently replaced the nonce generation\nalgorithm."}
{"id": "2509.09351", "categories": ["cs.CR"], "pdf": "https://arxiv.org/pdf/2509.09351", "abs": "https://arxiv.org/abs/2509.09351", "authors": ["Harshini Sri Ramulu", "Helen Schmitt", "Bogdan Rerich", "Rachel Gonzalez Rodriguez", "Tadayoshi Kohno", "Yasemin Acar"], "title": "[Extended] Ethics in Computer Security Research: A Data-Driven Assessment of the Past, the Present, and the Possible Future", "comment": "19 pages", "summary": "Ethical questions are discussed regularly in computer security. Still,\nresearchers in computer security lack clear guidance on how to make, document,\nand assess ethical decisions in research when what is morally right or\nacceptable is not clear-cut. In this work, we give an overview of the\ndiscussion of ethical implications in current published work in computer\nsecurity by reviewing all 1154 top-tier security papers published in 2024,\nfinding inconsistent levels of ethics reporting with a strong focus of\nreporting institutional or ethics board approval, human subjects protection,\nand responsible disclosure, and a lack of discussion of balancing harms and\nbenefits. We further report on the results of a semi-structured interview study\nwith 24 computer security and privacy researchers (among whom were also:\nreviewers, ethics committee members, and/or program chairs) and their ethical\ndecision-making both as authors and during peer review, finding a strong desire\nfor ethical research, but a lack of consistency in considered values, ethical\nframeworks (if articulated), decision-making, and outcomes. We present an\noverview of the current state of the discussion of ethics and current de-facto\nstandards in computer security research, and contribute suggestions to improve\nthe state of ethics in computer security research."}
{"id": "2509.09424", "categories": ["cs.CR", "cs.AI"], "pdf": "https://arxiv.org/pdf/2509.09424", "abs": "https://arxiv.org/abs/2509.09424", "authors": ["Zhiyu He", "Maojiang Wang", "Xinwen Gao", "Yuchuan Luo", "Lin Liu", "Shaojing Fu"], "title": "ENSI: Efficient Non-Interactive Secure Inference for Large Language Models", "comment": null, "summary": "Secure inference enables privacy-preserving machine learning by leveraging\ncryptographic protocols that support computations on sensitive user data\nwithout exposing it. However, integrating cryptographic protocols with large\nlanguage models (LLMs) presents significant challenges, as the inherent\ncomplexity of these protocols, together with LLMs' massive parameter scale and\nsophisticated architectures, severely limits practical usability. In this work,\nwe propose ENSI, a novel non-interactive secure inference framework for LLMs,\nbased on the principle of co-designing the cryptographic protocols and LLM\narchitecture. ENSI employs an optimized encoding strategy that seamlessly\nintegrates CKKS scheme with a lightweight LLM variant, BitNet, significantly\nreducing the computational complexity of encrypted matrix multiplications. In\nresponse to the prohibitive computational demands of softmax under homomorphic\nencryption (HE), we pioneer the integration of the sigmoid attention mechanism\nwith HE as a seamless, retraining-free alternative. Furthermore, by embedding\nthe Bootstrapping operation within the RMSNorm process, we efficiently refresh\nciphertexts while markedly decreasing the frequency of costly bootstrapping\ninvocations. Experimental evaluations demonstrate that ENSI achieves\napproximately an 8x acceleration in matrix multiplications and a 2.6x speedup\nin softmax inference on CPU compared to state-of-the-art method, with the\nproportion of bootstrapping is reduced to just 1%."}
{"id": "2509.09488", "categories": ["cs.CR", "cs.AI"], "pdf": "https://arxiv.org/pdf/2509.09488", "abs": "https://arxiv.org/abs/2509.09488", "authors": ["Felix Mächtle", "Ashwath Shetty", "Jonas Sander", "Nils Loose", "Sören Pirk", "Thomas Eisenbarth"], "title": "Prompt Pirates Need a Map: Stealing Seeds helps Stealing Prompts", "comment": null, "summary": "Diffusion models have significantly advanced text-to-image generation,\nenabling the creation of highly realistic images conditioned on textual prompts\nand seeds. Given the considerable intellectual and economic value embedded in\nsuch prompts, prompt theft poses a critical security and privacy concern. In\nthis paper, we investigate prompt-stealing attacks targeting diffusion models.\nWe reveal that numerical optimization-based prompt recovery methods are\nfundamentally limited as they do not account for the initial random noise used\nduring image generation. We identify and exploit a noise-generation\nvulnerability (CWE-339), prevalent in major image-generation frameworks,\noriginating from PyTorch's restriction of seed values to a range of $2^{32}$\nwhen generating the initial random noise on CPUs. Through a large-scale\nempirical analysis conducted on images shared via the popular platform CivitAI,\nwe demonstrate that approximately 95% of these images' seed values can be\neffectively brute-forced in 140 minutes per seed using our seed-recovery tool,\nSeedSnitch. Leveraging the recovered seed, we propose PromptPirate, a genetic\nalgorithm-based optimization method explicitly designed for prompt stealing.\nPromptPirate surpasses state-of-the-art methods, i.e., PromptStealer, P2HP, and\nCLIP-Interrogator, achieving an 8-11% improvement in LPIPS similarity.\nFurthermore, we introduce straightforward and effective countermeasures that\nrender seed stealing, and thus optimization-based prompt stealing, ineffective.\nWe have disclosed our findings responsibly and initiated coordinated mitigation\nefforts with the developers to address this critical vulnerability."}
{"id": "2509.09564", "categories": ["cs.CR", "cs.LG"], "pdf": "https://arxiv.org/pdf/2509.09564", "abs": "https://arxiv.org/abs/2509.09564", "authors": ["Meghan Wilkinson", "Robert H Thomson"], "title": "What Does Normal Even Mean? Evaluating Benign Traffic in Intrusion Detection Datasets", "comment": "10 pages; accepted to SBP-BRiMS 2025 Poster Session", "summary": "Supervised machine learning techniques rely on labeled data to achieve high\ntask performance, but this requires the labels to capture some meaningful\ndifferences in the underlying data structure. For training network intrusion\ndetection algorithms, most datasets contain a series of attack classes and a\nsingle large benign class which captures all non-attack network traffic. A\nreview of intrusion detection papers and guides that explicitly state their\ndata preprocessing steps identified that the majority took the labeled\ncategories of the dataset at face value when training their algorithms. The\npresent paper evaluates the structure of benign traffic in several common\nintrusion detection datasets (NSL-KDD, UNSW-NB15, and CIC-IDS 2017) and\ndetermines whether there are meaningful sub-categories within this traffic\nwhich may improve overall multi-classification performance using common machine\nlearning techniques. We present an overview of some unsupervised clustering\ntechniques (e.g., HDBSCAN, Mean Shift Clustering) and show how they\ndifferentially cluster the benign traffic space."}
{"id": "2509.09592", "categories": ["cs.CR"], "pdf": "https://arxiv.org/pdf/2509.09592", "abs": "https://arxiv.org/abs/2509.09592", "authors": ["Aditya Kulkarni", "Shahil Manishbhai Patel", "Shivam Pradip Tirmare", "Vivek Balachandran", "Tamal Das"], "title": "Bridging the Gap in Phishing Detection: A Comprehensive Phishing Dataset Collector", "comment": null, "summary": "To combat phishing attacks -- aimed at luring web users to divulge their\nsensitive information -- various phishing detection approaches have been\nproposed. As attackers focus on devising new tactics to bypass existing\ndetection solutions, researchers have adapted by integrating machine learning\nand deep learning into phishing detection. Phishing dataset collection is vital\nto developing effective phishing detection approaches, which highly depend on\nthe diversity of the gathered datasets. The lack of diversity in the dataset\nresults in a biased model. Since phishing websites are often short-lived,\ncollecting them is also a challenge. Consequently, very few phishing webpage\ndataset repositories exist to date. No single repository comprehensively\nconsolidates all phishing elements corresponding to a phishing webpage, namely,\nURL, webpage source code, screenshot, and related webpage resources. This paper\nintroduces a resource collection tool designed to gather various resources\nassociated with a URL, such as CSS, Javascript, favicons, webpage images, and\nscreenshots. Our tool leverages PhishTank as the primary source for obtaining\nactive phishing URLs. Our tool fetches several additional webpage resources\ncompared to PyWebCopy Python library, which provides webpage content for a\ngiven URL. Additionally, we share a sample dataset generated using our tool\ncomprising 4,056 legitimate and 5,666 phishing URLs along with their associated\nresources. We also remark on the top correlated phishing features with their\nassociated class label found in our dataset. Our tool offers a comprehensive\nresource set that can aid researchers in developing effective phishing\ndetection approaches."}
{"id": "2509.09638", "categories": ["cs.CR", "cs.HC"], "pdf": "https://arxiv.org/pdf/2509.09638", "abs": "https://arxiv.org/abs/2509.09638", "authors": ["Amitabh Chakravorty", "Jess Kropczynski", "Nelly Elsayed"], "title": "CryptoGuard: An AI-Based Cryptojacking Detection Dashboard Prototype", "comment": null, "summary": "With the widespread adoption of cryptocurrencies, cryptojacking has become a\nsignificant security threat to crypto wallet users. This paper presents a\nfront-end prototype of an AI-powered security dashboard, namely, CryptoGuard.\nDeveloped through a user-centered design process, the prototype was constructed\nas a high-fidelity, click-through model from Figma mockups to simulate key user\ninteractions. It is designed to assist users in monitoring their login and\ntransaction activity, identifying any suspicious behavior, and enabling them to\ntake action directly within the wallet interface. The dashboard is designed for\na general audience, prioritizing an intuitive user experience for non-technical\nindividuals. Although its AI functionality is conceptual, the prototype\ndemonstrates features like visual alerts and reporting. This work is positioned\nexplicitly as a design concept, bridging cryptojacking detection research with\nhuman-centered interface design. This paper also demonstrates how usability\nheuristics can directly inform a tool's ability to support rapid and confident\ndecision-making under real-world threats. This paper argues that practical\nsecurity tools require not only robust backend functionality but also a\nuser-centric design that communicates risk and empowers users to take\nmeaningful action."}
