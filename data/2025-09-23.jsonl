{"id": "2509.16274", "categories": ["cs.CR", "cs.CY"], "pdf": "https://arxiv.org/pdf/2509.16274", "abs": "https://arxiv.org/abs/2509.16274", "authors": ["Uwe Serd√ºlt"], "title": "Reconnecting Citizens to Politics via Blockchain - Starting the Debate", "comment": "Published as Proceedings of Ongoing Research, Practitioners, Posters,\n  Workshops, and Projects of the International Conference EGOV-CeDEM-ePart 2019", "summary": "Elections are not the only but arguably one of the most important pillars for\nthe proper functioning of liberal democracies. Recent evidence across the globe\nshows that it is not straightforward to conduct them in a free and fair manner.\nOne constant concern is the role of money in politics, more specifically,\nelection campaign financing. Frequent scandals are proof of the difficulties\nencountered with current approaches to tackle the issue. Suggestions on how to\novercome the problem exist but seem difficult to implement. With the help of\nblockchain technology we might be able to make a step forward. A separate\ncrypto currency specifically designed to pay for costs of political campaigning\nand advertising could be introduced. Admittedly, at this stage, there are many\nopen questions. However, under the assumption that blockchain technology is\nhere to stay, it is an idea that deserves further exploration."}
{"id": "2509.16275", "categories": ["cs.CR", "cs.AI", "cs.SE"], "pdf": "https://arxiv.org/pdf/2509.16275", "abs": "https://arxiv.org/abs/2509.16275", "authors": ["Jugal Gajjar", "Kamalasankari Subramaniakuppusamy", "Relsy Puthal", "Kaustik Ranaware"], "title": "SecureFixAgent: A Hybrid LLM Agent for Automated Python Static Vulnerability Repair", "comment": "6 pages, 3 figures, 4 tables, 1 algorithm, accepted in the Robustness\n  and Security of Large Language Models (ROSE-LLM) special session at ICMLA\n  2025", "summary": "Modern software development pipelines face growing challenges in securing\nlarge codebases with extensive dependencies. Static analysis tools like Bandit\nare effective at vulnerability detection but suffer from high false positives\nand lack repair capabilities. Large Language Models (LLMs), in contrast, can\nsuggest fixes but often hallucinate changes and lack self-validation. We\npresent SecureFixAgent, a hybrid repair framework integrating Bandit with\nlightweight local LLMs (<8B parameters) in an iterative detect-repair-validate\nloop. To improve precision, we apply parameter-efficient LoRA-based fine-tuning\non a diverse, curated dataset spanning multiple Python project domains,\nmitigating dataset bias and reducing unnecessary edits. SecureFixAgent uses\nBandit for detection, the LLM for candidate fixes with explanations, and Bandit\nre-validation for verification, all executed locally to preserve privacy and\nreduce cloud reliance. Experiments show SecureFixAgent reduces false positives\nby 10.8% over static analysis, improves fix accuracy by 13.51%, and lowers\nfalse positives by 5.46% compared to pre-trained LLMs, typically converging\nwithin three iterations. Beyond metrics, developer studies rate explanation\nquality 4.5/5, highlighting its value for human trust and adoption. By\ncombining verifiable security improvements with transparent rationale in a\nresource-efficient local framework, SecureFixAgent advances trustworthy,\nautomated vulnerability remediation for modern pipelines."}
{"id": "2509.16292", "categories": ["cs.CR", "cs.IR"], "pdf": "https://arxiv.org/pdf/2509.16292", "abs": "https://arxiv.org/abs/2509.16292", "authors": ["Qian'ang Mao", "Jiaxin Wang", "Zhiqi Feng", "Yi Zhang", "Jiaqi Yan"], "title": "Decoding TRON: A Comprehensive Framework for Large-Scale Blockchain Data Extraction and Exploration", "comment": "written in early 2024", "summary": "Cryptocurrencies and Web3 applications based on blockchain technology have\nflourished in the blockchain research field. Unlike Bitcoin and Ethereum, due\nto its unique architectural designs in consensus mechanisms, resource\nmanagement, and throughput, TRON has developed a more distinctive ecosystem and\napplication scenarios centered around stablecoins. Although it is popular in\nareas like stablecoin payments and settlement, research on analyzing on-chain\ndata from the TRON blockchain is remarkably scarce. To fill this gap, this\npaper proposes a comprehensive data extraction and exploration framework for\nthe TRON blockchain. An innovative high-performance ETL system aims to\nefficiently extract raw on-chain data from TRON, including blocks,\ntransactions, smart contracts, and receipts, establishing a research dataset.\nAn in-depth analysis of the extracted dataset reveals insights into TRON's\nblock generation, transaction trends, the dominance of exchanges, the resource\ndelegation market, smart contract usage patterns, and the central role of the\nUSDT stablecoin. The prominence of gambling applications and potential illicit\nactivities related to USDT is emphasized. The paper discusses opportunities for\nfuture research leveraging this dataset, including analysis of delegate\nservices, gambling scenarios, stablecoin activities, and illicit transaction\ndetection. These contributions enhance blockchain data management capabilities\nand understanding of the rapidly evolving TRON ecosystem."}
{"id": "2509.16340", "categories": ["cs.CR", "cs.OS"], "pdf": "https://arxiv.org/pdf/2509.16340", "abs": "https://arxiv.org/abs/2509.16340", "authors": ["Mohammad Hossein Asghari", "Lianying Zhao"], "title": "To Unpack or Not to Unpack: Living with Packers to Enable Dynamic Analysis of Android Apps", "comment": null, "summary": "Android apps have become a valuable target for app modifiers and imitators\ndue to its popularity and being trusted with highly sensitive data. Packers, on\nthe other hand, protect apps from tampering with various anti-analysis\ntechniques embedded in the app. Meanwhile, packers also conceal certain\nbehavior potentially against the interest of the users, aside from being abused\nby malware for stealth. Security practitioners typically try to capture\nundesired behavior at runtime with hooking (e.g., Frida) or debugging\ntechniques, which are heavily affected by packers. Unpackers have been the\ncommunity's continuous effort to address this, but due to the emerging\ncommercial packers, our study shows that none of the unpackers remain\neffective, and they are unfit for this purpose as unpacked apps can no longer\nrun. We first perform a large-scale prevalence analysis of Android packers with\na real-world dataset of 12,341 apps, the first of its kind, to find out what\npercentage of Android apps are actually packed and to what extent dynamic\nanalysis is hindered. We then propose Purifire, an evasion engine to bypass\npackers' anti-analysis techniques and enable dynamic analysis on packed apps\nwithout unpacking them. Purifire is based on eBPF, a low-level kernel feature,\nwhich provides observability and invisibility to userspace apps to enforce\ndefined evasion rules while staying low-profile. Our evaluation shows that\nPurifire is able to bypass packers' anti-analysis checks and more importantly,\nfor previous research works suffering from packers, we observe a significant\nimprovement (e.g., a much higher number of detected items such as device\nfingerprints)."}
{"id": "2509.16352", "categories": ["cs.CR", "cs.AI"], "pdf": "https://arxiv.org/pdf/2509.16352", "abs": "https://arxiv.org/abs/2509.16352", "authors": ["Yunfan Yang", "Jiarong Xu", "Hongzhe Zhang", "Xiao Fang"], "title": "Secure Confidential Business Information When Sharing Machine Learning Models", "comment": null, "summary": "Model-sharing offers significant business value by enabling firms with\nwell-established Machine Learning (ML) models to monetize and share their\nmodels with others who lack the resources to develop ML models from scratch.\nHowever, concerns over data confidentiality remain a significant barrier to\nmodel-sharing adoption, as Confidential Property Inference (CPI) attacks can\nexploit shared ML models to uncover confidential properties of the model\nprovider's private model training data. Existing defenses often assume that CPI\nattacks are non-adaptive to the specific ML model they are targeting. This\nassumption overlooks a key characteristic of real-world adversaries: their\nresponsiveness, i.e., adversaries' ability to dynamically adjust their attack\nmodels based on the information of the target and its defenses. To overcome\nthis limitation, we propose a novel defense method that explicitly accounts for\nthe responsive nature of real-world adversaries via two methodological\ninnovations: a novel Responsive CPI attack and an attack-defense arms race\nframework. The former emulates the responsive behaviors of adversaries in the\nreal world, and the latter iteratively enhances both the target and attack\nmodels, ultimately producing a secure ML model that is robust against\nresponsive CPI attacks. Furthermore, we propose and integrate a novel\napproximate strategy into our defense, which addresses a critical computational\nbottleneck of defense methods and improves defense efficiency. Through\nextensive empirical evaluations across various realistic model-sharing\nscenarios, we demonstrate that our method outperforms existing defenses by more\neffectively defending against CPI attacks, preserving ML model utility, and\nreducing computational overhead."}
{"id": "2509.16389", "categories": ["cs.CR"], "pdf": "https://arxiv.org/pdf/2509.16389", "abs": "https://arxiv.org/abs/2509.16389", "authors": ["Tianrou Xia", "Kaiming Huang", "Dongyeon Yu", "Yuseok Jeon", "Jie Zhou", "Dinghao Wu", "Taegyu Kim"], "title": "LiteRSan: Lightweight Memory Safety Via Rust-specific Program Analysis and Selective Instrumentation", "comment": "14 pages (main text), 18 pages including references and appendix, 2\n  figures", "summary": "Rust is a memory-safe language, and its strong safety guarantees combined\nwith high performance have been attracting widespread adoption in systems\nprogramming and security-critical applications. However, Rust permits the use\nof unsafe code, which bypasses compiler-enforced safety checks and can\nintroduce memory vulnerabilities. A widely adopted approach for detecting\nmemory safety bugs in Rust is Address Sanitizer (ASan). Optimized versions,\nsuch as ERASan and RustSan, have been proposed to selectively apply security\nchecks in order to reduce performance overhead. However, these tools still\nincur significant performance and memory overhead and fail to detect many\nclasses of memory safety vulnerabilities due to the inherent limitations of\nASan. In this paper, we present LiteRSan, a novel memory safety sanitizer that\naddresses the limitations of prior approaches. By leveraging Rust's unique\nownership model, LiteRSan performs Rust-specific static analysis that is aware\nof pointer lifetimes to identify risky pointers. It then selectively\ninstruments risky pointers to enforce only the necessary spatial or temporal\nmemory safety checks. Consequently, LiteRSan introduces significantly lower\nruntime overhead (18.84% versus 152.05% and 183.50%) and negligible memory\noverhead (0.81% versus 739.27% and 861.98%) compared with existing ASan-based\nsanitizers while being capable of detecting memory safety bugs that prior\ntechniques miss."}
{"id": "2509.16390", "categories": ["cs.CR", "cs.DC", "cs.NI"], "pdf": "https://arxiv.org/pdf/2509.16390", "abs": "https://arxiv.org/abs/2509.16390", "authors": ["Mohamed Abdessamed Rezazi", "Mouhamed Amine Bouchiha", "Ahmed Mounsf Rafik Bendada", "Yacine Ghamri-Doudane"], "title": "B5GRoam: A Zero Trust Framework for Secure and Efficient On-Chain B5G Roaming", "comment": "6 pages, 2 figures, Accepted at GLOBECOM'25", "summary": "Roaming settlement in 5G and beyond networks demands secure, efficient, and\ntrustworthy mechanisms for billing reconciliation between mobile operators.\nWhile blockchain promises decentralization and auditability, existing solutions\nsuffer from critical limitations-namely, data privacy risks, assumptions of\nmutual trust, and scalability bottlenecks. To address these challenges, we\npresent B5GRoam, a novel on-chain and zero-trust framework for secure,\nprivacy-preserving, and scalable roaming settlements. B5GRoam introduces a\ncryptographically verifiable call detail record (CDR) submission protocol,\nenabling smart contracts to authenticate usage claims without exposing\nsensitive data. To preserve privacy, we integrate non-interactive\nzero-knowledge proofs (zkSNARKs) that allow on-chain verification of roaming\nactivity without revealing user or network details. To meet the high-throughput\ndemands of 5G environments, B5GRoam leverages Layer 2 zk-Rollups, significantly\nreducing gas costs while maintaining the security guarantees of Layer 1.\nExperimental results demonstrate a throughput of over 7,200 tx/s with strong\nprivacy and substantial cost savings. By eliminating intermediaries and\nenhancing verifiability, B5GRoam offers a practical and secure foundation for\ndecentralized roaming in future mobile networks."}
{"id": "2509.16418", "categories": ["cs.CR", "cs.AI", "cs.CV", "cs.SD", "eess.AS"], "pdf": "https://arxiv.org/pdf/2509.16418", "abs": "https://arxiv.org/abs/2509.16418", "authors": ["Petr Grinberg", "Eric Bezzam", "Paolo Prandoni", "Martin Vetterli"], "title": "LenslessMic: Audio Encryption and Authentication via Lensless Computational Imaging", "comment": "Submitted to ICASSP 2026", "summary": "With society's increasing reliance on digital data sharing, the protection of\nsensitive information has become critical. Encryption serves as one of the\nprivacy-preserving methods; however, its realization in the audio domain\npredominantly relies on signal processing or software methods embedded into\nhardware. In this paper, we introduce LenslessMic, a hybrid optical\nhardware-based encryption method that utilizes a lensless camera as a physical\nlayer of security applicable to multiple types of audio. We show that\nLenslessMic enables (1) robust authentication of audio recordings and (2)\nencryption strength that can rival the search space of 256-bit digital\nstandards, while maintaining high-quality signals and minimal loss of content\ninformation. The approach is validated with a low-cost Raspberry Pi prototype\nand is open-sourced together with datasets to facilitate research in the area."}
{"id": "2509.16489", "categories": ["cs.CR"], "pdf": "https://arxiv.org/pdf/2509.16489", "abs": "https://arxiv.org/abs/2509.16489", "authors": ["Minhaj Uddin Ahmad", "Akid Abrar", "Sagar Dasgupta", "Mizanur Rahman"], "title": "End-to-End Co-Simulation Testbed for Cybersecurity Research and Development in Intelligent Transportation Systems", "comment": null, "summary": "Intelligent Transportation Systems (ITS) have been widely deployed across\nmajor metropolitan regions worldwide to improve roadway safety, optimize\ntraffic flow, and reduce environmental impacts. These systems integrate\nadvanced sensors, communication networks, and data analytics to enable\nreal-time traffic monitoring, adaptive signal control, and predictive\nmaintenance. However, such integration significantly broadens the ITS attack\nsurface, exposing critical infrastructures to cyber threats that jeopardize\nsafety, data integrity, and operational resilience. Ensuring robust\ncybersecurity is therefore essential, yet comprehensive vulnerability\nassessments, threat modeling, and mitigation validations are often\ncost-prohibitive and time-intensive when applied to large-scale, heterogeneous\ntransportation systems. Simulation platforms offer a cost-effective and\nrepeatable means for cybersecurity evaluation, and the simulation platform\nshould encompass the full range of ITS dimensions - mobility, sensing,\nnetworking, and applications. This chapter discusses an integrated\nco-simulation testbed that links CARLA for 3D environment and sensor modeling,\nSUMO for microscopic traffic simulation and control, and OMNeT++ for V2X\ncommunication simulation. The co-simulation testbed enables end-to-end\nexperimentation, vulnerability identification, and mitigation benchmarking,\nproviding practical insights for developing secure, efficient, and resilient\nITS infrastructures. To illustrate its capabilities, the chapter incorporates a\ncase study on a C-V2X proactive safety alert system enhanced with post-quantum\ncryptography, highlighting the role of the testbed in advancing secure and\nresilient ITS infrastructures."}
{"id": "2509.16546", "categories": ["cs.CR", "cs.AI", "F.2.2, I.2.7"], "pdf": "https://arxiv.org/pdf/2509.16546", "abs": "https://arxiv.org/abs/2509.16546", "authors": ["Ashley Kurian", "Aydin Aysu"], "title": "Train to Defend: First Defense Against Cryptanalytic Neural Network Parameter Extraction Attacks", "comment": "18 pages, 3 Figures", "summary": "Neural networks are valuable intellectual property due to the significant\ncomputational cost, expert labor, and proprietary data involved in their\ndevelopment. Consequently, protecting their parameters is critical not only for\nmaintaining a competitive advantage but also for enhancing the model's security\nand privacy. Prior works have demonstrated the growing capability of\ncryptanalytic attacks to scale to deeper models. In this paper, we present the\nfirst defense mechanism against cryptanalytic parameter extraction attacks. Our\nkey insight is to eliminate the neuron uniqueness necessary for these attacks\nto succeed. We achieve this by a novel, extraction-aware training method.\nSpecifically, we augment the standard loss function with an additional\nregularization term that minimizes the distance between neuron weights within a\nlayer. Therefore, the proposed defense has zero area-delay overhead during\ninference. We evaluate the effectiveness of our approach in mitigating\nextraction attacks while analyzing the model accuracy across different\narchitectures and datasets. When re-trained with the same model architecture,\nthe results show that our defense incurs a marginal accuracy change of less\nthan 1% with the modified loss function. Moreover, we present a theoretical\nframework to quantify the success probability of the attack. When tested\ncomprehensively with prior attack settings, our defense demonstrated empirical\nsuccess for sustained periods of extraction, whereas unprotected networks are\nextracted between 14 minutes to 4 hours."}
{"id": "2509.16558", "categories": ["cs.CR"], "pdf": "https://arxiv.org/pdf/2509.16558", "abs": "https://arxiv.org/abs/2509.16558", "authors": ["Mingjian Duan", "Ming Xu", "Shenghao Zhang", "Jiaheng Zhang", "Weili Han"], "title": "MoPE: A Mixture of Password Experts for Improving Password Guessing", "comment": null, "summary": "Textual passwords remain a predominant authentication mechanism in web\nsecurity. To evaluate their strength, existing research has proposed several\ndata-driven models across various scenarios. However, these models generally\ntreat passwords uniformly, neglecting the structural differences among\npasswords. This typically results in biased training that favors frequent\npassword structural patterns. To mitigate the biased training, we argue that\npasswords, as a type of complex short textual data, should be processed in a\nstructure-aware manner by identifying their structural patterns and routing\nthem to specialized models accordingly. In this paper, we propose MoPE, a\nMixture of Password Experts framework, specifically designed to leverage the\nstructural patterns in passwords to improveguessing performance. Motivated by\nthe observation that passwords with similar structural patterns (e.g.,\nfixed-length numeric strings) tend to cluster in high-density regions within\nthe latent space, our MoPE introduces: (1) a novel structure-based method for\ngenerating specialized expert models; (2) a lightweight gate method to select\nappropriate expert models to output reliable guesses, better aligned with the\nhigh computational frequency of password guessing tasks. Our evaluation shows\nthat MoPE significantly outperforms existing state-of-the-art baselines in both\noffline and online guessing scenarios, achieving up to 38.80% and 9.27%\nimprovement in cracking rate, respectively, showcasing that MoPE can\neffectively exploit the capabilities of data-driven models for password\nguessing. Additionally, we implement a real-time Password Strength Meter (PSM)\nbased on offline MoPE, assisting users in choosing stronger passwords more\nprecisely with millisecond-level response latency."}
{"id": "2509.16581", "categories": ["cs.CR", "cs.CE"], "pdf": "https://arxiv.org/pdf/2509.16581", "abs": "https://arxiv.org/abs/2509.16581", "authors": ["Mohsen Ahmadvand", "Pedro Souto"], "title": "Towards Cost-Effective ZK-Rollups: Modeling and Optimization of Proving Infrastructure", "comment": null, "summary": "Zero-knowledge rollups rely on provers to generate multi-step state\ntransition proofs under strict finality and availability constraints. These\nsteps require expensive hardware (e.g., GPUs), and finality is reached only\nonce all stages complete and results are posted on-chain. As rollups scale,\nstaying economically viable becomes increasingly difficult due to rising\nthroughput, fast finality demands, volatile gas prices, and dynamic resource\nneeds. We base our study on Halo2-based proving systems and identify\ntransactions per second (TPS), average gas usage, and finality time as key cost\ndrivers. To address this, we propose a parametric cost model that captures\nrollup-specific constraints and ensures provers can keep up with incoming\ntransaction load. We formulate this model as a constraint system and solve it\nusing the Z3 SMT solver to find cost-optimal configurations. To validate our\napproach, we implement a simulator that detects lag and estimates operational\ncosts. Our method shows a potential cost reduction of up to 70\\%."}
{"id": "2509.16593", "categories": ["cs.CR", "cs.SY", "eess.SY"], "pdf": "https://arxiv.org/pdf/2509.16593", "abs": "https://arxiv.org/abs/2509.16593", "authors": ["Avi Shaked"], "title": "Reproducing a Security Risk Assessment Using Computer Aided Design", "comment": null, "summary": "Security risk assessment is essential in establishing the trustworthiness and\nreliability of modern systems. While various security risk assessment\napproaches exist, prevalent applications are \"pen and paper\" implementations\nthat -- even if performed digitally using computers -- remain prone to\nauthoring mistakes and inconsistencies. Computer-aided design approaches can\ntransform security risk assessments into more rigorous and sustainable efforts.\nThis is of value to both industrial practitioners and researchers, who practice\nsecurity risk assessments to reflect on systems' designs and to contribute to\nthe discipline's state-of-the-art. In this article, we report the application\nof a model-based security design tool to reproduce a previously reported\nsecurity assessment. The main contributions are: 1) an independent attempt to\nreproduce a refereed article describing a real security risk assessment of a\nsystem; 2) comparison of a new computer-aided application with a previous\nnon-computer-aided application, based on a published, real-world case study; 3)\na showcase for the potential advantages -- for both practitioners and\nresearchers -- of using computer-aided design approaches to analyze reports and\nto assess systems."}
{"id": "2509.16620", "categories": ["cs.CR"], "pdf": "https://arxiv.org/pdf/2509.16620", "abs": "https://arxiv.org/abs/2509.16620", "authors": ["Yi Chen", "Xiaoyang Dong", "Ruijie Ma", "Yantian Shen", "Anyu Wang", "Hongbo Yu", "Xiaoyun Wang"], "title": "Delving into Cryptanalytic Extraction of PReLU Neural Networks", "comment": "Accepted by ASIACRYPT 2025", "summary": "The machine learning problem of model extraction was first introduced in 1991\nand gained prominence as a cryptanalytic challenge starting with Crypto 2020.\nFor over three decades, research in this field has primarily focused on\nReLU-based neural networks. In this work, we take the first step towards the\ncryptanalytic extraction of PReLU neural networks, which employ more complex\nnonlinear activation functions than their ReLU counterparts. We propose a raw\noutput-based parameter recovery attack for PReLU networks and extend it to more\nrestrictive scenarios where only the top-m probability scores are accessible.\nOur attacks are rigorously evaluated through end-to-end experiments on diverse\nPReLU neural networks, including models trained on the MNIST dataset. To the\nbest of our knowledge, this is the first practical demonstration of PReLU\nneural network extraction across three distinct attack scenarios."}
{"id": "2509.16671", "categories": ["cs.CR"], "pdf": "https://arxiv.org/pdf/2509.16671", "abs": "https://arxiv.org/abs/2509.16671", "authors": ["Ekin B√∂ke", "Simon Torka"], "title": "\"Digital Camouflage\": The LLVM Challenge in LLM-Based Malware Detection", "comment": null, "summary": "Large Language Models (LLMs) have emerged as promising tools for malware\ndetection by analyzing code semantics, identifying vulnerabilities, and\nadapting to evolving threats. However, their reliability under adversarial\ncompiler-level obfuscation is yet to be discovered. In this study, we\nempirically evaluate the robustness of three state-of-the-art LLMs: ChatGPT-4o,\nGemini Flash 2.5, and Claude Sonnet 4 against compiler-level obfuscation\ntechniques implemented via the LLVM infrastructure. These include control flow\nflattening, bogus control flow injection, instruction substitution, and split\nbasic blocks, which are widely used to evade detection while preserving\nmalicious behavior. We perform a structured evaluation on 40~C functions (20\nvulnerable, 20 secure) sourced from the Devign dataset and obfuscated using\nLLVM passes. Our results show that these models often fail to correctly\nclassify obfuscated code, with precision, recall, and F1-score dropping\nsignificantly after transformation. This reveals a critical limitation: LLMs,\ndespite their language understanding capabilities, can be easily misled by\ncompiler-based obfuscation strategies. To promote reproducibility, we release\nall evaluation scripts, prompts, and obfuscated code samples in a public\nrepository. We also discuss the implications of these findings for adversarial\nthreat modeling, and outline future directions such as software watermarking,\ncompiler-aware defenses, and obfuscation-resilient model design."}
{"id": "2509.16682", "categories": ["cs.CR", "cs.AI"], "pdf": "https://arxiv.org/pdf/2509.16682", "abs": "https://arxiv.org/abs/2509.16682", "authors": ["Javier Jim√©nez-Rom√°n", "Florina Almenares-Mendoza", "Alfonso S√°nchez-Maci√°n"], "title": "Design and Development of an Intelligent LLM-based LDAP Honeypot", "comment": null, "summary": "Cybersecurity threats continue to increase, with a growing number of\npreviously unknown attacks each year targeting both large corporations and\nsmaller entities. This scenario demands the implementation of advanced security\nmeasures, not only to mitigate damage but also to anticipate emerging attack\ntrends. In this context, deception tools have become a key strategy, enabling\nthe detection, deterrence, and deception of potential attackers while\nfacilitating the collection of information about their tactics and methods.\nAmong these tools, honeypots have proven their value, although they have\ntraditionally been limited by rigidity and configuration complexity, hindering\ntheir adaptability to dynamic scenarios. The rise of artificial intelligence,\nand particularly general-purpose Large Language Models (LLMs), is driving the\ndevelopment of new deception solutions capable of offering greater adaptability\nand ease of use. This work proposes the design and implementation of an\nLLM-based honeypot to simulate an LDAP server, a critical protocol present in\nmost organizations due to its central role in identity and access management.\nThe proposed solution aims to provide a flexible and realistic tool capable of\nconvincingly interacting with attackers, thereby contributing to early\ndetection and threat analysis while enhancing the defensive capabilities of\ninfrastructures against intrusions targeting this service."}
{"id": "2509.16749", "categories": ["cs.CR"], "pdf": "https://arxiv.org/pdf/2509.16749", "abs": "https://arxiv.org/abs/2509.16749", "authors": ["Anna Bertiger", "Bobby Filar", "Aryan Luthra", "Stefano Meschiari", "Aiden Mitchell", "Sam Scholten", "Vivek Sharath"], "title": "Evaluating LLM Generated Detection Rules in Cybersecurity", "comment": "Preprint of a paper accepted at the Conference on Applied Machine\n  Learning in Information Security (CAMLIS 2025). 11 pages, 3 figures, 4 tables", "summary": "LLMs are increasingly pervasive in the security environment, with limited\nmeasures of their effectiveness, which limits trust and usefulness to security\npractitioners. Here, we present an open-source evaluation framework and\nbenchmark metrics for evaluating LLM-generated cybersecurity rules. The\nbenchmark employs a holdout set-based methodology to measure the effectiveness\nof LLM-generated security rules in comparison to a human-generated corpus of\nrules. It provides three key metrics inspired by the way experts evaluate\nsecurity rules, offering a realistic, multifaceted evaluation of the\neffectiveness of an LLM-based security rule generator. This methodology is\nillustrated using rules from Sublime Security's detection team and those\nwritten by Sublime Security's Automated Detection Engineer (ADE), with a\nthorough analysis of ADE's skills presented in the results section."}
{"id": "2509.16861", "categories": ["cs.CR", "cs.AI", "cs.SE"], "pdf": "https://arxiv.org/pdf/2509.16861", "abs": "https://arxiv.org/abs/2509.16861", "authors": ["Rui Yang", "Michael Fu", "Chakkrit Tantithamthavorn", "Chetan Arora", "Gunel Gulmammadova", "Joey Chua"], "title": "AdaptiveGuard: Towards Adaptive Runtime Safety for LLM-Powered Software", "comment": "Accepted to the ASE 2025 International Conference on Automated\n  Software Engineering, Industry Showcase Track", "summary": "Guardrails are critical for the safe deployment of Large Language Models\n(LLMs)-powered software. Unlike traditional rule-based systems with limited,\npredefined input-output spaces that inherently constrain unsafe behavior, LLMs\nenable open-ended, intelligent interactions--opening the door to jailbreak\nattacks through user inputs. Guardrails serve as a protective layer, filtering\nunsafe prompts before they reach the LLM. However, prior research shows that\njailbreak attacks can still succeed over 70% of the time, even against advanced\nmodels like GPT-4o. While guardrails such as LlamaGuard report up to 95%\naccuracy, our preliminary analysis shows their performance can drop sharply--to\nas low as 12%--when confronted with unseen attacks. This highlights a growing\nsoftware engineering challenge: how to build a post-deployment guardrail that\nadapts dynamically to emerging threats? To address this, we propose\nAdaptiveGuard, an adaptive guardrail that detects novel jailbreak attacks as\nout-of-distribution (OOD) inputs and learns to defend against them through a\ncontinual learning framework. Through empirical evaluation, AdaptiveGuard\nachieves 96% OOD detection accuracy, adapts to new attacks in just two update\nsteps, and retains over 85% F1-score on in-distribution data post-adaptation,\noutperforming other baselines. These results demonstrate that AdaptiveGuard is\na guardrail capable of evolving in response to emerging jailbreak strategies\npost deployment. We release our AdaptiveGuard and studied datasets at\nhttps://github.com/awsm-research/AdaptiveGuard to support further research."}
{"id": "2509.16899", "categories": ["cs.CR"], "pdf": "https://arxiv.org/pdf/2509.16899", "abs": "https://arxiv.org/abs/2509.16899", "authors": ["Md Wasiul Haque", "Md Erfan", "Sagar Dasgupta", "Md Rayhanur Rahman", "Mizanur Rahman"], "title": "Security Vulnerabilities in Software Supply Chain for Autonomous Vehicles", "comment": "16 pages, 9 figures, 10 tables", "summary": "The interest in autonomous vehicles (AVs) for critical missions, including\ntransportation, rescue, surveillance, reconnaissance, and mapping, is growing\nrapidly due to their significant safety and mobility benefits. AVs consist of\ncomplex software systems that leverage artificial intelligence (AI), sensor\nfusion algorithms, and real-time data processing. Additionally, AVs are\nbecoming increasingly reliant on open-source software supply chains, such as\nopen-source packages, third-party software components, AI models, and\nthird-party datasets. Software security best practices in the automotive sector\nare often an afterthought for developers. Thus, significant cybersecurity risks\nexist in the software supply chain of AVs, particularly when secure software\ndevelopment practices are not rigorously implemented. For example, Upstream's\n2024 Automotive Cybersecurity Report states that 49.5% of cyberattacks in the\nautomotive sector are related to exploiting security vulnerabilities in\nsoftware systems. In this chapter, we analyze security vulnerabilities in\nopen-source software components in AVs. We utilize static analyzers on popular\nopen-source AV software, such as Autoware, Apollo, and openpilot. Specifically,\nthis chapter covers: (1) prevalent software security vulnerabilities of AVs;\nand (2) a comparison of static analyzer outputs for different open-source AV\nrepositories. The goal is to inform researchers, practitioners, and\npolicymakers about the existing security flaws in the commonplace open-source\nsoftware ecosystem in the AV domain. The findings would emphasize the necessity\nof security best practices earlier in the software development lifecycle to\nreduce cybersecurity risks, thereby ensuring system reliability, safeguarding\nuser data, and maintaining public trust in an increasingly automated world."}
{"id": "2509.16950", "categories": ["cs.CR"], "pdf": "https://arxiv.org/pdf/2509.16950", "abs": "https://arxiv.org/abs/2509.16950", "authors": ["Xuan Chen", "Shiwei Feng", "Zikang Xiong", "Shengwei An", "Yunshu Mao", "Lu Yan", "Guanhong Tao", "Wenbo Guo", "Xiangyu Zhang"], "title": "Temporal Logic-Based Multi-Vehicle Backdoor Attacks against Offline RL Agents in End-to-end Autonomous Driving", "comment": null, "summary": "Assessing the safety of autonomous driving (AD) systems against security\nthreats, particularly backdoor attacks, is a stepping stone for real-world\ndeployment. However, existing works mainly focus on pixel-level triggers that\nare impractical to deploy in the real world. We address this gap by introducing\na novel backdoor attack against the end-to-end AD systems that leverage one or\nmore other vehicles' trajectories as triggers. To generate precise trigger\ntrajectories, we first use temporal logic (TL) specifications to define the\nbehaviors of attacker vehicles. Configurable behavior models are then used to\ngenerate these trajectories, which are quantitatively evaluated and iteratively\nrefined based on the TL specifications. We further develop a negative training\nstrategy by incorporating patch trajectories that are similar to triggers but\nare designated not to activate the backdoor. It enhances the stealthiness of\nthe attack and refines the system's responses to trigger scenarios. Through\nextensive experiments on 5 offline reinforcement learning (RL) driving agents\nwith 6 trigger patterns and target action combinations, we demonstrate the\nflexibility and effectiveness of our proposed attack, showing the\nunder-exploration of existing end-to-end AD systems' vulnerabilities to such\ntrajectory-based backdoor attacks."}
{"id": "2509.16987", "categories": ["cs.CR"], "pdf": "https://arxiv.org/pdf/2509.16987", "abs": "https://arxiv.org/abs/2509.16987", "authors": ["Vyron Kampourakis", "Christos Smiliotopoulos", "Vasileios Gkioulos", "Sokratis Katsikas"], "title": "In Numeris Veritas: An Empirical Measurement of Wi-Fi Integration in Industry", "comment": null, "summary": "Traditional air gaps in industrial systems are disappearing as IT\ntechnologies permeate the OT domain, accelerating the integration of wireless\nsolutions like Wi-Fi. Next-generation Wi-Fi standards (IEEE 802.11ax/be) meet\nperformance demands for industrial use cases, yet their introduction raises\nsignificant security concerns. A critical knowledge gap exists regarding the\nempirical prevalence and security configuration of Wi-Fi in real-world\nindustrial settings. This work addresses this by mining the global crowdsourced\nWiGLE database to provide a data-driven understanding. We create the first\npublicly available dataset of 1,087 high-confidence industrial Wi-Fi networks,\nexamining key attributes such as SSID patterns, encryption methods, vendor\ntypes, and global distribution. Our findings reveal a growing adoption of Wi-Fi\nacross industrial sectors but underscore alarming security deficiencies,\nincluding the continued use of weak or outdated security configurations that\ndirectly expose critical infrastructure. This research serves as a pivotal\nreference point, offering both a unique dataset and practical insights to guide\nfuture investigations into wireless security within industrial environments."}
{"id": "2509.17048", "categories": ["cs.CR"], "pdf": "https://arxiv.org/pdf/2509.17048", "abs": "https://arxiv.org/abs/2509.17048", "authors": ["Huifang Yu", "Jiaxing Jie", "Lei Li"], "title": "Electronic Reporting Using SM2-Based Ring Signcryption", "comment": null, "summary": "Electronic whistleblowing systems are widely used due to their efficiency and\nconvenience. The key to designing such systems lies in protecting the identity\nprivacy of whistleblowers, preventing malicious whistleblowing, and ensuring\nthe confidentiality of whistleblowing information. To address these issues, a\nSM2 traceable ring signcryption scheme for electronic voting is proposed. This\nscheme combines the SM2 elliptic curve public key cryptography algorithm with\nthe ring signature algorithm, enhancing the overall efficiency of the scheme\nwhile ensuring the autonomy and controllability of the core cryptographic\nalgorithms. Security analysis demonstrates that the proposed scheme satisfies\nconfidentiality, unforgeability, traceability, linkability, and deniability.\nEfficiency analysis shows that, compared to existing ring signature schemes,\nthe proposed scheme exhibits significant efficiency advantages during the\nsignature phase. The electronic whistleblowing system designed using the\nproposed scheme can track malicious whistleblowers while protecting user\nidentity privacy, and ensures that the content of whistleblowing remains\nunknown to third parties."}
{"id": "2509.17070", "categories": ["cs.CR", "cs.CL", "cs.LG"], "pdf": "https://arxiv.org/pdf/2509.17070", "abs": "https://arxiv.org/abs/2509.17070", "authors": ["Mayukh Borana", "Junyi Liang", "Sai Sathiesh Rajan", "Sudipta Chattopadhyay"], "title": "Localizing Malicious Outputs from CodeLLM", "comment": "10 pages, 2 figures, 6 tables, Accepted at EMNLP 2025 Findings", "summary": "We introduce FreqRank, a mutation-based defense to localize malicious\ncomponents in LLM outputs and their corresponding backdoor triggers. FreqRank\nassumes that the malicious sub-string(s) consistently appear in outputs for\ntriggered inputs and uses a frequency-based ranking system to identify them.\nOur ranking system then leverages this knowledge to localize the backdoor\ntriggers present in the inputs. We create nine malicious models through\nfine-tuning or custom instructions for three downstream tasks, namely, code\ncompletion (CC), code generation (CG), and code summarization (CS), and show\nthat they have an average attack success rate (ASR) of 86.6%. Furthermore,\nFreqRank's ranking system highlights the malicious outputs as one of the top\nfive suggestions in 98% of cases. We also demonstrate that FreqRank's\neffectiveness scales as the number of mutants increases and show that FreqRank\nis capable of localizing the backdoor trigger effectively even with a limited\nnumber of triggered samples. Finally, we show that our approach is 35-50% more\neffective than other defense methods."}
{"id": "2509.17126", "categories": ["cs.CR"], "pdf": "https://arxiv.org/pdf/2509.17126", "abs": "https://arxiv.org/abs/2509.17126", "authors": ["Stefanos Chaliasos", "Conner Swann", "Sina Pilehchiha", "Nicolas Mohnblatt", "Benjamin Livshits", "Assimakis Kattis"], "title": "Unaligned Incentives: Pricing Attacks Against Blockchain Rollups", "comment": null, "summary": "Rollups have become the de facto scalability solution for Ethereum, securing\nmore than $55B in assets. They achieve scale by executing transactions on a\nLayer 2 ledger, while periodically posting data and finalizing state on the\nLayer 1, either optimistically or via validity proofs. Their fees must\nsimultaneously reflect the pricing of three resources: L2 costs (e.g.,\nexecution), L1 DA, and underlying L1 gas costs for batch settlement and proof\nverification. In this work, we identify critical mis-pricings in existing\nrollup transaction fee mechanisms (TFMs) that allow for two powerful attacks.\nFirstly, an adversary can saturate the L2's DA batch capacity with\ncompute-light data-heavy transactions, forcing low-gas transaction batches that\nenable both L2 DoS attacks, and finality-delay attacks. Secondly, by crafting\nprover killer transactions that maximize proving cycles relative to the gas\ncharges, an adversary can effectively stall proof generation, delaying finality\nby hours and inflicting prover-side economic losses to the rollup at a minimal\ncost.\n  We analyze the above attack vectors across the major Ethereum rollups,\nquantifying adversarial costs and protocol losses. We find that the first\nattack enables periodic DoS on rollups, lasting up to 30 minutes, at a cost\nbelow 2 ETH for most rollups. Moreover, we identify three rollups that are\nexposed to indefinite DoS at a cost of approximately 0.8 to 2.7 ETH per hour.\nThe attack can be further modified to increase finalization delays by a factor\nof about 1.45x to 2.73x, compared to direct L1 blob-stuffing, depending on the\nrollup's parameters. Furthermore, we find that the prover killer attack induces\na finalization latency increase of about 94x. Finally, we propose comprehensive\nmitigations to prevent these attacks and suggest how some practical uses of\nmulti-dimensional rollup TFMs can rectify the identified mis-pricing attacks."}
{"id": "2509.17185", "categories": ["cs.CR"], "pdf": "https://arxiv.org/pdf/2509.17185", "abs": "https://arxiv.org/abs/2509.17185", "authors": ["Bence So√≥ki-T√≥th", "Istv√°n Andr√°s Seres", "Kamilla Kara", "√Åbel Nagy", "Bal√°zs Pej√≥", "Gergely Bicz√≥k"], "title": "Bribers, Bribers on The Chain, Is Resisting All in Vain? Trustless Consensus Manipulation Through Bribing Contracts", "comment": "pre-print", "summary": "The long-term success of cryptocurrencies largely depends on the incentive\ncompatibility provided to the validators. Bribery attacks, facilitated\ntrustlessly via smart contracts, threaten this foundation. This work\nintroduces, implements, and evaluates three novel and efficient bribery\ncontracts targeting Ethereum validators. The first bribery contract enables a\nbriber to fork the blockchain by buying votes on their proposed blocks. The\nsecond contract incentivizes validators to voluntarily exit the consensus\nprotocol, thus increasing the adversary's relative staking power. The third\ncontract builds a trustless bribery market that enables the briber to auction\noff their manipulative power over the RANDAO, Ethereum's distributed randomness\nbeacon. Finally, we provide an initial game-theoretical analysis of one of the\ndescribed bribery markets."}
{"id": "2509.17253", "categories": ["cs.CR"], "pdf": "https://arxiv.org/pdf/2509.17253", "abs": "https://arxiv.org/abs/2509.17253", "authors": ["Selma Yahia", "Ildi Alla", "Girija Bangalore Mohan", "Daniel Rau", "Mridula Singh", "Valeria Loscri"], "title": "Seeing is Deceiving: Mirror-Based LiDAR Spoofing for Autonomous Vehicle Deception", "comment": null, "summary": "Autonomous vehicles (AVs) rely heavily on LiDAR sensors for accurate 3D\nperception. We show a novel class of low-cost, passive LiDAR spoofing attacks\nthat exploit mirror-like surfaces to inject or remove objects from an AV's\nperception. Using planar mirrors to redirect LiDAR beams, these attacks require\nno electronics or custom fabrication and can be deployed in real settings. We\ndefine two adversarial goals: Object Addition Attacks (OAA), which create\nphantom obstacles, and Object Removal Attacks (ORA), which conceal real\nhazards. We develop geometric optics models, validate them with controlled\noutdoor experiments using a commercial LiDAR and an Autoware-equipped vehicle,\nand implement a CARLA-based simulation for scalable testing. Experiments show\nmirror attacks corrupt occupancy grids, induce false detections, and trigger\nunsafe planning and control behaviors. We discuss potential defenses (thermal\nsensing, multi-sensor fusion, light-fingerprinting) and their limitations."}
{"id": "2509.17263", "categories": ["cs.CR"], "pdf": "https://arxiv.org/pdf/2509.17263", "abs": "https://arxiv.org/abs/2509.17263", "authors": ["Colman McGuan", "Aadithyan V. Raghavan", "Komala M. Mandapati", "Chansu Yu", "Brian E. Ray", "Debbie K. Jackson", "Sathish Kumar"], "title": "Bridging Cybersecurity Practice and Law: a Hands-on, Scenario-Based Curriculum Using the NICE Framework to Foster Skill Development", "comment": null, "summary": "In an increasingly interconnected world, cybersecurity professionals play a\npivotal role in safeguarding organizations from cyber threats. To secure their\ncyberspace, organizations are forced to adopt a cybersecurity framework such as\nthe NIST National Initiative for Cybersecurity Education Workforce Framework\nfor Cybersecurity (NICE Framework). Although these frameworks are a good\nstarting point for businesses and offer critical information to identify,\nprevent, and respond to cyber incidents, they can be difficult to navigate and\nimplement, particularly for small-medium businesses (SMB). To help overcome\nthis issue, this paper identifies the most frequent attack vectors to SMBs\n(Objective 1) and proposes a practical model of both technical and\nnon-technical tasks, knowledge, skills, abilities (TKSA) from the NICE\nFramework for those attacks (Objective 2). The research develops a\nscenario-based curriculum. By immersing learners in realistic cyber threat\nscenarios, their practical understanding and preparedness in responding to\ncybersecurity incidents is enhanced (Objective 3). Finally, this work\nintegrates practical experience and real-life skill development into the\ncurriculum (Objective 4). SMBs can use the model as a guide to evaluate, equip\ntheir existing workforce, or assist in hiring new employees. In addition,\neducational institutions can use the model to develop scenario-based learning\nmodules to adequately equip the emerging cybersecurity workforce for SMBs.\nTrainees will have the opportunity to practice both technical and legal issues\nin a simulated environment, thereby strengthening their ability to identify,\nmitigate, and respond to cyber threats effectively."}
{"id": "2509.17266", "categories": ["cs.CR", "cs.IT", "cs.SY", "eess.SY", "math.IT"], "pdf": "https://arxiv.org/pdf/2509.17266", "abs": "https://arxiv.org/abs/2509.17266", "authors": ["Farhad Farokhi"], "title": "Privacy-Preserving State Estimation with Crowd Sensors: An Information-Theoretic Respective", "comment": "Accepted for presentation at the 17th IEEE International Workshop on\n  Information Forensics and Security (WIFS2025)", "summary": "Privacy-preserving state estimation for linear time-invariant dynamical\nsystems with crowd sensors is considered. At any time step, the estimator has\naccess to measurements from a randomly selected sensor from a pool of sensors\nwith pre-specified models and noise profiles. A Luenberger-like observer is\nused to fuse the measurements with the underlying model of the system to\nrecursively generate the state estimates. An additive privacy-preserving noise\nis used to constrain information leakage. Information leakage is measured via\nmutual information between the identity of the sensors and the state estimate\nconditioned on the actual state of the system. This captures an omnipotent\nadversary that not only can access state estimates but can also gather direct\nhigh-quality state measurements. Any prescribed level of information leakage is\nshown to be achievable by appropriately selecting the variance of the\nprivacy-preserving noise. Therefore, privacy-utility trade-off can be\nfine-tuned."}
{"id": "2509.17302", "categories": ["cs.CR"], "pdf": "https://arxiv.org/pdf/2509.17302", "abs": "https://arxiv.org/abs/2509.17302", "authors": ["Duoxun Tang", "Xinhang Jiang", "Jiajun Niu"], "title": "TextCrafter: Optimization-Calibrated Noise for Defending Against Text Embedding Inversion", "comment": null, "summary": "Text embedding inversion attacks reconstruct original sentences from latent\nrepresentations, posing severe privacy threats in collaborative inference and\nedge computing. We propose TextCrafter, an optimization-based adversarial\nperturbation mechanism that combines RL learned, geometry aware noise injection\northogonal to user embeddings with cluster priors and PII signal guidance to\nsuppress inversion while preserving task utility. Unlike prior defenses either\nnon learnable or agnostic to perturbation direction, TextCrafter provides a\ndirectional protective policy that balances privacy and utility. Under strong\nprivacy setting, TextCrafter maintains 70 percentage classification accuracy on\nfour datasets and consistently outperforms Gaussian/LDP baselines across lower\nprivacy budgets, demonstrating a superior privacy utility trade off."}
{"id": "2509.17371", "categories": ["cs.CR", "cs.LG"], "pdf": "https://arxiv.org/pdf/2509.17371", "abs": "https://arxiv.org/abs/2509.17371", "authors": ["Haotian Xu", "Qingsong Peng", "Jie Shi", "Huadi Zheng", "Yu Li", "Cheng Zhuo"], "title": "SilentStriker:Toward Stealthy Bit-Flip Attacks on Large Language Models", "comment": null, "summary": "The rapid adoption of large language models (LLMs) in critical domains has\nspurred extensive research into their security issues. While input manipulation\nattacks (e.g., prompt injection) have been well studied, Bit-Flip Attacks\n(BFAs) -- which exploit hardware vulnerabilities to corrupt model parameters\nand cause severe performance degradation -- have received far less attention.\nExisting BFA methods suffer from key limitations: they fail to balance\nperformance degradation and output naturalness, making them prone to discovery.\nIn this paper, we introduce SilentStriker, the first stealthy bit-flip attack\nagainst LLMs that effectively degrades task performance while maintaining\noutput naturalness. Our core contribution lies in addressing the challenge of\ndesigning effective loss functions for LLMs with variable output length and the\nvast output space. Unlike prior approaches that rely on output perplexity for\nattack loss formulation, which inevitably degrade output naturalness, we\nreformulate the attack objective by leveraging key output tokens as targets for\nsuppression, enabling effective joint optimization of attack effectiveness and\nstealthiness. Additionally, we employ an iterative, progressive search strategy\nto maximize attack efficacy. Experiments show that SilentStriker significantly\noutperforms existing baselines, achieving successful attacks without\ncompromising the naturalness of generated text."}
{"id": "2509.17409", "categories": ["cs.CR"], "pdf": "https://arxiv.org/pdf/2509.17409", "abs": "https://arxiv.org/abs/2509.17409", "authors": ["Yao Wu", "Ziye Jia", "Qihui Wu", "Yian Zhu"], "title": "A Lightweight Authentication and Key Agreement Protocol Design for FANET", "comment": null, "summary": "The advancement of low-altitude intelligent networks enables unmanned aerial\nvehicle (UAV) interconnection via flying ad-hoc networks (FANETs), offering\nflexibility and decentralized coordination. However, resource constraints,\ndynamic topologies, and UAV operations in open environments present significant\nsecurity and communication challenges. Existing multi-factor and public-key\ncryptography protocols are vulnerable due to their reliance on stored sensitive\ninformation, increasing the risk of exposure and compromise. This paper\nproposes a lightweight authentication and key agreement protocol for FANETs,\nintegrating physical unclonable functions with dynamic credential management\nand lightweight cryptographic primitives. The protocol reduces computational\nand communication overhead while enhancing security. Security analysis confirms\nits resilience against various attacks, and comparative evaluations demonstrate\nits superiority in security, communication efficiency, and computational cost."}
{"id": "2509.17416", "categories": ["cs.CR"], "pdf": "https://arxiv.org/pdf/2509.17416", "abs": "https://arxiv.org/abs/2509.17416", "authors": ["Jianbin Ji", "Dawen Xu", "Li Dong", "Lin Yang", "Songhan He"], "title": "DINVMark: A Deep Invertible Network for Video Watermarking", "comment": "Accepted by IEEE Transaction on Multimedia (2025)", "summary": "With the wide spread of video, video watermarking has become increasingly\ncrucial for copyright protection and content authentication. However, video\nwatermarking still faces numerous challenges. For example, existing methods\ntypically have shortcomings in terms of watermarking capacity and robustness,\nand there is a lack of specialized noise layer for High Efficiency Video\nCoding(HEVC) compression. To address these issues, this paper introduces a Deep\nInvertible Network for Video watermarking (DINVMark) and designs a noise layer\nto simulate HEVC compression. This approach not only in creases watermarking\ncapacity but also enhances robustness. DINVMark employs an Invertible Neural\nNetwork (INN), where the encoder and decoder share the same network structure\nfor both watermark embedding and extraction. This shared architecture ensures\nclose coupling between the encoder and decoder, thereby improving the accuracy\nof the watermark extraction process. Experimental results demonstrate that the\nproposed scheme significantly enhances watermark robustness, preserves video\nquality, and substantially increases watermark embedding capacity."}
{"id": "2509.17488", "categories": ["cs.CR", "cs.AI"], "pdf": "https://arxiv.org/pdf/2509.17488", "abs": "https://arxiv.org/abs/2509.17488", "authors": ["Shouju Wang", "Fenglin Yu", "Xirui Liu", "Xiaoting Qin", "Jue Zhang", "Qingwei Lin", "Dongmei Zhang", "Saravan Rajmohan"], "title": "Privacy in Action: Towards Realistic Privacy Mitigation and Evaluation for LLM-Powered Agents", "comment": "To appear at EMNLP 2025 (Findings)", "summary": "The increasing autonomy of LLM agents in handling sensitive communications,\naccelerated by Model Context Protocol (MCP) and Agent-to-Agent (A2A)\nframeworks, creates urgent privacy challenges. While recent work reveals\nsignificant gaps between LLMs' privacy Q&A performance and their agent\nbehavior, existing benchmarks remain limited to static, simplified scenarios.\nWe present PrivacyChecker, a model-agnostic, contextual integrity based\nmitigation approach that effectively reduces privacy leakage from 36.08% to\n7.30% on DeepSeek-R1 and from 33.06% to 8.32% on GPT-4o, all while preserving\ntask helpfulness. We also introduce PrivacyLens-Live, transforming static\nbenchmarks into dynamic MCP and A2A environments that reveal substantially\nhigher privacy risks in practical. Our modular mitigation approach integrates\nseamlessly into agent protocols through three deployment strategies, providing\npractical privacy protection for the emerging agentic ecosystem. Our data and\ncode will be made available at https://aka.ms/privacy_in_action."}
{"id": "2509.17508", "categories": ["cs.CR", "cs.CY"], "pdf": "https://arxiv.org/pdf/2509.17508", "abs": "https://arxiv.org/abs/2509.17508", "authors": ["Eric Filiol"], "title": "Community Covert Communication - Dynamic Mass Covert Communication Through Social Media", "comment": "22 pages, 8 figures, this work has been presented at 44CON 2024 &\n  44CON 2025 in London", "summary": "Since the early 2010s, social network-based influence technologies have grown\nalmost exponentially. Initiated by the U.S. Army's early OEV system in 2011, a\nnumber of companies specializing in this field have emerged. The most\n(in)famous cases are Bell Pottinger, Cambridge Analytica, Aggregate-IQ and,\nmore recently, Team Jorge.\n  In this paper, we consider the use-case of sock puppet master activities,\nwhich consist in creating hundreds or even thousands of avatars, in organizing\nthem into communities and implement influence operations. On-purpose software\nis used to automate these operations (e.g. Ripon software, AIMS) and organize\nthese avatar populations into communities. The aim is to organize targeted and\ndirected influence communication to rather large communities (influence\ntargets).\n  The goal of the present research work is to show how these community\nmanagement techniques (social networks) can also be used to\ncommunicate/disseminate relatively large volumes (up to a few tens of Mb) of\nmulti-level encrypted information to a limited number of actors. To a certain\nextent, this can be compared to a Dark Post-type function, with a number of\nmuch more powerful potentialities. As a consequence, the concept of\ncommunication has been totally redefined and disrupted, so that eavesdropping,\ninterception and jamming operations no longer make sense."}
{"id": "2509.17595", "categories": ["cs.CR", "math.OC"], "pdf": "https://arxiv.org/pdf/2509.17595", "abs": "https://arxiv.org/abs/2509.17595", "authors": ["Shunnosuke Ikeda", "Kazumasa Shinagawa"], "title": "Impossibility Results of Card-Based Protocols via Mathematical Optimization", "comment": null, "summary": "This paper introduces mathematical optimization as a new method for proving\nimpossibility proofs in the field of card-based cryptography. While previous\nimpossibility proofs were often limited to cases involving a small number of\ncards, this new approach establishes results that hold for a large number of\ncards. The research focuses on single-cut full-open (SCFO) protocols, which\nconsist of performing one random cut and then revealing all cards. The main\ncontribution is that for any three-variable Boolean function, no new SCFO\nprotocols exist beyond those already known, under the condition that all\nadditional cards have the same color. The significance of this work is that it\nprovides a new framework for impossibility proofs and delivers a proof that is\nvalid for any number of cards, as long as all additional cards have the same\ncolor."}
{"id": "2509.17709", "categories": ["cs.CR"], "pdf": "https://arxiv.org/pdf/2509.17709", "abs": "https://arxiv.org/abs/2509.17709", "authors": ["Masayuki Tezuka", "Keisuke Tanaka"], "title": "Ordered Multi-Signatures with Public-Key Aggregation from SXDH Assumption", "comment": "A preliminary version of this paper is appeared in the 20th\n  International Workshop on Security (IWSEC 2025)", "summary": "An ordered multi-signature scheme allows multiple signers to sign a common\nmessage in a sequential manner and allows anyone to verify the signing order of\nsigners with a public-key list. In this work, we propose an ordered\nmulti-signature scheme by modifying the sequential aggregate signature scheme\nby Chatterjee and Kabaleeshwaran (ACISP 2020). Our scheme offers compact public\nparameter size and the public-key aggregation property. This property allows us\nto compress a public-key list into a short aggregated key. We prove the\nsecurity of our scheme under the symmetric external Diffie-Hellman (SXDH)\nassumption without the random oracle model."}
{"id": "2509.17722", "categories": ["cs.CR"], "pdf": "https://arxiv.org/pdf/2509.17722", "abs": "https://arxiv.org/abs/2509.17722", "authors": ["Masayuki Tezuka", "Keisuke Tanaka"], "title": "Public Key Encryption with Equality Test from Tag-Based Encryption", "comment": "A preliminary version of this paper is appeared in the 20th\n  International Workshop on Security (IWSEC 2025)", "summary": "Public key encryption with equality test (PKEET), proposed by Yang et al.\n(CT-RSA 2010), is a variant of public key encryption that enables an equality\ntest to determine whether two ciphertexts correspond to the same plaintext.\nThis test applies not only for ciphertexts generated under the same encryption\nkey but also for those generated under different encryption keys. To date,\nseveral generic constructions of PKEET have been proposed. However, these\ngeneric constructions have the drawback of reliance on the random oracle model\nor a (hierarchical) identity-based encryption scheme. In this paper, we propose\na generic construction of a PKEET scheme based on tag-based encryption without\nthe random oracle model. Tag-based encryption is a weaker primitive than\nidentity-based encryption. Our scheme allows to derive new PKEET schemes\nwithout the random oracle model. By instantiating our construction with the\npairing-free tag-based encryption scheme by Kiltz (TCC 2006), we obtain a\npairing-free PKEET scheme without the random oracle model. Moreover, by\ninstantiating our construction with a tag-based encryption scheme based on the\nlearning parity with noise (LPN) assumption, we obtain a PKEET scheme based on\nthe LPN assumption without the random oracle model."}
{"id": "2509.17832", "categories": ["cs.CR"], "pdf": "https://arxiv.org/pdf/2509.17832", "abs": "https://arxiv.org/abs/2509.17832", "authors": ["Xiangmin Shen", "Wenyuan Cheng", "Yan Chen", "Zhenyuan Li", "Yuqiao Gu", "Lingzhi Wang", "Wencheng Zhao", "Dawei Sun", "Jiashui Wang"], "title": "AEAS: Actionable Exploit Assessment System", "comment": "AEAS has been implemented in the planning agent of PentestAgent, our\n  LLM-driven automated penetration testing framework. Check out our repository:\n  https://github.com/nbshenxm/pentest-agent", "summary": "Security practitioners face growing challenges in exploit assessment, as\npublic vulnerability repositories are increasingly populated with inconsistent\nand low-quality exploit artifacts. Existing scoring systems, such as CVSS and\nEPSS, offer limited support for this task. They either rely on theoretical\nmetrics or produce opaque probability estimates without assessing whether\nusable exploit code exists. In practice, security teams often resort to manual\ntriage of exploit repositories, which is time-consuming, error-prone, and\ndifficult to scale. We present AEAS, an automated system designed to assess and\nprioritize actionable exploits through static analysis. AEAS analyzes both\nexploit code and associated documentation to extract a structured set of\nfeatures reflecting exploit availability, functionality, and setup complexity.\nIt then computes an actionability score for each exploit and produces ranked\nexploit recommendations. We evaluate AEAS on a dataset of over 5,000\nvulnerabilities derived from 600+ real-world applications frequently\nencountered by red teams. Manual validation and expert review on representative\nsubsets show that AEAS achieves a 100% top-3 success rate in recommending\nfunctional exploits and shows strong alignment with expert-validated rankings.\nThese results demonstrate the effectiveness of AEAS in supporting\nexploit-driven vulnerability prioritization."}
{"id": "2509.17836", "categories": ["cs.CR"], "pdf": "https://arxiv.org/pdf/2509.17836", "abs": "https://arxiv.org/abs/2509.17836", "authors": ["Roberto Doriguzzi-Corin", "Petr Sabel", "Silvio Cretti", "Silvio Ranise"], "title": "Federated Learning in the Wild: A Comparative Study for Cybersecurity under Non-IID and Unbalanced Settings", "comment": null, "summary": "Machine Learning (ML) techniques have shown strong potential for network\ntraffic analysis; however, their effectiveness depends on access to\nrepresentative, up-to-date datasets, which is limited in cybersecurity due to\nprivacy and data-sharing restrictions. To address this challenge, Federated\nLearning (FL) has recently emerged as a novel paradigm that enables\ncollaborative training of ML models across multiple clients while ensuring that\nsensitive data remains local. Nevertheless, Federated Averaging (FedAvg), the\ncanonical FL algorithm, has proven poor convergence in heterogeneous\nenvironments where data distributions are non-independent and identically\ndistributed (i.i.d.) and client datasets are unbalanced, conditions frequently\nobserved in cybersecurity contexts. To overcome these challenges, several\nalternative FL strategies have been developed, yet their applicability to\nnetwork intrusion detection remains insufficiently explored. This study\nsystematically reviews and evaluates a range of FL methods in the context of\nintrusion detection for DDoS attacks. Using a dataset of network attacks within\na Kubernetes-based testbed, we assess convergence efficiency, computational\noverhead, bandwidth consumption, and model accuracy. To the best of our\nknowledge, this is the first comparative analysis of FL algorithms for\nintrusion detection under realistic non-i.i.d. and unbalanced settings,\nproviding new insights for the design of robust, privacypreserving network\nsecurity solutions."}
{"id": "2509.17871", "categories": ["cs.CR"], "pdf": "https://arxiv.org/pdf/2509.17871", "abs": "https://arxiv.org/abs/2509.17871", "authors": ["Samuel Breckenridge", "Dani Vilardell", "Andr√©s F√°brega", "Amy Zhao", "Patrick McCorry", "Rafael Solari", "Ari Juels"], "title": "B-Privacy: Defining and Enforcing Privacy in Weighted Voting", "comment": null, "summary": "In traditional, one-vote-per-person voting systems, privacy equates with\nballot secrecy: voting tallies are published, but individual voters' choices\nare concealed.\n  Voting systems that weight votes in proportion to token holdings, though, are\nnow prevalent in cryptocurrency and web3 systems. We show that these\nweighted-voting systems overturn existing notions of voter privacy. Our\nexperiments demonstrate that even with secret ballots, publishing raw tallies\noften reveals voters' choices.\n  Weighted voting thus requires a new framework for privacy. We introduce a\nnotion called B-privacy whose basis is bribery, a key problem in voting systems\ntoday. B-privacy captures the economic cost to an adversary of bribing voters\nbased on revealed voting tallies.\n  We propose a mechanism to boost B-privacy by noising voting tallies. We prove\nbounds on its tradeoff between B-privacy and transparency, meaning\nreported-tally accuracy. Analyzing 3,582 proposals across 30 Decentralized\nAutonomous Organizations (DAOs), we find that the prevalence of large voters\n(\"whales\") limits the effectiveness of any B-Privacy-enhancing technique.\nHowever, our mechanism proves to be effective in cases without extreme voting\nweight concentration: among proposals requiring coalitions of $\\geq5$ voters to\nflip outcomes, our mechanism raises B-privacy by a geometric mean factor of\n$4.1\\times$.\n  Our work offers the first principled guidance on transparency-privacy\ntradeoffs in weighted-voting systems, complementing existing approaches that\nfocus on ballot secrecy and revealing fundamental constraints that voting\nweight concentration imposes on privacy mechanisms."}
{"id": "2509.17962", "categories": ["cs.CR", "J.3"], "pdf": "https://arxiv.org/pdf/2509.17962", "abs": "https://arxiv.org/abs/2509.17962", "authors": ["Jon Crowcroft", "Anil Madhavapeddy", "Chris Hicks", "Richard Mortier", "Vasilios Mavroudis"], "title": "What if we could hot swap our Biometrics?", "comment": null, "summary": "What if you could really revoke your actual biometric identity, and install a\nnew one, by live rewriting your biological self? We propose some novel\nmechanisms for hot swapping identity based in novel biotechnology. We discuss\nthe potential positive use cases, and negative consequences if such technology\nwas to become available and affordable. Biometrics are selected on the basis\nthat they are supposed to be unfakeable, or at least not at reasonable cost. If\nthey become easier to fake, it may be much cheaper to fake someone else's\nbiometrics than it is for you to change your own biometrics if someone does\ncopy yours. This potentially makes biometrics a bad trade-off for the user. At\nthe time of writing, this threat is highly speculative, but we believe it is\nworth raising and considering the potential consequences."}
{"id": "2509.17969", "categories": ["cs.CR"], "pdf": "https://arxiv.org/pdf/2509.17969", "abs": "https://arxiv.org/abs/2509.17969", "authors": ["Gorka Guardiola M√∫zquiz", "Juan Gonz√°lez-G√≥mez", "Enrique Soriano-Salvador"], "title": "The Reverse File System: Towards open cost-effective secure WORM storage devices for logging", "comment": null, "summary": "Write Once Read Many (WORM) properties for storage devices are desirable to\nensure data immutability for applications such as secure logging, regulatory\ncompliance, archival storage, and other types of backup systems. WORM devices\nguarantee that data, once written, cannot be altered or deleted. However,\nimplementing secure and compatible WORM storage remains a challenge.\nTraditional solutions often rely on specialized hardware, which is either\ncostly, closed, or inaccessible to the general public. Distributed approaches,\nwhile promising, introduce additional risks such as denial-of-service\nvulnerabilities and operational complexity. We introduce Socarrat, a novel,\ncost-effective, and local WORM storage solution that leverages a simple\nexternal USB device (specifically, a single-board computer running Linux with\nUSB On-The-Go support). The resulting device can be connected via USB,\nappearing as an ordinary external disk formatted with an ext4 or exFAT file\nsystem, without requiring any specialized software or drivers. By isolating the\nWORM enforcement mechanism in a dedicated USB hardware module, Socarrat\nsignificantly reduces the attack surface and ensures that even privileged\nattackers cannot modify or erase stored data. In addition to the WORM capacity,\nthe system is designed to be tamper-evident, becoming resilient against\nadvanced attacks. This work describes a novel approach, the Reverse File\nSystem, based on inferring the file system operations occurring at higher\nlayers in the host computer where Socarrat is mounted. The paper also describes\nthe current Socarrat prototype, implemented in Go and available as free/libre\nsoftware. Finally, it provides a complete evaluation of the logging performance\non different single-board computers."}
{"id": "2509.18014", "categories": ["cs.CR", "stat.ML"], "pdf": "https://arxiv.org/pdf/2509.18014", "abs": "https://arxiv.org/abs/2509.18014", "authors": ["Joshua Ward", "Xiaofeng Lin", "Chi-Hua Wang", "Guang Cheng"], "title": "Synth-MIA: A Testbed for Auditing Privacy Leakage in Tabular Data Synthesis", "comment": null, "summary": "Tabular Generative Models are often argued to preserve privacy by creating\nsynthetic datasets that resemble training data. However, auditing their\nempirical privacy remains challenging, as commonly used similarity metrics fail\nto effectively characterize privacy risk. Membership Inference Attacks (MIAs)\nhave recently emerged as a method for evaluating privacy leakage in synthetic\ndata, but their practical effectiveness is limited. Numerous attacks exist\nacross different threat models, each with distinct implementations targeting\nvarious sources of privacy leakage, making them difficult to apply\nconsistently. Moreover, no single attack consistently outperforms the others,\nleading to a routine underestimation of privacy risk.\n  To address these issues, we propose a unified, model-agnostic threat\nframework that deploys a collection of attacks to estimate the maximum\nempirical privacy leakage in synthetic datasets. We introduce Synth-MIA, an\nopen-source Python library that streamlines this auditing process through a\nnovel testbed that integrates seamlessly into existing synthetic data\nevaluation pipelines through a Scikit-Learn-like API. Our software implements\n13 attack methods through a Scikit-Learn-like API, designed to enable fast\nsystematic estimation of privacy leakage for practitioners as well as\nfacilitate the development of new attacks and experiments for researchers.\n  We demonstrate our framework's utility in the largest tabular synthesis\nprivacy benchmark to date, revealing that higher synthetic data quality\ncorresponds to greater privacy leakage, that similarity-based privacy metrics\nshow weak correlation with MIA results, and that the differentially private\ngenerator PATEGAN can fail to preserve privacy under such attacks. This\nunderscores the necessity of MIA-based auditing when designing and deploying\nTabular Generative Models."}
{"id": "2509.18039", "categories": ["cs.CR"], "pdf": "https://arxiv.org/pdf/2509.18039", "abs": "https://arxiv.org/abs/2509.18039", "authors": ["Alessio Izzillo", "Riccardo Lazzeretti", "Emilio Coppa"], "title": "STAFF: Stateful Taint-Assisted Full-system Firmware Fuzzing", "comment": "This paper is currently under review at Computers & Security\n  (Elsevier)", "summary": "Modern embedded Linux devices, such as routers, IP cameras, and IoT gateways,\nrely on complex software stacks where numerous daemons interact to provide\nservices. Testing these devices is crucial from a security perspective since\nvendors often use custom closed- or open-source software without documenting\nreleases and patches. Recent coverage-guided fuzzing solutions primarily test\nindividual processes, ignoring deep dependencies between daemons and their\npersistent internal state. This article presents STAFF, a firmware fuzzing\nframework for discovering bugs in Linux-based firmware built around three key\nideas: (a) user-driven multi-request recording, which monitors user\ninteractions with emulated firmware to capture request sequences involving\napplication-layer protocols (e.g., HTTP); (b) intra- and inter-process\ndependency detection, which uses whole-system taint analysis to track how input\nbytes influence user-space states, including files, sockets, and memory areas;\n(c) protocol-aware taint-guided fuzzing, which applies mutations to request\nsequences based on identified dependencies, exploiting multi-staged forkservers\nto efficiently checkpoint protocol states. When evaluating STAFF on 15\nLinux-based firmware targets, it identifies 42 bugs involving multiple network\nrequests and different firmware daemons, significantly outperforming existing\nstate-of-the-art fuzzing solutions in both the number and reproducibility of\ndiscovered bugs."}
{"id": "2509.18044", "categories": ["cs.CR", "cs.AI"], "pdf": "https://arxiv.org/pdf/2509.18044", "abs": "https://arxiv.org/abs/2509.18044", "authors": ["Saeid Sheikhi", "Panos Kostakos", "Lauri Loven"], "title": "Hybrid Reputation Aggregation: A Robust Defense Mechanism for Adversarial Federated Learning in 5G and Edge Network Environments", "comment": null, "summary": "Federated Learning (FL) in 5G and edge network environments face severe\nsecurity threats from adversarial clients. Malicious participants can perform\nlabel flipping, inject backdoor triggers, or launch Sybil attacks to corrupt\nthe global model. This paper introduces Hybrid Reputation Aggregation (HRA), a\nnovel robust aggregation mechanism designed to defend against diverse\nadversarial behaviors in FL without prior knowledge of the attack type. HRA\ncombines geometric anomaly detection with momentum-based reputation tracking of\nclients. In each round, it detects outlier model updates via distance-based\ngeometric analysis while continuously updating a trust score for each client\nbased on historical behavior. This hybrid approach enables adaptive filtering\nof suspicious updates and long-term penalization of unreliable clients,\ncountering attacks ranging from backdoor insertions to random noise Byzantine\nfailures. We evaluate HRA on a large-scale proprietary 5G network dataset (3M+\nrecords) and the widely used NF-CSE-CIC-IDS2018 benchmark under diverse\nadversarial attack scenarios. Experimental results reveal that HRA achieves\nrobust global model accuracy of up to 98.66% on the 5G dataset and 96.60% on\nNF-CSE-CIC-IDS2018, outperforming state-of-the-art aggregators such as Krum,\nTrimmed Mean, and Bulyan by significant margins. Our ablation studies further\ndemonstrate that the full hybrid system achieves 98.66% accuracy, while the\nanomaly-only and reputation-only variants drop to 84.77% and 78.52%,\nrespectively, validating the synergistic value of our dual-mechanism approach.\nThis demonstrates HRA's enhanced resilience and robustness in 5G/edge federated\nlearning deployments, even under significant adversarial conditions."}
