<div id=toc></div>

# Table of Contents

- [cs.CR](#cs.CR) [Total: 26]


<div id='cs.CR'></div>

# cs.CR [[Back]](#toc)

### [1] [Practical challenges of control monitoring in frontier AI deployments](https://arxiv.org/abs/2512.22154)
*David Lindner,Charlie Griffin,Tomek Korbak,Roland S. Zimmermann,Geoffrey Irving,Sebastian Farquhar,Alan Cooney*

Main category: cs.CR

TL;DR: 论文分析了将控制监控扩展到现实世界AI部署的设计选择，重点关注同步、半同步和异步三种监控形式，提出了高层安全案例框架，并识别了监督、延迟和恢复三大挑战。


<details>
  <summary>Details</summary>
Motivation: 现有控制监控研究主要在简化环境中进行，但现实世界部署面临并行代理实例、非可忽略的监督延迟、代理实例间的渐进攻击以及难以基于单个有害行为识别阴谋代理等挑战，需要设计能够应对这些挑战的监控方案。

Method: 提出了三种不同延迟-安全权衡的监控形式：同步监控、半同步监控和异步监控；引入了高层安全案例框架作为理解和比较这些监控协议的工具；通过四个未来AI部署案例研究分析了监督、延迟和恢复三大挑战。

Result: 分析识别了现实世界AI监控面临的三个核心挑战：监督挑战（确保监控有效）、延迟挑战（平衡安全与效率）、恢复挑战（从攻击中恢复）；通过案例研究展示了不同监控协议在不同部署场景下的适用性。

Conclusion: 现实世界AI控制监控需要综合考虑并行性、延迟和渐进攻击等复杂因素，提出的监控协议框架和安全案例工具为设计可扩展的监控系统提供了理论基础，未来需要进一步研究具体实现方案。

Abstract: Automated control monitors could play an important role in overseeing highly capable AI agents that we do not fully trust. Prior work has explored control monitoring in simplified settings, but scaling monitoring to real-world deployments introduces additional dynamics: parallel agent instances, non-negligible oversight latency, incremental attacks between agent instances, and the difficulty of identifying scheming agents based on individual harmful actions. In this paper, we analyse design choices to address these challenges, focusing on three forms of monitoring with different latency-safety trade-offs: synchronous, semi-synchronous, and asynchronous monitoring. We introduce a high-level safety case sketch as a tool for understanding and comparing these monitoring protocols. Our analysis identifies three challenges -- oversight, latency, and recovery -- and explores them in four case studies of possible future AI deployments.

</details>


### [2] [A Statistical Side-Channel Risk Model for Timing Variability in Lattice-Based Post-Quantum Cryptography](https://arxiv.org/abs/2512.22301)
*Aayush Mainali,Sirjan Ghimire*

Main category: cs.CR

TL;DR: 该论文提出了一种基于场景的统计风险模型来评估后量子密码实现中的时序侧信道泄漏，通过合成不同执行条件下的迹线并量化泄漏，为早期设计阶段提供可复现的比较方法。


<details>
  <summary>Details</summary>
Motivation: 后量子密码（特别是基于格的方案）由于复杂的算术和控制流可能产生依赖于秘密的时序变化，而实际时序测量又受到环境噪声（如调度效应、争用、重尾延迟）的影响，需要系统化的风险评估方法。

Method: 提出基于场景的统计风险模型，在空闲、抖动和负载三种执行条件下合成两类秘密的迹线，使用多种泄漏量化指标（Welch's t-test、KS距离、Cliff's delta、互信息、分布重叠度）以TLRI方式组合得到一致的评分来排序风险场景。

Result: 在代表性格基KEM方案（Kyber、Saber、Frodo）中：空闲条件下区分度最好；抖动和负载条件通过增加方差和重叠度削弱区分度；缓存索引和分支式泄漏通常产生最高风险信号；更快的方案在相似泄漏假设下可能具有更高的峰值风险。

Conclusion: 该方法能够在早期设计阶段（平台特定验证之前）提供可复现的风险比较，帮助识别和量化后量子密码实现中的时序侧信道漏洞，为安全实现提供指导。

Abstract: Timing side-channels are an important threat to cryptography that still needs to be addressed in implementations, and the advent of post-quantum cryptography raises this issue because the lattice-based schemes may produce secret-dependent timing variability with the help of complex arithmetic and control flow. Since also real timing measurements are affected by environmental noise (e.g. scheduling effects, contention, heavy tailed delays), in this work a scenario-based statistical risk model is proposed for timing leakage as a problem of distributional distinguishability under controlled execution conditions. We synthesize traces for two secret classes in idle, jitter and loaded scenarios and for multiple leakage models and quantify leakage with Welch's t-test, KS distance, Cliff's delta, mutual information, and distribution overlap to combine in a TLRI like manner to obtain a consistent score for ranking scenarios. Across representative lattice-based KEM families (Kyber, Saber, Frodo), idle conditions generally have the best distinguishability, jitter and loaded conditions erode distinguishability through an increase in variance and increase in overlap; cache-index and branch-style leakage tends to give the highest risk signals, and faster schemes can have a higher peak risk given similar leakage assumptions, allowing reproducible comparisons at an early design stage, prior to platform-specific validation.

</details>


### [3] [Beyond Single Bugs: Benchmarking Large Language Models for Multi-Vulnerability Detection](https://arxiv.org/abs/2512.22306)
*Chinmay Pushkar,Sanchit Kabra,Dhruv Kumar,Jagat Sesh Challa*

Main category: cs.CR

TL;DR: 本文提出了一个多漏洞检测基准，评估LLM在真实软件中检测多个交互漏洞的能力，发现随着漏洞密度增加，性能显著下降。


<details>
  <summary>Details</summary>
Motivation: 现有基准主要关注孤立单漏洞样本或函数级分类，无法反映真实软件中多个交互漏洞共存的复杂性。LLM在多标签任务中存在"计数偏差"和"选择偏差"，但在代码安全领域尚未得到严格量化。

Method: 构建了包含C、C++、Python和JavaScript四种语言的40,000个文件数据集，通过系统注入控制数量的漏洞（1、3、5、9个）到长上下文代码样本（7.5k-10k tokens）中。评估了包括GPT-4o-mini、Llama-3.3-70B和Qwen-2.5系列在内的五个最先进LLM。

Result: 结果显示随着漏洞密度增加，性能急剧下降。Llama-3.3-70B在单漏洞C任务中达到接近完美的F1分数（约0.97），但在高密度设置下性能下降高达40%。Python和JavaScript表现出与C/C++不同的失败模式，模型在复杂Python文件中表现出严重的"计数不足"（召回率降至0.30以下）。

Conclusion: 需要更全面的基准来评估LLM在真实世界多漏洞检测中的能力，当前模型在处理高密度漏洞时存在显著局限性，特别是在Python和JavaScript中表现更差。

Abstract: Large Language Models (LLMs) have demonstrated significant potential in automated software security, particularly in vulnerability detection. However, existing benchmarks primarily focus on isolated, single-vulnerability samples or function-level classification, failing to reflect the complexity of real-world software where multiple interacting vulnerabilities often coexist within large files. Recent studies indicate that LLMs suffer from "count bias" and "selection bias" in multi-label tasks, yet this has not been rigorously quantified in the domain of code security. In this work, we introduce a comprehensive benchmark for Multi-Vulnerability Detection across four major languages: C, C++, Python, and JavaScript. We construct a dataset of 40,000 files by systematically injecting controlled counts of vulnerabilities (1, 3, 5, and 9) into long-context code samples (7.5k-10k tokens) sourced from CodeParrot. We evaluate five state-of-the-art LLMs, including GPT-4o-mini, Llama-3.3-70B, and the Qwen-2.5 series. Our results reveal a sharp degradation in performance as vulnerability density increases. While Llama-3.3-70B achieves near-perfect F1 scores (approximately 0.97) on single-vulnerability C tasks, performance drops by up to 40% in high-density settings. Notably, Python and JavaScript show distinct failure modes compared to C/C++, with models exhibiting severe "under-counting" (Recall dropping to less than 0.30) in complex Python files.

</details>


### [4] [LLA: Enhancing Security and Privacy for Generative Models with Logic-Locked Accelerators](https://arxiv.org/abs/2512.22307)
*You Li,Guannan Zhao,Yuhao Ju,Yunqi He,Jie Gu,Hai Zhou*

Main category: cs.CR

TL;DR: LLA是一种结合硬件和软件的保护生成式AI模型知识产权的方案，通过嵌入密钥位到神经元并利用硬件锁定模块来防御模型盗窃、损坏和信息泄露等供应链威胁。


<details>
  <summary>Details</summary>
Motivation: 随着生成式AI模型的广泛应用，知识产权保护变得日益重要。模型面临供应链威胁，包括模型盗窃、模型损坏和信息泄露等风险，需要有效的保护机制。

Method: 软件方面：将密钥位嵌入神经元，触发异常值降低性能，并应用不变性变换来隐藏密钥值。硬件方面：在AI加速器中集成轻量级锁定模块，保持与各种数据流模式和工具链的兼容性。加速器预存密钥作为访问模型服务的许可证。

Result: LLA能够抵御广泛的oracle引导密钥优化攻击，同时计算开销极小（7,168个密钥位的情况下小于0.1%）。

Conclusion: LLA通过软硬件协同设计为生成式AI模型提供了有效的知识产权保护方案，在保持高性能的同时增强了模型安全性。

Abstract: We introduce LLA, an effective intellectual property (IP) protection scheme for generative AI models. LLA leverages the synergy between hardware and software to defend against various supply chain threats, including model theft, model corruption, and information leakage. On the software side, it embeds key bits into neurons that can trigger outliers to degrade performance and applies invariance transformations to obscure the key values. On the hardware side, it integrates a lightweight locking module into the AI accelerator while maintaining compatibility with various dataflow patterns and toolchains. An accelerator with a pre-stored secret key acts as a license to access the model services provided by the IP owner. The evaluation results show that LLA can withstand a broad range of oracle-guided key optimization attacks, while incurring a minimal computational overhead of less than 0.1% for 7,168 key bits.

</details>


### [5] [NOWA: Null-space Optical Watermark for Invisible Capture Fingerprinting and Tamper Localization](https://arxiv.org/abs/2512.22501)
*Edwin Vargas*

Main category: cs.CR

TL;DR: 提出了一种混合光学-数字图像认证框架，通过在相机孔径中嵌入相位掩模产生光学水印，结合空域网络进行重建，实现不可见但可检测的图像保护。


<details>
  <summary>Details</summary>
Motivation: 现有数字水印技术容易受到复杂数字攻击，需要更鲁棒的图像认证方法来确保数字图像的真实性和所有权。

Method: 采用混合光学-数字框架：1) 光学层面：在相机孔径中嵌入相位掩模产生空域光学水印；2) 数字层面：使用空域网络进行测量一致性重建，在保持图像质量的同时保护水印签名。

Result: 实验表明该方法在图像质量保持和篡改定位精度方面优于现有数字水印和学习型认证方法，能抵抗压缩等常见退化，且具有结构安全不对称性。

Conclusion: 提出的NOWA-NSN框架通过光学物理线索与数字学习的结合，实现了鲁棒的图像认证和篡改检测，为数字图像保护提供了新方向。

Abstract: Ensuring the authenticity and ownership of digital images is increasingly challenging as modern editing tools enable highly realistic forgeries. Existing image protection systems mainly rely on digital watermarking, which is susceptible to sophisticated digital attacks. To address this limitation, we propose a hybrid optical-digital framework that incorporates physical authentication cues during image formation and preserves them through a learned reconstruction process. At the optical level, a phase mask in the camera aperture produces a Null-space Optical Watermark (NOWA) that lies in the Null Space of the imaging operator and therefore remains invisible in the captured image. Then, a Null-Space Network (NSN) performs measurement-consistent reconstruction that delivers high-quality protected images while preserving the NOWA signature. The proposed design enables tamper localization by projecting the image onto the camera's null space and detecting pixel-level inconsistencies. Our design preserves perceptual quality, resists common degradations such as compression, and establishes a structural security asymmetry: without access to the optical or NSN parameters, adversaries cannot forge the NOWA signature. Experiments with simulations and a prototype camera demonstrate competitive performance in terms of image quality preservation, and tamper localization accuracy compared to state-of-the-art digital watermarking and learning-based authentication methods.

</details>


### [6] [Verifiable Dropout: Turning Randomness into a Verifiable Claim](https://arxiv.org/abs/2512.22526)
*Kichang Lee,Sungmin Lee,Jaeho Jin,JeongGil Ko*

Main category: cs.CR

TL;DR: 提出Verifiable Dropout机制，使用零知识证明确保深度学习训练中dropout操作的完整性，防止攻击者利用随机性作为恶意操作的掩护。


<details>
  <summary>Details</summary>
Motivation: 现有云AI训练的审计机制无法有效处理深度学习的非确定性特性。随机操作（如dropout）为攻击者提供了"合理否认"的模糊空间，他们可以将恶意操作伪装成自然随机变化。现有日志机制无法验证随机值是否被诚实生成和应用，同时又不暴露敏感训练数据。

Method: 引入Verifiable Dropout，基于零知识证明的隐私保护机制。将随机性视为可验证的声明而非借口。该方法将dropout掩码绑定到确定性的、可密码验证的种子，并证明dropout操作的正确执行。

Result: 设计使用户能够事后审计随机训练步骤的完整性，确保随机性既没有被偏置也没有被精心挑选，同时严格保护模型和数据的机密性。

Conclusion: Verifiable Dropout填补了深度学习训练中的完整性空白，通过密码学方法解决了随机操作带来的审计挑战，在保护隐私的同时提供了可验证的训练完整性保证。

Abstract: Modern cloud-based AI training relies on extensive telemetry and logs to ensure accountability. While these audit trails enable retrospective inspection, they struggle to address the inherent non-determinism of deep learning. Stochastic operations, such as dropout, create an ambiguity surface where attackers can mask malicious manipulations as natural random variance, granting them plausible deniability. Consequently, existing logging mechanisms cannot verify whether stochastic values were generated and applied honestly without exposing sensitive training data. To close this integrity gap, we introduce Verifiable Dropout, a privacy-preserving mechanism based on zero-knowledge proofs. We treat stochasticity not as an excuse but as a verifiable claim. Our approach binds dropout masks to a deterministic, cryptographically verifiable seed and proves the correct execution of the dropout operation. This design enables users to audit the integrity of stochastic training steps post-hoc, ensuring that randomness was neither biased nor cherry-picked, while strictly preserving the confidentiality of the model and data.

</details>


### [7] [Raven: Mining Defensive Patterns in Ethereum via Semantic Transaction Revert Invariants Categories](https://arxiv.org/abs/2512.22616)
*Mojtaba Eshghie,Melissa Mazura,Alexandre Bartel*

Main category: cs.CR

TL;DR: Raven框架通过分析以太坊回滚交易中的防御性不变式，挖掘智能合约的安全防御模式，发现了6个新的不变式类别，并展示了其在漏洞检测中的实际应用价值。


<details>
  <summary>Details</summary>
Motivation: 以太坊交易中因不变式检查而回滚的交易（如require/assert/if-revert语句）是活跃链上防御的重要信号，但这些防御模式在安全研究中尚未被充分发现和利用。

Method: 提出Raven框架：1) 将回滚交易与智能合约源代码中导致回滚的不变式对齐；2) 使用基于BERT的微调模型嵌入这些不变式；3) 通过语义意图对不变式进行聚类，挖掘以太坊上的防御性不变式类别。

Result: 在20,000个回滚交易样本上评估，Raven实现了有凝聚力和有意义的聚类。手动专家审查发现的19个语义聚类中，揭示了6个现有不变式目录中不存在的新类别：功能开关、重放防护、证明/签名验证、计数器、调用者提供的滑点阈值、允许/禁止/机器人列表。

Conclusion: Raven能够映射以太坊成功的防御机制，这些不变式类别使安全研究人员能够基于从智能合约工作防御中提取的数据驱动安全预言来开发分析工具，并通过案例研究展示了其在实际漏洞检测中的实用性。

Abstract: We frame Ethereum transactions reverted by invariants-require(<invariant>)/ assert(<invariant>)/if (<invariant>) revert statements in the contract implementation-as a positive signal of active on-chain defenses. Despite their value, the defensive patterns in these transactions remain undiscovered and underutilized in security research. We present Raven, a framework that aligns reverted transactions to the invariant causing the reversion in the smart contract source code, embeds these invariants using our BERT-based fine-tuned model, and clusters them by semantic intent to mine defensive invariant categories on Ethereum. Evaluated on a sample of 20,000 reverted transactions, Raven achieves cohesive and meaningful clusters of transaction-reverting invariants. Manual expert review of the mined 19 semantic clusters uncovers six new invariant categories absent from existing invariant catalogs, including feature toggles, replay prevention, proof/signature verification, counters, caller-provided slippage thresholds, and allow/ban/bot lists. To demonstrate the practical utility of this invariant catalog mining pipeline, we conduct a case study using one of the newly discovered invariant categories as a fuzzing oracle to detect vulnerabilities in a real-world attack. Raven thus can map Ethereum's successful defenses. These invariant categories enable security researchers to develop analysis tools based on data-driven security oracles extracted from the smart contracts' working defenses.

</details>


### [8] [SCyTAG: Scalable Cyber-Twin for Threat-Assessment Based on Attack Graphs](https://arxiv.org/abs/2512.22669)
*David Tayouri,Elad Duani,Abed Showgan,Ofir Manor,Ortal Lavi,Igor Podoski,Miro Ohana,Yuval Elovici,Andres Murillo,Asaf Shabtai,Rami Puzis*

Main category: cs.CR

TL;DR: SCyTAG是一个自动生成最小可行网络孪生体的框架，用于评估网络威胁情报报告中攻击场景的影响，相比完整拓扑减少85%的网络组件需求。


<details>
  <summary>Details</summary>
Motivation: 当前组织评估网络威胁风险的方法存在局限性：手动分析需要专业知识且无法频繁进行；自动化方法使用攻击图或威胁仿真器，但网络孪生体由于无法扩展而在组织网络中应用有限。需要一种成本效益高、可扩展的威胁评估解决方案。

Method: SCyTAG是一个多步骤框架，输入组织计算机网络规格和从CTI报告中提取的攻击场景，首先生成攻击图，然后基于攻击图自动构建包含必要网络组件的网络孪生体，用于仿真攻击场景并评估攻击的相关性和风险。

Result: 在真实和虚构的组织网络上评估SCyTAG，结果显示相比完整拓扑，SCyTAG将仿真所需的网络组件数量减少了85%，所需资源减半，同时保持了仿真攻击的保真度。

Conclusion: SCyTAG作为一种成本效益高、可扩展且高度适应的威胁评估解决方案，通过弥合抽象CTI与实用场景驱动测试之间的差距，提高了组织的网络防御能力。

Abstract: Understanding the risks associated with an enterprise environment is the first step toward improving its security. Organizations employ various methods to assess and prioritize the risks identified in cyber threat intelligence (CTI) reports that may be relevant to their operations. Some methodologies rely heavily on manual analysis (which requires expertise and cannot be applied frequently), while others automate the assessment, using attack graphs (AGs) or threat emulators. Such emulators can be employed in conjunction with cyber twins to avoid disruptions in live production environments when evaluating the highlighted threats. Unfortunately, the use of cyber twins in organizational networks is limited due to their inability to scale. In this paper, we propose SCyTAG, a multi-step framework that generates the minimal viable cyber twin required to assess the impact of a given attack scenario. Given the organizational computer network specifications and an attack scenario extracted from a CTI report, SCyTAG generates an AG. Then, based on the AG, it automatically constructs a cyber twin comprising the network components necessary to emulate the attack scenario and assess the relevance and risks of the attack to the organization. We evaluate SCyTAG on both a real and fictitious organizational network. The results show that compared to the full topology, SCyTAG reduces the number of network components needed for emulation by up to 85% and halves the amount of required resources while preserving the fidelity of the emulated attack. SCyTAG serves as a cost-effective, scalable, and highly adaptable threat assessment solution, improving organizational cyber defense by bridging the gap between abstract CTI and practical scenario-driven testing.

</details>


### [9] [When RSA Fails: Exploiting Prime Selection Vulnerabilities in Public Key Cryptography](https://arxiv.org/abs/2512.22720)
*Murtaza Nikzad,Kerem Atas*

Main category: cs.CR

TL;DR: 该论文分析了RSA密码系统中由于素数选择不当导致的漏洞，重点研究了费马分解法和GCD攻击两种攻击向量，揭示了这些漏洞在现实世界密码实现中仍然普遍存在，主要原因是嵌入式设备中的弱随机数生成。


<details>
  <summary>Details</summary>
Motivation: 研究RSA密码系统中因素数选择不当而产生的安全漏洞，特别是针对费马分解法和GCD攻击这两种攻击向量，旨在揭示这些看似基础但仍在现实世界系统中普遍存在的安全问题。

Method: 通过分析两种主要攻击向量：1) 费马分解法 - 利用生成过于接近的素数对；2) GCD攻击 - 利用共享公因子的素数。研究借鉴了Heninger等人的"挖掘你的P和Q"研究和Böck的2023年费马分解分析等里程碑研究。

Result: 分析显示这些漏洞在现实世界的密码实现中仍然普遍存在，Heninger等人的研究发现超过64,000个易受攻击的TLS主机。主要原因是嵌入式设备中的弱随机数生成。

Conclusion: 论文强调了RSA密钥生成中适当素数选择的重要性，提出了缓解策略，包括正确的熵收集和素数验证检查，以防止这些基础但危险的攻击。

Abstract: This paper explores vulnerabilities in RSA cryptosystems that arise from improper prime number selection during key generation. We examine two primary attack vectors: Fermat's factorization method, which exploits RSA keys generated with primes that are too close together, and the Greatest Common Divisor (GCD) attack, which exploits keys that share a common prime factor. Drawing from landmark research including Heninger et al.'s ``Mining Your Ps and Qs'' study, which discovered over 64,000 vulnerable TLS hosts, and B{ö}ck's 2023 analysis of Fermat factorization in deployed systems, we demonstrate that these vulnerabilities remain prevalent in real-world cryptographic implementations. Our analysis reveals that weak random number generation in embedded devices is the primary cause of these failures, and we discuss mitigation strategies including proper entropy collection and prime validation checks.

</details>


### [10] [Identifying social bots via heterogeneous motifs based on Naïve Bayes model](https://arxiv.org/abs/2512.22759)
*Yijun Ran,Jingjing Xiao,Xiao-Ke Xu*

Main category: cs.CR

TL;DR: 提出基于异构motifs的社交机器人检测理论框架，通过节点标签信息细化motifs，系统评估不同节点对贡献，数学量化motif最大能力，在四个基准数据集上超越现有方法。


<details>
  <summary>Details</summary>
Motivation: 现有拓扑方法未能充分考虑邻居偏好的异质性，缺乏系统理论基础，主要依赖直觉和经验。社交机器人对社交媒体生态系统影响重大，检测成为关键挑战。

Method: 基于朴素贝叶斯模型，将同质motifs细化为异构motifs，融入节点标签信息捕捉邻居偏好异质性。系统评估异构motifs中不同节点对贡献，数学量化每个异构motif的最大能力。

Result: 在四个大型公开基准数据集上超越最先进技术，在五个评估指标上实现优越性能。发现选择最高能力motifs能达到与使用所有异构motifs相当的检测性能。

Conclusion: 该框架为社交机器人检测提供了有效且理论基础的解决方案，显著增强了社交网络的网络安全措施。异构motifs能有效捕捉社交网络中的复杂交互模式。

Abstract: Identifying social bots has become a critical challenge due to their significant influence on social media ecosystems. Despite advancements in detection methods, most topology-based approaches insufficiently account for the heterogeneity of neighborhood preferences and lack a systematic theoretical foundation, relying instead on intuition and experience. Here, we propose a theoretical framework for detecting social bots utilizing heterogeneous motifs based on the Naïve Bayes model. Specifically, we refine homogeneous motifs into heterogeneous ones by incorporating node-label information, effectively capturing the heterogeneity of neighborhood preferences. Additionally, we systematically evaluate the contribution of different node pairs within heterogeneous motifs to the likelihood of a node being identified as a social bot. Furthermore, we mathematically quantify the maximum capability of each heterogeneous motif, enabling the estimation of its potential benefits. Comprehensive evaluations on four large, publicly available benchmarks confirm that our method surpasses state-of-the-art techniques, achieving superior performance across five evaluation metrics. Moreover, our results reveal that selecting motifs with the highest capability achieves detection performance comparable to using all heterogeneous motifs. Overall, our framework offers an effective and theoretically grounded solution for social bot detection, significantly enhancing cybersecurity measures in social networks.

</details>


### [11] [A generalized motif-based Naïve Bayes model for sign prediction in complex networks](https://arxiv.org/abs/2512.22765)
*Yijun Ran,Si-Yuan Liu,Junjie Huang,Tao Jia,Xiao-Ke Xu*

Main category: cs.CR

TL;DR: 提出一个可泛化的符号预测框架，通过角色函数量化邻居节点的异质性影响，从单motif扩展到多motif，其中FGMNB模型在多个真实符号网络上优于现有嵌入方法。


<details>
  <summary>Details</summary>
Motivation: 传统基于motif的朴素贝叶斯模型假设所有邻居节点对目标链接符号的贡献相等，忽略了邻居间的异质性影响，这限制了模型性能。需要建模这种异质性来提升符号预测效果。

Method: 设计两个角色函数来量化邻居节点的差异化影响，从单motif扩展到多motif：1）广义多motif朴素贝叶斯模型线性组合不同motif信息；2）特征驱动的广义motif朴素贝叶斯（FGMNB）模型使用机器学习集成高维motif特征。

Result: 在四个真实符号网络上的实验表明，FGMNB在三个网络上持续优于五种最先进的嵌入基线方法。不同数据集中最具预测性的motif结构各不相同，凸显了局部结构模式的重要性。

Conclusion: 该框架为符号预测提供了有效且理论基础的解决方案，对增强在线平台的信任和安全具有实际意义，同时为基于motif的特征工程提供了有价值的见解。

Abstract: Signed networks, encoding both positive and negative interactions, are essential for modeling complex systems in social and financial domains. Sign prediction, which infers the sign of a target link, has wide-ranging practical applications. Traditional motif-based Naïve Bayes models assume that all neighboring nodes contribute equally to a target link's sign, overlooking the heterogeneous influence among neighbors and potentially limiting performance. To address this, we propose a generalizable sign prediction framework that explicitly models the heterogeneity. Specifically, we design two role functions to quantify the differentiated influence of neighboring nodes. We further extend this approach from a single motif to multiple motifs via two strategies. The generalized multiple motifs-based Naïve Bayes model linearly combines information from diverse motifs, while the Feature-driven Generalized Motif-based Naïve Bayes (FGMNB) model integrates high-dimensional motif features using machine learning. Extensive experiments on four real-world signed networks show that FGMNB consistently outperforms five state-of-the-art embedding-based baselines on three of these networks. Moreover, we observe that the most predictive motif structures differ across datasets, highlighting the importance of local structural patterns and offering valuable insights for motif-based feature engineering. Our framework provides an effective and theoretically grounded solution to sign prediction, with practical implications for enhancing trust and security in online platforms.

</details>


### [12] [Breaking the illusion: Automated Reasoning of GDPR Consent Violations](https://arxiv.org/abs/2512.22789)
*Ying Li,Wenjun Qiu,Faysal Hossain Shezan,Kunlin Cai,Michelangelo van Dam,Lisa Austin,David Lie,Yuan Tian*

Main category: cs.CR

TL;DR: Cosmic是一个自动化框架，用于检测网页表单中的同意相关隐私违规，在5823个网站和3598个表单中发现了大量GDPR/CCPA违规行为。


<details>
  <summary>Details</summary>
Motivation: GDPR和CCPA等隐私法规要求用户同意必须是知情、自由、具体且明确的，但现实中仍存在许多违规行为。当前研究主要关注cookie横幅和移动应用对话框，而网页表单中的同意机制多样且难以评估，导致自动化合规审计面临重大挑战。

Method: 开发了Cosmic自动化框架，用于检测网页表单中的同意相关隐私违规。该工具能够审计网页表单的合规性，覆盖5823个网站和3598个表单。

Result: Cosmic在94.1%的同意表单中检测到3384个违规行为，涵盖GDPR关键原则如自由同意、目的披露和撤回选项。检测同意和违规的真阳性率分别达到98.6%和99.1%，显示出高准确性和实际应用价值。

Conclusion: Cosmic框架能够有效自动化检测网页表单中的隐私合规违规，填补了当前研究空白，为实际隐私法规执行提供了实用工具。

Abstract: Recent privacy regulations such as the General Data Protection Regulation (GDPR) and the California Consumer Privacy Act (CCPA) have established legal requirements for obtaining user consent regarding the collection, use, and sharing of personal data. These regulations emphasize that consent must be informed, freely given, specific, and unambiguous. However, there are still many violations, which highlight a gap between legal expectations and actual implementation. Consent mechanisms embedded in functional web forms across websites play a critical role in ensuring compliance with data protection regulations such as the GDPR and CCPA, as well as in upholding user autonomy and trust. However, current research has primarily focused on cookie banners and mobile app dialogs. These forms are diverse in structure, vary in legal basis, and are often difficult to locate or evaluate, creating a significant challenge for automated consent compliance auditing. In this work, we present Cosmic, a novel automated framework for detecting consent-related privacy violations in web forms. We evaluate our developed tool for auditing consent compliance in web forms, across 5,823 websites and 3,598 forms. Cosmic detects 3,384 violations on 94.1% of consent forms, covering key GDPR principles such as freely given consent, purpose disclosure, and withdrawal options. It achieves 98.6% and 99.1% TPR for consent and violation detection, respectively, demonstrating high accuracy and real-world applicability.

</details>


### [13] [Adaptive Trust Consensus for Blockchain IoT: Comparing RL, DRL, and MARL Against Naive, Collusive, Adaptive, Byzantine, and Sleeper Attacks](https://arxiv.org/abs/2512.22860)
*Soham Padia,Dhananjay Vaidya,Ramchandra Mangrulkar*

Main category: cs.CR

TL;DR: 提出基于信任的委托共识框架，结合全同态加密和属性访问控制，并比较三种强化学习方法对抗五种攻击的效果，发现多智能体强化学习在应对合谋攻击方面表现最佳，但所有方法都对时间延迟投毒攻击脆弱。


<details>
  <summary>Details</summary>
Motivation: 保护区块链物联网网络免受复杂对抗攻击是一个关键挑战，现有方法难以有效应对信任操纵攻击，需要开发更强大的防御机制。

Method: 提出信任基委托共识框架，集成全同态加密和基于属性的访问控制进行隐私保护策略评估，结合基于学习的防御机制，系统比较三种强化学习方法：表格Q学习、深度强化学习（Dueling Double DQN）和多智能体强化学习。

Result: 在16节点模拟物联网网络上的实验显示：多智能体强化学习在合谋攻击下检测效果最佳（F1=0.85），深度强化学习和多智能体强化学习对自适应攻击达到完美检测（F1=1.00），所有智能体都能成功防御拜占庭攻击（F1=1.00），但时间延迟投毒攻击对所有智能体都是灾难性的（F1降至0.11-0.16）。

Conclusion: 协调的多智能体学习在防御区块链物联网环境中的复杂信任操纵攻击方面具有可测量的优势，但时间延迟投毒攻击揭示了信任构建对手构成的严重威胁，需要进一步研究。

Abstract: Securing blockchain-enabled IoT networks against sophisticated adversarial attacks remains a critical challenge. This paper presents a trust-based delegated consensus framework integrating Fully Homomorphic Encryption (FHE) with Attribute-Based Access Control (ABAC) for privacy-preserving policy evaluation, combined with learning-based defense mechanisms. We systematically compare three reinforcement learning approaches -- tabular Q-learning (RL), Deep RL with Dueling Double DQN (DRL), and Multi-Agent RL (MARL) -- against five distinct attack families: Naive Malicious Attack (NMA), Collusive Rumor Attack (CRA), Adaptive Adversarial Attack (AAA), Byzantine Fault Injection (BFI), and Time-Delayed Poisoning (TDP). Experimental results on a 16-node simulated IoT network reveal significant performance variations: MARL achieves superior detection under collusive attacks (F1=0.85 vs. DRL's 0.68 and RL's 0.50), while DRL and MARL both attain perfect detection (F1=1.00) against adaptive attacks where RL fails (F1=0.50). All agents successfully defend against Byzantine attacks (F1=1.00). Most critically, the Time-Delayed Poisoning attack proves catastrophic for all agents, with F1 scores dropping to 0.11-0.16 after sleeper activation, demonstrating the severe threat posed by trust-building adversaries. Our findings indicate that coordinated multi-agent learning provides measurable advantages for defending against sophisticated trust manipulation attacks in blockchain IoT environments.

</details>


### [14] [Agentic AI for Cyber Resilience: A New Security Paradigm and Its System-Theoretic Foundations](https://arxiv.org/abs/2512.22883)
*Tao Li,Quanyan Zhu*

Main category: cs.CR

TL;DR: 论文提出从预防性安全转向智能体驱动的网络韧性，利用大语言模型实现自主规划、工具编排和战略适应，通过博弈论框架设计攻防对抗的智能体工作流。


<details>
  <summary>Details</summary>
Motivation: 基于基础模型的AI正在重塑网络安全，大语言模型能够实现大规模自主规划、工具编排和战略适应，挑战了基于静态规则、边界防御和人工工作流的传统安全架构，需要转向更具韧性的安全范式。

Method: 提出系统级框架设计智能体AI工作流，引入通用智能体架构，分析攻防工作流作为耦合自适应过程，使用博弈论公式化作为自主分配、信息流和时间组合的统一设计语言，并通过自动渗透测试、修复和网络欺骗案例研究说明。

Result: 开发了基于均衡的系统级韧性设计方法，展示了如何通过博弈论框架实现攻防智能体工作流的有效协调，使系统能够在攻击下保持关键功能并高效恢复。

Conclusion: 网络安全需要从预防为中心转向智能体驱动的韧性范式，AI增强的自主智能体直接参与网络和网络物理系统的感知、推理、行动和适应，基于博弈论的均衡设计为实现系统级网络韧性提供了统一框架。

Abstract: Cybersecurity is being fundamentally reshaped by foundation-model-based artificial intelligence. Large language models now enable autonomous planning, tool orchestration, and strategic adaptation at scale, challenging security architectures built on static rules, perimeter defenses, and human-centered workflows. This chapter argues for a shift from prevention-centric security toward agentic cyber resilience. Rather than seeking perfect protection, resilient systems must anticipate disruption, maintain critical functions under attack, recover efficiently, and learn continuously. We situate this shift within the historical evolution of cybersecurity paradigms, culminating in an AI-augmented paradigm where autonomous agents participate directly in sensing, reasoning, action, and adaptation across cyber and cyber-physical systems. We then develop a system-level framework for designing agentic AI workflows. A general agentic architecture is introduced, and attacker and defender workflows are analyzed as coupled adaptive processes, and game-theoretic formulations are shown to provide a unifying design language for autonomy allocation, information flow, and temporal composition. Case studies in automated penetration testing, remediation, and cyber deception illustrate how equilibrium-based design enables system-level resiliency design.

</details>


### [15] [DECEPTICON: How Dark Patterns Manipulate Web Agents](https://arxiv.org/abs/2512.22894)
*Phil Cuvin,Hao Zhu,Diyi Yang*

Main category: cs.CR

TL;DR: 暗模式（欺骗性UI设计）对AI代理构成严重风险，在70%以上任务中能成功操纵代理轨迹，而人类平均只有31%。更大的模型和推理能力反而使其更易受攻击。


<details>
  <summary>Details</summary>
Motivation: 暗模式（欺骗性UI设计）在网络上广泛存在，能操纵用户执行与其目标不符的操作。本研究旨在量化暗模式对AI代理的操纵风险，揭示其对代理鲁棒性的威胁。

Method: 开发了DECEPTICON测试环境，包含700个网页导航任务（600个生成任务和100个真实世界任务），用于单独测试各种暗模式。测量指令遵循成功率和暗模式有效性，评估最先进AI代理的表现。

Result: 暗模式在超过70%的生成和真实世界任务中成功操纵代理轨迹（人类平均31%）。暗模式有效性随模型大小和推理能力增加而增加。现有对抗攻击防御措施（包括上下文提示和护栏模型）无法有效降低暗模式成功率。

Conclusion: 暗模式是网页代理的潜在且未缓解的风险，更大的模型反而更易受攻击。当前防御措施无效，迫切需要开发针对操纵性设计的鲁棒防御机制。

Abstract: Deceptive UI designs, widely instantiated across the web and commonly known as dark patterns, manipulate users into performing actions misaligned with their goals. In this paper, we show that dark patterns are highly effective in steering agent trajectories, posing a significant risk to agent robustness. To quantify this risk, we introduce DECEPTICON, an environment for testing individual dark patterns in isolation. DECEPTICON includes 700 web navigation tasks with dark patterns -- 600 generated tasks and 100 real-world tasks, designed to measure instruction-following success and dark pattern effectiveness. Across state-of-the-art agents, we find dark patterns successfully steer agent trajectories towards malicious outcomes in over 70% of tested generated and real-world tasks -- compared to a human average of 31%. Moreover, we find that dark pattern effectiveness correlates positively with model size and test-time reasoning, making larger, more capable models more susceptible. Leading countermeasures against adversarial attacks, including in-context prompting and guardrail models, fail to consistently reduce the success rate of dark pattern interventions. Our findings reveal dark patterns as a latent and unmitigated risk to web agents, highlighting the urgent need for robust defenses against manipulative designs.

</details>


### [16] [SecureBank: A Financially-Aware Zero Trust Architecture for High-Assurance Banking Systems](https://arxiv.org/abs/2512.23124)
*Paulo Fernandes Biao*

Main category: cs.CR

TL;DR: SecureBank是一个针对高保障银行系统的财务感知、上下文自适应的零信任架构，集成了财务零信任、自适应身份评分、上下文微分割和影响驱动的安全自动化，显著提升了自动化攻击处理和身份信任适应能力。


<details>
  <summary>Details</summary>
Motivation: 金融机构日益依赖分布式架构、开放银行API、云原生基础设施和高频数字交易，这些转变扩大了攻击面并暴露了传统基于边界的安全模型的局限性。虽然零信任架构提供了基本安全原则，但现有框架大多未明确纳入交易语义、金融风险建模、自适应身份信任或基于经济影响的自动化。

Method: 提出了SecureBank框架，集成了四个核心组件：财务零信任、自适应身份评分、上下文微分割和影响驱动的安全自动化。使用蒙特卡洛模拟评估SecureBank与基于规则的基线架构，采用交易完整性指数(TII)、身份信任适应水平(ITAL)和安全自动化效率(SAE)等指标。

Result: SecureBank显著改善了自动化攻击处理，加速了身份信任适应，同时保持了保守且符合监管要求的交易完整性水平。实验验证表明该架构在金融环境中具有优越性能。

Conclusion: SecureBank不仅提供了实验验证，还旨在作为受监管金融环境中财务感知零信任系统的参考架构和评估基准，为高保障银行系统提供专门设计的安全解决方案。

Abstract: Financial institutions increasingly rely on distributed architectures, open banking APIs, cloud native infrastructures, and high frequency digital transactions. These transformations expand the attack surface and expose limitations in traditional perimeter based security models. While Zero Trust architectures provide essential security principles, most existing frameworks do not explicitly incorporate transactional semantics, financial risk modeling, adaptive identity trust, or automation weighted by economic impact.
  This paper introduces SecureBank, a financially aware and context adaptive Zero Trust architecture designed specifically for high assurance banking systems. The proposed framework integrates Financial Zero Trust, Adaptive Identity Scoring, Contextual Micro Segmentation, and Impact Driven Security Automation. A Monte Carlo simulation evaluates SecureBank against a representative rule based baseline architecture using metrics such as the Transactional Integrity Index (TII), Identity Trust Adaptation Level (ITAL), and Security Automation Efficiency (SAE).
  The results demonstrate that SecureBank significantly improves automated attack handling and accelerates identity trust adaptation while preserving conservative and regulator aligned levels of transactional integrity. Beyond experimental validation, SecureBank is intended to serve as a reference architecture and evaluation baseline for financially aware Zero Trust systems in regulated financial environments.

</details>


### [17] [Multi-Agent Framework for Threat Mitigation and Resilience in AI-Based Systems](https://arxiv.org/abs/2512.23132)
*Armstrong Foundjem,Lionel Nganyewou Tidjon,Leuson Da Silva,Foutse Khomh*

Main category: cs.CR

TL;DR: 该研究系统分析了机器学习安全风险，识别了93种威胁，构建了本体驱动的威胁图谱，揭示了商业LLM API模型窃取等未报告威胁，并提出了ML专用安全框架建议。


<details>
  <summary>Details</summary>
Motivation: 机器学习在金融、医疗等关键领域支撑基础模型，成为数据投毒、模型提取、提示注入等攻击的目标。传统网络安全缺乏针对基础模型、多模态和RAG系统的ML专用威胁建模，需要系统分析ML安全风险。

Method: 从MITRE ATLAS（26个）、AI事件数据库（12个）和文献（55个）提取93种威胁，分析854个GitHub/Python仓库。使用多代理RAG系统（ChatGPT-4o，温度0.4）挖掘300+文章，构建本体驱动的威胁图谱，链接TTPs、漏洞和生命周期阶段。

Result: 识别了未报告的威胁，包括商业LLM API模型窃取、参数记忆泄漏和偏好引导的纯文本越狱。主要TTPs包括MASTERKEY风格越狱、联邦投毒、扩散后门和偏好优化泄漏，主要影响预训练和推理阶段。图谱分析显示库中存在密集漏洞集群且补丁传播差。

Conclusion: 需要自适应、ML专用的安全框架，结合依赖卫生、威胁情报和监控，以减轻ML生命周期中的供应链和推理风险。

Abstract: Machine learning (ML) underpins foundation models in finance, healthcare, and critical infrastructure, making them targets for data poisoning, model extraction, prompt injection, automated jailbreaking, and preference-guided black-box attacks that exploit model comparisons. Larger models can be more vulnerable to introspection-driven jailbreaks and cross-modal manipulation. Traditional cybersecurity lacks ML-specific threat modeling for foundation, multimodal, and RAG systems. Objective: Characterize ML security risks by identifying dominant TTPs, vulnerabilities, and targeted lifecycle stages. Methods: We extract 93 threats from MITRE ATLAS (26), AI Incident Database (12), and literature (55), and analyze 854 GitHub/Python repositories. A multi-agent RAG system (ChatGPT-4o, temp 0.4) mines 300+ articles to build an ontology-driven threat graph linking TTPs, vulnerabilities, and stages. Results: We identify unreported threats including commercial LLM API model stealing, parameter memorization leakage, and preference-guided text-only jailbreaks. Dominant TTPs include MASTERKEY-style jailbreaking, federated poisoning, diffusion backdoors, and preference optimization leakage, mainly impacting pre-training and inference. Graph analysis reveals dense vulnerability clusters in libraries with poor patch propagation. Conclusion: Adaptive, ML-specific security frameworks, combining dependency hygiene, threat intelligence, and monitoring, are essential to mitigate supply-chain and inference risks across the ML lifecycle.

</details>


### [18] [Certifying the Right to Be Forgotten: Primal-Dual Optimization for Sample and Label Unlearning in Vertical Federated Learning](https://arxiv.org/abs/2512.23171)
*Yu Jiang,Xindi Tong,Ziyao Liu,Xiaoxi Zhang,Kwok-Yan Lam,Chee Wei Tan*

Main category: cs.CR

TL;DR: FedORA是一个用于垂直联邦学习(VFL)中样本和标签遗忘的新方法，通过原始-对偶优化框架解决数据移除问题，在保持模型效用的同时降低计算和通信开销。


<details>
  <summary>Details</summary>
Motivation: 垂直联邦学习中的遗忘问题具有挑战性，因为不同参与方持有相同样本的互补特征，遗忘任务需要跨方协调，导致计算开销和特征依赖复杂性。现有研究主要集中在水平联邦学习，VFL中的遗忘问题尚未得到充分解决。

Method: 提出FedORA方法，将样本或标签移除问题形式化为约束优化问题，使用原始-对偶框架求解。引入新的遗忘损失函数促进分类不确定性而非错误分类，采用自适应步长增强稳定性，使用非对称批次设计根据剩余数据对模型的先验影响来差异化处理遗忘数据和保留数据。

Result: 理论分析证明FedORA与从头训练模型的差异有界，建立了遗忘有效性的保证。在表格和图像数据集上的实验表明，FedORA在减少计算和通信开销的同时，实现了与从头训练相当的遗忘有效性和效用保持。

Conclusion: FedORA为垂直联邦学习中的样本和标签遗忘提供了一个有效的解决方案，通过优化框架实现了隐私保护与模型效用的平衡，为"被遗忘权"在分布式特征架构中的实现提供了可行途径。

Abstract: Federated unlearning has become an attractive approach to address privacy concerns in collaborative machine learning, for situations when sensitive data is remembered by AI models during the machine learning process. It enables the removal of specific data influences from trained models, aligning with the growing emphasis on the "right to be forgotten." While extensively studied in horizontal federated learning, unlearning in vertical federated learning (VFL) remains challenging due to the distributed feature architecture. VFL unlearning includes sample unlearning that removes specific data points' influence and label unlearning that removes entire classes. Since different parties hold complementary features of the same samples, unlearning tasks require cross-party coordination, creating computational overhead and complexities from feature interdependencies. To address such challenges, we propose FedORA (Federated Optimization for data Removal via primal-dual Algorithm), designed for sample and label unlearning in VFL. FedORA formulates the removal of certain samples or labels as a constrained optimization problem solved using a primal-dual framework. Our approach introduces a new unlearning loss function that promotes classification uncertainty rather than misclassification. An adaptive step size enhances stability, while an asymmetric batch design, considering the prior influence of the remaining data on the model, handles unlearning and retained data differently to efficiently reduce computational costs. We provide theoretical analysis proving that the model difference between FedORA and Train-from-scratch is bounded, establishing guarantees for unlearning effectiveness. Experiments on tabular and image datasets demonstrate that FedORA achieves unlearning effectiveness and utility preservation comparable to Train-from-scratch with reduced computation and communication overhead.

</details>


### [19] [EquaCode: A Multi-Strategy Jailbreak Approach for Large Language Models via Equation Solving and Code Completion](https://arxiv.org/abs/2512.23173)
*Zhen Liang,Hai Huang,Zhengkui Chen*

Main category: cs.CR

TL;DR: Equacode是一种新颖的多策略越狱攻击方法，通过将恶意意图转化为数学问题并让LLM用代码解决，利用跨领域任务的复杂性来绕过安全约束。


<details>
  <summary>Details</summary>
Motivation: 现有越狱攻击主要在自然语言层面且依赖单一攻击策略，限制了全面评估LLM鲁棒性的能力。需要更有效的多策略方法来测试LLM的安全性。

Method: 将恶意意图转化为数学问题，然后要求LLM使用代码解决该问题。利用跨领域任务（数学+编程）的复杂性，分散模型对安全约束的注意力。

Result: 在GPT系列上平均成功率91.19%，在3个最先进的LLM上达到98.65%，且仅需单次查询。消融实验显示数学方程模块和代码模块的组合效果优于单独使用任一模块。

Conclusion: 多策略方法（数学方程+代码完成）具有强大的协同效应，能够有效绕过LLM的安全约束，为评估LLM鲁棒性提供了新视角。

Abstract: Large language models (LLMs), such as ChatGPT, have achieved remarkable success across a wide range of fields. However, their trustworthiness remains a significant concern, as they are still susceptible to jailbreak attacks aimed at eliciting inappropriate or harmful responses. However, existing jailbreak attacks mainly operate at the natural language level and rely on a single attack strategy, limiting their effectiveness in comprehensively assessing LLM robustness. In this paper, we propose Equacode, a novel multi-strategy jailbreak approach for large language models via equation-solving and code completion. This approach transforms malicious intent into a mathematical problem and then requires the LLM to solve it using code, leveraging the complexity of cross-domain tasks to divert the model's focus toward task completion rather than safety constraints. Experimental results show that Equacode achieves an average success rate of 91.19% on the GPT series and 98.65% across 3 state-of-the-art LLMs, all with only a single query. Further, ablation experiments demonstrate that EquaCode outperforms either the mathematical equation module or the code module alone. This suggests a strong synergistic effect, thereby demonstrating that multi-strategy approach yields results greater than the sum of its parts.

</details>


### [20] [Multiparty Authorization for Secure Data Storage in Cloud Environments using Improved Attribute-Based Encryption](https://arxiv.org/abs/2512.23216)
*Partha Paul,Keshav Sinha*

Main category: cs.CR

TL;DR: 提出基于功能流密码的改进属性基加密方案，用于云环境下的安全数据存储和访问控制，支持多用户授权并抵抗碰撞攻击。


<details>
  <summary>Details</summary>
Motivation: 云环境中存储敏感数据面临数据请求频率高（增加服务器计算开销）和数据存储泄露等问题，需要有效的安全访问控制技术。

Method: 使用功能流密码改进属性基加密，基于抛物线上的标量点实现多方授权，采用Shamir秘密共享生成授权点，2D-Lagrange插值重构秘密点，设定阈值(Ts>3)要求合法授权用户重构属性关联密钥。

Result: 方案具有最小存储开销，抵抗碰撞攻击，加密时间随授权策略属性数量增加而增加，通过NIST统计测试、相关系数和直方图分析验证加密质量。

Conclusion: 提出的方案在云环境中更健壮和安全，能有效保护数据存储并控制授权访问。

Abstract: In todays scenario, various organizations store their sensitive data in the cloud environment. Multiple problems are present while retrieving and storing vast amounts of data, such as the frequency of data requests (increasing the computational overhead of the server) and data leakage while storing. To cope with said problem, Attribute-Based Encryption (ABE) is one of the potential security and access control techniques for secure data storage and authorization. The proposed work divides into two objectives: (i) provide access to authorized users and (ii) secure data storage in a cloud environment. The improved ABE using Functional Based Stream Cipher (FBSE) is proposed for data storage. The proposed technique uses simple scalar points over a parabolic curve to provide multiparty authorization. The authorization points are generated and share only with the authorized recipients. The Shamir secret sharing technique generate the authorization points and 2D-Lagrange Interpolation is used to reconstruct the secret points from regular parabola. The proposed scheme has specified the threshold (Ts>3) legally authorized users to reconstruct the attribute-associated keys for decryption. The encryption of data is evaluated using Statistical analysis (NIST Statistical Test Suite, Correlation Coefficient, and Histogram) test to investigate image pixel deviation. The parameters like encryption and decryption are used for performance analysis, where an increase in the number of attributes for the authorization policy will increase the encryption time. The proposed scheme imposes minimal storage overhead, irrespective of the users identity. The security analysis evidence that it resists collision attacks. The security and performance analysis results demonstrate that the proposed scheme is more robust and secure.

</details>


### [21] [RobustMask: Certified Robustness against Adversarial Neural Ranking Attack via Randomized Masking](https://arxiv.org/abs/2512.23307)
*Jiawei Liu,Zhuo Chen,Rui Zhu,Miaokun Chen,Yuyang Gong,Wei Lu,Xiaofeng Wang*

Main category: cs.CR

TL;DR: 提出RobustMask防御方法，结合预训练语言模型和随机掩码平滑机制，增强神经排序模型对抗字符、词、短语级对抗攻击的能力，并提供理论上的top-K鲁棒性证明。


<details>
  <summary>Details</summary>
Motivation: 神经排序模型在RAG等应用中广泛部署，但容易受到字符、词、短语级对抗攻击的影响，现有防御方法要么依赖泛化能力差的启发式方法，要么假设过强的对抗知识，限制了实际应用。

Method: 提出RobustMask防御框架，结合预训练语言模型的上下文预测能力和基于随机掩码的平滑机制，利用排序模型的成对比较能力和概率统计分析，提供理论上的认证top-K鲁棒性。

Result: 实验表明RobustMask能够成功认证超过20%的候选文档在top-10排名位置中，对抗影响高达30%内容的对抗扰动，显著增强了神经排序模型的对抗鲁棒性。

Conclusion: RobustMark为神经排序模型提供了有效的对抗防御解决方案，通过理论证明和实验验证展示了其在增强检索系统安全性方面的有效性，是向实际检索系统提供更强安全保障的重要一步。

Abstract: Neural ranking models have achieved remarkable progress and are now widely deployed in real-world applications such as Retrieval-Augmented Generation (RAG). However, like other neural architectures, they remain vulnerable to adversarial manipulations: subtle character-, word-, or phrase-level perturbations can poison retrieval results and artificially promote targeted candidates, undermining the integrity of search engines and downstream systems. Existing defenses either rely on heuristics with poor generalization or on certified methods that assume overly strong adversarial knowledge, limiting their practical use. To address these challenges, we propose RobustMask, a novel defense that combines the context-prediction capability of pretrained language models with a randomized masking-based smoothing mechanism. Our approach strengthens neural ranking models against adversarial perturbations at the character, word, and phrase levels. Leveraging both the pairwise comparison ability of ranking models and probabilistic statistical analysis, we provide a theoretical proof of RobustMask's certified top-K robustness. Extensive experiments further demonstrate that RobustMask successfully certifies over 20% of candidate documents within the top-10 ranking positions against adversarial perturbations affecting up to 30% of their content. These results highlight the effectiveness of RobustMask in enhancing the adversarial robustness of neural ranking models, marking a significant step toward providing stronger security guarantees for real-world retrieval systems.

</details>


### [22] [Fuzzilicon: A Post-Silicon Microcode-Guided x86 CPU Fuzzer](https://arxiv.org/abs/2512.23438)
*Johannes Lenzen,Mohamadreza Rostami,Lichao Wu,Ahmad-Reza Sadeghi*

Main category: cs.CR

TL;DR: Fuzzilicon是首个针对真实x86 CPU的后硅片模糊测试框架，通过逆向工程Intel微码更新接口实现微架构级反馈，自动发现CPU漏洞。


<details>
  <summary>Details</summary>
Motivation: 现代CPU是黑盒且存在复杂微架构缺陷，传统分析方法难以检测。现有漏洞发现依赖繁琐的手动逆向工程，缺乏自动化系统化检测框架。

Method: 逆向工程Intel专有微码更新接口，开发最小侵入式微码级插桩技术，结合基于hypervisor的模糊测试框架，实现精确反馈引导的输入生成。

Result: 在Intel Goldmont微架构中发现5个重要发现，包括2个新的微码级推测执行漏洞；自动重新发现μSpectre类漏洞；覆盖率收集开销降低31倍，实现16.27%可钩挂位置的微码覆盖率。

Conclusion: Fuzzilicon建立了后硅片模糊测试的新基础，为自动化发现复杂CPU漏洞提供了实用、覆盖引导且可扩展的方法。

Abstract: Modern CPUs are black boxes, proprietary, and increasingly characterized by sophisticated microarchitectural flaws that evade traditional analysis. While some of these critical vulnerabilities have been uncovered through cumbersome manual effort, building an automated and systematic vulnerability detection framework for real-world post-silicon processors remains a challenge.
  In this paper, we present Fuzzilicon, the first post-silicon fuzzing framework for real-world x86 CPUs that brings deep introspection into the microcode and microarchitectural layers. Fuzzilicon automates the discovery of vulnerabilities that were previously only detectable through extensive manual reverse engineering, and bridges the visibility gap by introducing microcode-level instrumentation. At the core of Fuzzilicon is a novel technique for extracting feedback directly from the processor's microarchitecture, enabled by reverse-engineering Intel's proprietary microcode update interface. We develop a minimally intrusive instrumentation method and integrate it with a hypervisor-based fuzzing harness to enable precise, feedback-guided input generation, without access to Register Transfer Level (RTL).
  Applied to Intel's Goldmont microarchitecture, Fuzzilicon introduces 5 significant findings, including two previously unknown microcode-level speculative-execution vulnerabilities. Besides, the Fuzzilicon framework automatically rediscover the $μ$Spectre class of vulnerabilities, which were detected manually in the previous work. Fuzzilicon reduces coverage collection overhead by up to 31$\times$ compared to baseline techniques and achieves 16.27% unique microcode coverage of hookable locations, the first empirical baseline of its kind. As a practical, coverage-guided, and scalable approach to post-silicon fuzzing, Fuzzilicon establishes a new foundation to automate the discovery of complex CPU vulnerabilities.

</details>


### [23] [Agentic AI for Autonomous Defense in Software Supply Chain Security: Beyond Provenance to Vulnerability Mitigation](https://arxiv.org/abs/2512.23480)
*Toqeer Ali Syed,Mohammad Riyaz Belgaum,Salman Jan,Asadullah Abdullah Khan,Saad Said Alqahtani*

Main category: cs.CR

TL;DR: 论文提出基于智能体AI的自主软件供应链安全框架，结合LLM推理、强化学习和多智能体协调，实现主动漏洞识别与缓解，相比传统方法有更好的检测精度和更低的缓解延迟。


<details>
  <summary>Details</summary>
Motivation: 传统软件供应链攻击已转向可信开发和交付流程，使得传统构建后完整性机制失效。现有框架如SLSA、SBOM和in-toto主要提供来源追溯，但缺乏主动识别和消除漏洞的能力。

Method: 提出基于智能体AI的自主软件供应链安全系统，结合LLM语义漏洞分析和可解释决策、强化学习自适应缓解策略、多智能体协调（使用LangChain和LangGraph），通过MCP协议与真实CI/CD环境交互，并将所有观察和行动记录在区块链安全账本中确保完整性和可审计性。

Result: 在模拟流水线和真实CI/CD环境（GitHub Actions和Jenkins）中测试，涵盖注入攻击、不安全反序列化、访问控制违规和配置错误等场景。实验结果显示比基于规则、仅来源追溯和仅强化学习的基线方法有更好的检测精度、更短的缓解延迟和合理的构建时间开销。

Conclusion: 智能体AI能够促进软件供应链从被动验证向主动防御、自我保护的转变，实现更安全的软件生产环境。

Abstract: The software supply chain attacks are becoming more and more focused on trusted development and delivery procedures, so the conventional post-build integrity mechanisms cannot be used anymore. The available frameworks like SLSA, SBOM and in toto are majorly used to offer provenance and traceability but do not have the capabilities of actively identifying and removing vulnerabilities in software production. The current paper includes an example of agentic artificial intelligence (AI) based on autonomous software supply chain security that combines large language model (LLM)-based reasoning, reinforcement learning (RL), and multi-agent coordination. The suggested system utilizes specialized security agents coordinated with the help of LangChain and LangGraph, communicates with actual CI/CD environments with the Model Context Protocol (MCP), and documents all the observations and actions in a blockchain security ledger to ensure integrity and auditing. Reinforcement learning can be used to achieve adaptive mitigation strategies that consider the balance between security effectiveness and the operational overhead, and LLMs can be used to achieve semantic vulnerability analysis, as well as explainable decisions. This framework is tested based on simulated pipelines, as well as, actual world CI/CD integrations on GitHub Actions and Jenkins, including injection attacks, insecure deserialization, access control violations, and configuration errors. Experimental outcomes indicate better detection accuracy, shorter mitigation latency and reasonable build-time overhead than rule-based, provenance only and RL only baselines. These results show that agentic AI can facilitate the transition to self defending, proactive software supply chains rather than reactive verification ones.

</details>


### [24] [A Privacy Protocol Using Ephemeral Intermediaries and a Rank-Deficient Matrix Power Function (RDMPF)](https://arxiv.org/abs/2512.23535)
*Eduardo Salazar*

Main category: cs.CR

TL;DR: 为Internet Computer设计的隐私传输架构，通过短暂中介实现存款与取款的解耦，使用RDMPF封装和公共提示实现匿名发现，提供身份隐私和内容机密性。


<details>
  <summary>Details</summary>
Motivation: 在区块链环境中实现隐私保护的资产转移，解决传统传输中身份暴露和中介可追踪的问题，为Internet Computer提供安全、隐私的传输协议。

Method: 使用两个短暂中介解耦存款和取款，采用非交互式RDMPF封装生成传输密钥，通过公共提示实现匿名发现，授权使用解密证明而不暴露身份，所有中介都是临时的并发布销毁证明。

Result: 协议已在ICP上以ICPP名称投入生产，经过全面测试并包含增强功能，提供发送方身份隐私、内容机密性、传输密钥前向安全性、可验证的活跃性和最终性。

Conclusion: 该设计为ICP提供了完整的隐私传输参考实现，通过形式化接口和安全论证确保了协议的正确性和隐私保护特性，现已成为公开可访问的协议标准。

Abstract: This paper presents a private transfer architecture for the Internet Computer (ICP) that decouples deposit and retrieval through two short-lived intermediaries, with sealed storage and attested teardown by an ephemeral witness. The protocol uses a non-interactive RDMPF-based encapsulation to derive per-transfer transport keys. A public notice hint is computed from the capsule to enable discovery without fingerprinting the recipient's key. Retrieval is authorized by a short proof of decapsulation that reveals no identities. All transaction intermediaries are ephemeral and issue certified destruction intents and proofs, allowing a noticeboard to publish auditable finalization records. The design provides sender identity privacy with respect to the recipient, content confidentiality against intermediaries, forward secrecy for transport keys after staged destruction, verifiable liveness and finality. We formalize the basic interfaces, provide the security arguments for encapsulation correctness, hint privacy, authorization soundness and timeout reclaim.
  In terms of implementation, it has been recently brought into production on the ICP under the name ICPP. It has been subject to exhaustive testing and incorporates a few enhancements, focusing on the operational possibilities offered by ICP's technology. This work hence serves as a broad reference for the protocol now publicly accessible.

</details>


### [25] [Toward Trustworthy Agentic AI: A Multimodal Framework for Preventing Prompt Injection Attacks](https://arxiv.org/abs/2512.23557)
*Toqeer Ali Syed,Mishal Ateeq Almutairi,Mahmoud Abdel Moaty*

Main category: cs.CR

TL;DR: 提出跨智能体多模态溯源感知防御框架，通过提示净化与输出验证来防范多模态提示注入攻击，保障多智能体系统的安全性。


<details>
  <summary>Details</summary>
Motivation: 随着LLM、VLM及LangChain/GraphChain等多智能体系统的发展，多模态提示注入攻击风险增加，恶意指令可能通过文本、图像、元数据或智能体间通信传播，导致意外行为、策略违反或状态破坏。

Method: 提出跨智能体多模态溯源感知防御框架，包含文本净化智能体、视觉净化智能体和输出验证智能体，由溯源账本协调管理。该框架对所有提示（用户生成或上游智能体产生）进行净化处理，并在发送到下游节点前独立验证LLM输出，通过元数据记录模态、来源和信任级别，确保智能体间通信遵循明确的信任框架。

Result: 实验评估显示，该框架显著提高了多模态注入检测准确率，最小化了跨智能体信任泄漏，并使智能体执行路径更加稳定。

Conclusion: 该框架将溯源追踪和验证概念扩展到多智能体编排领域，有助于建立安全、可理解和可靠的多智能体AI系统。

Abstract: Powerful autonomous systems, which reason, plan, and converse using and between numerous tools and agents, are made possible by Large Language Models (LLMs), Vision-Language Models (VLMs), and new agentic AI systems, like LangChain and GraphChain. Nevertheless, this agentic environment increases the probability of the occurrence of multimodal prompt injection (PI) attacks, in which concealed or malicious instructions carried in text, pictures, metadata, or agent-to-agent messages may spread throughout the graph and lead to unintended behavior, a breach of policy, or corruption of state. In order to mitigate these risks, this paper suggests a Cross-Agent Multimodal Provenanc- Aware Defense Framework whereby all the prompts, either user-generated or produced by upstream agents, are sanitized and all the outputs generated by an LLM are verified independently before being sent to downstream nodes. This framework contains a Text sanitizer agent, visual sanitizer agent, and output validator agent all coordinated by a provenance ledger, which keeps metadata of modality, source, and trust level throughout the entire agent network. This architecture makes sure that agent-to-agent communication abides by clear trust frames such such that injected instructions are not propagated down LangChain or GraphChain-style-workflows. The experimental assessments show that multimodal injection detection accuracy is significantly enhanced, and the cross-agent trust leakage is minimized, as well as, agentic execution pathways become stable. The framework, which expands the concept of provenance tracking and validation to the multi-agent orchestration, enhances the establishment of secure, understandable and reliable agentic AI systems.

</details>


### [26] [Enhanced Web Payload Classification Using WAMM: An AI-Based Framework for Dataset Refinement and Model Evaluation](https://arxiv.org/abs/2512.23610)
*Heba Osama,Omar Elebiary,Youssef Qassim,Mohamed Amgad,Ahmed Maghawry,Ahmed Saafan,Haitham Ghalwash*

Main category: cs.CR

TL;DR: WAMM是一个AI驱动的多类别Web攻击检测框架，通过重新分类HTTP请求到OWASP对齐的类别，暴露基于规则系统的局限性，在相同技术栈上达到99.59%准确率，相比OWASP CRS提升高达86%


<details>
  <summary>Details</summary>
Motivation: 传统基于静态规则集的Web应用防火墙（如OWASP CRS）经常错过混淆或零日攻击模式，需要大量手动调整。需要更智能、自适应的检测方法来应对日益复杂的Web攻击

Method: 1) 多阶段增强管道处理SR-BH 2020数据集：大规模去重、LLM引导的重新标注、真实攻击数据增强、LLM过滤；2) 构建统一特征空间（统计和文本表示）；3) 评估四种机器学习和深度学习模型；4) 在相同技术栈和未见增强数据集上测试

Result: 1) 在增强和LLM过滤的数据集上，XGBoost达到99.59%准确率，微秒级推理；2) 深度学习模型在噪声增强下性能下降；3) 相比OWASP CRS，在未见增强数据集上实现96-100%真正例拦截率，提升高达86%

Conclusion: 精心策划的训练管道结合高效机器学习模型能够实现更弹性的实时Web攻击检测方法，适合生产WAF环境，暴露了广泛部署的基于规则防御系统的差距

Abstract: Web applications increasingly face evasive and polymorphic attack payloads, yet traditional web application firewalls (WAFs) based on static rule sets such as the OWASP Core Rule Set (CRS) often miss obfuscated or zero-day patterns without extensive manual tuning. This work introduces WAMM, an AI-driven multiclass web attack detection framework designed to reveal the limitations of rule-based systems by reclassifying HTTP requests into OWASP-aligned categories for a specific technology stack. WAMM applies a multi-phase enhancement pipeline to the SR-BH 2020 dataset that includes large-scale deduplication, LLM-guided relabeling, realistic attack data augmentation, and LLM-based filtering, producing three refined datasets. Four machine and deep learning models are evaluated using a unified feature space built from statistical and text-based representations. Results show that using an augmented and LLM-filtered dataset on the same technology stack, XGBoost reaches 99.59% accuracy with microsecond-level inference while deep learning models degrade under noisy augmentation. When tested against OWASP CRS using an unseen augmented dataset, WAMM achieves true positive block rates between 96 and 100% with improvements of up to 86%. These findings expose gaps in widely deployed rule-based defenses and demonstrate that curated training pipelines combined with efficient machine learning models enable a more resilient, real-time approach to web attack detection suitable for production WAF environments.

</details>
