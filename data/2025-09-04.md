<div id=toc></div>

# Table of Contents

- [cs.CR](#cs.CR) [Total: 13]


<div id='cs.CR'></div>

# cs.CR [[Back]](#toc)

### [1] [Secure Password Generator Based on Secure Pseudo-Random Number Generator](https://arxiv.org/abs/2509.02578)
*Abel C. H. Chen*

Main category: cs.CR

TL;DR: 本文提出了一种使用密码学安全伪随机数生成器（PRNG）的安全密码生成方法，通过多种MAC算法生成高随机性密码，并满足NIST SP 800-90B的熵和IID要求。


<details>
  <summary>Details</summary>
Motivation: 近年来网站账户和密码泄露事件频发，凸显了信息安全和个人密码保护的重要性。虽然许多泄露归因于网站基础设施漏洞，但密码本身的强度也是关键因素。

Method: 使用密码学安全PRNG，采用多种消息认证码算法（HMAC、CMAC、KMAC）生成强随机值用于密码生成。

Result: 实验评估按照NIST SP 800-90B指南进行，结果表明该方法满足熵估计和IID特性验证要求，能够生成具有高度随机性和安全性的密码。

Conclusion: 提出的密码生成方法能够有效生成安全可靠的密码，为增强系统安全性和保护个人数据提供了有效的解决方案。

Abstract: In recent years, numerous incidents involving the leakage of website accounts
and text passwords (referred to as passwords) have raised significant concerns
regarding the potential exposure of personal information. These events
underscore the critical importance of both information security and password
protection. While many of these breaches are attributable to vulnerabilities
within website infrastructure, the strength and security of the passwords
themselves also play a crucial role. Consequently, the creation of secure
passwords constitutes a fundamental aspect of enhancing overall system security
and protecting personal data. In response to these challenges, this study
presents a secure password generation approach utilizing a cryptographically
secure Pseudo-Random Number Generator (PRNG). The generator is implemented
using a range of Message Authentication Code (MAC) algorithms, including the
Keyed-Hash Message Authentication Code (HMAC), Cipher-based Message
Authentication Code (CMAC), and KECCAK Message Authentication Code (KMAC), to
produce robust random values suitable for password generation. To evaluate the
proposed method, empirical assessments were conducted in accordance with the
guidelines provided in the National Institute of Standards and Technology
(NIST) Special Publication (SP) 800-90B. The evaluation focused on two primary
aspects: entropy estimation and verification of independent and identically
distributed (IID) properties. Experimental results indicate that the proposed
method satisfies both entropy and IID requirements, thereby demonstrating its
ability to generate passwords with a high degree of randomness and security.

</details>


### [2] [Managing Correlations in Data and Privacy Demand](https://arxiv.org/abs/2509.02856)
*Syomantak Chaudhuri,Thomas A. Courtade*

Main category: cs.CR

TL;DR: 提出了Add-remove Heterogeneous Differential Privacy (AHDP)框架，解决了传统HDP在用户数据与隐私需求相关时的不足，提供了对数据-隐私相关性的鲁棒性保证，并设计了无需先验知识的实用机制。


<details>
  <summary>Details</summary>
Motivation: 传统异构差分隐私(HDP)框架假设用户数据与隐私级别不相关，但在实际应用中这种相关性普遍存在，导致标准HDP框架失效。

Method: 提出AHDP框架，通过操作假设检验形式化隐私保证，设计了无需数据-隐私相关性先验知识的非平凡机制，应用于均值估计、频率估计和线性回归等核心统计任务。

Result: AHDP框架能够有效处理数据与隐私需求的相关性，提出的机制实现简单，假设和建模要求最小，适合实际应用。在LLM生成的合成数据集上进行了实证评估。

Conclusion: AHDP框架为解决数据与隐私需求相关性提供了有效解决方案，提出的机制具有实用价值，为未来隐私保护研究提供了新的方向和数据集资源。

Abstract: Previous works in the differential privacy literature that allow users to
choose their privacy levels typically operate under the heterogeneous
differential privacy (HDP) framework with the simplifying assumption that user
data and privacy levels are not correlated. Firstly, we demonstrate that the
standard HDP framework falls short when user data and privacy demands are
allowed to be correlated. Secondly, to address this shortcoming, we propose an
alternate framework, Add-remove Heterogeneous Differential Privacy (AHDP), that
jointly accounts for user data and privacy preference. We show that AHDP is
robust to possible correlations between data and privacy. Thirdly, we formalize
the guarantees of the proposed AHDP framework through an operational hypothesis
testing perspective. The hypothesis testing setup may be of independent
interest in analyzing other privacy frameworks as well. Fourthly, we show that
there exists non-trivial AHDP mechanisms that notably do not require prior
knowledge of the data-privacy correlations. We propose some such mechanisms and
apply them to core statistical tasks such as mean estimation, frequency
estimation, and linear regression. The proposed mechanisms are simple to
implement with minimal assumptions and modeling requirements, making them
attractive for real-world use. Finally, we empirically evaluate proposed AHDP
mechanisms, highlighting their trade-offs using LLM-generated synthetic
datasets, which we release for future research.

</details>


### [3] [Efficient Privacy-Preserving Recommendation on Sparse Data using Fully Homomorphic Encryption](https://arxiv.org/abs/2509.03024)
*Moontaha Nishat Chowdhury,André Bauer,Minxuan Zhou*

Main category: cs.CR

TL;DR: 使用压缩稀疏行表示和全同态加密的矩阵分解方法，在推荐系统中高效处理稀疏矩阵并降低通信开销，保护用户隐私。


<details>
  <summary>Details</summary>
Motivation: 推荐系统依赖敏感数据引发隐私担忧，而全同态加密在处理大型稀疏矩阵时遍压力大、通信成本高。

Method: 结合压缩稀疏行(CSR)表示法和FHE基于矩阵分解，在加密域高效处理矩阵稀疏性，最小化通信开销。

Result: 实验结果显示在加密数据上实现了高推荐准确性，同时达到了最低的通信成本。

Conclusion: 该方法有效保护用户隐私，解决了FHE在推荐系统中处理稀疏矩阵的效率和通信挑战。

Abstract: In today's data-driven world, recommendation systems personalize user
experiences across industries but rely on sensitive data, raising privacy
concerns. Fully homomorphic encryption (FHE) can secure these systems, but a
significant challenge in applying FHE to recommendation systems is efficiently
handling the inherently large and sparse user-item rating matrices. FHE
operations are computationally intensive, and naively processing various sparse
matrices in recommendation systems would be prohibitively expensive.
Additionally, the communication overhead between parties remains a critical
concern in encrypted domains. We propose a novel approach combining Compressed
Sparse Row (CSR) representation with FHE-based matrix factorization that
efficiently handles matrix sparsity in the encrypted domain while minimizing
communication costs. Our experimental results demonstrate high recommendation
accuracy with encrypted data while achieving the lowest communication costs,
effectively preserving user privacy.

</details>


### [4] [TraceLLM: Security Diagnosis Through Traces and Smart Contracts in Ethereum](https://arxiv.org/abs/2509.03037)
*Shuzheng Wang,Yue Huang,Zhuoer Xu,Yuming Huang,Jing Tang*

Main category: cs.CR

TL;DR: TraceLLM是一个基于LLM的框架，通过结合执行轨迹分析和反编译合约代码，实现智能合约安全分析自动化，在攻击检测精度和自动化报告生成方面显著优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 现有智能合约安全分析方法存在局限：异常交易检测无法深入分析执行轨迹中的攻击策略，代码漏洞检测无法处理未验证合约且难以展示实际攻击利用方式，导致分析师仍需手动分析。

Method: 提出TraceLLM框架，集成LLM进行执行轨迹级检测与反编译合约代码分析，引入异常执行路径识别算法和LLM精炼反编译工具，识别脆弱函数并提供明确攻击路径。

Result: 在27个有专家标注的案例中，攻击者和受害者地址识别精度达85.19%，自动化报告事实精度70.37%，比最佳基线高25.93%。在148个真实事件中，自动化报告专家验证精度达66.22%。

Conclusion: TraceLLM首次建立了联合轨迹和合约代码驱动的安全分析基准，展示了强大的泛化能力，为智能合约安全分析提供了有效的自动化解决方案。

Abstract: Ethereum smart contracts hold tens of billions of USD in DeFi and NFTs, yet
comprehensive security analysis remains difficult due to unverified code,
proxy-based architectures, and the reliance on manual inspection of complex
execution traces. Existing approaches fall into two main categories: anomaly
transaction detection, which flags suspicious transactions but offers limited
insight into specific attack strategies hidden in execution traces inside
transactions, and code vulnerability detection, which cannot analyze unverified
contracts and struggles to show how identified flaws are exploited in real
incidents. As a result, analysts must still manually align transaction traces
with contract code to reconstruct attack scenarios and conduct forensics. To
address this gap, TraceLLM is proposed as a framework that leverages LLMs to
integrate execution trace-level detection with decompiled contract code. We
introduce a new anomaly execution path identification algorithm and an
LLM-refined decompile tool to identify vulnerable functions and provide
explicit attack paths to LLM. TraceLLM establishes the first benchmark for
joint trace and contract code-driven security analysis. For comparison, proxy
baselines are created by jointly transmitting the results of three
representative code analysis along with raw traces to LLM. TraceLLM identifies
attacker and victim addresses with 85.19\% precision and produces automated
reports with 70.37\% factual precision across 27 cases with ground truth expert
reports, achieving 25.93\% higher accuracy than the best baseline. Moreover,
across 148 real-world Ethereum incidents, TraceLLM automatically generates
reports with 66.22\% expert-verified accuracy, demonstrating strong
generalizability.

</details>


### [5] [EverTracer: Hunting Stolen Large Language Models via Stealthy and Robust Probabilistic Fingerprint](https://arxiv.org/abs/2509.03058)
*Zhenhua Xu,Meng Han,Wenpeng Xing*

Main category: cs.CR

TL;DR: EverTracer是一个新颖的灰盒指纹框架，通过重新利用成员推理攻击(MIA)进行防御性使用，在自然语言数据上微调模型嵌入所有权信号，实现隐蔽且鲁棒的模型溯源验证。


<details>
  <summary>Details</summary>
Motivation: 大型语言模型(LLM)的普及加剧了模型盗版和许可证违规问题，需要强大且隐蔽的所有权验证方法。现有指纹方法要么需要不切实际的白盒访问，要么引入可检测的统计异常。

Method: 1) 指纹注入：在任何自然语言数据上微调模型而不产生可检测的伪影；2) 验证：利用校准的概率变化信号来区分指纹模型。通过记忆化而非人工触发-输出过拟合来嵌入所有权信号。

Result: 跨架构的广泛实验证明EverTracer具有最先进的效能、隐蔽性和韧性，能够抵抗自适应对手的攻击，包括输入级修改和模型级修改。

Conclusion: EverTracer为保护LLM知识产权提供了一个实用的解决方案，建立了第一个将MIA重新用于防御目的的框架，实现了隐蔽且鲁棒的模型溯源。

Abstract: The proliferation of large language models (LLMs) has intensified concerns
over model theft and license violations, necessitating robust and stealthy
ownership verification. Existing fingerprinting methods either require
impractical white-box access or introduce detectable statistical anomalies. We
propose EverTracer, a novel gray-box fingerprinting framework that ensures
stealthy and robust model provenance tracing. EverTracer is the first to
repurpose Membership Inference Attacks (MIAs) for defensive use, embedding
ownership signals via memorization instead of artificial trigger-output
overfitting. It consists of Fingerprint Injection, which fine-tunes the model
on any natural language data without detectable artifacts, and Verification,
which leverages calibrated probability variation signal to distinguish
fingerprinted models. This approach remains robust against adaptive
adversaries, including input level modification, and model-level modifications.
Extensive experiments across architectures demonstrate EverTracer's
state-of-the-art effectiveness, stealthness, and resilience, establishing it as
a practical solution for securing LLM intellectual property. Our code and data
are publicly available at https://github.com/Xuzhenhua55/EverTracer.

</details>


### [6] [Compressed verification for post-quantum signatures with long-term public keys](https://arxiv.org/abs/2509.03098)
*Gustavo Banegas,Anaëlle Le Dévéhat,Benjamin Smith*

Main category: cs.CR

TL;DR: 提出了一种压缩GPV风格签名方案中大型公钥的方法，用更小的私密验证密钥替代，显著减少验证者存储和运行时间，同时保持安全性。


<details>
  <summary>Details</summary>
Motivation: 后量子签名方案（如Wave和Squirrels）虽然具有长期安全性优势，但公钥尺寸极大，增加了存储成本和验证时间，需要解决这一瓶颈问题。

Method: 采用私密验证密钥替代传统大型公钥的方法，在GPV风格签名方案中实现密钥压缩，保持相同的安全保证。

Result: 成功压缩Squirrels-I密钥从665 kB到20.7 kB（压缩率约32倍），Wave822密钥从3.5 MB到207.97 kB（压缩率约17倍）。

Conclusion: 该方法有效解决了后量子签名方案中公钥尺寸过大的问题，为实际部署提供了可行的解决方案，在保持安全性的同时显著提升了性能。

Abstract: Many signature applications-such as root certificates, secure software
updates, and authentication protocols-involve long-lived public keys that are
transferred or installed once and then used for many verifications. This key
longevity makes post-quantum signature schemes with conservative assumptions
(e.g., structure-free lattices) attractive for long-term security. But many
such schemes, especially those with short signatures, suffer from extremely
large public keys. Even in scenarios where bandwidth is not a major concern,
large keys increase storage costs and slow down verification. We address this
with a method to replace large public keys in GPV-style signatures with
smaller, private verification keys. This significantly reduces verifier storage
and runtime while preserving security. Applied to the conservative,
short-signature schemes Wave and Squirrels, our method compresses Squirrels-I
keys from 665 kB to 20.7 kB and Wave822 keys from 3.5 MB to 207.97 kB.

</details>


### [7] [PromptCOS: Towards System Prompt Copyright Auditing for LLMs via Content-level Output Similarity](https://arxiv.org/abs/2509.03117)
*Yuchen Yang,Yiming Li,Hongwei Yao,Enhao Huang,Shuo Shao,Bingrun Yang,Zhibo Wang,Dacheng Tao,Zhan Qin*

Main category: cs.CR

TL;DR: PromptCOS是一种基于内容级别输出相似性的提示词版权审计方法，通过嵌入水印和优化验证查询来保护LLM系统提示词版权，具有高有效性、强区分性和鲁棒性。


<details>
  <summary>Details</summary>
Motivation: 大型语言模型的快速发展促进了基于LLM的应用开发，但系统提示词容易被盗用和滥用，现有水印方法依赖中间LLM输出，实用性受限。

Method: 通过优化提示词同时协同优化特殊验证查询和内容级别信号标记，利用循环输出信号和注入辅助令牌，在纯内容场景下实现可靠审计，并加入覆盖令牌防止恶意删除。

Result: 实验结果显示方法达到99.3%的平均水印相似度，比最佳基线高60.8%的区分性，准确率下降不超过0.58%，对三种攻击具有鲁棒性，计算成本降低98.1%。

Conclusion: PromptCOS提供了一种实用有效的方法来保护LLM提示词版权，在内容级别输出相似性基础上实现了可靠的版权审计。

Abstract: The rapid progress of large language models (LLMs) has greatly enhanced
reasoning tasks and facilitated the development of LLM-based applications. A
critical factor in improving LLM-based applications is the design of effective
system prompts, which significantly impact the behavior and output quality of
LLMs. However, system prompts are susceptible to theft and misuse, which could
undermine the interests of prompt owners. Existing methods protect prompt
copyrights through watermark injection and verification but face challenges due
to their reliance on intermediate LLM outputs (e.g., logits), which limits
their practical feasibility.
  In this paper, we propose PromptCOS, a method for auditing prompt copyright
based on content-level output similarity. It embeds watermarks by optimizing
the prompt while simultaneously co-optimizing a special verification query and
content-level signal marks. This is achieved by leveraging cyclic output
signals and injecting auxiliary tokens to ensure reliable auditing in
content-only scenarios. Additionally, it incorporates cover tokens to protect
the watermark from malicious deletion. For copyright verification, PromptCOS
identifies unauthorized usage by comparing the similarity between the
suspicious output and the signal mark. Experimental results demonstrate that
our method achieves high effectiveness (99.3% average watermark similarity),
strong distinctiveness (60.8% greater than the best baseline), high fidelity
(accuracy degradation of no more than 0.58%), robustness (resilience against
three types of potential attacks), and computational efficiency (up to 98.1%
reduction in computational cost). Our code is available at GitHub
https://github.com/LianPing-cyber/PromptCOS.

</details>


### [8] [Kangaroo: A Private and Amortized Inference Framework over WAN for Large-Scale Decision Tree Evaluation](https://arxiv.org/abs/2509.03123)
*Wei Xu,Hui Zhu,Yandong Zheng,Song Bian,Ning Sun,Hao Yuan,Dengguo Feng,Hui Li*

Main category: cs.CR

TL;DR: Kangaroo是一个基于打包同态加密的私有决策树推理框架，通过创新的模型隐藏编码方案和安全协议，实现了计算和通信开销的完全分摊，在WAN环境下比现有方案快14-59倍。


<details>
  <summary>Details</summary>
Motivation: 随着模型即服务的快速普及，数据和模型隐私问题日益重要。现有私有决策树评估方案存在显著限制：其通信和计算成本随树数量、节点数或树深度线性增长，在大规模模型和WAN网络中效率低下。

Method: 提出Kangaroo框架，基于打包同态加密设计新颖的模型隐藏编码方案，结合安全特征选择、不经意比较和安全路径评估协议，实现开销随节点或树数量增长的分摊。通过同模型共享、延迟感知和自适应编码调整策略进行优化。

Result: 在WAN环境下比最先进的一轮交互方案性能提升14-59倍。对于大规模决策树推理任务，比现有方案快3-44倍。能够以每棵树约60ms的摊销时间在WAN环境下评估包含969棵树和411825个节点的随机森林。

Conclusion: Kangaroo框架成功解决了现有私有决策树评估方案的可扩展性问题，通过完全摊销开销实现了高效的大规模私有推理，为模型即服务场景下的隐私保护提供了实用解决方案。

Abstract: With the rapid adoption of Models-as-a-Service, concerns about data and model
privacy have become increasingly critical. To solve these problems, various
privacy-preserving inference schemes have been proposed. In particular, due to
the efficiency and interpretability of decision trees, private decision tree
evaluation (PDTE) has garnered significant attention. However, existing PDTE
schemes suffer from significant limitations: their communication and
computation costs scale with the number of trees, the number of nodes, or the
tree depth, which makes them inefficient for large-scale models, especially
over WAN networks. To address these issues, we propose Kangaroo, a private and
amortized decision tree inference framework build upon packed homomorphic
encryption. Specifically, we design a novel model hiding and encoding scheme,
together with secure feature selection, oblivious comparison, and secure path
evaluation protocols, enabling full amortization of the overhead as the number
of nodes or trees scales. Furthermore, we enhance the performance and
functionality of the framework through optimizations, including
same-sharing-for-same-model, latency-aware, and adaptive encoding adjustment
strategies. Kangaroo achieves a $14\times$ to $59\times$ performance
improvement over state-of-the-art (SOTA) one-round interactive schemes in WAN
environments. For large-scale decision tree inference tasks, it delivers a
$3\times$ to $44\times$ speedup compared to existing schemes. Notably, Kangaroo
enables the evaluation of a random forest with $969$ trees and $411825$ nodes
in approximately $60$ ms per tree (amortized) under WAN environments.

</details>


### [9] [A Comprehensive Guide to Differential Privacy: From Theory to User Expectations](https://arxiv.org/abs/2509.03294)
*Napsu Karmitsa,Antti Airola,Tapio Pahikkala,Tinja Pitkämäki*

Main category: cs.CR

TL;DR: 关于差分隐私(DP)的全面综述，涵盖理论基础、实践机制和实际应用，特别关注隐私保护机器学习和合成数据生成领域的挑战。


<details>
  <summary>Details</summary>
Motivation: 随着个人数据可用性增加，在机器学习、医疗健康和网络安全等领域取得显著进展的同时，也带来了严重的隐私担忧，特别是在重识别攻击日益强大以及法律伦理对负责任数据使用要求不断提高的背景下。

Method: 提供差分隐私的综合性调查，包括理论基础的数学框架、实际实现机制，以及在不同领域特别是隐私保护机器学习和合成数据生成中的具体应用方法。

Result: 系统梳理了差分隐私的核心算法工具和领域特定挑战，强调了DP系统在可用性、沟通和透明度方面需要改进的问题。

Conclusion: 该综述旨在通过提供全面的DP知识，支持研究人员和从业者在不断发展的数据隐私环境中做出明智的差分隐私采用决策。

Abstract: The increasing availability of personal data has enabled significant advances
in fields such as machine learning, healthcare, and cybersecurity. However,
this data abundance also raises serious privacy concerns, especially in light
of powerful re-identification attacks and growing legal and ethical demands for
responsible data use. Differential privacy (DP) has emerged as a principled,
mathematically grounded framework for mitigating these risks. This review
provides a comprehensive survey of DP, covering its theoretical foundations,
practical mechanisms, and real-world applications. It explores key algorithmic
tools and domain-specific challenges - particularly in privacy-preserving
machine learning and synthetic data generation. The report also highlights
usability issues and the need for improved communication and transparency in DP
systems. Overall, the goal is to support informed adoption of DP by researchers
and practitioners navigating the evolving landscape of data privacy.

</details>


### [10] [Exposing Privacy Risks in Anonymizing Clinical Data: Combinatorial Refinement Attacks on k-Anonymity Without Auxiliary Information](https://arxiv.org/abs/2509.03350)
*Somiya Chhillar,Mary K. Righi,Rebecca E. Sutter,Evgenios M. Kornaropoulos*

Main category: cs.CR

TL;DR: 本文提出了组合精化攻击(CRA)，这是一种针对k-匿名化数据集的新型隐私攻击方法，无需外部辅助信息即可显著降低敏感值的可能空间，挑战了k-匿名化的安全性假设。


<details>
  <summary>Details</summary>
Motivation: 尽管隐私社区长期批评k-匿名化，但由于其简单性、监管合规性和数据效用保持，仍被广泛使用。非专业人士常以缺乏辅助信息时无法攻破为由为其辩护，本文旨在反驳这一观点。

Method: 提出组合精化攻击(CRA)，利用ARX等广泛使用的本地重编码匿名化软件的效用优化行为，构建线性规划模型来缩小敏感值的可能空间，无需外部辅助信息或数据分布假设。

Result: 通过与社区健康诊所合作，在真实临床微数据上验证，结果显示即使没有外部信息，现有的匿名化框架也无法提供承诺的隐私保护水平，存在严重隐私风险。

Conclusion: 研究揭示了k-匿名化在本地重编码实现中的根本缺陷，即使没有外部辅助信息，攻击者仍能有效推断敏感信息，这对依赖k-匿名化的隐私保护实践提出了严峻挑战。

Abstract: Despite longstanding criticism from the privacy community, k-anonymity
remains a widely used standard for data anonymization, mainly due to its
simplicity, regulatory alignment, and preservation of data utility. However,
non-experts often defend k-anonymity on the grounds that, in the absence of
auxiliary information, no known attacks can compromise its protections. In this
work, we refute this claim by introducing Combinatorial Refinement Attacks
(CRA), a new class of privacy attacks targeting k-anonymized datasets produced
using local recoding. This is the first method that does not rely on external
auxiliary information or assumptions about the underlying data distribution.
CRA leverages the utility-optimizing behavior of local recoding anonymization
of ARX, which is a widely used open-source software for anonymizing data in
clinical settings, to formulate a linear program that significantly reduces the
space of plausible sensitive values. To validate our findings, we partnered
with a network of free community health clinics, an environment where (1)
auxiliary information is indeed hard to find due to the population they serve
and (2) open-source k-anonymity solutions are attractive due to regulatory
obligations and limited resources. Our results on real-world clinical microdata
reveal that even in the absence of external information, established
anonymization frameworks do not deliver the promised level of privacy, raising
critical privacy concerns.

</details>


### [11] [Tuning Block Size for Workload Optimization in Consortium Blockchain Networks](https://arxiv.org/abs/2509.03367)
*Narges Dadkhah,Somayeh Mohammadi,Gerhard Wunder*

Main category: cs.CR

TL;DR: 通过数学模型和遗传算法确定Hyperledger Fabric的最佳块大小，以优化区块链系统吞吐量和性能


<details>
  <summary>Details</summary>
Motivation: 块大小对区块链系统性能致命关键，但目前存在分歧观点和网络分析问题，需要系统化方法来确定最优配置

Method: 构建数学模型来最大化系统性能，结合机器学习和遗传算法解决模型，分析块大小、交易大小、网络容量对块处理时间的影响

Result: 通过优化汇编器进行准确的块大小配置调整，在部署前确保系统性能提升

Conclusion: 该系统方法能够平衡块处理效率、网络延迟和系统吞吐量，为不同业务场景下的区块链性能提供稳健解决方案

Abstract: Determining the optimal block size is crucial for achieving high throughput
in blockchain systems. Many studies have focused on tuning various components,
such as databases, network bandwidth, and consensus mechanisms. However, the
impact of block size on system performance remains a topic of debate, often
resulting in divergent views and even leading to new forks in blockchain
networks. This research proposes a mathematical model to maximize performance
by determining the ideal block size for Hyperledger Fabric, a prominent
consortium blockchain. By leveraging machine learning and solving the model
with a genetic algorithm, the proposed approach assesses how factors such as
block size, transaction size, and network capacity influence the block
processing time. The integration of an optimization solver enables precise
adjustments to block size configuration before deployment, ensuring improved
performance from the outset. This systematic approach aims to balance block
processing efficiency, network latency, and system throughput, offering a
robust solution to improve blockchain performance across diverse business
contexts.

</details>


### [12] [Federated Learning: An approach with Hybrid Homomorphic Encryption](https://arxiv.org/abs/2509.03427)
*Pedro Correia,Ivan Silva,Ivone Amorim,Eva Maia,Isabel Praça*

Main category: cs.CR

TL;DR: 提出首个用于联邦学习的混合同态加密框架，结合PASTA对称密码和BFV FHE方案，在保持97.6%准确率的同时显著降低客户端带宽和计算开销，但服务器计算成本大幅增加。


<details>
  <summary>Details</summary>
Motivation: 联邦学习中梯度重建和成员推理攻击存在隐私泄露风险，完全同态加密虽然能解决隐私问题但存在密文膨胀和资源消耗大的问题，需要更高效的隐私保护方案。

Method: 客户端使用PASTA对称密码加密本地模型更新，同时发送轻量级密文和BFV加密的PASTA密钥给服务器，服务器通过同态计算PASTA解密电路并聚合BFV密文。

Result: 在MNIST数据集上达到97.6%准确率（仅比明文低1.3%），客户端上传带宽减少2000倍，运行时降低30%，但服务器计算成本增加15621倍。

Conclusion: HHE框架在保护隐私的同时显著改善了客户端性能，但服务器计算开销巨大，是未来工作需要解决的关键挑战。

Abstract: Federated Learning (FL) is a distributed machine learning approach that
promises privacy by keeping the data on the device. However, gradient
reconstruction and membership-inference attacks show that model updates still
leak information. Fully Homomorphic Encryption (FHE) can address those privacy
concerns but it suffers from ciphertext expansion and requires prohibitive
overhead on resource-constrained devices. We propose the first Hybrid
Homomorphic Encryption (HHE) framework for FL that pairs the PASTA symmetric
cipher with the BFV FHE scheme. Clients encrypt local model updates with PASTA
and send both the lightweight ciphertexts and the PASTA key (itself
BFV-encrypted) to the server, which performs a homomorphic evaluation of the
decryption circuit of PASTA and aggregates the resulting BFV ciphertexts. A
prototype implementation, developed on top of the Flower FL framework, shows
that on independently and identically distributed MNIST dataset with 12 clients
and 10 training rounds, the proposed HHE system achieves 97.6% accuracy, just
1.3% below plaintext, while reducing client upload bandwidth by over 2,000x and
cutting client runtime by 30% compared to a system based solely on the BFV FHE
scheme. However, server computational cost increases by roughly 15621x for each
client participating in the training phase, a challenge to be addressed in
future work.

</details>


### [13] [Evaluating Diverse Feature Extraction Techniques of Multifaceted IoT Malware Analysis: A Survey](https://arxiv.org/abs/2509.03442)
*Zhuoyun Qian,Hongyi Miao,Yili Jiang,Qin Hu,Jiaqi Huang,Cheng Zhang,Fangtian Zhong*

Main category: cs.CR

TL;DR: 这篇论文是一个关于IoT恶意软件分析中特征提取技术的综述性评论，从多个角度对静态、动态、混合以及图学习基于的特征表示策略进行了系统性分析。


<details>
  <summary>Details</summary>
Motivation: 随着IoT设备的普及，安全问题成为制约其可靠性的关键因素。虽然已有多种恶意软件分析技术，但当前方法在实际应用中仍面临重大挑战。

Method: 采用综述性评论方法，首先分析静态和动态特征提取方法，接着研究混合方法，然后探讨基于图学习的特征表示策略。

Result: 论文对现有技术进行了对比分析，明确了各种方法的优势和局限性，持续性挑战以及未来研究方向。

Conclusion: 这份综述为IoT恶意软件分析领域的特征提取技术提供了全面的视角，为解决实际应用中的挑战和指明了未来研究的潜在路径。

Abstract: As IoT devices continue to proliferate, their reliability is increasingly
constrained by security concerns. In response, researchers have developed
diverse malware analysis techniques to detect and classify IoT malware. These
techniques typically rely on extracting features at different levels from IoT
applications, giving rise to a wide range of feature extraction methods.
However, current approaches still face significant challenges when applied in
practice. This survey provides a comprehensive review of feature extraction
techniques for IoT malware analysis from multiple perspectives. We first
examine static and dynamic feature extraction methods, followed by hybrid
approaches. We then explore feature representation strategies based on graph
learning. Finally, we compare the strengths and limitations of existing
techniques, highlight open challenges, and outline promising directions for
future research.

</details>
