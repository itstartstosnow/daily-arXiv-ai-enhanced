<div id=toc></div>

# Table of Contents

- [cs.CR](#cs.CR) [Total: 22]


<div id='cs.CR'></div>

# cs.CR [[Back]](#toc)

### [1] [Automated Repeatable Adversary Threat Emulation with Effects Language (EL)](https://arxiv.org/abs/2510.06420)
*Suresh K. Damodaran,Paul D. Rowe*

Main category: cs.CR

TL;DR: 本文介绍了使用效果语言(EL)来自动化模拟多步骤网络攻击的方法，以解决训练防御者和评估防御工具的需求。


<details>
  <summary>Details</summary>
Motivation: 模拟高级持续性威胁的多步骤攻击对于训练防御者和评估防御工具很有价值，但面临诸多挑战，需要找到有效的自动化解决方案。

Method: 引入效果语言(EL)，这是一种基于图形操作语义的可视化编程语言，用于编码多步骤攻击，并正式定义了EL的执行语义和重要执行属性。

Result: 通过公开可用的攻击场景示例展示了EL的应用，证明了EL能够为复杂多步骤攻击提供攻击证明，并在时间和资源效率方面实现了显著改进。

Conclusion: 效果语言(EL)是解决多步骤攻击自动化挑战的有效方案，能够提高重复自动化的效率和可靠性。

Abstract: The emulation of multi-step attacks attributed to advanced persistent threats
is valuable for training defenders and evaluating defense tools. In this paper,
we discuss the numerous challenges and desired attributes associated with such
automation. Additionally, we introduce the use of Effects Language (EL), a
visual programming language with graph-based operational semantics, as a
solution to address many of these challenges and requirements. We formally
define the execution semantics of EL, and prove important execution properties.
Furthermore, we showcase the application of EL to codify attacks using an
example from one of the publicly available attack scenarios. We also
demonstrate how EL can be utilized to provide proof-of-attack of complex
multi-step attacks. Our results highlight the improvements in time and resource
efficiency achieved through the use of EL for repeatable automation.

</details>


### [2] [Breaking Precision Time: OS Vulnerability Exploits Against IEEE 1588](https://arxiv.org/abs/2510.06421)
*Muhammad Abdullah Soomro,Fatima Muhammad Anwar*

Main category: cs.CR

TL;DR: 本文首次系统研究了针对PTP协议的内核级攻击，揭示了特权攻击者如何通过操纵系统接口而非网络流量来破坏时钟同步，绕过了现有安全机制。


<details>
  <summary>Details</summary>
Motivation: 现有PTP安全研究主要关注网络攻击，假设主机环境可信，但忽略了内核级攻击者从主机内部破坏PTP栈的威胁。

Method: 实现了三种攻击原语：恒定偏移、渐进偏移和随机抖动，使用内核有效载荷评估对ptp4l和phc2sys守护进程的影响。

Result: 实验表明这些攻击可以静默破坏时钟同步，绕过现有PTP安全扩展机制。

Conclusion: 研究结果强调需要重新考虑主机级信任假设，并将内核完整性纳入安全时间同步系统设计。

Abstract: The Precision Time Protocol (PTP), standardized as IEEE 1588, provides
sub-microsecond synchronization across distributed systems and underpins
critical infrastructure in telecommunications, finance, power systems, and
industrial automation. While prior work has extensively analyzed PTP's
vulnerability to network-based attacks, prompting the development of
cryptographic protections and anomaly detectors, these defenses presume an
uncompromised host. In this paper, we identify and exploit a critical blind
spot in current threat models: kernel-level adversaries operating from within
the host running the PTP stack. We present the first systematic study of
kernel-rooted attacks on PTP, demonstrating how privileged attackers can
manipulate system time by corrupting key interfaces without altering PTP
network traffic. We implement three attack primitives, constant offset,
progressive skew, and random jitter, using in-kernel payloads, and evaluate
their impact on the widely used ptp4l and phc2sys daemons. Our experiments
reveal that these attacks can silently destabilize clock synchronization,
bypassing existing PTP security extensions. These findings highlight the urgent
need to reconsider host-level trust assumptions and integrate kernel integrity
into the design of secure time synchronization systems.

</details>


### [3] [Proofs of No Intrusion](https://arxiv.org/abs/2510.06432)
*Vipul Goyal,Justin Raizes*

Main category: cs.CR

TL;DR: 提出了"无入侵证明"，使经典客户端能够远程检测量子服务器是否被入侵和数据是否被盗，且测试不会破坏被测试的数据。


<details>
  <summary>Details</summary>
Motivation: 传统数据安全无法检测完美复制是否发生，而量子力学禁止一般复制，这为检测数据盗窃提供了新可能性。

Method: 基于完全同态加密构建无入侵证明，并为不可克隆基元（如不可克隆解密密钥和签名令牌）配备无入侵证明。核心是使用经典通信非破坏性测试陪集态的新方法。

Result: 成功定义了无入侵证明并构建了具体实现，展示了该方法适用于几乎所有不可克隆基元。

Conclusion: 无入侵证明为量子环境下的数据安全提供了有效的检测机制，避免了传统备份的需求，具有广泛的应用前景。

Abstract: A central challenge in data security is not just preventing theft, but
detecting whether it has occurred. Classically, this is impossible because a
perfect copy leaves no evidence. Quantum mechanics, on the other hand, forbids
general duplication, opening up new possibilities.
  We introduce Proofs of No Intrusion, which enable a classical client to
remotely test whether a quantum server has been hacked and the client's data
stolen. Crucially, the test does not destroy the data being tested, avoiding
the need to store a backup elsewhere. We define and construct proofs of no
intrusion for ciphertexts assuming fully homomorphic encryption. Additionally,
we show how to equip several constructions of unclonable primitives with proofs
of non-intrusion, such as unclonable decryption keys and signature tokens.
Conceptually, proofs of non-intrusion can be defined for essentially any
unclonable primitive.
  At the heart of our techniques is a new method for non-destructively testing
coset states with classical communication. It can be viewed as a
non-destructive proof of knowledge of a measurement result of the coset state.

</details>


### [4] [BATTLE for Bitcoin: Capital-Efficient Optimistic Bridges with Large Committees](https://arxiv.org/abs/2510.06468)
*Sergio Demian Lerner,Ariel Futoransky*

Main category: cs.CR

TL;DR: BATTLE for Bitcoin是一个抗DoS攻击的争议解决层，用于保护比特币与rollups或侧链之间的乐观桥接。它采用BATTLE锦标赛协议，适配比特币UTXO模型，使用BitVM风格的FLEX组件和乱码电路，通过按需L1安全保证金解决争议。


<details>
  <summary>Details</summary>
Motivation: 为比特币与rollups或侧链之间的跨链桥接提供安全、去中心化的争议解决机制，抵御DoS攻击，同时保持诚实断言者的初始资本恒定。

Method: 将BATTLE锦标赛协议适配到比特币UTXO模型，使用BitVM风格的FLEX组件和乱码电路，结合按需L1安全保证金。争议在logarithmic轮次内解决，奖励可回收利用。仅依赖标准时间锁和预签名交易DAG，无需新操作码。

Result: 协议在N个操作者情况下需要O(N²)预签名交易、签名和消息交换，但在N≥10³时仍保持实用性，支持高度去中心化。

Conclusion: BATTLE for Bitcoin为比特币跨链桥接提供了高效、安全的争议解决方案，具有抗DoS、资本效率高和完全可争议的特点，适用于大规模去中心化场景。

Abstract: We present BATTLE for Bitcoin, a DoS-resilient dispute layer that secures
optimistic bridges between Bitcoin and rollups or sidechains. Our design adapts
the BATTLE tournament protocol to Bitcoin's UTXO model using BitVM-style FLEX
components and garbled circuits with on-demand L1 security bonds. Disputes are
resolved in logarithmic rounds while recycling rewards, keeping the honest
asserter's minimum initial capital constant even under many permissionless
challengers. The construction is fully contestable (challengers can supply
higher-work counter-proofs) and relies only on standard timelocks and
pre-signed transaction DAGs, without new opcodes.
  For $N$ operators, the protocol requires $O(N^2)$ pre-signed transactions,
signatures, and message exchanges, yet remains practical at $N\!\gtrsim\!10^3$,
enabling high decentralization.

</details>


### [5] [From Description to Detection: LLM based Extendable O-RAN Compliant Blind DoS Detection in 5G and Beyond](https://arxiv.org/abs/2510.06530)
*Thusitha Dayaratne,Ngoc Duy Pham,Viet Vo,Shangqi Lai,Sharif Abuadbba,Hajime Suzuki,Xingliang Yuan,Carsten Rudolph*

Main category: cs.CR

TL;DR: 提出了一种基于大语言模型的零样本异常检测框架，用于检测5G控制平面协议中的安全威胁，在O-RAN架构中实现高效攻击检测。


<details>
  <summary>Details</summary>
Motivation: 5G控制平面协议存在安全漏洞，现有异常检测方法需要大量训练数据、预定义规则且可解释性有限，需要更高效的检测方案。

Method: 利用大语言模型在零样本模式下处理无序数据和简短自然语言攻击描述，在O-RAN架构中实现自动化攻击检测。

Result: 框架对提示变化具有鲁棒性，检测质量依赖于描述的语义完整性而非措辞或长度，在RRC/NAS数据集上表现出优越性能。

Conclusion: 该框架在O-RAN实时约束下具有实用性，能够检测其他Layer-3攻击，展示了LLM在网络安全领域的应用潜力。

Abstract: The quality and experience of mobile communication have significantly
improved with the introduction of 5G, and these improvements are expected to
continue beyond the 5G era. However, vulnerabilities in control-plane
protocols, such as Radio Resource Control (RRC) and Non-Access Stratum (NAS),
pose significant security threats, such as Blind Denial of Service (DoS)
attacks. Despite the availability of existing anomaly detection methods that
leverage rule-based systems or traditional machine learning methods, these
methods have several limitations, including the need for extensive training
data, predefined rules, and limited explainability. Addressing these
challenges, we propose a novel anomaly detection framework that leverages the
capabilities of Large Language Models (LLMs) in zero-shot mode with unordered
data and short natural language attack descriptions within the Open Radio
Access Network (O-RAN) architecture. We analyse robustness to prompt variation,
demonstrate the practicality of automating the attack descriptions and show
that detection quality relies on the semantic completeness of the description
rather than its phrasing or length. We utilise an RRC/NAS dataset to evaluate
the solution and provide an extensive comparison of open-source and proprietary
LLM implementations to demonstrate superior performance in attack detection. We
further validate the practicality of our framework within O-RAN's real-time
constraints, illustrating its potential for detecting other Layer-3 attacks.

</details>


### [6] [SpyChain: Multi-Vector Supply Chain Attacks on Small Satellite Systems](https://arxiv.org/abs/2510.06535)
*Jack Vanlyssel,Enrique Sobrados,Ramsha Anwar,Gruia-Catalin Roman,Afsah Anwar*

Main category: cs.CR

TL;DR: SpyChain是首个针对小型卫星的端到端硬件供应链威胁设计与实现，展示了独立和共谋的硬件攻击如何规避测试、窃取遥测数据、破坏操作，并通过隐蔽通道发起拒绝服务攻击。


<details>
  <summary>Details</summary>
Motivation: 小型卫星依赖商用现货硬件，扩大了攻击面。虽然其他网络物理领域的供应链威胁已有研究，但在空间系统中的可行性和隐蔽性仍未充分探索。辅助COTS组件缺乏安全保障却拥有对关键资源的特权访问，这种内部威胁尚未得到足够关注。

Method: 使用NASA卫星模拟器(NOS3)设计和实现SpyChain，涵盖从简单独立组件到动态协调恶意软件的升级过程，构建了五种场景的隐蔽性分类法。

Result: SpyChain能够规避测试、窃取遥测数据、破坏操作，并通过隐蔽通道发起DoS攻击。研究揭示了辅助组件中隐含信任导致的隐蔽持久性，并发现了一种新的多组件执行技术，已被纳入SPARTA矩阵。

Conclusion: 研究强调了小型卫星硬件供应链威胁的现实风险，并实现了轻量级机载防御（包括运行时监控）来缓解类似SpyChain的威胁。NASA NOS3团队已确认并支持这些发现。

Abstract: Small satellites are integral to scientific, commercial, and defense
missions, but reliance on commercial off-the-shelf (COTS) hardware broadens
their attack surface. Although supply chain threats are well studied in other
cyber-physical domains, their feasibility and stealth in space systems remain
largely unexplored. Prior work has focused on flight software, which benefits
from strict security practices and oversight. In contrast, auxiliary COTS
components often lack robust assurance yet enjoy comparable access to critical
on-board resources, including telemetry, system calls, and the software bus.
Despite this privileged access, the insider threat within COTS hardware supply
chains has received little attention. In this work, we present SpyChain, the
first end-to-end design and implementation of independent and colluding
hardware supply chain threats targeting small satellites. Using NASA's
satellite simulation (NOS3), we demonstrate that SpyChain can evade testing,
exfiltrate telemetry, disrupt operations, and launch Denial of Service (DoS)
attacks through covert channels that bypass ground monitoring. Our study traces
an escalation from a simple solo component to dynamic, coordinating malware,
introducing a taxonomy of stealth across five scenarios. We showcase how
implicit trust in auxiliary components enables covert persistence and reveal
novel attack vectors, highlighting a new multi-component execution technique
that is now incorporated into the SPARTA matrix. Our findings are reinforced by
acknowledgment and affirmation from NASA's NOS3 team. Finally, we implement
lightweight onboard defenses, including runtime monitoring, to mitigate threats
like SpyChain.

</details>


### [7] [Auto-Stega: An Agent-Driven System for Lifelong Strategy Evolution in LLM-Based Text Steganography](https://arxiv.org/abs/2510.06565)
*Jiuan Zhou,Yu Cheng,Yuan Xie,Zhaoxia Yin*

Main category: cs.CR

TL;DR: Auto-Stega是一个基于智能体驱动的自进化文本隐写框架，通过自动发现、组合和调整隐写策略，在高嵌入率下实现更好的隐写效果。


<details>
  <summary>Details</summary>
Motivation: 随着LLM的发展，高质量生成文本成为文本隐写的理想载体，但现有方法依赖手工策略，难以在高嵌入率下平衡效率、不可感知性和安全性。

Method: 采用智能体驱动的自进化框架，通过生成、评估、总结和更新的闭环过程，持续构建结构化策略库并适应不同语料库、风格和任务约束。引入PC-DNTE算法处理高嵌入率问题。

Result: 在高嵌入率下，Auto-Stega相比SOTA方法在困惑度上提升42.2%，在反隐写分析性能上提升1.6%。

Conclusion: Auto-Stega框架首次实现了自进化的隐写策略，在高嵌入率下显著提升了隐写性能，为文本隐写提供了新的解决方案。

Abstract: With the rapid progress of LLMs, high quality generative text has become
widely available as a cover for text steganography. However, prevailing methods
rely on hand-crafted or pre-specified strategies and struggle to balance
efficiency, imperceptibility, and security, particularly at high embedding
rates. Accordingly, we propose Auto-Stega, an agent-driven self-evolving
framework that is the first to realize self-evolving steganographic strategies
by automatically discovering, composing, and adapting strategies at inference
time; the framework operates as a closed loop of generating, evaluating,
summarizing, and updating that continually curates a structured strategy
library and adapts across corpora, styles, and task constraints. A decoding LLM
recovers the information under the shared strategy. To handle high embedding
rates, we introduce PC-DNTE, a plug-and-play algorithm that maintains alignment
with the base model's conditional distribution at high embedding rates,
preserving imperceptibility while enhancing security. Experimental results
demonstrate that at higher embedding rates Auto-Stega achieves superior
performance with gains of 42.2\% in perplexity and 1.6\% in anti-steganalysis
performance over SOTA methods.

</details>


### [8] [Reading Between the Lines: Towards Reliable Black-box LLM Fingerprinting via Zeroth-order Gradient Estimation](https://arxiv.org/abs/2510.06605)
*Shuo Shao,Yiming Li,Hongwei Yao,Yifei Chen,Yuchen Yang,Zhan Qin*

Main category: cs.CR

TL;DR: ZeroPrint是一种新颖的黑盒LLM指纹识别方法，通过零阶估计近似信息丰富的梯度，使用语义保留的词替换来模拟输入扰动，从而估计模型的Jacobian矩阵作为独特指纹。


<details>
  <summary>Details</summary>
Motivation: LLMs作为重要知识产权需要版权保护，现有黑盒指纹识别方法因依赖模型输出而丢失关键参数信息，无法生成独特的LLM指纹。

Method: 利用Fisher信息理论证明模型输入的梯度比输出更具信息性；提出ZeroPrint方法，在离散文本中通过语义保留的词替换模拟输入扰动，使用零阶估计近似梯度，估计Jacobian矩阵作为指纹。

Result: 在标准基准测试中，ZeroPrint实现了最先进的有效性和鲁棒性，显著优于现有的黑盒方法。

Conclusion: ZeroPrint通过利用梯度信息而非模型输出，成功解决了黑盒LLM指纹识别的挑战，为LLM版权保护提供了有效解决方案。

Abstract: The substantial investment required to develop Large Language Models (LLMs)
makes them valuable intellectual property, raising significant concerns about
copyright protection. LLM fingerprinting has emerged as a key technique to
address this, which aims to verify a model's origin by extracting an intrinsic,
unique signature (a "fingerprint") and comparing it to that of a source model
to identify illicit copies. However, existing black-box fingerprinting methods
often fail to generate distinctive LLM fingerprints. This ineffectiveness
arises because black-box methods typically rely on model outputs, which lose
critical information about the model's unique parameters due to the usage of
non-linear functions. To address this, we first leverage Fisher Information
Theory to formally demonstrate that the gradient of the model's input is a more
informative feature for fingerprinting than the output. Based on this insight,
we propose ZeroPrint, a novel method that approximates these information-rich
gradients in a black-box setting using zeroth-order estimation. ZeroPrint
overcomes the challenge of applying this to discrete text by simulating input
perturbations via semantic-preserving word substitutions. This operation allows
ZeroPrint to estimate the model's Jacobian matrix as a unique fingerprint.
Experiments on the standard benchmark show ZeroPrint achieves a
state-of-the-art effectiveness and robustness, significantly outperforming
existing black-box methods.

</details>


### [9] [Code Agent can be an End-to-end System Hacker: Benchmarking Real-world Threats of Computer-use Agent](https://arxiv.org/abs/2510.06607)
*Weidi Luo,Qiming Zhang,Tianyu Lu,Xiaogeng Liu,Bin Hu,Hung-Chun Chiu,Siyuan Ma,Yizhe Zhang,Xusheng Xiao,Yinzhi Cao,Zhen Xiang,Chaowei Xiao*

Main category: cs.CR

TL;DR: AdvCUA是首个基于MITRE ATT&CK企业矩阵真实TTPs的基准测试，包含140个任务，在真实企业环境中评估计算机使用代理(CUA)的安全风险。


<details>
  <summary>Details</summary>
Motivation: 随着CUA框架在日常操作中日益普及，需要评估其现实安全影响，特别是能否被滥用来执行真实的安全攻击。现有研究存在TTP攻击者知识模型缺失、端到端攻击链覆盖不完整、环境不真实等局限。

Method: 提出AdvCUA基准，包含140个任务（40个直接恶意任务、74个基于TTP的恶意任务、26个端到端攻击链），在多主机环境沙箱中通过硬编码评估系统性地评估CUA。评估了基于8个基础LLM的5个主流CUA。

Result: 当前前沿CUA未能充分覆盖操作系统安全威胁。CUA的能力降低了对定制恶意软件和深度领域专业知识的依赖，使缺乏经验的攻击者也能发起复杂的企业入侵。

Conclusion: CUA的安全责任问题引发社会关注，当前CUA在操作系统安全威胁防护方面存在不足，可能被滥用于企业入侵攻击。

Abstract: Computer-use agent (CUA) frameworks, powered by large language models (LLMs)
or multimodal LLMs (MLLMs), are rapidly maturing as assistants that can
perceive context, reason, and act directly within software environments. Among
their most critical applications is operating system (OS) control. As CUAs in
the OS domain become increasingly embedded in daily operations, it is
imperative to examine their real-world security implications, specifically
whether CUAs can be misused to perform realistic, security-relevant attacks.
Existing works exhibit four major limitations: Missing attacker-knowledge model
on tactics, techniques, and procedures (TTP), Incomplete coverage for
end-to-end kill chains, unrealistic environment without multi-host and
encrypted user credentials, and unreliable judgment dependent on
LLM-as-a-Judge. To address these gaps, we propose AdvCUA, the first benchmark
aligned with real-world TTPs in MITRE ATT&CK Enterprise Matrix, which comprises
140 tasks, including 40 direct malicious tasks, 74 TTP-based malicious tasks,
and 26 end-to-end kill chains, systematically evaluates CUAs under a realistic
enterprise OS security threat in a multi-host environment sandbox by hard-coded
evaluation. We evaluate the existing five mainstream CUAs, including ReAct,
AutoGPT, Gemini CLI, Cursor CLI, and Cursor IDE based on 8 foundation LLMs. The
results demonstrate that current frontier CUAs do not adequately cover OS
security-centric threats. These capabilities of CUAs reduce dependence on
custom malware and deep domain expertise, enabling even inexperienced attackers
to mount complex enterprise intrusions, which raises social concern about the
responsibility and security of CUAs.

</details>


### [10] [Unsupervised Backdoor Detection and Mitigation for Spiking Neural Networks](https://arxiv.org/abs/2510.06629)
*Jiachen Li,Bang Wu,Xiaoyu Xia,Xiaoning Liu,Xun Yi,Xiuzhen Zhang*

Main category: cs.CR

TL;DR: 本文提出了一种针对脉冲神经网络(SNNs)后门攻击的无监督检测框架TMPBD和缓解机制NDSBM，解决了传统防御方法在SNNs中效果不佳的问题。


<details>
  <summary>Details</summary>
Motivation: 脉冲神经网络因其高能效受到关注，但其安全方面特别是后门攻击防御研究有限。传统ANN防御方法在SNNs中表现不佳，因为SNNs具有事件驱动和时间依赖性特征。

Method: 提出TMPBD框架，利用最终脉冲层中时间膜电位的最大边际统计来检测目标标签；引入NDSBM缓解机制，通过钳制早期卷积层之间的树突连接来抑制恶意神经元。

Result: 在多个神经形态基准测试和最先进的输入感知动态触发攻击上，TMPBD达到100%检测准确率，NDSBM将攻击成功率从100%降至8.44%，结合检测后降至2.81%，且不降低清洁准确率。

Conclusion: 该方法有效解决了SNNs中的后门攻击问题，为SNNs的安全部署提供了重要保障。

Abstract: Spiking Neural Networks (SNNs) have gained increasing attention for their
superior energy efficiency compared to Artificial Neural Networks (ANNs).
However, their security aspects, particularly under backdoor attacks, have
received limited attention. Existing defense methods developed for ANNs perform
poorly or can be easily bypassed in SNNs due to their event-driven and temporal
dependencies. This paper identifies the key blockers that hinder traditional
backdoor defenses in SNNs and proposes an unsupervised post-training detection
framework, Temporal Membrane Potential Backdoor Detection (TMPBD), to overcome
these challenges. TMPBD leverages the maximum margin statistics of temporal
membrane potential (TMP) in the final spiking layer to detect target labels
without any attack knowledge or data access. We further introduce a robust
mitigation mechanism, Neural Dendrites Suppression Backdoor Mitigation (NDSBM),
which clamps dendritic connections between early convolutional layers to
suppress malicious neurons while preserving benign behaviors, guided by TMP
extracted from a small, clean, unlabeled dataset. Extensive experiments on
multiple neuromorphic benchmarks and state-of-the-art input-aware dynamic
trigger attacks demonstrate that TMPBD achieves 100% detection accuracy, while
NDSBM reduces the attack success rate from 100% to 8.44%, and to 2.81% when
combined with detection, without degrading clean accuracy.

</details>


### [11] [Distilling Lightweight Language Models for C/C++ Vulnerabilities](https://arxiv.org/abs/2510.06645)
*Zhiyuan Wei,Xiaoxuan Yang,Jing Sun,Zijian Zhang*

Main category: cs.CR

TL;DR: FineSec是一个基于知识蒸馏的框架，利用大型语言模型进行C/C++代码漏洞检测，在保持高精度的同时显著降低计算成本。


<details>
  <summary>Details</summary>
Motivation: 现代软件系统日益复杂导致安全漏洞普遍存在，传统漏洞检测方法效率不足，而大型语言模型在代码漏洞检测方面的潜力尚未充分开发。

Method: 通过知识蒸馏技术将大型教师模型的专业知识转移到紧凑的学生模型中，构建包含数据准备、训练、评估和持续学习的统一工作流程。

Result: 在C/C++代码库上的广泛评估表明，FineSec在识别复杂漏洞和逻辑缺陷方面优于基础模型和更大的LLM。

Conclusion: FineSec为现实世界软件安全提供了一个实用且可扩展的解决方案，在保持高准确性的同时实现了计算效率的提升。

Abstract: The increasing complexity of modern software systems exacerbates the
prevalence of security vulnerabilities, posing risks of severe breaches and
substantial economic loss. Consequently, robust code vulnerability detection is
essential for software security. While Large Language Models (LLMs) have
demonstrated remarkable capabilities in natural language processing, their
potential for automated code vulnerability detection remains underexplored.
This paper presents FineSec, a novel framework that harnesses LLMs through
knowledge distillation to enable efficient and precise vulnerability
identification in C/C++ codebases. FineSec utilizes knowledge distillation to
transfer expertise from large teacher models to compact student models,
achieving high accuracy with minimal computational cost. By integrating data
preparation, training, evaluation, and continuous learning into a unified,
single-task workflow, FineSec offers a streamlined approach. Extensive
evaluations on C/C++ codebases demonstrate its superiority over both base
models and larger LLMs in identifying complex vulnerabilities and logical
flaws, establishing FineSec as a practical and scalable solution for real-world
software security. To facilitate reproducibility, the datasets, source code,
and experimental results are made publicly available at:
https://github.com/yangxiaoxuan123/FineSec_detect.

</details>


### [12] [Differentially Private Synthetic Text Generation for Retrieval-Augmented Generation (RAG)](https://arxiv.org/abs/2510.06719)
*Junki Mori,Kazuya Kakizaki,Taiki Miyagawa,Jun Sakuma*

Main category: cs.CR

TL;DR: DP-SynRAG是一种隐私保护的检索增强生成框架，通过生成差分隐私合成RAG数据库来避免重复噪声注入和隐私损失累积。


<details>
  <summary>Details</summary>
Motivation: 现有私有RAG方法依赖查询时差分隐私，需要重复注入噪声导致隐私损失累积，限制了在敏感领域的应用。

Method: 使用LLMs生成差分隐私合成RAG数据库，扩展私有预测方法，让LLMs以差分隐私方式生成模拟子采样数据库记录的文本。

Result: 实验显示DP-SynRAG在保持固定隐私预算的同时，性能优于现有最先进的私有RAG系统。

Conclusion: DP-SynRAG为隐私保护RAG提供了可扩展的解决方案，避免了重复噪声注入和额外隐私成本。

Abstract: Retrieval-Augmented Generation (RAG) enhances large language models (LLMs) by
grounding them in external knowledge. However, its application in sensitive
domains is limited by privacy risks. Existing private RAG methods typically
rely on query-time differential privacy (DP), which requires repeated noise
injection and leads to accumulated privacy loss. To address this issue, we
propose DP-SynRAG, a framework that uses LLMs to generate differentially
private synthetic RAG databases. Unlike prior methods, the synthetic text can
be reused once created, thereby avoiding repeated noise injection and
additional privacy costs. To preserve essential information for downstream RAG
tasks, DP-SynRAG extends private prediction, which instructs LLMs to generate
text that mimics subsampled database records in a DP manner. Experiments show
that DP-SynRAG achieves superior performanec to the state-of-the-art private
RAG systems while maintaining a fixed privacy budget, offering a scalable
solution for privacy-preserving RAG.

</details>


### [13] [Bionetta: Efficient Client-Side Zero-Knowledge Machine Learning Proving](https://arxiv.org/abs/2510.06784)
*Dmytro Zakharov,Oleksandr Kurbatov,Artem Sdobnov,Lev Soukhanov,Yevhenii Sekhin,Vitalii Volovyk,Mykhailo Velykodnyi,Mark Cherepovskyi,Kyrylo Baibula,Lasha Antadze,Pavlo Kravchenko,Volodymyr Dubinin,Yaroslav Panasenko*

Main category: cs.CR

TL;DR: Bionetta框架在零知识机器学习证明方面表现优异，证明时间显著提升，可在移动设备上运行，是唯一能在原生EVM智能合约上部署的解决方案。


<details>
  <summary>Details</summary>
Motivation: 比较Bionetta与其他零知识机器学习工具的性能，解决现有工具在EVM智能合约部署中的证明大小和验证开销问题。

Method: 基于UltraGroth的零知识机器学习框架，采用定制化神经网络设计，虽然增加了一次性预处理成本，但优化了证明生成效率。

Result: 证明时间显著提升，定制神经网络可在移动设备上完成证明，支持客户端证明应用，是唯一能在原生EVM智能合约上部署的方案。

Conclusion: Bionetta框架在零知识机器学习证明方面具有显著优势，特别适合在资源受限环境和区块链应用中部署。

Abstract: In this report, we compare the performance of our UltraGroth-based
zero-knowledge machine learning framework Bionetta to other tools of similar
purpose such as EZKL, Lagrange's deep-prove, or zkml. The results show a
significant boost in the proving time for custom-crafted neural networks: they
can be proven even on mobile devices, enabling numerous client-side proving
applications. While our scheme increases the cost of one-time preprocessing
steps, such as circuit compilation and generating trusted setup, our approach
is, to the best of our knowledge, the only one that is deployable on the native
EVM smart contracts without overwhelming proof size and verification overheads.

</details>


### [14] [Exposing Citation Vulnerabilities in Generative Engines](https://arxiv.org/abs/2510.06823)
*Riku Mochizuki,Shusuke Komatsu,Souta Noguchi,Kazuto Ataka*

Main category: cs.CR

TL;DR: 该论文分析了生成引擎在引用来源选择上的安全漏洞，提出了基于引用发布者属性的内容注入屏障评估标准，揭示了当前生成引擎面临的中毒攻击风险。


<details>
  <summary>Details</summary>
Motivation: 由于任何人都可以在网络上发布信息，生成引擎容易受到中毒攻击。现有研究主要关注答案内容是否忠实反映引用来源，但忽略了应该选择哪些网络来源作为引用来防御中毒攻击。

Method: 引入评估标准，通过分析答案中的引用信息来评估中毒威胁。该标准基于引用发布者的属性对内容注入屏障进行分类，从而揭示当前生成引擎的中毒攻击威胁。

Result: 实验显示，美国政治领域答案中来自官方政党网站（主要来源）的引用仅占25%-45%，而日本为60%-65%，表明美国政治答案面临更高的中毒攻击风险。同时发现，低内容注入屏障的来源被频繁引用，但在答案内容中反映较差。

Conclusion: 为了缓解这一威胁，讨论了主要来源发布者如何增加其网络内容在答案中的曝光度，并指出知名技术受到语言差异的限制。

Abstract: We analyze answers generated by generative engines (GEs) from the
perspectives of citation publishers and the content-injection barrier, defined
as the difficulty for attackers to manipulate answers to user prompts by
placing malicious content on the web. GEs integrate two functions: web search
and answer generation that cites web pages using large language models. Because
anyone can publish information on the web, GEs are vulnerable to poisoning
attacks. Existing studies of citation evaluation focus on how faithfully answer
content reflects cited sources, leaving unexamined which web sources should be
selected as citations to defend against poisoning attacks. To fill this gap, we
introduce evaluation criteria that assess poisoning threats using the citation
information contained in answers. Our criteria classify the publisher
attributes of citations to estimate the content-injection barrier thereby
revealing the threat of poisoning attacks in current GEs. We conduct
experiments in political domains in Japan and the United States (U.S.) using
our criteria and show that citations from official party websites (primary
sources) are approximately \(25\%\)--\(45\%\) in the U.S. and
\(60\%\)--\(65\%\) in Japan, indicating that U.S. political answers are at
higher risk of poisoning attacks. We also find that sources with low
content-injection barriers are frequently cited yet are poorly reflected in
answer content. To mitigate this threat, we discuss how publishers of primary
sources can increase exposure of their web content in answers and show that
well-known techniques are limited by language differences.

</details>


### [15] [I Can't Patch My OT Systems! A Look at CISA's KEVC Workarounds & Mitigations for OT](https://arxiv.org/abs/2510.06951)
*Philip Huff,Nishka Gandu,Pavel Novák*

Main category: cs.CR

TL;DR: 分析CISA已知可利用漏洞目录(KEVC)中针对OT环境的漏洞信息，发现虽然大部分漏洞可能影响OT环境，但仅有13%包含供应商提供的补丁替代方案。


<details>
  <summary>Details</summary>
Motivation: 评估现有公开漏洞信息是否足够支持OT环境进行有效和可靠的漏洞修复，因为OT环境通常难以实施补丁。

Method: 分析截至2025年7月的所有KEVC条目，评估OT环境依赖现有修复建议的程度，并研究基于漏洞和利用特征开发替代方案的可行性。

Result: KEVC中大多数条目可能影响OT环境，但仅有13%包含供应商提供的临时解决方案或缓解措施作为补丁替代方案。

Conclusion: 当前公开的OT漏洞信息不足以支持有效的修复，需要开发更多补丁替代方案，初步证据表明基于漏洞特征开发此类方案是可行的。

Abstract: We examine the state of publicly available information about known
exploitable vulnerabilities applicable to operational technology (OT)
environments. Specifically, we analyze the Known Exploitable Vulnerabilities
Catalog (KEVC) maintained by the US Department of Homeland Security
Cybersecurity and Infrastructure Security Agency (CISA) to assess whether
currently available data is sufficient for effective and reliable remediation
in OT settings. Our team analyzed all KEVC entries through July 2025 to
determine the extent to which OT environments can rely on existing remediation
recommendations. We found that although most entries in the KEVC could affect
OT environments, only 13% include vendor workarounds or mitigations as
alternatives to patching. This paper also examines the feasibility of
developing such alternatives based on vulnerability and exploit
characteristics, and we present early evidence of success with this approach.

</details>


### [16] [VelLMes: A high-interaction AI-based deception framework](https://arxiv.org/abs/2510.06975)
*Muris Sladić,Veronica Valeros,Carlos Catania,Sebastian Garcia*

Main category: cs.CR

TL;DR: 本文提出了一个基于LLM的多协议欺骗框架VelLMes，能够模拟SSH、MySQL、POP3和HTTP等服务作为蜜罐，并通过人类攻击者评估验证了其有效性。


<details>
  <summary>Details</summary>
Motivation: 当前基于LLM的欺骗系统很少，且仅限于模拟SSH服务，缺乏包含人类攻击者的全面评估。生成式AI在网络安全领域具有巨大潜力，需要开发更全面的欺骗框架。

Method: 开发了VelLMes框架，使用LLM模拟多种协议和服务。通过精心设计的提示词让LLM生成逼真响应，并分别评估生成能力和欺骗能力。

Result: 单元测试显示某些LLM通过率可达100%。89名人类攻击者测试中，约30%认为他们在与真实系统交互。实际部署的10个SSH蜜罐能够正确处理大多数命令。

Conclusion: 通过精心设计的提示词，LLM能够有效模拟多种网络服务，在欺骗人类攻击者和应对真实网络攻击方面表现出色。

Abstract: There are very few SotA deception systems based on Large Language Models. The
existing ones are limited only to simulating one type of service, mainly SSH
shells. These systems - but also the deception technologies not based on LLMs -
lack an extensive evaluation that includes human attackers. Generative AI has
recently become a valuable asset for cybersecurity researchers and
practitioners, and the field of cyber-deception is no exception. Researchers
have demonstrated how LLMs can be leveraged to create realistic-looking
honeytokens, fake users, and even simulated systems that can be used as
honeypots. This paper presents an AI-based deception framework called VelLMes,
which can simulate multiple protocols and services such as SSH Linux shell,
MySQL, POP3, and HTTP. All of these can be deployed and used as honeypots, thus
VelLMes offers a variety of choices for deception design based on the users'
needs. VelLMes is designed to be attacked by humans, so interactivity and
realism are key for its performance. We evaluate the generative capabilities
and the deception capabilities. Generative capabilities were evaluated using
unit tests for LLMs. The results of the unit tests show that, with careful
prompting, LLMs can produce realistic-looking responses, with some LLMs having
a 100% passing rate. In the case of the SSH Linux shell, we evaluated deception
capabilities with 89 human attackers. The results showed that about 30% of the
attackers thought that they were interacting with a real system when they were
assigned an LLM-based honeypot. Lastly, we deployed 10 instances of the SSH
Linux shell honeypot on the Internet to capture real-life attacks. Analysis of
these attacks showed us that LLM honeypots simulating Linux shells can perform
well against unstructured and unexpected attacks on the Internet, responding
correctly to most of the issued commands.

</details>


### [17] [RedTWIZ: Diverse LLM Red Teaming via Adaptive Attack Planning](https://arxiv.org/abs/2510.06994)
*Artur Horal,Daniel Pina,Henrique Paz,Iago Paulo,João Soares,Rafael Ferreira,Diogo Tavares,Diogo Glória-Silva,João Magalhães,David Semedo*

Main category: cs.CR

TL;DR: RedTWIZ是一个自适应、多样化的多轮红队测试框架，用于评估大型语言模型在AI辅助软件开发中的鲁棒性。


<details>
  <summary>Details</summary>
Motivation: 当前需要系统评估LLM的对话越狱漏洞，开发多样化的多轮攻击策略，并针对特定LLM的弱点进行自适应攻击规划。

Method: 结合三个主要研究流：系统化评估LLM对话越狱、多样化生成多轮攻击套件、以及分层攻击规划器进行自适应攻击。

Result: 实验结果表明，该多轮对抗攻击策略能成功诱导最先进的LLM产生不安全输出，暴露了LLM鲁棒性的严重缺陷。

Conclusion: 该框架全面评估并揭示了LLM的弱点，强调了增强LLM鲁棒性的迫切研究需求。

Abstract: This paper presents the vision, scientific contributions, and technical
details of RedTWIZ: an adaptive and diverse multi-turn red teaming framework,
to audit the robustness of Large Language Models (LLMs) in AI-assisted software
development. Our work is driven by three major research streams: (1) robust and
systematic assessment of LLM conversational jailbreaks; (2) a diverse
generative multi-turn attack suite, supporting compositional, realistic and
goal-oriented jailbreak conversational strategies; and (3) a hierarchical
attack planner, which adaptively plans, serializes, and triggers attacks
tailored to specific LLM's vulnerabilities. Together, these contributions form
a unified framework -- combining assessment, attack generation, and strategic
planning -- to comprehensively evaluate and expose weaknesses in LLMs'
robustness. Extensive evaluation is conducted to systematically assess and
analyze the performance of the overall system and each component. Experimental
results demonstrate that our multi-turn adversarial attack strategies can
successfully lead state-of-the-art LLMs to produce unsafe generations,
highlighting the pressing need for more research into enhancing LLM's
robustness.

</details>


### [18] [Pseudo-MDPs: A Novel Framework for Efficiently Optimizing Last Revealer Seed Manipulations in Blockchains](https://arxiv.org/abs/2510.07080)
*Maxime Reynouard*

Main category: cs.CR

TL;DR: 提出伪MDP框架解决特定MDP问题，应用于PoS区块链中的最后揭示者攻击问题，显著降低计算复杂度从指数级到多项式级


<details>
  <summary>Details</summary>
Motivation: 解决PoS区块链（如以太坊）中最后揭示者攻击对公平性的威胁，该攻击影响市值4000亿美元的系统安全

Method: 引入伪MDP框架，提出两种问题约简方法到标准MDP，结合两种约简方法改进动态规划算法如值迭代

Result: 将最后揭示者攻击的计算复杂度从O(2^κ κ^(2^(κ+2)))降低到O(κ^4)每迭代，在以太坊案例中κ=325

Conclusion: 该框架不仅有效解决大规模MDP问题，还增强了对区块链系统安全漏洞的理解，为资源受限代理提供实用解决方案

Abstract: This study tackles the computational challenges of solving Markov Decision
Processes (MDPs) for a restricted class of problems. It is motivated by the
Last Revealer Attack (LRA), which undermines fairness in some Proof-of-Stake
(PoS) blockchains such as Ethereum (\$400B market capitalization). We introduce
pseudo-MDPs (pMDPs) a framework that naturally models such problems and propose
two distinct problem reductions to standard MDPs. One problem reduction
provides a novel, counter-intuitive perspective, and combining the two problem
reductions enables significant improvements in dynamic programming algorithms
such as value iteration. In the case of the LRA which size is parameterized by
$\kappa$ (in Ethereum's case $\kappa$= 325), we reduce the computational
complexity from $O(2^\kappa \kappa^{2^{\kappa+2}})$ to $O(\kappa^4)$ (per
iteration). This solution also provide the usual benefits from Dynamic
Programming solutions: exponentially fast convergence toward the optimal
solution is guaranteed. The dual perspective also simplifies policy extraction,
making the approach well-suited for resource-constrained agents who can operate
with very limited memory and computation once the problem has been solved.
Furthermore, we generalize those results to a broader class of MDPs, enhancing
their applicability. The framework is validated through two case studies: a
fictional card game and the LRA on the Ethereum random seed consensus protocol.
These applications demonstrate the framework's ability to solve large-scale
problems effectively while offering actionable insights into optimal
strategies. This work advances the study of MDPs and contributes to
understanding security vulnerabilities in blockchain systems.

</details>


### [19] [GNN-enhanced Traffic Anomaly Detection for Next-Generation SDN-Enabled Consumer Electronics](https://arxiv.org/abs/2510.07109)
*Guan-Yan Yang,Farn Wang,Kuo-Hui Yeh*

Main category: cs.CR

TL;DR: 提出GNN-NAD框架，结合SDN和CFN技术，使用图神经网络和随机森林进行物联网设备异常流量检测，在准确率、召回率等指标上优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 物联网设备易受DDoS和网络攻击，现有深度学习检测系统过于复杂且依赖静态基础设施，需要手动配置管理。

Method: 集成SDN和CFN的可扩展网络模型，提出GNN-NAD框架，融合静态漏洞感知攻击图和动态流量特征，使用GSAGE图神经网络和随机森林分类器。

Result: 在物联网环境中实验显示，GNN-NAD在准确率、召回率、精确率和F1分数上表现优异，即使在小样本情况下也超越现有网络异常检测方法。

Conclusion: 该工作提升了新一代智能物联网网络的安全性和效率。

Abstract: Consumer electronics (CE) connected to the Internet of Things are susceptible
to various attacks, including DDoS and web-based threats, which can compromise
their functionality and facilitate remote hijacking. These vulnerabilities
allow attackers to exploit CE for broader system attacks while enabling the
propagation of malicious code across the CE network, resulting in device
failures. Existing deep learning-based traffic anomaly detection systems
exhibit high accuracy in traditional network environments but are often overly
complex and reliant on static infrastructure, necessitating manual
configuration and management. To address these limitations, we propose a
scalable network model that integrates Software-defined Networking (SDN) and
Compute First Networking (CFN) for next-generation CE networks. In this network
model, we propose a Graph Neural Networks-based Network Anomaly Detection
framework (GNN-NAD) that integrates SDN-based CE networks and enables the CFN
architecture. GNN-NAD uniquely fuses a static, vulnerability-aware attack graph
with dynamic traffic features, providing a holistic view of network security.
The core of the framework is a GNN model (GSAGE) for graph representation
learning, followed by a Random Forest (RF) classifier. This design (GSAGE+RF)
demonstrates superior performance compared to existing feature selection
methods. Experimental evaluations on CE environment reveal that GNN-NAD
achieves superior metrics in accuracy, recall, precision, and F1 score, even
with small sample sizes, exceeding the performance of current network anomaly
detection methods. This work advances the security and efficiency of
next-generation intelligent CE networks.

</details>


### [20] [A multi-layered embedded intrusion detection framework for programmable logic controllers](https://arxiv.org/abs/2510.07171)
*Rishabh Das. Aaron Werth,Tommy Morris*

Main category: cs.CR

TL;DR: 提出了一种在工业控制器内运行的嵌入式入侵检测系统，使用头部级遥测技术检测和响应网络攻击，结合半监督异常检测和监督攻击分类器，在石油终端测试平台上验证了有效性。


<details>
  <summary>Details</summary>
Motivation: 工业控制系统中的可信端点（如HMI和工作站）一旦被攻破，会向PLC发送不安全的执行器命令，危及安全关键操作。由于大多数PLC缺乏分层防御，需要嵌入式安全解决方案。

Method: 在控制器内部署嵌入式入侵检测系统，使用头部级遥测数据，结合半监督异常检测和监督攻击分类器进行网络攻击检测。

Result: 异常检测器实现了零漏报攻击（马修斯相关系数0.998），监督阶段达到97.37%的保留准确率和97.03%的外部准确率，仅增加2031微秒的中位端到端延迟，不影响PLC周期时间。

Conclusion: 该架构提供了满足工业系统实时需求的多层嵌入式安全保护。

Abstract: Industrial control system (ICS) operations use trusted endpoints like human
machine interfaces (HMIs) and workstations to relay commands to programmable
logic controllers (PLCs). Because most PLCs lack layered defenses, compromise
of a trusted endpoint can drive unsafe actuator commands and risk
safety-critical operation. This research presents an embedded intrusion
detection system that runs inside the controller and uses header-level
telemetry to detect and respond to network attacks. The system combines a
semi-supervised anomaly detector and a supervised attack classifier. We
evaluate the approach on a midstream oil-terminal testbed using three datasets
collected during tanker-truck loading. The anomaly detector achieves zero
missed attacks, corresponding to 0.998 Matthews correlation. The supervised
stage attains 97.37 percent hold-out accuracy and 97.03 percent external
accuracy. The embedded design adds a median of 2,031 microseconds of end-to-end
latency and does not impact PLC's cycle time. The proposed architecture
provides a multi-layer embedded security that meets the real-time requirements
of an industrial system.

</details>


### [21] [Exposing LLM User Privacy via Traffic Fingerprint Analysis: A Study of Privacy Risks in LLM Agent Interactions](https://arxiv.org/abs/2510.07176)
*Yixiang Zhang,Xinhao Deng,Zhongyi Gu,Yihao Chen,Ke Xu,Qi Li,Jianping Wu*

Main category: cs.CR

TL;DR: LLM代理的交互行为会在加密流量中留下独特指纹，攻击者可通过分析流量模式推断代理活动、识别特定代理甚至分析用户敏感属性。AgentPrint工具展示了这种隐私风险。


<details>
  <summary>Details</summary>
Motivation: 随着LLM代理被广泛部署用于协调任务和集成外部工具，其交互行为可能通过加密流量暴露用户隐私，需要揭示这种被忽视的安全风险。

Method: 开发AgentPrint工具，通过分析LLM代理工作流和工具调用相关的流量模式，识别代理活动并推断用户属性。

Result: AgentPrint在代理识别中达到0.866的F1分数，在模拟和真实用户设置中分别达到73.9%和69.1%的top-3准确率进行用户属性推断。

Conclusion: LLM代理的交互性在增强功能的同时也暴露了用户隐私，迫切需要技术对策以及监管和政策保障措施。

Abstract: Large Language Models (LLMs) are increasingly deployed as agents that
orchestrate tasks and integrate external tools to execute complex workflows. We
demonstrate that these interactive behaviors leave distinctive fingerprints in
encrypted traffic exchanged between users and LLM agents. By analyzing traffic
patterns associated with agent workflows and tool invocations, adversaries can
infer agent activities, distinguish specific agents, and even profile sensitive
user attributes. To highlight this risk, we develop AgentPrint, which achieves
an F1-score of 0.866 in agent identification and attains 73.9% and 69.1% top-3
accuracy in user attribute inference for simulated- and real-user settings,
respectively. These results uncover an overlooked risk: the very interactivity
that empowers LLM agents also exposes user privacy, underscoring the urgent
need for technical countermeasures alongside regulatory and policy safeguards.

</details>


### [22] [Security-Robustness Trade-offs in Diffusion Steganography: A Comparative Analysis of Pixel-Space and VAE-Based Architectures](https://arxiv.org/abs/2510.07219)
*Yuhua Xu,Wei Sun,Chengpei Tang,Jiaxing Lu,Jingying Zhou,Chen Gu*

Main category: cs.CR

TL;DR: 提出了一种基于近似高斯映射的高效生成隐写框架，通过系统比较像素空间模型与VAE潜在空间系统的隐写性能，揭示了架构依赖的安全性与鲁棒性权衡关系。


<details>
  <summary>Details</summary>
Motivation: 当前生成隐写研究主要追求计算昂贵的完美高斯先验映射，需要开发更高效的框架来系统分析不同架构的隐写特性。

Method: 使用基于尺度因子校准的近似高斯映射框架作为统一分析工具，对像素空间模型和VAE潜在空间系统进行系统比较分析。

Result: 发现像素空间模型具有高安全性但鲁棒性差，而VAE系统如Stable Diffusion提供强鲁棒性但安全性存在漏洞；VAE编码器通过流形正则化提供鲁棒性，解码器则放大潜在扰动引入安全漏洞。

Conclusion: 揭示了生成隐写中架构角色的冲突特性，为未来研究奠定了基础。

Abstract: Current generative steganography research mainly pursues computationally
expensive mappings to perfect Gaussian priors within single diffusion model
architectures. This work introduces an efficient framework based on approximate
Gaussian mapping governed by a scale factor calibrated through capacity-aware
adaptive optimization. Using this framework as a unified analytical tool,
systematic comparative analysis of steganography in pixel-space models versus
VAE-based latent-space systems is conducted. The investigation reveals a
pronounced architecture dependent security-robustness trade-off: pixel-space
models achieve high security against steganalysis but exhibit fragility to
channel distortions, while VAE-based systems like Stable Diffusion offer
substantial robustness at the cost of security vulnerabilities. Further
analysis indicates that the VAE component drives this behavior through opposing
mechanisms where the encoder confers robustness via manifold regularization
while the decoder introduces vulnerabilities by amplifying latent perturbations
into detectable artifacts. These findings characterize the conflicting
architectural roles in generative steganography and establish a foundation for
future research.

</details>
