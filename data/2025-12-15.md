<div id=toc></div>

# Table of Contents

- [cs.CR](#cs.CR) [Total: 15]


<div id='cs.CR'></div>

# cs.CR [[Back]](#toc)

### [1] [SCOUT: A Defense Against Data Poisoning Attacks in Fine-Tuned Language Models](https://arxiv.org/abs/2512.10998)
*Mohamed Afane,Abhishek Satyam,Ke Chen,Tao Li,Junaid Farooq,Juntao Chen*

Main category: cs.CR

TL;DR: 本文提出SCOUT防御框架，通过token级显著性分析检测后门攻击，包括传统攻击和新型上下文感知攻击（ViralApp、Fever、Referral），在保持干净输入准确性的同时有效检测隐蔽威胁。


<details>
  <summary>Details</summary>
Motivation: 现有防御方法能有效应对明显的后门攻击（如上下文无关触发词），但无法检测使用上下文适当触发词的复杂攻击。这些攻击利用领域特定知识，在保持语义连贯性的同时操纵模型行为，对医疗等敏感领域构成严重威胁。

Method: 提出SCOUT防御框架，通过构建token级显著性图来检测后门触发词。该方法通过测量移除单个token对目标标签输出logits的影响来识别可疑token，不依赖传统基于上下文的检测方法。

Result: 在标准基准数据集（SST-2、IMDB、AG News）上评估SCOUT，结果显示它能成功检测传统攻击（BadNet、AddSent等）和新型上下文感知攻击，同时保持干净输入的准确性。

Conclusion: SCOUT框架通过token级显著性分析有效检测各种后门攻击，包括传统攻击和新型上下文感知攻击，为语言模型提供了更全面的安全防护，特别是在医疗等敏感领域。

Abstract: Backdoor attacks create significant security threats to language models by embedding hidden triggers that manipulate model behavior during inference, presenting critical risks for AI systems deployed in healthcare and other sensitive domains. While existing defenses effectively counter obvious threats such as out-of-context trigger words and safety alignment violations, they fail against sophisticated attacks using contextually-appropriate triggers that blend seamlessly into natural language. This paper introduces three novel contextually-aware attack scenarios that exploit domain-specific knowledge and semantic plausibility: the ViralApp attack targeting social media addiction classification, the Fever attack manipulating medical diagnosis toward hypertension, and the Referral attack steering clinical recommendations. These attacks represent realistic threats where malicious actors exploit domain-specific vocabulary while maintaining semantic coherence, demonstrating how adversaries can weaponize contextual appropriateness to evade conventional detection methods. To counter both traditional and these sophisticated attacks, we present \textbf{SCOUT (Saliency-based Classification Of Untrusted Tokens)}, a novel defense framework that identifies backdoor triggers through token-level saliency analysis rather than traditional context-based detection methods. SCOUT constructs a saliency map by measuring how the removal of individual tokens affects the model's output logits for the target label, enabling detection of both conspicuous and subtle manipulation attempts. We evaluate SCOUT on established benchmark datasets (SST-2, IMDB, AG News) against conventional attacks (BadNet, AddSent, SynBkd, StyleBkd) and our novel attacks, demonstrating that SCOUT successfully detects these sophisticated threats while preserving accuracy on clean inputs.

</details>


### [2] [An LLVM-Based Optimization Pipeline for SPDZ](https://arxiv.org/abs/2512.11112)
*Tianye Dai,Hammurabi Mendes,Heuichan Lim*

Main category: cs.CR

TL;DR: 基于LLVM的SPDZ协议优化框架，通过自动批处理、非阻塞调度和GPU支持，显著提升MPC性能，同时保持易用性。


<details>
  <summary>Details</summary>
Motivation: 当前MPC框架存在性能瓶颈：需要特定编译栈、程序员需显式表达并行性、通信开销高，限制了实际应用和可用性。

Method: 设计基于LLVM的优化流水线：前端接受带隐私标注的C语言子集，后端进行数据流和控制流分析，实现非阻塞运行时调度，支持GPU内核映射。

Result: CPU后端在中高负载下实现最高5.56倍加速，GPU后端随输入规模扩大表现更好，在线阶段性能显著优于MP-SPDZ。

Conclusion: 结合LLVM和协议感知调度是有效架构方向，可在不牺牲易用性的前提下自动提取并行性，提升MPC性能。

Abstract: Actively secure arithmetic MPC is now practical for real applications, but performance and usability are still limited by framework-specific compilation stacks, the need for programmers to explicitly express parallelism, and high communication overhead. We design and implement a proof-of-concept LLVM-based optimization pipeline for the SPDZ protocol that addresses these bottlenecks. Our front end accepts a subset of C with lightweight privacy annotations and lowers it to LLVM IR, allowing us to reuse mature analyses and transformations to automatically batch independent arithmetic operations. Our back end performs data-flow and control-flow analysis on the optimized IR to drive a non-blocking runtime scheduler that overlaps independent operations and aggressively overlaps communication with computation; when enabled, it can map batched operations to GPU kernels. This design preserves a low learning curve by using a mainstream language and hiding optimization and hardware-specific mechanics from programmers. We evaluate the system on controlled microbenchmarks against MP-SPDZ, focusing on online phase performance. Our CPU back end achieves up to 5.56 times speedup under intermediate and heavy algebraic workloads, shows strong scaling with thread count, and our GPU back end scales better as the input size increases. Overall, these results indicate that leveraging LLVM with protocol-aware scheduling is an effective architectural direction for extracting parallelism without sacrificing usability.

</details>


### [3] [Cybersecurity policy adoption in South Africa: Does public trust matter?](https://arxiv.org/abs/2512.11122)
*Mbali Nkosi,Mike Nkongolo*

Main category: cs.CR

TL;DR: 南非网络安全框架实施受公众感知影响的研究：通过系统文献综述发现，虽然全球范围内信任和公众情绪影响网络安全政策采纳，但在南非政策环境中这些因素影响甚微，尽管该国网络犯罪率高。研究提出了一个以信任为中心的政策制定框架。


<details>
  <summary>Details</summary>
Motivation: 研究动机是探讨公众感知如何影响南非网络安全框架的实施和采纳。尽管南非网络犯罪率高，但公众信任和情绪对政策采纳的影响尚未得到充分研究，需要理解这些因素在南非特定背景下的作用。

Method: 采用PRISMA方法论进行系统文献综述，在权威学术数据库中筛选出34篇符合预设纳入标准的文献。运用文献计量学和主题分析方法，辅以网络可视化技术，识别出网络安全、治理、信任、隐私、网络犯罪和公众意见等主要主题集群。

Result: 研究发现：1) 网络安全、治理、信任、隐私、网络犯罪和公众意见是主要主题集群；2) 虽然全球范围内信任和公众情绪显著影响网络安全政策采纳，但在南非政策环境中这些因素影响甚微；3) 尽管南非网络犯罪率高，但公众感知对政策采纳的影响有限。

Conclusion: 研究提出了一个以信任为中心的政策制定框架，旨在将公众感知作为网络安全治理的主动维度。该框架旨在防止信任赤字阻碍政策有效性，并为恢复已受损的信任提供指导，特别适用于南非等网络犯罪高发但公众感知影响有限的环境。

Abstract: This study examines how public perception influences the implementation and adoption of cybersecurity frameworks in South Africa. Using the PRISMA methodology, a systematic literature review was conducted across reputable scholarly databases, yielding 34 relevant sources aligned with predefined inclusion criteria. Cybersecurity, governance, trust, privacy, cybercrime, and public opinion emerged as dominant thematic clusters. Bibliometric and thematic analyses, supported by network visualisations, revealed that while trust and public sentiment affect cybersecurity policy adoption globally, these factors have minimal influence within the South African policy landscape, despite the country's high cybercrime prevalence. In response, the study proposes a trust-centric policymaking framework designed to integrate public perception as a proactive dimension of cybersecurity governance. This framework seeks to prevent trust deficits from obstructing policy effectiveness and provides guidance for restoring trust where it has eroded.

</details>


### [4] [Network and Compiler Optimizations for Efficient Linear Algebra Kernels in Private Transformer Inference](https://arxiv.org/abs/2512.11135)
*Karthik Garimella,Negar Neda,Austin Ebel,Nandan Kumar Jha,Brandon Reagen*

Main category: cs.CR

TL;DR: 该论文探索了在完全同态加密（FHE）环境下实现Transformer推理的线性代数核，比较了两种线性变换方法，并引入网络级剪枝策略来降低FHE计算成本。


<details>
  <summary>Details</summary>
Motivation: 当前基于LLM的服务采用客户端-服务器架构，查询数据需要在云端明文处理，存在隐私泄露风险。FHE可以在加密数据上直接计算，但Transformer推理在FHE中实现困难，需要将标准核映射到FHE受限指令集。

Method: 利用Orion PyTorch到FHE框架对线性代数核进行基准测试，分析两种线性变换方法（packed row和BSGS），引入网络级剪枝策略，扩展Orion支持密文-密文矩阵乘法，并进行屋顶线分析。

Result: BSGS方法在Transformer规模上比packed row方法快13.7倍；网络剪枝使前馈层FHE运行时间减少11.46倍；FHE原语和加密线性变换是内存受限的，每字节DRAM流量仅有约0.1个整数操作。

Conclusion: 需要在CKKS中探索替代编码方案和计算模型，以实现可扩展的私有Transformer推理。FHE实现目前受内存带宽限制，需要进一步优化。

Abstract: Large language model (LLM) based services are primarily structured as client-server interactions, with clients sending queries directly to cloud providers that host LLMs. This approach currently compromises data privacy as all queries must be processed in the cloud and in the clear. Fully Homomorphic Encryption (FHE) is a solution to this data privacy issue by enabling computations directly upon encrypted queries. However, running encrypted transformer inference is challenging as programmers must map standard kernels to the constrained instruction set provided by FHE. In this work, we explore implementations of linear algebra kernels needed for transformer inference in FHE and understand how network optimization can help mitigate FHE costs while remaining performant.
  We leverage the Orion PyTorch to FHE framework to benchmark several linear algebra kernels in order to profile two linear transformation methods, packed row and BSGS, and find that BSGS outperforms packed row methods by up to $13.7 \times$ at transformer-level scales. We also incorporate network-level pruning strategies that reduce FHE runtimes of feed forward layers by up to $11.46\times$. Furthermore, we extend Orion to include ciphertext-ciphertext matrix-matrix products, a key component in the self-attention blocks. Finally, we perform a roofline analysis of FHE primitives and encrypted linear transformations and find that (SIMD encoded) implementations are memory-bound with primitives having roughly $0.1$ integer operations per byte of DRAM traffic. These findings illustrate the need for exploring alternative encoding schemes and models of computation within CKKS to unlock scalable private transformer inference. We conduct all experiments using the Orion framework which can be found at: https://github.com/baahl-nyu/orion.

</details>


### [5] [Automated Penetration Testing with LLM Agents and Classical Planning](https://arxiv.org/abs/2512.11143)
*Lingzhi Wang,Xinyi Shi,Ziyu Li,Yi Jiang,Shiyu Tan,Yuhao Jiang,Junjie Cheng,Wenyuan Chen,Xiangmin Shen,Zhenyuan LI,Yan Chen*

Main category: cs.CR

TL;DR: 论文提出CHECKMATE框架，通过增强经典规划与LLM代理结合，显著提升自动化渗透测试能力，相比现有最佳系统成功率提高20%以上，成本降低50%以上。


<details>
  <summary>Details</summary>
Motivation: 自动化渗透测试是网络安全重要但具有挑战性的研究方向，现有基于LLM的代理系统在长期规划、复杂推理和工具使用方面存在局限，限制了其整体能力、效率和稳定性。

Method: 提出"规划器-执行器-感知器(PEP)"设计范式用于系统分析现有工作，并开发CHECKMATE框架，将增强的经典规划与LLM代理集成，提供外部结构化"大脑"来弥补LLM代理的固有弱点。

Result: 评估显示Claude Code和Sonnet 4.5在现有系统中表现最佳，但CHECKMATE框架在渗透能力上超越最先进系统(Claude Code)，基准成功率提高20%以上，稳定性大幅提升，时间和金钱成本降低50%以上。

Conclusion: CHECKMATE框架通过结合经典规划与LLM代理，有效解决了自动化渗透测试中的关键挑战，显著提升了系统性能、稳定性和成本效益，为完全自动化渗透测试提供了有前景的解决方案。

Abstract: While penetration testing plays a vital role in cybersecurity, achieving fully automated, hands-off-the-keyboard execution remains a significant research challenge. In this paper, we introduce the "Planner-Executor-Perceptor (PEP)" design paradigm and use it to systematically review existing work and identify the key challenges in this area. We also evaluate existing penetration testing systems, with a particular focus on the use of Large Language Model (LLM) agents for this task. The results show that the out-of-the-box Claude Code and Sonnet 4.5 exhibit superior penetration capabilities observed to date, substantially outperforming all prior systems. However, a detailed analysis of their testing processes reveals specific strengths and limitations; notably, LLM agents struggle with maintaining coherent long-horizon plans, performing complex reasoning, and effectively utilizing specialized tools. These limitations significantly constrain its overall capability, efficiency, and stability. To address these limitations, we propose CHECKMATE, a framework that integrates enhanced classical planning with LLM agents, providing an external, structured "brain" that mitigates the inherent weaknesses of LLM agents. Our evaluation shows that CHECKMATE outperforms the state-of-the-art system (Claude Code) in penetration capability, improving benchmark success rates by over 20%. In addition, it delivers substantially greater stability, cutting both time and monetary costs by more than 50%.

</details>


### [6] [MiniScope: A Least Privilege Framework for Authorizing Tool Calling Agents](https://arxiv.org/abs/2512.11147)
*Jinhao Zhu,Kevin Tseng,Gil Vernik,Xiao Huang,Shishir G. Patil,Vivian Fang,Raluca Ada Popa*

Main category: cs.CR

TL;DR: MiniScope是一个工具调用代理安全框架，通过自动重构权限层次结构和移动式权限模型，在保证安全性的同时最小化权限授予，仅带来1-6%的性能开销。


<details>
  <summary>Details</summary>
Motivation: 当前工具调用代理（如ChatGPT、Claude、Gemini）在敏感用户服务上运行时存在安全风险。现有方法要么依赖手动编写策略需要安全专业知识，要么将LLM置于缺乏严格安全保障的约束循环中。

Method: MiniScope通过重构工具调用关系的权限层次结构，结合移动式权限模型，自动且严格地执行最小权限原则。该方法平衡了安全性和易用性。

Result: 在从10个流行真实应用构建的合成数据集上评估，MiniScope相比基础工具调用代理仅带来1-6%的延迟开销，同时在最小化权限、计算和运营成本方面显著优于基于LLM的基线方法。

Conclusion: MiniScope为工具调用代理提供了一个安全框架，能够在用户账户上操作时限制不可靠LLM的潜在损害，实现了安全性和性能的良好平衡。

Abstract: Tool calling agents are an emerging paradigm in LLM deployment, with major platforms such as ChatGPT, Claude, and Gemini adding connectors and autonomous capabilities. However, the inherent unreliability of LLMs introduces fundamental security risks when these agents operate over sensitive user services. Prior approaches either rely on manually written policies that require security expertise, or place LLMs in the confinement loop, which lacks rigorous security guarantees. We present MiniScope, a framework that enables tool calling agents to operate on user accounts while confining potential damage from unreliable LLMs. MiniScope introduces a novel way to automatically and rigorously enforce least privilege principles by reconstructing permission hierarchies that reflect relationships among tool calls and combining them with a mobile-style permission model to balance security and ease of use. To evaluate MiniScope, we create a synthetic dataset derived from ten popular real-world applications, capturing the complexity of realistic agentic tasks beyond existing simplified benchmarks. Our evaluation shows that MiniScope incurs only 1-6% latency overhead compared to vanilla tool calling agents, while significantly outperforming the LLM based baseline in minimizing permissions as well as computational and operational costs.

</details>


### [7] [A Scalable Multi-GPU Framework for Encrypted Large-Model Inference](https://arxiv.org/abs/2512.11269)
*Siddharth Jayashankar,Joshua Kim,Michael B. Sullivan,Wenting Zheng,Dimitrios Skarlatos*

Main category: cs.CR

TL;DR: Cerium是一个多GPU框架，用于全同态加密（FHE）的大模型推理，通过自动生成高性能GPU内核、管理TB级内存和多GPU并行化，实现了接近ASIC的性能，首次在GPU上实现了BERT-Base和Llama3-8B的加密推理。


<details>
  <summary>Details</summary>
Motivation: FHE提供强隐私保证但性能慢，ASIC加速方案成本高且难以普及，GPU更易获取但难以达到ASIC级性能。现有方法主要针对小模型，大模型（如LLM）的FHE推理需要TB级内存管理和多GPU并行化，这是当前GPU平台面临的挑战。

Method: Cerium集成了领域特定语言、优化编译器和运行时系统，包含新的IR构造、编译器传递、稀疏多项式表示、内存高效数据布局和通信感知并行化技术，自动生成高性能GPU内核，管理TB级内存，并在多GPU间并行化计算。

Result: 小模型性能比专家手写GPU库快2.25倍；性能与最先进FHE ASIC竞争，匹配CraterLake ASIC；首次在GPU上实现10毫秒以下的引导（7.5毫秒）；首次实现BERT-Base（8秒）和Llama3-8B（134秒）的加密推理。

Conclusion: Cerium证明了GPU平台能够实现接近ASIC性能的FHE推理，支持从CNN到Llama3-8B的各种规模模型，为加密AI的实际部署提供了更易获取的高性能解决方案。

Abstract: Encrypted AI using fully homomorphic encryption (FHE) provides strong privacy guarantees; but its slow performance has limited practical deployment. Recent works proposed ASICs to accelerate FHE, but require expensive advanced manufacturing processes that constrain their accessibility. GPUs are a far more accessible platform, but achieving ASIC-level performance using GPUs has remained elusive. Furthermore, state-of-the-art approaches primarily focus on small models that fit comfortably within a single device. Supporting large models such as LLMs in FHE introduces a dramatic increase in computational complexity that requires optimized GPU kernels, along with managing terabyte-scale memory footprints that far exceed the capacity of a single GPU. This paper presents Cerium, a multi-GPU framework for FHE inference on large models. Cerium integrates a domain-specific language, an optimizing compiler, and a runtime system to automatically generate high-performance GPU kernels, manage terabyte-scale memory footprints, and parallelize computation across multiple GPUs. It introduces new IR constructs, compiler passes, sparse polynomial representations, memory-efficient data layouts, and communication-aware parallelization techniques that together enable encrypted inference for models ranging from small CNNs to Llama3-8B. We build Cerium on NVIDIA GPUs and demonstrate significant performance gains. For small models, Cerium outperforms expert-written hand-optimized GPU libraries by up to 2.25 times. Cerium achieves performance competitive with state-of-the-art FHE ASICs, outright matching prior FHE ASIC CraterLake. It is the first GPU system to execute bootstrapping in under 10 milliseconds, achieving 7.5 milliseconds, and is the first to demonstrate encrypted inference for BERT-Base and Llama3-8B in 8 seconds and 134 seconds, respectively.

</details>


### [8] [Vision-Based Learning for Cyberattack Detection in Blockchain Smart Contracts and Transactions](https://arxiv.org/abs/2512.11272)
*Do Hai Son,Le Vu Hieu,Tran Viet Khoa,Yibeltal F. Alem,Hoang Trong Minh,Tran Thi Thuy Quynh,Nguyen Viet Ha,Nguyen Linh Trung*

Main category: cs.CR

TL;DR: 提出结合NLP和视觉Transformer的区块链攻击检测框架，将交易特征转换为图像，通过ViT分析，在基准数据集上达到99.5%准确率。


<details>
  <summary>Details</summary>
Motivation: 区块链技术在各行业广泛应用，但平台易受针对交易和智能合约的网络攻击，导致数字资产被盗或系统完整性受损，需要有效的攻击检测方案。

Method: 1. 使用NLP技术预处理区块链交易关键特征，将其转换为图像表示；2. 采用Vision Transformer（ViT）进行视觉分析，利用其捕捉复杂模式和语义关系的能力；3. 结合NLP预处理和视觉学习，构建攻击检测框架。

Result: 在基准数据集上的实验评估显示，该方法在准确率（99.5%）和鲁棒性方面显著优于现有最先进方法，能有效检测多种区块链攻击类型。

Conclusion: 提出的NLP-ViT集成框架为区块链系统提供了一种新颖有效的网络攻击检测方案，通过将交易特征转换为图像并利用视觉Transformer分析，实现了高精度和鲁棒的攻击检测。

Abstract: Blockchain technology has experienced rapid growth and has been widely adopted across various sectors, including healthcare, finance, and energy. However, blockchain platforms remain vulnerable to a broad range of cyberattacks, particularly those aimed at exploiting transactions and smart contracts (SCs) to steal digital assets or compromise system integrity. To address this issue, we propose a novel and effective framework for detecting cyberattacks within blockchain systems. Our framework begins with a preprocessing tool that uses Natural Language Processing (NLP) techniques to transform key features of blockchain transactions into image representations. These images are then analyzed through vision-based analysis using Vision Transformers (ViT), a recent advancement in computer vision known for its superior ability to capture complex patterns and semantic relationships. By integrating NLP-based preprocessing with vision-based learning, our framework can detect a wide variety of attack types. Experimental evaluations on benchmark datasets demonstrate that our approach significantly outperforms existing state-of-the-art methods in terms of both accuracy (achieving 99.5%) and robustness in cyberattack detection for blockchain transactions and SCs.

</details>


### [9] [Visualisation for the CIS benchmark scanning results](https://arxiv.org/abs/2512.11316)
*Zhenshuo Zhao,Maria Spichkova,Duttkumari Champavat,Juilee N. Kulkarni,Sahil Singla,Muhammad A. Zulkefli,Pradhuman Khandelwal*

Main category: cs.CR

TL;DR: GraphSecure是一个用于分析和可视化AWS安全扫描结果的Web应用，支持CIS基准验证并提供统计图表展示


<details>
  <summary>Details</summary>
Motivation: 解决AWS账户安全扫描结果分析和可视化不足的问题，帮助用户更好地理解和评估其云安全状况

Method: 开发Web应用程序，集成AWS扫描功能，实现CIS基准验证，创建统计图表和告警系统

Result: 成功构建了GraphSecure系统，能够扫描AWS账户、验证CIS合规性、可视化扫描结果并提供账户状态告警

Conclusion: GraphSecure为AWS安全监控提供了有效的分析和可视化工具，帮助用户提升云安全管理和合规性评估能力

Abstract: In this paper, we introduce GraphSecure, a web application that provides advanced analysis and visualisation of security scanning results. GraphSecure enables users to initiate scans for their AWS account, validate them against specific Center for Internet Security (CIS) Benchmarks and return results, showcase those returned results in the form of statistical charts and warn the users about their account status.

</details>


### [10] [Proving DNSSEC Correctness: A Formal Approach to Secure Domain Name Resolution](https://arxiv.org/abs/2512.11431)
*Qifan Zhang,Zilin Shen,Imtiaz Karim,Elisa Bertino,Zhou Li*

Main category: cs.CR

TL;DR: DNSSECVerif是首个用于DNSSEC协议套件全面自动化形式安全分析的框架，通过形式化验证发现了协议设计中的根本性弱点，包括NSEC和NSEC3的不安全共存问题，并通过大规模测量研究确认了这些漏洞的现实影响。


<details>
  <summary>Details</summary>
Motivation: DNSSEC对于防止DNS欺骗至关重要，但其规范存在模糊性和漏洞，传统"破坏-修复"方法难以发现。对协议进行全面、基础性的安全分析一直是一个开放性问题。

Method: 基于SAPIC+符号验证器构建DNSSECVerif框架，建立高保真模型捕获协议级交互，包括加密操作和具有细粒度并发控制的状态缓存。通过形式化验证证明安全保证并发现漏洞，最后通过主流DNS软件测试和对220多万个开放解析器的大规模测量研究验证发现。

Result: 形式化证明了DNSSEC的四个核心安全保证，发现了标准中的关键模糊性（特别是NSEC和NSEC3的不安全共存），自动重新发现了三类已知攻击，展示了协议设计的根本弱点。大规模测量确认了这些漏洞在现实世界中的影响。

Conclusion: 这项工作为强化DNSSEC规范和实现提供了关键、基于证据的建议，填补了DNSSEC全面形式化安全分析的空白，揭示了协议设计中的根本性安全问题。

Abstract: The Domain Name System Security Extensions (DNSSEC) are critical for preventing DNS spoofing, yet its specifications contain ambiguities and vulnerabilities that elude traditional "break-and-fix" approaches. A holistic, foundational security analysis of the protocol has thus remained an open problem. This paper introduces DNSSECVerif, the first framework for comprehensive, automated formal security analysis of the DNSSEC protocol suite. Built on the SAPIC+ symbolic verifier, our high-fidelity model captures protocol-level interactions, including cryptographic operations and stateful caching with fine-grained concurrency control. Using DNSSECVerif, we formally prove four of DNSSEC's core security guarantees and uncover critical ambiguities in the standards--notably, the insecure coexistence of NSEC and NSEC3. Our model also automatically rediscovers three classes of known attacks, demonstrating fundamental weaknesses in the protocol design. To bridge the model-to-reality gap, we validate our findings through targeted testing of mainstream DNS software and a large-scale measurement study of over 2.2 million open resolvers, confirming the real-world impact of these flaws. Our work provides crucial, evidence-based recommendations for hardening DNSSEC specifications and implementations.

</details>


### [11] [Capacitive Touchscreens at Risk: Recovering Handwritten Trajectory on Smartphone via Electromagnetic Emanations](https://arxiv.org/abs/2512.11484)
*Yukun Cheng,Shiyu Zhu,Changhai Ou,Xingshuo Han,Yuan Li,Shihui Zheng*

Main category: cs.CR

TL;DR: TESLA攻击利用电容触摸屏的电磁侧信道泄露，通过非接触方式捕获书写时的电磁信号，实时恢复出手写轨迹，在商用手机上达到77%的字符识别准确率。


<details>
  <summary>Details</summary>
Motivation: 揭示电容触摸屏存在严重的电磁侧信道安全漏洞，攻击者无需物理接触即可窃取用户在触摸屏上的手写输入信息，这对隐私和安全构成重大威胁。

Method: 提出TESLA攻击框架：1）捕获触摸屏书写时产生的电磁信号；2）通过回归分析将电磁信号转换为二维手写轨迹；3）实时处理实现攻击。

Result: 在多种商用智能手机上的广泛评估显示：字符识别准确率达到77%，Jaccard指数为0.74，能够恢复出高度可识别且接近原始笔迹的运动轨迹。

Conclusion: 电容触摸屏的电磁侧信道泄露严重安全漏洞，TESLA攻击证明攻击者能够非接触地恢复精细手写轨迹，需要新的安全防护措施来应对此类威胁。

Abstract: This paper reveals and exploits a critical security vulnerability: the electromagnetic (EM) side channel of capacitive touchscreens leaks sufficient information to recover fine-grained, continuous handwriting trajectories. We present Touchscreen Electromagnetic Side-channel Leakage Attack (TESLA), a non-contact attack framework that captures EM signals generated during on-screen writing and regresses them into two-dimensional (2D) handwriting trajectories in real time. Extensive evaluations across a variety of commercial off-the-shelf (COTS) smartphones show that TESLA achieves 77% character recognition accuracy and a Jaccard index of 0.74, demonstrating its capability to recover highly recognizable motion trajectories that closely resemble the original handwriting under realistic attack conditions.

</details>


### [12] [Granite: Granular Runtime Enforcement for GitHub Actions Permissions](https://arxiv.org/abs/2512.11602)
*Mojtaba Moazen,Amir. M Ahmadian,Musard Balliu*

Main category: cs.CR

TL;DR: Granite是一个运行时代理系统，为GitHub Actions提供细粒度的步骤级权限控制，防止权限滥用攻击，减少CI/CD攻击面。


<details>
  <summary>Details</summary>
Motivation: GitHub Actions现有的作业级权限模型过于粗粒度，违反最小权限原则，导致权限滥用攻击风险，可能引发更广泛的软件供应链攻击。

Method: Granite采用运行时代理架构，透明监控JavaScript和复合动作的请求，根据预定义的步骤级策略进行运行时检查。

Result: 评估显示52.7%的作业可通过Granite得到保护；在20个顶级仓库测试中，成功预防了10种权限滥用攻击，平均每个作业增加55%（3.67秒）的开销。

Conclusion: Granite能有效减少CI/CD攻击面，通过细粒度的步骤级权限控制增强GitHub Actions的安全性。

Abstract: Modern software projects use automated CI/CD pipelines to streamline their development, build, and deployment processes. GitHub Actions is a popular CI/CD platform that enables project maintainers to create custom workflows -- collections of jobs composed of sequential steps -- using reusable components known as actions. Wary of the security risks introduced by fully-privileged actions, GitHub provides a job-level permission model for controlling workflow access to repository resources. Unfortunately, this model is too coarse-grained to reduce the attack surface pertaining to permission misuse attacks: All actions within a job share the same permissions granted to the job. This violates the principle of least privilege and can lead to broader software supply chain attacks, whenever a compromised action exploits the granted permissions to compromise the repository resources. In this paper, we present Granite, a runtime proxy-based system that enforces fine-grained permissions for GitHub Actions at the step-level granularity within a job. Granite transparently monitors requests made by JavaScript and composite actions during workflow execution and checks them against predefined step-level policies at runtime. We evaluate Granite in terms of compatibility, security, and performance overhead using a dataset of 500 workflows comprising 12,916 jobs from the most-starred GitHub repositories that use GitHub Actions. Our analysis reveals that 52.7% of the jobs can be protected by Granite against permission misuse attacks. We evaluate Granite on 20 top-starred repositories (63 actions, 58 workflows), validate attack prevention using 10 permission misuse attacks across 42 overprivileged jobs, and measure an average overhead of 55% (3.67 seconds) per job, concluding that Granite effectively reduces CI/CD attack surfaces.

</details>


### [13] [Leveraging FPGAs for Homomorphic Matrix-Vector Multiplication in Oblivious Message Retrieval](https://arxiv.org/abs/2512.11690)
*Grant Bosworth,Keewoo Lee,Sunwoong Kim*

Main category: cs.CR

TL;DR: 本文提出了一种硬件架构来加速Oblivious Message Retrieval中的同态矩阵向量乘法，相比软件实现获得13.86倍加速


<details>
  <summary>Details</summary>
Motivation: 端到端加密保护消息内容但不保护元数据，Oblivious Message Retrieval使用同态加密来保护元数据隐私，但其核心的同态矩阵向量乘法计算密集，限制了实际应用

Method: 提出硬件架构加速同态矩阵向量乘法算法，使用高层次综合实现同态算子，设计不同并行度参数，在FPGA平台上采用高效设计空间探索策略部署

Result: 相比软件实现，提出的硬件加速器实现了13.86倍的加速

Conclusion: 硬件加速显著提升了Oblivious Message Retrieval中同态矩阵向量乘法的性能，使其更具实用性

Abstract: While end-to-end encryption protects the content of messages, it does not secure metadata, which exposes sender and receiver information through traffic analysis. A plausible approach to protecting this metadata is to have senders post encrypted messages on a public bulletin board and receivers scan it for relevant messages. Oblivious message retrieval (OMR) leverages homomorphic encryption (HE) to improve user experience in this solution by delegating the scan to a resource-rich server while preserving privacy. A key process in OMR is the homomorphic detection of pertinent messages for the receiver from the bulletin board. It relies on a specialized matrix-vector multiplication algorithm, which involves extensive multiplications between ciphertext vectors and plaintext matrices, as well as homomorphic rotations. The computationally intensive nature of this process limits the practicality of OMR. To address this challenge, this paper proposes a hardware architecture to accelerate the matrix-vector multiplication algorithm. The building homomorphic operators in this algorithm are implemented using high-level synthesis, with design parameters for different parallelism levels. These operators are then deployed on a field-programmable gate array platform using an efficient design space exploration strategy to accelerate homomorphic matrix-vector multiplication. Compared to a software implementation, the proposed hardware accelerator achieves a 13.86x speedup.

</details>


### [14] [SoK: Demystifying the multiverse of MPC protocols](https://arxiv.org/abs/2512.11699)
*Roberta De Viti,Vaastav Anand,Pierfrancesco Ingo,Deepak Garg*

Main category: cs.CR

TL;DR: 该论文系统化研究了多方计算(MPC)协议的性能，通过理论分析和大量实验评估不同协议的效率，为开发者提供实用指导，旨在缩小MPC理论与实践的差距。


<details>
  <summary>Details</summary>
Motivation: 尽管MPC具有强大的隐私和正确性保证，但在实际应用中采用仍然有限，主要原因是恶意设置下的高成本和缺乏针对具体工作负载选择合适协议的指导。

Method: 识别影响MPC效率的理论和实践参数，进行跨多样化基准测试的广泛实验研究，分析不同协议之间的权衡。

Result: 分析讨论了不同协议之间的权衡，并突出了哪些技术最适合不同的应用场景和需求。

Conclusion: 通过为开发者提供可操作的指导并为研究人员概述开放挑战，这项工作旨在缩小MPC理论与实践的差距。

Abstract: This paper systematizes knowledge on the performance of Multi-Party Computation (MPC) protocols. Despite strong privacy and correctness guarantees, MPC adoption in real-world applications remains limited by high costs (especially in the malicious setting) and lack of guidance on choosing suitable protocols for concrete workloads. We identify the theoretical and practical parameters that shape MPC efficiency and conduct an extensive experimental study across diverse benchmarks. Our analysis discusses the trade-offs between protocols, and highlights which techniques align best with different application scenarios and needs. By providing actionable guidance for developers and outlining open challenges for researchers, this work seeks to narrow the gap between MPC theory and practice.

</details>


### [15] [Super Suffixes: Bypassing Text Generation Alignment and Guard Models Simultaneously](https://arxiv.org/abs/2512.11783)
*Andrew Adiletta,Kathryn Adiletta,Kemal Derya,Berk Sunar*

Main category: cs.CR

TL;DR: 本文提出Super Suffixes攻击方法，可绕过Llama Prompt Guard 2等防护模型，并开发DeltaGuard检测方法来防御此类攻击。


<details>
  <summary>Details</summary>
Motivation: 随着大语言模型（LLMs）的广泛部署，处理不可信文本输入和执行代码生成时面临安全隐私风险。现有防护模型（如Llama Prompt Guard 2）存在被绕过风险，需要研究更强大的攻击和防御方法。

Method: 1. 提出Super Suffixes攻击方法：通过联合优化技术生成能绕过多种对齐目标和不同分词方案的通用后缀；2. 开发DeltaGuard防御方法：通过分析模型内部状态与特定概念方向的余弦相似度变化来检测恶意提示。

Result: 1. Super Suffixes成功绕过Llama Prompt Guard 2对5个文本生成模型的保护，实现恶意文本和代码生成；2. DeltaGuard将非良性分类率提升至近100%，显著增强对抗性提示攻击的检测能力。

Conclusion: 本研究首次揭示Llama Prompt Guard 2可通过联合优化被绕过，同时提出的DeltaGuard检测方法能有效防御Super Suffixes攻击，为防护模型栈提供了有价值的增强方案。

Abstract: The rapid deployment of Large Language Models (LLMs) has created an urgent need for enhanced security and privacy measures in Machine Learning (ML). LLMs are increasingly being used to process untrusted text inputs and even generate executable code, often while having access to sensitive system controls. To address these security concerns, several companies have introduced guard models, which are smaller, specialized models designed to protect text generation models from adversarial or malicious inputs. In this work, we advance the study of adversarial inputs by introducing Super Suffixes, suffixes capable of overriding multiple alignment objectives across various models with different tokenization schemes. We demonstrate their effectiveness, along with our joint optimization technique, by successfully bypassing the protection mechanisms of Llama Prompt Guard 2 on five different text generation models for malicious text and code generation. To the best of our knowledge, this is the first work to reveal that Llama Prompt Guard 2 can be compromised through joint optimization.
  Additionally, by analyzing the changing similarity of a model's internal state to specific concept directions during token sequence processing, we propose an effective and lightweight method to detect Super Suffix attacks. We show that the cosine similarity between the residual stream and certain concept directions serves as a distinctive fingerprint of model intent. Our proposed countermeasure, DeltaGuard, significantly improves the detection of malicious prompts generated through Super Suffixes. It increases the non-benign classification rate to nearly 100%, making DeltaGuard a valuable addition to the guard model stack and enhancing robustness against adversarial prompt attacks.

</details>
