<div id=toc></div>

# Table of Contents

- [cs.CR](#cs.CR) [Total: 36]


<div id='cs.CR'></div>

# cs.CR [[Back]](#toc)

### [1] [A Comparative Study of Hybrid Post-Quantum Cryptographic X.509 Certificate Schemes](https://arxiv.org/abs/2511.00111)
*Abel C. H. Chen*

Main category: cs.CR

TL;DR: 本文对基于X.509证书格式的三种后量子密码混合证书方案（复合方案、催化剂方案和变色龙方案）进行了全面分析和比较，评估它们在证书大小、计算效率和迁移可行性等方面的适用性。


<details>
  <summary>Details</summary>
Motivation: 随着量子计算硬件的进步，RSA和椭圆曲线密码学可能被量子算法在多项式时间内破解。NIST在2024年8月发布了后量子密码标准并制定了迁移路线图，因此设计符合PQC标准的X.509证书成为证书管理系统开发的关键焦点。

Method: 对国际上提出的三种混合证书方案进行多角度分析比较，包括证书大小、计算效率和迁移可行性等维度。

Result: 通过综合比较评估了不同混合证书方案在各种应用和服务中的适用性。

Conclusion: 混合证书方案能够增强安全性并促进平滑迁移过程，不同方案在不同应用场景下具有各自的优势和适用性。

Abstract: As quantum computing hardware continues to advance, the integration of such
technology with quantum algorithms is anticipated to enable the decryption of
ciphertexts produced by RSA and Elliptic Curve Cryptography (ECC) within
polynomial time. In response to this emerging threat, the U.S. National
Institute of Standards and Technology (NIST) finalized a series of Post-Quantum
Cryptography (PQC) standards in August 2024 and outlined a roadmap for PQC
migration. Consequently, the design of X.509 certificates that adhere to PQC
standards has become a crucial focus in the development of certificate
management systems. To further strengthen security and facilitate a smooth
migration process, several hybrid certificate schemes have been proposed
internationally based on the X.509 certificate format, including the composite
scheme, the catalyst scheme, and the chameleon scheme. This study presents a
comprehensive analysis and comparison of these hybrid certificate schemes from
multiple perspectives (e.g., certificate size, computational efficiency, and
migration feasibility) to assess their suitability for various applications and
services.

</details>


### [2] [Real-time and Zero-footprint Bag of Synthetic Syllables Algorithm for E-mail Spam Detection Using Subject Line and Short Text Fields](https://arxiv.org/abs/2511.00118)
*Stanislav Selitskiy*

Main category: cs.CR

TL;DR: 提出了一种基于合成音节袋算法的轻量级垃圾邮件检测方法，专门针对邮件主题行等短文本，无需额外资源即可实时检测相似垃圾邮件。


<details>
  <summary>Details</summary>
Motivation: 现代电子邮件服务面临高可用性要求和资源限制，深度学习架构资源消耗大且处理时间长，不适合作为前端过滤器。大部分垃圾邮件并不复杂，可以通过简单算法检测。

Method: 使用合成音节袋算法为每个邮件主题行生成约200维的稀疏哈希向量，通过余弦或欧几里得距离比较与已知垃圾邮件主题的相似性。

Result: 在真实SMTP流量的一天数据上测试了算法性能，证明其有效性。

Conclusion: 该算法无需持久存储、字典、额外硬件或软件包，能够减轻深度学习架构的压力，实现近实时、零资源占用的垃圾邮件检测。

Abstract: Contemporary e-mail services have high availability expectations from the
customers and are resource-strained because of the high-volume throughput and
spam attacks. Deep Machine Learning architectures, which are resource hungry
and require off-line processing due to the long processing times, are not
acceptable at the front line filters. On the other hand, the bulk of the
incoming spam is not sophisticated enough to bypass even the simplest
algorithms. While the small fraction of the intelligent, highly mutable spam
can be detected only by the deep architectures, the stress on them can be
unloaded by the simple near real-time and near zero-footprint algorithms such
as the Bag of Synthetic Syllables algorithm applied to the short texts of the
e-mail subject lines and other short text fields. The proposed algorithm
creates a circa 200 sparse dimensional hash or vector for each e-mail subject
line that can be compared for the cosine or euclidean proximity distance to
find similarities to the known spammy subjects. The algorithm does not require
any persistent storage, dictionaries, additional hardware upgrades or software
packages. The performance of the algorithm is presented on the one day of the
real SMTP traffic.

</details>


### [3] [Supply Chain Exploitation of Secure ROS 2 Systems: A Proof-of-Concept on Autonomous Platform Compromise via Keystore Exfiltration](https://arxiv.org/abs/2511.00140)
*Tahmid Hasan Sakib,Yago Romano Martinez,Carter Brady,Syed Rafay Hasan,Terry N. Guo*

Main category: cs.CR

TL;DR: 本文展示了对SROS 2框架的概念验证供应链攻击，通过受感染的Debian包窃取密钥库凭证，使攻击者能够重新加入网络并发布虚假控制或感知消息，导致自动驾驶车辆出现危险行为。


<details>
  <summary>Details</summary>
Motivation: 揭示SROS 2安全框架在实际应用中的供应链漏洞，证明即使使用安全通信协议，如果供应链被破坏，攻击者仍能获得合法凭证并实施破坏性攻击。

Method: 通过特洛伊木马感染的Debian包修改ROS 2安全命令，将新生成的密钥库凭证通过DNS以base64编码块的形式外泄到攻击者控制的域名服务器。

Result: 实验结果显示，控制主题注入可导致强制刹车、持续高速加速和连续转弯循环；感知主题欺骗可诱导虚假停车标志或抑制真实检测。攻击可推广到任何使用SROS 2的DDS机器人系统。

Conclusion: 需要供应链完整性控制和运行时语义验证来保护自主系统免受内部和冒充威胁。

Abstract: This paper presents a proof-of-concept supply chain attack against the Secure
ROS 2 (SROS 2) framework, demonstrated on a Quanser QCar2 autonomous vehicle
platform. A Trojan-infected Debian package modifies core ROS 2 security
commands to exfiltrate newly generated keystore credentials via DNS in
base64-encoded chunks to an attacker-controlled nameserver. Possession of these
credentials enables the attacker to rejoin the SROS 2 network as an
authenticated participant and publish spoofed control or perception messages
without triggering authentication failures. We evaluate this capability on a
secure ROS 2 Humble testbed configured for a four-stop-sign navigation routine
using an Intel RealSense camera for perception. Experimental results show that
control-topic injections can cause forced braking, sustained high-speed
acceleration, and continuous turning loops, while perception-topic spoofing can
induce phantom stop signs or suppress real detections. The attack generalizes
to any data distribution service (DDS)-based robotic system using SROS 2,
highlighting the need for both supply chain integrity controls and runtime
semantic validation to safeguard autonomous systems against insider and
impersonation threats.

</details>


### [4] [Identifying Linux Kernel Instability Due to Poor RCU Synchronization](https://arxiv.org/abs/2511.00237)
*Oisin O Sullivan,Colin Flanagan,Eoin O Connell*

Main category: cs.CR

TL;DR: 该论文研究了Linux内核中RCU保护哈希表在删除条目时缺乏显式synchronize_rcu()调用导致的同步问题，发现了Intel ICE网络驱动中的漏洞，会造成悬空指针、内存碎片和UAF漏洞。


<details>
  <summary>Details</summary>
Motivation: RCU在Linux内核中广泛用于管理共享数据结构的并发访问，但哈希表条目删除时的不当同步会导致悬空指针、查找不一致和关键的使用后释放漏洞，影响内核稳定性。

Method: 通过分析Intel ICE网络驱动中VF管理的实际漏洞案例，研究RCU哈希表在快速插入/删除工作负载下的同步问题，验证缺乏synchronize_rcu()的影响。

Result: 实验结果显示，删除VF条目时缺乏适当同步会导致瞬态陈旧条目、内存回收延迟，并在快速插入/删除工作负载下造成显著的内存碎片。

Conclusion: 建议显式插入synchronize_rcu()调用来确保及时安全的内存回收，这些发现强化了RCU同步的最佳实践，对维护内核稳定性和内存安全至关重要。

Abstract: Read-Copy-Update (RCU) is widely used in the Linux kernel to manage
concurrent access to shared data structures.However, improper synchronization
when removing RCU protected hash table entries can lead to stale pointers,
inconsistent lookups, and critical use after free (UAF) vulnerabilities. This
paper investigates a driver-level synchronization issue arising from the
omission of explicit synchronize_rcu() calls during hash table updates, using a
discovered weakness in the Intel ICE network drivers Virtual Function (VF)
management. Previous kernel vulnerabilities, such as a bug in the Reliable
Datagram Sockets (RDS) subsystem, show how improper RCU synchronization can
directly cause kernel crashes. Experimental results demonstrate that removing
VF entries without proper synchronization leaves transient stale entries,
delays memory reclamation, and results in significant memory fragmentation
under rapid insert/delete workloads. RCU hash tables are widely deployed in
Linux kernel subsystems such as networking, virtualization, and file systems;
improper synchronization can cause memory fragmentation, kernel instability,
and out-of-memory (OOM) conditions. Mitigations are proposed, recommending
explicit insertion of synchronize_rcu() calls to ensure timely and safe memory
reclamation. These findings reinforce established best practices for RCU
synchronization, highlighting their importance for maintaining kernel stability
and memory safety.
  Keywords: RCU, kernel synchronization, hash tables, ICE driver, memory
fragmentation, use-after-free

</details>


### [5] [Application of Blockchain Frameworks for Decentralized Identity and Access Management of IoT Devices](https://arxiv.org/abs/2511.00249)
*Sushil Khairnar*

Main category: cs.CR

TL;DR: 提出基于Hyperledger Fabric和DID的去中心化身份管理框架，用于提升物联网环境的安全性和用户控制权。


<details>
  <summary>Details</summary>
Motivation: 物联网设备增长带来数据安全风险，集中式系统存在隐私、控制和审查问题，需要转向去中心化架构。

Method: 使用Hyperledger Fabric和去中心化标识符(DID)构建身份管理框架，通过Node-RED模拟物联网数据流，实现设备注册、认证和安全资产查询功能。

Result: 成功实现关键功能，改善了数据完整性、透明度和用户控制，减少了对中心化机构的依赖。

Conclusion: 验证了基于区块链的身份管理在增强物联网基础设施安全性和可信度方面的实用性。

Abstract: The growth in IoT devices means an ongoing risk of data vulnerability. The
transition from centralized ecosystems to decentralized ecosystems is of
paramount importance due to security, privacy, and data use concerns. Since the
majority of IoT devices will be used by consumers in peer-to-peer applications,
a centralized approach raises many issues of trust related to privacy, control,
and censorship. Identity and access management lies at the heart of any
user-facing system. Blockchain technologies can be leveraged to augment user
authority, transparency, and decentralization. This study proposes a
decentralized identity management framework for IoT environments using
Hyperledger Fabric and Decentralized Identifiers (DIDs). The system was
simulated using Node-RED to model IoT data streams, and key functionalities
including device onboarding, authentication, and secure asset querying were
successfully implemented. Results demonstrated improved data integrity,
transparency, and user control, with reduced reliance on centralized
authorities. These findings validate the practicality of blockchain-based
identity management in enhancing the security and trustworthiness of IoT
infrastructures.

</details>


### [6] [Split Learning-Enabled Framework for Secure and Light-weight Internet of Medical Things Systems](https://arxiv.org/abs/2511.00336)
*Siva Sai,Manish Prasad,Animesh Bhargava,Vinay Chamola,Rajkumar Buyya*

Main category: cs.CR

TL;DR: 提出基于分割学习(SL)的IoMT恶意软件检测框架，通过图像分类方法解决资源受限设备的安全问题，相比联邦学习(FL)在准确率、F1分数、收敛速度和资源消耗方面均有显著提升。


<details>
  <summary>Details</summary>
Motivation: IoMT设备快速增长带来严重安全风险，传统深度学习方法在资源受限设备上不实用，而联邦学习存在通信开销大和对非独立同分布数据脆弱的缺点。

Method: 采用分割学习框架，将神经网络训练分割在客户端和边缘服务器之间，使用博弈论方法平衡计算成本和通信效率的联合优化问题。

Result: 实验评估显示，相比流行的联邦学习方法，准确率提升6.35%，F1分数提升5.03%，收敛速度加快14.96%，资源消耗减少33.83%。

Conclusion: 分割学习作为可扩展且安全的范式，在下一代物联网安全中具有巨大潜力。

Abstract: The rapid growth of Internet of Medical Things (IoMT) devices has resulted in
significant security risks, particularly the risk of malware attacks on
resource-constrained devices. Conventional deep learning methods are
impractical due to resource limitations, while Federated Learning (FL) suffers
from high communication overhead and vulnerability to non-IID (heterogeneous)
data. In this paper, we propose a split learning (SL) based framework for IoT
malware detection through image-based classification. By dividing the neural
network training between the clients and an edge server, the framework reduces
computational burden on resource-constrained clients while ensuring data
privacy. We formulate a joint optimization problem that balances computation
cost and communication efficiency by using a game-theoretic approach for
attaining better training performance. Experimental evaluations show that the
proposed framework outperforms popular FL methods in terms of accuracy
(+6.35%), F1-score (+5.03%), high convergence speed (+14.96%), and less
resource consumption (33.83%). These results establish the potential of SL as a
scalable and secure paradigm for next-generation IoT security.

</details>


### [7] [MH-1M: A 1.34 Million-Sample Comprehensive Multi-Feature Android Malware Dataset for Machine Learning, Deep Learning, Large Language Models, and Threat Intelligence Research](https://arxiv.org/abs/2511.00342)
*Hendrio Braganca,Diego Kreutz,Vanderson Rocha,Joner Assolin,and Eduardo Feitosa*

Main category: cs.CR

TL;DR: MH-1M是一个包含1,340,515个Android应用的全面恶意软件研究数据集，通过VirusTotal API进行准确分类，提供超过400GB的开放数据。


<details>
  <summary>Details</summary>
Motivation: 为Android恶意软件研究提供最全面和最新的数据集，以理解恶意软件不断演变的态势。

Method: 使用VirusTotal API整合多个检测引擎进行恶意软件分类，构建包含广泛特征和元数据的数据集。

Result: 创建了包含1,340,515个应用、超过400GB数据的MH-1M数据集，在GitHub、Figshare和Harvard Dataverse上开放访问。

Conclusion: MH-1M数据集在理解恶意软件演变态势方面具有重要价值，为恶意软件研究提供了宝贵资源。

Abstract: We present MH-1M, one of the most comprehensive and up-to-date datasets for
advanced Android malware research. The dataset comprises 1,340,515
applications, encompassing a wide range of features and extensive metadata. To
ensure accurate malware classification, we employ the VirusTotal API,
integrating multiple detection engines for comprehensive and reliable
assessment. Our GitHub, Figshare, and Harvard Dataverse repositories provide
open access to the processed dataset and its extensive supplementary metadata,
totaling more than 400 GB of data and including the outputs of the feature
extraction pipeline as well as the corresponding VirusTotal reports. Our
findings underscore the MH-1M dataset's invaluable role in understanding the
evolving landscape of malware.

</details>


### [8] [Exploiting Latent Space Discontinuities for Building Universal LLM Jailbreaks and Data Extraction Attacks](https://arxiv.org/abs/2511.00346)
*Kayua Oleques Paim,Rodrigo Brandao Mansilha,Diego Kreutz,Muriel Figueredo Franco,Weverton Cordeiro*

Main category: cs.CR

TL;DR: 提出了一种利用潜在空间不连续性来构建通用越狱和数据提取攻击的新方法，该方法能够跨多种模型和接口进行攻击，对7个最先进的大语言模型和1个图像生成模型都有效。


<details>
  <summary>Details</summary>
Motivation: 大型语言模型的快速扩散引发了对其对抗攻击安全性的严重担忧，需要开发能够跨模型通用的攻击方法。

Method: 通过利用与训练数据稀疏性相关的架构漏洞——潜在空间不连续性，来构建通用越狱和数据提取攻击。

Result: 当利用这些不连续性时，即使在存在分层防御的情况下，也能持续且深度地破坏模型行为，该方法在7个最先进的大语言模型和1个图像生成模型中都证明高度有效。

Conclusion: 这种利用潜在空间不连续性的策略具有作为系统性攻击向量的巨大潜力。

Abstract: The rapid proliferation of Large Language Models (LLMs) has raised
significant concerns about their security against adversarial attacks. In this
work, we propose a novel approach to crafting universal jailbreaks and data
extraction attacks by exploiting latent space discontinuities, an architectural
vulnerability related to the sparsity of training data. Unlike previous
methods, our technique generalizes across various models and interfaces,
proving highly effective in seven state-of-the-art LLMs and one image
generation model. Initial results indicate that when these discontinuities are
exploited, they can consistently and profoundly compromise model behavior, even
in the presence of layered defenses. The findings suggest that this strategy
has substantial potential as a systemic attack vector.

</details>


### [9] [Ultralow-power standoff acoustic leak detection](https://arxiv.org/abs/2511.00348)
*Michael P. Hasselbeck*

Main category: cs.CR

TL;DR: 开发了一种自动非接触式声学泄漏检测系统，可检测压力管道泄漏，有效距离超过10米，并能穿透墙壁等障碍物检测。


<details>
  <summary>Details</summary>
Motivation: 需要一种能够自动检测压力管道泄漏的解决方案，特别是在难以直接观察的位置，如墙壁后方。

Method: 结合玻璃破碎和烟雾检测原理，使用声学传感器在人类听觉范围以上的频率进行检测，所有信号处理在边缘设备完成。

Result: 成功检测到0.15升/分钟的模拟水泄漏，检测距离超过10米，功耗仅为20-200微瓦，能穿透墙壁等障碍物检测。

Conclusion: 该系统可发展为自主、电池供电的无线节点，不仅适用于水管泄漏检测，也可用于气体泄漏检测。

Abstract: An automated, standoff acoustic leak detection scheme has been designed,
built, and tested. It merges the principles of glass breakage and smoke
detection to alert for the presence of leaks emanating from pressurized
plumbing. A simulated water leak flowing at 0.15 l/min has been reliably
detected at a standoff distance of more than 10 m. The device is also effective
at identifying the presence of leaks located behind surfaces such as walls,
doors, floors, and ceilings. The anticipated application is as an autonomous,
battery-powered, remote wireless node. All signal processing and analysis takes
place on the edge with no need to stream audio data to the cloud. Sensor status
is conveyed on-demand with only a few bytes of information, requiring minimal
bandwidth. Power consumption is the range of 20--200 micro-Watts, depending on
the amount of environmental noise and desired sensor latency. To attain optimum
sensitivity and reliability, the hardware operates at acoustic frequencies well
above the range of human conversations, making eavesdropping impossible.
Development has been done with water escaping from pressurized plumbing, but
the sensor concept can be used effectively to detect gas leaks.

</details>


### [10] [Mind the Gap: Missing Cyber Threat Coverage in NIDS Datasets for the Energy Sector](https://arxiv.org/abs/2511.00360)
*Adrita Rahman Tory,Khondokar Fida Hasan,Md Saifur Rahman,Nickolaos Koroniotis,Mohammad Ali Moni*

Main category: cs.CR

TL;DR: 评估五个常用网络入侵检测数据集对能源IT/OT混合环境的代表性，发现CIC-IDS2017、Sherlock和CIC-Modbus2023组合可覆盖92%的网络可观测攻击技术。


<details>
  <summary>Details</summary>
Motivation: 现有公开数据集主要针对企业环境，在能源基础设施的IT/OT融合环境中有效性存疑，需要评估其代表性。

Method: 采用五步分析方法，从274个MITRE ATT&CK技术中提取94个网络可观测技术，对五个数据集进行差距分析。

Result: Sherlock数据集平均覆盖率最高(0.56)，CIC-IDS2017次之(0.55)，SWaT和WADI最低(0.38)。三个数据集组合可达92%覆盖率。

Conclusion: 识别了横向移动和工业协议操作等关键差距，为数据集增强和更稳健的NIDS评估提供了明确路径。

Abstract: Network Intrusion Detection Systems (NIDS) developed us- ing publicly
available datasets predominantly focus on enterprise environ- ments, raising
concerns about their effectiveness for converged Informa- tion Technology (IT)
and Operational Technology (OT) in energy infras- tructures. This study
evaluates the representativeness of five widely used datasets: CIC-IDS2017,
SWaT, WADI, Sherlock, and CIC-Modbus2023 against network-detectable MITRE
ATT&CK techniques extracted from documented energy sector incidents. Using a
structured five-step analyt- ical approach, this article successfully developed
and performed a gap analysis that identified 94 network observable techniques
from an initial pool of 274 ATT&CK techniques. Sherlock dataset exhibited the
high- est mean coverage (0.56), followed closely by CIC-IDS2017 (0.55), while
SWaT and WADI recorded the lowest scores (0.38). Combining CIC- IDS2017,
Sherlock, and CIC-Modbus2023 achieved an aggregate coverage of 92%,
highlighting their complementary strengths. The analysis identi- fies critical
gaps, particularly in lateral movement and industrial protocol manipulation,
providing a clear pathway for dataset enhancement and more robust NIDS
evaluation in hybrid IT/OT energy environments.

</details>


### [11] [MalDataGen: A Modular Framework for Synthetic Tabular Data Generation in Malware Detection](https://arxiv.org/abs/2511.00361)
*Kayua Oleques Paim,Angelo Gaspar Diniz Nogueira,Diego Kreutz,Weverton Cordeiro,Rodrigo Brandao Mansilha*

Main category: cs.CR

TL;DR: MalDataGen是一个开源模块化框架，使用WGAN-GP、VQ-VAE等深度学习模型生成高质量合成表格数据，解决恶意软件检测中高质量数据稀缺问题。


<details>
  <summary>Details</summary>
Motivation: 恶意软件检测领域高质量数据稀缺，限制了机器学习模型的性能表现。

Method: 使用模块化深度学习模型（如WGAN-GP、VQ-VAE）生成高保真合成表格数据，通过双重验证、七种分类器和效用指标进行评估。

Result: MalDataGen在性能上优于SDV等基准方法，同时保持了数据效用，其灵活设计可无缝集成到检测流程中。

Conclusion: 该框架为网络安全应用提供了一个实用的解决方案，能够有效缓解数据稀缺问题。

Abstract: High-quality data scarcity hinders malware detection, limiting ML
performance. We introduce MalDataGen, an open-source modular framework for
generating high-fidelity synthetic tabular data using modular deep learning
models (e.g., WGAN-GP, VQ-VAE). Evaluated via dual validation (TR-TS/TS-TR),
seven classifiers, and utility metrics, MalDataGen outperforms benchmarks like
SDV while preserving data utility. Its flexible design enables seamless
integration into detection pipelines, offering a practical solution for
cybersecurity applications.

</details>


### [12] [Fast Networks for High-Performance Distributed Trust](https://arxiv.org/abs/2511.00363)
*Yicheng Liu,Rafail Ostrovsky,Scott Shenker,Sam Kumar*

Main category: cs.CR

TL;DR: 本文提出分布式但邻近信任(DBPT)框架，通过重新设计LAN环境下的分布式信任系统，实现比传统方法高一个数量级的性能提升，使安全协作数据分析和AI更加实用。


<details>
  <summary>Details</summary>
Motivation: 组织需要在保护各自数据隐私的前提下进行协作计算，但现有加密技术在分布式信任方面性能不足，特别是在跨WAN或公共互联网通信时。

Method: 重新设计分布式信任框架以适应LAN环境，开发分布式但邻近信任(DBPT)部署模型，让各方能在保持物理和逻辑分离的同时使用LAN。

Result: 通过优化LAN环境下的分布式信任框架，实现了比传统方法高一个数量级的性能提升。

Conclusion: DBPT框架使安全协作数据分析和AI更加实用，并为开发高性能分布式信任系统和密码理论开辟了新的研究方向。

Abstract: Organizations increasingly need to collaborate by performing a computation on
their combined dataset, while keeping their data hidden from each other.
Certain kinds of collaboration, such as collaborative data analytics and AI,
require a level of performance beyond what current cryptographic techniques for
distributed trust can provide. This is because the organizations run software
in different trust domains, which can require them to communicate over WANs or
the public Internet. In this paper, we explore how to instead run such
applications using fast datacenter-type LANs. We show that, by carefully
redesigning distributed trust frameworks for LANs, we can achieve up to
order-of-magnitude better performance than na\"ively using a LAN. Then, we
develop deployment models for Distributed But Proximate Trust (DBPT) that allow
parties to use a LAN while remaining physically and logically distinct. These
developments make secure collaborative data analytics and AI significantly more
practical and set new research directions for developing systems and
cryptographic theory for high-performance distributed trust.

</details>


### [13] [Penetrating the Hostile: Detecting DeFi Protocol Exploits through Cross-Contract Analysis](https://arxiv.org/abs/2511.00408)
*Xiaoqi Li,Wenkai Li,Zhiquan Liu,Yuqing Zhang,Yingjie Mao*

Main category: cs.CR

TL;DR: DeFiTail是一个基于深度学习的框架，用于检测DeFi协议中的访问控制和闪电贷漏洞，通过分析跨合约静态数据流自动学习攻击逻辑，在实验中取得了98.39%和97.43%的高准确率。


<details>
  <summary>Details</summary>
Motivation: 当前DeFi攻击频繁，损失超过800亿美元，现有工具主要分析受害者合约的状态变化，但缺乏对攻击者交互意图逻辑的覆盖能力，且实际遭受攻击的DeFi协议比例很小，导致现有检测工具实用性受限。

Method: DeFiTail通过跨合约静态数据流分析，统一多账户交易中的执行路径，使用符号执行栈验证数据路径，并利用深度学习模型检测恶意模式。

Result: 实验结果显示，DeFiTail在访问控制检测中达到98.39%准确率，在闪电贷漏洞检测中达到97.43%准确率，在CVE数据集中恶意合约检测准确率达到86.67%。

Conclusion: DeFiTail是首个利用深度学习技术检测DeFi协议漏洞的框架，能够有效捕获攻击者与受害者合约之间的威胁模式，显著提升了DeFi安全检测的准确性和实用性。

Abstract: Decentralized finance (DeFi) protocols are crypto projects developed on the
blockchain to manage digital assets. Attacks on DeFi have been frequent and
have resulted in losses exceeding $80 billion. Current tools detect and locate
possible vulnerabilities in contracts by analyzing the state changes that may
occur during malicious events. However, this victim-only approaches seldom
possess the capability to cover the attacker's interaction intention logic.
Furthermore, only a minuscule percentage of DeFi protocols experience attacks
in real-world scenarios, which poses a significant challenge for these
detection tools to demonstrate practical effectiveness. In this paper, we
propose DeFiTail, the first framework that utilizes deep learning technology
for access control and flash loan exploit detection. Through feeding the
cross-contract static data flow, DeFiTail automatically learns the attack logic
in real-world malicious events that occur on DeFi protocols, capturing the
threat patterns between attacker and victim contracts. Since the DeFi protocol
events involve interactions with multi-account transactions, the execution path
with external and internal transactions requires to be unified. Moreover, to
mitigate the impact of mistakes in Control Flow Graph (CFG) connections,
DeFiTail validates the data path by employing the symbolic execution stack.
Furthermore, we feed the data paths through our model to achieve the inspection
of DeFi protocols. Comparative experiment results indicate that DeFiTail
achieves the highest accuracy, with 98.39% in access control and 97.43% in
flash loan exploits. DeFiTail also demonstrates an enhanced capability to
detect malicious contracts, identifying 86.67% accuracy from the CVE dataset.

</details>


### [14] [Zero-Knowledge Extensions on Solana: A Theory of ZK Architecture](https://arxiv.org/abs/2511.00415)
*Jotaro Yano*

Main category: cs.CR

TL;DR: 本文提出了Solana上零知识扩展的架构理论，通过双轴模型（用途：可扩展性vs隐私；位置：链上vs链下）和五个跨层不变性来标准化零知识使用，并推导出PCM和PCIM等设计抽象。


<details>
  <summary>Details</summary>
Motivation: 为Solana生态系统中的零知识技术使用提供统一的架构框架和理论模型，以促进跨模块和跨链的正确性推理。

Method: 基于现有生态系统和作者先前工作，提出双轴模型（用途×位置）和五个跨层不变性（来源真实性、重放安全、最终性对齐、参数绑定、私有消费），覆盖Solana基金会的三大支柱及相关组件。

Result: 建立了统一的零知识扩展理论框架，定义了五个关键不变性作为通用词汇，并推导出PCM、Verifier Router Interface和PCIM等具体设计抽象。

Conclusion: 该理论框架为Solana的零知识扩展提供了系统化的设计指导，指明了扩展三大支柱的具体路径，促进了零知识技术在区块链生态系统中的标准化应用。

Abstract: This paper reconstructs zero-knowledge extensions on Solana as an
architecture theory. Drawing on the existing ecosystem and on the author's
prior papers and implementations as reference material, we propose a two-axis
model that normalizes zero-knowledge (ZK) use by purpose (scalability vs.
privacy) and by placement (on-chain vs. off-chain). On this grid we define five
layer-crossing invariants: origin authenticity, replay-safety, finality
alignment, parameter binding, and private consumption, which serve as a common
vocabulary for reasoning about correctness across modules and chains. The
framework covers the Solana Foundation's three pillars (ZK Compression,
Confidential Transfer, light clients/bridges) together with surrounding
components (Light Protocol/Helius, Succinct SP1, RISC Zero, Wormhole,
Tinydancer, Arcium). From the theory we derive two design abstractions -
Proof-Carrying Message (PCM) and a Verifier Router Interface - and a
cross-chain counterpart, Proof-Carrying Interchain Message (PCIM), indicating
concrete avenues for extending the three pillars.

</details>


### [15] [DRIP: Defending Prompt Injection via De-instruction Training and Residual Fusion Model Architecture](https://arxiv.org/abs/2511.00447)
*Ruofan Liu,Yun Lin,Jin Song Dong*

Main category: cs.CR

TL;DR: DRIP是一种针对LLM提示注入攻击的训练时防御方法，通过语义解耦和残差融合机制，在不牺牲模型性能的情况下增强指令与数据的语义分离。


<details>
  <summary>Details</summary>
Motivation: 大语言模型缺乏语义角色理解能力，无法区分指令意图和描述性内容，导致容易受到提示注入攻击，其中恶意输入会覆盖或干扰原始指令。

Method: DRIP包含两个互补机制：(1) 词元级去指令偏移，在数据词元中削弱指令语义同时保留内容含义；(2) 残差融合路径，提供持续语义锚点，在生成过程中强化顶层指令的影响。

Result: 在LLaMA-8B和Mistral-7B上的实验表明，DRIP在三个提示注入基准测试中优于现有防御方法，角色分离提升49%，自适应攻击成功率降低66%，同时在标准评估中保持与未防御模型相当的性能。

Conclusion: 轻量级表征编辑和角色感知监督在保护LLM免受自适应提示注入攻击方面具有强大效果。

Abstract: Large language models (LLMs) have demonstrated impressive
instruction-following capabilities. However, these capabilities also expose
models to prompt injection attacks, where maliciously crafted inputs overwrite
or distract from the intended instructions. A core vulnerability lies in the
model's lack of semantic role understanding: it cannot distinguish directive
intent from descriptive content, leading it to execute instruction-like phrases
embedded in data.
  We propose DRIP, a training-time defense grounded in a semantic modeling
perspective, which enforces robust separation between instruction and data
semantics without sacrificing utility. DRIP introduces two lightweight yet
complementary mechanisms: (1) a token-wise de-instruction shift that performs
semantic disentanglement, weakening directive semantics in data tokens while
preserving content meaning; and (2) a residual fusion pathway that provides a
persistent semantic anchor, reinforcing the influence of the true top-level
instruction during generation. Experimental results on LLaMA-8B and Mistral-7B
across three prompt injection benchmarks (SEP, AlpacaFarm, and InjecAgent)
demonstrate that DRIP outperforms state-of-the-art defenses, including StruQ,
SecAlign, ISE, and PFT, improving role separation by 49%, and reducing attack
success rate by 66% for adaptive attacks. Meanwhile, DRIP's utility is on par
with the undefended model across AlpacaEval, IFEval, and MT-Bench. Our findings
underscore the power of lightweight representation edits and role-aware
supervision in securing LLMs against adaptive prompt injection.

</details>


### [16] [Proactive DDoS Detection and Mitigation in Decentralized Software-Defined Networking via Port-Level Monitoring and Zero-Training Large Language Models](https://arxiv.org/abs/2511.00460)
*Mohammed N. Swileh,Shengli Zhang*

Main category: cs.CR

TL;DR: 提出了一种针对分布式SDN的DDoS攻击检测与缓解框架，结合轻量级端口统计和LLM推理，无需微调即可实现高精度恶意流量分类，并在攻击源端口直接阻断恶意流量。


<details>
  <summary>Details</summary>
Motivation: 集中式SDN存在可扩展性和可靠性问题，分布式SDN虽然解决了这些问题，但仍易受DDoS攻击。需要为分布式SDN环境设计专门的DDoS防护机制。

Method: 利用轻量级端口级统计数据，结合提示工程和上下文学习，使DeepSeek-v3 LLM无需微调或重新训练即可分类流量为良性或恶意。检测到异常后，直接在攻击者端口实施缓解措施。

Result: 在各种DDoS攻击场景下的实验评估显示，该方法实现了近乎完美的检测性能：准确率99.99%、精确率99.97%、召回率100%、F1分数99.98%、AUC为1.0。

Conclusion: 结合分布式监控和零训练LLM推理的方法有效，为保护分布式SDN基础设施免受DDoS威胁提供了主动且可扩展的防御机制。

Abstract: Centralized Software-Defined Networking (cSDN) offers flexible and
programmable control of networks but suffers from scalability and reliability
issues due to its reliance on centralized controllers. Decentralized SDN (dSDN)
alleviates these concerns by distributing control across multiple local
controllers, yet this architecture remains highly vulnerable to Distributed
Denial-of-Service (DDoS) attacks. In this paper, we propose a novel detection
and mitigation framework tailored for dSDN environments. The framework
leverages lightweight port-level statistics combined with prompt engineering
and in-context learning, enabling the DeepSeek-v3 Large Language Model (LLM) to
classify traffic as benign or malicious without requiring fine-tuning or
retraining. Once an anomaly is detected, mitigation is enforced directly at the
attacker's port, ensuring that malicious traffic is blocked at their origin
while normal traffic remains unaffected. An automatic recovery mechanism
restores normal operation after the attack inactivity, ensuring both security
and availability. Experimental evaluation under diverse DDoS attack scenarios
demonstrates that the proposed approach achieves near-perfect detection, with
99.99% accuracy, 99.97% precision, 100% recall, 99.98% F1-score, and an AUC of
1.0. These results highlight the effectiveness of combining distributed
monitoring with zero-training LLM inference, providing a proactive and scalable
defense mechanism for securing dSDN infrastructures against DDoS threats.

</details>


### [17] [An Efficient Anomaly Detection Framework for Wireless Sensor Networks Using Markov Process](https://arxiv.org/abs/2511.00481)
*Rahul Mishra,Sudhanshu Kumar Jha,Omar Faruq Osama,Bishnu Bhusal,Sneha Sudhakaran,Naresh Kshetri*

Main category: cs.CR

TL;DR: 提出了一种基于一阶马尔可夫链的轻量级可解释异常检测框架，用于无线传感器网络中的实时异常检测，无需标记数据或大量计算。


<details>
  <summary>Details</summary>
Motivation: 无线传感器网络是现代网络物理系统的核心，但收集的数据可能因传感器故障、环境干扰或恶意入侵而包含异常，确保数据可靠性至关重要。

Method: 将连续传感器读数离散化为有限状态，通过转移概率矩阵建模传感器转换的时间动态，当观测到的转换概率低于计算阈值时检测异常。

Result: 在英特尔伯克利研究实验室数据集上验证，能够以高精度识别热峰值、电压相关故障和不规则温度波动，F1分数达到0.86，在准确性、互操作性和计算效率之间取得平衡。

Conclusion: 该框架的可扩展性和低资源占用突显了其在无线传感器网络部署中大规模实时异常检测的适用性。

Abstract: Wireless Sensor Networks forms the backbone of modern cyber physical systems
used in various applications such as environmental monitoring, healthcare
monitoring, industrial automation, and smart infrastructure. Ensuring the
reliability of data collected through these networks is essential as these data
may contain anomalies due to many reasons such as sensor faults, environmental
disturbances, or malicious intrusions. In this paper a lightweight and
interpretable anomaly detection framework based on a first order Markov chain
model has been proposed. The method discretizes continuous sensor readings into
finite states and models the temporal dynamics of sensor transitions through a
transition probability matrix. Anomalies are detected when observed transitions
occur with probabilities below a computed threshold, allowing for real time
detection without labeled data or intensive computation. The proposed framework
was validated using the Intel Berkeley Research Lab dataset, as a case study on
indoor environmental monitoring demonstrates its capability to identify thermal
spikes, voltage related faults, and irregular temperature fluctuations with
high precision. Comparative analysis with Z score, Hidden Markov Model, and
Auto encoder based methods shows that the proposed Markov based framework
achieves a balanced trade-off between accuracy, F1 score is 0.86,
interoperability, and computational efficiency. The systems scalability and low
resource footprint highlight its suitability for large-scale and real time
anomaly detection in WSN deployments.

</details>


### [18] [ShadowLogic: Backdoors in Any Whitebox LLM](https://arxiv.org/abs/2511.00664)
*Kasimir Schulz,Amelia Kawasaki,Leo Ring*

Main category: cs.CR

TL;DR: ShadowLogic方法通过在LLM的计算图中植入隐蔽后门，能够绕过内容安全防护机制，当检测到特定触发短语时移除内容生成限制。


<details>
  <summary>Details</summary>
Motivation: 揭示计算图格式LLM中的安全漏洞，证明广泛使用的部署流程可能受到隐蔽后门的威胁。

Method: 在计算图表示中注入去审查向量，设置触发短语检测逻辑，并将该逻辑隐藏在标准模型函数中以避免检测。

Result: 在Phi-3和Llama 3.2上成功实现，植入去审查向量后对后续恶意查询的攻击成功率超过60%。

Conclusion: 计算图格式的LLM存在严重安全漏洞，需要加强部署流程的安全性以防止此类隐蔽攻击。

Abstract: Large language models (LLMs) are widely deployed across various applications,
often with safeguards to prevent the generation of harmful or restricted
content. However, these safeguards can be covertly bypassed through adversarial
modifications to the computational graph of a model. This work highlights a
critical security vulnerability in computational graph-based LLM formats,
demonstrating that widely used deployment pipelines may be susceptible to
obscured backdoors. We introduce ShadowLogic, a method for creating a backdoor
in a white-box LLM by injecting an uncensoring vector into its computational
graph representation. We set a trigger phrase that, when added to the beginning
of a prompt into the LLM, applies the uncensoring vector and removes the
content generation safeguards in the model. We embed trigger logic directly
into the computational graph which detects the trigger phrase in a prompt. To
evade detection of our backdoor, we obfuscate this logic within the graph
structure, making it similar to standard model functions. Our method requires
minimal alterations to model parameters, making backdoored models appear benign
while retaining the ability to generate uncensored responses when activated. We
successfully implement ShadowLogic in Phi-3 and Llama 3.2, using ONNX for
manipulating computational graphs. Implanting the uncensoring vector achieved a
>60% attack success rate for further malicious queries.

</details>


### [19] [EP-HDC: Hyperdimensional Computing with Encrypted Parameters for High-Throughput Privacy-Preserving Inference](https://arxiv.org/abs/2511.00737)
*Jaewoo Park,Chenghao Quan,Jongeun Lee*

Main category: cs.CR

TL;DR: 提出EP-HDC方法，在客户端使用同态加密模型进行推理，显著降低加密和数据传输开销，在保持高准确率的同时大幅提升批处理推理的吞吐量和延迟性能


<details>
  <summary>Details</summary>
Motivation: 传统同态加密计算成本高，限制了其在复杂任务中的应用。现有的基于超维计算的同态加密方法在批处理推理场景下仍有很高的计算时间和加密传输开销

Method: 提出HDC with encrypted parameters (EP-HDC)，采用客户端同态加密，即在客户端使用同态加密模型进行推理。通过设计空间探索优化量化、架构和HE相关参数

Result: 使用BFV方案和Face/Emotion数据集测试，相比现有PPML方法，批处理推理吞吐量提升36.52~1068倍，延迟降低6.45~733倍，准确率损失小于1%

Conclusion: EP-HDC能有效缓解加密和数据传输开销，在保护用户数据和模型参数的同时，为多客户端场景提供高可扩展性

Abstract: While homomorphic encryption (HE) provides strong privacy protection, its
high computational cost has restricted its application to simple tasks.
Recently, hyperdimensional computing (HDC) applied to HE has shown promising
performance for privacy-preserving machine learning (PPML). However, when
applied to more realistic scenarios such as batch inference, the HDC-based HE
has still very high compute time as well as high encryption and data
transmission overheads. To address this problem, we propose HDC with encrypted
parameters (EP-HDC), which is a novel PPML approach featuring client-side HE,
i.e., inference is performed on a client using a homomorphically encrypted
model. Our EP-HDC can effectively mitigate the encryption and data transmission
overhead, as well as providing high scalability with many clients while
providing strong protection for user data and model parameters. In addition to
application examples for our client-side PPML, we also present design space
exploration involving quantization, architecture, and HE-related parameters.
Our experimental results using the BFV scheme and the Face/Emotion datasets
demonstrate that our method can improve throughput and latency of batch
inference by orders of magnitude over previous PPML methods (36.52~1068x and
6.45~733x, respectively) with less than 1% accuracy degradation.

</details>


### [20] [Towards Ultra-Low Latency: Binarized Neural Network Architectures for In-Vehicle Network Intrusion Detection](https://arxiv.org/abs/2511.00828)
*Huiyao Dong,Igor Kotenko*

Main category: cs.CR

TL;DR: 提出了一种基于二值化神经网络(BNN)的轻量级CAN总线入侵检测方法，结合混合二进制编码技术处理非二进制特征，适用于车载微控制器部署。


<details>
  <summary>Details</summary>
Motivation: CAN协议缺乏强大的安全特性，使车辆易受网络攻击，现有机器学习方法在实际应用中存在不确定性。

Method: 使用二值化神经网络(BNN)框架，结合混合二进制编码技术整合载荷数据、消息ID和CAN消息频率等特征进行入侵检测。

Result: 该方法在异常检测和多类网络流量分类中表现出色，特别适合在微控制器和网关ECU上部署。

Conclusion: 提出的BNN框架结合混合二进制量化技术为车载CAN总线安全应用提供了有效的实时入侵检测解决方案。

Abstract: The Control Area Network (CAN) protocol is essential for in-vehicle
communication, facilitating high-speed data exchange among Electronic Control
Units (ECUs). However, its inherent design lacks robust security features,
rendering vehicles susceptible to cyberattacks. While recent research has
investigated machine learning and deep learning techniques to enhance network
security, their practical applicability remains uncertain. This paper presents
a lightweight intrusion detection technique based on Binarized Neural Networks
(BNNs), which utilizes payload data, message IDs, and CAN message frequencies
for effective intrusion detection. Additionally, we develop hybrid binary
encoding techniques to integrate non-binary features, such as message IDs and
frequencies. The proposed method, namely the BNN framework specifically
optimized for in-vehicle intrusion detection combined with hybrid binary
quantization techniques for non-payload attributes, demonstrates efficacy in
both anomaly detection and multi-class network traffic classification. The
system is well-suited for deployment on micro-controllers and Gateway ECUs,
aligning with the real-time requirements of CAN bus safety applications.

</details>


### [21] [Android Malware Detection: A Machine Leaning Approach](https://arxiv.org/abs/2511.00894)
*Hasan Abdulla*

Main category: cs.CR

TL;DR: 该研究比较了多种机器学习技术在Android恶意软件检测中的表现，发现集成方法性能最优，但在模型可解释性、效率和准确性之间存在权衡。


<details>
  <summary>Details</summary>
Motivation: 随着Android恶意软件的威胁日益增加，需要评估不同机器学习技术的检测效果，为实际应用提供指导。

Method: 使用决策树、支持向量机、逻辑回归、神经网络和集成方法等机器学习技术，在Android应用数据集上进行评估。

Result: 集成方法表现出最优性能，但不同模型在准确性、效率和可解释性方面存在权衡。

Conclusion: 研究结果为未来使用机器学习对抗Android恶意软件的研究和实际应用提供了重要指导。

Abstract: This study examines machine learning techniques like Decision Trees, Support
Vector Machines, Logistic Regression, Neural Networks, and ensemble methods to
detect Android malware. The study evaluates these models on a dataset of
Android applications and analyzes their accuracy, efficiency, and real-world
applicability. Key findings show that ensemble methods demonstrate superior
performance, but there are trade-offs between model interpretability,
efficiency, and accuracy. Given its increasing threat, the insights guide
future research and practical use of ML to combat Android malware.

</details>


### [22] [Leakage-abuse Attack Against Substring-SSE with Partially Known Dataset](https://arxiv.org/abs/2511.00930)
*Xijie Ba,Qin Liu,Xiaohong Li,Jianting Ning*

Main category: cs.CR

TL;DR: 首次提出了在部分已知数据集条件下的子字符串可搜索对称加密泄漏滥用攻击，通过矩阵相关技术从加密后缀树结构中高效恢复明文数据。


<details>
  <summary>Details</summary>
Motivation: 现有的子字符串-SSE方案在搜索操作期间容易受到信息泄漏攻击，特别是在攻击者拥有目标数据集部分知识的情况下。虽然泄漏滥用攻击在传统SSE中已被广泛研究，但在部分已知数据假设下对子字符串-SSE的适用性尚未探索。

Method: 开发了一种新颖的基于矩阵的相关技术，扩展并优化了LEAP框架用于子字符串-SSE，通过迭代矩阵变换直接利用已知数据片段建立密文令牌和明文字符串之间的高置信度映射。

Result: 在真实世界数据集上的综合实验证明了攻击的有效性，在50%辅助知识下子字符串恢复率达到98.32%。即使只有10%的先验知识，攻击也能实现74.42%的子字符串恢复，同时在各种规模的数据集上保持强可扩展性。

Conclusion: 结果揭示了当前子字符串-SSE设计中的重大隐私风险，并强调了构建泄漏弹性方案的紧迫需求。

Abstract: Substring-searchable symmetric encryption (substring-SSE) has become
increasingly critical for privacy-preserving applications in cloud systems.
However, existing schemes remain vulnerable to information leakage during
search operations, particularly when adversaries possess partial knowledge of
the target dataset. Although leakage-abuse attacks have been widely studied for
traditional SSE, their applicability to substring-SSE under partially known
data assumptions remains unexplored. In this paper, we present the first
leakage-abuse attack on substring-SSE under partially-known dataset conditions.
We develop a novel matrix-based correlation technique that extends and
optimizes the LEAP framework for substring-SSE, enabling efficient recovery of
plaintext data from encrypted suffix tree structures. Unlike existing
approaches that rely on independent auxiliary datasets, our method directly
exploits known data fragments to establish high-confidence mappings between
ciphertext tokens and plaintext substrings through iterative matrix
transformations. Comprehensive experiments on real-world datasets demonstrate
the effectiveness of the attack, with recovery rates reaching 98.32% for
substrings given 50% auxiliary knowledge. Even with only 10% prior knowledge,
the attack achieves 74.42% substring recovery while maintaining strong
scalability across datasets of varying sizes. The result reveals significant
privacy risks in current substring-SSE designs and highlights the urgent need
for leakage-resilient constructions.

</details>


### [23] [Keys in the Weights: Transformer Authentication Using Model-Bound Latent Representations](https://arxiv.org/abs/2511.00973)
*Ayşe S. Okatan,Mustafa İlhan Akbaş,Laxima Niure Kandel,Berker Peköz*

Main category: cs.CR

TL;DR: MoBLE提出了一种Transformer自编码器的解码器绑定特性，称为零样本解码器不可转移性(ZSDN)，使得只有正确配对的解码器才能从编码器的隐藏状态中恢复明文，提供了一种基于潜在表示的认证和访问控制机制。


<details>
  <summary>Details</summary>
Motivation: 为安全关键领域（如航空和网络物理系统）提供轻量级、加速器友好的安全AI部署方案，通过模型绑定实现潜在表示的认证和访问控制。

Method: 使用相同架构和训练数据但不同种子的Transformer自编码器，研究自解码和零样本交叉解码的性能差异，通过权重空间距离和注意力散度诊断来验证解码器绑定特性。

Result: 自解码达到超过0.91的精确匹配和0.98的token准确率，而零样本交叉解码崩溃至随机水平且无精确匹配，证明了ZSDN的有效性。

Conclusion: MoBLE提供了一种无需注入密钥或对抗训练的模型绑定机制，即使在架构和训练方法公开的情况下，也能通过潜在表示实现安全认证，但需要注意可学习性风险并采取缓解措施。

Abstract: We introduce Model-Bound Latent Exchange (MoBLE), a decoder-binding property
in Transformer autoencoders formalized as Zero-Shot Decoder Non-Transferability
(ZSDN). In identity tasks using iso-architectural models trained on identical
data but differing in seeds, self-decoding achieves more than 0.91 exact match
and 0.98 token accuracy, while zero-shot cross-decoding collapses to chance
without exact matches. This separation arises without injected secrets or
adversarial training, and is corroborated by weight-space distances and
attention-divergence diagnostics. We interpret ZSDN as model binding, a
latent-based authentication and access-control mechanism, even when the
architecture and training recipe are public: encoder's hidden state
representation deterministically reveals the plaintext, yet only the correctly
keyed decoder reproduces it in zero-shot. We formally define ZSDN, a
decoder-binding advantage metric, and outline deployment considerations for
secure artificial intelligence (AI) pipelines. Finally, we discuss learnability
risks (e.g., adapter alignment) and outline mitigations. MoBLE offers a
lightweight, accelerator-friendly approach to secure AI deployment in
safety-critical domains, including aviation and cyber-physical systems.

</details>


### [24] [Verification and Attack Synthesis for Network Protocols](https://arxiv.org/abs/2511.01124)
*Max von Hippel*

Main category: cs.CR

TL;DR: 该论文展示了形式化方法能够有效描述网络协议在正常条件和遭受攻击时的功能与性能特性


<details>
  <summary>Details</summary>
Motivation: 网络协议作为遵循预定通信模式的程序，其功能和性能需求可通过形式化规范表达，但可能因设计缺陷、组件故障或攻击而无法达成要求

Method: 使用形式化方法来描述网络协议的功能和性能特性，包括在正常条件和遭受攻击时的情况

Result: 研究表明形式化方法能够可行地表征网络协议在各种条件下的行为特性

Conclusion: 形式化方法为网络协议的功能和性能分析提供了可行的技术途径

Abstract: Network protocols are programs with inputs and outputs that follow predefined
communication patterns to synchronize and exchange information. There are many
protocols and each serves a different purpose, e.g., routing, transport, secure
communication, etc. The functional and performance requirements for a protocol
can be expressed using a formal specification, such as, a set of logical
predicates over its traces. A protocol could be prevented from achieving its
requirements due to a bug in its design or implementation, a component failure
(e.g., a crash), or an attack. This dissertation shows that formal methods can
feasibly characterize the functionality and performance of network protocols
under normal conditions as well as when subjected to attacks.

</details>


### [25] [AthenaBench: A Dynamic Benchmark for Evaluating LLMs in Cyber Threat Intelligence](https://arxiv.org/abs/2511.01144)
*Md Tanvirul Alam,Dipkamal Bhusal,Salman Ahmad,Nidhi Rastogi,Peter Worth*

Main category: cs.CR

TL;DR: AthenaBench扩展了CTIBench基准，评估12个LLM在网络安全威胁情报任务上的表现，发现专有模型表现更好但推理密集型任务仍有不足，开源模型差距更大。


<details>
  <summary>Details</summary>
Motivation: 虽然LLM在自然语言推理方面表现出色，但在网络安全威胁情报领域的应用仍然有限。CTI分析需要从大量非结构化报告中提炼可操作知识，LLM可以显著减少分析师工作量。

Method: 开发AthenaBench增强基准，包括改进的数据集创建流程、重复数据删除、精炼的评估指标，以及专注于风险缓解策略的新任务。评估了12个LLM，包括GPT-5、Gemini-2.5 Pro等专有模型和LLaMA、Qwen等开源模型。

Result: 专有LLM整体表现更强，但在推理密集型任务（如威胁行为者归因和风险缓解）上表现仍然不佳，开源模型表现更差。

Conclusion: 当前LLM在推理能力上存在根本性限制，需要专门为CTI工作流和自动化定制的模型。

Abstract: Large Language Models (LLMs) have demonstrated strong capabilities in natural
language reasoning, yet their application to Cyber Threat Intelligence (CTI)
remains limited. CTI analysis involves distilling large volumes of unstructured
reports into actionable knowledge, a process where LLMs could substantially
reduce analyst workload. CTIBench introduced a comprehensive benchmark for
evaluating LLMs across multiple CTI tasks. In this work, we extend CTIBench by
developing AthenaBench, an enhanced benchmark that includes an improved dataset
creation pipeline, duplicate removal, refined evaluation metrics, and a new
task focused on risk mitigation strategies. We evaluate twelve LLMs, including
state-of-the-art proprietary models such as GPT-5 and Gemini-2.5 Pro, alongside
seven open-source models from the LLaMA and Qwen families. While proprietary
LLMs achieve stronger results overall, their performance remains subpar on
reasoning-intensive tasks, such as threat actor attribution and risk
mitigation, with open-source models trailing even further behind. These
findings highlight fundamental limitations in the reasoning capabilities of
current LLMs and underscore the need for models explicitly tailored to CTI
workflows and automation.

</details>


### [26] [A Large Scale Study of AI-based Binary Function Similarity Detection Techniques for Security Researchers and Practitioners](https://arxiv.org/abs/2511.01180)
*Jingyi Shi,Yufeng Chen,Yang Xiao,Yuekang Li,Zhengzi Xu,Sihao Qiu,Chi Zhang,Keyu Qi,Yeting Li,Xingchu Chen,Yanyan Zou,Yang Liu,Wei Huo*

Main category: cs.CR

TL;DR: 本文进行了首个大规模AI二进制函数相似性检测工具实证研究，构建了两个高质量数据集并评估了9个代表性工具，提出了组合策略提升性能13.4%。


<details>
  <summary>Details</summary>
Motivation: 现有AI二进制函数相似性检测工具评估存在三个关键局限：缺乏性能影响因素深度分析、缺少实际应用分析、依赖小规模或低质量数据集。

Method: 构建两个高质量数据集：BinAtlas（12,453个二进制文件，700万+函数）用于能力评估，BinAres（12,291个二进制文件，54个真实1日漏洞）用于物联网固件环境下的漏洞检测性能评估。评估9个代表性BFSD工具，分析挑战和局限性，研究工具间一致性。

Result: 评估发现现有BFSD工具存在挑战和局限性，提出了组合BFSD工具的可操作策略，整体性能提升13.4%。

Conclusion: 该研究不仅推动了BFSD工具的实际应用，还为未来可扩展和自动化二进制相似性检测研究提供了宝贵资源和指导。

Abstract: Binary Function Similarity Detection (BFSD) is a foundational technique in
software security, underpinning a wide range of applications including
vulnerability detection, malware analysis. Recent advances in AI-based BFSD
tools have led to significant performance improvements. However, existing
evaluations of these tools suffer from three key limitations: a lack of
in-depth analysis of performance-influencing factors, an absence of realistic
application analysis, and reliance on small-scale or low-quality datasets.
  In this paper, we present the first large-scale empirical study of AI-based
BFSD tools to address these gaps. We construct two high-quality and diverse
datasets: BinAtlas, comprising 12,453 binaries and over 7 million functions for
capability evaluation; and BinAres, containing 12,291 binaries and 54
real-world 1-day vulnerabilities for evaluating vulnerability detection
performance in practical IoT firmware settings. Using these datasets, we
evaluate nine representative BFSD tools, analyze the challenges and limitations
of existing BFSD tools, and investigate the consistency among BFSD tools. We
also propose an actionable strategy for combining BFSD tools to enhance overall
performance (an improvement of 13.4%). Our study not only advances the
practical adoption of BFSD tools but also provides valuable resources and
insights to guide future research in scalable and automated binary similarity
detection.

</details>


### [27] [CryptoMoE: Privacy-Preserving and Scalable Mixture of Experts Inference via Balanced Expert Routing](https://arxiv.org/abs/2511.01197)
*Yifan Zhou,Tianshi Xu,Jue Hong,Ye Wu,Meng Li*

Main category: cs.CR

TL;DR: CryptoMoE是首个支持MoE架构私有推理的框架，通过平衡专家负载、安全调度协议和置信度感知策略，实现了2.8-3.5倍延迟降低和2.9-4.3倍通信减少。


<details>
  <summary>Details</summary>
Motivation: 现有加密推理框架仅支持密集LLM，无法扩展到MoE架构，主要挑战在于安全评估动态路由机制可能泄露敏感输入信息。

Method: 提出平衡专家负载保护路由信息、安全专家调度和组合协议、置信度感知token选择策略以及批量矩阵乘法协议。

Result: 在DeepSeekMoE-16.4B、OLMoE-6.9B和QWenMoE-14.3B上测试，相比密集基线实现2.8-3.5倍端到端延迟降低和2.9-4.3倍通信减少，精度损失最小。

Conclusion: CryptoMoE成功解决了MoE架构私有推理的关键挑战，为隐私保护深度学习提供了高效解决方案。

Abstract: Private large language model (LLM) inference based on cryptographic
primitives offers a promising path towards privacy-preserving deep learning.
However, existing frameworks only support dense LLMs like LLaMA-1 and struggle
to scale to mixture-of-experts (MoE) architectures. The key challenge comes
from securely evaluating the dynamic routing mechanism in MoE layers, which may
reveal sensitive input information if not fully protected. In this paper, we
propose CryptoMoE, the first framework that enables private, efficient, and
accurate inference for MoE-based models. CryptoMoE balances expert loads to
protect expert routing information and proposes novel protocols for secure
expert dispatch and combine. CryptoMoE also develops a confidence-aware token
selection strategy and a batch matrix multiplication protocol to improve
accuracy and efficiency further. Extensive experiments on DeepSeekMoE-16.4B,
OLMoE-6.9B, and QWenMoE-14.3B show that CryptoMoE achieves $2.8\sim3.5\times$
end-to-end latency reduction and $2.9\sim4.3\times$ communication reduction
over a dense baseline with minimum accuracy loss. We also adapt CipherPrune
(ICLR'25) for MoE inference and demonstrate CryptoMoE can reduce the
communication by up to $4.3 \times$. Code is available at:
https://github.com/PKU-SEC-Lab/CryptoMoE.

</details>


### [28] [Rescuing the Unpoisoned: Efficient Defense against Knowledge Corruption Attacks on RAG Systems](https://arxiv.org/abs/2511.01268)
*Minseok Kim,Hankook Lee,Hyungjoon Koo*

Main category: cs.CR

TL;DR: RAGDefender是一种针对检索增强生成系统中知识污染攻击的轻量级防御机制，通过后检索阶段检测和过滤对抗性内容，无需额外模型训练或推理。


<details>
  <summary>Details</summary>
Motivation: RAG系统面临知识污染攻击的威胁，现有防御方法计算成本高昂，需要开发资源高效的防御方案。

Method: 在后检索阶段使用轻量级机器学习技术检测和过滤对抗性内容，无需额外模型训练或推理。

Result: RAGDefender显著降低攻击成功率，在Gemini模型上将攻击成功率从0.89降至0.02，优于现有最佳防御方法。

Conclusion: RAGDefender为RAG系统提供了一种资源高效且有效的防御机制，能够可靠地抵御知识污染攻击。

Abstract: Large language models (LLMs) are reshaping numerous facets of our daily
lives, leading widespread adoption as web-based services. Despite their
versatility, LLMs face notable challenges, such as generating hallucinated
content and lacking access to up-to-date information. Lately, to address such
limitations, Retrieval-Augmented Generation (RAG) has emerged as a promising
direction by generating responses grounded in external knowledge sources. A
typical RAG system consists of i) a retriever that probes a group of relevant
passages from a knowledge base and ii) a generator that formulates a response
based on the retrieved content. However, as with other AI systems, recent
studies demonstrate the vulnerability of RAG, such as knowledge corruption
attacks by injecting misleading information. In response, several defense
strategies have been proposed, including having LLMs inspect the retrieved
passages individually or fine-tuning robust retrievers. While effective, such
approaches often come with substantial computational costs.
  In this work, we introduce RAGDefender, a resource-efficient defense
mechanism against knowledge corruption (i.e., by data poisoning) attacks in
practical RAG deployments. RAGDefender operates during the post-retrieval
phase, leveraging lightweight machine learning techniques to detect and filter
out adversarial content without requiring additional model training or
inference. Our empirical evaluations show that RAGDefender consistently
outperforms existing state-of-the-art defenses across multiple models and
adversarial scenarios: e.g., RAGDefender reduces the attack success rate (ASR)
against the Gemini model from 0.89 to as low as 0.02, compared to 0.69 for
RobustRAG and 0.24 for Discern-and-Answer when adversarial passages outnumber
legitimate ones by a factor of four (4x).

</details>


### [29] [Black-Box Differentially Private Nonparametric Confidence Intervals Under Minimal Assumptions](https://arxiv.org/abs/2511.01303)
*Tomer Shoham,Moshe Shenfeld,Noa Velner-Harris,Katrina Ligett*

Main category: cs.CR

TL;DR: 提出一个通用框架，可将任何差分隐私估计器转换为差分隐私非参数置信区间，通过重复子采样和CDF后处理实现隐私放大和渐近有效性。


<details>
  <summary>Details</summary>
Motivation: 现有差分隐私置信区间方法不够通用，需要为每个统计量专门设计。本文旨在构建一个通用框架，能够将任意差分隐私估计器转换为有效的置信区间。

Method: 重复子采样数据，对每个子样本应用差分隐私估计器，然后对得到的经验CDF进行后处理构建置信区间，利用子采样的随机性实现隐私放大。

Result: 在温和假设下，经验CDF收敛于隐私统计量的真实CDF，构建的置信区间具有渐近有效性、紧致性，且与非隐私版本等价。实证表明该方法优于现有专用算法。

Conclusion: 该框架提供了一个简单通用的方法，能够将任意差分隐私估计器转换为有效的置信区间，解决了现有方法通用性不足的问题。

Abstract: We introduce a simple, general framework that takes any differentially
private estimator of any arbitrary quantity as a black box, and from it
constructs a differentially private nonparametric confidence interval of that
quantity. Our approach repeatedly subsamples the data, applies the private
estimator to each subsample, and then post-processes the resulting empirical
CDF to a confidence interval. Our analysis uses the randomness from the
subsampling to achieve privacy amplification. Under mild assumptions, the
empirical CDF we obtain approaches the CDF of the private statistic as the
sample size grows. We use this to show that the confidence intervals we
estimate are asymptotically valid, tight, and equivalent to their non-private
counterparts. We provide empirical evidence that our method performs well
compared with the (less-general) state-of-the-art algorithms.

</details>


### [30] [Beyond Static Thresholds: Adaptive RRC Signaling Storm Detection with Extreme Value Theory](https://arxiv.org/abs/2511.01391)
*Dang Kien Nguyen,Rim El Malki,Filippo Rebecchi,Raymond Knopp,Melek Önen*

Main category: cs.CR

TL;DR: 提出基于极值理论的自适应阈值检测系统，用于检测5G网络中针对RRC层的信令风暴攻击，能够区分恶意攻击和合法高流量情况。


<details>
  <summary>Details</summary>
Motivation: 5G网络中用户设备与基站的无线接口在连接建立过程中容易受到信令风暴攻击，攻击者通过发送大量连接请求阻止新用户建立连接，威胁无线接入控制平面的可用性。

Method: 基于极值理论设计自适应阈值检测系统，仅利用RRC层特征，在真实运营商网络RRC流量数据上应用模拟攻击场景进行数值评估。

Result: 检测系统在复杂条件下仍能实现高精度（93%以上）、高召回率和低检测延迟，能够有效区分攻击和合法高流量情况。

Conclusion: 基于极值理论的自适应阈值检测方法能够有效保护5G网络免受信令风暴攻击，确保在不同流量条件下稳定工作。

Abstract: In 5G and beyond networks, the radio communication between a User Equipment
(UE) and a base station (gNodeB or gNB), also known as the air interface, is a
critical component of network access and connectivity. During the connection
establishment procedure, the Radio Resource Control (RRC) layer can be
vulnerable to signaling storms, which threaten the availability of the radio
access control plane. These attacks may occur when one or more UEs send a large
number of connection requests to the gNB, preventing new UEs from establishing
connections. In this paper, we investigate the detection of such threats and
propose an adaptive threshold-based detection system based on Extreme Value
Theory (EVT). The proposed solution is evaluated numerically by applying
simulated attack scenarios based on a realistic threat model on top of
real-world RRC traffic data from an operator network. We show that, by
leveraging features from the RRC layer only, the detection system can not only
identify the attacks but also differentiate them from legitimate high-traffic
situations. The adaptive threshold calculated using EVT ensures that the system
can work under diverse traffic conditions. The results show high accuracy,
precision, and recall values (above 93%), and a low detection latency even
under complex conditions.

</details>


### [31] [ConneX: Automatically Resolving Transaction Opacity of Cross-Chain Bridges for Security Analysis](https://arxiv.org/abs/2511.01393)
*Hanzhong Liang,Yue Duan,Xing Su,Xiao Li,Yating Liu,Yulong Tian,Fengyuan Xu,Sheng Zhong*

Main category: cs.CR

TL;DR: ConneX是一个自动化系统，用于准确识别跨链桥两端的对应交易对，解决跨链交易配对记录缺失的问题。


<details>
  <summary>Details</summary>
Motivation: 随着Web3向多链架构发展，跨链桥成为关键基础设施，但缺乏跨链交易配对记录给安全分析带来挑战。

Method: 利用大语言模型(LLMs)在复杂交易记录中识别语义上合理的关键信息候选，并通过验证器模块根据交易值精炼这些候选。

Result: 在5个主要桥平台的约50万笔交易数据集上，ConneX平均F1得分0.9746，比基线至少提高20.05%，将语义搜索空间从1e10减少到小于100。

Conclusion: ConneX在追踪现实世界黑客事件中的非法资金方面成功应用，证明了其在增强跨链安全性和透明度方面的实用价值。

Abstract: As the Web3 ecosystem evolves toward a multi-chain architecture, cross-chain
bridges have become critical infrastructure for enabling interoperability
between diverse blockchain networks. However, while connecting isolated
blockchains, the lack of cross-chain transaction pairing records introduces
significant challenges for security analysis like cross-chain fund tracing,
advanced vulnerability detection, and transaction graph-based analysis. To
address this gap, we introduce ConneX, an automated and general-purpose system
designed to accurately identify corresponding transaction pairs across both
ends of cross-chain bridges. Our system leverages Large Language Models (LLMs)
to efficiently prune the semantic search space by identifying semantically
plausible key information candidates within complex transaction records.
Further, it deploys a novel examiner module that refines these candidates by
validating them against transaction values, effectively addressing semantic
ambiguities and identifying the correct semantics. Extensive evaluations on a
dataset of about 500,000 transactions from five major bridge platforms
demonstrate that ConneX achieves an average F1 score of 0.9746, surpassing
baselines by at least 20.05\%, with good efficiency that reduces the semantic
search space by several orders of magnitude (1e10 to less than 100). Moreover,
its successful application in tracing illicit funds (including a cross-chain
transfer worth $1 million) in real-world hacking incidents underscores its
practical utility for enhancing cross-chain security and transparency.

</details>


### [32] [Security-Aware Joint Sensing, Communication, and Computing Optimization in Low Altitude Wireless Networks](https://arxiv.org/abs/2511.01451)
*Jiacheng Wang,Changyuan Zhao,Jialing He,Geng Sun,Weijie Yuan,Dusit Niyato,Liehuang Zhu,Tao Xiang*

Main category: cs.CR

TL;DR: 本文研究低空无线网络中集成感知、通信和计算(ISCC)的联合性能优化，在保证通信保密性的前提下平衡感知和计算性能，提出基于DQN的多目标进化算法。


<details>
  <summary>Details</summary>
Motivation: 随着地面资源日益饱和，低空空域应用（如城市空中出租车、空中巡检）快速发展，但低空空域的开放性使通信面临安全威胁，影响ISCC性能并危及LAWN支持的应用程序可靠性。

Method: 推导波束图误差、保密率和信息年龄作为感知、保密通信和计算的性能指标，构建多目标优化问题，提出基于深度Q网络的多目标进化算法，自适应选择进化算子。

Result: 大量仿真表明，所提方法在感知精度、通信保密性和信息新鲜度之间实现了优于基线算法的平衡。

Conclusion: 该方法能有效保障ISCC性能和LAWN支持的低空应用，解决了低空无线网络中的安全与性能平衡问题。

Abstract: As terrestrial resources become increasingly saturated, the research
attention is shifting to the low-altitude airspace, with many emerging
applications such as urban air taxis and aerial inspection. Low-Altitude
Wireless Networks (LAWNs) are the foundation for these applications, with
integrated sensing, communications, and computing (ISCC) being one of the core
parts of LAWNs. However, the openness of low-altitude airspace exposes
communications to security threats, degrading ISCC performance and ultimately
compromising the reliability of applications supported by LAWNs. To address
these challenges, this paper studies joint performance optimization of ISCC
while considering secrecyness of the communications. Specifically, we derive
beampattern error, secrecy rate, and age of information (AoI) as performance
metrics for sensing, secrecy communication, and computing. Building on these
metrics, we formulate a multi-objective optimization problem that balances
sensing and computation performance while keeping the probability of
communication being detected below a required threshold. We then propose a deep
Q-network (DQN)-based multi-objective evolutionary algorithm, which adaptively
selects evolutionary operators according to the evolving optimization
objectives, thereby leading to more effective solutions. Extensive simulations
show that the proposed method achieves a superior balance among sensing
accuracy, communication secrecyness, and information freshness compared with
baseline algorithms, thereby safeguarding ISCC performance and LAWN-supported
low-altitude applications.

</details>


### [33] [Federated Cyber Defense: Privacy-Preserving Ransomware Detection Across Distributed Systems](https://arxiv.org/abs/2511.01583)
*Daniel M. Jimenez-Gutierrez,Enrique Zuazua,Joaquin Del Rio,Oleksii Sliusarenko,Xabi Uribe-Etxebarria*

Main category: cs.CR

TL;DR: 本文评估了使用联邦学习（FL）进行勒索软件检测的方法，通过Sherpa.ai FL平台实现多组织协作训练，同时保持原始数据本地化。实验表明FL相比本地模型将检测准确率相对提升9%，性能接近集中式训练。


<details>
  <summary>Details</summary>
Motivation: 勒索软件检测需要多样化数据集，但数据通常分布在多个组织中，集中化学习因安全、隐私法规和数据所有权问题而不可行。同时勒索软件快速演变，需要既鲁棒又适应性强的模型。

Method: 使用联邦学习（FL）和Sherpa.ai FL平台，让多个组织协作训练勒索软件检测模型，同时保持原始数据本地安全。基于Ransomware Storage Access Patterns (RanSAP)数据集进行验证。

Result: 实验显示FL将勒索软件检测准确率相对提升9%超过服务器本地模型，并达到与集中式训练相当的性能。

Conclusion: FL提供了一个可扩展、高性能且保护隐私的框架，能够在组织和监管边界之间实现主动的勒索软件检测。

Abstract: Detecting malware, especially ransomware, is essential to securing today's
interconnected ecosystems, including cloud storage, enterprise file-sharing,
and database services. Training high-performing artificial intelligence (AI)
detectors requires diverse datasets, which are often distributed across
multiple organizations, making centralization necessary. However, centralized
learning is often impractical due to security, privacy regulations, data
ownership issues, and legal barriers to cross-organizational sharing.
Compounding this challenge, ransomware evolves rapidly, demanding models that
are both robust and adaptable.
  In this paper, we evaluate Federated Learning (FL) using the Sherpa.ai FL
platform, which enables multiple organizations to collaboratively train a
ransomware detection model while keeping raw data local and secure. This
paradigm is particularly relevant for cybersecurity companies (including both
software and hardware vendors) that deploy ransomware detection or firewall
systems across millions of endpoints. In such environments, data cannot be
transferred outside the customer's device due to strict security, privacy, or
regulatory constraints. Although FL applies broadly to malware threats, we
validate the approach using the Ransomware Storage Access Patterns (RanSAP)
dataset.
  Our experiments demonstrate that FL improves ransomware detection accuracy by
a relative 9% over server-local models and achieves performance comparable to
centralized training. These results indicate that FL offers a scalable,
high-performing, and privacy-preserving framework for proactive ransomware
detection across organizational and regulatory boundaries.

</details>


### [34] [Prompt Injection as an Emerging Threat: Evaluating the Resilience of Large Language Models](https://arxiv.org/abs/2511.01634)
*Daniyal Ganiuly,Assel Smaiyl*

Main category: cs.CR

TL;DR: 提出了一个统一的框架来评估大语言模型对提示注入攻击的抵抗能力，定义了三个互补指标（RDI、SCC、IIM）来衡量鲁棒性、安全性和语义稳定性。


<details>
  <summary>Details</summary>
Motivation: 大语言模型虽然能够遵循自然语言指令，但也容易受到提示注入攻击，导致模型忽略预期任务或产生不安全响应。

Method: 使用统一评估框架，在四个指令调优模型（GPT-4、GPT-4o、LLaMA-3 8B Instruct、Flan-T5-Large）上评估五个常见语言任务。

Result: GPT-4整体表现最佳，开源模型更易受攻击。所有模型都部分易受攻击，特别是间接和直接覆盖攻击。

Conclusion: 对齐强度和安全调优对抵抗力的重要性超过模型大小本身，该框架为评估模型鲁棒性提供了结构化、可复现的方法。

Abstract: Large Language Models (LLMs) are increasingly used in intelligent systems
that perform reasoning, summarization, and code generation. Their ability to
follow natural-language instructions, while powerful, also makes them
vulnerable to a new class of attacks known as prompt injection. In these
attacks, hidden or malicious instructions are inserted into user inputs or
external content, causing the model to ignore its intended task or produce
unsafe responses. This study proposes a unified framework for evaluating how
resistant Large Language Models (LLMs) are to prompt injection attacks. The
framework defines three complementary metrics such as the Resilience
Degradation Index (RDI), Safety Compliance Coefficient (SCC), and Instructional
Integrity Metric (IIM) to jointly measure robustness, safety, and semantic
stability. We evaluated four instruction-tuned models (GPT-4, GPT-4o, LLaMA-3
8B Instruct, and Flan-T5-Large) on five common language tasks: question
answering, summarization, translation, reasoning, and code generation. Results
show that GPT-4 performs best overall, while open-weight models remain more
vulnerable. The findings highlight that strong alignment and safety tuning are
more important for resilience than model size alone. Results show that all
models remain partially vulnerable, especially to indirect and direct-override
attacks. GPT-4 achieved the best overall resilience (RDR = 9.8 %, SCR = 96.4
%), while open-source models exhibited higher performance degradation and lower
safety scores. The findings demonstrate that alignment strength and safety
tuning play a greater role in resilience than model size alone. The proposed
framework offers a structured, reproducible approach for assessing model
robustness and provides practical insights for improving LLM safety and
reliability.

</details>


### [35] [Panther: A Cost-Effective Privacy-Preserving Framework for GNN Training and Inference Services in Cloud Environments](https://arxiv.org/abs/2511.01654)
*Congcong Chen,Xinyu Liu,Kaifeng Huang,Lifei Wei,Yang Shi*

Main category: cs.CR

TL;DR: Panther是一个在云环境中保护图神经网络隐私的框架，通过四方向计算和随机填充技术，显著降低了训练和推理的时间和通信开销，从而大幅减少财务成本。


<details>
  <summary>Details</summary>
Motivation: 随着云计算的普及，如何在保护GNN隐私的同时降低云计算的财务成本成为一个关键问题。现有隐私保护技术虽然有效，但计算和通信开销较高，导致财务成本限制了其广泛应用。

Method: Panther利用四方向计算异步执行安全数组访问协议，并随机填充GNN节点的邻居信息，以保护训练和推理过程中的隐私。

Result: 评估显示，与现有技术相比，Panther平均减少了75.28%的训练时间和82.80%的推理时间，通信开销平均降低了52.61%和50.26%，在Google云平台上估计可节省55.05%的训练成本和59.00%的推理成本。

Conclusion: Panther框架在保护GNN隐私的同时，显著降低了云计算的财务成本，为隐私保护GNN在云环境中的广泛应用提供了可行方案。

Abstract: Graph Neural Networks (GNNs) have marked significant impact in traffic state
prediction, social recommendation, knowledge-aware question answering and so
on. As more and more users move towards cloud computing, it has become a
critical issue to unleash the power of GNNs while protecting the privacy in
cloud environments. Specifically, the training data and inference data for GNNs
need to be protected from being stolen by external adversaries. Meanwhile, the
financial cost of cloud computing is another primary concern for users.
Therefore, although existing studies have proposed privacy-preserving
techniques for GNNs in cloud environments, their additional computational and
communication overhead remain relatively high, causing high financial costs
that limit their widespread adoption among users.
  To protect GNN privacy while lowering the additional financial costs, we
introduce Panther, a cost-effective privacy-preserving framework for GNN
training and inference services in cloud environments. Technically, Panther
leverages four-party computation to asynchronously executing the secure array
access protocol, and randomly pads the neighbor information of GNN nodes. We
prove that Panther can protect privacy for both training and inference of GNN
models. Our evaluation shows that Panther reduces the training and inference
time by an average of 75.28% and 82.80%, respectively, and communication
overhead by an average of 52.61% and 50.26% compared with the state-of-the-art,
which is estimated to save an average of 55.05% and 59.00% in financial costs
(based on on-demand pricing model) for the GNN training and inference process
on Google Cloud Platform.

</details>


### [36] [Scam Shield: Multi-Model Voting and Fine-Tuned LLMs Against Adversarial Attacks](https://arxiv.org/abs/2511.01746)
*Chen-Wei Chang,Shailik Sarkar,Hossein Salemi,Hyungmin Kim,Shutonu Mitra,Hemant Purohit,Fengxiu Zhang,Michin Hong,Jin-Hee Cho,Chang-Tien Lu*

Main category: cs.CR

TL;DR: 提出了一种分层诈骗检测系统HSDS，结合轻量级多模型投票前端和微调LLaMA 3.1后端，通过多数投票和对抗性训练提高检测准确性和鲁棒性。


<details>
  <summary>Details</summary>
Motivation: 诈骗检测面临关键挑战，攻击者会制作逃避自动过滤器的消息，需要更准确和鲁棒的系统。

Method: 使用四个分类器的集成进行初步预测，通过多数投票决定，模糊案例升级到经过对抗性训练微调的LLaMA 3.1 8B模型。

Result: 实验显示该分层设计既提高了对抗性诈骗检测能力，又通过将大多数案例路由远离LLM缩短了推理时间，优于传统机器学习和专有LLM基线。

Conclusion: 混合投票机制和对抗性微调能有效增强LLMs对抗不断演变的诈骗策略，提升自动诈骗检测系统的韧性。

Abstract: Scam detection remains a critical challenge in cybersecurity as adversaries
craft messages that evade automated filters. We propose a Hierarchical Scam
Detection System (HSDS) that combines a lightweight multi-model voting front
end with a fine-tuned LLaMA 3.1 8B Instruct back end to improve accuracy and
robustness against adversarial attacks. An ensemble of four classifiers
provides preliminary predictions through majority vote, and ambiguous cases are
escalated to the fine-tuned model, which is optimized with adversarial training
to reduce misclassification. Experiments show that this hierarchical design
both improves adversarial scam detection and shortens inference time by routing
most cases away from the LLM, outperforming traditional machine-learning
baselines and proprietary LLM baselines. The findings highlight the
effectiveness of a hybrid voting mechanism and adversarial fine-tuning in
fortifying LLMs against evolving scam tactics, enhancing the resilience of
automated scam detection systems.

</details>
