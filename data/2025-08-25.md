<div id=toc></div>

# Table of Contents

- [cs.CR](#cs.CR) [Total: 19]


<div id='cs.CR'></div>

# cs.CR [[Back]](#toc)

### [1] [Implementing Zero Trust Architecture to Enhance Security and Resilience in the Pharmaceutical Supply Chain](https://arxiv.org/abs/2508.15776)
*Saeid Ghasemshirazi,Ghazaleh Shirvani,Marziye Ranjbar Tavakoli,Bahar Ghaedi,Mohammad Amin Langarizadeh*

Main category: cs.CR

TL;DR: 本文探讨零信任架构在医药供应链网络安全中的变革潜力，通过持续验证、最小权限访问和数据中心安全原则来应对数据泄露、假冒伪劣和供应链中断等挑战。


<details>
  <summary>Details</summary>
Motivation: 医药供应链面临日益严峻的网络安全威胁，这些威胁危及患者安全和运营连续性，需要创新的安全架构来保护这一关键生态系统。

Method: 采用零信任架构原则，包括持续验证、最小权限访问和数据中心安全，并通过真实案例研究展示成功实施。特别关注麻醉药品、高风险药物和易滥用物质的管理领域。

Result: 零信任架构能够显著提升医药供应链的安全性和数据保护能力，建立适应性强的韧性体系，有效防范不断变化的网络威胁。

Conclusion: 通过实施零信任架构，医药行业可以加强供应链安全，确保关键医疗操作的可信度，为患者安全提供可靠保障。

Abstract: The pharmaceutical supply chain faces escalating cybersecurity challenges
threatening patient safety and operational continuity. This paper examines the
transformative potential of zero trust architecture for enhancing security and
resilience within this critical ecosystem. We explore the challenges posed by
data breaches, counterfeiting, and disruptions and introduce the principles of
continuous verification, least-privilege access, and data-centric security
inherent in zero trust. Real-world case studies illustrate successful
implementations. Benefits include heightened security, data protection, and
adaptable resilience. As recognized by researchers and industrialists, a
reliable drug tracing system is crucial for ensuring drug safety throughout the
pharmaceutical production process. One of the most pivotal domains within the
pharmaceutical industry and its associated supply chains where zero trust can
be effectively implemented is in the management of narcotics, high-health-risk
drugs, and abusable substances. By embracing zero trust, the pharmaceutical
industry fortifies its supply chain against constantly changing cyber threats,
ensuring the trustworthiness of critical medical operations.

</details>


### [2] [Towards Stealthy and Effective Backdoor Attacks on Lane Detection: A Naturalistic Data Poisoning Approach](https://arxiv.org/abs/2508.15778)
*Yifan Liao,Yuxin Cao,Yedi Zhang,Wentao He,Yan Xiao,Xianglong Du,Zhiyong Huang,Jin Song Dong*

Main category: cs.CR

TL;DR: DBALD是一个基于扩散模型的自然化后门触发生成框架，通过热图定位最优触发位置和区域编辑扩散过程生成隐蔽后门，在车道检测模型中实现了高攻击成功率和优越的隐蔽性。


<details>
  <summary>Details</summary>
Motivation: 现有车道检测后门攻击方法的触发机制过于人工化和明显，缺乏实际应用价值，需要研究更具生态效度的自然化后门攻击方法。

Method: 提出DBALD框架，包含两个核心组件：1）基于热图的最优触发位置定位方法，通过梯度分析生成攻击特异性热图；2）基于区域编辑的扩散过程，在易受攻击区域合成视觉合理的触发机制，并引入车道结构保持和驾驶场景一致性两种损失策略。

Result: 在4个主流车道检测模型上的实验表明，DBALD相比现有方法平均攻击成功率提升+10.87%，且隐蔽性显著增强。

Conclusion: 实验结果凸显了在真实世界后门威胁下确保车道检测模型鲁棒性的重大实践挑战，DBALD为研究更自然的后门攻击提供了有效框架。

Abstract: Deep learning-based lane detection (LD) plays a critical role in autonomous
driving and advanced driver assistance systems. However, its vulnerability to
backdoor attacks presents a significant security concern. Existing backdoor
attack methods on LD often exhibit limited practical utility due to the
artificial and conspicuous nature of their triggers. To address this limitation
and investigate the impact of more ecologically valid backdoor attacks on LD
models, we examine the common data poisoning attack and introduce DBALD, a
novel diffusion-based data poisoning framework for generating naturalistic
backdoor triggers. DBALD comprises two key components: optimal trigger position
finding and stealthy trigger generation. Given the insight that attack
performance varies depending on the trigger position, we propose a
heatmap-based method to identify the optimal trigger location, with gradient
analysis to generate attack-specific heatmaps. A region-based editing diffusion
process is then applied to synthesize visually plausible triggers within the
most susceptible regions identified previously. Furthermore, to ensure scene
integrity and stealthy attacks, we introduce two loss strategies: one for
preserving lane structure and another for maintaining the consistency of the
driving scene. Consequently, compared to existing attack methods, DBALD
achieves both a high attack success rate and superior stealthiness. Extensive
experiments on 4 mainstream LD models show that DBALD exceeds state-of-the-art
methods, with an average success rate improvement of +10.87% and significantly
enhanced stealthiness. The experimental results highlight significant practical
challenges in ensuring model robustness against real-world backdoor threats in
LD.

</details>


### [3] [Uplifted Attackers, Human Defenders: The Cyber Offense-Defense Balance for Trailing-Edge Organizations](https://arxiv.org/abs/2508.15808)
*Benjamin Murphy,Twm Stone*

Main category: cs.CR

TL;DR: AI技术进步将会大大增加后进企业的网络安全风险，需要改变安全策略和政府干预来应对这些挑战


<details>
  <summary>Details</summary>
Motivation: 分析AI对网络安全攻防平衡的影响，特别是对侚赖遗留软件、安全人力不足的"后进企业"的风险

Method: 通过分析AI技术发展对网络攻击经济学的影响，识别两个主要风险前沿：攻击成本下降导致更多攻击，以及AI加速漏洞利用和攻击发动

Result: 预计近期将出现敏锐增长的网络攻击数量，后进企业的当前安全策略将无法应对这些挑战

Conclusion: 建议企业和政府采取一系列措施来提升后进企业的防御能力，包括加快补丁部署速度、开发更弹性的软件，以及政府层面的干预和支持

Abstract: Advances in AI are widely understood to have implications for cybersecurity.
Articles have emphasized the effect of AI on the cyber offense-defense balance,
and commentators can be found arguing either that cyber will privilege
attackers or defenders. For defenders, arguments are often made that AI will
enable solutions like formal verification of all software--and for some
well-equipped companies, this may be true. This conversation, however, does not
match the reality for most companies. "Trailing-edge organizations," as we term
them, rely heavily on legacy software, poorly staff security roles, and
struggle to implement best practices like rapid deployment of security patches.
These decisions may be the result of corporate inertia, but may also be the
result of a seemingly-rational calculation that attackers may not bother
targeting a firm due to lack of economic incentives, and as a result,
underinvestment in defense will not be punished.
  This approach to security may have been sufficient prior to the development
of AI systems, but it is unlikely to remain viable in the near future. We argue
that continuing improvements in AI's capabilities poses additional risks on two
fronts: First, increased usage of AI will alter the economics of the marginal
cyberattack and expose these trailing-edge organizations to more attackers,
more frequently. Second, AI's advances will enable attackers to develop
exploits and launch attacks earlier than they can today--meaning that it is
insufficient for these companies to attain parity with today's leading
defenders, but must instead aim for faster remediation timelines and more
resilient software. The situation today portends a dramatically increased
number of attacks in the near future. Moving forward, we offer a range of
solutions for both organizations and governments to improve the defensive
posture of firms which lag behind their peers today.

</details>


### [4] [CIA+TA Risk Assessment for AI Reasoning Vulnerabilities](https://arxiv.org/abs/2508.15839)
*Yuksel Aydin*

Main category: cs.CR

TL;DR: 提出了认知网络安全框架，扩展传统CIA三元组为CIA+TA（增加信任和自主性），提供量化风险评估方法，验证显示防御效果高度依赖架构


<details>
  <summary>Details</summary>
Motivation: AI系统在关键决策中日益重要，面临利用推理机制而非技术基础设施的攻击威胁，需要系统性地保护AI推理过程免受对抗性操纵

Method: 建立认知网络安全学科框架，引入CIA+TA概念扩展，开发量化风险评估方法，通过151名人类参与者和12,180次AI试验进行验证

Result: 验证显示防御效果高度依赖架构：相同防御措施对漏洞的影响范围从减少96%到放大135%，需要部署前认知渗透测试作为治理要求

Conclusion: 认知网络安全是传统网络安全和AI安全的重要补充，需要将认知渗透测试作为可信AI部署的治理要求，框架可映射到OWASP LLM Top 10和MITRE ATLAS标准

Abstract: As AI systems increasingly influence critical decisions, they face threats
that exploit reasoning mechanisms rather than technical infrastructure. We
present a framework for cognitive cybersecurity, a systematic protection of AI
reasoning processes from adversarial manipulation. Our contributions are
threefold. First, we establish cognitive cybersecurity as a discipline
complementing traditional cybersecurity and AI safety, addressing
vulnerabilities where legitimate inputs corrupt reasoning while evading
conventional controls. Second, we introduce the CIA+TA, extending traditional
Confidentiality, Integrity, and Availability triad with Trust (epistemic
validation) and Autonomy (human agency preservation), requirements unique to
systems generating knowledge claims and mediating decisions. Third, we present
a quantitative risk assessment methodology with empirically-derived
coefficients, enabling organizations to measure cognitive security risks. We
map our framework to OWASP LLM Top 10 and MITRE ATLAS, facilitating operational
integration. Validation through previously published studies (151 human
participants; 12,180 AI trials) reveals strong architecture dependence:
identical defenses produce effects ranging from 96% reduction to 135%
amplification of vulnerabilities. This necessitates pre-deployment Cognitive
Penetration Testing as a governance requirement for trustworthy AI deployment.

</details>


### [5] [Unveiling Unicode's Unseen Underpinnings in Undermining Authorship Attribution](https://arxiv.org/abs/2508.15840)
*Robert Dilworth*

Main category: cs.CR

TL;DR: 论文分析了公共通信中用户隐私保护的局限性，即使采取各种匿名化措施，消息内容本身仍可通过文本风格分析暴露作者身份，并提出了基于Unicode隐写术的对抗性文本风格分析增强策略。


<details>
  <summary>Details</summary>
Motivation: 用户在公共通信渠道中即使采取各种匿名化技术，消息内容本身仍可能通过文本风格分析（stylometry）暴露作者真实身份，这构成了隐私保护的重大挑战。

Method: 论文剖析了文本风格分析技术，讨论了对抗性文本风格分析的策略，并设计了通过Unicode隐写术来增强隐私保护的方法。

Result: 研究发现即使最谨慎的匿名化措施也无法完全保护用户免受文本风格分析的威胁，需要开发更先进的对抗技术。

Conclusion: 公共通信中的隐私保护需要超越传统匿名化技术，采用如Unicode隐写术等高级对抗性文本风格分析方法来有效保护用户身份隐私。

Abstract: When using a public communication channel -- whether formal or informal, such
as commenting or posting on social media -- end users have no expectation of
privacy: they compose a message and broadcast it for the world to see. Even if
an end user takes utmost precautions to anonymize their online presence --
using an alias or pseudonym; masking their IP address; spoofing their
geolocation; concealing their operating system and user agent; deploying
encryption; registering with a disposable phone number or email; disabling
non-essential settings; revoking permissions; and blocking cookies and
fingerprinting -- one obvious element still lingers: the message itself.
Assuming they avoid lapses in judgment or accidental self-exposure, there
should be little evidence to validate their actual identity, right? Wrong. The
content of their message -- necessarily open for public consumption -- exposes
an attack vector: stylometric analysis, or author profiling. In this paper, we
dissect the technique of stylometry, discuss an antithetical counter-strategy
in adversarial stylometry, and devise enhancements through Unicode
steganography.

</details>


### [6] [Self-Disguise Attack: Induce the LLM to disguise itself for AIGT detection evasion](https://arxiv.org/abs/2508.15848)
*Yinghan Zhou,Juan Wen,Wanli Peng,Zhengxian Wu,Ziwei Zhang,Yiming Xue*

Main category: cs.CR

TL;DR: 自我伪装攻击(SDA)通过生成伪装特征和检索相关示例，使LLM生成更像人类文本的文本，以避免AI生成文本检测器的检测，同时保持文本质量和减少计算成本。


<details>
  <summary>Details</summary>
Motivation: 现有的AI生成文本检测避免方法存在计算成本高和文本质量下降的问题，需要一种更有效的方法来提高检测器的可靠性和实际应用效果。

Method: 提出自我伪装攻击(SDA)，包含对抗性特征提取器和基于检索的上下文示例优化器。前者生成伪装特征使LLM生成更像人类的文本，后者从外部知识库中检索相关示例作为上下文示例，提高自我伪装能力并维持文本多样性。

Result: 实验结果显示，SDA能够有效降低多种AIGT检测器对三种不同LLM生成文本的平均检测准确率，同时保持AIGT的质量。

Conclusion: SDA为AI生成文本检测避免提供了一种高效的方法，能够在保持文本质量的同时降低检测概率，并减少资源消耗，对提升检测器的可靠性和实际应用有重要意义。

Abstract: AI-generated text (AIGT) detection evasion aims to reduce the detection
probability of AIGT, helping to identify weaknesses in detectors and enhance
their effectiveness and reliability in practical applications. Although
existing evasion methods perform well, they suffer from high computational
costs and text quality degradation. To address these challenges, we propose
Self-Disguise Attack (SDA), a novel approach that enables Large Language Models
(LLM) to actively disguise its output, reducing the likelihood of detection by
classifiers. The SDA comprises two main components: the adversarial feature
extractor and the retrieval-based context examples optimizer. The former
generates disguise features that enable LLMs to understand how to produce more
human-like text. The latter retrieves the most relevant examples from an
external knowledge base as in-context examples, further enhancing the
self-disguise ability of LLMs and mitigating the impact of the disguise process
on the diversity of the generated text. The SDA directly employs prompts
containing disguise features and optimized context examples to guide the LLM in
generating detection-resistant text, thereby reducing resource consumption.
Experimental results demonstrate that the SDA effectively reduces the average
detection accuracy of various AIGT detectors across texts generated by three
different LLMs, while maintaining the quality of AIGT.

</details>


### [7] [Linkage Attacks Expose Identity Risks in Public ECG Data Sharing](https://arxiv.org/abs/2508.15850)
*Ziyu Wang,Elahe Khatibi,Farshad Firouzi,Sanaz Rahimi Mousavi,Krishnendu Chakrabarty,Amir M. Rahmani*

Main category: cs.CR

TL;DR: 这篇论文通过实际攻击场景评估心电图(ECG)数据隐私风险，证明即使攻击者仅拥有部分知识也能达到85%的重识别准确率，显示简单匿名化技术的不足。


<details>
  <summary>Details</summary>
Motivation: 随着公开分享心电图数据的增多，其生物识别特性使个人面临链接攻击风险。之前研究假设理想化攻击条件，本研究重点考察实际部分知识攻击场景。

Method: 使用109名参与者的多样化实际数据集，在攻击者仅拥有部分知识的实际条件下评估重识别风险，通过最优信心阈值进行分析。

Result: 结果显示在公共数据集中达到85%的个人重识别准确率，总体错误分类率为14.2%，未知个体被错误识别为已知的比例为15.6%，已知个体被错误识别为未知的比例为12.8%。

Conclusion: 简单匿名化技术无法有效防范重识别风险，即使攻击者仅拥有限知识也能实现高效身份链接。强调必须采用差分隐私、访问控制和加密计算等隐私保护策略，以在保障数据有用性的同时减少重识别风险。

Abstract: The increasing availability of publicly shared electrocardiogram (ECG) data
raises critical privacy concerns, as its biometric properties make individuals
vulnerable to linkage attacks. Unlike prior studies that assume idealized
adversarial capabilities, we evaluate ECG privacy risks under realistic
conditions where attackers operate with partial knowledge. Using data from 109
participants across diverse real-world datasets, our approach achieves 85%
accuracy in re-identifying individuals in public datasets while maintaining a
14.2% overall misclassification rate at an optimal confidence threshold, with
15.6% of unknown individuals misclassified as known and 12.8% of known
individuals misclassified as unknown. These results highlight the inadequacy of
simple anonymization techniques in preventing re-identification, demonstrating
that even limited adversarial knowledge enables effective identity linkage. Our
findings underscore the urgent need for privacy-preserving strategies, such as
differential privacy, access control, and encrypted computation, to mitigate
re-identification risks while ensuring the utility of shared biosignal data in
healthcare applications.

</details>


### [8] [Securing Swarms: Cross-Domain Adaptation for ROS2-based CPS Anomaly Detection](https://arxiv.org/abs/2508.15865)
*Julia Boone,Fatemeh Afghah*

Main category: cs.CR

TL;DR: 开发了一种适用于网络物理系统（CPS）的自适应异常检测模型，利用领域自适应技术将网络流量环境中的攻击知识迁移到CPS环境中，无需标记数据即可检测攻击。


<details>
  <summary>Details</summary>
Motivation: 当前大多数入侵检测系统仅基于网络流量数据集进行训练和验证，忽略了CPS多层设计中其他系统层可能发生的独特攻击，导致CPS安全防护存在局限性。

Method: 采用领域自适应技术，将已知攻击知识从纯网络流量环境迁移到CPS环境，构建无需预先标记数据的异常检测模型。使用包含网络、操作系统和ROS数据的先进CPS入侵数据集进行验证。

Result: 模型在网络流量环境和CPS环境中均表现出色，能够有效检测不同类型的攻击，性能优于其他异常检测方法。

Conclusion: 该自适应异常检测模型为CPS安全提供了有效的解决方案，通过领域自适应技术成功解决了CPS多层攻击检测的挑战，具有实际应用价值。

Abstract: Cyber-physical systems (CPS) are being increasingly utilized for critical
applications. CPS combines sensing and computing elements, often having
multi-layer designs with networking, computational, and physical interfaces,
which provide them with enhanced capabilities for a variety of application
scenarios. However, the combination of physical and computational elements also
makes CPS more vulnerable to attacks compared to network-only systems, and the
resulting impacts of CPS attacks can be substantial. Intelligent intrusion
detection systems (IDS) are an effective mechanism by which CPS can be secured,
but the majority of current solutions often train and validate on network
traffic-only datasets, ignoring the distinct attacks that may occur on other
system layers. In order to address this, we develop an adaptable CPS anomaly
detection model that can detect attacks within CPS without the need for
previously labeled data. To achieve this, we utilize domain adaptation
techniques that allow us to transfer known attack knowledge from a network
traffic-only environment to a CPS environment. We validate our approach using a
state-of-the-art CPS intrusion dataset that combines network, operating system
(OS), and Robot Operating System (ROS) data. Through this dataset, we are able
to demonstrate the effectiveness of our model across network traffic-only and
CPS environments with distinct attack types and its ability to outperform other
anomaly detection methods.

</details>


### [9] [Evolving k-Threshold Visual Cryptography Schemes](https://arxiv.org/abs/2508.15917)
*Xiaoli Zhuo,Xuehu Yan,Lintao Liu,Wei Yan*

Main category: cs.CR

TL;DR: 本文提出了首个适用于任意k值的(k,∞)视觉密码方案，基于随机网格技术，无需像素扩展且能提升对比度。


<details>
  <summary>Details</summary>
Motivation: 现有的视觉密码方案主要针对有限参与者，对于无限参与者的(k,∞)VCS缺乏正式定义和有效构造方法，且存在对比度不足的问题。

Method: 首先形式化定义(k,∞)VCS，然后基于随机网格技术构建适用于任意k值的方案，并针对k=2,3开发优化方案，对k≥4提出对比度增强策略。

Result: 理论分析和实验结果表明，所提方案在对比度性能上优于现有方法，能够有效支持无限参与者的视觉密码共享。

Conclusion: 该研究填补了无限参与者视觉密码方案的空白，为实际应用提供了理论基础和实用构造方法，具有重要的理论和实践价值。

Abstract: In evolving access structures, the number of participants is countably
infinite with no predetermined upper bound. While such structures have been
realized in secret sharing, research in secret image sharing has primarily
focused on visual cryptography schemes (VCS). However, there exists no
construction for $(k,\infty)$ VCS that applies to arbitrary $k$ values without
pixel expansion currently, and the contrast requires enhancement. In this
paper, we first present a formal mathematical definition of $(k,\infty)$ VCS.
Then, propose a $(k,\infty)$ VCS based on random grids that works for arbitrary
$k$. In addition, to further improve contrast, we develop optimized
$(k,\infty)$ VCS for $k=2$ and $3$, along with contrast enhancement strategies
for $k\geq 4$. Theoretical analysis and experimental results demonstrate the
superiority of our proposed schemes.

</details>


### [10] [Strategic Sample Selection for Improved Clean-Label Backdoor Attacks in Text Classification](https://arxiv.org/abs/2508.15934)
*Onur Alp Kirci,M. Emre Gursoy*

Main category: cs.CR

TL;DR: 通过三种样本选择策略（Minimum、Above50、Below50）提高清洁标签后门攻击效果，在保持模型净度的同时显著提升攻击成功率


<details>
  <summary>Details</summary>
Motivation: 清洁标签后门攻击比脏标签攻击更难，需要提高攻击效果性

Method: 识别模型预测错误或低信心度的样本，在这些样本中注入后门触发器，强化触发模式与目标标签的关联

Result: 提出的策略（尤其是Minimum策略）显著提高了ASR，在三个数据集和四种模型上都超过随机选择，还超过了现有的BITE方法

Conclusion: 通过智能样本选择策略可以有效提升清洁标签后门攻击的效果，为NLP模型安全提供了新的攻击方法

Abstract: Backdoor attacks pose a significant threat to the integrity of text
classification models used in natural language processing. While several
dirty-label attacks that achieve high attack success rates (ASR) have been
proposed, clean-label attacks are inherently more difficult. In this paper, we
propose three sample selection strategies to improve attack effectiveness in
clean-label scenarios: Minimum, Above50, and Below50. Our strategies identify
those samples which the model predicts incorrectly or with low confidence, and
by injecting backdoor triggers into such samples, we aim to induce a stronger
association between the trigger patterns and the attacker-desired target label.
We apply our methods to clean-label variants of four canonical backdoor attacks
(InsertSent, WordInj, StyleBkd, SynBkd) and evaluate them on three datasets
(IMDB, SST2, HateSpeech) and four model types (LSTM, BERT, DistilBERT,
RoBERTa). Results show that the proposed strategies, particularly the Minimum
strategy, significantly improve the ASR over random sample selection with
little or no degradation in the model's clean accuracy. Furthermore,
clean-label attacks enhanced by our strategies outperform BITE, a state of the
art clean-label attack method, in many configurations.

</details>


### [11] [PickleBall: Secure Deserialization of Pickle-based Machine Learning Models](https://arxiv.org/abs/2508.15987)
*Andreas D. Kellas,Neophytos Christou,Wenxin Jiang,Penghui Li,Laurent Simon,Yaniv David,Vasileios P. Kemerlis,James C. Davis,Junfeng Yang*

Main category: cs.CR

TL;DR: PickleBall是一个针对机器学习模型安全加载的工具，通过静态分析生成安全策略，在加载时动态执行，能安全加载79.8%的良性pickle模型并100%拒绝恶意模型。


<details>
  <summary>Details</summary>
Motivation: Hugging Face等模型仓库中44.9%的流行模型仍使用不安全的pickle格式，现有防御措施存在不足：限制性加载策略不灵活，模型扫描器存在误报和漏报，缺乏透明安全的加载工具。

Method: PickleBall静态分析机器学习库的源代码，计算自定义策略来指定良性模型的安全加载行为，然后在加载时作为pickle模块的替代品动态执行该策略。

Result: PickleBall能正确加载数据集中79.8%的良性pickle模型，同时拒绝所有(100%)恶意样本。相比现有技术，评估的模型扫描器未能识别已知恶意模型，最先进的加载器比PickleBall少加载22%的良性模型。

Conclusion: PickleBall消除了恶意pickle模型中任意函数调用的威胁，提高了攻击者依赖代码重用技术的门槛，为机器学习社区提供了透明的安全加载解决方案。

Abstract: Machine learning model repositories such as the Hugging Face Model Hub
facilitate model exchanges. However, bad actors can deliver malware through
compromised models. Existing defenses such as safer model formats, restrictive
(but inflexible) loading policies, and model scanners have shortcomings: 44.9%
of popular models on Hugging Face still use the insecure pickle format, 15% of
these cannot be loaded by restrictive loading policies, and model scanners have
both false positives and false negatives. Pickle remains the de facto standard
for model exchange, and the ML community lacks a tool that offers transparent
safe loading.
  We present PickleBall to help machine learning engineers load pickle-based
models safely. PickleBall statically analyzes the source code of a given
machine learning library and computes a custom policy that specifies a safe
load-time behavior for benign models. PickleBall then dynamically enforces the
policy during load time as a drop-in replacement for the pickle module.
PickleBall generates policies that correctly load 79.8% of benign pickle-based
models in our dataset, while rejecting all (100%) malicious examples in our
dataset. In comparison, evaluated model scanners fail to identify known
malicious models, and the state-of-art loader loads 22% fewer benign models
than PickleBall. PickleBall removes the threat of arbitrary function invocation
from malicious pickle-based models, raising the bar for attackers to depend on
code reuse techniques.

</details>


### [12] [A Survey of Post-Quantum Cryptography Support in Cryptographic Libraries](https://arxiv.org/abs/2508.16078)
*Nadeem Ahmed,Lei Zhang,Aryya Gangopadhyay*

Main category: cs.CR

TL;DR: 对主流开源加密库的后量子加密算法支持状况进行评估，发现各库准备程度差异显著，需要加强研究、标准化和协调采用策略


<details>
  <summary>Details</summary>
Motivation: 量子计算的快速发展对现代加密系统构成严重威胁，必须向后量子加密迁移

Method: 基于2025年初的最新文档、发布说明和行业报告，评估9个广泛使用的开源加密库对NIST选定的后量子加密算法的支持情况

Result: 各加密库的准备状态差异显著，一些库已集成PQC支持或有清晰实现路线图，而另一些延后，造成安全风险

Conclusion: 需要继续研究、标准化努力和协调采用策略，确保安全迁移到量子耐受加密领域

Abstract: The rapid advancement of quantum computing poses a significant threat to
modern cryptographic systems, necessitating the transition to Post-Quantum
Cryptography (PQC). This study evaluates the support for PQC algorithms within
nine widely used open-source cryptographic libraries -- OpenSSL, wolfSSL,
BoringSSL, LibreSSL, Bouncy Castle, libsodium, Crypto++, Botan, and MbedTLS --
focusing on their implementation of the NIST-selected PQC finalists:
CRYSTALS-Kyber, CRYSTALS-Dilithium, FALCON, and SPHINCS+. Our analysis, based
on the latest available documentation, release notes, and industry reports as
of early 2025, reveals a varied state of readiness across these libraries.
While some libraries have integrated PQC support or have clear implementation
roadmaps, others lag behind, creating potential security risks as quantum
threats become more imminent. We discuss key challenges, including performance
trade-offs, implementation security, and adoption hurdles in real-world
cryptographic applications. Our findings highlight the urgent need for
continued research, standardization efforts, and coordinated adoption
strategies to ensure a secure transition to the quantum-resistant cryptographic
landscape.

</details>


### [13] [SoK: Understanding the Fundamentals and Implications of Sensor Out-of-band Vulnerabilities](https://arxiv.org/abs/2508.16133)
*Shilin Xiao,Wenjun Zhu,Yan Jiang,Kai Wang,Peiwang Wang,Chen Yan,Xiaoyu Ji,Wenyuan Xu*

Main category: cs.CR

TL;DR: 提出了传感器带外(OOB)漏洞系统化框架，首次基于物理原理为传感器攻击面提供全面抽象，通过组件、传感器和系统三个层次分析漏洞，为构建更安全的传感器和CPS提供指导。


<details>
  <summary>Details</summary>
Motivation: 当前对传感器硬件漏洞的理解是碎片化的，由于该领域的临时性特点，且无限攻击信号空间使威胁抽象和防御复杂化，需要系统化的分析框架。

Method: 采用自下而上的系统化方法，在三个层次分析OOB漏洞：组件层面分析物理原理和限制；传感器层面分类已知攻击并评估实用性；系统层面分析CPS特性如传感器融合、闭环控制和智能感知对漏洞暴露和缓解的影响。

Result: 提供了对传感器硬件安全的基础性理解，建立了首个基于物理原理的传感器攻击面全面抽象框架。

Conclusion: 该框架为传感器设计者、安全研究人员和系统开发者提供了构建更安全传感器和CPS的指导和未来研究方向。

Abstract: Sensors are fundamental to cyber-physical systems (CPS), enabling perception
and control by transducing physical stimuli into digital measurements. However,
despite growing research on physical attacks on sensors, our understanding of
sensor hardware vulnerabilities remains fragmented due to the ad-hoc nature of
this field. Moreover, the infinite attack signal space further complicates
threat abstraction and defense. To address this gap, we propose a
systematization framework, termed sensor out-of-band (OOB) vulnerabilities,
that for the first time provides a comprehensive abstraction for sensor attack
surfaces based on underlying physical principles. We adopt a bottom-up
systematization methodology that analyzes OOB vulnerabilities across three
levels. At the component level, we identify the physical principles and
limitations that contribute to OOB vulnerabilities. At the sensor level, we
categorize known attacks and evaluate their practicality. At the system level,
we analyze how CPS features such as sensor fusion, closed-loop control, and
intelligent perception impact the exposure and mitigation of OOB threats. Our
findings offer a foundational understanding of sensor hardware security and
provide guidance and future directions for sensor designers, security
researchers, and system developers aiming to build more secure sensors and CPS.

</details>


### [14] [Evaluating the Defense Potential of Machine Unlearning against Membership Inference Attacks](https://arxiv.org/abs/2508.16150)
*Aristeidis Sidiropoulos,Christos Chrysanthos Nikolaidis,Theodoros Tsiolakis,Nikolaos Pavlidis,Vasilis Perifanis,Pavlos S. Efraimidis*

Main category: cs.CR

TL;DR: 本研究系统评估了机器学习遗忘算法对成员推理攻击(MIA)脆弱性的影响，发现遗忘算法和数据特征会显著影响模型对MIA的暴露程度


<details>
  <summary>Details</summary>
Motivation: 机器学习遗忘主要设计为隐私保护机制，但其对模型抵抗成员推理攻击能力的影响仍是一个开放性问题

Method: 在四个多样化数据集(两个图像域和两个表格格式)上应用最先进的机器学习遗忘算法，系统评估模型对成员推理攻击的脆弱性

Result: 研究发现机器学习遗忘本身并非MIA的对策，但遗忘算法和数据特征会显著影响模型的脆弱性

Conclusion: 这项工作为机器学习遗忘与成员推理攻击之间的相互作用提供了重要见解，为设计隐私保护机器学习系统提供了指导

Abstract: Membership Inference Attacks (MIAs) pose a significant privacy risk, as they
enable adversaries to determine whether a specific data point was included in
the training dataset of a model. While Machine Unlearning is primarily designed
as a privacy mechanism to efficiently remove private data from a machine
learning model without the need for full retraining, its impact on the
susceptibility of models to MIA remains an open question. In this study, we
systematically assess the vulnerability of models to MIA after applying
state-of-art Machine Unlearning algorithms. Our analysis spans four diverse
datasets (two from the image domain and two in tabular format), exploring how
different unlearning approaches influence the exposure of models to membership
inference. The findings highlight that while Machine Unlearning is not
inherently a countermeasure against MIA, the unlearning algorithm and data
characteristics can significantly affect a model's vulnerability. This work
provides essential insights into the interplay between Machine Unlearning and
MIAs, offering guidance for the design of privacy-preserving machine learning
systems.

</details>


### [15] [A Relay-Chain-Powered Ciphertext-Policy Attribute-Based Encryption in Intelligent Transportation Systems](https://arxiv.org/abs/2508.16189)
*Aparna Singh,Geetanjali Rathee,Chaker Abdelaziz Kerrache,Mohamed Chahine Ghanem*

Main category: cs.CR

TL;DR: 提出了一种结合中继链驱动加密系统和改进CP-ABE方案的新架构，用于智能交通系统中的安全数据共享，实现动态访问控制和低延迟通信。


<details>
  <summary>Details</summary>
Motivation: 智能交通系统的快速发展对安全、高效和上下文感知的数据共享机制提出了迫切需求，特别是在异构和地理分散的环境中需要解决动态访问和低延迟通信的双重挑战。

Method: 采用中继链驱动的加密系统与改进的CP-ABE方案相结合，通过上下文感知智能合约根据数据类型、时间和地理区域等属性确定加密策略，OBU使用CP-ABE进行端到端加密并将密文存储在本地区域区块链中。

Result: 该分布式可扩展模型在实时响应性和安全性之间取得了良好平衡，高敏感事件采用严格的多属性访问规则，常规更新使用轻量策略以减轻处理负担，同时提供可追溯性和低延迟撤销功能。

Conclusion: 该架构非常适合在多管辖域运行的下一代车载网络，为智能交通系统提供了安全有效的数据共享解决方案。

Abstract: The very high growth of Intelligent Transportation Systems (ITS) has
generated an urgent requirement for secure, effective, and context-aware data
sharing mechanisms, especially over heterogeneous and geographically dispersed
settings. This work suggests a new architecture that combines a relay
chain-driven encryption system with a modified Ciphertext-Policy
Attribute-Based Encryption (CP-ABE) scheme to tackle the double impediment of
dynamic access and low-latency communication. The model proposes a
context-aware smart contract on a worldwide relay chain that checks against
data properties, including event type, time, and geographical region, to
specify the suitable level of encryption policy. From such relay-directed
judgment, On-Board Units (OBUs) encrypt data end-to-end by utilising CP-ABE and
store ciphertext inside localised regional blockchains, preventing dependence
on symmetric encryption or off-chain storage. High-sensitivity events are
secured with firm, multi-attribute access rules, whereas common updates use
light policies to help reduce processing burdens. The crypto system also adds
traceability and low-latency revocation, with global enforcement managed
through the relay chain. This distributed, scalable model provides a proper
balance between responsiveness in real time and security and is extremely apt
for next-gen vehicular networks that function across multi-jurisdictional
domains.

</details>


### [16] [How to Beat Nakamoto in the Race](https://arxiv.org/abs/2508.16202)
*Shu-Jie Cao,Dongning Guo*

Main category: cs.CR

TL;DR: 本文通过马尔可夫决策过程框架研究有界网络延迟下的工作量证明Nakamoto共识，提出了最优攻击策略"诱饵与切换"，并精确计算了任意确认深度下的安全违规概率。


<details>
  <summary>Details</summary>
Motivation: 解决区块链安全中的两个长期问题：在给定区块确认延迟下，对手如何最有效地攻击区块安全性？以及由此产生的安全违规概率是多少？

Method: 引入马尔可夫决策过程(MDP)框架来精确描述系统状态（包括所有挖出区块的树结构和时间）、对手的潜在行动，以及由于对手行动和随机区块到达过程导致的状态转换。提出了称为"诱饵与切换"的最优攻击策略。

Result: 证明了"诱饵与切换"攻击通过"在竞赛中击败Nakamoto"来最大化对手违反区块安全性的机会。使用马尔可夫链分析计算了任意确认深度下的确切违规概率。

Conclusion: 该研究为网络延迟、确认规则和区块链安全之间的相互作用提供了新的见解，为Nakamoto共识在有限网络延迟下的安全性提供了精确分析框架。

Abstract: This paper studies proof-of-work Nakamoto consensus under bounded network
delays, settling two long-standing questions in blockchain security: How can an
adversary most effectively attack block safety under a given block confirmation
latency? And what is the resulting probability of safety violation? A Markov
decision process (MDP) framework is introduced to precise characterize the
system state (including the tree and timings of all blocks mined), the
adversary's potential actions, and the state transitions due to the adversarial
action and the random block arrival processes. An optimal attack, called
bait-and-switch, is proposed and proved to maximize the adversary's chance of
violating block safety by "beating Nakamoto in the race". The exact probability
of this violation is calculated for any confirmation depth using Markov chain
analysis, offering fresh insights into the interplay of network delay,
confirmation rules, and blockchain security.

</details>


### [17] [Confusion is the Final Barrier: Rethinking Jailbreak Evaluation and Investigating the Real Misuse Threat of LLMs](https://arxiv.org/abs/2508.16347)
*Yu Yan,Sheng Sun,Zhe Wang,Yijun Lin,Zenghao Duan,zhifei zheng,Min Liu,Zhiyi yin,Jianping Zhang*

Main category: cs.CR

TL;DR: 研究发现LLMs的安全评估与实际威胁存在差距，越狱成功率与有害知识掌握程度不匹配，现有评判框架过度关注毒性语言模式而非真实危险知识。


<details>
  <summary>Details</summary>
Motivation: 现有研究虽然推动了LLMs安全对齐的进展，但不清楚LLMs是否真正内化了处理现实犯罪的知识，还是仅仅在模拟毒性语言模式，这种模糊性引发了担忧。

Method: 通过解耦越狱技术的使用，构建知识密集型问答来调查LLMs在危险知识掌握、有害任务规划效用和危害性判断鲁棒性方面的滥用威胁。

Result: 实验显示LLMs的越狱成功率与有害知识掌握程度存在不匹配，现有LLM-as-a-judge框架倾向于将危害性判断锚定在毒性语言模式上。

Conclusion: 研究揭示了现有LLM安全评估与现实世界威胁潜力之间的差距，需要更关注模型是否真正掌握危险知识而非表面语言模式。

Abstract: With the development of Large Language Models (LLMs), numerous efforts have
revealed their vulnerabilities to jailbreak attacks. Although these studies
have driven the progress in LLMs' safety alignment, it remains unclear whether
LLMs have internalized authentic knowledge to deal with real-world crimes, or
are merely forced to simulate toxic language patterns. This ambiguity raises
concerns that jailbreak success is often attributable to a hallucination loop
between jailbroken LLM and judger LLM. By decoupling the use of jailbreak
techniques, we construct knowledge-intensive Q\&A to investigate the misuse
threats of LLMs in terms of dangerous knowledge possession, harmful task
planning utility, and harmfulness judgment robustness. Experiments reveal a
mismatch between jailbreak success rates and harmful knowledge possession in
LLMs, and existing LLM-as-a-judge frameworks tend to anchor harmfulness
judgments on toxic language patterns. Our study reveals a gap between existing
LLM safety assessments and real-world threat potential.

</details>


### [18] [Temperature-Resilient Reconfigurable PUF with Dual-Pulse Modulation based on SOT-MRAM Chip](https://arxiv.org/abs/2508.16405)
*Min Wang,Chuanpeng Jiang,Zhaohao Wang,Zhengyi Hou,Zhongkui Zhang,Yuanfu Zhao,Hongxi Liu,Weisheng Zhao*

Main category: cs.CR

TL;DR: 基于SOT-MRAM的双冲重构策略实现了不依赖环境温度的实时可重构物理不可克隆功能，为下一代物联网安全保护提供基础


<details>
  <summary>Details</summary>
Motivation: 在动态运行场景中保护大量数据，需要实现不依赖环境条件的实时重构能力，尤其是操作温度的影响

Method: 提出基于SOT-MRAM载体的双冲重构策略，扩大了操作窗口

Result: 实验结果表明设计在工业级操作温度范围内实现实时重构，无需实时温度动态反馈，并展现优秀的PUF指标

Conclusion: 该SOT-MRAM rPUF设计为下一代物联网保护架构奠定了坚实基础

Abstract: In the Internet of Things (IoT) era, hardware-based security solutions have
become an emerging choice for enhancing end-terminal information security. As
one of the hardware technologies, physical unclonable functions (PUFs) utilize
the inherent variations in the manufacturing process to generate cryptographic
keys. Reconfigurable PUFs (rPUFs), characterized by updating cryptographic
keys, offer enhanced security ability for protecting massive amounts of data in
dynamic operational scenarios. The core challenge lies in achieving real-time
reconfiguration independent of environmental conditions, particularly operating
temperature, which has rarely been investigated and addressed. In this study,
we propose a dual-pulse reconfiguration strategy based on SOT-MRAM carriers,
which effectively widens the operating window and exhibits excellent PUF
metrics. Experimental results demonstrate that our design achieves real-time
reconfiguration across industrial-grade operating temperature ranges, without
the need for dynamic feedback of real-time temperature. The proposed SOT-MRAM
rPUF design lays a solid foundation for next-generation IoT protection
architectures.

</details>


### [19] [Retrieval-Augmented Defense: Adaptive and Controllable Jailbreak Prevention for Large Language Models](https://arxiv.org/abs/2508.16406)
*Guangyu Yang,Jinghong Chen,Jingbiao Mei,Weizhe Lin,Bill Byrne*

Main category: cs.CR

TL;DR: RAD是一种基于检索增强生成的越狱检测框架，通过已知攻击示例数据库识别恶意查询和攻击策略，无需重新训练即可防御新兴攻击，并在安全性和实用性之间实现可控平衡。


<details>
  <summary>Details</summary>
Motivation: 大型语言模型容易受到越狱攻击，现有防御系统面临两大挑战：需要适应新兴攻击策略而无需昂贵重新训练，以及控制安全性与实用性之间的权衡。

Method: 提出检索增强防御（RAD）框架，将已知攻击示例数据库整合到检索增强生成中，用于推断恶意用户查询和攻击策略，支持无训练更新新发现的攻击策略。

Result: 在StrongREJECT数据集上的实验显示，RAD显著降低了PAP和PAIR等强越狱攻击的有效性，同时保持对良性查询的低拒绝率，实现了稳健的安全-效用权衡。

Conclusion: RAD提供了一种无需重新训练即可防御新兴越狱攻击的有效方法，通过可控机制在安全性和实用性之间取得良好平衡，为LLM安全防御提供了新思路。

Abstract: Large Language Models (LLMs) remain vulnerable to jailbreak attacks, which
attempt to elicit harmful responses from LLMs. The evolving nature and
diversity of these attacks pose many challenges for defense systems, including
(1) adaptation to counter emerging attack strategies without costly retraining,
and (2) control of the trade-off between safety and utility. To address these
challenges, we propose Retrieval-Augmented Defense (RAD), a novel framework for
jailbreak detection that incorporates a database of known attack examples into
Retrieval-Augmented Generation, which is used to infer the underlying,
malicious user query and jailbreak strategy used to attack the system. RAD
enables training-free updates for newly discovered jailbreak strategies and
provides a mechanism to balance safety and utility. Experiments on StrongREJECT
show that RAD substantially reduces the effectiveness of strong jailbreak
attacks such as PAP and PAIR while maintaining low rejection rates for benign
queries. We propose a novel evaluation scheme and show that RAD achieves a
robust safety-utility trade-off across a range of operating points in a
controllable manner.

</details>
