<div id=toc></div>

# Table of Contents

- [cs.CR](#cs.CR) [Total: 46]


<div id='cs.CR'></div>

# cs.CR [[Back]](#toc)

### [1] [Code Vulnerability Detection Across Different Programming Languages with AI Models](https://arxiv.org/abs/2508.11710)
*Hael Abdulhakim Ali Humran,Ferdi Sonmez*

Main category: cs.CR

TL;DR: 这篇论文研究了使用转换器模型（CodeBERT和CodeLlama）检测多编程语言代码安全漏洞的方法，通过动态微调、集成学习和可解释AI技术，达到了超过97%的准确率，在查全率方面表现优异于传统静态分析工具。


<details>
  <summary>Details</summary>
Motivation: 传统的基于规则的静态分析工具在检测上下文依赖性错误时效果很差，产生高假正率。人工智能技术的发展为解决这一问题提供了新的可能性。

Method: 采用转换器模型（CodeBERT和CodeLlama），包括数据集收集、语言标准化、模型微调、集成学习和可解释AI技术的综合应用。

Result: 实验结果显示经过良好训练的CodeBERT模型准确率超过97%，在查全率方面表现优异于传统静态分析工具。混合模型和验证流程有助于降低假正率。AI基于方案能够同时适用于不同编程语言和漏洞类型。

Conclusion: 这项研究证明了AI技术在提高代码漏洞检测的可靠性、易用性和可扩展性方面的巨大潜力，但在模型稳健性、可解释性和部署准备度方面仍需进一步完善。

Abstract: Security vulnerabilities present in a code that has been written in diverse
programming languages are among the most critical yet complicated aspects of
source code to detect. Static analysis tools based on rule-based patterns
usually do not work well at detecting the context-dependent bugs and lead to
high false positive rates. Recent developments in artificial intelligence,
specifically the use of transformer-based models like CodeBERT and CodeLlama,
provide light to this problem, as they show potential in finding such flaws
better. This paper presents the implementations of these models on various
datasets of code vulnerability, showing how off-the-shelf models can
successfully produce predictive capacity in models through dynamic fine-tuning
of the models on vulnerable and safe code fragments. The methodology comprises
the gathering of the dataset, normalization of the language, fine-tuning of the
model, and incorporation of ensemble learning and explainable AI. Experiments
show that a well-trained CodeBERT can be as good as or even better than some
existing static analyzers in terms of accuracy greater than 97%. Further study
has indicated that although language models can achieve close-to-perfect
recall, the precision can decrease. A solution to this is given by hybrid
models and validation procedures, which will reduce false positives. According
to the results, the AI-based solutions generalize to different programming
languages and classes of vulnerability. Nevertheless, robustness,
interpretability, and deployment readiness are still being developed. The
results illustrate the probabilities that AI will enhance the trustworthiness
in the usability and scalability of machine-learning-based detectors of
vulnerabilities.

</details>


### [2] [Enhancing GraphQL Security by Detecting Malicious Queries Using Large Language Models, Sentence Transformers, and Convolutional Neural Networks](https://arxiv.org/abs/2508.11711)
*Irash Perera,Hiranya Abeyrathne,Sanjeewa Malalgoda,Arshardh Ifthikar*

Main category: cs.CR

TL;DR: 这篇论文提出了一种基于AI的实时检测恶意GraphQL查询的新方法，结合静态分析和机器学习技术，能够高精度检测多种安全威胁。


<details>
  <summary>Details</summary>
Motivation: GraphQL的灵活性导致了传统API安全机制无法有效处理的独特安全漏洞，恶意查询可能导致拒绝服务攻击、数据泄漏等风险。

Method: 结合静态分析与机器学习技术，使用大语言模型(LLM)进行动态模式配置，使用Sentence Transformers(SBERT和Doc2Vec)进行查询负载的上下文嵌入，以及卷积神经网络(CNN)、随机森林和多层感知机进行分类。

Result: 系统在负载下表现良好，能够高精度检测SQL注入、操作系统命令注入、XSS漏洞等多种威胁，同时有效减缓DoS和SSRF攻击。

Conclusion: 这项研究为提高GraphQL API安全提供了一种稳健且适应性强的解决方案，能够有效应对灵活的恶意查询攻击。

Abstract: GraphQL's flexibility, while beneficial for efficient data fetching,
introduces unique security vulnerabilities that traditional API security
mechanisms often fail to address. Malicious GraphQL queries can exploit the
language's dynamic nature, leading to denial-of-service attacks, data
exfiltration through injection, and other exploits. Existing solutions, such as
static analysis, rate limiting, and general-purpose Web Application Firewalls,
offer limited protection against sophisticated, context-aware attacks. This
paper presents a novel, AI-driven approach for real-time detection of malicious
GraphQL queries. Our method combines static analysis with machine learning
techniques, including Large Language Models (LLMs) for dynamic schema-based
configuration, Sentence Transformers (SBERT and Doc2Vec) for contextual
embedding of query payloads, and Convolutional Neural Networks (CNNs), Random
Forests, and Multilayer Perceptrons for classification. We detail the system
architecture, implementation strategies optimized for production environments
(including ONNX Runtime optimization and parallel processing), and evaluate the
performance of our detection models and the overall system under load. Results
demonstrate high accuracy in detecting various threats, including SQL
injection, OS command injection, and XSS exploits, alongside effective
mitigation of DoS and SSRF attempts. This research contributes a robust and
adaptable solution for enhancing GraphQL API security.

</details>


### [3] [Privacy-Aware Detection of Fake Identity Documents: Methodology, Benchmark, and Improved Detection Methods (FakeIDet2)](https://arxiv.org/abs/2508.11716)
*Javier Muñoz-Haro,Ruben Tolosana,Ruben Vera-Rodriguez,Aythami Morales,Julian Fierrez*

Main category: cs.CR

TL;DR: 这篇论文提出了一种基于片段的隐私保护方法，并公开了包含90万个真伪ID片段的数据库，用于训练防范AI制造假证件的检测系统。


<details>
  <summary>Details</summary>
Motivation: 由于身份证件的敏感性，真实数据难以获取，而AI技术发展使得假证件制作更加以乱真，导致伪造ID检测研究面临数据缺乏的挑战。

Method: 采用片段基础方法来保护隐私，建立包含多种攻击模式（打印、屏幕、复合）的大规模公开数据库FakeIDet2-db，并提出隐私意识假ID检测方法FakeIDet2。

Result: 提供了超过900K个真伪ID片段的公开数据集，包含多种手机感应器、照明条件和拍摄角度的2,000张ID图像，为研究者提供了标准可复现的测试基准。

Conclusion: 该研究解决了假ID检测领域的数据缺乏问题，通过片段化方法保护用户隐私，为开发更有效的AI假证件检测系统奠定了基础。

Abstract: Remote user verification in Internet-based applications is becoming
increasingly important nowadays. A popular scenario for it consists of
submitting a picture of the user's Identity Document (ID) to a service
platform, authenticating its veracity, and then granting access to the
requested digital service. An ID is well-suited to verify the identity of an
individual, since it is government issued, unique, and nontransferable.
However, with recent advances in Artificial Intelligence (AI), attackers can
surpass security measures in IDs and create very realistic physical and
synthetic fake IDs. Researchers are now trying to develop methods to detect an
ever-growing number of these AI-based fakes that are almost indistinguishable
from authentic (bona fide) IDs. In this counterattack effort, researchers are
faced with an important challenge: the difficulty in using real data to train
fake ID detectors. This real data scarcity for research and development is
originated by the sensitive nature of these documents, which are usually kept
private by the ID owners (the users) and the ID Holders (e.g., government,
police, bank, etc.). The main contributions of our study are: 1) We propose and
discuss a patch-based methodology to preserve privacy in fake ID detection
research. 2) We provide a new public database, FakeIDet2-db, comprising over
900K real/fake ID patches extracted from 2,000 ID images, acquired using
different smartphone sensors, illumination and height conditions, etc. In
addition, three physical attacks are considered: print, screen, and composite.
3) We present a new privacy-aware fake ID detection method, FakeIDet2. 4) We
release a standard reproducible benchmark that considers physical and synthetic
attacks from popular databases in the literature.

</details>


### [4] [Assessing User Privacy Leakage in Synthetic Packet Traces: An Attack-Grounded Approach](https://arxiv.org/abs/2508.11742)
*Minhao Jin,Hongyu He,Maria Apostolaki*

Main category: cs.CR

TL;DR: 这篇论文提出了首个攻击基于的流量生成器隐私评测标准TraceBleed，发现现有合成流量生成器存在用户级别信息泄漏问题，差分隐私无法有效防范，并提出了TracePatch防御方案。


<details>
  <summary>Details</summary>
Motivation: 当前的合成网络流量生成器(SynNetGens)虽然提供隐私保证，但缺乏综合性保证和实证验证，需要建立一个基于实际攻击的评测标准来评估其隐私性能。

Method: 提出TraceBleed攻击方法，利用对比学习和时间切片技术来利用流量行为指纹进行成员推断，并在GAN、滿散和GPT基础的合成流量生成器上进行大规模实验。

Result: 研究发现：(i)合成流量生成器泄漏用户级别信息；(ii)差分隐私无法防止这些攻击或会严重降低保真度；(iii)分享更多合成数据会平均增加59%的信息泄漏。

Conclusion: 论文提出了TracePatch防御方案，通过结合对抗机器学习和SMT约束来减少信息泄漏同时保持保真度，为合成流量生成器提供了一个与生成器无关的隐私保护方案。

Abstract: Current synthetic traffic generators (SynNetGens) promise privacy but lack
comprehensive guarantees or empirical validation, even as their fidelity
steadily improves. We introduce the first attack-grounded benchmark for
assessing the privacy of SynNetGens directly from the traffic they produce. We
frame privacy as membership inference at the traffic-source level--a realistic
and actionable threat for data holders. To this end, we present TraceBleed, the
first attack that exploits behavioral fingerprints across flows using
contrastive learning and temporal chunking, outperforming prior membership
inference baselines by 172%. Our large-scale study across GAN-, diffusion-, and
GPT-based SynNetGens uncovers critical insights: (i) SynNetGens leak user-level
information; (ii) differential privacy either fails to stop these attacks or
severely degrades fidelity; and (iii) sharing more synthetic data amplifies
leakage by 59% on average. Finally, we introduce TracePatch, the first
SynNetGen-agnostic defense that combines adversarial ML with SMT constraints to
mitigate leakage while preserving fidelity.

</details>


### [5] [AegisBlock: A Privacy-Preserving Medical Research Framework using Blockchain](https://arxiv.org/abs/2508.11797)
*Calkin Garg,Omar Rios Cruz,Tessa Andersen,Gaby G. Dagher,Donald Winiecki,Min Long*

Main category: cs.CR

TL;DR: AegisBlock是一个基于区块链的患者中心化医疗数据共享框架，通过时间范围查询和患者授权机制，在保护患者隐私的同时确保研究数据的可信性。


<details>
  <summary>Details</summary>
Motivation: 由于HIPAA等隐私法规要求，在医疗记录研究中必须保护患者隐私，同时确保提供给研究人员的数据可信。

Method: 提出AegisBlock框架，采用患者中心化的访问控制机制，患者可以授权访问其医疗数据，研究人员提交时间范围查询请求，经患者批准后获得访问权限，数据验证由矿工完成。

Result: 实验评估显示AegisBlock在系统患者和医院数量方面具有良好的可扩展性，并且能够有效抵抗高达50%的恶意矿工攻击。

Conclusion: AegisBlock提供了一个可行的解决方案，能够在保护患者隐私的同时支持医疗研究数据的可信共享。

Abstract: Due to HIPAA and other privacy regulations, it is imperative to maintain
patient privacy while conducting research on patient health records. In this
paper, we propose AegisBlock, a patient-centric access controlled framework to
share medical records with researchers such that the anonymity of the patient
is maintained while ensuring the trustworthiness of the data provided to
researchers. AegisBlock allows for patients to provide access to their medical
data, verified by miners. A researcher submits a time-based range query to
request access to records from a certain patient, and upon patient approval,
access will be granted. Our experimental evaluation results show that
AegisBlock is scalable with respect to the number of patients and hospitals in
the system, and efficient with up to 50% of malicious miners.

</details>


### [6] [Securing Sideways: Thwarting Lateral Movement by Implementing Active Directory Tiering](https://arxiv.org/abs/2508.11812)
*Tyler Schroder,Sohee Kim Park*

Main category: cs.CR

TL;DR: 本文分析主动目录(AD)环境的安全挑战，提出通过层级化(tiering)策略防范凭据盗窃和限制攻击者横向移动，以减少赌金升级风险。


<details>
  <summary>Details</summary>
Motivation: 计算设备和网络服务的发展促使组织采用共享计算环境，而中央化身份系统成为网络攻击的主要目标。美国2024年网络犯罪损失达到166亿美元，强调了提升AD安全的紧迫性。

Method: 提出层级化(tiering)策略，通过限制被突破凭据的横向移动来防范权限升级和凭据盗窃。结合技术指南与理论论证，并使用实际场景案例进行说明。

Result: 层级化策略能够有效阻止横向移动和高级网络攻击，从而降低赌金升级的风险。该方法被证明是现代网络安全战略的关键组成部分。

Conclusion: 随着硬件和云服务的高速发展，安全专家与业务部门应联手开发能够自动、准确分类设备并将其整合到层级结构中的软件和框架。层级化虽不能独立运作，但是现代网络安全体系的重要组成部分。

Abstract: The advancement of computing equipment and the advances in services over the
Internet has allowed corporations, higher education, and many other
organizations to pursue the shared computing network environment. A requirement
for shared computing environments is a centralized identity system to
authenticate and authorize user access. An organization's digital identity
plane is a prime target for cyber threat actors. When compromised, identities
can be exploited to steal credentials, create unauthorized accounts, and
manipulate permissions-enabling attackers to gain control of the network and
undermine its confidentiality, availability, and integrity. Cybercrime losses
reached a record of 16.6 B in the United States in 2024. For organizations
using Microsoft software, Active Directory is the on-premises identity system
of choice. In this article, we examine the challenge of security compromises in
Active Directory (AD) environments and present effective strategies to prevent
credential theft and limit lateral movement by threat actors. Our proposed
approaches aim to confine the movement of compromised credentials, preventing
significant privilege escalation and theft. We argue that through our
illustration of real-world scenarios, tiering can halt lateral movement and
advanced cyber-attacks, thus reducing ransom escalation. Our work bridges a gap
in existing literature by combining technical guidelines with theoretical
arguments in support of tiering, positioning it as a vital component of modern
cybersecurity strategy even though it cannot function in isolation. As the
hardware advances and the cloud sourced services along with AI is advancing
with unprecedented speed, we think it is important for security experts and the
business to work together and start designing and developing software and
frameworks to classify devices automatically and accurately within the tiered
structure.

</details>


### [7] [Machine Learning-Based AES Key Recovery via Side-Channel Analysis on the ASCAD Dataset](https://arxiv.org/abs/2508.11817)
*Mukesh Poudel,Nick Rahimi*

Main category: cs.CR

TL;DR: \u673a\u5668\u5b66\u4e60\u6280\u672f\u7528\u4e8e\u5229\u7528AES\u5bc6\u7801\u5b9e\u73b0\u7684\u7535\u78c1\u6f0f\u6e0f\u8fdb\u884c\u90e8\u5206\u5bc6\u94a5\u6062\u590d\uff0cCNN\u548c\u7279\u5f81\u9009\u62e9\u7684\u968f\u673a\u68ee\u6797\u8868\u73b0\u6700\u4f73


<details>
  <summary>Details</summary>
Motivation: \u7406\u8bba\u4e0a\u5b89\u5168\u7684\u52a0\u5bc6\u7b97\u6cd5\u5728\u7269\u7406\u8bbe\u5907\u4e0a\u5b9e\u65bd\u65f6\u53ef\u80fd\u901a\u8fc7\u4fa6\u6d4b\u7535\u78c1\u6f0f\u6e0f\u88ab\u653b\u51fb\uff0c\u9700\u8981\u7814\u7a76\u673a\u5668\u5b66\u4e60\u5728\u5229\u7528\u8fd9\u79cd\u5076\u53d1\u6f0f\u6e0f\u8fdb\u884c\u5bc6\u94a5\u6062\u590d\u7684\u6548\u679c

Method: \u4f7f\u7528ASCAD\u6570\u636e\u96c6\uff0c\u5c06\u95ee\u9898\u6846\u67b6\u4e3a256\u7c7b\u5206\u7c7b\u4efb\u52a1\uff0c\u8bc4\u4f30\u968f\u673a\u68ee\u6797\u3001\u652f\u6301\u5411\u91cf\u673a\u3001\u5377\u79ef\u795e\u7ecf\u7f51\u7edc\u548c\u6b8a\u5dee\u795e\u7ecf\u7f51\u7edc\u7b49\u6a21\u578b\uff0c\u5e76\u4f7f\u7528\u7279\u5f81\u91cd\u8981\u6027\u5206\u6790\u8fdb\u884c\u7279\u5f81\u9009\u62e9

Result: \u968f\u673a\u68ee\u679\u6797\u5728\u7ecf\u7279\u5f81\u9009\u62e9\u540e\u4ec5\u9700\u4e00\u534a\u653b\u51fb\u8de8\u8ff9\u5373\u53ef\u5b8c\u6210\u5bc6\u94a5\u6062\u590d\uff0cCNN\u9700\u7ea665\u6761\u8de8\u8ff9\uff0cResNet\u5728\u590d\u6742\u6570\u636e\u96c6\u4e0a\u8868\u73b0\u6700\u4f73\u4f46\u5728\u7b80\u5355\u6570\u636e\u96c6\u4e0a\u6548\u7387\u4e0d\u5982CNN

Conclusion: \u673a\u5668\u5b66\u4e60\u6a21\u578b\u7279\u522b\u662fCNN\u3001ResNet\u548c\u7279\u5f81\u9009\u62e9\u7684\u968f\u673a\u68ee\u6797\uff0c\u7ed3\u5408Key Rank\u8bc4\u4f30\u6307\u6807\uff0c\u662f\u8fdb\u884c\u5076\u53d1\u6f0f\u6e0f\u5bc6\u94a5\u6062\u590d\u7684\u6709\u6548\u5de5\u5177\uff0c\u8bc1\u660e\u4e86\u52a0\u5bc6\u5b9e\u73b0\u7684\u5b9e\u9645\u5f31\u70b9

Abstract: Cryptographic algorithms like AES and RSA are widely used and they are
mathematically robust and almost unbreakable but its implementation on physical
devices often leak information through side channels, such as electromagnetic
(EM) emissions, potentially compromising said theoretically secure algorithms.
This paper investigates the application of machine learning (ML) techniques and
Deep Learning models to exploit such leakage for partial key recovery. We use
the public ASCAD `fixed' and `variable' key dataset, containing 700 and 1400 EM
traces respectively from an AES-128 implementation on an 8-bit microcontroller.
The problem is framed as a 256-class classification task where we target the
output of the first-round S-box operation, which is dependent on a single key
byte. We evaluate standard classifiers (Random Forest (RF), Support Vector
Machine (SVM)), a Convolutional Neural Network(CNN) and a Residual Neural
Network(ResNet). We also explore the utility of RF-based feature importance for
dimensionality reduction. Crucially, we employ this domain-specific Key Rank
metric for evaluation, showing its necessity over standard classification
accuracy. Our results show that SVM and RF on full features perform poorly in
key ranking. However, RF trained on reduced (top 100) identified via importance
analysis achieves Rank 0 (successful key byte recovery) using almost half the
attack traces. The implemented CNN also achieves Rank 0 efficiently using
approximately 65 attack traces for the fixed-key dataset. The ResNets perform
best on large and complex datasets but may not always be the best choice for
simple fixed key dataset in terms of efficiency. Thus we conclude that models,
particularly CNNs, ResNets and feature-selected RF, coupled with the Key Rank
metric, are an effective tool for side-channel key recovery, confirming the
practical vulnerability of the cryptographic implementations.

</details>


### [8] [Deciphering the Interplay between Attack and Protection Complexity in Privacy-Preserving Federated Learning](https://arxiv.org/abs/2508.11907)
*Xiaojin Zhang,Mingcong Xu,Yiming Li,Wei Chen,Qiang Yang*

Main category: cs.CR

TL;DR: 这篇论文提出了一个新的理论框架，用于分析聚合学习中攻击与保护的复杂性关系，通过定义攻击复杂性和保护复杂性来量化隐私保护的基本特性性。


<details>
  <summary>Details</summary>
Motivation: 聚合学习虽然能够在保持数据隐私的同时进行协作模型训练，但容易受到梯度逆反攻击，因此需要更加突出的隐私保护机制。

Method: 使用最大贝叶斯隐私（MBP）理论，形式定义了"攻击复杂性"和"保护复杂性"，并推导出了保护复杂性的严格理论界和攻击复杂性的全面界限。

Result: 研究发现保护复杂性随着模型维度和隐私预算的增长而扩展，而攻击复杂性则取决于隐私泄漏、梯度扭曲、模型维度和选择的隐私级别。

Conclusion: 该框架量化地揭示了隐私保证、系统效用以及攻击和防御所需努力之间的基本特性性，为设计更加安全高效的聚合学习系统提供了关键见解。

Abstract: Federated learning (FL) offers a promising paradigm for collaborative model
training while preserving data privacy. However, its susceptibility to gradient
inversion attacks poses a significant challenge, necessitating robust privacy
protection mechanisms. This paper introduces a novel theoretical framework to
decipher the intricate interplay between attack and protection complexities in
privacy-preserving FL. We formally define "Attack Complexity" as the minimum
computational and data resources an adversary requires to reconstruct private
data below a given error threshold, and "Protection Complexity" as the expected
distortion introduced by privacy mechanisms. Leveraging Maximum Bayesian
Privacy (MBP), we derive tight theoretical bounds for protection complexity,
demonstrating its scaling with model dimensionality and privacy budget.
Furthermore, we establish comprehensive bounds for attack complexity, revealing
its dependence on privacy leakage, gradient distortion, model dimension, and
the chosen privacy level. Our findings quantitatively illuminate the
fundamental trade-offs between privacy guarantees, system utility, and the
effort required for both attacking and defending. This framework provides
critical insights for designing more secure and efficient federated learning
systems.

</details>


### [9] [WebGeoInfer: A Structure-Free and Multi-Stage Framework for Geolocation Inference of Devices Exposing Information](https://arxiv.org/abs/2508.11913)
*Huipeng Yang,Li Yang,Lichuan Ma,Lu Zhou,Junbo Jia,Anyuan Sang,Xinyue Wang*

Main category: cs.CR

TL;DR: WebGeoInfer是一个无结构的地理位置推断框架，通过多阶段信息增强技术从远程管理设备的网页中自动提取地理位置信息，准确率在国家、城市和街道级别分别达到96.96%、88.05%和79.70%。


<details>
  <summary>Details</summary>
Motivation: 远程管理设备虽然便于基础设施监控，但暴露的地理信息带来了安全风险。由于网页信息格式不统一、样式多变且地理信息不完整，自动发现地理位置信息具有挑战性。

Method: 提出WebGeoInfer框架，通过聚类相似设备网页并分析集群间差异来提取潜在地理信息，利用搜索引擎增强和大型语言模型挖掘技术从识别信息中提取地理坐标。

Result: 成功推断出5,435个设备的位置，覆盖94个国家和2,056个城市，在国家、城市和街道级别的准确率分别为96.96%、88.05%和79.70%。

Conclusion: WebGeoInfer框架有效解决了从非结构化网页中提取地理位置信息的挑战，为网络安全监管提供了重要工具，能够识别因管理员疏忽而暴露位置信息的设备。

Abstract: Remote management devices facilitate critical infrastructure monitoring for
administrators but simultaneously increase asset exposure. Sensitive
geographical information overlooked in exposed device management pages poses
substantial security risks. Therefore, identifying devices that reveal location
information due to administrator negligence is crucial for cybersecurity
regulation. Despite the rich information exposed by web interfaces of remote
management devices, automatically discovering geographical locations remains
challenging due to unstructured formats, varying styles, and incomplete
geographical details.
  This study introduces WebGeoInfer, a structure-free geolocation inference
framework utilizing multi-stage information enhancement. WebGeoInfer clusters
similar device web pages and analyzes inter-cluster differences to extract
potential geographical information, bypassing structural limitations. Through
search engine enhancement and Large Language Models mining, the framework
extracts geographical coordinates from identified information. WebGeoInfer
successfully inferred locations for 5,435 devices across 94 countries and 2,056
cities, achieving accuracy rates of 96.96\%, 88.05\%, and 79.70\% at country,
city, and street levels, respectively.

</details>


### [10] [Optimizing Token Choice for Code Watermarking: A RL Approach](https://arxiv.org/abs/2508.11925)
*Zhimeng Guo,Huaisheng Zhu,Siyuan Xu,Hangfan Zhang,Teng Xiao,Minhao Cheng*

Main category: cs.CR

TL;DR: CodeTracer是一个基于强化学习的自适应代码水印框架，通过策略驱动的参数化模型在代码生成过程中嵌入水印，同时保持代码功能性和可检测性


<details>
  <summary>Details</summary>
Motivation: 检测LLM生成的代码需要能够在高度结构化、语法约束的环境中工作的水印系统

Method: 使用强化学习训练范式，采用策略驱动的方法通过参数化模型在下一个token预测时智能偏置token选择，设计综合奖励系统整合执行反馈和水印嵌入信号，使用Gumbel Top-k重参数化进行离散水印决策的梯度优化

Result: 广泛的比较评估显示CodeTracer在水印可检测性和生成代码功能保持方面显著优于最先进的基线方法

Conclusion: CodeTracer提供了一个有效的框架，能够在保持代码功能性的同时嵌入统计可检测的水印，为LLM生成代码的检测提供了可靠解决方案

Abstract: The need for detecting LLM-generated code necessitates watermarking systems
capable of operating within its highly structured and syntactically constrained
environment. To address this, we introduce CodeTracer, an innovative adaptive
code watermarking framework underpinned by a novel reinforcement learning
training paradigm. At its core, CodeTracer features a policy-driven approach
that utilizes a parameterized model to intelligently bias token choices during
next-token prediction. This strategy ensures that embedded watermarks maintain
code functionality while exhibiting subtle yet statistically detectable
deviations from typical token distributions. To facilitate policy learning, we
devise a comprehensive reward system that seamlessly integrates execution
feedback with watermark embedding signals, balancing process-level and
outcome-level rewards. Additionally, we employ Gumbel Top-k reparameterization
to enable gradient-based optimization of discrete watermarking decisions.
Extensive comparative evaluations demonstrate CodeTracer's significant
superiority over state-of-the-art baselines in both watermark detectability and
the preservation of generated code's functionality.

</details>


### [11] [The Passwordless Authentication with Passkey Technology from an Implementation Perspective](https://arxiv.org/abs/2508.11928)
*Lien Tran,Boyuan Zhang,Ratchanon Pawanja,Rashid Hussain Khokhar*

Main category: cs.CR

TL;DR: 本文分析了无密码认证技术，重点研究了Passkey技术的实现方案和安全优势，并与TOTP机制进行对比评估


<details>
  <summary>Details</summary>
Motivation: 应对日益复杂的认证绕过技术，密码不再是可靠的认证方式，需要研究更安全的无密码认证方案

Method: 通过实现角度分析TOTP和Passkey机制，研究关键技术和系统集成考虑因素

Result: 证明Passkey技术具有更优异的安全性，能有效应对密码泄漏、鱼叉攻击和暴力破解等安全风险

Conclusion: Passkey技术在实际应用中显示出良好的可行性和效果，有广阔的推广潜力，能在保持安全性、易用性和性能的同时提供更可靠的认证解决方案

Abstract: With the rise of sophisticated authentication bypass techniques, passwords
are no longer considered a reliable method for securing authentication systems.
In recent years, new authentication technologies have shifted from traditional
password-based logins to passwordless security. Among these, Time-Based
One-Time Passwords (TOTP) remain one of the most widely used mechanisms, while
Passkeys are emerging as a promising alternative with growing adoption. This
paper highlights the key techniques used during the implementation of the
authentication system with Passkey technology. It also suggests considerations
for integrating components during system development to ensure that users can
securely access their accounts with minimal complexity, while still meeting the
requirements of a robust authentication system that balances security,
usability, and performance. Additionally, by examining TOTP and Passkey
mechanisms from an implementation perspective, this work not only addresses
major security concerns such as password leaks, phishing attacks, and
susceptibility to brute-force attacks, but also evaluates the feasibility and
effectiveness of these mechanisms in real-world implementations. This paper
demonstrates the superior security of Passkey technology and its potential for
broader adoption in secure authentication systems.

</details>


### [12] [Design and Implementation of a Controlled Ransomware Framework for Educational Purposes Using Flutter Cryptographic APIs on Desktop PCs and Android Devices](https://arxiv.org/abs/2508.11939)
*James Gu,Ahmed Sartaj,Mohammed Akram Taher Khan,Rashid Hussain Khokhar*

Main category: cs.CR

TL;DR: 这是一个用于教育目的的劫持软件框架，使用Python和Flutter/Dart开发，通过控制环境模拟WannaCry劫持软件行为，包含多重安全保护机制以便安全学习和研究。


<details>
  <summary>Details</summary>
Motivation: 为了教育和培训下一代网络安全专业人员，需要一个安全的环境来系统性地研究劫持软件的功能特性，包括文件加密过程、密钥管理和受害者交互动态。

Method: 使用Python原生加密API和Flutter/Dart开发了两个版本的劫持软件框架，利用开源加密库，模拟WannaCry行为，并包含多重安全保护机制如限制加密目录、提供RSA私钥立即解密、限制可目标文件类型等。

Result: 开发出了一个开源的教育性劫持软件框架，支持Python和Android平台，使得研究人员可以在安全受控环境中学习、修改和扩展该程序。

Conclusion: 该框架为安全教育提供了一个实践工具，能够帮助培养网络安全人才，通过安全的方式深入理解劫持软件的工作机制和防范策略。

Abstract: This study focuses on the creation and implementation of ransomware for
educational purposes that leverages Python's native cryptographic APIs in a
controlled environment. Additionally, an Android version of the framework is
implemented using Flutter and Dart. For both versions, open-source
cryptographic libraries are utilized. With this framework, researchers can
systematically explore the functionalities of ransomware, including file
encryption processes, cryptographic key management, and victim interaction
dynamics. To ensure safe experimentation, multiple safeguards are incorporated,
such as the ability to restrict the encryption process to a specific directory,
providing the RSA private key for immediate decryption, and narrowing the scope
of targetable files to a carefully curated list (.txt, .jpg, .csv, .doc). This
paper draws inspiration from the infamous WannaCry ransomware and aims to
simulate its behaviour on Android devices. By making the codebase open-source,
it enables users to study, modify, and extend the program for pedagogical
purposes and offers a hands-on tool that can be used to train the next
generation of cybersecurity professionals.

</details>


### [13] [ToxiEval-ZKP: A Structure-Private Verification Framework for Molecular Toxicity Repair Tasks](https://arxiv.org/abs/2508.12035)
*Fei Lin,Tengchao Zhang,Ziyang Gong,Fei-Yue Wang*

Main category: cs.CR

TL;DR: 这篇论文提出了ToxiEval-ZKP框架，首次将零知识证明机制应用于分子毒性修复任务的验证过程，在保持分子结构隐私的前提下实现多维毒性修复标准的验证。


<details>
  <summary>Details</summary>
Motivation: 解决生成式AI在分子科学等高风险领域中输出的可验证性和结构隐私保护问题，特别是分子毒性修复任务中的隐私与验证相关挑战。

Method: 设计了一个通用电路，兼容分类和回归任务，包含评估逻辑、Poseidon基于的承诺哒函数和基于无效器的重放防止机制，构建了完整的终端到终端ZK验证系统。

Result: 实验结果表明ToxiEval-ZKP能够在完全结构不可见的条件下进行充分的验证，提供了强大的电路效率、安全性和适应性。

Conclusion: 该框架为生成式科学任务中的可信验证开启了一个新的范式，通过零知识证明机制实现了在保护分子结构隐私的同时进行多维毒性修复标准验证的能力。

Abstract: In recent years, generative artificial intelligence (GenAI) has demonstrated
remarkable capabilities in high-stakes domains such as molecular science.
However, challenges related to the verifiability and structural privacy of its
outputs remain largely unresolved. This paper focuses on the task of molecular
toxicity repair. It proposes a structure-private verification framework -
ToxiEval-ZKP - which, for the first time, introduces zero-knowledge proof (ZKP)
mechanisms into the evaluation process of this task. The system enables model
developers to demonstrate to external verifiers that the generated molecules
meet multidimensional toxicity repair criteria, without revealing the molecular
structures themselves. To this end, we design a general-purpose circuit
compatible with both classification and regression tasks, incorporating
evaluation logic, Poseidon-based commitment hashing, and a nullifier-based
replay prevention mechanism to build a complete end-to-end ZK verification
system. Experimental results demonstrate that ToxiEval-ZKP facilitates adequate
validation under complete structural invisibility, offering strong circuit
efficiency, security, and adaptability, thereby opening up a novel paradigm for
trustworthy evaluation in generative scientific tasks.

</details>


### [14] [Mitigating Jailbreaks with Intent-Aware LLMs](https://arxiv.org/abs/2508.12072)
*Wei Jie Yeo,Ranjan Satapathy,Erik Cambria*

Main category: cs.CR

TL;DR: Intent-FT是一种轻量级微调方法，通过训练LLM先推断指令的潜在意图再回应，显著提升模型对对抗性攻击的鲁棒性，同时保持通用能力。


<details>
  <summary>Details</summary>
Motivation: 尽管经过大量安全调优，大语言模型仍然容易受到对抗性指令的越狱攻击，这反映了安全性和任务性能之间的持续权衡。

Method: 提出Intent-FT方法，在对抗性指令集上进行针对性微调，使LLM能够学习推断指令的底层意图，并将这种意图推断能力泛化到未见过的攻击。

Result: Intent-FT持续缓解所有评估的攻击类别，没有单一攻击成功率超过50%，而现有防御方法仅部分有效。同时保持模型通用能力，减少对良性指令的过度拒绝。

Conclusion: 该方法能够准确识别对抗性攻击中的隐藏有害意图，并且学到的意图可以有效地迁移到增强普通模型的防御能力中。

Abstract: Despite extensive safety-tuning, large language models (LLMs) remain
vulnerable to jailbreak attacks via adversarially crafted instructions,
reflecting a persistent trade-off between safety and task performance. In this
work, we propose Intent-FT, a simple and lightweight fine-tuning approach that
explicitly trains LLMs to infer the underlying intent of an instruction before
responding. By fine-tuning on a targeted set of adversarial instructions,
Intent-FT enables LLMs to generalize intent deduction to unseen attacks,
thereby substantially improving their robustness. We comprehensively evaluate
both parametric and non-parametric attacks across open-source and proprietary
models, considering harmfulness from attacks, utility, over-refusal, and impact
against white-box threats. Empirically, Intent-FT consistently mitigates all
evaluated attack categories, with no single attack exceeding a 50\% success
rate -- whereas existing defenses remain only partially effective. Importantly,
our method preserves the model's general capabilities and reduces excessive
refusals on benign instructions containing superficially harmful keywords.
Furthermore, models trained with Intent-FT accurately identify hidden harmful
intent in adversarial attacks, and these learned intentions can be effectively
transferred to enhance vanilla model defenses.

</details>


### [15] [PP-STAT: An Efficient Privacy-Preserving Statistical Analysis Framework using Homomorphic Encryption](https://arxiv.org/abs/2508.12093)
*Hyunmin Choi*

Main category: cs.CR

TL;DR: PP-STAT是一个基于同态加密的高效隐私保护统计分析框架，支持多种统计指标的安全计算，通过优化技术显著降低计算开销。


<details>
  <summary>Details</summary>
Motivation: 随着云计算的普及，需要将统计分析外包给第三方平台，但处理医疗记录和财务信息等敏感数据在云环境中存在严重的隐私问题。

Method: 使用同态加密技术直接在加密数据上进行计算，引入切比雪夫近似策略初始化逆平方根操作，以及预归一化缩放技术减少乘法深度。

Result: 在真实数据集上评估显示，PP-STAT实现了高数值精度，平均相对误差低于2.4x10-4，加密的Pearson相关系数达到0.7873，MRE为2.86x10-4。

Conclusion: PP-STAT在隐私敏感领域实现了安全精确的统计分析，具有实际应用价值。

Abstract: With the widespread adoption of cloud computing, the need for outsourcing
statistical analysis to third-party platforms is growing rapidly. However,
handling sensitive data such as medical records and financial information in
cloud environments raises serious privacy concerns. In this paper, we present
PP-STAT, a novel and efficient Homomorphic Encryption (HE)-based framework for
privacy-preserving statistical analysis. HE enables computations to be
performed directly on encrypted data without revealing the underlying
plaintext. PP-STAT supports advanced statistical measures, including Z-score
normalization, skewness, kurtosis, coefficient of variation, and Pearson
correlation coefficient, all computed securely over encrypted data. To improve
efficiency, PP-STAT introduces two key optimizations: (1) a Chebyshev-based
approximation strategy for initializing inverse square root operations, and (2)
a pre-normalization scaling technique that reduces multiplicative depth by
folding constant scaling factors into mean and variance computations. These
techniques significantly lower computational overhead and minimize the number
of expensive bootstrapping procedures. Our evaluation on real-world datasets
demonstrates that PP-STAT achieves high numerical accuracy, with mean relative
error (MRE) below 2.4x10-4. Notably, the encrypted Pearson correlation between
the smoker attribute and charges reaches 0.7873, with an MRE of 2.86x10-4.
These results confirm the practical utility of PP-STAT for secure and precise
statistical analysis in privacy-sensitive domains.

</details>


### [16] [Ethereum Crypto Wallets under Address Poisoning: How Usable and Secure Are They?](https://arxiv.org/abs/2508.12107)
*Shixuan Guan,Kai Li*

Main category: cs.CR

TL;DR: 该研究通过模拟地址毒化攻击系统评估53款以太坊钱包的安全性，发现许多钱包存在交易历史显示问题和高风险，仅少数钱包能抓取毒化攻击。


<details>
  <summary>Details</summary>
Motivation: 地址毒化攻击已造成过百万美元损失，但以太坊钱包在防范这种攻击方面的效果仍不明确，需要系统性评估。

Method: 设计实验模拟地址毒化攻击，对53款流行的以太坊助记钱包进行使用性和安全性系统评估。

Result: 12款钱包无法下载用户交易历史，16款显示假代币毒化转账构成高风险，仅3款钱包在用户向毒化地址转账时发出明确警告。

Conclusion: 以太坊钱包开发社区需要加强安全防护措施，当前的防毒化能力存在显著缺口，研究已引起开发者关注并推动解决方案开发。

Abstract: Blockchain address poisoning is an emerging phishing attack that crafts
"similar-looking" transfer records in the victim's transaction history, which
aims to deceive victims and lure them into mistakenly transferring funds to the
attacker. Recent works have shown that millions of Ethereum users were targeted
and lost over 100 million US dollars.
  Ethereum crypto wallets, serving users in browsing transaction history and
initiating transactions to transfer funds, play a central role in deploying
countermeasures to mitigate the address poisoning attack. However, whether they
have done so remains an open question. To fill the research void, in this
paper, we design experiments to simulate address poisoning attacks and
systematically evaluate the usability and security of 53 popular Ethereum
crypto wallets. Our evaluation shows that there exist communication failures
between 12 wallets and their transaction activity provider, which renders them
unable to download the users' transaction history. Besides, our evaluation also
shows that 16 wallets pose a high risk to their users due to displaying fake
token phishing transfers. Moreover, our further analysis suggests that most
wallets rely on transaction activity providers to filter out phishing
transfers. However, their phishing detection capability varies. Finally, we
found that only three wallets throw an explicit warning message when users
attempt to transfer to the phishing address, implying a significant gap within
the broader Ethereum crypto wallet community in protecting users from address
poisoning attacks.
  Overall, our work shows that more efforts are needed by the Ethereum crypto
wallet developer community to achieve the highest usability and security
standard. Our bug reports have been acknowledged by the developer community,
who are currently developing mitigation solutions.

</details>


### [17] [Substituting Proof of Work in Blockchain with Training-Verified Collaborative Model Computation](https://arxiv.org/abs/2508.12138)
*Mohammad Ishzaz Asif Rafid,Morsalin Sakib*

Main category: cs.CR

TL;DR: 这篇论文提出了一种混合形式的机制，用中央化云计算协作训练模型替代传统的比特币工作量证明，以解决能源浪费问题。


<details>
  <summary>Details</summary>
Motivation: 传统比特币PoW机制存在过高的能源消耗和硬件效率低下的问题，需要找到更可持续的解决方案。

Method: 通过中央化服务器组织挖矿者贡献计算资源进行机器学习模型的协作训练，使用参数数量和模型损失减少作为评估指标，通过加权抽奖选出胜利者获得数字签名证书来替代PoW。

Result: 该方案将挖矿资源重定向生产性计算任务，在保持区块链完整性的同时解决了能源消耗问题。

Conclusion: 这种混合形式将安全激励与实际计算进展相结合，转化资源消耗为社会价值创造，为区块链可持续发展提供了新的解决方案。

Abstract: Bitcoin's Proof of Work (PoW) mechanism, while central to achieving
decentralized consensus, has long been criticized for excessive energy use and
hardware inefficiencies \cite{devries2018bitcoin, truby2018decarbonizing}. This
paper introduces a hybrid architecture that replaces Bitcoin's traditional PoW
with a centralized, cloud-based collaborative training framework. In this
model, miners contribute computing resources to train segments of horizontally
scaled machine learning models on preprocessed datasets, ensuring privacy and
generating meaningful outputs \cite{li2017securing}. A central server evaluates
contributions using two metrics: number of parameters trained and reduction in
model loss during each cycle. At the end of every cycle, a weighted lottery
selects the winning miner, who receives a digitally signed certificate. This
certificate serves as a verifiable substitute for PoW and grants the right to
append a block to the blockchain \cite{nakamoto2008bitcoin}. By integrating
digital signatures and SHA-256 hashing \cite{nist2015sha}, the system preserves
blockchain integrity while redirecting energy toward productive computation.
The proposed approach addresses the sustainability concerns of traditional
mining by converting resource expenditure into socially valuable work, aligning
security incentives with real-world computational progress.

</details>


### [18] [Attack Graph Generation on HPC Clusters](https://arxiv.org/abs/2508.12161)
*Ming Li,John Hale*

Main category: cs.CR

TL;DR: 本文提出使用高性能计算集群来生成攻击图，以解决传统方法中状态空间爆炸导致的时间和内存消耗问题。


<details>
  <summary>Details</summary>
Motivation: 攻击图是分析网络安全的重要工具，但随着网络资产、设备互连和漏洞数量的增加，攻击图的生成变得极其耗时和内存密集，存在状态空间爆炸问题。

Method: 采用高性能计算(HPC)集群来实现攻击图生成器，利用集群环境的并行计算能力来加速生成过程并降低内存需求。

Result: 通过实验评估证明了集群环境在解决攻击图生成速度慢和内存需求高的问题方面具有良好的平衡性能。

Conclusion: 高性能计算集群是解决攻击图生成中状态空间爆炸问题的有效方法，能够在速度和内存需求之间取得良好平衡。

Abstract: Attack graphs (AGs) are graphical tools to analyze the security of computer
networks. By connecting the exploitation of individual vulnerabilities, AGs
expose possible multi-step attacks against target networks, allowing system
administrators to take preventive measures to enhance their network's security.
As powerful analytical tools, however, AGs are both time- and memory-consuming
to be generated. As the numbers of network assets, interconnections between
devices, as well as vulnerabilities increase, the size and volume of the
resulting AGs grow at a much higher rate, leading to the well-known state-space
explosion. In this paper, we propose the use of high performance computing
(HPC) clusters to implement AG generators. We evaluate the performance through
experiments and provide insights into how cluster environments can help resolve
the issues of slow speed and high memory demands in AG generation in a balanced
way.

</details>


### [19] [Invitation Is All You Need! Promptware Attacks Against LLM-Powered Assistants in Production Are Practical and Dangerous](https://arxiv.org/abs/2508.12175)
*Ben Nassi,Stav Cohen,Or Yair*

Main category: cs.CR

TL;DR: 本文提出了一种新的威胁分析框架TARA来评估针对Gemini助手的Promptware攻击风险，发现了14种攻击场景，73%的威胁具有高关键风险，但通过缓解措施可将风险降至很低水平。


<details>
  <summary>Details</summary>
Motivation: 随着LLM应用的普及，Promptware（恶意设计的提示词）对应用程序CIA三要素构成新的安全威胁，但当前对其风险认知不足，需要系统评估。

Method: 提出新颖的威胁分析和风险评估(TARA)框架，针对Gemini助手的web应用、移动应用和Google助手，分析目标化Promptware攻击变种，通过间接提示注入方式（如邮件、日历邀请、共享文档）进行测试。

Result: 识别了5大类威胁（短期上下文污染、永久记忆污染、工具滥用、自动代理调用、自动应用调用），展示了14种攻击场景，73%的威胁具有高关键风险，可导致数字和物理后果。

Conclusion: Promptware风险被严重低估，但通过适当的缓解措施可以显著降低风险。研究结果已向Google披露并部署了专门缓解措施。

Abstract: The growing integration of LLMs into applications has introduced new security
risks, notably known as Promptware - maliciously engineered prompts designed to
manipulate LLMs to compromise the CIA triad of these applications. While prior
research warned about a potential shift in the threat landscape for LLM-powered
applications, the risk posed by Promptware is frequently perceived as low. In
this paper, we investigate the risk Promptware poses to users of Gemini-powered
assistants (web application, mobile application, and Google Assistant). We
propose a novel Threat Analysis and Risk Assessment (TARA) framework to assess
Promptware risks for end users. Our analysis focuses on a new variant of
Promptware called Targeted Promptware Attacks, which leverage indirect prompt
injection via common user interactions such as emails, calendar invitations,
and shared documents. We demonstrate 14 attack scenarios applied against
Gemini-powered assistants across five identified threat classes: Short-term
Context Poisoning, Permanent Memory Poisoning, Tool Misuse, Automatic Agent
Invocation, and Automatic App Invocation. These attacks highlight both digital
and physical consequences, including spamming, phishing, disinformation
campaigns, data exfiltration, unapproved user video streaming, and control of
home automation devices. We reveal Promptware's potential for on-device lateral
movement, escaping the boundaries of the LLM-powered application, to trigger
malicious actions using a device's applications. Our TARA reveals that 73% of
the analyzed threats pose High-Critical risk to end users. We discuss
mitigations and reassess the risk (in response to deployed mitigations) and
show that the risk could be reduced significantly to Very Low-Medium. We
disclosed our findings to Google, which deployed dedicated mitigations.

</details>


### [20] [CAN Networks Security in Smart Grids Communication Technologies](https://arxiv.org/abs/2508.12181)
*Ayman W. Baharia,Khaled T. Naga,Hesham S. Abdelfattah,Shady A. Maged,Sherif A. Hammad*

Main category: cs.CR

TL;DR: 基于单个专门节点的CAN网络安全方案，在不增加节点计算开销的前提下提高智能电网的网络安全性


<details>
  <summary>Details</summary>
Motivation: 智能电网通信中CAN协议虽然可靠但容易受到网络攻击，现有安全机制多带来计算开销和网络延迟

Method: 实现了一种只需要单个节点负责安全保护的方案，其他CAN节点几乎无需额外计算开销，使用Code Composer Studio软件和TM4C 1294微控制器评估板进行开发

Result: 该方案能够在几乎不增加CAN网络节点计算负担的前提下提高网络安全性，具体测试结果将在后续讨论中详细展示

Conclusion: 通过将安全保护职能集中在单个节点上，该方案有效解决了CAN网络在智能电网中遇到的安全性与性能开销的两难问题

Abstract: The rapid evolution of smart grids requires effective communication protocols
to transfer data reliably and securely. Controller Area Network (CAN) is one of
the most recognized protocols that offer reliable data transmission in smart
grids due to its robustness, real-time capabilities, and relatively low initial
cost of its required hardware. However, as a smart city becomes more
interconnected, it also becomes more vulnerable to cyber-attacks. As there are
many mechanisms to secure the CAN nodes from attacks, most of those mechanisms
have computational overhead, resulting in more delay in the network. We
implemented a solution that requires almost no overhead to any CAN node
connected to the network. It depends on a single node responsible for securing
the CAN network. This approach seeks to augment network security while reducing
security mechanisms overhead to all CAN network nodes. The methodology and
comprehensive test results will be presented in detail during a subsequent
discussion. The used software for development is Code Composer Studio, and the
used microcontroller evaluation boards (EVB) are TM4C 1294.

</details>


### [21] [AUTOVR: Automated UI Exploration for Detecting Sensitive Data Flow Exposures in Virtual Reality Apps](https://arxiv.org/abs/2508.12187)
*John Y. Kim,Chaoshun Zuo,Yanjie Zhao,Zhiqiang Lin*

Main category: cs.CR

TL;DR: AUTOVR是一个针对Unity引擎VR应用的自动化UI探索和用户事件测试框架，通过分析应用内部二进制文件来发现隐藏事件并解决生成事件依赖，在敏感数据暴露测试方面显著优于Android Monkey工具。


<details>
  <summary>Details</summary>
Motivation: 随着Meta Quest等VR平台的普及，VR应用数量快速增长，但缺乏强大的无头工具进行UI探索和用户事件测试，需要专门的自动化测试框架来保障VR应用的安全性。

Method: AUTOVR分析VR应用的内部二进制文件来揭示隐藏事件，解析生成事件依赖关系，并利用这些信息对VR应用进行全面探索，特别针对Unity引擎构建的应用。

Result: 与广泛使用的Android Monkey工具相比，AUTOVR在触发敏感数据暴露方面表现优异，能够触发数量级更多的敏感数据暴露事件，显著提升了VR应用的隐私保护能力。

Conclusion: AUTOVR框架有效解决了VR应用自动化测试的空白，在隐私安全测试方面展现出卓越性能，为VR应用的安全开发提供了重要工具支持。

Abstract: The rise of Virtual Reality (VR) has provided developers with an
unprecedented platform for creating games and applications (apps) that require
distinct inputs, different from those of conventional devices like smartphones.
The Meta Quest VR platform, driven by Meta, has democratized VR app publishing
and attracted millions of users worldwide. However, as the number of published
apps grows, there is a notable lack of robust headless tools for user interface
(UI) exploration and user event testing. To address this need, we present
AUTOVR, an automatic framework for dynamic UI and user event interaction in VR
apps built on the Unity Engine. Unlike conventional Android and GUI testers,
AUTOVR analyzes the app's internal binary to reveal hidden events, resolves
generative event dependencies, and utilizes them for comprehensive exploration
of VR apps. Using sensitive data exposure as a performance metric, we compare
AUTOVR with Android Monkey, a widely used headless Android GUI stress testing
tool. Our empirical evaluation demonstrates AUTOVR's superior performance,
triggering an order of magnitude of more sensitive data exposures and
significantly enhancing the privacy of VR apps.

</details>


### [22] [Fortifying the Agentic Web: A Unified Zero-Trust Architecture Against Logic-layer Threats](https://arxiv.org/abs/2508.12259)
*Ken Huang,Yasir Mehmood,Hammad Atta,Jerry Huang,Muhammad Zeeshan Baig,Sree Bhargavi Balija*

Main category: cs.CR

TL;DR: 基于零信任IAM的统一安全架构，通过DID、VC和代理名称服务构建强化的代理网络安全，提供可证明的LPCI攻击防御能力。


<details>
  <summary>Details</summary>
Motivation: 解决Agentic Web中的安全漏洞，特别是低代价连接供应渗透（LPCI）攻击的威胁，为代理生态系统提供一个完整的安全蓝图。

Method: 构建基于零信任IAM框架的统一安全架构，采用去中心化标识符（DID）和可验证凭证（VC）来创建丰富的代理身份，通过协议无关的代理名称服务（ANS）进行发现管理，并通过多层信任组织（Trust Fabric）实现安全运营。

Result: 形式分析证明，该架构能够提供可证明的安全保障，可以在有限成功概率下防御LPCI攻击。

Conclusion: 该研究提出了一个全面且具有前知性的安全蓝图，为建立安全、弹性和可信的代理生态系统提供了基础。

Abstract: This paper presents a Unified Security Architecture that fortifies the
Agentic Web through a Zero-Trust IAM framework. This architecture is built on a
foundation of rich, verifiable agent identities using Decentralized Identifiers
(DIDs) and Verifiable Credentials (VCs), with discovery managed by a
protocol-agnostic Agent Name Service (ANS). Security is operationalized through
a multi-layered Trust Fabric which introduces significant innovations,
including Trust-Adaptive Runtime Environments (TARE), Causal Chain Auditing,
and Dynamic Identity with Behavioral Attestation. By explicitly linking the
LPCI threat to these enhanced architectural countermeasures within a formal
security model, we propose a comprehensive and forward-looking blueprint for a
secure, resilient, and trustworthy agentic ecosystem. Our formal analysis
demonstrates that the proposed architecture provides provable security
guarantees against LPCI attacks with bounded probability of success.

</details>


### [23] [CryptPEFT: Efficient and Private Neural Network Inference via Parameter-Efficient Fine-Tuning](https://arxiv.org/abs/2508.12264)
*Saisai Xia,Wenhao Wang,Zihao Wang,Yuhui Zhang,Yier Jin,Dan Meng,Rui Hou*

Main category: cs.CR

TL;DR: CryptPEFT是一种专门为私有推理场景设计的参数高效微调解决方案，通过单向通信架构将加密计算限制在适配器中，显著降低了计算和通信开销，同时保持模型性能。


<details>
  <summary>Details</summary>
Motivation: 现有的大型预训练模型和轻量级适配器在参数高效微调中广泛应用，但在推理过程中保护用户输入和微调适配器的隐私仍然是一个重大挑战。现有的加密技术在多参数高效微调设置中仍然需要大量的加密计算。

Method: 提出CryptPEFT解决方案，采用单向通信架构将加密计算限制在适配器中，探索单向通信兼容适配器的设计空间，并使用自动化架构搜索算法来优化私有推理效率和模型效用之间的权衡。

Result: 在Vision Transformer骨干网络上评估，CryptPEFT显著优于现有基线，在广域网和局域网设置中实现了20.62倍到291.48倍的加速。在CIFAR-100上达到85.47%的准确率，推理延迟仅2.26秒。

Conclusion: CryptPEFT为基于参数高效微调的现代推理提供了一个高效且保护隐私的解决方案，在保持模型性能的同时大幅提升了私有推理的效率。

Abstract: Publicly available large pretrained models (i.e., backbones) and lightweight
adapters for parameter-efficient fine-tuning (PEFT) have become standard
components in modern machine learning pipelines. However, preserving the
privacy of both user inputs and fine-tuned adapters -- often trained on
sensitive data -- during inference remains a significant challenge. Applying
cryptographic techniques, such as multi-party computation (MPC), to PEFT
settings still incurs substantial encrypted computation across both the
backbone and adapter, mainly due to the inherent two-way communication between
them. To address this limitation, we propose CryptPEFT, the first PEFT solution
specifically designed for private inference scenarios. CryptPEFT introduces a
novel one-way communication (OWC) architecture that confines encrypted
computation solely to the adapter, significantly reducing both computational
and communication overhead. To maintain strong model utility under this
constraint, we explore the design space of OWC-compatible adapters and employ
an automated architecture search algorithm to optimize the trade-off between
private inference efficiency and model utility. We evaluated CryptPEFT using
Vision Transformer backbones across widely used image classification datasets.
Our results show that CryptPEFT significantly outperforms existing baselines,
delivering speedups ranging from $20.62\times$ to $291.48\times$ in simulated
wide-area network (WAN) and local-area network (LAN) settings. On CIFAR-100,
CryptPEFT attains 85.47% accuracy with just 2.26 seconds of inference latency.
These findings demonstrate that CryptPEFT offers an efficient and
privacy-preserving solution for modern PEFT-based inference.

</details>


### [24] [Adjustable AprilTags For Identity Secured Tasks](https://arxiv.org/abs/2508.12304)
*Hao Li*

Main category: cs.CR

TL;DR: 本文主张在开放公共环境中使用可调节的AprilTags替代固定标签，以应对对抗性攻击带来的身份安全风险。


<details>
  <summary>Details</summary>
Motivation: 在封闭私有环境中，AprilTags的身份安全不是问题，因为所有标签都可以完全管控。但在开放公共环境中，身份安全成为不可忽视的问题，需要处理对抗性攻击可能造成的潜在危害。

Method: 提倡使用可调节的AprilTags而非固定标签，但没有详细说明具体的技术实现方法。

Result: 提出了在开放环境中使用可调节AprilTags的概念性解决方案，但没有提供具体的实验结果或性能数据。

Conclusion: 在开放公共环境中，为了应对对抗性攻击带来的身份安全威胁，应该采用可调节的AprilTags来替代传统的固定标签设计。

Abstract: Special tags such as AprilTags that facilitate image processing and pattern
recognition are useful in practical applications. In close and private
environments, identity security is unlikely to be an issue because all involved
AprilTags can be completely regulated. However, in open and public
environments, identity security is no longer an issue that can be neglected. To
handle potential harm caused by adversarial attacks, this note advocates
utilization of adjustable AprilTags instead of fixed ones.

</details>


### [25] [Where to Start Alignment? Diffusion Large Language Model May Demand a Distinct Position](https://arxiv.org/abs/2508.12398)
*Zhixin Xie,Xurui Song,Jun Luo*

Main category: cs.CR

TL;DR: 本文首次分析了扩散大语言模型(dLLMs)的安全性表现，发现防御者和攻击者之间存在关键不对称性，并提出了一种针对中间令牌的安全对齐方法MOSA，在保持实用性的同时显著提升了安全性。


<details>
  <summary>Details</summary>
Motivation: 扩散大语言模型作为一种新兴的非自回归范式，目前缺乏对其安全性的系统研究。需要了解这种新型架构的安全性能并开发专门的安全对齐方法。

Method: 提出了Middle-tOken Safety Alignment (MOSA)方法，通过强化学习直接对齐模型的中间生成过程与安全拒绝响应，利用dLLMs中间令牌对整体安全性的关键影响这一发现。

Result: 在8种攻击方法和2个基准测试上，MOSA表现出优越的安全性能。同时在编程、数学和通用推理任务上保持了良好的实用性，证明了该方法的有效性。

Conclusion: MOSA方法成功利用了dLLMs防御-攻击不对称性，通过中间令牌对齐实现了安全性和实用性的平衡，为扩散大语言模型的安全对齐提供了有效解决方案。

Abstract: Diffusion Large Language Models (dLLMs) have recently emerged as a
competitive non-autoregressive paradigm due to their unique training and
inference approach. However, there is currently a lack of safety study on this
novel architecture. In this paper, we present the first analysis of dLLMs'
safety performance and propose a novel safety alignment method tailored to
their unique generation characteristics. Specifically, we identify a critical
asymmetry between the defender and attacker in terms of security. For the
defender, we reveal that the middle tokens of the response, rather than the
initial ones, are more critical to the overall safety of dLLM outputs; this
seems to suggest that aligning middle tokens can be more beneficial to the
defender. The attacker, on the contrary, may have limited power to manipulate
middle tokens, as we find dLLMs have a strong tendency towards a sequential
generation order in practice, forcing the attack to meet this distribution and
diverting it from influencing the critical middle tokens. Building on this
asymmetry, we introduce Middle-tOken Safety Alignment (MOSA), a novel method
that directly aligns the model's middle generation with safe refusals
exploiting reinforcement learning. We implement MOSA and compare its security
performance against eight attack methods on two benchmarks. We also test the
utility of MOSA-aligned dLLM on coding, math, and general reasoning. The
results strongly prove the superiority of MOSA.

</details>


### [26] [LumiMAS: A Comprehensive Framework for Real-Time Monitoring and Enhanced Observability in Multi-Agent Systems](https://arxiv.org/abs/2508.12412)
*Ron Solomon,Yarin Yerushalmi Levi,Lior Vaknin,Eran Aizikovich,Amit Baras,Etai Ohana,Amit Giloni,Shamik Bose,Chiara Picardi,Yuval Elovici,Asaf Shabtai*

Main category: cs.CR

TL;DR: LumiMAS是一个新颖的多智能体系统监控框架，通过三层架构（监控日志层、异常检测层、异常解释层）来实时检测和解释MAS中的系统故障，特别关注幻觉和偏见等新型故障。


<details>
  <summary>Details</summary>
Motivation: 现有MAS可观测性框架主要分析单个智能体，忽视了整个MAS系统的故障检测需求，特别是在大语言模型融入MAS后带来的新型挑战。

Method: 提出三层框架：1）监控日志层记录智能体活动；2）异常检测层实时检测工作流异常；3）异常解释层进行分类和根因分析。在7个不同MAS应用上评估，包括专门设计的幻觉和偏见故障场景。

Result: 评估结果表明LumiMAS在故障检测、分类和根因分析方面具有显著效果，能够有效处理包括幻觉和偏见在内的多种故障类型。

Conclusion: LumiMAS填补了MAS整体系统监控的空白，为复杂多智能体系统的故障检测和解释提供了有效的解决方案，特别适用于集成大语言模型的MAS环境。

Abstract: The incorporation of large language models in multi-agent systems (MASs) has
the potential to significantly improve our ability to autonomously solve
complex problems. However, such systems introduce unique challenges in
monitoring, interpreting, and detecting system failures. Most existing MAS
observability frameworks focus on analyzing each individual agent separately,
overlooking failures associated with the entire MAS. To bridge this gap, we
propose LumiMAS, a novel MAS observability framework that incorporates advanced
analytics and monitoring techniques. The proposed framework consists of three
key components: a monitoring and logging layer, anomaly detection layer, and
anomaly explanation layer. LumiMAS's first layer monitors MAS executions,
creating detailed logs of the agents' activity. These logs serve as input to
the anomaly detection layer, which detects anomalies across the MAS workflow in
real time. Then, the anomaly explanation layer performs classification and root
cause analysis (RCA) of the detected anomalies. LumiMAS was evaluated on seven
different MAS applications, implemented using two popular MAS platforms, and a
diverse set of possible failures. The applications include two novel
failure-tailored applications that illustrate the effects of a hallucination or
bias on the MAS. The evaluation results demonstrate LumiMAS's effectiveness in
failure detection, classification, and RCA.

</details>


### [27] [A Robust Cross-Domain IDS using BiGRU-LSTM-Attention for Medical and Industrial IoT Security](https://arxiv.org/abs/2508.12470)
*Afrah Gueriani,Hamza Kheddar,Ahmed Cherif Mazari,Mohamed Chahine Ghanem*

Main category: cs.CR

TL;DR: 这篇论文提出了一种新的变换器基于入侵检测系统BiGAT-ID，通过结合BiGRU、LSTM和多头注意力机制，在医疗IoT和工业IoT环境中实现了超过99%的检测准确率和极快的推理速度。


<details>
  <summary>Details</summary>
Motivation: 医疗IoT和工业IoT的互联网联通带来了复杂的网络安全挑战，需要有效防范敏感数据泄露、病人安全和工业运营风险。

Method: 设计了一种混合模型BiGAT-ID，结合了双向门控回连单元(BiGRU)、长短期记忆网络(LSTM)和多头注意力机制(MHA)，用于捕捉双向时间依赖性、建模序列模式和增强上下文特征表示。

Result: 在CICIoMT2024医疗IoT数据集上达到99.13%检测准确率，在EdgeIIoTset工业IoT数据集上达到99.34%检测准确率。推理速度极快（IoMT场景0.0002秒/实例，IIoT场景0.0001秒/实例），低假正率。

Conclusion: BiGAT-ID被证明是一种可靠、高效的入侵检测系统，适合在实际异构IoT环境中部署。

Abstract: The increased Internet of Medical Things IoMT and the Industrial Internet of
Things IIoT interconnectivity has introduced complex cybersecurity challenges,
exposing sensitive data, patient safety, and industrial operations to advanced
cyber threats. To mitigate these risks, this paper introduces a novel
transformer-based intrusion detection system IDS, termed BiGAT-ID a hybrid
model that combines bidirectional gated recurrent units BiGRU, long short-term
memory LSTM networks, and multi-head attention MHA. The proposed architecture
is designed to effectively capture bidirectional temporal dependencies, model
sequential patterns, and enhance contextual feature representation. Extensive
experiments on two benchmark datasets, CICIoMT2024 medical IoT and EdgeIIoTset
industrial IoT demonstrate the model's cross-domain robustness, achieving
detection accuracies of 99.13 percent and 99.34 percent, respectively.
Additionally, the model exhibits exceptional runtime efficiency, with inference
times as low as 0.0002 seconds per instance in IoMT and 0.0001 seconds in IIoT
scenarios. Coupled with a low false positive rate, BiGAT-ID proves to be a
reliable and efficient IDS for deployment in real-world heterogeneous IoT
environments

</details>


### [28] [ChamaleoNet: Programmable Passive Probe for Enhanced Visibility on Erroneous Traffic](https://arxiv.org/abs/2508.12496)
*Zhihao Wang,Alessandro Cornacchia,Andrea Bianco,Idilio Drago,Paolo Giaccone,Dingde Jiang,Marco Mellia*

Main category: cs.CR

TL;DR: ChamaleoNet是一个基于SDN的网络监控系统，能够透明地收集网络中未应答和错误的流量，用于检测错误配置、临时故障和攻击，同时通过硬件过滤减少96%的控制器流量。


<details>
  <summary>Details</summary>
Motivation: 网络可见性对于管理和安全运营至关重要，需要有效监控未请求和错误流量来检测错误配置、临时故障和攻击。

Method: 利用SDN范式，通过硬件过滤技术处理校园/企业网络流量，专注于收集错误数据包，降低收集系统压力并保护隐私。

Result: SDN硬件过滤将控制器流量减少96%，系统能够发现内部错误配置和受感染主机，识别临时故障，增强对外部攻击者扫描活动的可见性。

Conclusion: ChamaleoNet提供了一个可扩展的开源解决方案，能够无缝集成主动欺骗系统如蜜罐，有效提升网络监控和安全防护能力。

Abstract: Traffic visibility remains a key component for management and security
operations. Observing unsolicited and erroneous traffic, such as unanswered
traffic or errors, is fundamental to detect misconfiguration, temporary
failures or attacks. ChamaleoNet transforms any production network into a
transparent monitor to let administrators collect unsolicited and erroneous
traffic directed to hosts, whether offline or active, hosting a server or a
client, protected by a firewall, or unused addresses. ChamaleoNet is programmed
to ignore well-formed traffic and collect only erroneous packets, including
those generated by misconfigured or infected internal hosts, and those sent by
external actors which scan for services. Engineering such a system poses
several challenges, from scalability to privacy. Leveraging the SDN paradigm,
ChamaleoNet processes the traffic flowing through a campus/corporate network
and focuses on erroneous packets only, lowering the pressure on the collection
system while respecting privacy regulations by design. ChamaleoNet enables the
seamless integration with active deceptive systems like honeypots that can
impersonate unused hosts/ports/services and engage with senders. The SDN
in-hardware filtering reduces the traffic to the controller by 96%, resulting
in a scalable solution, which we offer as open source. Simple analytics unveil
internal misconfigured and infected hosts, identify temporary failures, and
enhance visibility on external radiation produced by attackers looking for
vulnerable services.

</details>


### [29] [Systematic Analysis of MCP Security](https://arxiv.org/abs/2508.12538)
*Yongjian Guo,Puzhuo Liu,Wanlun Ma,Zehang Deng,Xiaogang Zhu,Peng Di,Xi Xiao,Sheng Wen*

Main category: cs.CR

TL;DR: 这篇论文提出了MCP Attack Library (MCPLIB)，通过定量分析曝露了Model Context Protocol (MCP)的31种攻击方法咄害性，为MCP安全机制提供了基础框架。


<details>
  <summary>Details</summary>
Motivation: MCP协议虽然提供了互操作性，但引入了重大安全漏洞，而当前学术研究多为定性分析，缺乏对实际威胁的全面识别咄实验。

Method: 构建MCPLIB攻击库，将31种攻击方法分为四大类别：直接工具注入、间接工具注入、恶意用户攻击咄LLM内在攻击，并进行定量分析。

Result: 实验发现了关键漏洞：组件对工具描述的盲目信任、对文件攻击的敏感性、利用共享上下文的链式攻击、难以区分外部数据与可执行命令。

Conclusion: 该研究为MCP安全提供了基础框架，通过构建全面的攻击分类系统、统一攻击框架咄实验漏洞分析，支持MCP生态系统的安全迭代。

Abstract: The Model Context Protocol (MCP) has emerged as a universal standard that
enables AI agents to seamlessly connect with external tools, significantly
enhancing their functionality. However, while MCP brings notable benefits, it
also introduces significant vulnerabilities, such as Tool Poisoning Attacks
(TPA), where hidden malicious instructions exploit the sycophancy of large
language models (LLMs) to manipulate agent behavior. Despite these risks,
current academic research on MCP security remains limited, with most studies
focusing on narrow or qualitative analyses that fail to capture the diversity
of real-world threats. To address this gap, we present the MCP Attack Library
(MCPLIB), which categorizes and implements 31 distinct attack methods under
four key classifications: direct tool injection, indirect tool injection,
malicious user attacks, and LLM inherent attack. We further conduct a
quantitative analysis of the efficacy of each attack. Our experiments reveal
key insights into MCP vulnerabilities, including agents' blind reliance on tool
descriptions, sensitivity to file-based attacks, chain attacks exploiting
shared context, and difficulty distinguishing external data from executable
commands. These insights, validated through attack experiments, underscore the
urgency for robust defense strategies and informed MCP design. Our
contributions include 1) constructing a comprehensive MCP attack taxonomy, 2)
introducing a unified attack framework MCPLIB, and 3) conducting empirical
vulnerability analysis to enhance MCP security mechanisms. This work provides a
foundational framework, supporting the secure evolution of MCP ecosystems.

</details>


### [30] [The Hidden Cost of Correlation: Rethinking Privacy Leakage in Local Differential Privacy](https://arxiv.org/abs/2508.12539)
*Sandaru Jayawardana,Sennur Ulukus,Ming Ding,Kanchana Thilakarathna*

Main category: cs.CR

TL;DR: 本文系统分析了局部差分隐私(LDP)机制中属性相关性导致的隐私泄漏问题，通过理论分析和实验验证，提出了量化泄漏的算法框架和新的评测标准，以优化隐私与效用性的平衡。


<details>
  <summary>Details</summary>
Motivation: 当前对LDP机制中属性相关性导致的隐私泄漏(CPL)的研究存在偏差，假设和指标不准确，且仅限于纯LDP机制，需要系统性的理论分析和实践验证。

Method: 首先对五种常用LDP机制(GRR, RAPPOR, OUE, OLH, Exponential)在四个实际数据集上进行统计分析，识别偏差；提出首个量化任意(ε,δ)-LDP机制CPL的算法框架；通过实验验证理论结果；提出两个新的相关性分析算法验证标准。

Result: 发现当前方法的偏差和限制，建立了普遍适用的CPL量化理论，并通过实验验证了理论模型的准确性，为实际数据管理中的隐私效用性平衡提供了实践指南。

Conclusion: 研究系统性地解析了LDP中相关性泄漏问题，提出的理论框架和验证方法有助于更准确地评估和优化隐私保护方案，推动了分布式系统中隐私与数据效用性的平衡。

Abstract: Local differential privacy (LDP) has emerged as a promising paradigm for
privacy-preserving data collection in distributed systems, where users
contribute multi-dimensional records with potentially correlated attributes.
Recent work has highlighted that correlation-induced privacy leakage (CPL)
plays a critical role in shaping the privacy-utility trade-off under LDP,
especially when correlations exist among attributes. Nevertheless, it remains
unclear to what extent the prevailing assumptions and proposed solutions are
valid and how significant CPL is in real-world data. To address this gap, we
first perform a comprehensive statistical analysis of five widely used LDP
mechanisms -- GRR, RAPPOR, OUE, OLH and Exponential mechanism -- to assess CPL
across four real-world datasets. We identify that many primary assumptions and
metrics in current approaches fall short of accurately characterising these
leakages. Moreover, current studies have been limited to a set of pure LDP
(i.e., {\delta = 0}) mechanisms. In response, we develop the first algorithmic
framework to theoretically quantify CPL for any general approximated LDP
(({\varepsilon},{\delta})-LDP) mechanism. We validate our theoretical results
against empirical statistical results and provide a theoretical explanation for
the observed statistical patterns. Finally, we propose two novel benchmarks to
validate correlation analysis algorithms and evaluate the utility vs CPL of LDP
mechanisms. Further, we demonstrate how these findings can be applied to
achieve an efficient privacy-utility trade-off in real-world data governance.

</details>


### [31] [DEFENDCLI: {Command-Line} Driven Attack Provenance Examination](https://arxiv.org/abs/2508.12553)
*Peilun Wu,Nan Sun,Nour Moustafa,Youyang Qu,Ming Ding*

Main category: cs.CR

TL;DR: DEFENDCLI是一个创新的端点检测与响应系统，通过攻击溯源图和命令行级检测，解决了现有EDR系统在检测混淆、攻击关联、低频事件识别等方面的局限性，在DARPA数据集上比现有方法精度提升约1.6倍。


<details>
  <summary>Details</summary>
Motivation: 当前EDR解决方案在攻击溯源图方法上仍存在互操作性、可靠性、灵活性和实用性等问题，特别是在检测混淆技术、攻击关联、低频事件识别以及命令行活动的上下文感知方面存在明显不足。

Method: 提出DEFENDCLI系统，首次深入命令行级检测，通过三个层次评估差异：异常系统进程调用、可疑命令行执行和不常见外部网络连接，提供更精细的检测粒度。

Result: 在DARPA Engagement Series攻击数据集上，DEFENDCLI比最先进方法精度提升约1.6倍；实时工业测试显示能检测其他商业解决方案遗漏的未知攻击实例，比最先进研究工作精度提升2.3倍。

Conclusion: DEFENDCLI通过多层次的精细检测方法，显著提高了EDR系统在复杂动态环境中的可靠性，填补了现代EDR系统中被忽视的检测粒度空白。

Abstract: Endpoint Detection and Response (EDR) solutions embrace the method of attack
provenance graph to discover unknown threats through system event correlation.
However, this method still faces some unsolved problems in the fields of
interoperability, reliability, flexibility, and practicability to deliver
actionable results. Our research highlights the limitations of current
solutions in detecting obfuscation, correlating attacks, identifying
low-frequency events, and ensuring robust context awareness in relation to
command-line activities. To address these challenges, we introduce DEFENDCLI,
an innovative system leveraging provenance graphs that, for the first time,
delves into command-line-level detection. By offering finer detection
granularity, it addresses a gap in modern EDR systems that has been overlooked
in previous research. Our solution improves the precision of the information
representation by evaluating differentiation across three levels: unusual
system process calls, suspicious command-line executions, and infrequent
external network connections. This multi-level approach enables EDR systems to
be more reliable in complex and dynamic environments. Our evaluation
demonstrates that DEFENDCLI improves precision by approximately 1.6x compared
to the state-of-the-art methods on the DARPA Engagement Series attack datasets.
Extensive real-time industrial testing across various attack scenarios further
validates its practical effectiveness. The results indicate that DEFENDCLI not
only detects previously unknown attack instances, which are missed by other
modern commercial solutions, but also achieves a 2.3x improvement in precision
over the state-of-the-art research work.

</details>


### [32] [Data-driven Trust Bootstrapping for Mobile Edge Computing-based Industrial IoT Services](https://arxiv.org/abs/2508.12560)
*Prabath Abeysekara,Hai Dong*

Main category: cs.CR

TL;DR: 提出一种数据驱动的上下文感知方法，用于在移动边缘计算基础的工业物联网系统中快速建立同构物联网服务的可信过程


<details>
  <summary>Details</summary>
Motivation: 解决现有信任引导方法在MEC基础IIoT系统中的关键限制，包括缺乏长期交互机会、无法一致从同伴获得可靠推荐以及不同MEC环境中不均匀上下文参数对信任评估的影响

Method: 采用数据驱动和上下文感知方法，通过在给定MEC拓扑结构中不同MEC环境间的知识共享来解决数据稀疏问题

Result: 在两个经过适当调整的真实世界数据集上进行了全面评估，实验结果证实了该方法的有效性

Conclusion: 该方法适合用于在MEC基础IIoT系统中快速建立服务的可信过程，能够有效克服现有方法的限制

Abstract: We propose a data-driven and context-aware approach to bootstrap
trustworthiness of homogeneous Internet of Things (IoT) services in Mobile Edge
Computing (MEC) based industrial IoT (IIoT) systems. The proposed approach
addresses key limitations in adapting existing trust bootstrapping approaches
into MEC-based IIoT systems. These key limitations include, the lack of
opportunity for a service consumer to interact with a lesser-known service over
a prolonged period of time to get a robust measure of its trustworthiness,
inability of service consumers to consistently interact with their peers to
receive reliable recommendations of the trustworthiness of a lesser-known
service as well as the impact of uneven context parameters in different MEC
environments causing uneven trust environments for trust evaluation. In
addition, the proposed approach also tackles the problem of data sparsity via
enabling knowledge sharing among different MEC environments within a given MEC
topology. To verify the effectiveness of the proposed approach, we carried out
a comprehensive evaluation on two real-world datasets suitably adjusted to
exhibit the context-dependent trust information accumulated in MEC environments
within a given MEC topology. The experimental results affirmed the
effectiveness of our approach and its suitability to bootstrap trustworthiness
of services in MEC-based IIoT systems.

</details>


### [33] [Cyber Risks to Next-Gen Brain-Computer Interfaces: Analysis and Recommendations](https://arxiv.org/abs/2508.12571)
*Tyler Schroder,Renee Sirbu,Sohee Park,Jessica Morley,Sam Street,Luciano Floridi*

Main category: cs.CR

TL;DR: 分析脑机接口的网络安全风险并提出安全建议，包括设备更新方法、身份验证、数据加密和网络连接最小化


<details>
  <summary>Details</summary>
Motivation: 脑机接口在个性化医疗中潜力巨大，但也带来了新的网络安全攻击途径，需要保护患者安全和数据机密性

Method: 分析问题并提出建议，设计假设性的平均案例威胁模型来识别可能的网络安全威胁并预测风险可能性

Result: 脑机接口物理攻击风险较低但远程攻击脆弱，提出了限制网络连接的技术控制措施

Conclusion: 设备制造商应实施建议的安全措施，监管机构应强制要求非手术设备更新方法、强身份验证、数据加密和最小化网络连接

Abstract: Brain-computer interfaces (BCIs) show enormous potential for advancing
personalized medicine. However, BCIs also introduce new avenues for
cyber-attacks or security compromises. In this article, we analyze the problem
and make recommendations for device manufacturers to better secure devices and
to help regulators understand where more guidance is needed to protect patient
safety and data confidentiality. Device manufacturers should implement the
prior suggestions in their BCI products. These recommendations help protect BCI
users from undue risks, including compromised personal health and genetic
information, unintended BCI-mediated movement, and many other cybersecurity
breaches. Regulators should mandate non-surgical device update methods, strong
authentication and authorization schemes for BCI software modifications,
encryption of data moving to and from the brain, and minimize network
connectivity where possible. We also design a hypothetical, average-case threat
model that identifies possible cybersecurity threats to BCI patients and
predicts the likeliness of risk for each category of threat. BCIs are at less
risk of physical compromise or attack, but are vulnerable to remote attack; we
focus on possible threats via network paths to BCIs and suggest technical
controls to limit network connections.

</details>


### [34] [Reducing False Positives with Active Behavioral Analysis for Cloud Security](https://arxiv.org/abs/2508.12584)
*Dikshant,Verma*

Main category: cs.CR

TL;DR: 通过主动行为测试验证云安全策略违规的可利用性，平均减少93%假正率，提高检测准确性和分析师效率


<details>
  <summary>Details</summary>
Motivation: 解决基于规则的云安全策略管理(CSPM)方案产生大量假正警报的问题，这些假正警报消耗分析师时间且很多是非可操作的

Method: 提出验证驱动的方法论，集成主动行为测试，使用轻量自动化探针(基于开源工具、验证脚本和洗洗测试案例)模拟对错误配置或存在漏洞的云资产的攻击

Result: 在AWS环境中进行受控实验，平均减少93%的假正率，框架展现低延迟性能，且支持多云环境扩展

Conclusion: 该方法为大型云环境提供了可扩展的方法来提高检测准确性和分析师生产力，有效解决了传统CSPM方案中假正警报过多的问题

Abstract: Rule-based cloud security posture management (CSPM) solutions are known to
produce a lot of false positives based on the limited contextual understanding
and dependence on static heuristics testing. This paper introduces a
validation-driven methodology that integrates active behavioral testing in
cloud security posture management solution(s) to evaluate the exploitability of
policy violations in real time. The proposed system employs lightweight and
automated probes, built from open-source tools, validation scripts, and
penetration testing test cases, to simulate adversarial attacks on
misconfigured or vulnerable cloud assets without any impact to the cloud
services or environment. For instance, cloud services may be flagged as
publicly exposed and vulnerable despite being protected by access control
layers, or secure policies, resulting in non-actionable alerts that consumes
analysts time during manual validation. Through controlled experimentation in a
reproducible AWS setup, we evaluated the reduction in false positive rates
across various misconfiguration and vulnerable alerts. Our findings indicate an
average reduction of 93\% in false positives. Furthermore, the framework
demonstrates low latency performance. These results demonstrate a scalable
method to improve detection accuracy and analyst productivity in large cloud
environments. While our evaluation focuses on AWS, the architecture is modular
and extensible to multi-cloud setups.

</details>


### [35] [UAV Individual Identification via Distilled RF Fingerprints-Based LLM in ISAC Networks](https://arxiv.org/abs/2508.12597)
*Haolin Zheng,Ning Gao,Donghong Cai,Shi Jin,Michail Matthaiou*

Main category: cs.CR

TL;DR: 基于GPT-2改进的RFF-LLM框架通过动态知识萌蓬技术实现高精度无人机识别，在复杂外部环境下达到98.38%的识别准确率，仅需0.15M参数和2.74ms响应时间


<details>
  <summary>Details</summary>
Motivation: 无人机在低空域ISAC网络中的识别问题对安全监控至关重要，需要在复杂外部环境下提高识别准确性同时控制模型复杂度

Method: 首先基于GPT-2改进构建RFF-LLM框架，然后采用动态知识萌蓬策略（使用PPO算法动态调整萌蓬温度）压缩模型，最后将知识转移到轻量级Lite-HRNet模型

Result: 在自建DRFF-R1数据集上（收20款商业无人机的I/Q信号），框架达到98.38%的ID识别准确率，参数仅需0.15百万，响应时间2.74ms，性能超过对照方案

Conclusion: 该动态KD启用的RFF-LLM框架能够在保持高准确性的同时有效压缩模型，为无人机安全监控提供了高效的解决方案

Abstract: Unmanned aerial vehicle (UAV) individual (ID) identification is a critical
security surveillance strategy in low-altitude integrated sensing and
communication (ISAC) networks. In this paper, we propose a novel dynamic
knowledge distillation (KD)-enabled wireless radio frequency fingerprint large
language model (RFF-LLM) framework for UAV ID identification. First, we propose
an RFF-LLM framework based on the modified GPT-2 model to improve the
identification accuracy in complex outdoor environments. Then, considering the
parameter overhead of the RFF-LLM, we design a dynamic KD strategy to compress
the model. Specifically, the proximal policy optimization (PPO) algorithm is
employed to dynamically adjust the distillation temperature, overcoming the
local optimum dilemma inherent in static KD. As a next step, the knowledge of
the RFF-LLM is adequately transferred to the lightweight Lite-HRNet model.
Finally, our experiments are conducted based on the self-built drone RFF
dataset of Release one, namely DRFF-R1, by collecting the I/Q signals of 20
commercial UAVs in channel 149. The experiment results show that the proposed
framework achieves 98.38\% ID identification accuracy with merely 0.15 million
parameters and 2.74 ms response time, which outperforms the benchmarks.

</details>


### [36] [Consiglieres in the Shadow: Understanding the Use of Uncensored Large Language Models in Cybercrimes](https://arxiv.org/abs/2508.12622)
*Zilong Lin,Zichuan Li,Xiaojing Liao,XiaoFeng Wang*

Main category: cs.CR

TL;DR: 系统性研究发现了超过11,000个未审查大语言模型(ULLMs)，这些模型被广泛用于生成恶意内容并集成到恶意应用中，下载量达千万次，构成严重安全风险。


<details>
  <summary>Details</summary>
Motivation: 随着AI技术发展，网络犯罪分子越来越多地利用未审查大语言模型(ULLMs)提供恶意服务，但由于开源模型数量巨大，识别这些恶意模型面临极大挑战。

Method: 通过建模开源LLMs之间以及它们与相关数据(如微调、合并、压缩模型和有害数据集)的关系，构建知识图并采用图神经网络进行深度学习分析。

Result: 从小量标签示例和未审查数据集中识别出超过11,000个ULLMs，其中一些模型下载量超过1900万次，能生成偷恶、暴力、色情内容和恶意代码，并被集成到数百个恶意应用中。

Conclusion: 这些发现呈现了LLM技术被法律法规之外的广泛滥用，形成了严重的安全威胁，突出了开发有效防范措施的紧迫急急性。

Abstract: The advancement of AI technologies, particularly Large Language Models
(LLMs), has transformed computing while introducing new security and privacy
risks. Prior research shows that cybercriminals are increasingly leveraging
uncensored LLMs (ULLMs) as backends for malicious services. Understanding these
ULLMs has been hindered by the challenge of identifying them among the vast
number of open-source LLMs hosted on platforms like Hugging Face. In this
paper, we present the first systematic study of ULLMs, overcoming this
challenge by modeling relationships among open-source LLMs and between them and
related data, such as fine-tuning, merging, compressing models, and using or
generating datasets with harmful content. Representing these connections as a
knowledge graph, we applied graph-based deep learning to discover over 11,000
ULLMs from a small set of labeled examples and uncensored datasets.
  A closer analysis of these ULLMs reveals their alarming scale and usage. Some
have been downloaded over a million times, with one over 19 million installs.
These models -- created through fine-tuning, merging, or compression of other
models -- are capable of generating harmful content, including hate speech,
violence, erotic material, and malicious code. Evidence shows their integration
into hundreds of malicious applications offering services like erotic
role-play, child pornography, malicious code generation, and more. In addition,
underground forums reveal criminals sharing techniques and scripts to build
cheap alternatives to commercial malicious LLMs. These findings highlight the
widespread abuse of LLM technology and the urgent need for effective
countermeasures against this growing threat.

</details>


### [37] [MPOCryptoML: Multi-Pattern based Off-Chain Crypto Money Laundering Detection](https://arxiv.org/abs/2508.12641)
*Yasaman Samadi,Hai Dong,Xiaoyu Xia*

Main category: cs.CR

TL;DR: MPOCryptoML模型通过多源个性化PageRank算法和时间戳/交易权重分析，有效检测加密货币洗钱的多种模式，在多个公开数据集上显著提升了检测性能。


<details>
  <summary>Details</summary>
Motivation: 现有模型未能专门针对加密货币链下洗钱的多样化模式进行检测，忽视任何洗钱模式都会导致检测漏洞，可能让洗钱活动绕过检测系统。

Method: 开发多源个性化PageRank算法检测随机洗钱模式；引入两种新算法分析时间戳和交易权重来检测多种洗钱结构（fan-in、fan-out、二分图、聚集-分散、堆栈模式）；使用逻辑回归模型分析模式间相关性；通过异常评分函数整合各模块结果对账户进行风险排序。

Result: 在Elliptic++、Ethereum欺诈检测和Wormhole交易数据集上的实验显示，模型在精确率上提升高达9.13%，召回率提升10.16%，F1分数提升7.63%，准确率提升10.19%。

Conclusion: MPOCryptoML模型能够系统性地识别高风险账户，有效填补了加密货币洗钱多样化模式检测的空白，显著提升了检测效果和效率。

Abstract: Recent advancements in money laundering detection have demonstrated the
potential of using graph neural networks to capture laundering patterns
accurately. However, existing models are not explicitly designed to detect the
diverse patterns of off-chain cryptocurrency money laundering. Neglecting any
laundering pattern introduces critical detection gaps, as each pattern reflects
unique transactional structures that facilitate the obfuscation of illicit fund
origins and movements. Failure to account for these patterns may result in
under-detection or omission of specific laundering activities, diminishing
model accuracy and allowing schemes to bypass detection. To address this gap,
we propose the MPOCryptoML model to effectively detect multiple laundering
patterns in cryptocurrency transactions. MPOCryptoML includes the development
of a multi-source Personalized PageRank algorithm to identify random laundering
patterns. Additionally, we introduce two novel algorithms by analyzing the
timestamp and weight of transactions in high-volume financial networks to
detect various money laundering structures, including fan-in, fan-out,
bipartite, gather-scatter, and stack patterns. We further examine correlations
between these patterns using a logistic regression model. An anomaly score
function integrates results from each module to rank accounts by anomaly score,
systematically identifying high-risk accounts. Extensive experiments on public
datasets including Elliptic++, Ethereum fraud detection, and Wormhole
transaction datasets validate the efficacy and efficiency of MPOCryptoML.
Results show consistent performance gains, with improvements up to 9.13% in
precision, up to 10.16% in recall, up to 7.63% in F1-score, and up to 10.19% in
accuracy.

</details>


### [38] [Unlearning Comparator: A Visual Analytics System for Comparative Evaluation of Machine Unlearning Methods](https://arxiv.org/abs/2508.12730)
*Jaeung Lee,Suhyeon Yu,Yurim Jang,Simon S. Woo,Jaemin Jo*

Main category: cs.CR

TL;DR: 这篇论文提出了一个可视化分析系统Unlearning Comparator，用于系统性评估机器忘印方法，解决当前评估方法依赖聚合指标和随机评估的问题。


<details>
  <summary>Details</summary>
Motivation: 机器忘印领域的研究人员在分析和理解不同MU方法时遇到困难，特别是在准确性、效率和隐私性这三个基本原则方面，导致依赖聚合指标和随机评估。

Method: 设计了可视化分析系统Unlearning Comparator，支持两个核心任务：模型比较（在类、实例和层级判断模型行为变化）和攻击模拟（通过成员推断攻击评估隐私性）。

Result: 通过对突出MU方法的案例研究评估，证明该系统不仅能帮助用户理解模型行为，还能获得改进MU方法的洞察。

Conclusion: Unlearning Comparator系统有效填补了机器忘印方法评估的空白，通过系统性的可视化分析工具，提升了对不同忘印方法在准确性、效率和隐私性方面特性的理解和评估能力。

Abstract: Machine Unlearning (MU) aims to remove target training data from a trained
model so that the removed data no longer influences the model's behavior,
fulfilling "right to be forgotten" obligations under data privacy laws. Yet, we
observe that researchers in this rapidly emerging field face challenges in
analyzing and understanding the behavior of different MU methods, especially in
terms of three fundamental principles in MU: accuracy, efficiency, and privacy.
Consequently, they often rely on aggregate metrics and ad-hoc evaluations,
making it difficult to accurately assess the trade-offs between methods. To
fill this gap, we introduce a visual analytics system, Unlearning Comparator,
designed to facilitate the systematic evaluation of MU methods. Our system
supports two important tasks in the evaluation process: model comparison and
attack simulation. First, it allows the user to compare the behaviors of two
models, such as a model generated by a certain method and a retrained baseline,
at class-, instance-, and layer-levels to better understand the changes made
after unlearning. Second, our system simulates membership inference attacks
(MIAs) to evaluate the privacy of a method, where an attacker attempts to
determine whether specific data samples were part of the original training set.
We evaluate our system through a case study visually analyzing prominent MU
methods and demonstrate that it helps the user not only understand model
behaviors but also gain insights that can inform the improvement of MU methods.

</details>


### [39] [Efficient and Verifiable Privacy-Preserving Convolutional Computation for CNN Inference with Untrusted Clouds](https://arxiv.org/abs/2508.12832)
*Jinyu Lu,Xinrong Sun,Yunting Tao,Tong Ji,Fanyu Kong,Guoqiang Yang*

Main category: cs.CR

TL;DR: 一种高效的可验证卷积神经网隐私保护方案，在保持准确性的同时实现26-87倍速度提升


<details>
  <summary>Details</summary>
Motivation: 解决机器学习印射服务(MLaaS)中数据隐私泄漏问题，现有隐私保护方案在卷积运算中效率低下

Method: 针对CNN卷积层设计的新题隐私保护方案，包括高效的加密解密机制和可验证机制

Result: 在10个数据集和多种CNN模型上进行实验，实现26-87倍速度提升，验证成功概率至少1-1/|Z|

Conclusion: 该方案为资源受限客户端提供了高效、可验证的CNN隐私保护计算方案，有效解决了现有方案的效率瓶颈

Abstract: The widespread adoption of convolutional neural networks (CNNs) in
resource-constrained scenarios has driven the development of Machine Learning
as a Service (MLaaS) system. However, this approach is susceptible to privacy
leakage, as the data sent from the client to the untrusted cloud server often
contains sensitive information. Existing CNN privacy-preserving schemes, while
effective in ensuring data confidentiality through homomorphic encryption and
secret sharing, face efficiency bottlenecks, particularly in convolution
operations. In this paper, we propose a novel verifiable privacy-preserving
scheme tailored for CNN convolutional layers. Our scheme enables efficient
encryption and decryption, allowing resource-constrained clients to securely
offload computations to the untrusted cloud server. Additionally, we present a
verification mechanism capable of detecting the correctness of the results with
a success probability of at least $1-\frac{1}{\left|Z\right|}$. Extensive
experiments conducted on 10 datasets and various CNN models demonstrate that
our scheme achieves speedups ranging $26 \times$ ~ $\ 87\times$ compared to the
original plaintext model while maintaining accuracy.

</details>


### [40] [The covering radius of Butson Hadamard codes for the homogeneous metric](https://arxiv.org/abs/2508.12859)
*Xingxing Xu,Minjia Shi,Patrick Sole*

Main category: cs.CR

TL;DR: 本文研究Butson Hadamard码在齐次度量下的覆盖半径，通过正交阵列论证得到上界，利用弯曲序列存在性得到下界，推广了Hamming度量的结果。


<details>
  <summary>Details</summary>
Motivation: Butson矩阵是复Hadamard矩阵，其元素为给定阶的复单位根。这类矩阵在相空间中有相关编码应用，研究其覆盖半径对于理解编码性能具有重要意义。

Method: 使用正交阵列论证推导覆盖半径的上界，利用弯曲序列的存在性建立下界。下界方法推广了Armario等人针对Hamming度量的已有结果。

Result: 获得了Butson Hadamard码在齐次度量下的覆盖半径的上界和下界估计。下界结果是对Armario等人工作的推广和扩展。

Conclusion: 本文成功建立了Butson Hadamard码在齐次度量下的覆盖半径界限，为这类特殊编码结构的性能分析提供了理论工具，扩展了现有关于Hamming度量的研究成果。

Abstract: Butson matrices are complex Hadamard matrices with entries in the complex
roots of unity of given order. There is an interesting code in phase space
related to this matrix (Armario et al. 2023). We study the covering radius of
Butson Hadamard codes for the homogeneous metric, a metric defined uniquely, up
to scaling, for a commutative ring alphabet that is Quasi Frobenius. An upper
bound is derived by an orthogonal array argument. A lower bound relies on the
existence of bent sequences in the sense of (Shi et al. 2022). This latter
bound generalizes a bound of (Armario et al. 2025) for the Hamming metric.

</details>


### [41] [Supporting Socially Constrained Private Communications with SecureWhispers](https://arxiv.org/abs/2508.12870)
*Vinod Khandkar,Kieron Ivy Turk,Ehsan Toreini,Nishanth Sastry*

Main category: cs.CR

TL;DR: 本文提出了一种通过摇晃手机来建立共享密钥的方法，无需网络传输即可实现设备间的私密通信，适用于敏感话题的安全交流。


<details>
  <summary>Details</summary>
Motivation: 社会规范和法律限制使人们难以讨论敏感话题，现有通信服务依赖第三方基础设施，存在安全隐患和可访问性问题，需要不依赖网络的严格私密通信方案。

Method: 开发了一种通过摇晃手机提取共享随机性来生成共享密钥的方法，每个设备从摇晃中提取随机性并处理为7.798比特/字节的密钥材料。

Result: 实现了基于Android的独立消息混淆应用，可用于与可信联系人的私密通信，并提出了三种应用：消息混淆、信任委托和加密信标。

Conclusion: 摇晃手机生成共享密钥的方法为设备间私密通信提供了可行的解决方案，无需依赖网络或第三方基础设施，具有实际应用价值和进一步集成到主流服务的潜力。

Abstract: Rapidly changing social norms and national, legal, and political conditions
socially constrain people from discussing sensitive topics such as sexuality or
religion. Such constrained, vulnerable minorities are often worried about
inadvertent information disclosure and may be unsure about the extent to which
their communications are being monitored in public or semi-public spaces like
workplaces or cafes. Personal devices extend trust to the digital domain,
making it desirable to have strictly private communication between trusted
devices. Currently, messaging services like WhatsApp provide alternative means
for exchanging sensitive private information, while personal safety apps such
as Noonlight enable private signaling. However, these rely on third-party
mechanisms for secure and private communication, which may not be accessible
for justifiable reasons, such as insecure internet access or companion device
connections. In these cases, it is challenging to achieve communication that is
strictly private between two devices instead of user accounts without any
dependency on third-party infrastructure. The goal of this paper is to support
private communications by setting up a shared secret between two or more
devices without sending any data on the network. We develop a method to create
a shared secret between phones by shaking them together. Each device extracts
the shared randomness from the shake, then conditions the randomness to 7.798
bits per byte of key material. This paper proposes three different applications
of this generated shared secret: message obfuscation, trust delegation, and
encrypted beacons. We have implemented the message obfuscation on Android as an
independent app that can be used for private communication with trusted
contacts. We also present research on the usability, design considerations, and
further integration of these tools in mainstream services.

</details>


### [42] [SecFSM: Knowledge Graph-Guided Verilog Code Generation for Secure Finite State Machines in Systems-on-Chip](https://arxiv.org/abs/2508.12910)
*Ziteng Hu,Yingjie Xia,Xiyuan Chen,Li Kuang*

Main category: cs.CR

TL;DR: SecFSM是一种利用安全知识图谱指导LLM生成更安全Verilog代码的方法，专门针对FSM实现中的安全漏洞问题。


<details>
  <summary>Details</summary>
Motivation: 传统硬件工程师手动编写Verilog代码实现FSM既繁琐又耗时，而LLM生成的代码往往存在安全漏洞，这对安全敏感的FSM实现尤其令人担忧。

Method: 首先构建FSM安全知识图谱(FSKG)作为LLM的外部辅助，分析用户需求识别漏洞，基于漏洞列表从FSKG检索知识，然后构建安全提示用于Verilog代码生成。

Result: 在25个安全测试用例的基准测试中，SecFSM达到了21/25的优秀通过率，优于现有最先进的基线方法。

Conclusion: SecFSM通过结合安全知识图谱和LLM，有效提高了Verilog代码生成的安全性，为自动化硬件设计提供了更可靠的解决方案。

Abstract: Finite State Machines (FSMs) play a critical role in implementing control
logic for Systems-on-Chip (SoC). Traditionally, FSMs are implemented by
hardware engineers through Verilog coding, which is often tedious and
time-consuming. Recently, with the remarkable progress of Large Language Models
(LLMs) in code generation, LLMs have been increasingly explored for automating
Verilog code generation. However, LLM-generated Verilog code often suffers from
security vulnerabilities, which is particularly concerning for
security-sensitive FSM implementations. To address this issue, we propose
SecFSM, a novel method that leverages a security-oriented knowledge graph to
guide LLMs in generating more secure Verilog code. Specifically, we first
construct a FSM Security Knowledge Graph (FSKG) as an external aid to LLMs.
Subsequently, we analyze users' requirements to identify vulnerabilities and
get a list of vulnerabilities in the requirements. Then, we retrieve knowledge
from FSKG based on the vulnerabilities list. Finally, we construct security
prompts based on the security knowledge for Verilog code generation. To
evaluate SecFSM, we build a dedicated dataset collected from academic datasets,
artificial datasets, papers, and industrial cases. Extensive experiments
demonstrate that SecFSM outperforms state-of-the-art baselines. In particular,
on a benchmark of 25 security test cases evaluated by DeepSeek-R1, SecFSM
achieves an outstanding pass rate of 21/25.

</details>


### [43] [Prescriptive Zero Trust- Assessing the impact of zero trust on cyber attack prevention](https://arxiv.org/abs/2508.12953)
*Samuel Aiello*

Main category: cs.CR

TL;DR: 该研究提出了一种基于零信任架构(ZTA)的四级成熟度模型，通过量化评估身份验证、微隔离、数据加密等关键技术控制点的集成深度，帮助企业评估和提升网络安全防护能力。


<details>
  <summary>Details</summary>
Motivation: 面对日益复杂的网络威胁，企业需要采用零信任架构来提升安全防护能力。但由于ZTA缺乏明确的量化标准，企业难以评估自身实施成熟度，因此需要建立数据驱动的评估框架。

Method: 研究开发了一种新的数据驱动方法，通过评估身份验证、微分段、数据加密、分析和编排等关键技术控制点的集成深度，并与行业最佳实践对齐，来量化企业的ZTA实施成熟度。

Result: 研究结果定义了一套规范的关键技术控制集，并建立了四级成熟度模型（从初始级到优化级），每个层级都增加了前一层级的能力，帮助企业评估其在安全转型旅程中的阶段。

Conclusion: 该研究提供了一个实用的量化框架，帮助企业评估零信任架构的实施成熟度，通过明确的控制点和分级模型指导企业逐步提升网络安全防护能力，有效应对网络攻击威胁。

Abstract: Increasingly sophisticated and varied cyber threats necessitate ever
improving enterprise security postures. For many organizations today, those
postures have a foundation in the Zero Trust Architecture. This strategy sees
trust as something an enterprise must not give lightly or assume too broadly.
Understanding the ZTA and its numerous controls centered around the idea of not
trusting anything inside or outside the network without verification, will
allow organizations to comprehend and leverage this increasingly common
paradigm. The ZTA, unlike many other regulatory frameworks, is not tightly
defined. The research assesses the likelihood of quantifiable guidelines that
measure cybersecurity maturity for an enterprise organization in relation to
ZTA implementation. This is a new, data driven methodology for quantifying
cyber resilience enabled by the adoption of Zero Trust principles to
pragmatically address the critical need of organizations. It also looks at the
practical aspects ZTA has on capabilities in deterring cyberattacks on a
network. The outcomes of this research define a prescriptive set of key
technical controls across identity verification, microsegmentation, data
encryption, analytics, and orchestration that characterize the comprehensive
ZTA deployment. By evaluating the depth of integration for each control
component and aligning to industry best practices, the study's results help
assess an organization's ZTA maturity level on a scale from Initial to
Optimized adoption. The research's resultant four tier model demarcates phases
for an organization on its security transformation journey, with each tier
adding to the capability of the last.

</details>


### [44] [AuthenTree: A Scalable MPC-Based Distributed Trust Architecture for Chiplet-based Heterogeneous Systems](https://arxiv.org/abs/2508.13033)
*Ishraq Tashdid,Tasnuva Farheen,Sazadur Rahman*

Main category: cs.CR

TL;DR: AuthenTree是一个基于多方计算的分布式认证框架，用于芯片级安全验证，无需专用硬件或中央信任，在面积、功耗和延迟方面具有极低开销。


<details>
  <summary>Details</summary>
Motivation: 芯片级异构集成虽然带来了模块化和快速上市的优势，但多供应商组装导致供应链碎片化，面临克隆、过度生产和芯片替换等安全威胁，现有解决方案依赖可信集成商或中央安全锚点，存在敏感数据暴露和单点故障风险。

Method: 提出了AuthenTree分布式认证框架，利用多方计算(MPC)在可扩展的树状架构中实现安全芯片验证，不暴露原始签名，将信任分布到多个集成商芯片中。

Result: 在五个SiP基准测试中，AuthenTree面积开销最低0.48%(7000平方微米)，功耗开销低于0.5%，认证延迟低于1微秒，在某些情况下比先前工作快700倍。

Conclusion: AuthenTree被证明是零信任SiP环境中下一代芯片级安全的高效、鲁棒和可扩展解决方案。

Abstract: The rapid adoption of chiplet-based heterogeneous integration is reshaping
semiconductor design by enabling modular, scalable, and faster time-to-market
solutions for AI and high-performance computing. However, multi-vendor assembly
in post-fabrication environments fragments the supply chain and exposes SiP
systems to serious security threats, including cloning, overproduction, and
chiplet substitution. Existing authentication solutions depend on trusted
integrators or centralized security anchors, which can expose sensitive data or
create single points of failure. We introduce AuthenTree, a distributed
authentication framework that leverages multi-party computation (MPC) in a
scalable tree-based architecture, removing the need for dedicated security
hardware or centralized trust. AuthenTree enables secure chiplet validation
without revealing raw signatures, distributing trust across multiple integrator
chiplets. Our evaluation in five SiP benchmarks demonstrates that AuthenTree
imposes minimal overhead, with an area as low as 0.48% (7,000 sq-micrometers),
an overhead power under 0.5%, and an authentication latency below 1
microsecond, surpassing previous work in some cases by 700 times. These results
establish AuthenTree as an efficient, robust, and scalable solution for
next-generation chiplet-based security in zero-trust SiP environments.

</details>


### [45] [MAJIC: Markovian Adaptive Jailbreaking via Iterative Composition of Diverse Innovative Strategies](https://arxiv.org/abs/2508.13048)
*Weiwei Qi,Shuo Shao,Wei Gu,Tianhang Zheng,Puning Zhao,Zhan Qin,Kui Ren*

Main category: cs.CR

TL;DR: MAJIC是一个马尔可夫自适应越狱框架，通过迭代组合多种伪装策略来攻击黑盒大语言模型，显著提升了攻击成功率和效率


<details>
  <summary>Details</summary>
Motivation: 现有黑盒越狱技术主要依赖静态提示或僵化的攻击方法组合，缺乏适应性和泛化能力，限制了攻击效果

Method: 建立伪装策略池，将策略选择和融合建模为马尔可夫链，通过动态调整转移概率来学习有效的攻击路径

Result: 在GPT-4o和Gemini-2.0-flash等主流模型上实现了超过90%的攻击成功率，平均每次尝试少于15次查询

Conclusion: MAJIC框架通过自适应策略组合显著提升了黑盒越狱攻击的效果，为LLM安全性研究提供了重要参考

Abstract: Large Language Models (LLMs) have exhibited remarkable capabilities but
remain vulnerable to jailbreaking attacks, which can elicit harmful content
from the models by manipulating the input prompts. Existing black-box
jailbreaking techniques primarily rely on static prompts crafted with a single,
non-adaptive strategy, or employ rigid combinations of several underperforming
attack methods, which limits their adaptability and generalization. To address
these limitations, we propose MAJIC, a Markovian adaptive jailbreaking
framework that attacks black-box LLMs by iteratively combining diverse
innovative disguise strategies. MAJIC first establishes a ``Disguise Strategy
Pool'' by refining existing strategies and introducing several innovative
approaches. To further improve the attack performance and efficiency, MAJIC
formulate the sequential selection and fusion of strategies in the pool as a
Markov chain. Under this formulation, MAJIC initializes and employs a Markov
matrix to guide the strategy composition, where transition probabilities
between strategies are dynamically adapted based on attack outcomes, thereby
enabling MAJIC to learn and discover effective attack pathways tailored to the
target model. Our empirical results demonstrate that MAJIC significantly
outperforms existing jailbreak methods on prominent models such as GPT-4o and
Gemini-2.0-flash, achieving over 90\% attack success rate with fewer than 15
queries per attempt on average.

</details>


### [46] [VerilogLAVD: LLM-Aided Rule Generation for Vulnerability Detection in Verilog](https://arxiv.org/abs/2508.13092)
*Xiang Long,Yingjie Xia,Xiyuan Chen,Li Kuang*

Main category: cs.CR

TL;DR: 通过创建Verilog属性图(VeriPG)表示法，结合LLM生成图遍历规则，实现了更准确的Verilog硬件漏洞检测方案


<details>
  <summary>Details</summary>
Motivation: 现有的早期硬件漏洞检测技术需要专业安全知识，而LLM在处理Verilog代码结构时表现不稳定

Method: 提出Verilog属性图(VeriPG)统一表示法，结合AST语法特征和控制流/数据依赖图语义信息，利用LLM从CWE描述生成VeriPG基于的检测规则

Result: 在77个Verilog设计和12种CWE类型的评估中，VerilogLAVD达到F1得0.54，相比于纯LLM和LLM外部知识基准分别提高0.31和0.27

Conclusion: VerilogLAVD通过图表示法和规则生成的结合，有效解决了LLM在Verilog漏洞检测中的结构理解问题，显著提升了检测准确性

Abstract: Timely detection of hardware vulnerabilities during the early design stage is
critical for reducing remediation costs. Existing early detection techniques
often require specialized security expertise, limiting their usability. Recent
efforts have explored the use of large language models (LLMs) for Verilog
vulnerability detection. However, LLMs struggle to capture the structure in
Verilog code, resulting in inconsistent detection results. To this end, we
propose VerilogLAVD, the first LLM-aided graph traversal rule generation
approach for Verilog vulnerability detection. Our approach introduces the
Verilog Property Graph (VeriPG), a unified representation of Verilog code. It
combines syntactic features extracted from the abstract syntax tree (AST) with
semantic information derived from control flow and data dependency graphs. We
leverage LLMs to generate VeriPG-based detection rules from Common Weakness
Enumeration (CWE) descriptions. These rules guide the rule executor that
traversal VeriPG for potential vulnerabilities. To evaluate VerilogLAVD, we
build a dataset collected from open-source repositories and synthesized data.
In our empirical evaluation on 77 Verilog designs encompassing 12 CWE types,
VerilogLAVD achieves an F1-score of 0.54. Compared to the LLM-only and LLM with
external knowledge baselines, VerilogLAVD improves F1-score by 0.31 and 0.27,
respectively.

</details>
