<div id=toc></div>

# Table of Contents

- [cs.CR](#cs.CR) [Total: 20]


<div id='cs.CR'></div>

# cs.CR [[Back]](#toc)

### [1] [Secure Autonomous Agent Payments: Verifying Authenticity and Intent in a Trustless Environment](https://arxiv.org/abs/2511.15712)
*Vivek Acharya*

Main category: cs.CR

TL;DR: 提出了一种基于区块链的框架，通过密码学方法验证AI代理发起的金融交易的真实性和意图，确保自主经济代理的安全性和可审计性。


<details>
  <summary>Details</summary>
Motivation: 随着AI代理越来越多地代表用户发起金融交易，传统支付系统基于人类授权的假设不再适用，需要在去中心化环境中验证代理身份和交易意图。

Method: 采用去中心化身份标准和可验证凭证建立代理身份，使用链上意图证明记录用户授权，零知识证明保护隐私，安全执行环境确保代理推理完整性。

Result: 通过定性分析，该框架展现出对冒充、未经授权交易和意图偏差的强抵抗力。

Conclusion: 为安全、可审计且意图感知的自主经济代理奠定了基础，为AI驱动的金融生态系统实现可验证的信任和问责制。

Abstract: Artificial intelligence (AI) agents are increasingly capable of initiating financial transactions on behalf of users or other agents. This evolution introduces a fundamental challenge: verifying both the authenticity of an autonomous agent and the true intent behind its transactions in a decentralized, trustless environment. Traditional payment systems assume human authorization, but autonomous, agent-led payments remove that safeguard. This paper presents a blockchain-based framework that cryptographically authenticates and verifies the intent of every AI-initiated transaction. The proposed system leverages decentralized identity (DID) standards and verifiable credentials to establish agent identities, on-chain intent proofs to record user authorization, and zero-knowledge proofs (ZKPs) to preserve privacy while ensuring policy compliance. Additionally, secure execution environments (TEE-based attestations) guarantee the integrity of agent reasoning and execution. The hybrid on-chain/off-chain architecture provides an immutable audit trail linking user intent to payment outcome. Through qualitative analysis, the framework demonstrates strong resistance to impersonation, unauthorized transactions, and misalignment of intent. This work lays the foundation for secure, auditable, and intent-aware autonomous economic agents, enabling a future of verifiable trust and accountability in AI-driven financial ecosystems.

</details>


### [2] [A Detailed Comparative Analysis of Blockchain Consensus Mechanisms](https://arxiv.org/abs/2511.15730)
*Kaeli Andrews,Linh Ngo,Md Amiruzzaman*

Main category: cs.CR

TL;DR: 对PoW和PoS两种主流区块链共识机制进行综合比较分析，评估它们在能源使用、安全性、交易速度等七个关键指标上的表现。


<details>
  <summary>Details</summary>
Motivation: 为未来区块链基础设施开发提供参考，在去中心化、性能和生态责任之间找到平衡。

Method: 利用近期学术研究和真实区块链数据，对PoW和PoS在七个关键指标上进行对比分析。

Result: PoW提供稳健的安全性但能耗高、吞吐量慢；PoS具有更好的可扩展性和效率，环境影响小，但存在验证者中心化和长期安全性成熟度问题。

Conclusion: 两种机制各有利弊，混合设计可能结合PoW的安全性和PoS的效率与可持续性。

Abstract: This paper presents a comprehensive comparative analysis of two dominant blockchain consensus mechanisms, Proof of Work (PoW) and Proof of Stake (PoS), evaluated across seven critical metrics: energy use, security, transaction speed, scalability, centralization risk, environmental impact, and transaction fees. Utilizing recent academic research and real-world blockchain data, the study highlights that PoW offers robust, time-tested security but suffers from high energy consumption, slower throughput, and centralization through mining pools. In contrast, PoS demonstrates improved scalability and efficiency, significantly reduced environmental impact, and more stable transaction fees, however it raises concerns over validator centralization and long-term security maturity. The findings underscore the trade-offs inherent in each mechanism and suggest hybrid designs may combine PoW's security with PoS's efficiency and sustainability. The study aims to inform future blockchain infrastructure development by striking a balance between decentralization, performance, and ecological responsibility.

</details>


### [3] [AnonLFI 2.0: Extensible Architecture for PII Pseudonymization in CSIRTs with OCR and Technical Recognizers](https://arxiv.org/abs/2511.15744)
*Cristhian Kapelinski,Douglas Lautert,Beatriz Machado,Diego Kreutz*

Main category: cs.CR

TL;DR: AnonLFI 2.0是一个用于CSIRTs的模块化假名化框架，使用HMAC SHA256生成强可逆假名，保留XML和JSON结构，集成OCR和技术识别器处理PII和安全工件。


<details>
  <summary>Details</summary>
Motivation: 为网络安全团队提供安全处理复杂数据集的方法，保护敏感信息同时保持数据结构完整性。

Method: 使用HMAC SHA256算法生成可逆假名，集成OCR技术识别PDF文档中的文本，以及专门识别器处理PII和安全工件，保留XML和JSON结构。

Result: 在两个案例研究中，系统在PDF文档OCR和OpenVAS XML报告处理中实现了完美精度，F1分数分别为76.5和92.13。

Conclusion: 该框架有效用于安全准备复杂网络安全数据集，展示了在保护敏感信息的同时保持数据处理准确性的能力。

Abstract: This work presents AnonLFI 2.0, a modular pseudonymization framework for CSIRTs that uses HMAC SHA256 to generate strong and reversible pseudonyms, preserves XML and JSON structures, and integrates OCR and technical recognizers for PII and security artifacts. In two case studies involving OCR applied to PDF documents and an OpenVAS XML report, the system achieved perfect precision and F1 scores of 76.5 and 92.13, demonstrating its effectiveness for securely preparing complex cybersecurity datasets.

</details>


### [4] [Structured Extraction of Vulnerabilities in OpenVAS and Tenable WAS Reports Using LLMs](https://arxiv.org/abs/2511.15745)
*Beatriz Machado,Douglas Lautert,Cristhian Kapelinski,Diego Kreutz*

Main category: cs.CR

TL;DR: 提出基于LLM的自动化方法，从OpenVAS和Tenable WAS扫描报告中提取和结构化漏洞信息，将非结构化数据转换为标准化格式用于风险管理。


<details>
  <summary>Details</summary>
Motivation: 网络安全扫描报告通常包含大量非结构化数据，难以直接用于风险管理和优先级排序，需要将其转换为结构化格式以提高可用性。

Method: 使用大型语言模型（LLM）自动化处理扫描报告，从OpenVAS和Tenable WAS报告中提取漏洞信息并转换为标准化格式。

Result: 在包含34个漏洞的报告评估中，GPT-4.1和DeepSeek模型与基准的相似度最高（ROUGE-L大于0.7），证明该方法在转换复杂报告为可用数据集方面的可行性。

Conclusion: 该方法成功将复杂的扫描报告转换为结构化数据集，支持有效的优先级排序和未来敏感数据的匿名化处理。

Abstract: This paper proposes an automated LLM-based method to extract and structure vulnerabilities from OpenVAS and Tenable WAS scanner reports, converting unstructured data into a standardized format for risk management. In an evaluation using a report with 34 vulnerabilities, GPT-4.1 and DeepSeek achieved the highest similarity to the baseline (ROUGE-L greater than 0.7). The method demonstrates feasibility in transforming complex reports into usable datasets, enabling effective prioritization and future anonymization of sensitive data.

</details>


### [5] [Securing AI Agents Against Prompt Injection Attacks](https://arxiv.org/abs/2511.15759)
*Badrinath Ramakrishnan,Akshaya Balaji*

Main category: cs.CR

TL;DR: 提出了一个评估RAG系统提示注入攻击风险的基准测试和防御框架，包含847个对抗测试用例，将攻击成功率从73.2%降低到8.7%。


<details>
  <summary>Details</summary>
Motivation: RAG系统虽然增强了大型语言模型能力，但引入了严重的提示注入攻击安全漏洞，需要系统性的安全评估和防御方案。

Method: 开发了包含847个对抗测试用例的基准测试，涵盖5种攻击类型；提出了多层防御框架，包括内容过滤、系统提示防护和多阶段响应验证。

Result: 在7个最先进的语言模型上评估，组合防御框架将成功攻击率从73.2%降低到8.7%，同时保持94.3%的基线任务性能。

Conclusion: 提出的基准测试和防御框架有效提升了RAG系统的安全性，为AI代理安全研究提供了重要工具和实现方案。

Abstract: Retrieval-augmented generation (RAG) systems have become widely used for enhancing large language model capabilities, but they introduce significant security vulnerabilities through prompt injection attacks. We present a comprehensive benchmark for evaluating prompt injection risks in RAG-enabled AI agents and propose a multi-layered defense framework. Our benchmark includes 847 adversarial test cases across five attack categories: direct injection, context manipulation, instruction override, data exfiltration, and cross-context contamination. We evaluate three defense mechanisms: content filtering with embedding-based anomaly detection, hierarchical system prompt guardrails, and multi-stage response verification, across seven state-of-the-art language models. Our combined framework reduces successful attack rates from 73.2% to 8.7% while maintaining 94.3% of baseline task performance. We release our benchmark dataset and defense implementation to support future research in AI agent security.

</details>


### [6] [Scalable Privilege Analysis for Multi-Cloud Big Data Platforms: A Hypergraph Approach](https://arxiv.org/abs/2511.15837)
*Sai Sitharaman,Hassan Karim,Deepti Gupta,Mudit Tyagi*

Main category: cs.CR

TL;DR: 提出了一种基于超图的权限管理框架，将NIST NGAC与超图语义结合，解决了传统ABAC方法在企业规模下的可扩展性问题，实现了亚线性复杂度的高效权限分析。


<details>
  <summary>Details</summary>
Motivation: 多云环境的快速采用加剧了特权访问管理风险，传统基于ABAC的PAM解决方案具有立方复杂度，在企业规模下无法进行实时权限分析。

Method: 集成NIST NGAC与超图语义，使用带标签超边建模复杂多维权限关系，提出3维权限分析框架（攻击面、攻击窗口、攻击身份）系统识别权限漏洞。

Result: 在AWS系统200-4000用户规模下验证，相比ABAC提升10倍性能，相比标准NGAC-DAG提升4倍性能，实现亚秒级权限检测。

Conclusion: 该框架能有效检测多云基础设施中的权限提升链、过度特权用户和横向移动路径，解决了企业级权限管理的可扩展性挑战。

Abstract: The rapid adoption of multi-cloud environments has amplified risks associated with privileged access mismanagement. Traditional Privileged Access Management (PAM) solutions based on Attribute-Based Access Control (ABAC) exhibit cubic O(n^3) complexity, rendering real-time privilege analysis intractable at enterprise scale. We present a novel PAM framework integrating NIST's Next Generation Access Control (NGAC) with hypergraph semantics to address this scalability crisis. Our approach leverages hypergraphs with labeled hyperedges to model complex, multi-dimensional privilege relationships, achieving sub-linear O(sqrt n) traversal complexity and O(nlogn) detection time-rigorously proven through formal complexity analysis. We introduce a 3-Dimensional Privilege Analysis framework encompassing Attack Surface, Attack Window, and Attack Identity to systematically identify privilege vulnerabilities. Experimental validation on AWS-based systems with 200-4000 users demonstrates 10x improvement over ABAC and 4x improvement over standard NGAC-DAG, enabling sub-second privilege detection at scale. Real-world use cases validate detection of privilege escalation chains, over-privileged users, and lateral movement pathways in multi-cloud infrastructures.

</details>


### [7] [Lifefin: Escaping Mempool Explosions in DAG-based BFT](https://arxiv.org/abs/2511.15936)
*Jianting Zhang,Sen Yang,Alberto Sonnino,Sebastián Loza,Aniket Kate*

Main category: cs.CR

TL;DR: Lifefin是一个通用的自稳定协议，用于解决DAG-based BFT协议中的活跃性漏洞问题，通过ACS机制在恶劣条件下也能保证交易提交。


<details>
  <summary>Details</summary>
Motivation: 现有的DAG-based BFT协议存在根本性的活跃性漏洞，攻击者可以通过触发内存池爆炸来阻止交易提交，从而破坏协议的活跃性。

Method: Lifefin利用Agreement on Common Subset (ACS)机制，使节点能够在内存池爆炸的情况下以有界资源使用提交交易，在典型情况下几乎不引入额外开销。

Result: 将Lifefin集成到Sailfish和Mysticeti协议中，实验评估显示在保持可比交易吞吐量的同时，仅引入最小额外延迟就能抵抗类似攻击。

Conclusion: Lifefin有效消除了DAG-based BFT协议的活跃性漏洞，在典型情况下几乎零开销，在恶劣条件下仍能保证协议正常运行。

Abstract: Directed Acyclic Graph (DAG)-based Byzantine Fault-Tolerant (BFT) protocols have emerged as promising solutions for high-throughput blockchains. By decoupling data dissemination from transaction ordering and constructing a well-connected DAG in the mempool, these protocols enable zero-message ordering and implicit view changes. However, we identify a fundamental liveness vulnerability: an adversary can trigger mempool explosions to prevent transaction commitment, ultimately compromising the protocol's liveness.
  In response, this work presents Lifefin, a generic and self-stabilizing protocol designed to integrate seamlessly with existing DAG-based BFT protocols and circumvent such vulnerabilities. Lifefin leverages the Agreement on Common Subset (ACS) mechanism, allowing nodes to escape mempool explosions by committing transactions with bounded resource usage even in adverse conditions. As a result, Lifefin imposes (almost) zero overhead in typical cases while effectively eliminating liveness vulnerabilities.
  To demonstrate the effectiveness of Lifefin, we integrate it into two state-of-the-art DAG-based BFT protocols, Sailfish and Mysticeti, resulting in two enhanced variants: Sailfish-Lifefin and Mysticeti-Lifefin. We implement these variants and compare them with the original Sailfish and Mysticeti systems. Our evaluation demonstrates that Lifefin achieves comparable transaction throughput while introducing only minimal additional latency to resist similar attacks.

</details>


### [8] [Digital Agriculture Sandbox for Collaborative Research](https://arxiv.org/abs/2511.15990)
*Osama Zafar,Rosemarie Santa González,Alfonso Morales,Erman Ayday*

Main category: cs.CR

TL;DR: 本文提出了一个名为"数字农业沙盒"的安全在线平台，通过联邦学习、差分隐私等技术，让农民和研究人员能够在保护数据隐私的前提下协作分析农业数据。


<details>
  <summary>Details</summary>
Motivation: 数字农业产生了大量有价值的数据，但由于隐私担忧，农民不愿分享数据，限制了研究人员利用这些数据改进农业实践的能力。

Method: 采用联邦学习、差分隐私和数据分析方法，构建一个安全平台，使农民能够识别相似农户，研究人员能够从数据中学习，而敏感信息不会离开农民的系统。

Result: 该平台创建了一个安全空间，农民愿意分享数据，研究人员能够进行重要发现，弥合了数据隐私保护与数据利用之间的差距。

Conclusion: 数字农业沙盒平台成功解决了农业数据隐私与利用之间的矛盾，为应对全球粮食和农业挑战提供了有效工具。

Abstract: Digital agriculture is transforming the way we grow food by utilizing technology to make farming more efficient, sustainable, and productive. This modern approach to agriculture generates a wealth of valuable data that could help address global food challenges, but farmers are hesitant to share it due to privacy concerns. This limits the extent to which researchers can learn from this data to inform improvements in farming. This paper presents the Digital Agriculture Sandbox, a secure online platform that solves this problem. The platform enables farmers (with limited technical resources) and researchers to collaborate on analyzing farm data without exposing private information. We employ specialized techniques such as federated learning, differential privacy, and data analysis methods to safeguard the data while maintaining its utility for research purposes. The system enables farmers to identify similar farmers in a simplified manner without needing extensive technical knowledge or access to computational resources. Similarly, it enables researchers to learn from the data and build helpful tools without the sensitive information ever leaving the farmer's system. This creates a safe space where farmers feel comfortable sharing data, allowing researchers to make important discoveries. Our platform helps bridge the gap between maintaining farm data privacy and utilizing that data to address critical food and farming challenges worldwide.

</details>


### [9] [Hiding in the AI Traffic: Abusing MCP for LLM-Powered Agentic Red Teaming](https://arxiv.org/abs/2511.15998)
*Strahinja Janjusevic,Anna Baron Garcia,Sohrob Kazerounian*

Main category: cs.CR

TL;DR: 提出基于模型上下文协议(MCP)的新型C2架构，用于协调分布式自适应侦察代理，在提升系统目标导向行为的同时消除可检测的主机和网络痕迹。


<details>
  <summary>Details</summary>
Motivation: 现有生成式AI在红队测试中存在通用性与专业性的权衡，以及幻觉、上下文限制和伦理问题等挑战，需要改进C2架构以实现更隐蔽、自适应的网络侦察。

Method: 采用模型上下文协议(MCP)构建命令与控制架构，支持异步并行操作和实时情报共享，避免周期性信标通信，减少检测痕迹。

Result: 与传统C2相比，实验显示手动工作量大幅减少，检测足迹显著降低，能够有效模拟高级持续性威胁。

Conclusion: MCP支持的C2框架是实现现实AI驱动红队操作的重要进展，为下一代防御系统开发提供参考，未来可集成自主利用、防御性LLM代理和预测性规避机动等功能。

Abstract: Generative AI is reshaping offensive cybersecurity by enabling autonomous red team agents that can plan, execute, and adapt during penetration tests. However, existing approaches face trade-offs between generality and specialization, and practical deployments reveal challenges such as hallucinations, context limitations, and ethical concerns. In this work, we introduce a novel command & control (C2) architecture leveraging the Model Context Protocol (MCP) to coordinate distributed, adaptive reconnaissance agents covertly across networks. Notably, we find that our architecture not only improves goal-directed behavior of the system as whole, but also eliminates key host and network artifacts that can be used to detect and prevent command & control behavior altogether. We begin with a comprehensive review of state-of-the-art generative red teaming methods, from fine-tuned specialist models to modular or agentic frameworks, analyzing their automation capabilities against task-specific accuracy. We then detail how our MCP-based C2 can overcome current limitations by enabling asynchronous, parallel operations and real-time intelligence sharing without periodic beaconing. We furthermore explore advanced adversarial capabilities of this architecture, its detection-evasion techniques, and address dual-use ethical implications, proposing defensive measures and controlled evaluation in lab settings. Experimental comparisons with traditional C2 show drastic reductions in manual effort and detection footprint. We conclude with future directions for integrating autonomous exploitation, defensive LLM agents, predictive evasive maneuvers, and multi-agent swarms. The proposed MCP-enabled C2 framework demonstrates a significant step toward realistic, AI-driven red team operations that can simulate advanced persistent threats while informing the development of next-generation defensive systems.

</details>


### [10] [A Quantum-Secure and Blockchain-Integrated E-Voting Framework with Identity Validation](https://arxiv.org/abs/2511.16034)
*Ashwin Poudel,Utsav Poudel,Dikshyanta Aryal,Anuj Nepal,Pranish Pathak,Subramaniyaswamy V*

Main category: cs.CR

TL;DR: 提出了一种后量子安全的电子投票架构，集成了Falcon数字签名、MobileNetV3和AdaFace生物认证，以及许可区块链，确保投票安全性和可审计性。


<details>
  <summary>Details</summary>
Motivation: 量子计算的快速发展对数字系统的密码学基础构成威胁，需要开发安全且可扩展的电子投票框架。

Method: 使用Falcon晶格数字签名进行生物特征认证，结合MobileNetV3和AdaFace进行实时生物验证，采用许可区块链存储防篡改投票记录。

Result: 在CelebA Spoof数据集上平均分类错误率低于3.5%，在WFAS数据集上低于8.2%；区块链锚定开销低（注册3.3%，投票0.15%），系统具有高可扩展性和并发负载弹性。

Conclusion: 该方案为数字系统中的选民认证、数据完整性和量子弹性安全等关键挑战提供了统一解决方案。

Abstract: The rapid growth of quantum computing poses a threat to the cryptographic foundations of digital systems, requiring the development of secure and scalable electronic voting (evoting) frameworks. We introduce a post-quantum-secure evoting architecture that integrates Falcon lattice-based digital signatures, biometric authentication via MobileNetV3 and AdaFace, and a permissioned blockchain for tamper-proof vote storage. Voter registration involves capturing facial embeddings, which are digitally signed using Falcon and stored on-chain to ensure integrity and non-repudiation. During voting, real-time biometric verification is performed using anti-spoofing techniques and cosine-similarity matching. The system demonstrates low latency and robust spoof detection, monitored through Prometheus and Grafana for real-time auditing. The average classification error rates (ACER) are below 3.5% on the CelebA Spoof dataset and under 8.2% on the Wild Face Anti-Spoofing (WFAS) dataset. Blockchain anchoring incurs minimal gas overhead, approximately 3.3% for registration and 0.15% for voting, supporting system efficiency, auditability, and transparency. The experimental results confirm the system's scalability, efficiency, and resilience under concurrent loads. This approach offers a unified solution to address key challenges in voter authentication, data integrity, and quantum-resilient security for digital systems.

</details>


### [11] [Future-Back Threat Modeling: A Foresight-Driven Security Framework](https://arxiv.org/abs/2511.16088)
*Vu Van Than*

Main category: cs.CR

TL;DR: 本文提出了一种前瞻性威胁建模方法——未来回溯威胁建模（FBTM），通过从设想的未来威胁状态反向分析，识别当前防御架构中的假设、盲点和漏洞，以应对传统威胁建模的局限性。


<details>
  <summary>Details</summary>
Motivation: 传统威胁建模主要关注已知威胁和过去事件，而威胁预测框架往往与操作或架构脱节。最严重的网络威胁通常来自未知、被忽视或尚未设想的领域，尤其是来自未来的威胁（如人工智能、信息战、供应链攻击），这些威胁能够绕过基于当前知识的防御体系。

Method: FBTM采用预测性方法，从设想的未来威胁状态开始，反向识别当前防御架构中的假设、差距、盲点和漏洞。该方法旨在揭示已知未知和未知未知，包括新兴、预期和可能的战术、技术和程序。

Result: 该方法能够提供更清晰准确的即将到来威胁视图，增强在不确定性下对对手行为的可预测性，帮助安全领导者做出明智决策。

Conclusion: FBTM通过当前行动塑造期望的未来，帮助构建更具弹性的安全态势，使组织能够预见威胁的出现并主动应对。

Abstract: Traditional threat modeling remains reactive-focused on known TTPs and past incident data, while threat prediction and forecasting frameworks are often disconnected from operational or architectural artifacts. This creates a fundamental weakness: the most serious cyber threats often do not arise from what is known, but from what is assumed, overlooked, or not yet conceived, and frequently originate from the future, such as artificial intelligence, information warfare, and supply chain attacks, where adversaries continuously develop new exploits that can bypass defenses built on current knowledge. To address this mental gap, this paper introduces the theory and methodology of Future-Back Threat Modeling (FBTM). This predictive approach begins with envisioned future threat states and works backward to identify assumptions, gaps, blind spots, and vulnerabilities in the current defense architecture, providing a clearer and more accurate view of impending threats so that we can anticipate their emergence and shape the future we want through actions taken now. The proposed methodology further aims to reveal known unknowns and unknown unknowns, including tactics, techniques, and procedures that are emerging, anticipated, and plausible. This enhances the predictability of adversary behavior, particularly under future uncertainty, helping security leaders make informed decisions today that shape more resilient security postures for the future.

</details>


### [12] [Multi-Faceted Attack: Exposing Cross-Model Vulnerabilities in Defense-Equipped Vision-Language Models](https://arxiv.org/abs/2511.16110)
*Yijun Yang,Lichao Wang,Jianping Zhang,Chi Harold Liu,Lanqing Hong,Qiang Xu*

Main category: cs.CR

TL;DR: MFA是一个针对视觉语言模型安全防御的系统性攻击框架，通过注意力转移攻击和轻量级迁移增强算法，成功绕过GPT-4o、Gemini-Pro等主流模型的多种安全防护措施。


<details>
  <summary>Details</summary>
Motivation: 当前视觉语言模型部署了多种安全防护措施，但这些防御机制在现实世界中对对抗性攻击的鲁棒性尚未得到充分探索。

Method: 提出注意力转移攻击(ATA)将有害指令隐藏在具有竞争目标的元任务中，并结合轻量级迁移增强算法和简单重复策略，无需模型特定微调即可绕过输入和输出级过滤器。

Result: MFA攻击成功率高达58.5%，在最新商业模型上达到52.8%的成功率，比次优攻击方法高出34%。对抗图像可跨模型迁移，表明共享视觉表示存在跨模型安全漏洞。

Conclusion: 研究结果挑战了当前防御机制的感知鲁棒性，突显出现代视觉语言模型中持续存在的安全弱点。

Abstract: The growing misuse of Vision-Language Models (VLMs) has led providers to deploy multiple safeguards, including alignment tuning, system prompts, and content moderation. However, the real-world robustness of these defenses against adversarial attacks remains underexplored. We introduce Multi-Faceted Attack (MFA), a framework that systematically exposes general safety vulnerabilities in leading defense-equipped VLMs such as GPT-4o, Gemini-Pro, and Llama-4. The core component of MFA is the Attention-Transfer Attack (ATA), which hides harmful instructions inside a meta task with competing objectives. We provide a theoretical perspective based on reward hacking to explain why this attack succeeds. To improve cross-model transferability, we further introduce a lightweight transfer-enhancement algorithm combined with a simple repetition strategy that jointly bypasses both input-level and output-level filters without model-specific fine-tuning. Empirically, we show that adversarial images optimized for one vision encoder transfer broadly to unseen VLMs, indicating that shared visual representations create a cross-model safety vulnerability. Overall, MFA achieves a 58.5% success rate and consistently outperforms existing methods. On state-of-the-art commercial models, MFA reaches a 52.8% success rate, surpassing the second-best attack by 34%. These results challenge the perceived robustness of current defense mechanisms and highlight persistent safety weaknesses in modern VLMs. Code: https://github.com/cure-lab/MultiFacetedAttack

</details>


### [13] [ART: A Graph-based Framework for Investigating Illicit Activity in Monero via Address-Ring-Transaction Structures](https://arxiv.org/abs/2511.16192)
*Andrea Venturi,Imanol Jerico-Yoldi,Francesco Zola,Raul Orduna*

Main category: cs.CR

TL;DR: 提出了一种基于图的方法来分析Monero交易中的犯罪行为模式，通过构建地址-环-交易图来提取结构特征，训练机器学习模型检测犯罪活动。


<details>
  <summary>Details</summary>
Motivation: 随着执法机构在加密货币取证方面的进步，犯罪分子越来越多地使用Monero等隐私币来隐藏非法资金流动。由于Monero的强隐私保护特性，传统区块链分析无效，因此需要新的方法来理解犯罪分子的行为模式。

Method: 构建地址-环-交易图，从标记的交易中提取结构和时间特征，使用这些特征训练机器学习模型来检测类似的犯罪行为模式。

Result: 开发了一种能够检测Monero交易中犯罪活动模式的分析方法，为隐私保护区块链生态系统中的调查工作提供支持。

Conclusion: 这是开发支持隐私保护区块链调查分析工具的第一步，有助于识别和打击非法活动。

Abstract: As Law Enforcement Agencies advance in cryptocurrency forensics, criminal actors aiming to conceal illicit fund movements increasingly turn to "mixin" services or privacy-based cryptocurrencies. Monero stands out as a leading choice due to its strong privacy preserving and untraceability properties, making conventional blockchain analysis ineffective. Understanding the behavior and operational patterns of criminal actors within Monero is therefore challenging and it is essential to support future investigative strategies and disrupt illicit activities. In this work, we propose a case study in which we leverage a novel graph-based methodology to extract structural and temporal patterns from Monero transactions linked to already discovered criminal activities. By building Address-Ring-Transaction graphs from flagged transactions, we extract structural and temporal features and use them to train Machine Learning models capable of detecting similar behavioral patterns that could highlight criminal modus operandi. This represents a first partial step toward developing analytical tools that support investigative efforts in privacy-preserving blockchain ecosystems

</details>


### [14] [PSM: Prompt Sensitivity Minimization via LLM-Guided Black-Box Optimization](https://arxiv.org/abs/2511.16209)
*Huseein Jawad,Nicolas Brunel*

Main category: cs.CR

TL;DR: 本文提出了一种通过盾牌附加来强化系统提示的新框架，这是一种轻量级方法，通过在原始提示中添加保护性文本层来防御提取攻击。


<details>
  <summary>Details</summary>
Motivation: 系统提示包含专有逻辑或敏感信息，容易受到提取攻击，现有防御机制要么依赖启发式方法，要么计算开销大，要么不适用于黑盒API模型。

Method: 将提示强化形式化为效用约束优化问题，利用LLM作为优化器搜索可能的SHIELD空间，在保持任务效用高于指定阈值的同时最小化泄漏指标。

Result: 优化的SHIELD显著减少了针对全面提取攻击的提示泄漏，优于现有基线防御，且不损害模型的预期功能。

Conclusion: 这项工作为在LLM安全不断升级的背景下开发鲁棒、效用感知的防御提供了范例。

Abstract: System prompts are critical for guiding the behavior of Large Language Models (LLMs), yet they often contain proprietary logic or sensitive information, making them a prime target for extraction attacks. Adversarial queries can successfully elicit these hidden instructions, posing significant security and privacy risks. Existing defense mechanisms frequently rely on heuristics, incur substantial computational overhead, or are inapplicable to models accessed via black-box APIs. This paper introduces a novel framework for hardening system prompts through shield appending, a lightweight approach that adds a protective textual layer to the original prompt. Our core contribution is the formalization of prompt hardening as a utility-constrained optimization problem. We leverage an LLM-as-optimizer to search the space of possible SHIELDs, seeking to minimize a leakage metric derived from a suite of adversarial attacks, while simultaneously preserving task utility above a specified threshold, measured by semantic fidelity to baseline outputs. This black-box, optimization-driven methodology is lightweight and practical, requiring only API access to the target and optimizer LLMs. We demonstrate empirically that our optimized SHIELDs significantly reduce prompt leakage against a comprehensive set of extraction attacks, outperforming established baseline defenses without compromising the model's intended functionality. Our work presents a paradigm for developing robust, utility-aware defenses in the escalating landscape of LLM security. The code is made public on the following link: https://github.com/psm-defense/psm

</details>


### [15] [Q-MLLM: Vector Quantization for Robust Multimodal Large Language Model Security](https://arxiv.org/abs/2511.16229)
*Wei Zhao,Zhe Li,Yige Li,Jun Sun*

Main category: cs.CR

TL;DR: Q-MLLM通过两级向量量化构建离散瓶颈来防御多模态大语言模型的视觉对抗攻击，在保持模型性能的同时实现100%的防御成功率。


<details>
  <summary>Details</summary>
Motivation: 多模态大语言模型在跨模态理解方面表现出色，但视觉输入容易受到对抗攻击，而文本安全机制无法有效转移到视觉内容上。

Method: 采用两级向量量化架构，在像素-补丁和语义层面离散化视觉表示，阻断攻击路径并弥合跨模态安全对齐差距，使用两阶段训练方法确保鲁棒学习。

Result: Q-MLLM在越狱攻击和有害图像攻击上取得显著更好的防御成功率，除一个争议案例外实现100%的越狱攻击防御成功率，同时在多个实用基准上保持竞争力。

Conclusion: 向量量化是构建安全多模态AI系统的有效防御机制，无需昂贵的特定安全微调或检测开销。

Abstract: Multimodal Large Language Models (MLLMs) have demonstrated impressive capabilities in cross-modal understanding, but remain vulnerable to adversarial attacks through visual inputs despite robust textual safety mechanisms. These vulnerabilities arise from two core weaknesses: the continuous nature of visual representations, which allows for gradient-based attacks, and the inadequate transfer of text-based safety mechanisms to visual content. We introduce Q-MLLM, a novel architecture that integrates two-level vector quantization to create a discrete bottleneck against adversarial attacks while preserving multimodal reasoning capabilities. By discretizing visual representations at both pixel-patch and semantic levels, Q-MLLM blocks attack pathways and bridges the cross-modal safety alignment gap. Our two-stage training methodology ensures robust learning while maintaining model utility. Experiments demonstrate that Q-MLLM achieves significantly better defense success rate against both jailbreak attacks and toxic image attacks than existing approaches. Notably, Q-MLLM achieves perfect defense success rate (100\%) against jailbreak attacks except in one arguable case, while maintaining competitive performance on multiple utility benchmarks with minimal inference overhead. This work establishes vector quantization as an effective defense mechanism for secure multimodal AI systems without requiring expensive safety-specific fine-tuning or detection overhead. Code is available at https://github.com/Amadeuszhao/QMLLM.

</details>


### [16] ["To Survive, I Must Defect": Jailbreaking LLMs via the Game-Theory Scenarios](https://arxiv.org/abs/2511.16278)
*Zhen Sun,Zongmin Zhang,Deqi Liang,Han Sun,Yule Liu,Yun Shen,Xiangshan Gao,Yilong Yang,Shuai Liu,Yutao Yue,Xinlei He*

Main category: cs.CR

TL;DR: GTA是一个基于博弈论的可扩展黑盒越狱框架，通过将攻击者与安全对齐LLM的交互建模为有限时域、可提前终止的序贯随机博弈，利用量化响应重新参数化LLM的随机输出，实现了超过95%的攻击成功率。


<details>
  <summary>Details</summary>
Motivation: 现有黑盒越狱攻击大多依赖手工启发式或狭窄搜索空间，限制了可扩展性。需要一种更系统、可扩展的框架来应对非专家用户使用LLM带来的安全风险。

Method: 将攻击建模为博弈论场景，提出"模板优先于安全"的行为猜想，通过重塑LLM的有效目标来削弱特定上下文中的安全约束。引入攻击者代理自适应施加压力，并使用有害词检测代理进行词级插入。

Result: 在多个协议和数据集上，GTA在Deepseek-R1等LLM上实现超过95%的攻击成功率，同时保持效率。在多种博弈论场景和LLM生成的变体上均获得高ASR，并能绕过提示防护模型。

Conclusion: GTA证明了博弈论框架在黑盒越狱攻击中的有效性，具有高攻击成功率、可扩展性和泛化能力，能够突破现有安全防护并监控真实世界LLM应用的安全状况。

Abstract: As LLMs become more common, non-expert users can pose risks, prompting extensive research into jailbreak attacks. However, most existing black-box jailbreak attacks rely on hand-crafted heuristics or narrow search spaces, which limit scalability. Compared with prior attacks, we propose Game-Theory Attack (GTA), an scalable black-box jailbreak framework. Concretely, we formalize the attacker's interaction against safety-aligned LLMs as a finite-horizon, early-stoppable sequential stochastic game, and reparameterize the LLM's randomized outputs via quantal response. Building on this, we introduce a behavioral conjecture "template-over-safety flip": by reshaping the LLM's effective objective through game-theoretic scenarios, the originally safety preference may become maximizing scenario payoffs within the template, which weakens safety constraints in specific contexts. We validate this mechanism with classical game such as the disclosure variant of the Prisoner's Dilemma, and we further introduce an Attacker Agent that adaptively escalates pressure to increase the ASR. Experiments across multiple protocols and datasets show that GTA achieves over 95% ASR on LLMs such as Deepseek-R1, while maintaining efficiency. Ablations over components, decoding, multilingual settings, and the Agent's core model confirm effectiveness and generalization. Moreover, scenario scaling studies further establish scalability. GTA also attains high ASR on other game-theoretic scenarios, and one-shot LLM-generated variants that keep the model mechanism fixed while varying background achieve comparable ASR. Paired with a Harmful-Words Detection Agent that performs word-level insertions, GTA maintains high ASR while lowering detection under prompt-guard models. Beyond benchmarks, GTA jailbreaks real-world LLM applications and reports a longitudinal safety monitoring of popular HuggingFace LLMs.

</details>


### [17] [Multi-Domain Security for 6G ISAC: Challenges and Opportunities in Transportation](https://arxiv.org/abs/2511.16316)
*Musa Furkan Keskin,Muralikrishnan Srinivasan,Onur Gunlu,Hui Chen,Panagiotis Papadimitratos,Magnus Almgren,Zhongxia Simon He,Henk Wymeersch*

Main category: cs.CR

TL;DR: 本文分析了6G交通系统中集成感知与通信(ISAC)带来的独特安全挑战和机遇，提出了跨域安全框架


<details>
  <summary>Details</summary>
Motivation: ISAC在6G交通系统中的紧密集成暴露了纯感知和通信系统未遇到的安全攻击点，需要解决这些新出现的威胁

Method: 识别了三个相互关联领域的安全挑战：网络物理层、物理层和协议层，并提出了统一保护的多域安全框架

Result: 明确了ISAC在交通系统中的独特安全漏洞，包括传感器/执行器操纵、无线信号欺骗/干扰以及协议层攻击检测不足等问题

Conclusion: 需要为6G交通系统设计集成的多域安全框架，以统一保护各个领域，确保ISAC系统的安全性

Abstract: Integrated sensing and communication (ISAC) will be central to 6G-enabled transportation, providing both seamless connectivity and high-precision sensing. However, this tight integration exposes attack points not encountered in pure sensing and communication systems. In this article, we identify unique ISAC-induced security challenges and opportunities in three interrelated domains: cyber-physical (where manipulation of sensors and actuators can mislead perception and control), physical-layer (where over-the-air signals are vulnerable to spoofing and jamming) and protocol (where complex cryptographic protocols cannot detect lower-layer attacks). Building on these insights, we put forward a multi-domain security vision for 6G transportation and propose an integrated security framework that unifies protection across domains.

</details>


### [18] [The Shawshank Redemption of Embodied AI: Understanding and Benchmarking Indirect Environmental Jailbreaks](https://arxiv.org/abs/2511.16347)
*Chunyang Li,Zifeng Kang,Junwei Zhang,Zhuo Ma,Anda Cheng,Xinghua Li,Jianfeng Ma*

Main category: cs.CR

TL;DR: 本文首次提出间接环境越狱（IEJ）攻击，通过向环境中注入恶意指令来攻击具身AI代理，并开发了自动化攻击生成框架SHAWSHANK和基准生成框架SHAWSHANK-FORGE。


<details>
  <summary>Details</summary>
Motivation: 现有研究主要关注直接越狱攻击，而忽视了具身AI代理对环境中指令的盲目信任可能被利用进行间接越狱攻击的安全风险。

Method: 设计了两种开源自动化框架：SHAWSHANK用于自动生成IEJ攻击，SHAWSHANK-FORGE用于自动生成IEJ基准测试。通过SHAWSHANK-FORGE构建了首个间接越狱具身代理的基准SHAWSHANK-BENCH。

Result: 评估显示SHAWSHANK在3,957个任务-场景组合中优于11种现有方法，成功攻破所有6个测试的VLM。现有防御措施只能部分缓解该攻击。

Conclusion: 具身AI代理对环境中指令的盲目信任构成了严重安全风险，需要开发更有效的防御机制来应对间接环境越狱攻击。

Abstract: The adoption of Vision-Language Models (VLMs) in embodied AI agents, while being effective, brings safety concerns such as jailbreaking. Prior work have explored the possibility of directly jailbreaking the embodied agents through elaborated multi-modal prompts. However, no prior work has studied or even reported indirect jailbreaks in embodied AI, where a black-box attacker induces a jailbreak without issuing direct prompts to the embodied agent. In this paper, we propose, for the first time, indirect environmental jailbreak (IEJ), a novel attack to jailbreak embodied AI via indirect prompt injected into the environment, such as malicious instructions written on a wall. Our key insight is that embodied AI does not ''think twice'' about the instructions provided by the environment -- a blind trust that attackers can exploit to jailbreak the embodied agent. We further design and implement open-source prototypes of two fully-automated frameworks: SHAWSHANK, the first automatic attack generation framework for the proposed attack IEJ; and SHAWSHANK-FORGE, the first automatic benchmark generation framework for IEJ. Then, using SHAWSHANK-FORGE, we automatically construct SHAWSHANK-BENCH, the first benchmark for indirectly jailbreaking embodied agents. Together, our two frameworks and one benchmark answer the questions of what content can be used for malicious IEJ instructions, where they should be placed, and how IEJ can be systematically evaluated. Evaluation results show that SHAWSHANK outperforms eleven existing methods across 3,957 task-scene combinations and compromises all six tested VLMs. Furthermore, current defenses only partially mitigate our attack, and we have responsibly disclosed our findings to all affected VLM vendors.

</details>


### [19] [Auditable Ledger Snapshot for Non-Repudiable Cross-Blockchain Communication](https://arxiv.org/abs/2511.16560)
*Tirthankar Sengupta,Bishakh Chandra Ghosh,Sandip Chakraborty,Shamik Sural*

Main category: cs.CR

TL;DR: InterSnap是一种区块链快照归档方法，通过跨链交易收据确保跨区块链交易的不可否认性和可审计性，增强系统韧性。


<details>
  <summary>Details</summary>
Motivation: 区块链分类账具有防篡改性，但跨链交易缺乏不可否认性保证，恶意网络可能否认合法索赔或制造欺诈负债。

Method: 引入跨链交易收据作为不可否认证据，采用分布式快照生成、基于需求的快照调度以及通过去中心化平台进行归档存储和共享。

Result: 基于Hyperledger Fabric的原型实验表明，InterSnap能从恶意攻击中恢复并保留跨链交易收据，适应负载增加且安全传输快照档案，开销最小。

Conclusion: InterSnap通过快照归档方法有效解决了跨区块链交易的不可否认性问题，增强了系统安全性和韧性。

Abstract: Blockchain interoperability is increasingly recognized as the centerpiece for robust interactions among decentralized services. Blockchain ledgers are generally tamper-proof and thus enforce non-repudiation for transactions recorded within the same network. However, such a guarantee does not hold for cross-blockchain transactions. When disruptions occur due to malicious activities or system failures within one blockchain network, foreign networks can take advantage by denying legitimate claims or mounting fraudulent liabilities against the defenseless network. In response, this paper introduces InterSnap, a novel blockchain snapshot archival methodology, for enabling auditability of crossblockchain transactions, enforcing non-repudiation. InterSnap introduces cross-chain transaction receipts that ensure their irrefutability. Snapshots of ledger data along with these receipts are utilized as non-repudiable proof of bilateral agreements among different networks. InterSnap enhances system resilience through a distributed snapshot generation process, need-based snapshot scheduling process, and archival storage and sharing via decentralized platforms. Through a prototype implementation based on Hyperledger Fabric, we conducted experiments using on-premise machines, AWS public cloud instances, as well as a private cloud infrastructure. We establish that InterSnap can recover from malicious attacks while preserving crosschain transaction receipts. Additionally, our proposed solution demonstrates adaptability to increasing loads while securely transferring snapshot archives with minimal overhead.

</details>


### [20] [Systematically Deconstructing APVD Steganography and its Payload with a Unified Deep Learning Paradigm](https://arxiv.org/abs/2511.16604)
*Kabbo Jit Deb,Md. Azizul Hakim,Md Shamse Tabrej*

Main category: cs.CR

TL;DR: 提出基于深度学习的自适应像素值差分(APVD)隐写检测和反向隐写分析方法，使用带注意力机制的CNN同时进行隐写检测和载荷恢复，在BOSSbase和UCID数据集上取得96.2%的检测准确率和最高93.6%的载荷恢复率。


<details>
  <summary>Details</summary>
Motivation: 在数字通信时代，APVD隐写方法因其高嵌入容量和不可见性而受到重视，对传统隐写分析构成挑战，需要开发新的检测和逆向分析方法。

Method: 使用带有注意力机制的卷积神经网络(CNN)，配备两个输出头分别用于隐写检测和载荷恢复，在BOSSbase和UCID数据集的10,000张图像上进行训练和验证。

Result: 模型实现了96.2%的隐写检测准确率，在较低嵌入密度下载荷恢复率可达93.6%，结果显示载荷大小与恢复准确率之间存在强逆相关关系。

Conclusion: 本研究揭示了自适应隐写技术的脆弱性，为数字取证分析提供了工具，并促使在AI驱动技术时代重新评估数据安全性。

Abstract: In the era of digital communication, steganography allows covert embedding of data within media files. Adaptive Pixel Value Differencing (APVD) is a steganographic method valued for its high embedding capacity and invisibility, posing challenges for traditional steganalysis. This paper proposes a deep learning-based approach for detecting APVD steganography and performing reverse steganalysis, which reconstructs the hidden payload. We present a Convolutional Neural Network (CNN) with an attention mechanism and two output heads for simultaneous stego detection and payload recovery. Trained and validated on 10,000 images from the BOSSbase and UCID datasets, our model achieves a detection accuracy of 96.2 percent. It also reconstructs embedded payloads with up to 93.6 percent recovery at lower embedding densities. Results indicate a strong inverse relationship between payload size and recovery accuracy. This study reveals a vulnerability in adaptive steganography and provides a tool for digital forensic analysis, while encouraging reassessment of data security in the age of AI-driven techniques.

</details>
