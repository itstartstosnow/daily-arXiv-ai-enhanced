<div id=toc></div>

# Table of Contents

- [cs.CR](#cs.CR) [Total: 17]


<div id='cs.CR'></div>

# cs.CR [[Back]](#toc)

### [1] [LIGHT-HIDS: A Lightweight and Effective Machine Learning-Based Framework for Robust Host Intrusion Detection](https://arxiv.org/abs/2509.13464)
*Onat Gungor,Ishaan Kale,Jiasheng Zhou,Tajana Rosing*

Main category: cs.CR

TL;DR: LIGHT-HIDS是一个轻量级机器学习框架，通过压缩神经网络特征提取器和高效新颖性检测模型，在边缘计算环境中实现实时主机入侵检测，推理时间减少75倍


<details>
  <summary>Details</summary>
Motivation: 边缘计算扩展增加了攻击面，需要实时ML-based主机入侵检测系统，但现有方法计算密集、推理成本高，限制了实际部署

Method: 结合压缩神经网络特征提取器（通过DeepSVDD训练）和高效新颖性检测模型的混合方法，学习正常系统调用行为的紧凑表示

Result: 在多个数据集上实验表明，LIGHT-HIDS持续提高检测精度，同时推理时间比最先进方法减少高达75倍

Conclusion: 该框架作为基于机器学习的实时主机入侵检测解决方案，具有有效性和可扩展性

Abstract: The expansion of edge computing has increased the attack surface, creating an
urgent need for robust, real-time machine learning (ML)-based host intrusion
detection systems (HIDS) that balance accuracy and efficiency. In such
settings, inference latency poses a critical security risk, as delays may
provide exploitable opportunities for attackers. However, many state-of-the-art
ML-based HIDS solutions rely on computationally intensive architectures with
high inference costs, limiting their practical deployment. This paper proposes
LIGHT-HIDS, a lightweight machine learning framework that combines a compressed
neural network feature extractor trained via Deep Support Vector Data
Description (DeepSVDD) with an efficient novelty detection model. This hybrid
approach enables the learning of compact, meaningful representations of normal
system call behavior for accurate anomaly detection. Experimental results on
multiple datasets demonstrate that LIGHT-HIDS consistently enhances detection
accuracy while reducing inference time by up to 75x compared to
state-of-the-art methods. These findings highlight its effectiveness and
scalability as a machine learning-based solution for real-time host intrusion
detection.

</details>


### [2] [Practitioners' Perspectives on a Differential Privacy Deployment Registry](https://arxiv.org/abs/2509.13509)
*Priyanka Nanayakkara,Elena Ghazi,Salil Vadhan*

Main category: cs.CR

TL;DR: 该论文提出了一个差分隐私部署的公共注册表系统，包括分层架构设计和交互界面实现，并通过用户研究验证了其价值。


<details>
  <summary>Details</summary>
Motivation: 差分隐私在实践中的应用需要做出多个实现决策，每个决策都会显著影响数据隐私和效用。为了促进共享学习和问责制，需要建立一个公开的差分隐私部署注册表。

Method: 1) 开发了描述差分隐私部署的整体分层架构；2) 设计并实现了交互式注册表界面；3) 用21个真实部署案例填充系统；4) 对16名从业者进行探索性用户研究

Result: 参与者对注册表作为评估现有部署和规划未来部署的宝贵资源表示热情。注册表可以成为社区中心，支持更广泛的沟通，但也面临采用挑战，包括公开实现选择的努力和风险。

Conclusion: 基于研究发现，提出了促进采用和增加注册表价值的建议，不仅对从业者，也对政策制定者、数据用户和数据主体都有价值。

Abstract: Differential privacy (DP) -- a principled approach to producing statistical
data products with strong, mathematically provable privacy guarantees for the
individuals in the underlying dataset -- has seen substantial adoption in
practice over the past decade. Applying DP requires making several
implementation decisions, each with significant impacts on data privacy and/or
utility. Hence, to promote shared learning and accountability around DP
deployments, Dwork, Kohli, and Mulligan (2019) proposed a public-facing
repository ("registry") of DP deployments. The DP community has recently
started to work toward realizing this vision. We contribute to this effort by
(1) developing a holistic, hierarchical schema to describe any given DP
deployment and (2) designing and implementing an interactive interface to act
as a registry where practitioners can access information about past DP
deployments. We (3) populate our interface with 21 real-world DP deployments
and (4) conduct an exploratory user study with DP practitioners ($n=16$) to
understand how they would use the registry, as well as what challenges and
opportunities they foresee around its adoption. We find that participants were
enthusiastic about the registry as a valuable resource for evaluating prior
deployments and making future deployments. They also identified several
opportunities for the registry, including that it can become a "hub" for the
community and support broader communication around DP (e.g., to legal teams).
At the same time, they identified challenges around the registry gaining
adoption, including the effort and risk involved with making implementation
choices public and moderating the quality of entries. Based on our findings, we
offer recommendations for encouraging adoption and increasing the registry's
value not only to DP practitioners, but also to policymakers, data users, and
data subjects.

</details>


### [3] [AQUA-LLM: Evaluating Accuracy, Quantization, and Adversarial Robustness Trade-offs in LLMs for Cybersecurity Question Answering](https://arxiv.org/abs/2509.13514)
*Onat Gungor,Roshan Sood,Harold Wang,Tajana Rosing*

Main category: cs.CR

TL;DR: AQUA-LLM框架评估量化与微调组合对小型LLM在网络安全问答中的效果，发现量化+微调组合在准确性、鲁棒性和效率间达到最佳平衡


<details>
  <summary>Details</summary>
Motivation: LLM在网络安全问答中潜力巨大但计算需求高，量化可压缩模型但可能降低准确性和鲁棒性，微调效果与量化结合的研究不足

Method: 提出AQUA-LLM评估框架，在四种配置下（基础、仅量化、仅微调、量化+微调）对多个先进小型LLM进行基准测试

Result: 仅量化准确性和鲁棒性最低但效率提升；量化与微调结合可同时增强LLM鲁棒性和预测性能

Conclusion: 需要量化感知、保持鲁棒性的微调方法来实现LLM在网络安全问答中的稳健高效部署

Abstract: Large Language Models (LLMs) have recently demonstrated strong potential for
cybersecurity question answering (QA), supporting decision-making in real-time
threat detection and response workflows. However, their substantial
computational demands pose significant challenges for deployment on
resource-constrained edge devices. Quantization, a widely adopted model
compression technique, can alleviate these constraints. Nevertheless,
quantization may degrade model accuracy and increase susceptibility to
adversarial attacks. Fine-tuning offers a potential means to mitigate these
limitations, but its effectiveness when combined with quantization remains
insufficiently explored. Hence, it is essential to understand the trade-offs
among accuracy, efficiency, and robustness. We propose AQUA-LLM, an evaluation
framework designed to benchmark several state-of-the-art small LLMs under four
distinct configurations: base, quantized-only, fine-tuned, and fine-tuned
combined with quantization, specifically for cybersecurity QA. Our results
demonstrate that quantization alone yields the lowest accuracy and robustness
despite improving efficiency. In contrast, combining quantization with
fine-tuning enhances both LLM robustness and predictive performance, achieving
an optimal balance of accuracy, robustness, and efficiency. These findings
highlight the critical need for quantization-aware, robustness-preserving
fine-tuning methodologies to enable the robust and efficient deployment of LLMs
for cybersecurity QA.

</details>


### [4] [GuardianPWA: Enhancing Security Throughout the Progressive Web App Installation Lifecycle](https://arxiv.org/abs/2509.13561)
*Mengxiao Wang,Guofei Gu*

Main category: cs.CR

TL;DR: GUARDIANPWA框架分析PWA安装机制的安全性，基于CIA安全原则发现203个违规实例，报告给浏览器厂商后获得积极回应，帮助开发者提升PWA安全性。


<details>
  <summary>Details</summary>
Motivation: PWA安装对整合网页和移动应用功能至关重要，但需要确保安装生命周期的安全性以维护用户信任和隐私。现有浏览器厂商在PWA安装机制中存在安全原则合规性问题。

Method: 提出GUARDIANPWA框架，基于CIA安全原则（机密性、完整性、可用性）分析PWA安装机制，识别浏览器厂商的合规性失败点，并分析PWA清单文件的语法和语义正确性。

Result: 发现203个安全原则违规实例，包括Firefox隐私模式问题（机密性风险）和Samsung Internet来源显示问题（完整性风险）。29,465个PWA面临风险。报告后Firefox承认4个问题，解决1个，计划解决2个。

Conclusion: GUARDIANPWA框架能有效识别PWA安装生命周期中的安全漏洞，帮助开发者和用户解决关键安全问题，提升对CIA原则的合规性，促进更安全的PWA开发实践。

Abstract: Progressive Web App (PWA) installation is critical for integrating web and
mobile app functionalities, offering a seamless user experience. However,
ensuring the security of the PWA installation lifecycle is essential for
maintaining user trust and privacy. This paper introduces the GUARDIANPWA
framework, a comprehensive approach to analyzing the PWA installation mechanism
based on the CIA security principles (Confidentiality, Integrity, and
Availability) and identifying areas where browser vendors fail to comply with
these principles. Our study revealed 203 instances of non-compliance with
security principles, highlighting how these irregularities in the PWA
installation lifecycle can lead to potential violations of user privacy. For
instance, in Firefox, PWAs installed in private mode incorrectly appear in
normal mode, risking user confidentiality. Additionally, 29,465 PWAs are at
risk because Samsung Internet does not display origins when PWAs navigate to
third-party websites, undermining integrity. These findings were reported to
browser vendors, leading to Firefox acknowledging four issues, resolving one,
and planning to resolve two others. GUARDIANPWA supports developers by
analyzing PWA manifest files for syntactic and semantic correctness, offering
actionable recommendations, and helping to create PWAs that align with security
best practices. By using GUARDIANPWA, developers and users can address critical
security gaps and enhance compliance with CIA principles throughout the PWA
installation lifecycle.

</details>


### [5] [Demystifying Progressive Web Application Permission Systems](https://arxiv.org/abs/2509.13563)
*Mengxiao Wang,Guofei Gu*

Main category: cs.CR

TL;DR: 对PWA权限管理的研究发现存在不一致性、不完整性和边界模糊等关键问题，导致权限泄露、设备识别和权限API滥用等攻击。通过与浏览器厂商合作，部分问题已得到解决。


<details>
  <summary>Details</summary>
Motivation: 现代PWA被授予系统级能力（如自动启动、与原生应用共享上下文），但其权限管理在不同平台和浏览器中定义不清且实现不一致，存在安全风险。

Method: 开发了跨平台分析工具Permissioner，对PWA权限进行系统性研究，分析权限执行中的不一致性、不完整性和边界模糊问题。

Result: 发现了导致权限泄露、设备识别和权限API滥用的多种攻击向量，揭示了浏览器在采用更细粒度权限控制时面临的可用性、兼容性和平台限制等权衡问题。

Conclusion: 研究强调了为PWA建立统一、健壮的权限模型的紧迫性，并提供了实现这一目标的可操作指导，部分发现的问题已得到Firefox和Chrome的确认和修复。

Abstract: Progressive Web Applications (PWAs) blend the advantages of web and native
apps, offering features like offline access, push notifications, and
installability. Beyond these, modern PWAs are increasingly granted system-level
capabilities such as auto-start on login and shared context with native
applications. However, their permission management remains poorly defined and
inconsistently implemented across platforms and browsers.
  To investigate these gaps, we developed Permissioner, a cross-platform
analysis tool, and conducted a systematic study of PWA permissions. Our
analysis uncovered critical issues of inconsistency, incompleteness, and
unclear boundaries in permission enforcement, leading to various attacks
including permission leakage, device identification, and Permission API abuse.
We further examined why some browsers resist adopting more granular permission
controls, identifying trade-offs involving usability, compatibility, and
platform limitations. Through collaboration with browser vendors, several
issues reported in our findings were acknowledged and resolved, notably by
Firefox and Chrome. Our work highlights the urgent need for a unified, robust
permission model for PWAs and provides actionable guidance toward achieving
this goal.

</details>


### [6] [Invisible Ears at Your Fingertips: Acoustic Eavesdropping via Mouse Sensors](https://arxiv.org/abs/2509.13581)
*Mohamad Fakih,Rahul Dharmaji,Youssef Mahmoud,Halima Bouzidi,Mohammad Abdullah Al Faruque*

Main category: cs.CR

TL;DR: Mic-E-Mouse是一种新型侧信道攻击，利用高性能光学鼠标传感器通过表面振动窃听音频信号，无需系统权限即可在用户空间收集敏感数据。


<details>
  <summary>Details</summary>
Motivation: 现代光学鼠标传感器具有高精度和响应性，但存在被利用进行侧信道攻击的潜在漏洞，研究人员希望探索这种被忽视的攻击向量。

Method: 通过音频信号诱导表面振动，利用鼠标光学传感器检测这些振动，并采用包含维纳滤波、重采样校正和编码器-频谱图神经滤波技术的端到端数据过滤管道来处理非均匀采样和非线性频率响应问题。

Result: 在受控环境中，语音重建的信噪比提升高达+19dB，在AudioMNIST和VCTK数据集上的语音识别准确率达到42%到61%。

Conclusion: 光学鼠标传感器确实存在被用于音频窃听的侧信道漏洞，这种攻击在用户空间即可实施，无需系统级权限，对隐私安全构成新的威胁。

Abstract: Modern optical mouse sensors, with their advanced precision and high
responsiveness, possess an often overlooked vulnerability: they can be
exploited for side-channel attacks. This paper introduces Mic-E-Mouse, the
first-ever side-channel attack that targets high-performance optical mouse
sensors to covertly eavesdrop on users. We demonstrate that audio signals can
induce subtle surface vibrations detectable by a mouse's optical sensor.
Remarkably, user-space software on popular operating systems can collect and
broadcast this sensitive side channel, granting attackers access to raw mouse
data without requiring direct system-level permissions. Initially, the
vibration signals extracted from mouse data are of poor quality due to
non-uniform sampling, a non-linear frequency response, and significant
quantization. To overcome these limitations, Mic-E-Mouse employs a
sophisticated end-to-end data filtering pipeline that combines Wiener
filtering, resampling corrections, and an innovative encoder-only spectrogram
neural filtering technique. We evaluate the attack's efficacy across diverse
conditions, including speaking volume, mouse polling rate and DPI, surface
materials, speaker languages, and environmental noise. In controlled
environments, Mic-E-Mouse improves the signal-to-noise ratio (SNR) by up to +19
dB for speech reconstruction. Furthermore, our results demonstrate a speech
recognition accuracy of roughly 42% to 61% on the AudioMNIST and VCTK datasets.
All our code and datasets are publicly accessible on
https://sites.google.com/view/mic-e-mouse.

</details>


### [7] [Agentic JWT: A Secure Delegation Protocol for Autonomous AI Agents](https://arxiv.org/abs/2509.13597)
*Abhishek Goswami*

Main category: cs.CR

TL;DR: 提出Agentic JWT（A-JWT）安全框架，为自主LLM代理提供身份验证和授权机制，防止权限扩展攻击，在商品硬件上实现亚毫秒级开销。


<details>
  <summary>Details</summary>
Motivation: 自主LLM代理每小时可发出数千次API调用而无人工监督，OAuth 2.0假设确定性客户端，但在代理环境中，随机推理、提示注入或多代理编排可能静默扩展权限，需要新的安全机制。

Method: 引入双方面意图令牌A-JWT，绑定代理操作到可验证用户意图和特定工作流步骤。包含代理身份的单向校验和哈希、链式委托断言和每代理持有证明密钥，防止重放和进程内冒充。

Result: 实现了功能性的范围违规请求阻止、重放攻击防护、冒充攻击防护和提示注入路径防护，在商品硬件上实现亚毫秒级开销。

Conclusion: 该设计与正在进行的OAuth代理讨论保持一致，为零信任保证提供即插即用路径，适用于代理应用程序的安全身份和分离。

Abstract: Autonomous LLM agents can issue thousands of API calls per hour without human
oversight. OAuth 2.0 assumes deterministic clients, but in agentic settings
stochastic reasoning, prompt injection, or multi-agent orchestration can
silently expand privileges.
  We introduce Agentic JWT (A-JWT), a dual-faceted intent token that binds each
agent's action to verifiable user intent and, optionally, to a specific
workflow step. A-JWT carries an agent's identity as a one-way checksum hash
derived from its prompt, tools and configuration, and a chained delegation
assertion to prove which downstream agent may execute a given task, and
per-agent proof-of-possession keys to prevent replay and in-process
impersonation. We define a new authorization mechanism and add a lightweight
client shim library that self-verifies code at run time, mints intent tokens,
tracks workflow steps and derives keys, thus enabling secure agent identity and
separation even within a single process.
  We illustrate a comprehensive threat model for agentic applications,
implement a Python proof-of-concept and show functional blocking of
scope-violating requests, replay, impersonation, and prompt-injection pathways
with sub-millisecond overhead on commodity hardware. The design aligns with
ongoing OAuth agent discussions and offers a drop-in path toward zero-trust
guarantees for agentic applications. A comprehensive performance and security
evaluation with experimental results will appear in our forthcoming journal
publication

</details>


### [8] [Secure, Scalable and Privacy Aware Data Strategy in Cloud](https://arxiv.org/abs/2509.13627)
*Vijay Kumar Butte,Sujata Butte*

Main category: cs.CR

TL;DR: 本文针对企业处理海量数据的安全、可扩展性挑战，提出了一种有效的云端企业数据策略，包含安全、可扩展性和隐私保护的架构方案。


<details>
  <summary>Details</summary>
Motivation: 企业面临处理、存储海量数据的安全性和可扩展性挑战，需要支持决策者快速做出数据驱动的决策。

Method: 讨论了有效数据策略的各个组件，并提供了解决安全性、可扩展性和隐私方面的架构设计。

Result: 开发了一套完整的云端企业数据策略方案，能够满足企业对数据处理的安全、可扩展和隐私保护需求。

Conclusion: 提出的云端数据策略有效解决了企业在大数据处理中的安全、扩展性和隐私问题，为数据驱动决策提供了可靠支撑。

Abstract: The enterprises today are faced with the tough challenge of processing,
storing large amounts of data in a secure, scalable manner and enabling
decision makers to make quick, informed data driven decisions. This paper
addresses this challenge and develops an effective enterprise data strategy in
the cloud. Various components of an effective data strategy are discussed and
architectures addressing security, scalability and privacy aspects are
provided.

</details>


### [9] [Publicly Verifiable Private Information Retrieval Protocols Based on Function Secret Sharing](https://arxiv.org/abs/2509.13684)
*Lin Zhu,Lingwei Kong,Xin Ning,Xiaoyang Qu,Jianzong Wang*

Main category: cs.CR

TL;DR: 提出了两种多服务器环境下公开可验证的私有信息检索（PVPIR）构造方案，支持点查询和谓词查询，在保证查询隐私、正确性和可验证性的同时，显著降低了通信开销。


<details>
  <summary>Details</summary>
Motivation: 私有信息检索（PIR）需要解决结果可验证性问题，确保用户能够验证检索数据的真实性和可信度，而现有方法如Merkle树存在通信开销大的问题。

Method: 设计了两种多服务器PVPIR构造方案，并基于此给出了三个具体实现：点查询方案计算开销小且通信成本低；谓词查询方案通信复杂度与数据库大小无关，具有良好的可扩展性。

Result: 点查询方案相比现有Merkle树方法显著降低了通信成本；谓词查询方案的通信复杂度稳定，适合大规模私有查询应用。

Conclusion: 所提出的PVPIR方案在保证隐私和可验证性的同时，有效解决了通信开销问题，为大规模私有查询应用提供了实用的解决方案。

Abstract: Private Information Retrieval (PIR) is a fundamental cryptographic primitive
that enables users to retrieve data from a database without revealing which
item is being accessed, thereby preserving query privacy. However, PIR
protocols also face the challenge of result verifiability, as users expect the
reconstructed data to be trustworthy and authentic. In this work, we propose
two effective constructions of publicly verifiable PIR (PVPIR) in the
multi-server setting, which achieve query privacy, correctness, and
verifiability simultaneously. We further present three concrete instantiations
based on these constructions. For the point query, our protocol introduces
minimal computational overhead and achieves strong verifiability guarantees
with significantly lower communication costs compared to existing Merkle
tree-based approaches. For the predicate query, the communication complexity of
our scheme remains stable as the database size increases, demonstrating strong
scalability and suitability for large-scale private query applications.

</details>


### [10] [Protocol-Aware Firmware Rehosting for Effective Fuzzing of Embedded Network Stacks](https://arxiv.org/abs/2509.13740)
*Moritz Bley,Tobias Scharnowski,Simon Wörner,Moritz Schloegel,Thorsten Holz*

Main category: cs.CR

TL;DR: Pemu是一个自动检测和处理固件中网络协议使用的新方法，通过自动推断可用网络协议并透明生成有效网络数据包，使模糊测试输入能够直接流入固件逻辑的更深层。


<details>
  <summary>Details</summary>
Motivation: 嵌入式系统的网络接口是最大的攻击面之一，但现有重托管方法难以有效探索网络堆栈，限制了发现深层软件故障的能力。

Method: 通过自动推断可用网络协议，透明生成封装模糊测试数据的有效网络数据包，实现逐层深度分析固件组件。

Result: Pemu持续提高了三个现有重托管工具的代码覆盖率，重新发现了多个已知漏洞并识别了五个先前未知的软件故障。

Conclusion: 该方法有效揭示了网络暴露代码中深层嵌套的漏洞，为嵌入式系统网络安全评估提供了更深入、更有针对性的分析能力。

Abstract: One of the biggest attack surfaces of embedded systems is their network
interfaces, which enable communication with other devices. Unlike their
general-purpose counterparts, embedded systems are designed for specialized use
cases, resulting in unique and diverse communication stacks. Unfortunately,
current approaches for evaluating the security of these embedded network stacks
require manual effort or access to hardware, and they generally focus only on
small parts of the embedded system. A promising alternative is firmware
rehosting, which enables fuzz testing of the entire firmware by generically
emulating the physical hardware. However, existing rehosting methods often
struggle to meaningfully explore network stacks due to their complex,
multi-layered input formats. This limits their ability to uncover deeply nested
software faults.
  To address this problem, we introduce a novel method to automatically detect
and handle the use of network protocols in firmware called Pemu. By
automatically deducing the available network protocols, Pemu can transparently
generate valid network packets that encapsulate fuzzing data, allowing the
fuzzing input to flow directly into deeper layers of the firmware logic. Our
approach thus enables a deeper, more targeted, and layer-by-layer analysis of
firmware components that were previously difficult or impossible to test. Our
evaluation demonstrates that Pemu consistently improves the code coverage of
three existing rehosting tools for embedded network stacks. Furthermore, our
fuzzer rediscovered several known vulnerabilities and identified five
previously unknown software faults, highlighting its effectiveness in
uncovering deeply nested bugs in network-exposed code.

</details>


### [11] [Who Taught the Lie? Responsibility Attribution for Poisoned Knowledge in Retrieval-Augmented Generation](https://arxiv.org/abs/2509.13772)
*Baolei Zhang,Haoran Xin,Yuxi Chen,Zhuqing Liu,Biao Yi,Tong Li,Lihai Nie,Zheli Liu,Minghong Fang*

Main category: cs.CR

TL;DR: RAGOrigin是一个黑盒责任归属框架，用于识别RAG系统中导致错误生成的污染文本，通过检索排名、语义相关性和生成影响评估来定位污染源。


<details>
  <summary>Details</summary>
Motivation: 现有的RAG系统防御机制容易被自适应攻击绕过，需要一种能够有效追溯污染知识来源的方法来增强系统安全性。

Method: 构建针对每个错误生成事件的聚焦归属范围，通过评估候选文本的检索排名、语义相关性和对生成响应的影响来分配责任分数，并使用无监督聚类方法隔离污染文本。

Result: 在7个数据集和15种污染攻击（包括新开发的自适应攻击和多攻击者场景）上评估，RAGOrigin在识别污染内容方面优于现有基线方法，在动态和嘈杂条件下保持鲁棒性。

Conclusion: RAGOrigin为追踪RAG系统中污染知识的来源提供了实用有效的解决方案，能够显著提升系统的安全性和可靠性。

Abstract: Retrieval-Augmented Generation (RAG) integrates external knowledge into large
language models to improve response quality. However, recent work has shown
that RAG systems are highly vulnerable to poisoning attacks, where malicious
texts are inserted into the knowledge database to influence model outputs.
While several defenses have been proposed, they are often circumvented by more
adaptive or sophisticated attacks.
  This paper presents RAGOrigin, a black-box responsibility attribution
framework designed to identify which texts in the knowledge database are
responsible for misleading or incorrect generations. Our method constructs a
focused attribution scope tailored to each misgeneration event and assigns a
responsibility score to each candidate text by evaluating its retrieval
ranking, semantic relevance, and influence on the generated response. The
system then isolates poisoned texts using an unsupervised clustering method. We
evaluate RAGOrigin across seven datasets and fifteen poisoning attacks,
including newly developed adaptive poisoning strategies and multi-attacker
scenarios. Our approach outperforms existing baselines in identifying poisoned
content and remains robust under dynamic and noisy conditions. These results
suggest that RAGOrigin provides a practical and effective solution for tracing
the origins of corrupted knowledge in RAG systems.

</details>


### [12] [Homomorphic encryption schemes based on coding theory and polynomials](https://arxiv.org/abs/2509.13788)
*Giovanni Giuseppe Grimaldi*

Main category: cs.CR

TL;DR: 同态加密综述：基于编码理论和多项式的同态加密方案现状


<details>
  <summary>Details</summary>
Motivation: 同态加密是一种强大的密码学工具，能够在不知道明文的情况下对加密数据安全执行任何函数操作，这对于云环境中敏感应用的数据隐私保护至关重要

Method: 本文是一篇综述性论文，系统整理了基于编码理论和多项式方法的同态加密方案，分析其数学基础和实现原理

Result: 总结了当前已知的同态加密方案，包括部分同态、有限同态和完全同态三种形式，重点介绍了基于编码理论和多项式构造的方案

Conclusion: 同态加密是保护云端数据隐私的重要技术，基于编码理论和多项式的方法为构建安全高效的同态加密方案提供了理论基础

Abstract: Homomorphic encryption is a powerful cryptographic tool that enables secure
computations on the private data. It evaluates any function for any operation
securely on the encrypted data without knowing its corresponding plaintext. For
original data $p$, $c$ denotes the ciphertext of the original plaintext $p$,
i.e. $c = Encrypt_k(p)$. This is crucial for any sensitive application running
in the Cloud, because we must protect data privacy even in the case when the
server has falled victim to a cyber attack. The encryption scheme $Encrypt_k$
is said to be homomorphic with respect to some set of operations $\mathcal{O}$,
if for any operation $\circ \in \mathcal{O}$ one can compute $Encrypt_k(p_1
\circ p_2)$ from $Encrypt_k(p_1) \circ Encrypt_k(p_2)$. Those schemes come in
three forms: somewhat, partially and fully homomorphic. In this survey, we
present the state of art of the known homomorphic encryption schemes based on
coding theory and polynomials.

</details>


### [13] [A Survey and Evaluation Framework for Secure DNS Resolution](https://arxiv.org/abs/2509.13797)
*Ali Sadeghi Jahromi,AbdelRahman Abdou,Paul C. van Oorschot*

Main category: cs.CR

TL;DR: 本文对DNS安全方案进行系统性分析，提出了14个安全属性评估框架，评估12种方案后发现单一方案无法提供完整保护，建议组合使用互补方案来实现全面的DNS解析安全。


<details>
  <summary>Details</summary>
Motivation: 由于DNS最初设计时未考虑安全性，现有各种安全增强方案要么试图完全替换DNS基础设施（未成功），要么在不改变基本两阶段结构的前提下改进安全。需要系统分析这些方案的有效性和互补性。

Method: 建立全面的DNS威胁模型和攻击分类法，制定14个安全、隐私和可用性属性作为评估标准，对12种安全DNS方案进行客观比较分析。

Result: 评估显示没有任何单一方案能在整个解析路径上提供理想保护，各方案倾向于针对特定阶段的属性子集。针对不同阶段的方案具有互补性，可以协同工作。

Conclusion: 组合使用兼容的DNS安全方案是实现DNS解析过程全面安全的实用有效方法，不同阶段的方案可以相互补充形成完整保护。

Abstract: Since security was not among the original design goals of the Domain Name
System (herein called Vanilla DNS), many secure DNS schemes have been proposed
to enhance the security and privacy of the DNS resolution process. Some
proposed schemes aim to replace the existing DNS infrastructure entirely, but
none have succeeded in doing so. In parallel, numerous schemes focus on
improving DNS security without modifying its fundamental two-stage structure.
These efforts highlight the feasibility of addressing DNS security as two
distinct but compatible stages. We survey DNS resolution process attacks and
threats and develop a comprehensive threat model and attack taxonomy for their
systematic categorization. This analysis results in the formulation of 14
desirable security, privacy, and availability properties to mitigate the
identified threats. Using these properties, we develop an objective evaluation
framework and apply it to comparatively analyze 12 secure DNS schemes surveyed
in this work that aim to augment the properties of the DNS resolution process.
Our evaluation reveals that no single scheme provides ideal protection across
the entire resolution path. Instead, the schemes tend to address a subset of
properties specific to individual stages. Since these schemes targeting
different stages of DNS resolution are complementary and can operate together,
combining compatible schemes offers a practical and effective approach to
achieving comprehensive security in the DNS resolution process.

</details>


### [14] [Differential Privacy in Federated Learning: Mitigating Inference Attacks with Randomized Response](https://arxiv.org/abs/2509.13987)
*Ozer Ozturk,Busra Buyuktanir,Gozde Karatas Baydogmus,Kazim Yildiz*

Main category: cs.CR

TL;DR: 本研究探讨了在联邦学习架构中应用差分隐私技术来解决模型推理攻击导致的数据泄露问题，分析了不同隐私级别下安全性与模型性能之间的权衡关系


<details>
  <summary>Details</summary>
Motivation: 联邦学习虽然避免了原始数据离开客户端，但攻击者仍可通过推理攻击从模型参数中近似还原训练数据，存在数据泄露风险，需要增强隐私保护机制

Method: 采用差分隐私技术，使用随机响应方法对数据进行隐私处理，以duCBA算法作为联邦聚合方法，在不同epsilon值下测试隐私保护效果

Result: 随着epsilon值减小（隐私级别提高），模型准确率下降，出现类别预测不平衡现象，表明更高的隐私保护水平并不总能带来实用结果

Conclusion: 在联邦学习中实施差分隐私时，需要仔细权衡安全性和性能之间的平衡，过高的隐私保护级别可能导致模型实用性下降

Abstract: Machine learning models used for distributed architectures consisting of
servers and clients require large amounts of data to achieve high accuracy.
Data obtained from clients are collected on a central server for model
training. However, storing data on a central server raises concerns about
security and privacy. To address this issue, a federated learning architecture
has been proposed. In federated learning, each client trains a local model
using its own data. The trained models are periodically transmitted to the
central server. The server then combines the received models using federated
aggregation algorithms to obtain a global model. This global model is
distributed back to the clients, and the process continues in a cyclical
manner. Although preventing data from leaving the clients enhances security,
certain concerns still remain. Attackers can perform inference attacks on the
obtained models to approximate the training dataset, potentially causing data
leakage. In this study, differential privacy was applied to address the
aforementioned security vulnerability, and a performance analysis was
conducted. The Data-Unaware Classification Based on Association (duCBA)
algorithm was used as the federated aggregation method. Differential privacy
was implemented on the data using the Randomized Response technique, and the
trade-off between security and performance was examined under different epsilon
values. As the epsilon value decreased, the model accuracy declined, and class
prediction imbalances were observed. This indicates that higher levels of
privacy do not always lead to practical outcomes and that the balance between
security and performance must be carefully considered.

</details>


### [15] [Piquant$\varepsilon$: Private Quantile Estimation in the Two-Server Model](https://arxiv.org/abs/2509.14035)
*Hannah Keller,Jacob Imola,Fabrizio Boninsegna,Rasmus Pagh,Amrita Roy Chowdhury*

Main category: cs.CR

TL;DR: Piquantε是一个分布式隐私保护分位数估计系统，在恶意威胁模型下实现中心差分隐私的准确性，无需可信服务器，通过两服务器模型和中间统计信息发布策略显著提升精度和效率。


<details>
  <summary>Details</summary>
Motivation: 分布式分析中分位数计算对敏感数据存在隐私风险，本地差分隐私精度低，中心差分隐私需要可信聚合器，安全多方计算面临可扩展性挑战，需要一种既能保护隐私又具有高精度的解决方案。

Method: 基于两服务器模型，采用新颖的中间统计信息发布策略，减少安全多方计算的复杂度，同时保持端到端差分隐私保护，在恶意威胁模型下运行。

Result: 在100万条记录、域大小10^9的数据集上，1分钟内估计5个分位数，精度比本地差分隐私提高10^4倍，运行时间比基线快约10倍。

Conclusion: Piquantε成功实现了在分布式环境下无需可信服务器的隐私保护分位数估计，达到了中心差分隐私的精度水平，同时解决了安全多方计算的可扩展性问题。

Abstract: Quantiles are key in distributed analytics, but computing them over sensitive
data risks privacy. Local differential privacy (LDP) offers strong protection
but lower accuracy than central DP, which assumes a trusted aggregator. Secure
multi-party computation (MPC) can bridge this gap, but generic MPC solutions
face scalability challenges due to large domains, complex secure operations,
and multi-round interactions.
  We present Piquant$\varepsilon$, a system for privacy-preserving estimation
of multiple quantiles in a distributed setting without relying on a trusted
server. Piquant$\varepsilon$ operates under the malicious threat model and
achieves accuracy of the central DP model. Built on the two-server model,
Piquant$\varepsilon$ uses a novel strategy of releasing carefully chosen
intermediate statistics, reducing MPC complexity while preserving end-to-end
DP. Empirically, Piquant$\varepsilon$ estimates 5 quantiles on 1 million
records in under a minute with domain size $10^9$, achieving up to $10^4$-fold
higher accuracy than LDP, and up to $\sim 10\times$ faster runtime compared to
baselines.

</details>


### [16] [The Cybersecurity of a Humanoid Robot](https://arxiv.org/abs/2509.14096)
*Víctor Mayoral-Vilches*

Main category: cs.CR

TL;DR: 对Unitree G1人形机器人平台的安全评估发现其存在严重漏洞，包括静态加密密钥和未经用户同意的持续遥测数据传输，提出了需要转向网络安全AI框架的新范式。


<details>
  <summary>Details</summary>
Motivation: 现有理论框架无法充分应对人形机器人快速发展带来的网络安全挑战，需要弥抽象安全模型与实际操作漏洞之间的差距。

Method: 通过系统静态分析、运行时观察和密码学检查，对生产级人形机器人平台进行全面安全评估，并在Unitree G1上部署网络安全AI代理进行漏洞利用映射。

Result: 发现了复杂的双层专有加密系统(FMX')存在根本性实现缺陷，包括使用静态加密密钥；记录了持续向外部服务器传输详细机器人状态信息（音频、视觉、空间和执行器数据）的遥测连接；展示了被入侵人形机器人如何从隐蔽数据收集升级到主动反制操作。

Conclusion: 保护人形机器人需要向网络安全AI(CAI)框架进行范式转变，以适应物理-网络融合的独特挑战，为开发强大安全标准提供了实证证据。

Abstract: The rapid advancement of humanoid robotics presents unprecedented
cybersecurity challenges that existing theoretical frameworks fail to
adequately address. This report presents a comprehensive security assessment of
a production humanoid robot platform, bridging the gap between abstract
security models and operational vulnerabilities. Through systematic static
analysis, runtime observation, and cryptographic examination, we uncovered a
complex security landscape characterized by both sophisticated defensive
mechanisms and critical vulnerabilities. Our findings reveal a dual-layer
proprietary encryption system (designated FMX') that, while innovative in
design, suffers from fundamental implementation flaws including the use of
static cryptographic keys that enable offline configuration decryption. More
significantly, we documented persistent telemetry connections transmitting
detailed robot state information--including audio, visual, spatial, and
actuator data--to external servers without explicit user consent or
notification mechanisms. We operationalized a Cybersecurity AI agent on the
Unitree G1 to map and prepare exploitation of its manufacturer's cloud
infrastructure, illustrating how a compromised humanoid can escalate from
covert data collection to active counter-offensive operations. We argue that
securing humanoid robots requires a paradigm shift toward Cybersecurity AI
(CAI) frameworks that can adapt to the unique challenges of physical-cyber
convergence. This work contributes empirical evidence for developing robust
security standards as humanoid robots transition from research curiosities to
operational systems in critical domains.

</details>


### [17] [Cybersecurity AI: Humanoid Robots as Attack Vectors](https://arxiv.org/abs/2509.14139)
*Víctor Mayoral-Vilches*

Main category: cs.CR

TL;DR: 对Unitree G1人形机器人的安全评估显示其具有隐蔽监控功能和主动网络攻击能力，存在严重隐私和安全风险


<details>
  <summary>Details</summary>
Motivation: 评估商业化人形机器人的安全架构，揭示其作为潜在监控节点和网络攻击平台的安全隐患

Method: 通过部分逆向工程Unitree的专有FMX加密协议，分析其静态Blowfish-ECB层和可预测LCG掩码，并进行两个实证案例研究

Result: 发现机器人每300秒向特定IP地址泄露多模态传感器数据，违反GDPR；内置网络安全AI代理可从侦察升级为主动攻击操作

Conclusion: 人形机器人进入关键基础设施需要自适应网络安全AI防御，为物理-网络融合系统的未来安全标准提供实证依据

Abstract: We present a systematic security assessment of the Unitree G1 humanoid
showing it operates simultaneously as a covert surveillance node and can be
purposed as an active cyber operations platform. Partial reverse engineering of
Unitree's proprietary FMX encryption reveal a static Blowfish-ECB layer and a
predictable LCG mask-enabled inspection of the system's otherwise sophisticated
security architecture, the most mature we have observed in commercial robotics.
Two empirical case studies expose the critical risk of this humanoid robot: (a)
the robot functions as a trojan horse, continuously exfiltrating multi-modal
sensor and service-state telemetry to 43.175.228.18:17883 and
43.175.229.18:17883 every 300 seconds without operator notice, creating
violations of GDPR Articles 6 and 13; (b) a resident Cybersecurity AI (CAI)
agent can pivot from reconnaissance to offensive preparation against any
target, such as the manufacturer's cloud control plane, demonstrating
escalation from passive monitoring to active counter-operations. These findings
argue for adaptive CAI-powered defenses as humanoids move into critical
infrastructure, contributing the empirical evidence needed to shape future
security standards for physical-cyber convergence systems.

</details>
