<div id=toc></div>

# Table of Contents

- [cs.CR](#cs.CR) [Total: 24]


<div id='cs.CR'></div>

# cs.CR [[Back]](#toc)

### [1] [Establishing a Baseline of Software Supply Chain Security Task Adoption by Software Organizations](https://arxiv.org/abs/2509.08083)
*Laurie Williams,Sammy Migues*

Main category: cs.CR

TL;DR: 这篇论文通过采访研究分析了软件供应链安全任务的采用情况，建议优先采用0新兴攻击向量的安全任务


<details>
  <summary>Details</summary>
Motivation: 软件供应链攻击快速增长，但完全采用所有安全框架任务不可行，需要优先级指导

Method: 对61名从事软件供应链风险管理的实践者进行访谈研究，涵盖9家软件开发组织

Result: 组织已实施最常采用的安全任务，但对付通过软件组件和构建基础设施的新兴攻击向量的防范任务仍处于早期阶段

Conclusion: 应优先采用0防范软件组件和构建基础设施攻击的安全任务，这些新兴风险需要更多关注

Abstract: Software supply chain attacks have increased exponentially since 2020. The
primary attack vectors for supply chain attacks are through: (1) software
components; (2) the build infrastructure; and (3) humans (a.k.a software
practitioners). Software supply chain risk management frameworks provide a list
of tasks that an organization can adopt to reduce software supply chain risk.
Exhaustively adopting all the tasks of these frameworks is infeasible,
necessitating the prioritized adoption of tasks. Software organizations can
benefit from being guided in this prioritization by learning what tasks other
teams have adopted. The goal of this study is to aid software development
organizations in understanding the adoption of security tasks that reduce
software supply chain risk through an interview study of software practitioners
engaged in software supply chain risk management efforts. An interview study
was conducted with 61 practitioners at nine software development organizations
that have focused efforts on reducing software supply chain risk. The results
of the interviews indicate that organizations had implemented the most adopted
software tasks before the focus on software supply chain security. Therefore,
their implementation in organizations is more mature. The tasks that mitigate
the novel attack vectors through software components and the build
infrastructure are in the early stages of adoption. Adoption of these tasks
should be prioritized.

</details>


### [2] [SAGE: Sample-Aware Guarding Engine for Robust Intrusion Detection Against Adversarial Attacks](https://arxiv.org/abs/2509.08091)
*Jing Chen,Onat Gungor,Zhengli Shang,Tajana Rosing*

Main category: cs.CR

TL;DR: SAGE是一种改进的对抗性攻击防御算法，通过主动学习和目标数据缩减来增强ML入侵检测系统的鲁棒性，显著提升性能并降低计算开销


<details>
  <summary>Details</summary>
Motivation: 物联网安全漏洞日益严重，机器学习入侵检测系统容易受到对抗性攻击，现有防御机制缺乏针对特定攻击的系统性选择方法

Method: 集成主动学习与目标数据缩减，通过主动学习机制选择最具信息量的样本和最优防御标签，训练二级学习器来选择最有效防御

Result: 在多个入侵检测数据集上平均F1分数提升201%，性能与Oracle差距缩小至3.8%，计算开销降低达29倍

Conclusion: SAGE通过智能样本选择和防御优化，显著提升了ML-IDS的对抗性攻击防御能力，具有优异的性能和效率

Abstract: The rapid proliferation of the Internet of Things (IoT) continues to expose
critical security vulnerabilities, necessitating the development of efficient
and robust intrusion detection systems (IDS). Machine learning-based intrusion
detection systems (ML-IDS) have significantly improved threat detection
capabilities; however, they remain highly susceptible to adversarial attacks.
While numerous defense mechanisms have been proposed to enhance ML-IDS
resilience, a systematic approach for selecting the most effective defense
against a specific adversarial attack remains absent. To address this
challenge, we previously proposed DYNAMITE, a dynamic defense selection
approach that identifies the most suitable defense against adversarial attacks
through an ML-driven selection mechanism. Building on this foundation, we
propose SAGE (Sample-Aware Guarding Engine), a substantially improved defense
algorithm that integrates active learning with targeted data reduction. It
employs an active learning mechanism to selectively identify the most
informative input samples and their corresponding optimal defense labels, which
are then used to train a second-level learner responsible for selecting the
most effective defense. This targeted sampling improves computational
efficiency, exposes the model to diverse adversarial strategies during
training, and enhances robustness, stability, and generalizability. As a
result, SAGE demonstrates strong predictive performance across multiple
intrusion detection datasets, achieving an average F1-score improvement of 201%
over the state-of-the-art defenses. Notably, SAGE narrows the performance gap
to the Oracle to just 3.8%, while reducing computational overhead by up to 29x.

</details>


### [3] [Accelerating AI Development with Cyber Arenas](https://arxiv.org/abs/2509.08200)
*William Cashman,Chasen Milner,Michael Houle,Michael Jones,Hayden Jananthan,Jeremy Kepner,Peter Michaleas,Alex Pentland*

Main category: cs.CR

TL;DR: 网络安全测试环境中部署AI测试平台的初步实验


<details>
  <summary>Details</summary>
Motivation: 为了在高保真度的测试环境中有效地转换AI技术从实验室到实际运行，利用网络演练场提供灵活的测试机会

Method: 在国民警卫队演习中部署MIT/IEEE/Amazon图形挖掘挑战匿名网络传感器平台

Result: 成功在网络演练场中实施了AI测试环境，为续继研究奠定基础

Conclusion: 网络演练场为AI技术的实际测试和迭代提供了有效的平台，有助于加快从实验室到部署的迁移过程

Abstract: AI development requires high fidelity testing environments to effectively
transition from the laboratory to operations. The flexibility offered by cyber
arenas presents a novel opportunity to test new artificial intelligence (AI)
capabilities with users. Cyber arenas are designed to expose end-users to
real-world situations and must rapidly incorporate evolving capabilities to
meet their core objectives. To explore this concept the MIT/IEEE/Amazon Graph
Challenge Anonymized Network Sensor was deployed in a cyber arena during a
National Guard exercise.

</details>


### [4] [Unlocking Reproducibility: Automating re-Build Process for Open-Source Software](https://arxiv.org/abs/2509.08204)
*Behnaz Hassanshahi,Trong Nhan Mai,Benjamin Selwyn Smith,Nicholas Allen*

Main category: cs.CR

TL;DR: 通过扩展Macaron框架自动重构Maven组件，解决二进制与源码分离带来的供应链安全风险，提高构建透明性和安全性


<details>
  <summary>Details</summary>
Motivation: Maven Central等软件生态系统中二进制与源码分离嫻致构建环境不透明，约84%常用组件无透明CI/CD流程，带来安全风险

Method: 扩展Macaron框架，自动化从源码重构Maven组件：改进源码检测性能、自动从GitHub Actions流程提取构建规范、提供可扩展的构建失败根因分析解决方案

Result: 实现了高效的源码检测和构建规范提取，能够自动化处理大规模依赖图的重构过程，提升了供应链安全性

Conclusion: 通过自动化重构技术可有效解决Maven生态系统中的构建透明性问题，为开源软件供应链提供更高级别的安全保障

Abstract: Software ecosystems like Maven Central play a crucial role in modern software
supply chains by providing repositories for libraries and build plugins.
However, the separation between binaries and their corresponding source code in
Maven Central presents a significant challenge, particularly when it comes to
linking binaries back to their original build environment. This lack of
transparency poses security risks, as approximately 84% of the top 1200
commonly used artifacts are not built using a transparent CI/CD pipeline.
Consequently, users must place a significant amount of trust not only in the
source code but also in the environment in which these artifacts are built.
  Rebuilding software artifacts from source provides a robust solution to
improve supply chain security. This approach allows for a deeper review of
code, verification of binary-source equivalence, and control over dependencies.
However, challenges arise due to variations in build environments, such as JDK
versions and build commands, which can lead to build failures. Additionally,
ensuring that all dependencies are rebuilt from source across large and complex
dependency graphs further complicates the process. In this paper, we introduce
an extension to Macaron, an industry-grade open-source supply chain security
framework, to automate the rebuilding of Maven artifacts from source. Our
approach improves upon existing tools, by offering better performance in source
code detection and automating the extraction of build specifications from
GitHub Actions workflows. We also present a comprehensive root cause analysis
of build failures in Java projects and propose a scalable solution to automate
the rebuilding of artifacts, ultimately enhancing security and transparency in
the open-source supply chain.

</details>


### [5] [EFPIX: A zero-trust encrypted flood protocol](https://arxiv.org/abs/2509.08248)
*Arin Upadhyay*

Main category: cs.CR

TL;DR: 提出了一种基于洪泛的中继通信协议，实现端到端加密、用户可否认性和消息不可追踪性


<details>
  <summary>Details</summary>
Motivation: 需要一种能够抵抗拓扑变化和基础设施故障，同时隐藏元数据（如发送者和接收者信息）的通信协议

Method: 基于洪泛的中继通信协议，采用端到端加密技术

Result: 协议实现了消息不可追踪性、用户可否认性，并能抵抗拓扑变化和基础设施故障

Conclusion: 该协议为需要高度隐私保护的通信场景提供了一种有效的解决方案

Abstract: We propose a flood-based relay communication protocol that achieves
end-to-end encryption, plausible deniability for users, and untraceable
messages. It is resistant to changes in topology and infrastructure failures.
It is also designed to hide metadata, such as sender and receiver, from those
not involved.

</details>


### [6] [Overcoming DNSSEC Islands of Security: A TLS and IP-Based Certificate Solution](https://arxiv.org/abs/2509.08364)
*Aduma Rishith,Aditya Kulkarni,Tamal Das,Vivek Balachandran*

Main category: cs.CR

TL;DR: 提出基于TLS和IP证书的去中心化方法解决DNSSEC信任链断裂问题，替代传统中心化方案


<details>
  <summary>Details</summary>
Motivation: DNSSEC在信任链断裂时形成"安全孤岛"，现有中心化方案需要额外基础设施且过度依赖单一权威机构

Method: 利用TLS和基于IP的证书实现层次间的端到端认证，无需在DNS层次结构的每个级别统一部署DNSSEC

Result: 增强了DNSSEC的整体完整性，减少了对注册商维护签名记录的依赖

Conclusion: 该方法提供了更灵活高效的解决方案，加强了DNS安全性并简化了在不同环境中的部署

Abstract: The Domain Name System (DNS) serves as the backbone of the Internet,
primarily translating domain names to IP addresses. Over time, various
enhancements have been introduced to strengthen the integrity of DNS. Among
these, DNSSEC stands out as a leading cryptographic solution. It protects
against attacks (such as DNS spoofing) by establishing a chain of trust
throughout the DNS nameserver hierarchy. However, DNSSEC's effectiveness is
compromised when there is a break in this chain, resulting in "Islands of
Security", where domains can authenticate locally but not across hierarchical
levels, leading to a loss of trust and validation between them. Leading
approaches to addressing these issues were centralized, with a single authority
maintaining some kind of bulletin board. This approach requires significantly
more infrastructure and places excessive trust in the entity responsible for
managing it properly. In this paper, we propose a decentralized approach to
addressing gaps in DNSSEC's chain of trust, commonly referred to as "Islands of
Security". We leverage TLS and IP-based certificates to enable end-to-end
authentication between hierarchical levels, eliminating the need for uniform
DNSSEC deployment across every level of the DNS hierarchy. This approach
enhances the overall integrity of DNSSEC, while reducing dependence on
registrars for maintaining signature records to verify the child nameserver's
authenticity. By offering a more flexible and efficient solution, our method
strengthens DNS security and streamlines deployment across diverse
environments.

</details>


### [7] [Phish-Blitz: Advancing Phishing Detection with Comprehensive Webpage Resource Collection and Visual Integrity Preservation](https://arxiv.org/abs/2509.08375)
*Duddu Hriday,Aditya Kulkarni,Vivek Balachandran,Tamal Das*

Main category: cs.CR

TL;DR: 提出了Phish-Blitz工具，用于收集钓鱼和合法网页的完整资源（包括截图），并提供了一个包含8809个合法网页和5000个钓鱼网页的数据集，以改善钓鱼检测模型的训练数据质量。


<details>
  <summary>Details</summary>
Motivation: 钓鱼攻击日益猖獗，现有检测模型面临训练数据不足的问题，特别是钓鱼网页生命周期短导致资源收集困难，限制了数据集的全面性。

Method: 开发Phish-Blitz工具，能够下载钓鱼和合法网页及其相关资源（包括实时网页截图），并更新资源文件路径以保持网页原始视觉完整性。

Result: 创建了一个包含13,809个网页的数据集（8809个合法网页和5000个钓鱼网页），包含所有相关资源，工具和数据集已在GitHub上公开。

Conclusion: Phish-Blitz工具和提供的数据集为钓鱼检测研究社区贡献了更完整的数据资源，有助于提高钓鱼检测模型的准确性。

Abstract: Phishing attacks are increasingly prevalent, with adversaries creating
deceptive webpages to steal sensitive information. Despite advancements in
machine learning and deep learning for phishing detection, attackers constantly
develop new tactics to bypass detection models. As a result, phishing webpages
continue to reach users, particularly those unable to recognize phishing
indicators. To improve detection accuracy, models must be trained on large
datasets containing both phishing and legitimate webpages, including URLs,
webpage content, screenshots, and logos. However, existing tools struggle to
collect the required resources, especially given the short lifespan of phishing
webpages, limiting dataset comprehensiveness. In response, we introduce
Phish-Blitz, a tool that downloads phishing and legitimate webpages along with
their associated resources, such as screenshots. Unlike existing tools,
Phish-Blitz captures live webpage screenshots and updates resource file paths
to maintain the original visual integrity of the webpage. We provide a dataset
containing 8,809 legitimate and 5,000 phishing webpages, including all
associated resources. Our dataset and tool are publicly available on GitHub,
contributing to the research community by offering a more complete dataset for
phishing detection.

</details>


### [8] [MIoT-Driven Comparison of Open Blockchain Platforms](https://arxiv.org/abs/2509.08399)
*Abdou-Essamad Jabri,Mostafa Azizi,Cyril Drocourt,Gil Utard*

Main category: cs.CR

TL;DR: 这篇论文分析了三种免费区块链平台（以太坊、Hyperledger Fabric和Corda）在医疗物联网（MIoT）环境中的安全性适用性。


<details>
  <summary>Details</summary>
Motivation: 随着工业4.0推动下IoT设备的普及，安全问题日益突出，特别是在医疗IoT和工业IoT领域。需要找到适合MIoT环境的区块链平台来提高安全性。

Method: 通过对比分析三种免费区块链平台（以太坊、Hyperledger Fabric和Corda）的特性，评估它们在MIoT环境中的安全性适用性。

Result: 区块链技术能够提供去中心化、自治、无信任和分布式环境，但需要智能部署以避免能消耗和过度计算等实际缺点。

Conclusion: 选择适合MIoT环境的区块链平台是一项挑战，需要综合考虑安全性、性能和实际部署需求。

Abstract: Being propelled by the fourth industrial revolution (Industry 4.0), IoT
devices and solutions are well adopted everywhere, ranging from home
applications to industrial use, crossing through transportation, healthcare,
energy, and so on. This wide use of IoT has not gone unnoticed, hackers are
tracking the weakness of such a technology and threatening them continuously.
Their security at various levels has become an important concern of
professionals and researchers. This issue takes more risk, especially with the
IoT variants, IIoT (Industrial IoT) and MIoT (Medical IoT). Many existing
security solutions are adapted and proposed for addressing IoT security. In
this paper, we are interested in exploring blockchain technology and we make a
comparison of three free Blockchain platforms towards their applicability for
MIoT context, namely Ethereum, Hyperledger Fabric and Corda. In general,
Blockchain technology provides a decentralized, autonomous, trustless, and
distributed environment. It is challenging to find a Blockchain platform that
fits the MIoT context and performs well in terms of security. The retained
platform should be deployed smartly to avoid its practical drawbacks related to
energy-consuming and excessive computing.

</details>


### [9] [Leveraging Blockchain and Proxy Re-Encryption to secure Medical IoT Records](https://arxiv.org/abs/2509.08402)
*Abdou-Essamad Jabri,C. Drocourt,Mostafa Azizi,Gil Utard*

Main category: cs.CR

TL;DR: 基于私有区块链和代理重加密技术的IoT医疗数据安全分享框架，解决医疗数据传输和存储中的安全隐私挑战


<details>
  <summary>Details</summary>
Motivation: IoT在医疗健康领域的集成带来了实时监测和数据收集的革命，但敏感医疗数据的传输和存储引发了重大的安全和隐私挑战

Method: 提出一种集成私有区块链和代理重加密（PRE）的架构。区块链提供去中心化的不可篦改账本，确保数据完整性；PRE允许加密数据在不暴露给中间人的情况下重新加密给新接收方

Result: 该结合创建了一个稳固的安全框架，支持安全、可追踪和隐私保护的数据分享，允许医疗专业人员在不影响保密性的前提下安全分享患者数据

Conclusion: 私有区块链与代理重加密的集成提供了一种流畅的解决方案，在保持数据完整性和透明性的同时，支持灵活的数据分享控制，为数字化医疗生态系统提升信任和效率

Abstract: The integration of the Internet of Things (IoT) in healthcare has
revolutionized patient monitoring and data collection, allowing real-time
tracking of vital signs, remote diagnostics, and automated medical responses.
However, the transmission and storage of sensitive medical data introduce
significant security and privacy challenges. To address these concerns,
blockchain technology provides a decentralized and immutable ledger that
ensures data integrity, , and transparency. Unlike public blockchains, private
blockchains are permissioned; the access is granted only to authorized
participants; they are more suitable for handling confidential healthcare data.
Although blockchain ensures security and trust, it lacks built-in mechanisms to
support flexible and controlled data sharing; This is where Proxy Re-Encryption
(PRE) comes into play. PRE is a cryptographic technique that allows encrypted
data to be re-encrypted for a new recipient without exposing it to
intermediaries. We propose an architecture integrating private blockchain and
PRE to enable secure, traceable, and privacy-preserving data sharing in
IoT-based healthcare systems. Blockchain guarantees tamper proof
record-keeping, while PRE enables fine-grained access control, allowing medical
professionals to securely share patient data without compromising
confidentiality. This combination creates a robust security framework that
enhances trust and efficiency in digital healthcare ecosystems.

</details>


### [10] [Phishing Webpage Detection: Unveiling the Threat Landscape and Investigating Detection Techniques](https://arxiv.org/abs/2509.08424)
*Aditya Kulkarni,Vivek Balachandran,Tamal Das*

Main category: cs.CR

TL;DR: 这篇论文是一个关于网页洗牌攻击检测的系统性评论，对URL基于、网页内容基于和视觉技术等多种检测方法进行了分类和分析，指出了当前研究空白并提出了潜在解决方案。


<details>
  <summary>Details</summary>
Motivation: 洗牌攻击作为一种普遍的网络安全威胁，攻击者不断发展新技术来突破现有检测方法，对研究社区构成了持续挑战。需要系统性地总结当前的检测方法并指出研究空白。

Method: 采用系统性分类方法，将洗牌网页检测方法分为三大类：URL基于方法、网页内容基于方法和视觉技术方法。通过对现有文献的全面审查和深入分析来评估各种方法的效果。

Result: 识别出了当前洗牌网页检测领域的重要研究空白，包括检测方法的局限性和攻击者新兴技术带来的挑战。

Conclusion: 这份评论不仅系统地总结了现有的洗牌网页检测技术，还为解决当前研究空白提供了潜在的解决方案，对抗击洗牌攻击的持续努力做出了贡献。

Abstract: In the realm of cybersecurity, phishing stands as a prevalent cyber attack,
where attackers employ various tactics to deceive users into gathering their
sensitive information, potentially leading to identity theft or financial gain.
Researchers have been actively working on advancing phishing webpage detection
approaches to detect new phishing URLs, bolstering user protection.
Nonetheless, the ever-evolving strategies employed by attackers, aimed at
circumventing existing detection approaches and tools, present an ongoing
challenge to the research community. This survey presents a systematic
categorization of diverse phishing webpage detection approaches, encompassing
URL-based, webpage content-based, and visual techniques. Through a
comprehensive review of these approaches and an in-depth analysis of existing
literature, our study underscores current research gaps in phishing webpage
detection. Furthermore, we suggest potential solutions to address some of these
gaps, contributing valuable insights to the ongoing efforts to combat phishing
attacks.

</details>


### [11] [DSFL: A Dual-Server Byzantine-Resilient Federated Learning Framework via Group-Based Secure Aggregation](https://arxiv.org/abs/2509.08449)
*Charuka Herath,Yogachandran Rahulamathavan,Varuna De Silva,Sangarapillai Lambotharan*

Main category: cs.CR

TL;DR: DSFL是一个双服务器拜占庭容错联邦学习框架，通过组安全聚合、信用过滤和动态奖惩机制，解决了现有FL协议在隐私保护、拜占庭攻击防御和非IID数据下的性能问题。


<details>
  <summary>Details</summary>
Motivation: 现有联邦学习协议难以同时防御拜占庭参与者、在非IID数据下保持模型性能，并且对边缘设备来说过于沉重。先前的工作要么依赖可信硬件，要么使用昂贵的密码学工具，或者无法同时解决隐私和鲁棒性问题。

Method: 提出DSFL框架，包含三个关键创新：(1)双服务器安全聚合协议，无需加密或密钥交换；(2)基于组的信用过滤机制，通过偏差分数隔离拜占庭客户端；(3)动态奖惩系统确保公平参与。

Result: 在MNIST、CIFAR-10和CIFAR-100数据集上，面对30%拜占庭参与者的IID和非IID设置，DSFL始终优于现有基线方法。在CIFAR-10上达到97.15%准确率，CIFAR-100上达到68.60%，而FedAvg在类似威胁下仅9.39%。DSFL轻量高效，每轮仅需55.9ms运行时间和1088KB通信量。

Conclusion: DSFL成功解决了联邦学习中的隐私保护、拜占庭容错和非IID数据挑战，提供了一个既安全又高效的解决方案，特别适合边缘计算环境。

Abstract: Federated Learning (FL) enables decentralized model training without sharing
raw data, offering strong privacy guarantees. However, existing FL protocols
struggle to defend against Byzantine participants, maintain model utility under
non-independent and identically distributed (non-IID) data, and remain
lightweight for edge devices. Prior work either assumes trusted hardware, uses
expensive cryptographic tools, or fails to address privacy and robustness
simultaneously. We propose DSFL, a Dual-Server Byzantine-Resilient Federated
Learning framework that addresses these limitations using a group-based secure
aggregation approach. Unlike LSFL, which assumes non-colluding semi-honest
servers, DSFL removes this dependency by revealing a key vulnerability: privacy
leakage through client-server collusion. DSFL introduces three key innovations:
(1) a dual-server secure aggregation protocol that protects updates without
encryption or key exchange, (2) a group-wise credit-based filtering mechanism
to isolate Byzantine clients based on deviation scores, and (3) a dynamic
reward-penalty system for enforcing fair participation. DSFL is evaluated on
MNIST, CIFAR-10, and CIFAR-100 under up to 30 percent Byzantine participants in
both IID and non-IID settings. It consistently outperforms existing baselines,
including LSFL, homomorphic encryption methods, and differential privacy
approaches. For example, DSFL achieves 97.15 percent accuracy on CIFAR-10 and
68.60 percent on CIFAR-100, while FedAvg drops to 9.39 percent under similar
threats. DSFL remains lightweight, requiring only 55.9 ms runtime and 1088 KB
communication per round.

</details>


### [12] [Flow-Based Detection and Identification of Zero-Day IoT Cameras](https://arxiv.org/abs/2509.08485)
*Priyanka Rushikesh Chaudhary,Rajib Ranjan Maiti*

Main category: cs.CR

TL;DR: zCamInspector是一个用于识别已知IoT摄像头和检测零日摄像头的系统，使用监督学习和单类分类器，在多个数据集上实现了高准确率。


<details>
  <summary>Details</summary>
Motivation: 大多数消费级IoT设备缺乏监控机制，管理员难以实施定制化安全策略，特别是难以检测新加入网络的流媒体IoT摄像头。

Method: 使用CICFlowmeter从三个数据集（商业IoT摄像头、开源IoT摄像头、非IoT流量）提取62个流特征，采用7种监督模型和4种单类模型进行分类和检测。

Result: XGB模型识别IoT摄像头准确率>99%，假阴性率低至0.3%；零日检测准确率最高达96.55%（SGDOCSVM），DeepSVDD在处理所有设备为零日时表现最佳（训练96.03%/测试74.51%）。

Conclusion: zCamInspector在多样化网络环境中能有效识别和检测零日IoT摄像头，对特定设备如间谍时钟摄像头准确率>95%，证明了其鲁棒性。

Abstract: The majority of consumer IoT devices lack mechanisms for administrators to
monitor and control them, hindering tailored security policies. A key challenge
is identifying whether a new device, especially a streaming IoT camera, has
joined the network. We present zCamInspector, a system for identifying known
IoT cameras with supervised classifiers (zCamClassifier) and detecting zero-day
cameras with one-class classifiers (zCamDetector). We analyzed ~40GB of traffic
across three datasets: Set I (six commercial IoT cameras), Set II (five
open-source IoT cameras, ~1.5GB), and Set III (four conferencing and two
video-sharing applications as non-IoT traffic). From each, 62 flow-based
features were extracted using CICFlowmeter. zCamInspector employs seven
supervised models (ET, DT, RF, KNN, XGB, LKSVM, GNB) and four one-class models
(OCSVM, SGDOCSVM, IF, DeepSVDD). Results show that XGB identifies IoT cameras
with >99% accuracy and false negatives as low as 0.3%, outperforming
state-of-the-art methods. For zero-day detection, accuracies reached 93.20%
(OCSVM), 96.55% (SGDOCSVM), 78.65% (IF), and 92.16% (DeepSVDD). When all
devices were treated as zero-day, DeepSVDD performed best with mean
training/testing accuracies of 96.03%/74.51%. zCamInspector also achieved >95%
accuracy for specific devices, such as Spy Clock cameras, demonstrating its
robustness for identifying and detecting zero-day IoT cameras in diverse
network environments.

</details>


### [13] [Send to which account? Evaluation of an LLM-based Scambaiting System](https://arxiv.org/abs/2509.08493)
*Hossein Siadati,Haadi Jafarian,Sima Jafarikhah*

Main category: cs.CR

TL;DR: 本文首次对基于大语言模型的诈骗诱饵系统进行了大规模真实世界评估，该系统通过对话蜜罐主动获取诈骗者敏感金融信息，取得了32%的信息披露率和70%的人工接受率。


<details>
  <summary>Details</summary>
Motivation: 诈骗者利用生成式AI技术大规模制作钓鱼内容，传统防御手段难以摧毁诈骗基础设施，需要更主动的策略来获取可操作的威胁情报。

Method: 使用基于大语言模型的对话蜜罐系统，在5个月部署期间与真实诈骗者进行2600多次互动，收集了18700多条消息数据。

Result: 系统实现了约32%的信息披露率，成功提取到骡子账户等敏感金融信息，同时保持约70%的人工接受率，显示LLM生成回复与人工偏好高度一致。

Conclusion: 虽然系统在获取敏感信息方面表现良好，但在初始互动阶段只有48.7%的诈骗者回应，表明需要进一步改进自动诈骗诱饵系统的设计。

Abstract: Scammers are increasingly harnessing generative AI(GenAI) technologies to
produce convincing phishing content at scale, amplifying financial fraud and
undermining public trust. While conventional defenses, such as detection
algorithms, user training, and reactive takedown efforts remain important, they
often fall short in dismantling the infrastructure scammers depend on,
including mule bank accounts and cryptocurrency wallets. To bridge this gap, a
proactive and emerging strategy involves using conversational honeypots to
engage scammers and extract actionable threat intelligence. This paper presents
the first large-scale, real-world evaluation of a scambaiting system powered by
large language models (LLMs). Over a five-month deployment, the system
initiated over 2,600 engagements with actual scammers, resulting in a dataset
of more than 18,700 messages. It achieved an Information Disclosure Rate (IDR)
of approximately 32%, successfully extracting sensitive financial information
such as mule accounts. Additionally, the system maintained a Human Acceptance
Rate (HAR) of around 70%, indicating strong alignment between LLM-generated
responses and human operator preferences. Alongside these successes, our
analysis reveals key operational challenges. In particular, the system
struggled with engagement takeoff: only 48.7% of scammers responded to the
initial seed message sent by defenders. These findings highlight the need for
further refinement and provide actionable insights for advancing the design of
automated scambaiting systems.

</details>


### [14] [Architecting Resilient LLM Agents: A Guide to Secure Plan-then-Execute Implementations](https://arxiv.org/abs/2509.08646)
*Ron F. Del Rosario,Klaudia Krawiecka,Christian Schroeder de Witt*

Main category: cs.CR

TL;DR: 本文提出了"Plan-then-Execute"（P-t-E）模式，这是一种将战略规划与战术执行分离的智能体设计模式，具有更好的可预测性、成本效益和推理质量，并对间接提示注入攻击具有内在弹性。


<details>
  <summary>Details</summary>
Motivation: 随着大型语言模型（LLM）智能体越来越能够自动化复杂的多步骤任务，需要健壮、安全和可预测的架构模式来确保系统可靠性。

Method: 详细分析了P-t-E模式的核心组件（规划器和执行器），探讨了其在三个主流框架（LangChain、CrewAI、AutoGen）中的实现蓝图，并提出了深度防御策略，包括最小权限原则、任务范围工具访问和沙盒代码执行等补充控制措施。

Result: 提供了完整的实施蓝图和代码参考，展示了P-t-E模式在可预测性、安全性和成本效率方面的优势，特别是在抵御间接提示注入攻击方面的内在弹性。

Conclusion: P-t-E模式为构建生产级、弹性和可信赖的LLM智能体提供了强大的基础架构，但需要结合深度防御策略和人工验证等高级模式来实现完整的解决方案。

Abstract: As Large Language Model (LLM) agents become increasingly capable of
automating complex, multi-step tasks, the need for robust, secure, and
predictable architectural patterns is paramount. This paper provides a
comprehensive guide to the ``Plan-then-Execute'' (P-t-E) pattern, an agentic
design that separates strategic planning from tactical execution. We explore
the foundational principles of P-t-E, detailing its core components - the
Planner and the Executor - and its architectural advantages in predictability,
cost-efficiency, and reasoning quality over reactive patterns like ReAct
(Reason + Act). A central focus is placed on the security implications of this
design, particularly its inherent resilience to indirect prompt injection
attacks by establishing control-flow integrity. We argue that while P-t-E
provides a strong foundation, a defense-in-depth strategy is necessary, and we
detail essential complementary controls such as the Principle of Least
Privilege, task-scoped tool access, and sandboxed code execution. To make these
principles actionable, this guide provides detailed implementation blueprints
and working code references for three leading agentic frameworks: LangChain
(via LangGraph), CrewAI, and AutoGen. Each framework's approach to implementing
the P-t-E pattern is analyzed, highlighting unique features like LangGraph's
stateful graphs for re-planning, CrewAI's declarative tool scoping for
security, and AutoGen's built-in Docker sandboxing. Finally, we discuss
advanced patterns, including dynamic re-planning loops, parallel execution with
Directed Acyclic Graphs (DAGs), and the critical role of Human-in-the-Loop
(HITL) verification, to offer a complete strategic blueprint for architects,
developers, and security engineers aiming to build production-grade, resilient,
and trustworthy LLM agents.

</details>


### [15] [Tight Privacy Audit in One Run](https://arxiv.org/abs/2509.08704)
*Zihang Xiang,Tianhao Wang,Hanshen Xiao,Yuan Tian,Di Wang*

Main category: cs.CR

TL;DR: 本文提出了一种单次运行的隐私审计方法，能够在各种差分隐私协议中实现紧密的审计结果，特别是在(ε,δ)-DP算法审计方面超越了现有工作。


<details>
  <summary>Details</summary>
Motivation: 解决现有隐私审计方法无法在单次运行中为(ε,δ)-DP算法提供紧密审计结果的问题，特别是在各种参数设置下现有方法都失败的情况。

Method: 首先构建了一个改进的单次运行隐私审计框架，然后基于f-DP隐私建模方法，从理论上推导出隐私审计的合理下界。

Result: 实验表明该方法在审计各种差分隐私算法时优于现有工作，并对单次运行隐私审计的参数设置得出了与先前工作相反的结论。

Conclusion: 该方法为(ε,δ)-DP算法提供了首个在单次运行中实现紧密审计结果的解决方案，在理论和实验上都验证了其优越性。

Abstract: In this paper, we study the problem of privacy audit in one run and show that
our method achieves tight audit results for various differentially private
protocols. This includes obtaining tight results for auditing
$(\varepsilon,\delta)$-DP algorithms where all previous work fails to achieve
in any parameter setups. We first formulate a framework for privacy audit
\textit{in one run} with refinement compared with previous work. Then, based on
modeling privacy by the $f$-DP formulation, we study the implications of our
framework to obtain a theoretically justified lower bound for privacy audit. In
the experiment, we compare with previous work and show that our audit method
outperforms the rest in auditing various differentially private algorithms. We
also provide experiments that give contrasting conclusions to previous work on
the parameter settings for privacy audits in one run.

</details>


### [16] [PAnDA: Rethinking Metric Differential Privacy Optimization at Scale with Anchor-Based Approximation](https://arxiv.org/abs/2509.08720)
*Ruiyao Liu,Chenxi Qiu*

Main category: cs.CR

TL;DR: 提出PAnDA框架，通过锚点选择和分布式近似方法解决度量差分隐私中的计算可扩展性问题，支持更大规模的地理位置数据处理


<details>
  <summary>Details</summary>
Motivation: 现有基于线性规划的度量差分隐私方法面临二次增长的计算变量问题，无法扩展到大规模数据集

Method: 提出两阶段PAnDA框架：用户选择锚点记录，服务器在缩减域上求解紧凑线性规划；引入三种锚点选择策略（指数衰减、幂律衰减、逻辑衰减）

Result: 在真实地理位置数据集上验证，PAnDA可扩展到5000条记录的机密域，比现有LP方法规模扩大两倍，同时提供隐私和效用的理论保证

Conclusion: PAnDA框架有效解决了度量差分隐私的可扩展性挑战，为大规模地理位置数据提供了实用的隐私保护解决方案

Abstract: Metric Differential Privacy (mDP) extends the local differential privacy
(LDP) framework to metric spaces, enabling more nuanced privacy protection for
data such as geo-locations. However, existing mDP optimization methods,
particularly those based on linear programming (LP), face scalability
challenges due to the quadratic growth in decision variables. In this paper, we
propose Perturbation via Anchor-based Distributed Approximation (PAnDA), a
scalable two-phase framework for optimizing metric differential privacy (mDP).
To reduce computational overhead, PAnDA allows each user to select a small set
of anchor records, enabling the server to solve a compact linear program over a
reduced domain. We introduce three anchor selection strategies, exponential
decay (PAnDA-e), power-law decay (PAnDA-p), and logistic decay (PAnDA-l), and
establish theoretical guarantees under a relaxed privacy notion called
probabilistic mDP (PmDP). Experiments on real-world geo-location datasets
demonstrate that PAnDA scales to secret domains with up to 5,000 records, two
times larger than prior LP-based methods, while providing theoretical
guarantees for both privacy and utility.

</details>


### [17] [SilentLedger: Privacy-Preserving Auditing for Blockchains with Complete Non-Interactivity](https://arxiv.org/abs/2509.08722)
*Zihan Liu,Xiaohu Wang,Chao Lin,Minghui Xu,Debiao He,Xinyi Huang*

Main category: cs.CR

TL;DR: SilentLedger是一个具有审计功能的隐私保护区块链系统，通过可再生匿名证书和可追溯交易机制实现完全非交互式交易，同时支持从链上数据独立审计。


<details>
  <summary>Details</summary>
Motivation: 现有隐私保护区块链系统在审计性和独立性方面存在不足，要么需要额外交互影响可用性和扩展性，要么依赖审计者作为验证节点带来安全风险。

Method: 提出可再生匿名证书方案支持公开授权验证，使用成熟密码学原语构建可追溯交易机制，用户无需交互即可交易，审计者仅需链上数据即可审计。

Result: 正式证明了真实性、匿名性、保密性和健全性等安全属性，在标准2-2交易模型下性能评估显示优于现有解决方案。

Conclusion: SilentLedger成功解决了隐私保护与审计需求之间的平衡问题，实现了完全非交互式的高性能隐私交易系统。

Abstract: Privacy-preserving blockchain systems are essential for protecting
transaction data, yet they must also provide auditability that enables auditors
to recover participant identities and transaction amounts when warranted.
Existing designs often compromise the independence of auditing and
transactions, introducing extra interactions that undermine usability and
scalability. Moreover, many auditable solutions depend on auditors serving as
validators or recording nodes, which introduces risks to both data security and
system reliability.
  To overcome these challenges, we propose SilentLedger, a privacy-preserving
transaction system with auditing and complete non-interactivity. To support
public verification of authorization, we introduce a renewable anonymous
certificate scheme with formal semantics and a rigorous security model.
SilentLedger further employs traceable transaction mechanisms constructed from
established cryptographic primitives, enabling users to transact without
interaction while allowing auditors to audit solely from on-chain data. We
formally prove security properties including authenticity, anonymity,
confidentiality, and soundness, provide a concrete instantiation, and evaluate
performance under a standard 2-2 transaction model. Our implementation and
benchmarks demonstrate that SilentLedger achieves superior performance compared
with state-of-the-art solutions.

</details>


### [18] [Securing Cryptographic Software via Typed Assembly Language (Extended Version)](https://arxiv.org/abs/2509.08727)
*Shixin Song,Tingzhen Dong,Kosi Nwabueze,Julian Zanders,Andres Erbsen,Adam Chlipala,Mengjia Yan*

Main category: cs.CR

TL;DR: SecSep是一个汇编级转换框架，通过栈数据分区来防止推测执行攻击，平均开销仅1.2%


<details>
  <summary>Details</summary>
Motivation: 现有的源代码标注方法无法正确跟踪栈上的秘密数据，且存在性能开销问题

Method: 提出Octal类型化汇编语言，在汇编级别重写程序以实现栈上的秘密和公共数据分区

Result: 成功应用于密码学程序，平均性能开销仅为1.2%

Conclusion: 汇编级重写方法比源代码标注更有效地解决了推测执行攻击的安全问题

Abstract: Authors of cryptographic software are well aware that their code should not
leak secrets through its timing behavior, and, until 2018, they believed that
following industry-standard constant-time coding guidelines was sufficient.
However, the revelation of the Spectre family of speculative execution attacks
injected new complexities.
  To block speculative attacks, prior work has proposed annotating the
program's source code to mark secret data, with hardware using this information
to decide when to speculate (i.e., when only public values are involved) or not
(when secrets are in play). While these solutions are able to track secret
information stored on the heap, they suffer from limitations that prevent them
from correctly tracking secrets on the stack, at a cost in performance.
  This paper introduces SecSep, a transformation framework that rewrites
assembly programs so that they partition secret and public data on the stack.
By moving from the source-code level to assembly rewriting, SecSep is able to
address limitations of prior work. The key challenge in performing this
assembly rewriting stems from the loss of semantic information through the
lengthy compilation process. The key innovation of our methodology is a new
variant of typed assembly language (TAL), Octal, which allows us to address
this challenge. Assembly rewriting is driven by compile-time inference within
Octal. We apply our technique to cryptographic programs and demonstrate that it
enables secure speculation efficiently, incurring a low average overhead of
$1.2\%$.

</details>


### [19] [Membrane: A Cryptographic Access Control System for Data Lakes](https://arxiv.org/abs/2509.08740)
*Sam Kumar,Samyukta Yagati,Conor Power,David E. Culler,Raluca Ada Popa*

Main category: cs.CR

TL;DR: Membrane是一个为数据湖设计的加密访问控制系统，通过SQL感知加密和静态加密技术，在保护敏感数据的同时允许数据分析师运行任意查询，仅需在会话开始时解密视图，后续查询开销很低。


<details>
  <summary>Details</summary>
Motivation: 数据湖存储敏感数据但面临黑客绕过访问控制的风险，需要在不限制分析查询能力的前提下加强安全保护。

Method: 结合静态加密和SQL感知加密技术，使用支持硬件加速的块密码算法，开发新的SQL感知加密协议。

Result: 系统仅在交互会话开始时因解密视图产生约20倍延迟，后续查询处理解密后的明文数据，摊销开销很低。

Conclusion: Membrane通过加密技术有效保护数据湖中的敏感数据，同时保持数据分析的灵活性，为数据湖安全提供了实用解决方案。

Abstract: Organizations use data lakes to store and analyze sensitive data. But hackers
may compromise data lake storage to bypass access controls and access sensitive
data. To address this, we propose Membrane, a system that (1) cryptographically
enforces data-dependent access control views over a data lake, (2) without
restricting the analytical queries data scientists can run. We observe that
data lakes, unlike DBMSes, disaggregate computation and storage into separate
trust domains, making at-rest encryption sufficient to defend against remote
attackers targeting data lake storage, even when running analytical queries in
plaintext. This leads to a new system design for Membrane that combines
encryption at rest with SQL-aware encryption. Using block ciphers, a fast
symmetric-key primitive with hardware acceleration in CPUs, we develop a new
SQL-aware encryption protocol well-suited to at-rest encryption. Membrane adds
overhead only at the start of an interactive session due to decrypting views,
delaying the first query result by up to $\approx 20\times$; subsequent queries
process decrypted data in plaintext, resulting in low amortized overhead.

</details>


### [20] [Stealth by Conformity: Evading Robust Aggregation through Adaptive Poisoning](https://arxiv.org/abs/2509.08746)
*Ryan McGaughey,Jesus Martinez del Rincon,Ihsen Alouani*

Main category: cs.CR

TL;DR: 本文提出了CHAMP（变色龙投毒）攻击方法，通过利用聚合过程的侧信道反馈来指导攻击，使恶意更新保持在主分布内，从而规避现有的鲁棒聚合防御机制。


<details>
  <summary>Details</summary>
Motivation: 联邦学习容易受到投毒攻击，现有防御方法基于恶意更新是分布外异常的假设。本文挑战这一假设，证明可以在保持恶意更新在分布内的情况下进行投毒。

Method: 提出CHAMP自适应投毒策略，通过侧信道反馈推断恶意贡献是否被纳入全局模型，动态调整本地损失函数，平衡恶意组件和伪装组件。

Result: 在两个数据集上评估，针对九种鲁棒聚合防御方法的攻击成功率平均提高47.07%。

Conclusion: CHAMP攻击揭示了现有鲁棒聚合防御的根本局限性，强调需要新策略来保护联邦学习免受复杂对手攻击。

Abstract: Federated Learning (FL) is a distributed learning paradigm designed to
address privacy concerns. However, FL is vulnerable to poisoning attacks, where
Byzantine clients compromise the integrity of the global model by submitting
malicious updates. Robust aggregation methods have been widely adopted to
mitigate such threats, relying on the core assumption that malicious updates
are inherently out-of-distribution and can therefore be identified and excluded
before aggregating client updates. In this paper, we challenge this underlying
assumption by showing that a model can be poisoned while keeping malicious
updates within the main distribution. We propose Chameleon Poisoning (CHAMP),
an adaptive and evasive poisoning strategy that exploits side-channel feedback
from the aggregation process to guide the attack. Specifically, the adversary
continuously infers whether its malicious contribution has been incorporated
into the global model and adapts accordingly. This enables a dynamic adjustment
of the local loss function, balancing a malicious component with a camouflaging
component, thereby increasing the effectiveness of the poisoning while evading
robust aggregation defenses. CHAMP enables more effective and evasive
poisoning, highlighting a fundamental limitation of existing robust aggregation
defenses and underscoring the need for new strategies to secure federated
learning against sophisticated adversaries. Our approach is evaluated in two
datasets reaching an average increase of 47.07% in attack success rate against
nine robust aggregation defenses.

</details>


### [21] [Silent Until Sparse: Backdoor Attacks on Semi-Structured Sparsity](https://arxiv.org/abs/2509.08747)
*Wei Guo,Maura Pintor,Ambra Demontis,Battista Biggio*

Main category: cs.CR

TL;DR: SUS攻击是一种针对半结构化稀疏化的后门攻击，在完整模型中是良性的，但在稀疏化后激活后门功能，攻击成功率从低于10%提升到超过99%。


<details>
  <summary>Details</summary>
Motivation: 针对现代GPU中通过稀疏矩阵乘法加速深度神经网络执行的半结构化稀疏化技术，研究其安全漏洞，开发一种在模型部署阶段难以检测的后门攻击方法。

Method: 采用双阶段攻击策略：1）后门训练阶段将恶意功能注入到剪枝过程中会被保留的权重中；2）后门隐藏阶段通过微调将被剪枝的元素来隐藏恶意行为

Result: 攻击成功威胁NVIDIA和PyTorch的半结构化稀疏化算法，无论模型架构如何，稀疏化前攻击成功率低于10%，稀疏化后超过99%，且能抵抗最先进的后门防御和微调

Conclusion: SUS攻击揭示了当前模型压缩和部署流程中的关键安全漏洞，半结构化稀疏化技术存在严重的安全风险

Abstract: In the deployment phase, semi-structured sparsity accelerates the execution
of deep neural networks on modern GPUs via sparse matrix multiplication. In
this paper, targeting the semi-structured sparsity, we introduce a Silent Until
Sparse (SUS) backdoor attack, where the released full model remains silent
(benign), but becomes a backdoored model after sparsification. The attack
operates in two phases: (i) in the backdoor training phase, the backdoor
functionality is injected into specific weights that will be retained during
the pruning process; (ii) in the backdoor hiding phase, the malicious behavior
is concealed by fine-tuning elements that will be pruned away. This dual-phase
approach ensures that the attack remains undetectable in the released model,
but activates properly once the model is pruned with the semi-structured
sparsity. Through extensive experiments, we show that our attack successfully
threatens the semi-structured sparsity algorithms from both NVIDIA and PyTorch.
Our empirical results show that, regardless of model architecture, the attack
success rate of the released model remains below 10% prior to sparsification
but exceeds 99% afterward. Moreover, we demonstrate that SUS attack is robust
against state-of-the-art backdoor defenses and finetuning, highlighting a
critical vulnerability in current model compression and deployment pipelines.

</details>


### [22] [Prototype-Guided Robust Learning against Backdoor Attacks](https://arxiv.org/abs/2509.08748)
*Wei Guo,Maura Pintor,Ambra Demontis,Battista Biggio*

Main category: cs.CR

TL;DR: PGRL是一种新型后门攻击防御方法，利用少量良性样本生成原型向量指导训练过程，能够有效抵御多种后门攻击，无需依赖特定假设或大规模无污染验证数据集。


<details>
  <summary>Details</summary>
Motivation: 现有后门攻击防御方法存在局限性，需要依赖特定触发信号、高毒化比例或大规模无污染验证数据集，无法应对多样化的后门攻击场景。

Method: 提出原型引导鲁棒学习(PGRL)方法，利用少量良性样本生成原型向量来指导训练过程，使模型在保持正常性能的同时抵御后门攻击。

Result: PGRL在8种现有防御方法中表现最优，具有卓越的鲁棒性，并在不同架构、数据集和高级攻击中展现出良好的泛化能力，即使在完全了解防御细节的自适应攻击下也能有效防御。

Conclusion: PGRL是一种通用且强大的后门攻击防御解决方案，克服了现有方法的局限性，为实际应用中的模型安全提供了有效保障。

Abstract: Backdoor attacks poison the training data to embed a backdoor in the model,
causing it to behave normally on legitimate inputs but maliciously when
specific trigger signals appear. Training a benign model from a dataset
poisoned by backdoor attacks is challenging. Existing works rely on various
assumptions and can only defend against backdoor attacks with specific trigger
signals, high poisoning ratios, or when the defender possesses a large,
untainted, validation dataset. In this paper, we propose a defense called
Prototype-Guided Robust Learning (PGRL), which overcomes all the aforementioned
limitations, being robust against diverse backdoor attacks. Leveraging a tiny
set of benign samples, PGRL generates prototype vectors to guide the training
process. We compare our PGRL with 8 existing defenses, showing that it achieves
superior robustness. We also demonstrate that PGRL generalizes well across
various architectures, datasets, and advanced attacks. Finally, to evaluate our
PGRL in the worst-case scenario, we perform an adaptive attack, where the
attackers fully know the details of the defense.

</details>


### [23] [Wanilla: Sound Noninterference Analysis for WebAssembly](https://arxiv.org/abs/2509.08758)
*Markus Scherer,Jeppe Fredsgaard Blaabjerg,Alexander Sjösten,Matteo Maffei*

Main category: cs.CR

TL;DR: 首个自动化、声音、全静态的WebAssembly非干扰分析工具Wanilla，通过提升达到性分析来验证内存完整性和信息流安全性。


<details>
  <summary>Details</summary>
Motivation: WebAssembly在安全关键领域作为软件组件分发格式广泛使用，但作为内存不安全语言的编译目标存在内存毁坏风险，需要非干扰分析来保证信息流安全和内存完整性。

Method: 提出了一种新题的通用方法，通过跟踪值上的污染标记，使用值敏感的关系推理在适当时机移除标记，将达到性分析提升为非干扰分析。

Result: 在Wanilla中实现了该方法，通过多个综合和实际测试案例验证了其性能和精度，成功验证了内存完整性和其他非干扰性质。

Conclusion: 该研究为WebAssembly提供了首个自动化、声音且全静态的非干扰分析方案，有效解决了内存完整性和信息流安全问题，在安全关键领域具有重要应用价值。

Abstract: WebAssembly (Wasm) is rapidly gaining popularity as a distribution format for
software components embedded in various security-critical domains.
Unfortunately, despite its prudent design, WebAssembly's primary use case as a
compilation target for memory-unsafe languages leaves some possibilities for
memory corruption. Independently of that, Wasm is an inherently interesting
target for information flow analysis due to its interfacing role.
  Both the information flows between a Wasm module and its embedding context,
as well as the memory integrity within a module, can be described by the
hyperproperty noninterference. So far, no sound, fully static noninterference
analysis for Wasm has been presented, but sound reachability analyses were.
This work presents a novel and general approach to lift reachability analyses
to noninterference by tracking taints on values and using value-sensitive,
relational reasoning to remove them when appropriate. We implement this
approach in Wanilla, the first automatic, sound, and fully static
noninterference analysis for WebAssembly, and demonstrate its performance and
precision by verifying memory integrity and other noninterference properties
with several synthetic and real-world benchmarks.

</details>


### [24] [Approximate Algorithms for Verifying Differential Privacy with Gaussian Distributions](https://arxiv.org/abs/2509.08804)
*Bishnu Bhusal,Rohit Chadha,A. Prasad Sistla,Mahesh Viswanathan*

Main category: cs.CR

TL;DR: 本文提出了一种验证使用高斯分布的差分隐私算法的新方法，通过近似概率分布和计算积分来验证(ε,δ)-差分隐私，实现了几乎可判定的验证问题。


<details>
  <summary>Details</summary>
Motivation: 高斯分布差分隐私算法的验证问题缺乏深入理解，现有方法难以有效验证这类程序的隐私保证。

Method: 引入新颖的概率分布近似方法，结合积分近似和尾部概率边界计算，使用FLINT库进行高精度积分计算，开发了DipApprox工具。

Result: 验证了(ε,δ)-差分隐私对于这类程序几乎是可判定的（除了有限个δ值），在稀疏向量技术和噪声最大算法等基础隐私保护算法上验证了有效性。

Conclusion: 该方法能够有效确认隐私保证并检测违规，为高斯分布差分隐私算法的验证提供了可行的解决方案。

Abstract: The verification of differential privacy algorithms that employ Gaussian
distributions is little understood. This paper tackles the challenge of
verifying such programs by introducing a novel approach to approximating
probability distributions of loop-free programs that sample from both discrete
and continuous distributions with computable probability density functions,
including Gaussian and Laplace. We establish that verifying
$(\epsilon,\delta)$-differential privacy for these programs is \emph{almost
decidable}, meaning the problem is decidable for all values of $\delta$ except
those in a finite set. Our verification algorithm is based on computing
probabilities to any desired precision by combining integral approximations,
and tail probability bounds. The proposed methods are implemented in the tool,
DipApprox, using the FLINT library for high-precision integral computations,
and incorporate optimizations to enhance scalability. We validate {\ourtool} on
fundamental privacy-preserving algorithms, such as Gaussian variants of the
Sparse Vector Technique and Noisy Max, demonstrating its effectiveness in both
confirming privacy guarantees and detecting violations.

</details>
