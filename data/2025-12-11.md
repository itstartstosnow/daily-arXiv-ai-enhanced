<div id=toc></div>

# Table of Contents

- [cs.CR](#cs.CR) [Total: 14]


<div id='cs.CR'></div>

# cs.CR [[Back]](#toc)

### [1] [EMMap: A Systematic Framework for Spatial EMFI Mapping and Fault Classification on Microcontrollers](https://arxiv.org/abs/2512.09049)
*Gandham Sai Santhosh,Siddhartha Sanjay Naik,Ritwik Badola,Chester Rebeiro*

Main category: cs.CR

TL;DR: 提出一个平台无关的电磁故障注入空间映射与故障分类框架，用于系统分析微控制器对空间探针位置的敏感性


<details>
  <summary>Details</summary>
Motivation: 现有文献缺乏统一的方法来系统映射电磁故障注入的空间敏感性和分类故障行为，需要一种可重复的工作流程来分析不同嵌入式架构的EMFI敏感性

Method: 基于O'Flynn和Kuhnapfel等人的研究，开发了一个平台无关的框架，包括空间EMFI映射和故障分类方法，并在三个代表性微控制器目标上进行了试点实验演示

Result: 通过ESP32（Xtensa LX6）和两个ChipWhisper板的初步实验，展示了该方法在实际应用中的可行性，验证了空间探针位置对故障结果的影响

Conclusion: 提出了一个通用且可重复的工作流程，研究人员可以将其应用于分析各种嵌入式架构的EMFI敏感性，为系统化电磁故障注入研究提供了方法论基础

Abstract: Electromagnetic Fault Injection (EMFI) is a powerful technique for inducing bit flips and instruction-level perturbations on microcontrollers, yet existing literature lacks a unified methodology for systematically mapping spatial sensitivity and classifying resulting fault behaviors. Building on insights from O'Flynn and Kuhnapfel et al., we introduce a platform-agnostic framework for Spatial EMFI Mapping and Fault Classification, aimed at understanding how spatial probe position influences fault outcomes. We present pilot experiments on three representative microcontroller targets including the Xtensa LX6 (ESP32) and two ChipWhisper boards not as definitive evaluations, but as illustrative demonstrations of how the proposed methodology can be applied in practice. These preliminary observations motivate a generalized and reproducible workflow that researchers can adopt when analyzing EMFI susceptibility across diverse embedded architectures.

</details>


### [2] [Exposing Vulnerabilities in Counterfeit Prevention Systems Utilizing Physically Unclonable Surface Features](https://arxiv.org/abs/2512.09150)
*Anirudh Nakra,Nayeeb Rashid,Chau-Wai Wong,Min Wu*

Main category: cs.CR

TL;DR: 该论文提出一个用于纸质物理不可克隆功能(PUF)认证的操作框架，揭示现有方法存在安全漏洞，设计了物理拒绝服务和数字伪造攻击，强调需要安全对策来确保可靠的防伪认证。


<details>
  <summary>Details</summary>
Motivation: 假冒产品通过渗透不可信供应链对公共健康和安全构成重大风险。虽然利用纸张表面固有的微观不规则性进行防伪是一种准确且经济高效的解决方案，但现有认证方法可能存在安全漏洞，导致技术可行性与安全实际部署之间存在差距。

Method: 通过形式化一个纸质PUF认证的操作框架，从物理和数字两个领域揭示系统级漏洞，设计物理拒绝服务和数字伪造攻击来破坏正常认证，并基于该框架进行分阶段的安全分析。

Result: 设计的攻击证明了现有纸质PUF认证系统的脆弱性，强调了需要安全对策来确保可靠和有弹性的认证。提出的框架为未来防伪系统的设计提供了指导。

Conclusion: 纸质PUF认证系统存在安全漏洞，需要全面的安全对策。提出的操作框架有助于系统级安全分析，为设计更安全的防伪系统提供基础，确保技术可行性与安全部署之间的协调。

Abstract: Counterfeit products pose significant risks to public health and safety through infiltrating untrusted supply chains. Among numerous anti-counterfeiting techniques, leveraging inherent, unclonable microscopic irregularities of paper surfaces is an accurate and cost-effective solution. Prior work of this approach has focused on enabling ubiquitous acquisition of these physically unclonable features (PUFs). However, we will show that existing authentication methods relying on paper surface PUFs may be vulnerable to adversaries, resulting in a gap between technological feasibility and secure real-world deployment. This gap is investigated through formalizing an operational framework for paper-PUF-based authentication. Informed by this framework, we reveal system-level vulnerabilities across both physical and digital domains, designing physical denial-of-service and digital forgery attacks to disrupt proper authentication. The effectiveness of the designed attacks underscores the strong need for security countermeasures for reliable and resilient authentication based on paper PUFs. The proposed framework further facilitates a comprehensive, stage-by-stage security analysis, guiding the design of future counterfeit prevention systems. This analysis delves into potential attack strategies, offering a foundational understanding of how various system components, such as physical features and verification processes, might be exploited by adversaries.

</details>


### [3] [Analysis of the Security Design, Engineering, and Implementation of the SecureDNA System](https://arxiv.org/abs/2512.09233)
*Alan T. Sherman,Jeremy J. Romanik Romano,Edward Zieglar,Enis Golaszewski,Jonathan D. Fuchs,William E. Byrd*

Main category: cs.CR

TL;DR: 对SecureDNA系统安全分析发现其自定义认证协议SCEP存在结构性弱点，仅实现单向认证，且缺乏加密绑定，可能被绕过速率限制和重放攻击。


<details>
  <summary>Details</summary>
Motivation: SecureDNA系统旨在通过密码学保护DNA合成订单请求和危险序列数据库的机密性，但需要评估其系统设计、工程实现和协议安全性，以确保实际部署中的安全防护有效性。

Method: 通过源代码分析（版本1.0.8）检查密钥管理、证书基础设施、认证和速率限制机制，并对相互认证、基本请求和豁免处理协议进行首次形式化方法分析。

Result: 发现SCEP协议仅实现单向认证，危险数据库和密钥服务器无法识别通信对象；缺乏加密绑定使得TLS通道内的响应可能被修改或重放；这些结构性弱点违反了深度防御原则，可能被绕过速率限制保护。

Conclusion: SecureDNA系统存在结构性安全弱点，建议添加强加密绑定等缓解措施。软件版本1.1.0已通过SCEP+协议修复了SCEP问题，但系统仍需加强安全工程设计。

Abstract: We analyze security aspects of the SecureDNA system regarding its system design, engineering, and implementation. This system enables DNA synthesizers to screen order requests against a database of hazards. By applying novel cryptography, the system aims to keep order requests and the database of hazards secret. Discerning the detailed operation of the system in part from source code (Version 1.0.8), our analysis examines key management, certificate infrastructure, authentication, and rate-limiting mechanisms. We also perform the first formal-methods analysis of the mutual authentication, basic request, and exemption-handling protocols.
  Without breaking the cryptography, our main finding is that SecureDNA's custom mutual authentication protocol SCEP achieves only one-way authentication: the hazards database and keyservers never learn with whom they communicate. This structural weakness violates the principle of defense in depth and enables an adversary to circumvent rate limits that protect the secrecy of the hazards database, if the synthesizer connects with a malicious or corrupted keyserver or hashed database. We point out an additional structural weakness that also violates the principle of defense in depth: inadequate cryptographic bindings prevent the system from detecting if responses, within a TLS channel, from the hazards database were modified. Consequently, if a synthesizer were to reconnect with the database over the same TLS session, an adversary could replay and swap responses from the database without breaking TLS. Although the SecureDNA implementation does not allow such reconnections, it would be stronger security engineering to avoid the underlying structural weakness. We identify these vulnerabilities and suggest and verify mitigations, including adding strong bindings. Software Version 1.1.0 fixes SCEP with our proposed SCEP+ protocol.

</details>


### [4] [FBA$^2$D: Frequency-based Black-box Attack for AI-generated Image Detection](https://arxiv.org/abs/2512.09264)
*Xiaojing Chen,Dan Li,Lijun Peng,Jun YanŁetter,Zhiqing Guo,Junyang Chen,Xiao Lan,Zhongjie Ba,Yunfeng DiaoŁetter*

Main category: cs.CR

TL;DR: 提出FBA²D方法：基于频率的黑盒决策攻击，针对AIGC检测器，利用DCT进行频带选择，提高查询效率和图像质量


<details>
  <summary>Details</summary>
Motivation: AIGC发展引发虚假信息传播担忧，现有检测器易受对抗样本攻击。实际应用中攻击者只能通过API查询黑盒模型，但决策型攻击在AIGC检测领域尚未探索

Method: 1) 基于生成图像与真实图像的频域差异，使用DCT进行精细频谱划分，选择频带作为查询子空间；2) 采用"对抗样本汤"方法，平均连续代理迭代的候选结果作为初始化，加速查询攻击

Result: 在Synthetic LSUN和GenImage数据集上的实证研究表明，该方法能有效攻击AIGC检测器，同时保持图像质量并满足严格的查询预算限制

Conclusion: 填补了AIGC检测器决策型攻击的研究空白，揭示了实际AIGC安全问题的紧迫性，为防御设计提供了重要参考

Abstract: The prosperous development of Artificial Intelligence-Generated Content (AIGC) has brought people's anxiety about the spread of false information on social media. Designing detectors for filtering is an effective defense method, but most detectors will be compromised by adversarial samples. Currently, most studies exposing AIGC security issues assume information on model structure and data distribution. In real applications, attackers query and interfere with models that provide services in the form of application programming interfaces (APIs), which constitutes the black-box decision-based attack paradigm. However, to the best of our knowledge, decision-based attacks on AIGC detectors remain unexplored. In this study, we propose \textbf{FBA$^2$D}: a frequency-based black-box attack method for AIGC detection to fill the research gap. Motivated by frequency-domain discrepancies between generated and real images, we develop a decision-based attack that leverages the Discrete Cosine Transform (DCT) for fine-grained spectral partitioning and selects frequency bands as query subspaces, improving both query efficiency and image quality. Moreover, attacks on AIGC detectors should mitigate initialization failures, preserve image quality, and operate under strict query budgets. To address these issues, we adopt an ``adversarial example soup'' method, averaging candidates from successive surrogate iterations and using the result as the initialization to accelerate the query-based attack. The empirical study on the Synthetic LSUN dataset and GenImage dataset demonstrate the effectiveness of our prosed method. This study shows the urgency of addressing practical AIGC security problems.

</details>


### [5] [ObliInjection: Order-Oblivious Prompt Injection Attack to LLM Agents with Multi-source Data](https://arxiv.org/abs/2512.09321)
*Ruiqi Wang,Yuqi Jia,Neil Zhenqiang Gong*

Main category: cs.CR

TL;DR: 提出ObliInjection攻击方法，针对多源输入的LLM应用，通过顺序无关损失和orderGCG算法优化污染片段，即使只控制少量输入源也能有效实施提示注入攻击。


<details>
  <summary>Details</summary>
Motivation: 现有提示注入攻击主要针对单源输入场景，忽略了多源输入应用中攻击者只能控制部分输入源且不知道片段顺序的现实情况，导致在多源数据领域的攻击效果有限。

Method: 提出ObliInjection攻击框架：1) 顺序无关损失函数，量化LLM完成攻击者指定任务的可能性，无论清洁和污染片段的排列顺序；2) orderGCG算法，专门用于最小化顺序无关损失并优化污染片段。

Result: 在三个不同应用领域的数据集和12个LLM上的综合实验表明，ObliInjection攻击高度有效，即使在输入数据中只有1/6到1/100的片段被污染的情况下也能成功。

Conclusion: ObliInjection是首个针对多源输入LLM应用的提示注入攻击，通过顺序无关优化方法解决了现有攻击在多源场景下的局限性，展示了即使在攻击者控制有限输入源的情况下也能有效实施攻击。

Abstract: Prompt injection attacks aim to contaminate the input data of an LLM to mislead it into completing an attacker-chosen task instead of the intended task. In many applications and agents, the input data originates from multiple sources, with each source contributing a segment of the overall input. In these multi-source scenarios, an attacker may control only a subset of the sources and contaminate the corresponding segments, but typically does not know the order in which the segments are arranged within the input. Existing prompt injection attacks either assume that the entire input data comes from a single source under the attacker's control or ignore the uncertainty in the ordering of segments from different sources. As a result, their success is limited in domains involving multi-source data.
  In this work, we propose ObliInjection, the first prompt injection attack targeting LLM applications and agents with multi-source input data. ObliInjection introduces two key technical innovations: the order-oblivious loss, which quantifies the likelihood that the LLM will complete the attacker-chosen task regardless of how the clean and contaminated segments are ordered; and the orderGCG algorithm, which is tailored to minimize the order-oblivious loss and optimize the contaminated segments. Comprehensive experiments across three datasets spanning diverse application domains and twelve LLMs demonstrate that ObliInjection is highly effective, even when only one out of 6-100 segments in the input data is contaminated.

</details>


### [6] [BugSweeper: Function-Level Detection of Smart Contract Vulnerabilities Using Graph Neural Networks](https://arxiv.org/abs/2512.09385)
*Uisang Lee,Changhoon Chung,Junmo Lee,Soo-Mook Moon*

Main category: cs.CR

TL;DR: BugSweeper是一个端到端的深度学习框架，直接从Solidity源代码检测智能合约漏洞，无需手动规则工程，通过函数级抽象语法图(FLAG)和两阶段图神经网络实现


<details>
  <summary>Details</summary>
Motivation: 现有基于机器学习的漏洞检测方法大多依赖领域专家设计的基于规则的预处理，这会丢弃源代码中的重要上下文信息，可能导致某些漏洞被忽略，且难以适应新出现的威胁

Method: 将每个Solidity函数表示为函数级抽象语法图(FLAG)，结合抽象语法树(AST)并增强控制流和数据流语义；使用两阶段图神经网络：第一阶段过滤语法图中的噪声，第二阶段进行高级推理以检测多种漏洞

Result: 在真实世界合约上的大量实验表明，BugSweeper显著优于所有最先进的检测方法

Conclusion: 通过消除对手工规则的需求，该方法提供了一个鲁棒、自动化、可扩展的智能合约安全解决方案，无需依赖安全专家

Abstract: The rapid growth of Ethereum has made it more important to quickly and accurately detect smart contract vulnerabilities. While machine-learning-based methods have shown some promise, many still rely on rule-based preprocessing designed by domain experts. Rule-based preprocessing methods often discard crucial context from the source code, potentially causing certain vulnerabilities to be overlooked and limiting adaptability to newly emerging threats. We introduce BugSweeper, an end-to-end deep learning framework that detects vulnerabilities directly from the source code without manual engineering. BugSweeper represents each Solidity function as a Function-Level Abstract Syntax Graph (FLAG), a novel graph that combines its Abstract Syntax Tree (AST) with enriched control-flow and data-flow semantics. Then, our two-stage Graph Neural Network (GNN) analyzes these graphs. The first-stage GNN filters noise from the syntax graphs, while the second-stage GNN conducts high-level reasoning to detect diverse vulnerabilities. Extensive experiments on real-world contracts show that BugSweeper significantly outperforms all state-of-the-art detection methods. By removing the need for handcrafted rules, our approach offers a robust, automated, and scalable solution for securing smart contracts without any dependence on security experts.

</details>


### [7] [Proof of Trusted Execution: A Consensus Paradigm for Deterministic Blockchain Finality](https://arxiv.org/abs/2512.09409)
*Kyle Habib,Vladislav Kapitsyn,Giovanni Mazzeo,Faisal Mehrban*

Main category: cs.CR

TL;DR: 提出Proof of Trusted Execution (PoTE)共识协议，利用可信执行环境(TEE)实现单轮验证，避免分叉和性能瓶颈


<details>
  <summary>Details</summary>
Motivation: 现有PoW能耗高延迟大，PoS存在权益集中、长程攻击等问题，且受限于时隙时间和多轮投票的性能瓶颈

Method: 验证者在异构VM-based TEEs中运行相同规范程序，生成供应商支持的证明，将代码哈希与区块内容绑定，通过确定性执行和公开随机性避免分叉

Result: PoTE避免分叉，消除时隙时间瓶颈，单轮验证即可提交区块

Conclusion: PoTE共识范式通过可验证执行而非重复执行实现共识，提供高效安全的区块链共识方案

Abstract: Current blockchain consensus protocols -- notably, Proof of Work (PoW) and Proof of Stake (PoS) -- deliver global agreement but exhibit structural constraints. PoW anchors security in heavy computation, inflating energy use and imposing high confirmation latency. PoS improves efficiency but introduces stake concentration, long-range and "nothing-at-stake" vulnerabilities, and a hard performance ceiling shaped by slot times and multi-round committee voting. In this paper, we propose Proof of Trusted Execution (PoTE), a consensus paradigm where agreement emerges from verifiable execution rather than replicated re-execution. Validators operate inside heterogeneous VM-based TEEs, each running the same canonical program whose measurement is publicly recorded, and each producing vendor-backed attestations that bind the enclave code hash to the block contents. Because the execution is deterministic and the proposer is uniquely derived from public randomness, PoTE avoids forks, eliminates slot.time bottlenecks, and commits blocks in a single round of verification. We present the design of a PoTE consensus client, describe our reference implementation, and evaluate its performance against the stringent throughput requirements of the Trillion decentralized exchange.

</details>


### [8] [Reference Recommendation based Membership Inference Attack against Hybrid-based Recommender Systems](https://arxiv.org/abs/2512.09442)
*Xiaoxiao Chi,Xuyun Zhang,Yan Wang,Hongsheng Hu,Wanchun Dou*

Main category: cs.CR

TL;DR: 本文提出了一种针对混合推荐系统的基于度量的成员推理攻击方法，利用个性化推荐特性来推断用户数据是否被用于训练推荐系统。


<details>
  <summary>Details</summary>
Motivation: 现有成员推理攻击方法未能充分利用推荐系统的独特特性，仅适用于包含两种推荐算法的混合推荐系统，无法有效攻击基于用户-物品历史交互和属性进行个性化推荐的混合推荐系统。

Method: 提出基于度量的成员推理攻击方法：利用个性化特性为目标用户获取参考推荐，然后提出相对成员度量，结合目标用户的历史交互、目标推荐和参考推荐来推断用户数据的成员身份。

Result: 通过理论和实证分析证明了所提出的基于度量的成员推理攻击方法在混合推荐系统上的有效性。

Conclusion: 混合推荐系统中的个性化特性会影响成员推理攻击的效果，提出的基于度量的攻击方法能够有效利用这一特性，填补了现有研究在混合推荐系统成员推理攻击方面的空白。

Abstract: Recommender systems have been widely deployed across various domains such as e-commerce and social media, and intelligently suggest items like products and potential friends to users based on their preferences and interaction history, which are often privacy-sensitive. Recent studies have revealed that recommender systems are prone to membership inference attacks (MIAs), where an attacker aims to infer whether or not a user's data has been used for training a target recommender system. However, existing MIAs fail to exploit the unique characteristic of recommender systems, and therefore are only applicable to mixed recommender systems consisting of two recommendation algorithms. This leaves a gap in investigating MIAs against hybrid-based recommender systems where the same algorithm utilizing user-item historical interactions and attributes of users and items serves and produces personalised recommendations. To investigate how the personalisation in hybrid-based recommender systems influences MIA, we propose a novel metric-based MIA. Specifically, we leverage the characteristic of personalisation to obtain reference recommendation for any target users. Then, a relative membership metric is proposed to exploit a target user's historical interactions, target recommendation, and reference recommendation to infer the membership of the target user's data. Finally, we theoretically and empirically demonstrate the efficacy of the proposed metric-based MIA on hybrid-based recommender systems.

</details>


### [9] [Advancing LLM-Based Security Automation with Customized Group Relative Policy Optimization for Zero-Touch Networks](https://arxiv.org/abs/2512.09485)
*Xinye Cao,Yihan Lin,Guoshun Nan,Qinchuan Zhou,Yuhang Luo,Yurui Gao,Zeliang Zhang,Haolang Lu,Qimei Cui,Yanzhao Hou,Xiaofeng Tao,Tony Q. S. Quek*

Main category: cs.CR

TL;DR: 提出了SecLoop和SA-GRPO两个方案，用于解决6G零接触网络中的安全自动化挑战，实现从安全策略生成到验证更新的全生命周期自动化管理。


<details>
  <summary>Details</summary>
Motivation: 6G零接触网络具有分布式架构、高度开放性和深度异构性，这扩大了攻击面并带来了前所未有的安全挑战。安全自动化是实现6G ZTN智能安全管理的关键能力，但面临两大挑战：1）在真实、并行、对抗条件下自动化安全策略的生命周期管理；2）使安全策略能够适应不断演变的威胁和动态环境。

Method: 提出了SecLoop框架，首次将大语言模型集成到安全策略生成、编排、响应和反馈的整个生命周期中，实现动态网络环境中的智能自适应防御。同时提出了SA-GRPO算法，这是一种新颖的安全感知群体相对策略优化算法，通过对比从并行SecLoop执行中收集的群体反馈来迭代优化安全策略。

Result: 在五个基准测试上进行了广泛的真实世界实验，包括11个MITRE ATT&CK流程和超过20种攻击类型，证明了SecLoop和SA-GRPO的优越性。作者将向社区发布平台，促进下一代通信安全自动化的发展。

Conclusion: SecLoop和SA-GRPO成功解决了6G零接触网络中安全自动化的两大关键挑战，为实现下一代通信网络的安全自动化管理提供了有效解决方案。

Abstract: Zero-Touch Networks (ZTNs) represent a transformative paradigm toward fully automated and intelligent network management, providing the scalability and adaptability required for the complexity of sixth-generation (6G) networks. However, the distributed architecture, high openness, and deep heterogeneity of 6G networks expand the attack surface and pose unprecedented security challenges. To address this, security automation aims to enable intelligent security management across dynamic and complex environments, serving as a key capability for securing 6G ZTNs. Despite its promise, implementing security automation in 6G ZTNs presents two primary challenges: 1) automating the lifecycle from security strategy generation to validation and update under real-world, parallel, and adversarial conditions, and 2) adapting security strategies to evolving threats and dynamic environments. This motivates us to propose SecLoop and SA-GRPO. SecLoop constitutes the first fully automated framework that integrates large language models (LLMs) across the entire lifecycle of security strategy generation, orchestration, response, and feedback, enabling intelligent and adaptive defenses in dynamic network environments, thus tackling the first challenge. Furthermore, we propose SA-GRPO, a novel security-aware group relative policy optimization algorithm that iteratively refines security strategies by contrasting group feedback collected from parallel SecLoop executions, thereby addressing the second challenge. Extensive real-world experiments on five benchmarks, including 11 MITRE ATT&CK processes and over 20 types of attacks, demonstrate the superiority of the proposed SecLoop and SA-GRPO. We will release our platform to the community, facilitating the advancement of security automation towards next generation communications.

</details>


### [10] [Comparative Analysis of Hash-based Malware Clustering via K-Means](https://arxiv.org/abs/2512.09539)
*Aink Acrie Soe Thein,Nikolaos Pitropakis,Pavlos Papadopoulos,Sam Grierson,Sana Ullah Jan*

Main category: cs.CR

TL;DR: 评估三种哈希算法（SSDeep、TLSH、IMPHash）在恶意软件聚类中的表现，发现TLSH和IMPHash能产生更清晰、语义更明确的聚类，而SSDeep在更广泛的分类任务中更高效。


<details>
  <summary>Details</summary>
Motivation: 随着数字设备普及，网络攻击面扩大，攻击者不断寻找新途径部署恶意软件。现有检测方法通常使用哈希算法（如SSDeep、TLSH、IMPHash）来捕获二进制文件的结构和行为相似性，需要评估这些技术在恶意软件聚类中的实际效果。

Method: 使用K-means算法对恶意软件样本进行聚类分析，实验了SSDeep、TLSH和IMPHash三种哈希技术，在已建立的恶意软件家族和特征上进行测试。

Result: TLSH和IMPHash能产生更清晰、语义更明确的聚类结果，而SSDeep在更广泛的分类任务中表现更高效。

Conclusion: 研究结果可以指导开发更强大的威胁检测机制和自适应安全机制，为恶意软件分析中的哈希算法选择提供实证依据。

Abstract: With the adoption of multiple digital devices in everyday life, the cyber-attack surface has increased. Adversaries are continuously exploring new avenues to exploit them and deploy malware. On the other hand, detection approaches typically employ hashing-based algorithms such as SSDeep, TLSH, and IMPHash to capture structural and behavioural similarities among binaries. This work focuses on the analysis and evaluation of these techniques for clustering malware samples using the K-means algorithm. More specifically, we experimented with established malware families and traits and found that TLSH and IMPHash produce more distinct, semantically meaningful clusters, whereas SSDeep is more efficient for broader classification tasks. The findings of this work can guide the development of more robust threat-detection mechanisms and adaptive security mechanisms.

</details>


### [11] [Chasing Shadows: Pitfalls in LLM Security Research](https://arxiv.org/abs/2512.09549)
*Jonathan Evertz,Niklas Risse,Nicolai Neuer,Andreas Müller,Philipp Normann,Gaetano Sapia,Srishti Gupta,David Pape,Soumya Shaw,Devansh Srivastav,Christian Wressnegger,Erwin Quiring,Thorsten Eisenhofer,Daniel Arp,Lea Schönherr*

Main category: cs.CR

TL;DR: 该论文识别了LLM安全研究中九个常见陷阱，分析了72篇顶会论文发现每篇都至少存在一个陷阱，但仅15.7%被明确讨论，并通过案例研究展示了这些陷阱如何误导评估、夸大性能或损害可复现性。


<details>
  <summary>Details</summary>
Motivation: 大型语言模型在安全研究中日益普及，但其独特特性挑战了研究的可复现性、严谨性和评估范式。现有关于机器学习研究陷阱的工作早于LLM时代，需要专门针对LLM安全研究识别新出现的陷阱。

Method: 1. 识别LLM安全研究中九个常见陷阱；2. 分析2023-2024年安全与软件工程顶会的72篇同行评审论文；3. 通过四个实证案例研究评估陷阱的实际影响；4. 提出可操作的指导方针。

Result: 1. 所有72篇论文都至少包含一个陷阱；2. 每个陷阱都在多篇论文中出现；3. 仅15.7%的陷阱被明确讨论；4. 案例研究表明陷阱会误导评估、夸大性能、损害可复现性。

Conclusion: LLM安全研究普遍存在未被充分认识的陷阱，威胁研究有效性。需要提高意识并采用更严谨的方法，论文提供的指导方针可帮助社区改进未来研究。

Abstract: Large language models (LLMs) are increasingly prevalent in security research. Their unique characteristics, however, introduce challenges that undermine established paradigms of reproducibility, rigor, and evaluation. Prior work has identified common pitfalls in traditional machine learning research, but these studies predate the advent of LLMs. In this paper, we identify \emph{nine} common pitfalls that have become (more) relevant with the emergence of LLMs and that can compromise the validity of research involving them. These pitfalls span the entire computation process, from data collection, pre-training, and fine-tuning to prompting and evaluation.
  We assess the prevalence of these pitfalls across all 72 peer-reviewed papers published at leading Security and Software Engineering venues between 2023 and 2024. We find that every paper contains at least one pitfall, and each pitfall appears in multiple papers. Yet only 15.7\% of the present pitfalls were explicitly discussed, suggesting that the majority remain unrecognized. To understand their practical impact, we conduct four empirical case studies showing how individual pitfalls can mislead evaluation, inflate performance, or impair reproducibility. Based on our findings, we offer actionable guidelines to support the community in future work.

</details>


### [12] [Defining Cost Function of Steganography with Large Language Models](https://arxiv.org/abs/2512.09769)
*Hanzhou Wu,Yige Wang*

Main category: cs.CR

TL;DR: 本文首次尝试利用大语言模型定义隐写成本函数，通过两阶段策略结合LLM引导的程序合成与进化搜索，自动生成优于现有方法的隐写成本函数。


<details>
  <summary>Details</summary>
Motivation: 传统隐写成本函数设计严重依赖专家知识或需要大规模数据集进行成本学习，本文旨在探索利用大语言模型自动设计隐写成本函数的新方法。

Method: 采用两阶段策略：第一阶段通过LLM响应结构化提示合成计算机程序形式的成本函数，并用预训练隐写分析模型评估；第二阶段为每个候选成本函数重新训练隐写分析模型，根据检测精度确定最优成本函数，通过迭代方式收集最佳成本函数。

Result: 实验表明，该方法设计的隐写成本函数在抵抗隐写分析工具方面显著优于现有工作，验证了方法的优越性。

Conclusion: 这是首次将LLM应用于高级隐写成本函数设计的工作，为隐写设计提供了新视角，可能启发进一步研究。

Abstract: In this paper, we make the first attempt towards defining cost function of steganography with large language models (LLMs), which is totally different from previous works that rely heavily on expert knowledge or require large-scale datasets for cost learning. To achieve this goal, a two-stage strategy combining LLM-guided program synthesis with evolutionary search is applied in the proposed method. In the first stage, a certain number of cost functions in the form of computer program are synthesized from LLM responses to structured prompts. These cost functions are then evaluated with pretrained steganalysis models so that candidate cost functions suited to steganography can be collected. In the second stage, by retraining a steganalysis model for each candidate cost function, the optimal cost function(s) can be determined according to the detection accuracy. This two-stage strategy is performed by an iterative fashion so that the best cost function can be collected at the last iteration. Experiments show that the proposed method enables LLMs to design new cost functions of steganography that significantly outperform existing works in terms of resisting steganalysis tools, which verifies the superiority of the proposed method. To the best knowledge of the authors, this is the first work applying LLMs to the design of advanced cost function of steganography, which presents a novel perspective for steganography design and may shed light on further research.

</details>


### [13] [FlipLLM: Efficient Bit-Flip Attacks on Multimodal LLMs using Reinforcement Learning](https://arxiv.org/abs/2512.09872)
*Khurram Khalil,Khaza Anuarul Hoque*

Main category: cs.CR

TL;DR: FlipLLM：基于强化学习的通用框架，用于高效发现大语言模型和视觉语言模型中的位翻转攻击漏洞，比现有方法快2.5倍，并能指导硬件防护机制。


<details>
  <summary>Details</summary>
Motivation: 现有位翻转攻击发现方法缺乏通用性和可扩展性，难以分析现代基础模型的庞大参数空间和复杂依赖关系。生成式AI模型虽然性能优异，但仍易受硬件威胁影响。

Method: 提出FlipLLM框架，将位翻转攻击发现建模为顺序决策问题。结合敏感度引导的层剪枝和Q学习，高效识别最小但影响最大的位集合。

Result: FlipLLM比现有方法快2.5倍，仅翻转5位就能将LLaMA 3.1 8B准确率从69.9%降至0.2%，翻转7位将LLaVA的VQA得分从78%降至近0%。应用ECC SECDED等硬件保护机制可完全缓解攻击。

Conclusion: FlipLLM为语言和多模态基础模型提供了首个可扩展、自适应的位翻转攻击漏洞分析方法，为全面的硬件安全评估铺平了道路，具有实际指导硬件防护的价值。

Abstract: Generative Artificial Intelligence models, such as Large Language Models (LLMs) and Large Vision Models (VLMs), exhibit state-of-the-art performance but remain vulnerable to hardware-based threats, specifically bit-flip attacks (BFAs). Existing BFA discovery methods lack generalizability and struggle to scale, often failing to analyze the vast parameter space and complex interdependencies of modern foundation models in a reasonable time. This paper proposes FlipLLM, a reinforcement learning (RL) architecture-agnostic framework that formulates BFA discovery as a sequential decision-making problem. FlipLLM combines sensitivity-guided layer pruning with Q-learning to efficiently identify minimal, high-impact bit sets that can induce catastrophic failure. We demonstrate the effectiveness and generalizability of FlipLLM by applying it to a diverse set of models, including prominent text-only LLMs (GPT-2 Large, LLaMA 3.1 8B, and DeepSeek-V2 7B), VLMs such as LLaVA 1.6, and datasets, such as MMLU, MMLU-Pro, VQAv2, and TextVQA. Our results show that FlipLLM can identify critical bits that are vulnerable to BFAs up to 2.5x faster than SOTA methods. We demonstrate that flipping the FlipLLM-identified bits plummets the accuracy of LLaMA 3.1 8B from 69.9% to ~0.2%, and for LLaVA's VQA score from 78% to almost 0%, by flipping as few as 5 and 7 bits, respectively. Further analysis reveals that applying standard hardware protection mechanisms, such as ECC SECDED, to the FlipLLM-identified bit locations completely mitigates the BFA impact, demonstrating the practical value of our framework in guiding hardware-level defenses. FlipLLM offers the first scalable and adaptive methodology for exploring the BFA vulnerability of both language and multimodal foundation models, paving the way for comprehensive hardware-security evaluation.

</details>


### [14] [ByteShield: Adversarially Robust End-to-End Malware Detection through Byte Masking](https://arxiv.org/abs/2512.09883)
*Daniel Gibert,Felip Manyà*

Main category: cs.CR

TL;DR: 提出一种基于字节级掩码的新型防御机制，通过生成多个掩码版本的文件、独立分类每个版本，并使用基于阈值的投票机制来增强端到端恶意软件检测器对抗对抗攻击的能力。


<details>
  <summary>Details</summary>
Motivation: 现有基于随机化和去随机化平滑的防御机制容易受到插入大量对抗性载荷的攻击，需要更有效的防御方法来保护端到端恶意软件检测器。

Method: 采用确定性掩码策略，在整个输入文件上系统地滑动掩码，生成多个掩码版本。对每个版本独立分类，然后应用基于阈值的投票机制进行最终分类。

Result: 在EMBER和BODMAS数据集上的实验表明，该防御机制优于随机化和去随机化平滑防御，能够有效对抗各种功能保持操作生成的对抗样本，同时在干净样本上保持高准确率。

Conclusion: 提出的字节级掩码防御机制通过结构化掩码策略和投票机制，能够有效减轻对抗性载荷的影响，为端到端恶意软件检测器提供了更强大的防御能力。

Abstract: Research has proven that end-to-end malware detectors are vulnerable to adversarial attacks. In response, the research community has proposed defenses based on randomized and (de)randomized smoothing. However, these techniques remain susceptible to attacks that insert large adversarial payloads. To address these limitations, we propose a novel defense mechanism designed to harden end-to-end malware detectors by leveraging masking at the byte level. This mechanism operates by generating multiple masked versions of the input file, independently classifying each version, and then applying a threshold-based voting mechanism to produce the final classification. Key to this defense is a deterministic masking strategy that systematically strides a mask across the entire input file. Unlike randomized smoothing defenses, which randomly mask or delete bytes, this structured approach ensures coverage of the file over successive versions. In the best-case scenario, this strategy fully occludes the adversarial payload, effectively neutralizing its influence on the model's decision. In the worst-case scenario, it partially occludes the adversarial payload, reducing its impact on the model's predictions. By occluding the adversarial payload in one or more masked versions, this defense ensures that some input versions remain representative of the file's original intent, allowing the voting mechanism to suppress the influence of the adversarial payload. Results achieved on the EMBER and BODMAS datasets demonstrate the suitability of our defense, outperforming randomized and (de)randomized smoothing defenses against adversarial examples generated with a wide range of functionality-preserving manipulations while maintaining high accuracy on clean examples.

</details>
