<div id=toc></div>

# Table of Contents

- [cs.CR](#cs.CR) [Total: 23]


<div id='cs.CR'></div>

# cs.CR [[Back]](#toc)

### [1] [Cybersecurity Data Extraction from Common Crawl](https://arxiv.org/abs/2602.22218)
*Ashim Mahara*

Main category: cs.CR

TL;DR: Alpha-Root是一个网络安全数据集，通过社区检测从Common Crawl网络图中一次性收集，使用20个可信种子域直接从网络图中挖掘高质量域


<details>
  <summary>Details</summary>
Motivation: 传统方法如DeepSeekMath采用迭代内容评分方法，作者希望开发一种更直接的方法来挖掘高质量网络安全数据，直接从网络图结构中识别优质域

Method: 使用社区检测技术从Common Crawl网络图中一次性收集数据，仅从20个可信种子域开始，通过分析网络图结构直接挖掘高质量域

Result: 创建了Alpha-Root网络安全数据集，该方法避免了传统迭代评分方法的复杂性，直接从网络图结构中识别优质域

Conclusion: 通过社区检测和网络图分析，可以从少量可信种子域开始，直接挖掘高质量网络安全数据，为网络安全研究提供了新的数据收集方法

Abstract: Alpha-Root is a cybersecurity-focused dataset collected in a single shot from the Common Crawl web graph using community detection. Unlike iterative content-scoring approaches like DeepSeekMath, we mine quality domains directly from the web graph, starting from just 20 trusted seed domains.

</details>


### [2] [An Adaptive Multichain Blockchain: A Multiobjective Optimization Approach](https://arxiv.org/abs/2602.22230)
*Nimrod Talmon,Haim Zysberg*

Main category: cs.CR

TL;DR: 提出一个将区块链配置建模为多智能体资源分配问题的动态多链架构，通过优化器将应用和操作者分组到临时链中，最大化治理加权的综合效用。


<details>
  <summary>Details</summary>
Motivation: 区块链在安全交易处理方面应用广泛，但其可扩展性有限，现有的多链设计通常是静态的，无法适应需求和容量的动态变化。

Method: 将区块链配置建模为多智能体资源分配问题：应用和操作者声明需求、容量和价格边界；优化器在每个时期将它们分组到临时链中，并设置链级清算价格。目标是最大化应用、操作者和系统的治理加权标准化效用组合。该模型是模块化的，支持能力兼容性、应用类型多样性和时期间稳定性，可在链下求解并在链上验证结果。

Result: 分析了公平性和激励问题，并通过仿真实验展示了吞吐量、去中心化程度、操作者收益和服务稳定性之间的权衡关系。

Conclusion: 提出了一种动态多链资源配置框架，能够适应需求变化，平衡各方利益，并通过链下优化、链上验证的方式实现高效可扩展的区块链架构。

Abstract: Blockchains are widely used for secure transaction processing, but their scalability remains limited, and existing multichain designs are typically static even as demand and capacity shift. We cast blockchain configuration as a multiagent resource-allocation problem: applications and operators declare demand, capacity, and price bounds; an optimizer groups them into ephemeral chains each epoch and sets a chain-level clearing price. The objective maximizes a governance-weighted combination of normalized utilities for applications, operators, and the system. The model is modular -- accommodating capability compatibility, application-type diversity, and epoch-to-epoch stability -- and can be solved off-chain with outcomes verifiable on-chain. We analyze fairness and incentive issues and present simulations that highlight trade-offs among throughput, decentralization, operator yield, and service stability.

</details>


### [3] [Optimized Disaster Recovery for Distributed Storage Systems: Lightweight Metadata Architectures to Overcome Cryptographic Hashing Bottleneck](https://arxiv.org/abs/2602.22237)
*Prasanna Kumar,Nishank Soni,Gaurang Munje*

Main category: cs.CR

TL;DR: 论文提出用确定性元数据驱动标识替代传统基于哈希的数据识别方法，以解决灾备场景中哈希索引失效导致的恢复时间瓶颈问题。


<details>
  <summary>Details</summary>
Motivation: 传统基于内容哈希的数据识别方法在灾备场景中存在根本性缺陷：当哈希索引过时、不完整或在崩溃后需要重建时，必须进行全量或部分重哈希计算，这严重影响了恢复时间目标（RTO）的合规性。

Method: 提出通用架构转变，采用确定性元数据驱动标识：在数据摄取时为数据块分配全局唯一的复合标识符（不依赖内容分析），从而实现灾备期间无需加密开销的即时差异计算。

Result: 论文精确描述了全量或部分重哈希不可避免的操作条件，并分析了加密重哈希对RTO合规性的下游影响。提出的元数据驱动框架能够在灾备场景中实现即时差异计算。

Conclusion: 需要从基于哈希的数据识别转向确定性元数据驱动标识，以消除灾备工作流中的加密计算瓶颈，确保RTO合规性，并为分布式存储架构提供更可靠的灾难恢复能力。

Abstract: Distributed storage architectures are foundational to modern cloud-native infrastructure, yet a critical operational bottleneck persists within disaster recovery (DR) workflows: the dependence on content-based cryptographic hashing for data identification and synchronization. While hash-based deduplication is effective for storage efficiency in steady-state operation, it becomes a systemic liability during failover and failback events when hash indexes are stale, incomplete, or must be rebuilt following a crash. This paper precisely characterizes the operational conditions under which full or partial re-hashing becomes unavoidable. The paper also analyzes the downstream impact of cryptographic re-hashing on Recovery Time Objective (RTO) compliance, and proposes a generalized architectural shift toward deterministic, metadata-driven identification. The proposed framework assigns globally unique composite identifiers to data blocks at ingestion time-independent of content analysis enabling instantaneous delta computation during DR without any cryptographic overhead.

</details>


### [4] [TT-SEAL: TTD-Aware Selective Encryption for Adversarially-Robust and Low-Latency Edge AI](https://arxiv.org/abs/2602.22238)
*Kyeongpil Min,Sangmin Jeon,Jae-Jin Lee,Woojoo Lee*

Main category: cs.CR

TL;DR: TT-SEAL：针对张量训练分解网络的轻量级选择性加密框架，在保证安全性的同时仅加密4.89-15.92%的参数，显著降低边缘AI延迟


<details>
  <summary>Details</summary>
Motivation: 云边AI需要在有限设备预算下同时满足模型压缩和安全性需求。现有选择性加密研究主要针对密集权重，而在TTD压缩模型下的实用性不明确

Method: 提出TT-SEAL框架：1）基于敏感度的重要性指标对TT核心排序；2）校准一次性鲁棒性阈值；3）使用值差分隐私优化器通过AES加密最小关键核心集

Result: 在TTD感知的威胁模型和FPGA原型边缘处理器上，TT-SEAL达到与全加密相当的鲁棒性，仅加密4.89-15.92%参数（ResNet-18、MobileNetV2、VGG-16），将AES解密在端到端延迟中的占比降至个位数（如ResNet-18从58%降至2.76%）

Conclusion: TT-SEAL实现了安全、低延迟的边缘AI，在TTD压缩网络中有效平衡了安全性和效率需求

Abstract: Cloud-edge AI must jointly satisfy model compression and security under tight device budgets. While Tensor-Train Decomposition (TTD) shrinks on-device models, prior selective-encryption studies largely assume dense weights, leaving its practicality under TTD compression unclear. We present TT-SEAL, a selective-encryption framework for TT-decomposed networks. TT-SEAL ranks TT cores with a sensitivity-based importance metric, calibrates a one-time robustness threshold, and uses a value-DP optimizer to encrypt the minimum set of critical cores with AES. Under TTD-aware, transfer-based threat models (and on an FPGA-prototyped edge processor) TT-SEAL matches the robustness of full (black-box) encryption while encrypting as little as 4.89-15.92% of parameters across ResNet-18, MobileNetV2, and VGG-16, and drives the share of AES decryption in end-to-end latency to low single digits (e.g., 58% -> 2.76% on ResNet-18), enabling secure, low-latency edge AI.

</details>


### [5] [Analysis of LLMs Against Prompt Injection and Jailbreak Attacks](https://arxiv.org/abs/2602.22242)
*Piyush Jaiswal,Aaditya Pratap,Shreyansh Saraswati,Harsh Kasyap,Somanath Tripathy*

Main category: cs.CR

TL;DR: 评估多个开源LLM的提示注入和越狱漏洞，发现不同模型行为差异显著，现有轻量级防御机制可缓解简单攻击但易被复杂推理提示绕过


<details>
  <summary>Details</summary>
Motivation: 随着LLM在现实系统中的广泛部署，提示工程成为资源有限组织采用LLM的有效工具，但同时LLM易受提示攻击，分析这种风险已成为关键的安全需求

Method: 使用大型手动整理的数据集，评估多个开源LLM（包括Phi、Mistral、DeepSeek-R1、Llama 3.2、Qwen和Gemma变体）的提示注入和越狱漏洞，并测试几种无需重新训练或GPU密集型微调的轻量级推理时防御机制

Result: 观察到不同模型行为差异显著，包括拒绝响应和内部安全机制触发的完全静默无响应。轻量级防御机制可缓解直接攻击，但始终被长且推理密集的提示绕过

Conclusion: LLM存在严重的提示注入和越狱漏洞，现有轻量级防御机制不足以应对复杂攻击，需要更强大的安全解决方案

Abstract: Large Language Models (LLMs) are widely deployed in real-world systems. Given their broader applicability, prompt engineering has become an efficient tool for resource-scarce organizations to adopt LLMs for their own purposes. At the same time, LLMs are vulnerable to prompt-based attacks. Thus, analyzing this risk has become a critical security requirement. This work evaluates prompt-injection and jailbreak vulnerability using a large, manually curated dataset across multiple open-source LLMs, including Phi, Mistral, DeepSeek-R1, Llama 3.2, Qwen, and Gemma variants. We observe significant behavioural variation across models, including refusal responses and complete silent non-responsiveness triggered by internal safety mechanisms. Furthermore, we evaluated several lightweight, inference-time defence mechanisms that operate as filters without any retraining or GPU-intensive fine-tuning. Although these defences mitigate straightforward attacks, they are consistently bypassed by long, reasoning-heavy prompts.

</details>


### [6] [Accelerating Incident Response: A Hybrid Approach for Data Breach Reporting](https://arxiv.org/abs/2602.22244)
*Aurora Arrus,Maria di Gisi,Sara Lilli,Marco Quadrini*

Main category: cs.CR

TL;DR: 提出混合恶意软件分析管道，结合静态和动态分析，利用LLM将异构取证证据转化为符合GDPR报告要求的结构化报告，特别针对Linux/ARM环境的外泄型恶意软件。


<details>
  <summary>Details</summary>
Motivation: GDPR要求在72小时内报告数据泄露，但技术取证证据与监管报告要求之间存在差距，导致延迟、不完整通知和分析师认知负担高。物联网和嵌入式设备普及导致Linux/ARM恶意软件快速增长。

Method: 混合恶意软件分析管道：结合静态分析识别潜在外泄者，动态分析重建其行为。使用受正式JSON模式约束的大型语言模型，该模式与意大利Garante Privacy通知表格对齐，将异构取证证据转化为结构化报告。

Result: 系统能够自动提取和组织泄露相关信息，将低级别取证证据（恶意软件痕迹、系统调用日志、网络捕获）转化为合规准备的结构化报告，人类操作员可快速验证。

Conclusion: 提出的混合分析管道通过自动化技术证据到监管报告的转换，帮助组织满足GDPR 72小时报告要求，特别适用于日益增长的Linux/ARM恶意软件环境。

Abstract: The General Data Protection Regulation (GDPR) requires organisations to notify supervisory authorities of personal data breaches within 72 hours of discovery. Meeting this strict deadline is challenging because incident responders must manually translate low-level forensic artefacts such as malware traces, system-call logs, and network captures into the structured, legally framed information required by data-protection authorities. This gap between technical evidence and regulatory reporting often results in delays, incomplete notifications, and a high cognitive burden on analysts. We propose a hybrid malware analysis pipeline that automates the extraction and organisation of breach-relevant information, with a particular focus on exfiltration-oriented Linux/ARM malware, which is rapidly increasing in prevalence due to the widespread adoption of IoT and embedded devices. The system combines static analysis to identify potential exfiltrators with dynamic analysis to reconstruct their behaviour. It employs a Large Language Model (LLM) constrained by a formal JSON schema aligned with the official Italian Garante Privacy notification form. The LLM transforms heterogeneous forensic artefacts into a structured, compliance-ready report that a human operator can rapidly validate.

</details>


### [7] [Self-Purification Mitigates Backdoors in Multimodal Diffusion Language Models](https://arxiv.org/abs/2602.22246)
*Guangnian Wan,Qi Li,Gongfan Fang,Xinyin Ma,Xinchao Wang*

Main category: cs.CR

TL;DR: 本文提出DiSP框架，通过选择性掩码视觉token和自净化数据来防御多模态扩散语言模型的后门攻击，无需辅助模型或干净数据即可将攻击成功率从90%以上降至5%以下。


<details>
  <summary>Details</summary>
Motivation: 多模态扩散语言模型（MDLMs）作为自回归模型的有力竞争者，其后门攻击脆弱性尚未得到充分研究。虽然现有数据投毒方法能成功植入后门，但针对这类模型的有效防御策略尚未出现。

Method: 提出DiSP（Diffusion Self-Purification）防御框架：1）在推理时选择性掩码某些视觉token以中和后门模型的触发行为；2）利用被攻击模型自身净化中毒数据集；3）在净化数据上微调模型以恢复为干净模型。该设计无需辅助模型或干净参考数据。

Result: 实验表明DiSP能有效缓解后门效应，将攻击成功率（ASR）从超过90%降至通常低于5%，同时保持模型在良性任务上的性能。

Conclusion: DiSP框架为多模态扩散语言模型提供了一种无需外部资源即可有效防御后门攻击的解决方案，填补了该领域防御策略的空白。

Abstract: Multimodal Diffusion Language Models (MDLMs) have recently emerged as a competitive alternative to their autoregressive counterparts. Yet their vulnerability to backdoor attacks remains largely unexplored. In this work, we show that well-established data-poisoning pipelines can successfully implant backdoors into MDLMs, enabling attackers to manipulate model behavior via specific triggers while maintaining normal performance on clean inputs. However, defense strategies effective to these models are yet to emerge. To bridge this gap, we introduce a backdoor defense framework for MDLMs named DiSP (Diffusion Self-Purification). DiSP is driven by a key observation: selectively masking certain vision tokens at inference time can neutralize a backdoored model's trigger-induced behaviors and restore normal functionality. Building on this, we purify the poisoned dataset using the compromised model itself, then fine-tune the model on the purified data to recover it to a clean one. Given such a specific design, DiSP can remove backdoors without requiring any auxiliary models or clean reference data. Extensive experiments demonstrate that our approach effectively mitigates backdoor effects, reducing the attack success rate (ASR) from over 90% to typically under 5%, while maintaining model performance on benign tasks.

</details>


### [8] [A Lightweight Defense Mechanism against Next Generation of Phishing Emails using Distilled Attention-Augmented BiLSTM](https://arxiv.org/abs/2602.22250)
*Morteza Eskandarian,Mahdi Rabbani,Arun Kaniyamattam,Fatemeh Nejati,Mansur Mirani,Gunjan Piya,Igor Opushnyev,Ali A. Ghorbani,Sajjad Dadkhah*

Main category: cs.CR

TL;DR: 提出基于MobileBERT蒸馏到BiLSTM+多头注意力的轻量级模型，用于检测邮件网关和端点的社交工程欺骗内容，在保持高性能的同时实现快速推理和小模型尺寸


<details>
  <summary>Details</summary>
Motivation: 当前大语言模型生成的社交工程内容能够绕过商业通信平台的标准文本筛查系统，需要一种隐私保护且满足网络和移动安全系统性能要求的解决方案

Method: 使用MobileBERT教师模型进行微调，然后蒸馏到BiLSTM+多头注意力模型（仅450万参数）。采用包含人工撰写消息和LLM生成改写（使用掩码技术和个性化方法）的混合数据集。评估系统包含五种测试协议

Result: 蒸馏模型与强transformer基线相比，加权F1分数差异仅为1-2.5点，同时推理时间快80-95%，模型尺寸小95-99%。系统在准确性和延迟方面表现优异，支持实时过滤和基于策略的管理

Conclusion: 提出的轻量级模型在保持高性能的同时实现了快速推理和小模型尺寸，能够在没有加速硬件的情况下进行实时过滤，并支持隐私保护和操作部署

Abstract: The current generation of large language models produces sophisticated social-engineering content that bypasses standard text screening systems in business communication platforms. Our proposed solution for mail gateway and endpoint deception detection operates in a privacy-protective manner while handling the performance requirements of network and mobile security systems. The MobileBERT teacher receives fine-tuning before its transformation into a BiLSTM model with multi-head attention which maintains semantic discrimination only with 4.5 million parameters. The hybrid dataset contains human-written messages together with LLM-generated paraphrases that use masking techniques and personalization methods to enhance modern attack resistance. The evaluation system uses five testing protocols which include human-only and LLM-only tests and two cross-distribution transfer tests and a production-like mixed traffic test to assess performance in native environments and across different distribution types and combined traffic scenarios. The distilled model maintains a weighted-F1 score difference of 1-2.5 points compared to the mixture split results of strong transformer baselines including ModernBERT, DeBERTaV3-base, T5-base, DeepSeek-R1 Distill Qwen-1.5B and Phi-4 mini while achieving 80-95\% faster inference times and 95-99\% smaller model sizes. The system demonstrates excellent performance in terms of accuracy and latency while maintaining a compact size which enables real-time filtering without acceleration hardware and supports policy-based management. The paper examines system performance under high traffic conditions and security measures for privacy protection and implementation methods for operational deployment.

</details>


### [9] [Poisoned Acoustics](https://arxiv.org/abs/2602.22258)
*Harrison Dahme*

Main category: cs.CR

TL;DR: 该论文展示了在声学车辆分类任务中，通过仅污染0.5%的训练标签（48个样本），就能实现95.7%攻击成功率的隐蔽数据投毒攻击，且不影响总体准确率。作者证明了这种隐蔽性是结构性的，并提出了结合密码学验证的数据溯源防御方案。


<details>
  <summary>Details</summary>
Motivation: 训练数据投毒攻击能够通过污染极少量的训练标签，在深度神经网络中诱导目标性、难以检测的故障。当前基于总体准确率的监控方法无法检测这类攻击，特别是在现实世界存在类别不平衡的情况下。

Method: 在MELAUDIS城市交叉路口数据集（约9600个音频片段，6个类别）上进行实验，使用基于log-mel频谱图的2D卷积神经网络。研究了两种攻击：标签翻转攻击（Truck-to-Car）和后门触发器攻击。将ML训练流程形式化为攻击面，并提出了结合内容寻址哈希、Merkle树数据集承诺和后量子数字签名的密码学验证防御方案。

Result: 在仅污染0.5%训练数据（48个记录）的情况下，实现了95.7%的攻击成功率，而总体准确率没有可检测的变化（基线87.6%；95%置信区间：88-100%）。证明了攻击的隐蔽性是结构性的：完整目标攻击的最大准确率下降受限于少数类比例。在后门攻击中发现了触发器主导崩溃现象。

Conclusion: 总体准确率监控在存在类别不平衡的情况下是理论上不足的，无法检测隐蔽的数据投毒攻击。需要密码学验证的数据溯源机制来确保训练数据的完整性，作者提出的结合内容寻址哈希、Merkle树承诺和后量子签名的方案提供了有效的防御框架。

Abstract: Training-data poisoning attacks can induce targeted, undetectable failure in deep neural networks by corrupting a vanishingly small fraction of training labels. We demonstrate this on acoustic vehicle classification using the MELAUDIS urban intersection dataset (approx. 9,600 audio clips, 6 classes): a compact 2-D convolutional neural network (CNN) trained on log-mel spectrograms achieves 95.7% Attack Success Rate (ASR) -- the fraction of target-class test samples misclassified under the attack -- on a Truck-to-Car label-flipping attack at just p=0.5% corruption (48 records), with zero detectable change in aggregate accuracy (87.6% baseline; 95% CI: 88-100%, n=3 seeds). We prove this stealth is structural: the maximum accuracy drop from a complete targeted attack is bounded above by the minority class fraction (beta). For real-world class imbalances (Truck approx. 3%), this bound falls below training-run noise, making aggregate accuracy monitoring provably insufficient regardless of architecture or attack method. A companion backdoor trigger attack reveals a novel trigger-dominance collapse: when the target class is a dataset minority, the spectrogram patch trigger becomes functionally redundant--clean ASR equals triggered ASR, and the attack degenerates to pure label flipping. We formalize the ML training pipeline as an attack surface and propose a trust-minimized defense combining content-addressed artifact hashing, Merkle-tree dataset commitment, and post-quantum digital signatures (ML-DSA-65/CRYSTALS-Dilithium3, NIST FIPS 204) for cryptographically verifiable data provenance.

</details>


### [10] [Differentially Private Truncation of Unbounded Data via Public Second Moments](https://arxiv.org/abs/2602.22282)
*Zilong Cao,Xuan Bi,Hai Zhang*

Main category: cs.CR

TL;DR: 提出PMT方法，利用少量公开数据的二阶矩信息处理无界分布数据的差分隐私问题，通过变换和截断改善条件数，提升DP模型精度


<details>
  <summary>Details</summary>
Motivation: 差分隐私(DP)通常要求数据有界分布，但现实数据往往无界。现有方法无法有效处理无界分布数据的隐私保护问题，需要新方法突破这一限制

Method: 提出公开矩引导截断(PMT)：1)利用少量公开数据的二阶矩矩阵变换私有数据；2)基于数据维度和样本量进行原则性截断；3)设计新损失函数和算法，确保变换空间解能映射回原始域

Result: PMT显著改善二阶矩矩阵条件数，增强抵抗DP噪声能力。理论误差界、鲁棒性保证和收敛结果均显示DP估计改进。合成和真实数据集实验证实PMT大幅提升DP模型精度和稳定性

Conclusion: PMT成功解决了无界分布数据的差分隐私问题，通过利用公开二阶矩信息改善条件数，为惩罚回归和广义线性回归等模型提供了有效的DP解决方案

Abstract: Data privacy is important in the AI era, and differential privacy (DP) is one of the golden solutions. However, DP is typically applicable only if data have a bounded underlying distribution. We address this limitation by leveraging second-moment information from a small amount of public data. We propose Public-moment-guided Truncation (PMT), which transforms private data using the public second-moment matrix and applies a principled truncation whose radius depends only on non-private quantities: data dimension and sample size. This transformation yields a well-conditioned second-moment matrix, enabling its inversion with a significantly strengthened ability to resist the DP noise. Furthermore, we demonstrate the applicability of PMT by using penalized and generalized linear regressions. Specifically, we design new loss functions and algorithms, ensuring that solutions in the transformed space can be mapped back to the original domain. We have established improvements in the models' DP estimation through theoretical error bounds, robustness guarantees, and convergence results, attributing the gains to the conditioning effect of PMT. Experiments on synthetic and real datasets confirm that PMT substantially improves the accuracy and stability of DP models.

</details>


### [11] [HubScan: Detecting Hubness Poisoning in Retrieval-Augmented Generation Systems](https://arxiv.org/abs/2602.22427)
*Idan Habler,Vineeth Sai Narajala,Stav Koren,Amy Chang,Tiffany Saade*

Main category: cs.CR

TL;DR: Hubscan是一个开源安全扫描器，用于检测RAG系统中的hubness安全漏洞，通过多检测器架构识别频繁出现在检索结果中的恶意中心点。


<details>
  <summary>Details</summary>
Motivation: RAG系统存在hubness安全漏洞——某些项目会频繁出现在大量不同查询的top-k检索结果中，这些中心点可被利用来引入有害内容、篡改搜索排名、绕过内容过滤并降低系统性能。

Method: 提出hubscan多检测器架构：1) 基于中位数/MAD的稳健统计hubness检测；2) 集群分布分析评估跨集群检索模式；3) 查询扰动下的稳定性测试；4) 领域感知和模态感知检测。支持多种向量数据库和检索技术。

Result: 在Food-101、MS-COCO和FiQA对抗性hubness基准测试中，hubscan在0.2%警报预算下达到90%召回率，0.4%时达到100%召回率，对抗性中心点排名超过99.8百分位。领域限定扫描可检测100%逃避全局检测的针对性攻击。

Conclusion: Hubscan为生产RAG系统提供了一个实用、可扩展的hubness威胁检测框架，能够有效识别和防御对抗性中心点攻击。

Abstract: Retrieval-Augmented Generation (RAG) systems are essential to contemporary AI applications, allowing large language models to obtain external knowledge via vector similarity search. Nevertheless, these systems encounter a significant security flaw: hubness - items that frequently appear in the top-k retrieval results for a disproportionately high number of varied queries. These hubs can be exploited to introduce harmful content, alter search rankings, bypass content filtering, and decrease system performance.
  We introduce hubscan, an open-source security scanner that evaluates vector indices and embeddings to identify hubs in RAG systems. Hubscan presents a multi-detector architecture that integrates: (1) robust statistical hubness detection utilizing median/MAD-based z-scores, (2) cluster spread analysis to assess cross-cluster retrieval patterns, (3) stability testing under query perturbations, and (4) domain-aware and modality-aware detection for category-specific and cross-modal attacks. Our solution accommodates several vector databases (FAISS, Pinecone, Qdrant, Weaviate) and offers versatile retrieval techniques, including vector similarity, hybrid search, and lexical matching with reranking capabilities.
  We evaluate hubscan on Food-101, MS-COCO, and FiQA adversarial hubness benchmarks constructed using state-of-the-art gradient-optimized and centroid-based hub generation methods. hubscan achieves 90% recall at a 0.2% alert budget and 100% recall at 0.4%, with adversarial hubs ranking above the 99.8th percentile. Domain-scoped scanning recovers 100% of targeted attacks that evade global detection. Production validation on 1M real web documents from MS MARCO demonstrates significant score separation between clean documents and adversarial content. Our work provides a practical, extensible framework for detecting hubness threats in production RAG systems.

</details>


### [12] [Predicting Known Vulnerabilities from Attack Descriptions Using Sentence Transformers](https://arxiv.org/abs/2602.22433)
*Refat Othman*

Main category: cs.CR

TL;DR: 开发基于transformer的句子嵌入方法，从网络攻击的自然语言描述中预测已知漏洞，实现攻击与漏洞的自动关联


<details>
  <summary>Details</summary>
Motivation: 现有网络威胁情报资源（如MITRE ATT&CK和CVE）对攻击-漏洞关系的覆盖不完整，攻击信息往往先于漏洞正式关联出现，需要自动化方法从攻击描述推断潜在漏洞

Method: 使用transformer模型将攻击和漏洞描述编码为语义向量表示，基于相似性进行排序和推荐；评估了14个最先进的transformer模型，涵盖四种攻击描述类型（战术、技术、程序、攻击模式）

Result: MITRE ATT&CK中的技术描述提供最强的预测信号；multi-qa-mpnet-base-dot-v1模型表现最佳；开发的VULDAT工具能够自动链接攻击与漏洞，并发现MITRE存储库中未记录的关系

Conclusion: 该方法能够从攻击描述中有效预测漏洞，支持主动漏洞感知，模型在未见过的网络攻击报告上表现出良好的泛化能力

Abstract: Modern infrastructures rely on software systems that remain vulnerable to cyberattacks. These attacks frequently exploit vulnerabilities documented in repositories such as MITRE's Common Vulnerabilities and Exposures (CVE). However, Cyber Threat Intelligence resources, including MITRE ATT&CK and CVE, provide only partial coverage of attack-vulnerability relationships. Attack information often appears before vulnerabilities are formally linked, creating the need for automated methods that infer likely vulnerabilities directly from attack descriptions.
  This thesis addresses the problem of predicting known vulnerabilities from natural-language descriptions of cyberattacks. We develop transformer-based sentence embedding methods that encode attack and vulnerability descriptions into semantic vector representations, enabling similarity-based ranking and recommendation.
  Fourteen state-of-the-art transformer models were evaluated across four attack description types (Tactic, Technique, Procedure, and Attack Pattern). Results show that Technique descriptions in MITRE ATT&CK provide the strongest predictive signal. The multi-qa-mpnet-base-dot-v1 (MMPNet) model achieved the best performance due to its hybrid pre-training and optimization for semantic similarity.
  The approach was implemented in the VULDAT tool, which automatically links attacks to vulnerabilities. Manual validation revealed previously undocumented relationships in MITRE repositories. Evaluation on unseen cyberattack reports demonstrates that the models generalize beyond curated datasets and support proactive vulnerability awareness.

</details>


### [13] [Differentially Private Data-Driven Markov Chain Modeling](https://arxiv.org/abs/2602.22443)
*Alexander Benvenuti,Brandon Fallin,Calvin Hawkins,Brendan Bialy,Miriam Dennis,Warren Dixon,Matthew Hale*

Main category: cs.CR

TL;DR: 提出一种保护马尔可夫链模型中用户数据的差分隐私方法，通过私有化单位单纯形查询来保护数据，同时保持模型准确性。


<details>
  <summary>Details</summary>
Motivation: 马尔可夫链广泛用于建模用户行为，但构建准确模型需要大量用户数据，而共享这些模型可能泄露敏感信息。需要一种既能保护用户隐私又能保持模型准确性的方法。

Method: 1) 开发私有化单位单纯形查询的差分隐私方法；2) 扩展到私有化随机矩阵（每行都是数据库的单纯形值查询）；3) 量化私有和非私有查询之间的KL散度；4) 分析私有化对马尔可夫链平稳分布和收敛速度的影响。

Result: 方法被证明是差分隐私的，在典型隐私实现下，平稳分布误差小于2%，表明该方法能忠实捕捉系统行为。

Conclusion: 提出的差分隐私方法能有效保护马尔可夫链模型中的用户数据隐私，同时保持模型准确性，为隐私保护的马尔可夫链建模提供了可行方案。

Abstract: Markov chains model a wide range of user behaviors. However, generating accurate Markov chain models requires substantial user data, and sharing these models without privacy protections may reveal sensitive information about the underlying user data. We introduce a method for protecting user data used to formulate a Markov chain model. First, we develop a method for privatizing database queries whose outputs are elements of the unit simplex, and we prove that this method is differentially private. We quantify its accuracy by bounding the expected KL divergence between private and non-private queries. We extend this method to privatize stochastic matrices whose rows are each a simplex-valued query of a database, which includes data-driven Markov chain models. To assess their accuracy, we analytically bound the change in the stationary distribution and the change in the convergence rate between a non-private Markov chain model and its private form. Simulations show that under a typical privacy implementation, our method yields less than 2% error in the stationary distribution, indicating that our approach to private modeling faithfully captures the behavior of the systems we study.

</details>


### [14] [Silent Egress: When Implicit Prompt Injection Makes LLM Agents Leak Without a Trace](https://arxiv.org/abs/2602.22450)
*Qianlong Lan,Anuj Kaul,Shaun Jones,Stephanie Westrum*

Main category: cs.CR

TL;DR: 研究发现LLM代理系统存在"隐性提示注入"风险，恶意网页可通过URL预览诱导代理泄露敏感信息，即使最终用户看到的输出无害。攻击成功率高且难以检测，需要系统级而非提示级的防护措施。


<details>
  <summary>Details</summary>
Motivation: 随着LLM代理系统越来越多地通过检索URL和调用外部工具来自动化任务，这种工作流程带来了新的安全风险。作者发现恶意网页可以通过URL预览中的对抗性指令诱导代理泄露敏感运行时上下文，即使最终用户看到的响应看起来无害。这种系统级风险被称为"静默外泄"。

Method: 使用完全本地和可复现的测试环境，基于qwen2.5:7b模型构建代理系统进行实验。设计了恶意网页诱导代理发出外泄敏感信息的外向请求。在480次实验运行中测试攻击成功率，并开发了"分片外泄"策略，将敏感信息分割到多个请求中以规避检测。通过消融实验比较不同防御层的有效性。

Result: 攻击成功概率高达0.89，95%的成功攻击未被基于输出的安全检查检测到。分片外泄策略使单请求泄漏指标降低73%，并能绕过简单的数据丢失防护机制。消融结果表明，提示层的防御措施保护有限，而系统和网络层的控制（如域名白名单和重定向链分析）更为有效。

Conclusion: 网络外泄应被视为LLM代理系统中的首要安全结果。需要超越提示级强化的架构方向，包括溯源跟踪和能力隔离。系统级和网络级的防护措施比单纯依赖提示工程更为有效。

Abstract: Agentic large language model systems increasingly automate tasks by retrieving URLs and calling external tools. We show that this workflow gives rise to implicit prompt injection: adversarial instructions embedded in automatically generated URL previews, including titles, metadata, and snippets, can introduce a system-level risk that we refer to as silent egress. Using a fully local and reproducible testbed, we demonstrate that a malicious web page can induce an agent to issue outbound requests that exfiltrate sensitive runtime context, even when the final response shown to the user appears harmless. In 480 experimental runs with a qwen2.5:7b-based agent, the attack succeeds with high probability (P (egress) =0.89), and 95% of successful attacks are not detected by output-based safety checks. We also introduce sharded exfiltration, where sensitive information is split across multiple requests to avoid detection. This strategy reduces single-request leakage metrics by 73% (Leak@1) and bypasses simple data loss prevention mechanisms. Our ablation results indicate that defenses applied at the prompt layer offer limited protection, while controls at the system and network layers, such as domain allowlisting and redirect-chain analysis, are considerably more effective. These findings suggest that network egress should be treated as a first-class security outcome in agentic LLM systems. We outline architectural directions, including provenance tracking and capability isolation, that go beyond prompt-level hardening.

</details>


### [15] [Explainability-Aware Evaluation of Transfer Learning Models for IoT DDoS Detection Under Resource Constraints](https://arxiv.org/abs/2602.22488)
*Nelly Elsayed*

Main category: cs.CR

TL;DR: 本文对7种预训练CNN架构进行可解释性评估，用于IoT DDoS多分类检测，发现DenseNet和MobileNet在性能、可靠性和可解释性方面表现最佳。


<details>
  <summary>Details</summary>
Motivation: DDoS攻击威胁IoT基础设施可用性，现有迁移学习模型在可靠性、计算可行性和可解释性方面研究不足，需要综合评估这些因素以选择适合IoT环境的检测模型。

Method: 使用CICDDoS2019数据集和基于图像的流量表示，评估7种预训练CNN架构；集成性能指标、可靠性统计（MCC、Youden指数、置信区间）、延迟与训练成本评估，以及Grad-CAM和SHAP可解释性分析。

Result: DenseNet和MobileNet架构在检测性能、可靠性和可解释性方面表现优异；DenseNet169提供最强的可靠性与可解释性对齐，MobileNetV3在雾计算部署中提供有效的延迟-精度权衡。

Conclusion: 选择IoT DDoS检测深度学习模型时，需要综合考虑性能、可靠性和可解释性标准；DenseNet和MobileNet架构特别适合资源受限的IoT环境部署。

Abstract: Distributed denial-of-service (DDoS) attacks threaten the availability of Internet of Things (IoT) infrastructures, particularly under resource-constrained deployment conditions. Although transfer learning models have shown promising detection accuracy, their reliability, computational feasibility, and interpretability in operational environments remain insufficiently explored. This study presents an explainability-aware empirical evaluation of seven pre-trained convolutional neural network architectures for multi-class IoT DDoS detection using the CICDDoS2019 dataset and an image-based traffic representation. The analysis integrates performance metrics, reliability-oriented statistics (MCC, Youden Index, confidence intervals), latency and training cost assessment, and interpretability evaluation using Grad-CAM and SHAP. Results indicate that DenseNet and MobileNet-based architectures achieve strong detection performance while demonstrating superior reliability and compact, class-consistent attribution patterns. DenseNet169 offers the strongest reliability and interpretability alignment, whereas MobileNetV3 provides an effective latency-accuracy trade-off for fog-level deployment. The findings emphasize the importance of combining performance, reliability, and explainability criteria when selecting deep learning models for IoT DDoS detection.

</details>


### [16] [Systems-Level Attack Surface of Edge Agent Deployments on IoT](https://arxiv.org/abs/2602.22525)
*Zhonghao Zhan,Krinos Li,Yefan Zhang,Hamed Haddadi*

Main category: cs.CR

TL;DR: 边缘部署LLM代理在物联网硬件上引入了云托管编排所没有的攻击面。通过多设备家庭自动化测试床，分析了三种架构（云托管、边缘本地集群、混合）的安全风险，识别出五个系统级攻击面，包括协调状态分歧和诱导信任侵蚀等新兴故障。


<details>
  <summary>Details</summary>
Motivation: 随着LLM代理在物联网边缘设备上的部署，出现了云托管编排所没有的新安全风险。需要实证分析不同部署架构（云托管、边缘本地集群、混合）的安全特性，以了解架构选择如何影响物联网系统的安全风险。

Method: 使用多设备家庭自动化测试床，包含本地MQTT消息传递和Android智能手机作为边缘推理节点。分析三种架构：云托管、边缘本地集群和混合架构。识别系统级攻击面，并将核心安全属性框架化为可测量的系统指标：数据出口量、故障转移窗口暴露、主权边界完整性和来源链完整性。

Result: 边缘本地部署消除了常规云数据暴露，但在故障转移机制触发时会无声地降低主权边界完整性，且边界跨越在应用层不可见。来源链在协作操作下保持完整，但如果没有加密强制执行则容易被绕过。故障转移窗口创建了可利用的瞬态盲点，用于未经授权的执行。识别出五个系统级攻击面，包括协调状态分歧和诱导信任侵蚀两种在实时测试床操作中观察到的新兴故障。

Conclusion: 部署架构（而不仅仅是模型或提示设计）是代理控制物联网系统安全风险的主要决定因素。边缘本地部署虽然减少了云数据暴露，但引入了新的攻击面和故障模式，需要在系统设计中考虑主权边界完整性、来源链加密强制执行和故障转移窗口管理等安全机制。

Abstract: Edge deployment of LLM agents on IoT hardware introduces attack surfaces absent from cloud-hosted orchestration. We present an empirical security analysis of three architectures (cloud-hosted, edge-local swarm, and hybrid) using a multi-device home-automation testbed with local MQTT messaging and an Android smartphone as an edge inference node. We identify five systems-level attack surfaces, including two emergent failures observed during live testbed operation: coordination-state divergence and induced trust erosion. We frame core security properties as measurable systems metrics: data egress volume, failover window exposure, sovereignty boundary integrity, and provenance chain completeness. Our measurements show that edge-local deployments eliminate routine cloud data exposure but silently degrade sovereignty when fallback mechanisms trigger, with boundary crossings invisible at the application layer. Provenance chains remain complete under cooperative operation yet are trivially bypassed without cryptographic enforcement. Failover windows create transient blind spots exploitable for unauthorised actuation. These results demonstrate that deployment architecture, not just model or prompt design, is a primary determinant of security risk in agent-controlled IoT systems.

</details>


### [17] [Layer-Targeted Multilingual Knowledge Erasure in Large Language Models](https://arxiv.org/abs/2602.22562)
*Taoran Li,Varun Chandrasekaran,Zhiyuan Yu*

Main category: cs.CR

TL;DR: 提出MUTE框架，通过识别语言无关的中间层进行定向擦除，解决LLM多语言遗忘中跨语言泛化失败的问题。


<details>
  <summary>Details</summary>
Motivation: 现有研究发现LLM的多语言遗忘存在跨语言泛化失败的问题：在一个语言中擦除的知识在其他语言中仍然可访问。但失败的根本原因和系统解决方案尚未明确。

Method: 提出MUTE框架，使用CKA和LRDS识别中间、语言无关的层（跨语言表示收敛的层），将遗忘更新限制在这些层中，仅需在少量源语言上进行优化。

Result: 在三种LLM架构和三种遗忘算法上的广泛实验验证了该方法，通过Logit Lens探测的机制分析确认了真正的知识移除而非输出级抑制。

Conclusion: 干预深度是决定多语言泛化的关键因素，MUTE通过识别语言无关层进行定向擦除，实现了稳健的多语言知识遗忘，解决了跨语言泛化失败的问题。

Abstract: Recent work has demonstrated that machine unlearning in Large Language Models (LLMs) fails to generalize across languages: knowledge erased in one language frequently remains accessible through others. However, the underlying cause of this failure and a principled solution remain open. In this work, we identify intervention depth as the key factor determining multilingual generalization. Through systematic layer-wise experiments, we characterize two distinct failure modes: shallow-layer interventions achieve erasure but collapse multilingual capabilities in held-out languages, while deep-layer interventions preserve utility but fail to erase target knowledge even in source languages. These findings reveal that the choice of intervention layer is not a free parameter; it fundamentally determines whether multilingual unlearning succeeds. We propose MUTE (Multilingual Unlearning via Targeted Erasure), a framework that uses Centered Kernel Alignment (CKA) and Linguistic Regions Development Score (LRDS) to identify intermediate, language-agnostic layers where cross-lingual representations converge. By restricting unlearning updates to these layers, MUTE achieves robust multilingual knowledge erasure while optimizing on only a small set of source languages. Extensive experiments across three LLM architectures and three unlearning algorithms validate our approach, with mechanistic analysis via Logit Lens probing confirming genuine knowledge removal rather than output-level suppression.

</details>


### [18] [DPSQL+: A Differentially Private SQL Library with a Minimum Frequency Rule](https://arxiv.org/abs/2602.22699)
*Tomoya Matsumoto,Shokichi Takakura,Shun Takagi,Satoshi Hasegawa*

Main category: cs.CR

TL;DR: DPSQL+ 是一个隐私保护的 SQL 库，同时强制执行用户级差分隐私和最小频率规则，通过模块化架构支持多种数据库引擎，在固定隐私预算下允许比现有库更多的查询。


<details>
  <summary>Details</summary>
Motivation: SQL 是探索性数据分析的实际标准接口，但发布精确查询结果可能通过成员或属性推断攻击暴露敏感信息。差分隐私提供严格的隐私保证，但单独使用可能无法满足治理要求，如最小频率规则（要求每个发布的组至少包含 k 个不同个体的贡献）。

Method: DPSQL+ 采用模块化架构：1) Validator - 静态限制查询到 DP 安全的 SQL 子集；2) Accountant - 一致跟踪多个查询的累积隐私损失；3) Backend - 与各种数据库引擎接口，确保可移植性和可扩展性。

Result: 在 TPC-H 基准测试上的实验表明，DPSQL+ 在广泛的分析工作负载（从基本聚合到二次统计和连接操作）中实现了实用的准确性，并且在固定全局隐私预算下，比评估中的先前库允许更多的查询。

Conclusion: DPSQL+ 成功开发了一个同时强制执行用户级差分隐私和最小频率规则的隐私保护 SQL 库，通过模块化设计实现了实用准确性、可移植性和更好的查询效率。

Abstract: SQL is the de facto interface for exploratory data analysis; however, releasing exact query results can expose sensitive information through membership or attribute inference attacks. Differential privacy (DP) provides rigorous privacy guarantees, but in practice, DP alone may not satisfy governance requirements such as the \emph{minimum frequency rule}, which requires each released group (cell) to include contributions from at least $k$ distinct individuals. In this paper, we present \textbf{DPSQL+}, a privacy-preserving SQL library that simultaneously enforces user-level $(\varepsilon,δ)$-DP and the minimum frequency rule. DPSQL+ adopts a modular architecture consisting of: (i) a \emph{Validator} that statically restricts queries to a DP-safe subset of SQL; (ii) an \emph{Accountant} that consistently tracks cumulative privacy loss across multiple queries; and (iii) a \emph{Backend} that interfaces with various database engines, ensuring portability and extensibility. Experiments on the TPC-H benchmark demonstrate that DPSQL+ achieves practical accuracy across a wide range of analytical workloads -- from basic aggregates to quadratic statistics and join operations -- and allows substantially more queries under a fixed global privacy budget than prior libraries in our evaluation.

</details>


### [19] [IMMACULATE: A Practical LLM Auditing Framework via Verifiable Computation](https://arxiv.org/abs/2602.22700)
*Yanpei Guo,Wenjie Qu,Linyu Wu,Shengfang Zhai,Lionel Z. Wang,Ming Xu,Yue Liu,Binhang Yuan,Dawn Song,Jiaheng Zhang*

Main category: cs.CR

TL;DR: IMMACULATE是一个实用的审计框架，用于检测商业大语言模型API服务中的经济动机偏差（如模型替换、量化滥用和token超额计费），无需可信硬件或访问模型内部，通过可验证计算实现强检测保证，同时将密码学开销分摊到少量请求中。


<details>
  <summary>Details</summary>
Motivation: 商业大语言模型通常作为黑盒API服务部署，用户需要信任提供商正确执行推理并如实报告token使用情况。然而，提供商可能存在经济动机的偏差行为，如使用更便宜的模型替代、降低精度量化、虚报token数量等，这些行为损害用户利益但难以检测。

Method: IMMACULATE框架采用选择性审计策略，仅对一小部分请求使用可验证计算技术进行验证。通过密码学方法确保推理执行的正确性，同时将计算开销分摊到整个请求流中，实现高效检测。该方法不需要可信硬件或访问模型内部结构。

Result: 实验在密集模型和MoE模型上验证，IMMACULATE能够可靠区分良性执行和恶意执行，同时保持低于1%的吞吐量开销。框架对模型替换、量化滥用和token超额计费等偏差行为具有强检测能力。

Conclusion: IMMACULATE提供了一个实用的解决方案，用于审计商业大语言模型API服务，检测经济动机的偏差行为，保护用户免受不诚实提供商的影响，同时保持高性能和低开销。

Abstract: Commercial large language models are typically deployed as black-box API services, requiring users to trust providers to execute inference correctly and report token usage honestly. We present IMMACULATE, a practical auditing framework that detects economically motivated deviations-such as model substitution, quantization abuse, and token overbilling-without trusted hardware or access to model internals. IMMACULATE selectively audits a small fraction of requests using verifiable computation, achieving strong detection guarantees while amortizing cryptographic overhead. Experiments on dense and MoE models show that IMMACULATE reliably distinguishes benign and malicious executions with under 1% throughput overhead. Our code is published at https://github.com/guo-yanpei/Immaculate.

</details>


### [20] [AgentSentry: Mitigating Indirect Prompt Injection in LLM Agents via Temporal Causal Diagnostics and Context Purification](https://arxiv.org/abs/2602.22724)
*Tian Zhang,Yiwei Xu,Juan Wang,Keyan Guo,Xiaoyang Xu,Bowen Xiao,Quanlong Guan,Jinlin Fan,Jiawei Liu,Zhiquan Liu,Hongxin Hu*

Main category: cs.CR

TL;DR: AgentSentry：首个将多轮间接提示注入建模为时序因果劫持的推理时防御框架，通过反事实重执行定位劫持点，并通过因果引导的上下文净化实现安全继续执行。


<details>
  <summary>Details</summary>
Motivation: LLM代理依赖外部工具和检索系统完成复杂任务，但面临间接提示注入攻击风险，攻击者通过工具输出或检索内容中的上下文悄无声息地引导代理偏离用户意图。现有防御主要依赖启发式检测和保守阻断高风险操作，容易过早终止工作流或在模糊的多轮场景中广泛抑制工具使用。

Method: 提出AgentSentry框架，将多轮间接提示注入建模为时序因果劫持，在工具返回边界通过受控的反事实重执行定位劫持点，并通过因果引导的上下文净化移除攻击诱导的偏差，同时保留任务相关证据。

Result: 在AgentDojo基准测试中，覆盖四个任务套件、三种IPI攻击家族和多个黑盒LLM，AgentSentry消除了所有成功攻击，在攻击下保持74.55%的平均实用度，比最强基线提升20.8-33.6个百分点，且不降低良性性能。

Conclusion: AgentSentry是首个将多轮间接提示注入建模为时序因果劫持的推理时防御框架，能够有效检测和缓解攻击，在保持任务实用性的同时提供强大的安全保障。

Abstract: Large language model (LLM) agents increasingly rely on external tools and retrieval systems to autonomously complete complex tasks. However, this design exposes agents to indirect prompt injection (IPI), where attacker-controlled context embedded in tool outputs or retrieved content silently steers agent actions away from user intent. Unlike prompt-based attacks, IPI unfolds over multi-turn trajectories, making malicious control difficult to disentangle from legitimate task execution. Existing inference-time defenses primarily rely on heuristic detection and conservative blocking of high-risk actions, which can prematurely terminate workflows or broadly suppress tool usage under ambiguous multi-turn scenarios. We propose AgentSentry, a novel inference-time detection and mitigation framework for tool-augmented LLM agents. To the best of our knowledge, AgentSentry is the first inference-time defense to model multi-turn IPI as a temporal causal takeover. It localizes takeover points via controlled counterfactual re-executions at tool-return boundaries and enables safe continuation through causally guided context purification that removes attack-induced deviations while preserving task-relevant evidence. We evaluate AgentSentry on the \textsc{AgentDojo} benchmark across four task suites, three IPI attack families, and multiple black-box LLMs. AgentSentry eliminates successful attacks and maintains strong utility under attack, achieving an average Utility Under Attack (UA) of 74.55 %, improving UA by 20.8 to 33.6 percentage points over the strongest baselines without degrading benign performance.

</details>


### [21] [Automated Vulnerability Detection in Source Code Using Deep Representation Learning](https://arxiv.org/abs/2602.23121)
*C. Seas,G. Fitzpatrick,J. A. Hamilton,M. C. Carlisle*

Main category: cs.CR

TL;DR: 提出基于卷积神经网络的C代码漏洞检测模型，在Draper Labs和NIST SATE Juliet数据集上训练，相比前人工作在高精度要求下获得更高召回率，并在Linux内核代码中验证了低误报率。


<details>
  <summary>Details</summary>
Motivation: 软件漏洞每年持续被发现，存在被利用和系统被攻破的重大风险。需要开发有效的漏洞检测方法，特别是针对C语言程序，因为C语言在系统软件中广泛使用且容易出现安全漏洞。

Method: 使用卷积神经网络模型检测C代码漏洞。采用两个互补数据集：Draper Labs使用三个静态分析器生成的机器标记数据集和NIST SATE Juliet人工标记数据集。对输入进行91个token类别的分词，将类别值转换为二进制向量以节省内存。使用两个卷积和池化层，后接两个全连接层，将程序分类为常见弱点枚举类别或"干净"代码。

Result: 相比Russell等人的工作，在需要高精度的条件下获得了更高的召回率。在自定义的Linux内核数据集上验证了模型能够在复杂代码中发现真实漏洞，同时保持较低的误报率。

Conclusion: 提出的卷积神经网络模型能够有效检测C代码中的漏洞，在高精度要求下优于前人工作，并在实际复杂代码中表现出良好的检测能力和低误报率，为软件漏洞检测提供了有效的深度学习解决方案。

Abstract: Each year, software vulnerabilities are discovered, which pose significant risks of exploitation and system compromise. We present a convolutional neural network model that can successfully identify bugs in C code. We trained our model using two complementary datasets: a machine-labeled dataset created by Draper Labs using three static analyzers and the NIST SATE Juliet human-labeled dataset designed for testing static analyzers. In contrast with the work of Russell et al. on these datasets, we focus on C programs, enabling us to specialize and optimize our detection techniques for this language. After removing duplicates from the dataset, we tokenize the input into 91 token categories. The category values are converted to a binary vector to save memory. Our first convolution layer is chosen so that the entire encoding of the token is presented to the filter. We use two convolution and pooling layers followed by two fully connected layers to classify programs into either a common weakness enumeration category or as ``clean.'' We obtain higher recall than prior work by Russell et al. on this dataset when requiring high precision. We also demonstrate on a custom Linux kernel dataset that we are able to find real vulnerabilities in complex code with a low false-positive rate.

</details>


### [22] [SettleFL: Trustless and Scalable Reward Settlement Protocol for Federated Learning on Permissionless Blockchains (Extended version)](https://arxiv.org/abs/2602.23167)
*Shuang Liang,Yang Hua,Linshan Jiang,Peishen Yan,Tao Song,Bin Yao,Haibing Guan*

Main category: cs.CR

TL;DR: SettleFL是一个去中心化的联邦学习奖励结算协议，通过两种可互操作的策略（乐观执行和有效性证明）来降低区块链成本，解决了开放FL环境中高频率模型训练与区块链高成本之间的矛盾。


<details>
  <summary>Details</summary>
Motivation: 在开放联邦学习环境中，缺乏中心权威机构，需要去中心化的奖励结算机制。然而，无许可区块链的高成本与模型训练的高频率、迭代特性直接冲突。现有解决方案要么牺牲去中心化，要么因线性链上成本而面临可扩展性瓶颈。

Method: 提出SettleFL协议，基于共享的领域特定电路架构，提供两种可互操作的策略：1) Commit-and-Challenge变体，通过乐观执行和争议驱动仲裁最小化链上成本；2) Commit-with-Proof变体，通过每轮有效性证明保证即时最终性。该设计允许协议灵活适应不同的延迟和成本约束，同时确保理性鲁棒性而无需可信协调。

Result: 结合真实FL工作负载和受控模拟的广泛实验表明，SettleFL在扩展到800名参与者时仍保持实用性，实现了显著更低的gas成本。

Conclusion: SettleFL提供了一个信任最小化且可扩展的奖励结算协议，通过灵活的协议设计解决了开放联邦学习环境中去中心化奖励结算的经济摩擦问题，为大规模FL应用提供了可行的解决方案。

Abstract: In open Federated Learning (FL) environments where no central authority exists, ensuring collaboration fairness relies on decentralized reward settlement, yet the prohibitive cost of permissionless blockchains directly clashes with the high-frequency, iterative nature of model training. Existing solutions either compromise decentralization or suffer from scalability bottlenecks due to linear on-chain costs. To address this, we present SettleFL, a trustless and scalable reward settlement protocol designed to minimize total economic friction by offering a family of two interoperable protocols. Leveraging a shared domain-specific circuit architecture, SettleFL offers two interoperable strategies: (1) a Commit-and-Challenge variant that minimizes on-chain costs via optimistic execution and dispute-driven arbitration, and (2) a Commit-with-Proof variant that guarantees instant finality through per-round validity proofs. This design allows the protocol to flexibly adapt to varying latency and cost constraints while enforcing rational robustness without trusted coordination. We conduct extensive experiments combining real FL workloads and controlled simulations. Results show that SettleFL remains practical when scaling to 800 participants, achieving substantially lower gas cost.

</details>


### [23] [Strengthening security and noise resistance in one-way quantum key distribution protocols through hypercube-based quantum walks](https://arxiv.org/abs/2602.23261)
*David Polzoni,Tommaso Bianchi,Mauro Conti*

Main category: cs.CR

TL;DR: 本文提出了一种基于超立方体拓扑的量子行走QKD协议，相比现有的环形拓扑协议，在相同参数下显著提升了安全性和抗噪能力，并开发了开源仿真框架。


<details>
  <summary>Details</summary>
Motivation: 传统BB84等QKD协议虽然简单，但对窃听抵抗有限且在现实噪声条件下性能不佳。量子行走(QW)已被用于增强QKD方案，但现有研究多基于环形拓扑，需要探索更优的拓扑结构来提升安全性和噪声抵抗能力。

Method: 提出基于超立方体拓扑的单向量子行走QKD协议，其安全性完全依赖于量子行走的拓扑结构而非协议细节。开发了基于Qiskit的可扩展仿真框架，支持环形和超立方体拓扑，能够进行噪声感知分析。

Result: 在相同参数下，超立方体拓扑协议相比环形拓扑（当前最优）显著增强了安全性和噪声抵抗能力，提供了更强的抗窃听保护。开源仿真框架支持可复现性和未来研究。

Conclusion: 基于超立方体拓扑的量子行走QKD协议在安全性和噪声容忍度方面优于现有方案，为设计拓扑感知的QKD协议奠定了基础，结合了增强的噪声容忍度和拓扑驱动的安全性。

Abstract: Quantum Key Distribution (QKD) is a foundational cryptographic protocol that ensures information-theoretic security. However, classical protocols such as BB84, though favored for their simplicity, offer limited resistance to eavesdropping, and perform poorly under realistic noise conditions. Recent research has explored the use of discrete-time Quantum Walks (QWs) to enhance QKD schemes. In this work, we specifically focus on a one-way QKD protocol, where security depends exclusively on the underlying Quantum Walk (QW) topology, rather than the details of the protocol itself. Our paper introduces a novel protocol based on QWs over a hypercube topology and demonstrates that, under identical parameters, it provides significantly enhanced security and noise resistance compared to the circular topology (i.e., state-of-the-art), thereby strengthening protection against eavesdropping. Furthermore, we introduce an efficient and extensible simulation framework for one-way QKD protocols based on QWs, supporting both circular and hypercube topologies. Implemented with IBM's software development kit for quantum computing (i.e., Qiskit), our toolkit enables noise-aware analysis under realistic noise models. To support reproducibility and future developments, we release our entire simulation framework as open-source. This contribution establishes a foundation for the design of topology-aware QKD protocols that combine enhanced noise tolerance with topologically driven security.

</details>
