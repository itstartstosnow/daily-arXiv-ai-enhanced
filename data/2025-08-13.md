<div id=toc></div>

# Table of Contents

- [cs.CR](#cs.CR) [Total: 14]


<div id='cs.CR'></div>

# cs.CR [[Back]](#toc)

### [1] [Selective KV-Cache Sharing to Mitigate Timing Side-Channels in LLM Inference](https://arxiv.org/abs/2508.08438)
*Kexin Chu,Zecheng Lin,Dawei Xiang,Zixu Shen,Jianchang Su,Cheng Chu,Yiwei Yang,Wenhui Zhang,Wenfei Wu,Wei Zhang*

Main category: cs.CR

TL;DR: SafeKV是一种隐私感知的KV缓存管理框架，通过选择性共享非敏感条目和隔离敏感内容，平衡性能与隐私保护。


<details>
  <summary>Details</summary>
Motivation: 全局KV缓存共享加速LLM推理，但引入计时侧信道攻击风险，现有防御方法性能损失大。

Method: SafeKV包含混合检测管道、统一基数树索引和熵基访问监控。

Result: SafeKV减少94%-97%侧信道攻击，提升TTFT性能40.58%和吞吐量2.66倍。

Conclusion: SafeKV在高效缓存重用和细粒度隐私控制间取得平衡，为LLM推理提供运行时隐私保障。

Abstract: Global KV-cache sharing has emerged as a key optimization for accelerating
large language model (LLM) inference. However, it exposes a new class of timing
side-channel attacks, enabling adversaries to infer sensitive user inputs via
shared cache entries. Existing defenses, such as per-user isolation, eliminate
leakage but degrade performance by up to 38.9% in time-to-first-token (TTFT),
making them impractical for high-throughput deployment. To address this gap, we
introduce SafeKV (Secure and Flexible KV Cache Sharing), a privacy-aware
KV-cache management framework that selectively shares non-sensitive entries
while confining sensitive content to private caches. SafeKV comprises three
components: (i) a hybrid, multi-tier detection pipeline that integrates
rule-based pattern matching, a general-purpose privacy detector, and
context-aware validation; (ii) a unified radix-tree index that manages public
and private entries across heterogeneous memory tiers (HBM, DRAM, SSD); and
(iii) entropy-based access monitoring to detect and mitigate residual
information leakage. Our evaluation shows that SafeKV mitigates 94% - 97% of
timing-based side-channel attacks. Compared to per-user isolation method,
SafeKV improves TTFT by up to 40.58% and throughput by up to 2.66X across
diverse LLMs and workloads. SafeKV reduces cache-induced TTFT overhead from
50.41% to 11.74% on Qwen3-235B. By combining fine-grained privacy control with
high cache reuse efficiency, SafeKV reclaims the performance advantages of
global sharing while providing robust runtime privacy guarantees for LLM
inference.

</details>


### [2] [Designing with Deception: ML- and Covert Gate-Enhanced Camouflaging to Thwart IC Reverse Engineering](https://arxiv.org/abs/2508.08462)
*Junling Fan,David Koblah,Domenic Forte*

Main category: cs.CR

TL;DR: 提出了一种基于机器学习的IC伪装方法，通过双层次伪装（功能保留与外观模仿）增强电路安全性，并验证了其对抗AI逆向工程攻击的鲁棒性。


<details>
  <summary>Details</summary>
Motivation: 现有IC伪装技术多关注局部门级修改，缺乏全面欺骗策略，无法有效应对物理逆向工程攻击。

Method: 采用AIG-VAE编码电路表示，引入新型隐蔽门（假反相器、假缓冲器、通用发射器）实现功能隐藏与外观误导。

Result: 实验显示该方法在保持电路功能的同时，实现了高伪装与相似性评分，且结构开销最小。

Conclusion: 该研究填补了硬件安全中模仿欺骗的空白，为IC伪装设定了新标准，推动了网络欺骗原则在关键系统保护中的应用。

Abstract: Integrated circuits (ICs) are essential to modern electronic systems, yet
they face significant risks from physical reverse engineering (RE) attacks that
compromise intellectual property (IP) and overall system security. While IC
camouflage techniques have emerged to mitigate these risks, existing approaches
largely focus on localized gate modifications, neglecting comprehensive
deception strategies. To address this gap, we present a machine learning
(ML)-driven methodology that integrates cryptic and mimetic cyber deception
principles to enhance IC security against RE. Our approach leverages a novel
And-Inverter Graph Variational Autoencoder (AIG-VAE) to encode circuit
representations, enabling dual-layered camouflage through functional
preservation and appearance mimicry. By introducing new variants of covert
gates -- Fake Inverters, Fake Buffers, and Universal Transmitters -- our
methodology achieves robust protection by obscuring circuit functionality while
presenting misleading appearances. Experimental results demonstrate the
effectiveness of our strategy in maintaining circuit functionality while
achieving high camouflage and similarity scores with minimal structural
overhead. Additionally, we validate the robustness of our method against
advanced artificial intelligence (AI)-enhanced RE attacks, highlighting its
practical applicability in securing IC designs. By bridging the gap in mimetic
deception for hardware security, our work sets a new standard for IC
camouflage, advancing the application of cyber deception principles to protect
critical systems from adversarial threats.

</details>


### [3] [AI Security Map: Holistic Organization of AI Security Technologies and Impacts on Stakeholders](https://arxiv.org/abs/2508.08583)
*Hiroya Kato,Kentaro Kita,Kento Hasegawa,Seira Hidano*

Main category: cs.CR

TL;DR: 论文提出了一种AI安全地图，全面组织AI安全相关元素及其对信息系统和利益相关者的负面影响，帮助理解它们之间的关系。


<details>
  <summary>Details</summary>
Motivation: 现有研究局限于特定领域或AI元素的攻击、防御和风险，难以理解它们之间的关系及其对利益相关者的负面影响。

Method: 开发了一个AI安全地图，分为信息系统方面（ISA）和外部影响方面（EIA），分类并识别了各元素的负面影响。

Result: 通过该地图，可以理解负面影响的潜在原因和应对措施，并明确AI系统与利益相关者负面影响的关系。

Conclusion: 论文提供了未来AI安全社区的建议和开放性问题，展示了通过地图获得的新发现。

Abstract: As the social implementation of AI has been steadily progressing, research
and development related to AI security has also been increasing. However,
existing studies have been limited to organizing related techniques, attacks,
defenses, and risks in terms of specific domains or AI elements. Thus, it
extremely difficult to understand the relationships among them and how negative
impacts on stakeholders are brought about. In this paper, we argue that the
knowledge, technologies, and social impacts related to AI security should be
holistically organized to help understand relationships among them. To this
end, we first develop an AI security map that holistically organizes
interrelationships among elements related to AI security as well as negative
impacts on information systems and stakeholders. This map consists of the two
aspects, namely the information system aspect (ISA) and the external influence
aspect (EIA). The elements that AI should fulfill within information systems
are classified under the ISA. The EIA includes elements that affect
stakeholders as a result of AI being attacked or misused. For each element,
corresponding negative impacts are identified. By referring to the AI security
map, one can understand the potential negative impacts, along with their causes
and countermeasures. Additionally, our map helps clarify how the negative
impacts on AI-based systems relate to those on stakeholders. We show some
findings newly obtained by referring to our map. We also provide several
recommendations and open problems to guide future AI security communities.

</details>


### [4] [Generative AI for Critical Infrastructure in Smart Grids: A Unified Framework for Synthetic Data Generation and Anomaly Detection](https://arxiv.org/abs/2508.08593)
*Aydin Zaboli,Junho Hong*

Main category: cs.CR

TL;DR: 本文提出了一种基于生成式AI（GenAI）的异常检测系统（ADS），用于解决IEC61850数字变电站中的网络安全挑战，特别是针对GOOSE协议的漏洞。通过先进的对抗性流量变异（AATM）技术生成合成数据集，并结合任务导向对话（ToD）流程，显著提升了攻击模式的检测能力。


<details>
  <summary>Details</summary>
Motivation: 数字变电站中的网络安全事件对电力系统的持续运行构成重大威胁。传统异常检测系统（ADS）在检测威胁方面存在局限性，因此需要一种更强大的方法来应对现代智能电网中的漏洞。

Method: 利用生成式AI（GenAI）开发ADS，包括AATM技术生成合成数据集，以及ToD流程优化攻击模式检测。

Result: GenAI-based ADS在性能评估中优于传统机器学习（ML）方法，特别是在检测零日攻击模式方面表现突出。

Conclusion: GenAI-based ADS为数字变电站提供了一种高效且可靠的网络安全解决方案，能够应对现代智能电网中的复杂威胁。

Abstract: In digital substations, security events pose significant challenges to the
sustained operation of power systems. To mitigate these challenges, the
implementation of robust defense strategies is critically important. A thorough
process of anomaly identification and detection in information and
communication technology (ICT) frameworks is crucial to ensure secure and
reliable communication and coordination between interconnected devices within
digital substations. Hence, this paper addresses the critical cybersecurity
challenges confronting IEC61850-based digital substations within modern smart
grids, where the integration of advanced communication protocols, e.g., generic
object-oriented substation event (GOOSE), has enhanced energy management and
introduced significant vulnerabilities to cyberattacks. Focusing on the
limitations of traditional anomaly detection systems (ADSs) in detecting
threats, this research proposes a transformative approach by leveraging
generative AI (GenAI) to develop robust ADSs. The primary contributions include
the suggested advanced adversarial traffic mutation (AATM) technique to
generate synthesized and balanced datasets for GOOSE messages, ensuring
protocol compliance and enabling realistic zero-day attack pattern creation to
address data scarcity. Then, the implementation of GenAI-based ADSs
incorporating the task-oriented dialogue (ToD) processes has been explored for
improved detection of attack patterns. Finally, a comparison of the GenAI-based
ADS with machine learning (ML)-based ADSs has been implemented to showcase the
outperformance of the GenAI-based frameworks considering the AATM-generated
GOOSE datasets and standard/advanced performance evaluation metrics.

</details>


### [5] [Hypervisor-based Double Extortion Ransomware Detection Method Using Kitsune Network Features](https://arxiv.org/abs/2508.08655)
*Manabu Hirano,Ryotaro Kobayashi*

Main category: cs.CR

TL;DR: 本文提出了一种基于低级存储、内存行为特征和网络流量特征的新型检测方法，用于防御双重勒索勒索软件攻击，实验结果显示检测率有所提升。


<details>
  <summary>Details</summary>
Motivation: 由于组织采用更强大的数据备份策略对抗传统加密勒索软件，双重勒索攻击成为主流，需要更深入的防御策略。

Method: 使用低级存储和内存行为特征及网络流量特征，结合轻量级Kitsune NIDS检测数据外泄阶段。

Result: 实验表明，该方法在数据外泄阶段检测的宏F分数提高了0.166。

Conclusion: 虽然方法有效，但仍存在局限性，未来需进一步改进。

Abstract: Double extortion ransomware attacks have become mainstream since many
organizations adopt more robust and resilient data backup strategies against
conventional crypto-ransomware. This paper presents detailed attack stages,
tactics, procedures, and tools used in the double extortion ransomware attacks.
We then present a novel detection method using low-level storage and memory
behavioral features and network traffic features obtained from a thin
hypervisor to establish a defense-in-depth strategy for when attackers
compromise OS-level protection. We employed the lightweight \emph{Kitsune}
Network Intrusion Detection System (NIDS)'s network feature to detect the data
exfiltration phase in double extortion ransomware attacks. Our experimental
results showed that the presented method improved by 0.166 in the macro F score
of the data exfiltration phase detection rate. Lastly, we discuss the
limitations of the presented method and future work.

</details>


### [6] [Evasive Ransomware Attacks Using Low-level Behavioral Adversarial Examples](https://arxiv.org/abs/2508.08656)
*Manabu Hirano,Ryotaro Kobayashi*

Main category: cs.CR

TL;DR: 论文探讨了如何通过生成低级别行为对抗样本来规避AI网络安全防御系统，并以Conti勒索软件为例验证了方法的有效性。


<details>
  <summary>Details</summary>
Motivation: 保护AI网络安全防御系统免受对抗性攻击至关重要，攻击者通过微小扰动生成对抗样本以欺骗深度学习模型。

Method: 提出低级别行为对抗样本概念及其威胁模型，利用微行为控制功能模拟勒索软件行为变化，生成最优规避恶意代码。

Result: 通过Conti勒索软件的微行为控制功能验证，攻击者可通过调整线程数、文件加密比例等行为特征降低检测率。

Conclusion: 研究表明，攻击者能有效控制勒索软件行为特征以规避检测，凸显了AI防御系统的脆弱性。

Abstract: Protecting state-of-the-art AI-based cybersecurity defense systems from cyber
attacks is crucial. Attackers create adversarial examples by adding small
changes (i.e., perturbations) to the attack features to evade or fool the deep
learning model. This paper introduces the concept of low-level behavioral
adversarial examples and its threat model of evasive ransomware. We formulate
the method and the threat model to generate the optimal source code of evasive
malware. We then examine the method using the leaked source code of Conti
ransomware with the micro-behavior control function. The micro-behavior control
function is our test component to simulate changing source code in ransomware;
ransomware's behavior can be changed by specifying the number of threads, file
encryption ratio, and delay after file encryption at the boot time. We
evaluated how much an attacker can control the behavioral features of
ransomware using the micro-behavior control function to decrease the detection
rate of a ransomware detector.

</details>


### [7] [Approximate DBSCAN under Differential Privacy](https://arxiv.org/abs/2508.08749)
*Yuan Qiu,Ke Yi*

Main category: cs.CR

TL;DR: 论文重新审视了差分隐私（DP）下的DBSCAN问题，提出了一种基于“spans”的新定义，并设计了一种线性时间的DP-DBSCAN算法。


<details>
  <summary>Details</summary>
Motivation: 现有DP-DBSCAN算法在发布聚类标签时缺乏实用性，因此需要一种更有效的方法来支持可视化和分类任务。

Method: 提出基于“spans”的新定义，并设计了一种线性时间的DP-DBSCAN算法，同时构建了一个纯DP下的直方图算法。

Result: 算法在任意常数维度下实现了三明治质量保证，并匹配了近似比的下界。实验验证了算法的实际性能。

Conclusion: 基于“spans”的DP-DBSCAN定义更实用，提出的算法在理论和实验中均表现出色。

Abstract: This paper revisits the DBSCAN problem under differential privacy (DP).
Existing DP-DBSCAN algorithms aim at publishing the cluster labels of the input
points. However, we show that both empirically and theoretically, this approach
cannot offer any utility in the published results. We therefore propose an
alternative definition of DP-DBSCAN based on the notion of spans. We argue that
publishing the spans actually better serves the purposes of visualization and
classification of DBSCAN. Then we present a linear-time DP-DBSCAN algorithm
achieving the sandwich quality guarantee in any constant dimensions, as well as
matching lower bounds on the approximation ratio. A key building block in our
algorithm is a linear-time algorithm for constructing a histogram under
pure-DP, which is of independent interest. Finally, we conducted experiments on
both synthetic and real-world datasets to verify the practical performance of
our DP-DBSCAN algorithm.

</details>


### [8] [Never Compromise to Vulnerabilities: A Comprehensive Survey on AI Governance](https://arxiv.org/abs/2508.08789)
*Yuchu Jiang,Jian Zhao,Yuchen Yuan,Tianle Zhang,Yao Huang,Yanghao Zhang,Yan Wang,Yanshu Li,Xizhong Guo,Yusheng Zhao,Jun Zhang,Zhi Zhang,Xiaojian Lin,Yixiu Zou,Haoxuan Ma,Yuhu Shang,Yuzhi Hu,Keshu Cai,Ruochen Zhang,Boyuan Chen,Yilan Gao,Ziheng Jiao,Yi Qin,Shuangjun Du,Xiao Tong,Zhekun Liu,Yu Chen,Xuankun Rong,Rui Wang,Yejie Zheng,Zhaoxin Fan,Hongyuan Zhang,Pan Zhou,Lei Jin,Hao Zhao,Xu Yang,Jiaojiao Zhao,Jianshu Li,Joey Tianyi Zhou,Zhi-Qi Cheng,Longtao Huang,Zhiyi Liu,Zheng Zhu,Jianan Li,Gang Wang,Qi Li,Xu-Yao Zhang,Yaodong Yang,Mang Ye,Wenqi Ren,Zhaofeng He,Hang Su,Rongrong Ni,Liping Jing,Xingxing Wei,Junliang Xing,Massimo Alioto,Shengmei Shen,Petia Radeva,Dacheng Tao,Ya-Qin Zhang,Shuicheng Yan,Chi Zhang,Zhongjiang He,Xuelong Li*

Main category: cs.CR

TL;DR: 本文提出了一种综合框架，整合技术和社会的维度，以解决AI治理中的核心挑战，包括系统可靠性、现实危害缓解和社会伦理。


<details>
  <summary>Details</summary>
Motivation: AI快速发展带来的技术漏洞和社会风险（如算法偏见和对抗性攻击）亟需治理框架。

Method: 通过系统综述300多项研究，提出三支柱框架：内在安全、衍生安全和社会伦理，结合技术方法和政策建议。

Result: 识别了三大挑战：防御泛化不足、评估协议不完善和监管碎片化，并提出了整合研究议程。

Conclusion: 框架为研究人员、工程师和政策制定者提供了行动指南，旨在开发既稳健又符合伦理的AI系统。

Abstract: The rapid advancement of AI has expanded its capabilities across domains, yet
introduced critical technical vulnerabilities, such as algorithmic bias and
adversarial sensitivity, that pose significant societal risks, including
misinformation, inequity, security breaches, physical harm, and eroded public
trust. These challenges highlight the urgent need for robust AI governance. We
propose a comprehensive framework integrating technical and societal
dimensions, structured around three interconnected pillars: Intrinsic Security
(system reliability), Derivative Security (real-world harm mitigation), and
Social Ethics (value alignment and accountability). Uniquely, our approach
unifies technical methods, emerging evaluation benchmarks, and policy insights
to promote transparency, accountability, and trust in AI systems. Through a
systematic review of over 300 studies, we identify three core challenges: (1)
the generalization gap, where defenses fail against evolving threats; (2)
inadequate evaluation protocols that overlook real-world risks; and (3)
fragmented regulations leading to inconsistent oversight. These shortcomings
stem from treating governance as an afterthought, rather than a foundational
design principle, resulting in reactive, siloed efforts that fail to address
the interdependence of technical integrity and societal trust. To overcome
this, we present an integrated research agenda that bridges technical rigor
with social responsibility. Our framework offers actionable guidance for
researchers, engineers, and policymakers to develop AI systems that are not
only robust and secure but also ethically aligned and publicly trustworthy. The
accompanying repository is available at
https://github.com/ZTianle/Awesome-AI-SG.

</details>


### [9] [Image selective encryption analysis using mutual information in CNN based embedding space](https://arxiv.org/abs/2508.08832)
*Ikram Messadi,Giulia Cervia,Vincent Itier*

Main category: cs.CR

TL;DR: 该论文研究了图像数据中的信息泄漏问题，提出使用互信息（MI）估计器（如经验估计器和MINE框架）来检测选择性加密图像中的泄漏。


<details>
  <summary>Details</summary>
Motivation: 随着数字数据传输规模的扩大，隐私问题日益紧迫，但隐私仍是一个社会构建且模糊的概念，缺乏普遍接受的量化指标。

Method: 结合深度学习、信息论和密码学，利用互信息估计器（如经验估计器和MINE框架）检测图像中的信息泄漏。

Result: 研究表明，稳健的估计器需要能够捕捉空间依赖性和残余结构的概率框架，即使在加密表示中也是如此。

Conclusion: 该工作为图像信息泄漏估计提供了一个有前景的方向。

Abstract: As digital data transmission continues to scale, concerns about privacy grow
increasingly urgent - yet privacy remains a socially constructed and
ambiguously defined concept, lacking a universally accepted quantitative
measure. This work examines information leakage in image data, a domain where
information-theoretic guarantees are still underexplored. At the intersection
of deep learning, information theory, and cryptography, we investigate the use
of mutual information (MI) estimators - in particular, the empirical estimator
and the MINE framework - to detect leakage from selectively encrypted images.
Motivated by the intuition that a robust estimator would require a
probabilistic frameworks that can capture spatial dependencies and residual
structures, even within encrypted representations - our work represent a
promising direction for image information leakage estimation.

</details>


### [10] [EditMF: Drawing an Invisible Fingerprint for Your Large Language Models](https://arxiv.org/abs/2508.08836)
*Jiaxuan Wu,Yinghan Zhou,Wanli Peng,Yiming Xue,Juan Wen,Ping Zhong*

Main category: cs.CR

TL;DR: EditMF是一种无需训练的方法，通过语义连贯的三元组嵌入指纹，实现高效且隐蔽的LLM所有权验证。


<details>
  <summary>Details</summary>
Motivation: 保护大型语言模型（LLM）的知识产权（IP）是资源密集型任务，现有方法在隐蔽性和效率上存在不足。

Method: 使用加密的人工知识库中的三元组映射所有权位，通过因果追踪和零空间更新嵌入指纹，仅需单次黑盒查询验证。

Result: 在LLaMA和Qwen模型上，EditMF实现了高隐蔽性和低性能损失，鲁棒性远超LoRA基方法。

Conclusion: EditMF是一种高效、低开销的LLM所有权验证解决方案。

Abstract: Training large language models (LLMs) is resource-intensive and expensive,
making protecting intellectual property (IP) for LLMs crucial. Recently,
embedding fingerprints into LLMs has emerged as a prevalent method for
establishing model ownership. However, existing back-door-based methods suffer
from limited stealth and efficiency. To simultaneously address these issues, we
propose EditMF, a training-free fingerprinting paradigm that achieves highly
imperceptible fingerprint embedding with minimal computational overhead.
Ownership bits are mapped to compact, semantically coherent triples drawn from
an encrypted artificial knowledge base (e.g., virtual author-novel-protagonist
facts). Causal tracing localizes the minimal set of layers influencing each
triple, and a zero-space update injects the fingerprint without perturbing
unrelated knowledge. Verification requires only a single black-box query and
succeeds when the model returns the exact pre-embedded protagonist. Empirical
results on LLaMA and Qwen families show that EditMF combines high
imperceptibility with negligible model's performance loss, while delivering
robustness far beyond LoRA-based fingerprinting and approaching that of SFT
embeddings. Extensive experiments demonstrate that EditMF is an effective and
low-overhead solution for secure LLM ownership verification.

</details>


### [11] [Redactable Blockchains: An Overview](https://arxiv.org/abs/2508.08898)
*Federico Calandra,Marco Bernardo,Andrea Esposito,Francesco Fabris*

Main category: cs.CR

TL;DR: 该论文探讨了可编辑区块链的必要性，介绍了实现安全编辑的密码学方法，并分析了不同方案的优缺点，同时讨论了其在私有环境中的实际应用和未来潜力。


<details>
  <summary>Details</summary>
Motivation: 传统区块链的不可变性在需要合规性、错误修正或敏感信息删除的实际场景中存在局限性，因此需要可编辑区块链来解决这些问题。

Method: 通过密码学机制（如变色龙哈希函数和其他编辑方案）实现区块链数据的可控、可审计修改。

Result: 论文总结了可编辑区块链的技术方案，并探讨了其在医疗、金融、无人机物联网和联邦学习等领域的应用。

Conclusion: 可编辑区块链在构建合规、可信和可扩展的数字基础设施方面具有巨大潜力，但仍需解决与可逆计算相关的挑战。

Abstract: Blockchains are widely recognized for their immutability, which provides
robust guarantees of data integrity and transparency. However, this same
feature poses significant challenges in real-world situations that require
regulatory compliance, correction of erroneous data, or removal of sensitive
information. Redactable blockchains address the limitations of traditional ones
by enabling controlled, auditable modifications to blockchain data, primarily
through cryptographic mechanisms such as chameleon hash functions and
alternative redaction schemes. This report examines the motivations for
introducing redactability, surveys the cryptographic primitives that enable
secure edits, and analyzes competing approaches and their shortcomings. Special
attention is paid to the practical deployment of redactable blockchains in
private settings, with discussions of use cases in healthcare, finance,
Internet of drones, and federated learning. Finally, the report outlines
further challenges, also in connection with reversible computing, and the
future potential of redactable blockchains in building law-compliant,
trustworthy, and scalable digital infrastructures.

</details>


### [12] [Load-Altering Attacks Against Power Grids: A Case Study Using the GB-36 Bus System Open Dataset](https://arxiv.org/abs/2508.08945)
*Syed Irtiza Maksud,Subhash Lakshminarayana*

Main category: cs.CR

TL;DR: 论文研究了负载改变攻击（LAA）对电力系统的威胁，利用开源数据集和实际电网模型（GB-36 Zone）评估攻击阈值及电池储能系统（BESS）的缓解效果。


<details>
  <summary>Details</summary>
Motivation: 随着物联网设备的普及，电网面临更多网络威胁，尤其是LAA可能导致频率波动和电网不稳定，亟需研究其实际影响及应对措施。

Method: 使用英国国家电网运营商的开源数据集和GB-36 Zone模型，通过DIgSILENT PowerFactory进行仿真，分析LAA的阈值及BESS的缓解作用。

Result: 研究确定了电网对LAA的容忍阈值，并发现BESS的位置和攻击延迟对系统响应有显著影响。

Conclusion: BESS能有效缓解LAA的影响，研究为电网运营商提供了实用的防御策略建议。

Abstract: The growing digitalization and the rapid adoption of high-powered
Internet-of-Things (IoT)-enabled devices (e.g., EV charging stations) have
increased the vulnerability of power grids to cyber threats. In particular, the
so-called Load Altering Attacks (LAAs) can trigger rapid frequency fluctuations
and potentially destabilize the power grid. This paper aims to bridge the gap
between academic research and practical application by using open-source
datasets released by grid operators. It investigates various LAA scenarios on a
real-world transmission network, namely the Great Britain (GB)-36 Zone model
released by the UK's National Electricity System Operator (NESO). It evaluates
the threshold of LAA severity that the grid can tolerate before triggering
cascading effects. Additionally, it explores how Battery Energy Storage Systems
(BESS) based fast frequency response services can mitigate or prevent such
impacts. Simulations are conducted using DIgSILENT PowerFactory to ensure
realistic system representation. The analysis provides several useful insights
to grid operators on the LAA impact, such as the influence of the relative
locations of BESS and LAA, as well as how delays in attack execution can
influence the overall system response.

</details>


### [13] [Attacks and Defenses Against LLM Fingerprinting](https://arxiv.org/abs/2508.09021)
*Kevin Kurian,Ethan Holland,Sean Oesch*

Main category: cs.CR

TL;DR: 本文研究了大型语言模型（LLM）的指纹攻击与防御方法，提出基于强化学习的攻击优化和语义保留的防御策略。


<details>
  <summary>Details</summary>
Motivation: 随着LLM在敏感环境中的部署增加，指纹攻击对隐私和安全构成威胁，需研究攻防方法。

Method: 攻击方法使用强化学习优化查询选择；防御方法通过次级LLM进行语义保留的输出过滤。

Result: 攻击方法仅需3次查询即可提高指纹识别准确率；防御方法降低指纹识别率且保持输出质量。

Conclusion: 研究提升了指纹工具能力，并提供了实用的防御策略。

Abstract: As large language models are increasingly deployed in sensitive environments,
fingerprinting attacks pose significant privacy and security risks. We present
a study of LLM fingerprinting from both offensive and defensive perspectives.
Our attack methodology uses reinforcement learning to automatically optimize
query selection, achieving better fingerprinting accuracy with only 3 queries
compared to randomly selecting 3 queries from the same pool. Our defensive
approach employs semantic-preserving output filtering through a secondary LLM
to obfuscate model identity while maintaining semantic integrity. The defensive
method reduces fingerprinting accuracy across tested models while preserving
output quality. These contributions show the potential to improve
fingerprinting tools capabilities while providing practical mitigation
strategies against fingerprinting attacks.

</details>


### [14] [Developing a Transferable Federated Network Intrusion Detection System](https://arxiv.org/abs/2508.09060)
*Abu Shafin Mohammad Mahdee Jameel,Shreya Ghosh,Aly El Gamal*

Main category: cs.CR

TL;DR: 提出了一种基于深度学习的分布式入侵检测系统，通过最大化已知攻击知识的迁移性关系提升模型对未知攻击的防御能力。


<details>
  <summary>Details</summary>
Motivation: 提升深度学习模型对未知攻击的防御能力，利用已知攻击知识增强入侵检测系统的迁移性。

Method: 开发了CNN模型，并提出两步数据预处理和BBSA算法以最大化迁移性关系。

Result: 系统在保持高本地检测率的同时，实现了优越的迁移性能，且方法具有通用性。

Conclusion: 该方法在跨数据集和不同主干网络下均表现出迁移潜力，代码已开源。

Abstract: Intrusion Detection Systems (IDS) are a vital part of a network-connected
device. In this paper, we develop a deep learning based intrusion detection
system that is deployed in a distributed setup across devices connected to a
network. Our aim is to better equip deep learning models against unknown
attacks using knowledge from known attacks. To this end, we develop algorithms
to maximize the number of transferability relationships. We propose a
Convolutional Neural Network (CNN) model, along with two algorithms that
maximize the number of relationships observed. One is a two step data
pre-processing stage, and the other is a Block-Based Smart Aggregation (BBSA)
algorithm. The proposed system succeeds in achieving superior transferability
performance while maintaining impressive local detection rates. We also show
that our method is generalizable, exhibiting transferability potential across
datasets and even with different backbones. The code for this work can be found
at https://github.com/ghosh64/tabfidsv2.

</details>
