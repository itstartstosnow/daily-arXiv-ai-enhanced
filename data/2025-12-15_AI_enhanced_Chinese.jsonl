{"id": "2512.10998", "categories": ["cs.CR", "cs.CL"], "pdf": "https://arxiv.org/pdf/2512.10998", "abs": "https://arxiv.org/abs/2512.10998", "authors": ["Mohamed Afane", "Abhishek Satyam", "Ke Chen", "Tao Li", "Junaid Farooq", "Juntao Chen"], "title": "SCOUT: A Defense Against Data Poisoning Attacks in Fine-Tuned Language Models", "comment": "9 pages, 3 figures", "summary": "Backdoor attacks create significant security threats to language models by embedding hidden triggers that manipulate model behavior during inference, presenting critical risks for AI systems deployed in healthcare and other sensitive domains. While existing defenses effectively counter obvious threats such as out-of-context trigger words and safety alignment violations, they fail against sophisticated attacks using contextually-appropriate triggers that blend seamlessly into natural language. This paper introduces three novel contextually-aware attack scenarios that exploit domain-specific knowledge and semantic plausibility: the ViralApp attack targeting social media addiction classification, the Fever attack manipulating medical diagnosis toward hypertension, and the Referral attack steering clinical recommendations. These attacks represent realistic threats where malicious actors exploit domain-specific vocabulary while maintaining semantic coherence, demonstrating how adversaries can weaponize contextual appropriateness to evade conventional detection methods. To counter both traditional and these sophisticated attacks, we present \\textbf{SCOUT (Saliency-based Classification Of Untrusted Tokens)}, a novel defense framework that identifies backdoor triggers through token-level saliency analysis rather than traditional context-based detection methods. SCOUT constructs a saliency map by measuring how the removal of individual tokens affects the model's output logits for the target label, enabling detection of both conspicuous and subtle manipulation attempts. We evaluate SCOUT on established benchmark datasets (SST-2, IMDB, AG News) against conventional attacks (BadNet, AddSent, SynBkd, StyleBkd) and our novel attacks, demonstrating that SCOUT successfully detects these sophisticated threats while preserving accuracy on clean inputs.", "AI": {"tldr": "\u672c\u6587\u63d0\u51faSCOUT\u9632\u5fa1\u6846\u67b6\uff0c\u901a\u8fc7token\u7ea7\u663e\u8457\u6027\u5206\u6790\u68c0\u6d4b\u540e\u95e8\u653b\u51fb\uff0c\u5305\u62ec\u4f20\u7edf\u653b\u51fb\u548c\u65b0\u578b\u4e0a\u4e0b\u6587\u611f\u77e5\u653b\u51fb\uff08ViralApp\u3001Fever\u3001Referral\uff09\uff0c\u5728\u4fdd\u6301\u5e72\u51c0\u8f93\u5165\u51c6\u786e\u6027\u7684\u540c\u65f6\u6709\u6548\u68c0\u6d4b\u9690\u853d\u5a01\u80c1\u3002", "motivation": "\u73b0\u6709\u9632\u5fa1\u65b9\u6cd5\u80fd\u6709\u6548\u5e94\u5bf9\u660e\u663e\u7684\u540e\u95e8\u653b\u51fb\uff08\u5982\u4e0a\u4e0b\u6587\u65e0\u5173\u89e6\u53d1\u8bcd\uff09\uff0c\u4f46\u65e0\u6cd5\u68c0\u6d4b\u4f7f\u7528\u4e0a\u4e0b\u6587\u9002\u5f53\u89e6\u53d1\u8bcd\u7684\u590d\u6742\u653b\u51fb\u3002\u8fd9\u4e9b\u653b\u51fb\u5229\u7528\u9886\u57df\u7279\u5b9a\u77e5\u8bc6\uff0c\u5728\u4fdd\u6301\u8bed\u4e49\u8fde\u8d2f\u6027\u7684\u540c\u65f6\u64cd\u7eb5\u6a21\u578b\u884c\u4e3a\uff0c\u5bf9\u533b\u7597\u7b49\u654f\u611f\u9886\u57df\u6784\u6210\u4e25\u91cd\u5a01\u80c1\u3002", "method": "\u63d0\u51faSCOUT\u9632\u5fa1\u6846\u67b6\uff0c\u901a\u8fc7\u6784\u5efatoken\u7ea7\u663e\u8457\u6027\u56fe\u6765\u68c0\u6d4b\u540e\u95e8\u89e6\u53d1\u8bcd\u3002\u8be5\u65b9\u6cd5\u901a\u8fc7\u6d4b\u91cf\u79fb\u9664\u5355\u4e2atoken\u5bf9\u76ee\u6807\u6807\u7b7e\u8f93\u51falogits\u7684\u5f71\u54cd\u6765\u8bc6\u522b\u53ef\u7591token\uff0c\u4e0d\u4f9d\u8d56\u4f20\u7edf\u57fa\u4e8e\u4e0a\u4e0b\u6587\u7684\u68c0\u6d4b\u65b9\u6cd5\u3002", "result": "\u5728\u6807\u51c6\u57fa\u51c6\u6570\u636e\u96c6\uff08SST-2\u3001IMDB\u3001AG News\uff09\u4e0a\u8bc4\u4f30SCOUT\uff0c\u7ed3\u679c\u663e\u793a\u5b83\u80fd\u6210\u529f\u68c0\u6d4b\u4f20\u7edf\u653b\u51fb\uff08BadNet\u3001AddSent\u7b49\uff09\u548c\u65b0\u578b\u4e0a\u4e0b\u6587\u611f\u77e5\u653b\u51fb\uff0c\u540c\u65f6\u4fdd\u6301\u5e72\u51c0\u8f93\u5165\u7684\u51c6\u786e\u6027\u3002", "conclusion": "SCOUT\u6846\u67b6\u901a\u8fc7token\u7ea7\u663e\u8457\u6027\u5206\u6790\u6709\u6548\u68c0\u6d4b\u5404\u79cd\u540e\u95e8\u653b\u51fb\uff0c\u5305\u62ec\u4f20\u7edf\u653b\u51fb\u548c\u65b0\u578b\u4e0a\u4e0b\u6587\u611f\u77e5\u653b\u51fb\uff0c\u4e3a\u8bed\u8a00\u6a21\u578b\u63d0\u4f9b\u4e86\u66f4\u5168\u9762\u7684\u5b89\u5168\u9632\u62a4\uff0c\u7279\u522b\u662f\u5728\u533b\u7597\u7b49\u654f\u611f\u9886\u57df\u3002"}}
{"id": "2512.11112", "categories": ["cs.CR", "cs.DC", "cs.SE"], "pdf": "https://arxiv.org/pdf/2512.11112", "abs": "https://arxiv.org/abs/2512.11112", "authors": ["Tianye Dai", "Hammurabi Mendes", "Heuichan Lim"], "title": "An LLVM-Based Optimization Pipeline for SPDZ", "comment": null, "summary": "Actively secure arithmetic MPC is now practical for real applications, but performance and usability are still limited by framework-specific compilation stacks, the need for programmers to explicitly express parallelism, and high communication overhead. We design and implement a proof-of-concept LLVM-based optimization pipeline for the SPDZ protocol that addresses these bottlenecks. Our front end accepts a subset of C with lightweight privacy annotations and lowers it to LLVM IR, allowing us to reuse mature analyses and transformations to automatically batch independent arithmetic operations. Our back end performs data-flow and control-flow analysis on the optimized IR to drive a non-blocking runtime scheduler that overlaps independent operations and aggressively overlaps communication with computation; when enabled, it can map batched operations to GPU kernels. This design preserves a low learning curve by using a mainstream language and hiding optimization and hardware-specific mechanics from programmers. We evaluate the system on controlled microbenchmarks against MP-SPDZ, focusing on online phase performance. Our CPU back end achieves up to 5.56 times speedup under intermediate and heavy algebraic workloads, shows strong scaling with thread count, and our GPU back end scales better as the input size increases. Overall, these results indicate that leveraging LLVM with protocol-aware scheduling is an effective architectural direction for extracting parallelism without sacrificing usability.", "AI": {"tldr": "\u57fa\u4e8eLLVM\u7684SPDZ\u534f\u8bae\u4f18\u5316\u6846\u67b6\uff0c\u901a\u8fc7\u81ea\u52a8\u6279\u5904\u7406\u3001\u975e\u963b\u585e\u8c03\u5ea6\u548cGPU\u652f\u6301\uff0c\u663e\u8457\u63d0\u5347MPC\u6027\u80fd\uff0c\u540c\u65f6\u4fdd\u6301\u6613\u7528\u6027\u3002", "motivation": "\u5f53\u524dMPC\u6846\u67b6\u5b58\u5728\u6027\u80fd\u74f6\u9888\uff1a\u9700\u8981\u7279\u5b9a\u7f16\u8bd1\u6808\u3001\u7a0b\u5e8f\u5458\u9700\u663e\u5f0f\u8868\u8fbe\u5e76\u884c\u6027\u3001\u901a\u4fe1\u5f00\u9500\u9ad8\uff0c\u9650\u5236\u4e86\u5b9e\u9645\u5e94\u7528\u548c\u53ef\u7528\u6027\u3002", "method": "\u8bbe\u8ba1\u57fa\u4e8eLLVM\u7684\u4f18\u5316\u6d41\u6c34\u7ebf\uff1a\u524d\u7aef\u63a5\u53d7\u5e26\u9690\u79c1\u6807\u6ce8\u7684C\u8bed\u8a00\u5b50\u96c6\uff0c\u540e\u7aef\u8fdb\u884c\u6570\u636e\u6d41\u548c\u63a7\u5236\u6d41\u5206\u6790\uff0c\u5b9e\u73b0\u975e\u963b\u585e\u8fd0\u884c\u65f6\u8c03\u5ea6\uff0c\u652f\u6301GPU\u5185\u6838\u6620\u5c04\u3002", "result": "CPU\u540e\u7aef\u5728\u4e2d\u9ad8\u8d1f\u8f7d\u4e0b\u5b9e\u73b0\u6700\u9ad85.56\u500d\u52a0\u901f\uff0cGPU\u540e\u7aef\u968f\u8f93\u5165\u89c4\u6a21\u6269\u5927\u8868\u73b0\u66f4\u597d\uff0c\u5728\u7ebf\u9636\u6bb5\u6027\u80fd\u663e\u8457\u4f18\u4e8eMP-SPDZ\u3002", "conclusion": "\u7ed3\u5408LLVM\u548c\u534f\u8bae\u611f\u77e5\u8c03\u5ea6\u662f\u6709\u6548\u67b6\u6784\u65b9\u5411\uff0c\u53ef\u5728\u4e0d\u727a\u7272\u6613\u7528\u6027\u7684\u524d\u63d0\u4e0b\u81ea\u52a8\u63d0\u53d6\u5e76\u884c\u6027\uff0c\u63d0\u5347MPC\u6027\u80fd\u3002"}}
{"id": "2512.11122", "categories": ["cs.CR", "cs.CY"], "pdf": "https://arxiv.org/pdf/2512.11122", "abs": "https://arxiv.org/abs/2512.11122", "authors": ["Mbali Nkosi", "Mike Nkongolo"], "title": "Cybersecurity policy adoption in South Africa: Does public trust matter?", "comment": null, "summary": "This study examines how public perception influences the implementation and adoption of cybersecurity frameworks in South Africa. Using the PRISMA methodology, a systematic literature review was conducted across reputable scholarly databases, yielding 34 relevant sources aligned with predefined inclusion criteria. Cybersecurity, governance, trust, privacy, cybercrime, and public opinion emerged as dominant thematic clusters. Bibliometric and thematic analyses, supported by network visualisations, revealed that while trust and public sentiment affect cybersecurity policy adoption globally, these factors have minimal influence within the South African policy landscape, despite the country's high cybercrime prevalence. In response, the study proposes a trust-centric policymaking framework designed to integrate public perception as a proactive dimension of cybersecurity governance. This framework seeks to prevent trust deficits from obstructing policy effectiveness and provides guidance for restoring trust where it has eroded.", "AI": {"tldr": "\u5357\u975e\u7f51\u7edc\u5b89\u5168\u6846\u67b6\u5b9e\u65bd\u53d7\u516c\u4f17\u611f\u77e5\u5f71\u54cd\u7684\u7814\u7a76\uff1a\u901a\u8fc7\u7cfb\u7edf\u6587\u732e\u7efc\u8ff0\u53d1\u73b0\uff0c\u867d\u7136\u5168\u7403\u8303\u56f4\u5185\u4fe1\u4efb\u548c\u516c\u4f17\u60c5\u7eea\u5f71\u54cd\u7f51\u7edc\u5b89\u5168\u653f\u7b56\u91c7\u7eb3\uff0c\u4f46\u5728\u5357\u975e\u653f\u7b56\u73af\u5883\u4e2d\u8fd9\u4e9b\u56e0\u7d20\u5f71\u54cd\u751a\u5fae\uff0c\u5c3d\u7ba1\u8be5\u56fd\u7f51\u7edc\u72af\u7f6a\u7387\u9ad8\u3002\u7814\u7a76\u63d0\u51fa\u4e86\u4e00\u4e2a\u4ee5\u4fe1\u4efb\u4e3a\u4e2d\u5fc3\u7684\u653f\u7b56\u5236\u5b9a\u6846\u67b6\u3002", "motivation": "\u7814\u7a76\u52a8\u673a\u662f\u63a2\u8ba8\u516c\u4f17\u611f\u77e5\u5982\u4f55\u5f71\u54cd\u5357\u975e\u7f51\u7edc\u5b89\u5168\u6846\u67b6\u7684\u5b9e\u65bd\u548c\u91c7\u7eb3\u3002\u5c3d\u7ba1\u5357\u975e\u7f51\u7edc\u72af\u7f6a\u7387\u9ad8\uff0c\u4f46\u516c\u4f17\u4fe1\u4efb\u548c\u60c5\u7eea\u5bf9\u653f\u7b56\u91c7\u7eb3\u7684\u5f71\u54cd\u5c1a\u672a\u5f97\u5230\u5145\u5206\u7814\u7a76\uff0c\u9700\u8981\u7406\u89e3\u8fd9\u4e9b\u56e0\u7d20\u5728\u5357\u975e\u7279\u5b9a\u80cc\u666f\u4e0b\u7684\u4f5c\u7528\u3002", "method": "\u91c7\u7528PRISMA\u65b9\u6cd5\u8bba\u8fdb\u884c\u7cfb\u7edf\u6587\u732e\u7efc\u8ff0\uff0c\u5728\u6743\u5a01\u5b66\u672f\u6570\u636e\u5e93\u4e2d\u7b5b\u9009\u51fa34\u7bc7\u7b26\u5408\u9884\u8bbe\u7eb3\u5165\u6807\u51c6\u7684\u6587\u732e\u3002\u8fd0\u7528\u6587\u732e\u8ba1\u91cf\u5b66\u548c\u4e3b\u9898\u5206\u6790\u65b9\u6cd5\uff0c\u8f85\u4ee5\u7f51\u7edc\u53ef\u89c6\u5316\u6280\u672f\uff0c\u8bc6\u522b\u51fa\u7f51\u7edc\u5b89\u5168\u3001\u6cbb\u7406\u3001\u4fe1\u4efb\u3001\u9690\u79c1\u3001\u7f51\u7edc\u72af\u7f6a\u548c\u516c\u4f17\u610f\u89c1\u7b49\u4e3b\u8981\u4e3b\u9898\u96c6\u7fa4\u3002", "result": "\u7814\u7a76\u53d1\u73b0\uff1a1) \u7f51\u7edc\u5b89\u5168\u3001\u6cbb\u7406\u3001\u4fe1\u4efb\u3001\u9690\u79c1\u3001\u7f51\u7edc\u72af\u7f6a\u548c\u516c\u4f17\u610f\u89c1\u662f\u4e3b\u8981\u4e3b\u9898\u96c6\u7fa4\uff1b2) \u867d\u7136\u5168\u7403\u8303\u56f4\u5185\u4fe1\u4efb\u548c\u516c\u4f17\u60c5\u7eea\u663e\u8457\u5f71\u54cd\u7f51\u7edc\u5b89\u5168\u653f\u7b56\u91c7\u7eb3\uff0c\u4f46\u5728\u5357\u975e\u653f\u7b56\u73af\u5883\u4e2d\u8fd9\u4e9b\u56e0\u7d20\u5f71\u54cd\u751a\u5fae\uff1b3) \u5c3d\u7ba1\u5357\u975e\u7f51\u7edc\u72af\u7f6a\u7387\u9ad8\uff0c\u4f46\u516c\u4f17\u611f\u77e5\u5bf9\u653f\u7b56\u91c7\u7eb3\u7684\u5f71\u54cd\u6709\u9650\u3002", "conclusion": "\u7814\u7a76\u63d0\u51fa\u4e86\u4e00\u4e2a\u4ee5\u4fe1\u4efb\u4e3a\u4e2d\u5fc3\u7684\u653f\u7b56\u5236\u5b9a\u6846\u67b6\uff0c\u65e8\u5728\u5c06\u516c\u4f17\u611f\u77e5\u4f5c\u4e3a\u7f51\u7edc\u5b89\u5168\u6cbb\u7406\u7684\u4e3b\u52a8\u7ef4\u5ea6\u3002\u8be5\u6846\u67b6\u65e8\u5728\u9632\u6b62\u4fe1\u4efb\u8d64\u5b57\u963b\u788d\u653f\u7b56\u6709\u6548\u6027\uff0c\u5e76\u4e3a\u6062\u590d\u5df2\u53d7\u635f\u7684\u4fe1\u4efb\u63d0\u4f9b\u6307\u5bfc\uff0c\u7279\u522b\u9002\u7528\u4e8e\u5357\u975e\u7b49\u7f51\u7edc\u72af\u7f6a\u9ad8\u53d1\u4f46\u516c\u4f17\u611f\u77e5\u5f71\u54cd\u6709\u9650\u7684\u73af\u5883\u3002"}}
{"id": "2512.11135", "categories": ["cs.CR"], "pdf": "https://arxiv.org/pdf/2512.11135", "abs": "https://arxiv.org/abs/2512.11135", "authors": ["Karthik Garimella", "Negar Neda", "Austin Ebel", "Nandan Kumar Jha", "Brandon Reagen"], "title": "Network and Compiler Optimizations for Efficient Linear Algebra Kernels in Private Transformer Inference", "comment": "10 pages, 6 figures", "summary": "Large language model (LLM) based services are primarily structured as client-server interactions, with clients sending queries directly to cloud providers that host LLMs. This approach currently compromises data privacy as all queries must be processed in the cloud and in the clear. Fully Homomorphic Encryption (FHE) is a solution to this data privacy issue by enabling computations directly upon encrypted queries. However, running encrypted transformer inference is challenging as programmers must map standard kernels to the constrained instruction set provided by FHE. In this work, we explore implementations of linear algebra kernels needed for transformer inference in FHE and understand how network optimization can help mitigate FHE costs while remaining performant.\n  We leverage the Orion PyTorch to FHE framework to benchmark several linear algebra kernels in order to profile two linear transformation methods, packed row and BSGS, and find that BSGS outperforms packed row methods by up to $13.7 \\times$ at transformer-level scales. We also incorporate network-level pruning strategies that reduce FHE runtimes of feed forward layers by up to $11.46\\times$. Furthermore, we extend Orion to include ciphertext-ciphertext matrix-matrix products, a key component in the self-attention blocks. Finally, we perform a roofline analysis of FHE primitives and encrypted linear transformations and find that (SIMD encoded) implementations are memory-bound with primitives having roughly $0.1$ integer operations per byte of DRAM traffic. These findings illustrate the need for exploring alternative encoding schemes and models of computation within CKKS to unlock scalable private transformer inference. We conduct all experiments using the Orion framework which can be found at: https://github.com/baahl-nyu/orion.", "AI": {"tldr": "\u8be5\u8bba\u6587\u63a2\u7d22\u4e86\u5728\u5b8c\u5168\u540c\u6001\u52a0\u5bc6\uff08FHE\uff09\u73af\u5883\u4e0b\u5b9e\u73b0Transformer\u63a8\u7406\u7684\u7ebf\u6027\u4ee3\u6570\u6838\uff0c\u6bd4\u8f83\u4e86\u4e24\u79cd\u7ebf\u6027\u53d8\u6362\u65b9\u6cd5\uff0c\u5e76\u5f15\u5165\u7f51\u7edc\u7ea7\u526a\u679d\u7b56\u7565\u6765\u964d\u4f4eFHE\u8ba1\u7b97\u6210\u672c\u3002", "motivation": "\u5f53\u524d\u57fa\u4e8eLLM\u7684\u670d\u52a1\u91c7\u7528\u5ba2\u6237\u7aef-\u670d\u52a1\u5668\u67b6\u6784\uff0c\u67e5\u8be2\u6570\u636e\u9700\u8981\u5728\u4e91\u7aef\u660e\u6587\u5904\u7406\uff0c\u5b58\u5728\u9690\u79c1\u6cc4\u9732\u98ce\u9669\u3002FHE\u53ef\u4ee5\u5728\u52a0\u5bc6\u6570\u636e\u4e0a\u76f4\u63a5\u8ba1\u7b97\uff0c\u4f46Transformer\u63a8\u7406\u5728FHE\u4e2d\u5b9e\u73b0\u56f0\u96be\uff0c\u9700\u8981\u5c06\u6807\u51c6\u6838\u6620\u5c04\u5230FHE\u53d7\u9650\u6307\u4ee4\u96c6\u3002", "method": "\u5229\u7528Orion PyTorch\u5230FHE\u6846\u67b6\u5bf9\u7ebf\u6027\u4ee3\u6570\u6838\u8fdb\u884c\u57fa\u51c6\u6d4b\u8bd5\uff0c\u5206\u6790\u4e24\u79cd\u7ebf\u6027\u53d8\u6362\u65b9\u6cd5\uff08packed row\u548cBSGS\uff09\uff0c\u5f15\u5165\u7f51\u7edc\u7ea7\u526a\u679d\u7b56\u7565\uff0c\u6269\u5c55Orion\u652f\u6301\u5bc6\u6587-\u5bc6\u6587\u77e9\u9635\u4e58\u6cd5\uff0c\u5e76\u8fdb\u884c\u5c4b\u9876\u7ebf\u5206\u6790\u3002", "result": "BSGS\u65b9\u6cd5\u5728Transformer\u89c4\u6a21\u4e0a\u6bd4packed row\u65b9\u6cd5\u5feb13.7\u500d\uff1b\u7f51\u7edc\u526a\u679d\u4f7f\u524d\u9988\u5c42FHE\u8fd0\u884c\u65f6\u95f4\u51cf\u5c1111.46\u500d\uff1bFHE\u539f\u8bed\u548c\u52a0\u5bc6\u7ebf\u6027\u53d8\u6362\u662f\u5185\u5b58\u53d7\u9650\u7684\uff0c\u6bcf\u5b57\u8282DRAM\u6d41\u91cf\u4ec5\u6709\u7ea60.1\u4e2a\u6574\u6570\u64cd\u4f5c\u3002", "conclusion": "\u9700\u8981\u5728CKKS\u4e2d\u63a2\u7d22\u66ff\u4ee3\u7f16\u7801\u65b9\u6848\u548c\u8ba1\u7b97\u6a21\u578b\uff0c\u4ee5\u5b9e\u73b0\u53ef\u6269\u5c55\u7684\u79c1\u6709Transformer\u63a8\u7406\u3002FHE\u5b9e\u73b0\u76ee\u524d\u53d7\u5185\u5b58\u5e26\u5bbd\u9650\u5236\uff0c\u9700\u8981\u8fdb\u4e00\u6b65\u4f18\u5316\u3002"}}
{"id": "2512.11143", "categories": ["cs.CR"], "pdf": "https://arxiv.org/pdf/2512.11143", "abs": "https://arxiv.org/abs/2512.11143", "authors": ["Lingzhi Wang", "Xinyi Shi", "Ziyu Li", "Yi Jiang", "Shiyu Tan", "Yuhao Jiang", "Junjie Cheng", "Wenyuan Chen", "Xiangmin Shen", "Zhenyuan LI", "Yan Chen"], "title": "Automated Penetration Testing with LLM Agents and Classical Planning", "comment": null, "summary": "While penetration testing plays a vital role in cybersecurity, achieving fully automated, hands-off-the-keyboard execution remains a significant research challenge. In this paper, we introduce the \"Planner-Executor-Perceptor (PEP)\" design paradigm and use it to systematically review existing work and identify the key challenges in this area. We also evaluate existing penetration testing systems, with a particular focus on the use of Large Language Model (LLM) agents for this task. The results show that the out-of-the-box Claude Code and Sonnet 4.5 exhibit superior penetration capabilities observed to date, substantially outperforming all prior systems. However, a detailed analysis of their testing processes reveals specific strengths and limitations; notably, LLM agents struggle with maintaining coherent long-horizon plans, performing complex reasoning, and effectively utilizing specialized tools. These limitations significantly constrain its overall capability, efficiency, and stability. To address these limitations, we propose CHECKMATE, a framework that integrates enhanced classical planning with LLM agents, providing an external, structured \"brain\" that mitigates the inherent weaknesses of LLM agents. Our evaluation shows that CHECKMATE outperforms the state-of-the-art system (Claude Code) in penetration capability, improving benchmark success rates by over 20%. In addition, it delivers substantially greater stability, cutting both time and monetary costs by more than 50%.", "AI": {"tldr": "\u8bba\u6587\u63d0\u51faCHECKMATE\u6846\u67b6\uff0c\u901a\u8fc7\u589e\u5f3a\u7ecf\u5178\u89c4\u5212\u4e0eLLM\u4ee3\u7406\u7ed3\u5408\uff0c\u663e\u8457\u63d0\u5347\u81ea\u52a8\u5316\u6e17\u900f\u6d4b\u8bd5\u80fd\u529b\uff0c\u76f8\u6bd4\u73b0\u6709\u6700\u4f73\u7cfb\u7edf\u6210\u529f\u7387\u63d0\u9ad820%\u4ee5\u4e0a\uff0c\u6210\u672c\u964d\u4f4e50%\u4ee5\u4e0a\u3002", "motivation": "\u81ea\u52a8\u5316\u6e17\u900f\u6d4b\u8bd5\u662f\u7f51\u7edc\u5b89\u5168\u91cd\u8981\u4f46\u5177\u6709\u6311\u6218\u6027\u7684\u7814\u7a76\u65b9\u5411\uff0c\u73b0\u6709\u57fa\u4e8eLLM\u7684\u4ee3\u7406\u7cfb\u7edf\u5728\u957f\u671f\u89c4\u5212\u3001\u590d\u6742\u63a8\u7406\u548c\u5de5\u5177\u4f7f\u7528\u65b9\u9762\u5b58\u5728\u5c40\u9650\uff0c\u9650\u5236\u4e86\u5176\u6574\u4f53\u80fd\u529b\u3001\u6548\u7387\u548c\u7a33\u5b9a\u6027\u3002", "method": "\u63d0\u51fa\"\u89c4\u5212\u5668-\u6267\u884c\u5668-\u611f\u77e5\u5668(PEP)\"\u8bbe\u8ba1\u8303\u5f0f\u7528\u4e8e\u7cfb\u7edf\u5206\u6790\u73b0\u6709\u5de5\u4f5c\uff0c\u5e76\u5f00\u53d1CHECKMATE\u6846\u67b6\uff0c\u5c06\u589e\u5f3a\u7684\u7ecf\u5178\u89c4\u5212\u4e0eLLM\u4ee3\u7406\u96c6\u6210\uff0c\u63d0\u4f9b\u5916\u90e8\u7ed3\u6784\u5316\"\u5927\u8111\"\u6765\u5f25\u8865LLM\u4ee3\u7406\u7684\u56fa\u6709\u5f31\u70b9\u3002", "result": "\u8bc4\u4f30\u663e\u793aClaude Code\u548cSonnet 4.5\u5728\u73b0\u6709\u7cfb\u7edf\u4e2d\u8868\u73b0\u6700\u4f73\uff0c\u4f46CHECKMATE\u6846\u67b6\u5728\u6e17\u900f\u80fd\u529b\u4e0a\u8d85\u8d8a\u6700\u5148\u8fdb\u7cfb\u7edf(Claude Code)\uff0c\u57fa\u51c6\u6210\u529f\u7387\u63d0\u9ad820%\u4ee5\u4e0a\uff0c\u7a33\u5b9a\u6027\u5927\u5e45\u63d0\u5347\uff0c\u65f6\u95f4\u548c\u91d1\u94b1\u6210\u672c\u964d\u4f4e50%\u4ee5\u4e0a\u3002", "conclusion": "CHECKMATE\u6846\u67b6\u901a\u8fc7\u7ed3\u5408\u7ecf\u5178\u89c4\u5212\u4e0eLLM\u4ee3\u7406\uff0c\u6709\u6548\u89e3\u51b3\u4e86\u81ea\u52a8\u5316\u6e17\u900f\u6d4b\u8bd5\u4e2d\u7684\u5173\u952e\u6311\u6218\uff0c\u663e\u8457\u63d0\u5347\u4e86\u7cfb\u7edf\u6027\u80fd\u3001\u7a33\u5b9a\u6027\u548c\u6210\u672c\u6548\u76ca\uff0c\u4e3a\u5b8c\u5168\u81ea\u52a8\u5316\u6e17\u900f\u6d4b\u8bd5\u63d0\u4f9b\u4e86\u6709\u524d\u666f\u7684\u89e3\u51b3\u65b9\u6848\u3002"}}
{"id": "2512.11147", "categories": ["cs.CR", "cs.AI"], "pdf": "https://arxiv.org/pdf/2512.11147", "abs": "https://arxiv.org/abs/2512.11147", "authors": ["Jinhao Zhu", "Kevin Tseng", "Gil Vernik", "Xiao Huang", "Shishir G. Patil", "Vivian Fang", "Raluca Ada Popa"], "title": "MiniScope: A Least Privilege Framework for Authorizing Tool Calling Agents", "comment": null, "summary": "Tool calling agents are an emerging paradigm in LLM deployment, with major platforms such as ChatGPT, Claude, and Gemini adding connectors and autonomous capabilities. However, the inherent unreliability of LLMs introduces fundamental security risks when these agents operate over sensitive user services. Prior approaches either rely on manually written policies that require security expertise, or place LLMs in the confinement loop, which lacks rigorous security guarantees. We present MiniScope, a framework that enables tool calling agents to operate on user accounts while confining potential damage from unreliable LLMs. MiniScope introduces a novel way to automatically and rigorously enforce least privilege principles by reconstructing permission hierarchies that reflect relationships among tool calls and combining them with a mobile-style permission model to balance security and ease of use. To evaluate MiniScope, we create a synthetic dataset derived from ten popular real-world applications, capturing the complexity of realistic agentic tasks beyond existing simplified benchmarks. Our evaluation shows that MiniScope incurs only 1-6% latency overhead compared to vanilla tool calling agents, while significantly outperforming the LLM based baseline in minimizing permissions as well as computational and operational costs.", "AI": {"tldr": "MiniScope\u662f\u4e00\u4e2a\u5de5\u5177\u8c03\u7528\u4ee3\u7406\u5b89\u5168\u6846\u67b6\uff0c\u901a\u8fc7\u81ea\u52a8\u91cd\u6784\u6743\u9650\u5c42\u6b21\u7ed3\u6784\u548c\u79fb\u52a8\u5f0f\u6743\u9650\u6a21\u578b\uff0c\u5728\u4fdd\u8bc1\u5b89\u5168\u6027\u7684\u540c\u65f6\u6700\u5c0f\u5316\u6743\u9650\u6388\u4e88\uff0c\u4ec5\u5e26\u67651-6%\u7684\u6027\u80fd\u5f00\u9500\u3002", "motivation": "\u5f53\u524d\u5de5\u5177\u8c03\u7528\u4ee3\u7406\uff08\u5982ChatGPT\u3001Claude\u3001Gemini\uff09\u5728\u654f\u611f\u7528\u6237\u670d\u52a1\u4e0a\u8fd0\u884c\u65f6\u5b58\u5728\u5b89\u5168\u98ce\u9669\u3002\u73b0\u6709\u65b9\u6cd5\u8981\u4e48\u4f9d\u8d56\u624b\u52a8\u7f16\u5199\u7b56\u7565\u9700\u8981\u5b89\u5168\u4e13\u4e1a\u77e5\u8bc6\uff0c\u8981\u4e48\u5c06LLM\u7f6e\u4e8e\u7f3a\u4e4f\u4e25\u683c\u5b89\u5168\u4fdd\u969c\u7684\u7ea6\u675f\u5faa\u73af\u4e2d\u3002", "method": "MiniScope\u901a\u8fc7\u91cd\u6784\u5de5\u5177\u8c03\u7528\u5173\u7cfb\u7684\u6743\u9650\u5c42\u6b21\u7ed3\u6784\uff0c\u7ed3\u5408\u79fb\u52a8\u5f0f\u6743\u9650\u6a21\u578b\uff0c\u81ea\u52a8\u4e14\u4e25\u683c\u5730\u6267\u884c\u6700\u5c0f\u6743\u9650\u539f\u5219\u3002\u8be5\u65b9\u6cd5\u5e73\u8861\u4e86\u5b89\u5168\u6027\u548c\u6613\u7528\u6027\u3002", "result": "\u5728\u4ece10\u4e2a\u6d41\u884c\u771f\u5b9e\u5e94\u7528\u6784\u5efa\u7684\u5408\u6210\u6570\u636e\u96c6\u4e0a\u8bc4\u4f30\uff0cMiniScope\u76f8\u6bd4\u57fa\u7840\u5de5\u5177\u8c03\u7528\u4ee3\u7406\u4ec5\u5e26\u67651-6%\u7684\u5ef6\u8fdf\u5f00\u9500\uff0c\u540c\u65f6\u5728\u6700\u5c0f\u5316\u6743\u9650\u3001\u8ba1\u7b97\u548c\u8fd0\u8425\u6210\u672c\u65b9\u9762\u663e\u8457\u4f18\u4e8e\u57fa\u4e8eLLM\u7684\u57fa\u7ebf\u65b9\u6cd5\u3002", "conclusion": "MiniScope\u4e3a\u5de5\u5177\u8c03\u7528\u4ee3\u7406\u63d0\u4f9b\u4e86\u4e00\u4e2a\u5b89\u5168\u6846\u67b6\uff0c\u80fd\u591f\u5728\u7528\u6237\u8d26\u6237\u4e0a\u64cd\u4f5c\u65f6\u9650\u5236\u4e0d\u53ef\u9760LLM\u7684\u6f5c\u5728\u635f\u5bb3\uff0c\u5b9e\u73b0\u4e86\u5b89\u5168\u6027\u548c\u6027\u80fd\u7684\u826f\u597d\u5e73\u8861\u3002"}}
{"id": "2512.11269", "categories": ["cs.CR", "cs.AI"], "pdf": "https://arxiv.org/pdf/2512.11269", "abs": "https://arxiv.org/abs/2512.11269", "authors": ["Siddharth Jayashankar", "Joshua Kim", "Michael B. Sullivan", "Wenting Zheng", "Dimitrios Skarlatos"], "title": "A Scalable Multi-GPU Framework for Encrypted Large-Model Inference", "comment": null, "summary": "Encrypted AI using fully homomorphic encryption (FHE) provides strong privacy guarantees; but its slow performance has limited practical deployment. Recent works proposed ASICs to accelerate FHE, but require expensive advanced manufacturing processes that constrain their accessibility. GPUs are a far more accessible platform, but achieving ASIC-level performance using GPUs has remained elusive. Furthermore, state-of-the-art approaches primarily focus on small models that fit comfortably within a single device. Supporting large models such as LLMs in FHE introduces a dramatic increase in computational complexity that requires optimized GPU kernels, along with managing terabyte-scale memory footprints that far exceed the capacity of a single GPU. This paper presents Cerium, a multi-GPU framework for FHE inference on large models. Cerium integrates a domain-specific language, an optimizing compiler, and a runtime system to automatically generate high-performance GPU kernels, manage terabyte-scale memory footprints, and parallelize computation across multiple GPUs. It introduces new IR constructs, compiler passes, sparse polynomial representations, memory-efficient data layouts, and communication-aware parallelization techniques that together enable encrypted inference for models ranging from small CNNs to Llama3-8B. We build Cerium on NVIDIA GPUs and demonstrate significant performance gains. For small models, Cerium outperforms expert-written hand-optimized GPU libraries by up to 2.25 times. Cerium achieves performance competitive with state-of-the-art FHE ASICs, outright matching prior FHE ASIC CraterLake. It is the first GPU system to execute bootstrapping in under 10 milliseconds, achieving 7.5 milliseconds, and is the first to demonstrate encrypted inference for BERT-Base and Llama3-8B in 8 seconds and 134 seconds, respectively.", "AI": {"tldr": "Cerium\u662f\u4e00\u4e2a\u591aGPU\u6846\u67b6\uff0c\u7528\u4e8e\u5168\u540c\u6001\u52a0\u5bc6\uff08FHE\uff09\u7684\u5927\u6a21\u578b\u63a8\u7406\uff0c\u901a\u8fc7\u81ea\u52a8\u751f\u6210\u9ad8\u6027\u80fdGPU\u5185\u6838\u3001\u7ba1\u7406TB\u7ea7\u5185\u5b58\u548c\u591aGPU\u5e76\u884c\u5316\uff0c\u5b9e\u73b0\u4e86\u63a5\u8fd1ASIC\u7684\u6027\u80fd\uff0c\u9996\u6b21\u5728GPU\u4e0a\u5b9e\u73b0\u4e86BERT-Base\u548cLlama3-8B\u7684\u52a0\u5bc6\u63a8\u7406\u3002", "motivation": "FHE\u63d0\u4f9b\u5f3a\u9690\u79c1\u4fdd\u8bc1\u4f46\u6027\u80fd\u6162\uff0cASIC\u52a0\u901f\u65b9\u6848\u6210\u672c\u9ad8\u4e14\u96be\u4ee5\u666e\u53ca\uff0cGPU\u66f4\u6613\u83b7\u53d6\u4f46\u96be\u4ee5\u8fbe\u5230ASIC\u7ea7\u6027\u80fd\u3002\u73b0\u6709\u65b9\u6cd5\u4e3b\u8981\u9488\u5bf9\u5c0f\u6a21\u578b\uff0c\u5927\u6a21\u578b\uff08\u5982LLM\uff09\u7684FHE\u63a8\u7406\u9700\u8981TB\u7ea7\u5185\u5b58\u7ba1\u7406\u548c\u591aGPU\u5e76\u884c\u5316\uff0c\u8fd9\u662f\u5f53\u524dGPU\u5e73\u53f0\u9762\u4e34\u7684\u6311\u6218\u3002", "method": "Cerium\u96c6\u6210\u4e86\u9886\u57df\u7279\u5b9a\u8bed\u8a00\u3001\u4f18\u5316\u7f16\u8bd1\u5668\u548c\u8fd0\u884c\u65f6\u7cfb\u7edf\uff0c\u5305\u542b\u65b0\u7684IR\u6784\u9020\u3001\u7f16\u8bd1\u5668\u4f20\u9012\u3001\u7a00\u758f\u591a\u9879\u5f0f\u8868\u793a\u3001\u5185\u5b58\u9ad8\u6548\u6570\u636e\u5e03\u5c40\u548c\u901a\u4fe1\u611f\u77e5\u5e76\u884c\u5316\u6280\u672f\uff0c\u81ea\u52a8\u751f\u6210\u9ad8\u6027\u80fdGPU\u5185\u6838\uff0c\u7ba1\u7406TB\u7ea7\u5185\u5b58\uff0c\u5e76\u5728\u591aGPU\u95f4\u5e76\u884c\u5316\u8ba1\u7b97\u3002", "result": "\u5c0f\u6a21\u578b\u6027\u80fd\u6bd4\u4e13\u5bb6\u624b\u5199GPU\u5e93\u5feb2.25\u500d\uff1b\u6027\u80fd\u4e0e\u6700\u5148\u8fdbFHE ASIC\u7ade\u4e89\uff0c\u5339\u914dCraterLake ASIC\uff1b\u9996\u6b21\u5728GPU\u4e0a\u5b9e\u73b010\u6beb\u79d2\u4ee5\u4e0b\u7684\u5f15\u5bfc\uff087.5\u6beb\u79d2\uff09\uff1b\u9996\u6b21\u5b9e\u73b0BERT-Base\uff088\u79d2\uff09\u548cLlama3-8B\uff08134\u79d2\uff09\u7684\u52a0\u5bc6\u63a8\u7406\u3002", "conclusion": "Cerium\u8bc1\u660e\u4e86GPU\u5e73\u53f0\u80fd\u591f\u5b9e\u73b0\u63a5\u8fd1ASIC\u6027\u80fd\u7684FHE\u63a8\u7406\uff0c\u652f\u6301\u4eceCNN\u5230Llama3-8B\u7684\u5404\u79cd\u89c4\u6a21\u6a21\u578b\uff0c\u4e3a\u52a0\u5bc6AI\u7684\u5b9e\u9645\u90e8\u7f72\u63d0\u4f9b\u4e86\u66f4\u6613\u83b7\u53d6\u7684\u9ad8\u6027\u80fd\u89e3\u51b3\u65b9\u6848\u3002"}}
{"id": "2512.11272", "categories": ["cs.CR"], "pdf": "https://arxiv.org/pdf/2512.11272", "abs": "https://arxiv.org/abs/2512.11272", "authors": ["Do Hai Son", "Le Vu Hieu", "Tran Viet Khoa", "Yibeltal F. Alem", "Hoang Trong Minh", "Tran Thi Thuy Quynh", "Nguyen Viet Ha", "Nguyen Linh Trung"], "title": "Vision-Based Learning for Cyberattack Detection in Blockchain Smart Contracts and Transactions", "comment": null, "summary": "Blockchain technology has experienced rapid growth and has been widely adopted across various sectors, including healthcare, finance, and energy. However, blockchain platforms remain vulnerable to a broad range of cyberattacks, particularly those aimed at exploiting transactions and smart contracts (SCs) to steal digital assets or compromise system integrity. To address this issue, we propose a novel and effective framework for detecting cyberattacks within blockchain systems. Our framework begins with a preprocessing tool that uses Natural Language Processing (NLP) techniques to transform key features of blockchain transactions into image representations. These images are then analyzed through vision-based analysis using Vision Transformers (ViT), a recent advancement in computer vision known for its superior ability to capture complex patterns and semantic relationships. By integrating NLP-based preprocessing with vision-based learning, our framework can detect a wide variety of attack types. Experimental evaluations on benchmark datasets demonstrate that our approach significantly outperforms existing state-of-the-art methods in terms of both accuracy (achieving 99.5%) and robustness in cyberattack detection for blockchain transactions and SCs.", "AI": {"tldr": "\u63d0\u51fa\u7ed3\u5408NLP\u548c\u89c6\u89c9Transformer\u7684\u533a\u5757\u94fe\u653b\u51fb\u68c0\u6d4b\u6846\u67b6\uff0c\u5c06\u4ea4\u6613\u7279\u5f81\u8f6c\u6362\u4e3a\u56fe\u50cf\uff0c\u901a\u8fc7ViT\u5206\u6790\uff0c\u5728\u57fa\u51c6\u6570\u636e\u96c6\u4e0a\u8fbe\u523099.5%\u51c6\u786e\u7387\u3002", "motivation": "\u533a\u5757\u94fe\u6280\u672f\u5728\u5404\u884c\u4e1a\u5e7f\u6cdb\u5e94\u7528\uff0c\u4f46\u5e73\u53f0\u6613\u53d7\u9488\u5bf9\u4ea4\u6613\u548c\u667a\u80fd\u5408\u7ea6\u7684\u7f51\u7edc\u653b\u51fb\uff0c\u5bfc\u81f4\u6570\u5b57\u8d44\u4ea7\u88ab\u76d7\u6216\u7cfb\u7edf\u5b8c\u6574\u6027\u53d7\u635f\uff0c\u9700\u8981\u6709\u6548\u7684\u653b\u51fb\u68c0\u6d4b\u65b9\u6848\u3002", "method": "1. \u4f7f\u7528NLP\u6280\u672f\u9884\u5904\u7406\u533a\u5757\u94fe\u4ea4\u6613\u5173\u952e\u7279\u5f81\uff0c\u5c06\u5176\u8f6c\u6362\u4e3a\u56fe\u50cf\u8868\u793a\uff1b2. \u91c7\u7528Vision Transformer\uff08ViT\uff09\u8fdb\u884c\u89c6\u89c9\u5206\u6790\uff0c\u5229\u7528\u5176\u6355\u6349\u590d\u6742\u6a21\u5f0f\u548c\u8bed\u4e49\u5173\u7cfb\u7684\u80fd\u529b\uff1b3. \u7ed3\u5408NLP\u9884\u5904\u7406\u548c\u89c6\u89c9\u5b66\u4e60\uff0c\u6784\u5efa\u653b\u51fb\u68c0\u6d4b\u6846\u67b6\u3002", "result": "\u5728\u57fa\u51c6\u6570\u636e\u96c6\u4e0a\u7684\u5b9e\u9a8c\u8bc4\u4f30\u663e\u793a\uff0c\u8be5\u65b9\u6cd5\u5728\u51c6\u786e\u7387\uff0899.5%\uff09\u548c\u9c81\u68d2\u6027\u65b9\u9762\u663e\u8457\u4f18\u4e8e\u73b0\u6709\u6700\u5148\u8fdb\u65b9\u6cd5\uff0c\u80fd\u6709\u6548\u68c0\u6d4b\u591a\u79cd\u533a\u5757\u94fe\u653b\u51fb\u7c7b\u578b\u3002", "conclusion": "\u63d0\u51fa\u7684NLP-ViT\u96c6\u6210\u6846\u67b6\u4e3a\u533a\u5757\u94fe\u7cfb\u7edf\u63d0\u4f9b\u4e86\u4e00\u79cd\u65b0\u9896\u6709\u6548\u7684\u7f51\u7edc\u653b\u51fb\u68c0\u6d4b\u65b9\u6848\uff0c\u901a\u8fc7\u5c06\u4ea4\u6613\u7279\u5f81\u8f6c\u6362\u4e3a\u56fe\u50cf\u5e76\u5229\u7528\u89c6\u89c9Transformer\u5206\u6790\uff0c\u5b9e\u73b0\u4e86\u9ad8\u7cbe\u5ea6\u548c\u9c81\u68d2\u7684\u653b\u51fb\u68c0\u6d4b\u3002"}}
{"id": "2512.11316", "categories": ["cs.CR", "cs.SE"], "pdf": "https://arxiv.org/pdf/2512.11316", "abs": "https://arxiv.org/abs/2512.11316", "authors": ["Zhenshuo Zhao", "Maria Spichkova", "Duttkumari Champavat", "Juilee N. Kulkarni", "Sahil Singla", "Muhammad A. Zulkefli", "Pradhuman Khandelwal"], "title": "Visualisation for the CIS benchmark scanning results", "comment": "Preprint. Accepted to the ICICT'26. Final version to be published by in conference proceedings by Springer LNNS", "summary": "In this paper, we introduce GraphSecure, a web application that provides advanced analysis and visualisation of security scanning results. GraphSecure enables users to initiate scans for their AWS account, validate them against specific Center for Internet Security (CIS) Benchmarks and return results, showcase those returned results in the form of statistical charts and warn the users about their account status.", "AI": {"tldr": "GraphSecure\u662f\u4e00\u4e2a\u7528\u4e8e\u5206\u6790\u548c\u53ef\u89c6\u5316AWS\u5b89\u5168\u626b\u63cf\u7ed3\u679c\u7684Web\u5e94\u7528\uff0c\u652f\u6301CIS\u57fa\u51c6\u9a8c\u8bc1\u5e76\u63d0\u4f9b\u7edf\u8ba1\u56fe\u8868\u5c55\u793a", "motivation": "\u89e3\u51b3AWS\u8d26\u6237\u5b89\u5168\u626b\u63cf\u7ed3\u679c\u5206\u6790\u548c\u53ef\u89c6\u5316\u4e0d\u8db3\u7684\u95ee\u9898\uff0c\u5e2e\u52a9\u7528\u6237\u66f4\u597d\u5730\u7406\u89e3\u548c\u8bc4\u4f30\u5176\u4e91\u5b89\u5168\u72b6\u51b5", "method": "\u5f00\u53d1Web\u5e94\u7528\u7a0b\u5e8f\uff0c\u96c6\u6210AWS\u626b\u63cf\u529f\u80fd\uff0c\u5b9e\u73b0CIS\u57fa\u51c6\u9a8c\u8bc1\uff0c\u521b\u5efa\u7edf\u8ba1\u56fe\u8868\u548c\u544a\u8b66\u7cfb\u7edf", "result": "\u6210\u529f\u6784\u5efa\u4e86GraphSecure\u7cfb\u7edf\uff0c\u80fd\u591f\u626b\u63cfAWS\u8d26\u6237\u3001\u9a8c\u8bc1CIS\u5408\u89c4\u6027\u3001\u53ef\u89c6\u5316\u626b\u63cf\u7ed3\u679c\u5e76\u63d0\u4f9b\u8d26\u6237\u72b6\u6001\u544a\u8b66", "conclusion": "GraphSecure\u4e3aAWS\u5b89\u5168\u76d1\u63a7\u63d0\u4f9b\u4e86\u6709\u6548\u7684\u5206\u6790\u548c\u53ef\u89c6\u5316\u5de5\u5177\uff0c\u5e2e\u52a9\u7528\u6237\u63d0\u5347\u4e91\u5b89\u5168\u7ba1\u7406\u548c\u5408\u89c4\u6027\u8bc4\u4f30\u80fd\u529b"}}
{"id": "2512.11431", "categories": ["cs.CR", "cs.FL", "cs.NI"], "pdf": "https://arxiv.org/pdf/2512.11431", "abs": "https://arxiv.org/abs/2512.11431", "authors": ["Qifan Zhang", "Zilin Shen", "Imtiaz Karim", "Elisa Bertino", "Zhou Li"], "title": "Proving DNSSEC Correctness: A Formal Approach to Secure Domain Name Resolution", "comment": null, "summary": "The Domain Name System Security Extensions (DNSSEC) are critical for preventing DNS spoofing, yet its specifications contain ambiguities and vulnerabilities that elude traditional \"break-and-fix\" approaches. A holistic, foundational security analysis of the protocol has thus remained an open problem. This paper introduces DNSSECVerif, the first framework for comprehensive, automated formal security analysis of the DNSSEC protocol suite. Built on the SAPIC+ symbolic verifier, our high-fidelity model captures protocol-level interactions, including cryptographic operations and stateful caching with fine-grained concurrency control. Using DNSSECVerif, we formally prove four of DNSSEC's core security guarantees and uncover critical ambiguities in the standards--notably, the insecure coexistence of NSEC and NSEC3. Our model also automatically rediscovers three classes of known attacks, demonstrating fundamental weaknesses in the protocol design. To bridge the model-to-reality gap, we validate our findings through targeted testing of mainstream DNS software and a large-scale measurement study of over 2.2 million open resolvers, confirming the real-world impact of these flaws. Our work provides crucial, evidence-based recommendations for hardening DNSSEC specifications and implementations.", "AI": {"tldr": "DNSSECVerif\u662f\u9996\u4e2a\u7528\u4e8eDNSSEC\u534f\u8bae\u5957\u4ef6\u5168\u9762\u81ea\u52a8\u5316\u5f62\u5f0f\u5b89\u5168\u5206\u6790\u7684\u6846\u67b6\uff0c\u901a\u8fc7\u5f62\u5f0f\u5316\u9a8c\u8bc1\u53d1\u73b0\u4e86\u534f\u8bae\u8bbe\u8ba1\u4e2d\u7684\u6839\u672c\u6027\u5f31\u70b9\uff0c\u5305\u62ecNSEC\u548cNSEC3\u7684\u4e0d\u5b89\u5168\u5171\u5b58\u95ee\u9898\uff0c\u5e76\u901a\u8fc7\u5927\u89c4\u6a21\u6d4b\u91cf\u7814\u7a76\u786e\u8ba4\u4e86\u8fd9\u4e9b\u6f0f\u6d1e\u7684\u73b0\u5b9e\u5f71\u54cd\u3002", "motivation": "DNSSEC\u5bf9\u4e8e\u9632\u6b62DNS\u6b3a\u9a97\u81f3\u5173\u91cd\u8981\uff0c\u4f46\u5176\u89c4\u8303\u5b58\u5728\u6a21\u7cca\u6027\u548c\u6f0f\u6d1e\uff0c\u4f20\u7edf\"\u7834\u574f-\u4fee\u590d\"\u65b9\u6cd5\u96be\u4ee5\u53d1\u73b0\u3002\u5bf9\u534f\u8bae\u8fdb\u884c\u5168\u9762\u3001\u57fa\u7840\u6027\u7684\u5b89\u5168\u5206\u6790\u4e00\u76f4\u662f\u4e00\u4e2a\u5f00\u653e\u6027\u95ee\u9898\u3002", "method": "\u57fa\u4e8eSAPIC+\u7b26\u53f7\u9a8c\u8bc1\u5668\u6784\u5efaDNSSECVerif\u6846\u67b6\uff0c\u5efa\u7acb\u9ad8\u4fdd\u771f\u6a21\u578b\u6355\u83b7\u534f\u8bae\u7ea7\u4ea4\u4e92\uff0c\u5305\u62ec\u52a0\u5bc6\u64cd\u4f5c\u548c\u5177\u6709\u7ec6\u7c92\u5ea6\u5e76\u53d1\u63a7\u5236\u7684\u72b6\u6001\u7f13\u5b58\u3002\u901a\u8fc7\u5f62\u5f0f\u5316\u9a8c\u8bc1\u8bc1\u660e\u5b89\u5168\u4fdd\u8bc1\u5e76\u53d1\u73b0\u6f0f\u6d1e\uff0c\u6700\u540e\u901a\u8fc7\u4e3b\u6d41DNS\u8f6f\u4ef6\u6d4b\u8bd5\u548c\u5bf9220\u591a\u4e07\u4e2a\u5f00\u653e\u89e3\u6790\u5668\u7684\u5927\u89c4\u6a21\u6d4b\u91cf\u7814\u7a76\u9a8c\u8bc1\u53d1\u73b0\u3002", "result": "\u5f62\u5f0f\u5316\u8bc1\u660e\u4e86DNSSEC\u7684\u56db\u4e2a\u6838\u5fc3\u5b89\u5168\u4fdd\u8bc1\uff0c\u53d1\u73b0\u4e86\u6807\u51c6\u4e2d\u7684\u5173\u952e\u6a21\u7cca\u6027\uff08\u7279\u522b\u662fNSEC\u548cNSEC3\u7684\u4e0d\u5b89\u5168\u5171\u5b58\uff09\uff0c\u81ea\u52a8\u91cd\u65b0\u53d1\u73b0\u4e86\u4e09\u7c7b\u5df2\u77e5\u653b\u51fb\uff0c\u5c55\u793a\u4e86\u534f\u8bae\u8bbe\u8ba1\u7684\u6839\u672c\u5f31\u70b9\u3002\u5927\u89c4\u6a21\u6d4b\u91cf\u786e\u8ba4\u4e86\u8fd9\u4e9b\u6f0f\u6d1e\u5728\u73b0\u5b9e\u4e16\u754c\u4e2d\u7684\u5f71\u54cd\u3002", "conclusion": "\u8fd9\u9879\u5de5\u4f5c\u4e3a\u5f3a\u5316DNSSEC\u89c4\u8303\u548c\u5b9e\u73b0\u63d0\u4f9b\u4e86\u5173\u952e\u3001\u57fa\u4e8e\u8bc1\u636e\u7684\u5efa\u8bae\uff0c\u586b\u8865\u4e86DNSSEC\u5168\u9762\u5f62\u5f0f\u5316\u5b89\u5168\u5206\u6790\u7684\u7a7a\u767d\uff0c\u63ed\u793a\u4e86\u534f\u8bae\u8bbe\u8ba1\u4e2d\u7684\u6839\u672c\u6027\u5b89\u5168\u95ee\u9898\u3002"}}
{"id": "2512.11484", "categories": ["cs.CR"], "pdf": "https://arxiv.org/pdf/2512.11484", "abs": "https://arxiv.org/abs/2512.11484", "authors": ["Yukun Cheng", "Shiyu Zhu", "Changhai Ou", "Xingshuo Han", "Yuan Li", "Shihui Zheng"], "title": "Capacitive Touchscreens at Risk: Recovering Handwritten Trajectory on Smartphone via Electromagnetic Emanations", "comment": null, "summary": "This paper reveals and exploits a critical security vulnerability: the electromagnetic (EM) side channel of capacitive touchscreens leaks sufficient information to recover fine-grained, continuous handwriting trajectories. We present Touchscreen Electromagnetic Side-channel Leakage Attack (TESLA), a non-contact attack framework that captures EM signals generated during on-screen writing and regresses them into two-dimensional (2D) handwriting trajectories in real time. Extensive evaluations across a variety of commercial off-the-shelf (COTS) smartphones show that TESLA achieves 77% character recognition accuracy and a Jaccard index of 0.74, demonstrating its capability to recover highly recognizable motion trajectories that closely resemble the original handwriting under realistic attack conditions.", "AI": {"tldr": "TESLA\u653b\u51fb\u5229\u7528\u7535\u5bb9\u89e6\u6478\u5c4f\u7684\u7535\u78c1\u4fa7\u4fe1\u9053\u6cc4\u9732\uff0c\u901a\u8fc7\u975e\u63a5\u89e6\u65b9\u5f0f\u6355\u83b7\u4e66\u5199\u65f6\u7684\u7535\u78c1\u4fe1\u53f7\uff0c\u5b9e\u65f6\u6062\u590d\u51fa\u624b\u5199\u8f68\u8ff9\uff0c\u5728\u5546\u7528\u624b\u673a\u4e0a\u8fbe\u523077%\u7684\u5b57\u7b26\u8bc6\u522b\u51c6\u786e\u7387\u3002", "motivation": "\u63ed\u793a\u7535\u5bb9\u89e6\u6478\u5c4f\u5b58\u5728\u4e25\u91cd\u7684\u7535\u78c1\u4fa7\u4fe1\u9053\u5b89\u5168\u6f0f\u6d1e\uff0c\u653b\u51fb\u8005\u65e0\u9700\u7269\u7406\u63a5\u89e6\u5373\u53ef\u7a83\u53d6\u7528\u6237\u5728\u89e6\u6478\u5c4f\u4e0a\u7684\u624b\u5199\u8f93\u5165\u4fe1\u606f\uff0c\u8fd9\u5bf9\u9690\u79c1\u548c\u5b89\u5168\u6784\u6210\u91cd\u5927\u5a01\u80c1\u3002", "method": "\u63d0\u51faTESLA\u653b\u51fb\u6846\u67b6\uff1a1\uff09\u6355\u83b7\u89e6\u6478\u5c4f\u4e66\u5199\u65f6\u4ea7\u751f\u7684\u7535\u78c1\u4fe1\u53f7\uff1b2\uff09\u901a\u8fc7\u56de\u5f52\u5206\u6790\u5c06\u7535\u78c1\u4fe1\u53f7\u8f6c\u6362\u4e3a\u4e8c\u7ef4\u624b\u5199\u8f68\u8ff9\uff1b3\uff09\u5b9e\u65f6\u5904\u7406\u5b9e\u73b0\u653b\u51fb\u3002", "result": "\u5728\u591a\u79cd\u5546\u7528\u667a\u80fd\u624b\u673a\u4e0a\u7684\u5e7f\u6cdb\u8bc4\u4f30\u663e\u793a\uff1a\u5b57\u7b26\u8bc6\u522b\u51c6\u786e\u7387\u8fbe\u523077%\uff0cJaccard\u6307\u6570\u4e3a0.74\uff0c\u80fd\u591f\u6062\u590d\u51fa\u9ad8\u5ea6\u53ef\u8bc6\u522b\u4e14\u63a5\u8fd1\u539f\u59cb\u7b14\u8ff9\u7684\u8fd0\u52a8\u8f68\u8ff9\u3002", "conclusion": "\u7535\u5bb9\u89e6\u6478\u5c4f\u7684\u7535\u78c1\u4fa7\u4fe1\u9053\u6cc4\u9732\u4e25\u91cd\u5b89\u5168\u6f0f\u6d1e\uff0cTESLA\u653b\u51fb\u8bc1\u660e\u653b\u51fb\u8005\u80fd\u591f\u975e\u63a5\u89e6\u5730\u6062\u590d\u7cbe\u7ec6\u624b\u5199\u8f68\u8ff9\uff0c\u9700\u8981\u65b0\u7684\u5b89\u5168\u9632\u62a4\u63aa\u65bd\u6765\u5e94\u5bf9\u6b64\u7c7b\u5a01\u80c1\u3002"}}
{"id": "2512.11602", "categories": ["cs.CR"], "pdf": "https://arxiv.org/pdf/2512.11602", "abs": "https://arxiv.org/abs/2512.11602", "authors": ["Mojtaba Moazen", "Amir. M Ahmadian", "Musard Balliu"], "title": "Granite: Granular Runtime Enforcement for GitHub Actions Permissions", "comment": "13 pages, abstract compacted for arxiv", "summary": "Modern software projects use automated CI/CD pipelines to streamline their development, build, and deployment processes. GitHub Actions is a popular CI/CD platform that enables project maintainers to create custom workflows -- collections of jobs composed of sequential steps -- using reusable components known as actions. Wary of the security risks introduced by fully-privileged actions, GitHub provides a job-level permission model for controlling workflow access to repository resources. Unfortunately, this model is too coarse-grained to reduce the attack surface pertaining to permission misuse attacks: All actions within a job share the same permissions granted to the job. This violates the principle of least privilege and can lead to broader software supply chain attacks, whenever a compromised action exploits the granted permissions to compromise the repository resources. In this paper, we present Granite, a runtime proxy-based system that enforces fine-grained permissions for GitHub Actions at the step-level granularity within a job. Granite transparently monitors requests made by JavaScript and composite actions during workflow execution and checks them against predefined step-level policies at runtime. We evaluate Granite in terms of compatibility, security, and performance overhead using a dataset of 500 workflows comprising 12,916 jobs from the most-starred GitHub repositories that use GitHub Actions. Our analysis reveals that 52.7% of the jobs can be protected by Granite against permission misuse attacks. We evaluate Granite on 20 top-starred repositories (63 actions, 58 workflows), validate attack prevention using 10 permission misuse attacks across 42 overprivileged jobs, and measure an average overhead of 55% (3.67 seconds) per job, concluding that Granite effectively reduces CI/CD attack surfaces.", "AI": {"tldr": "Granite\u662f\u4e00\u4e2a\u8fd0\u884c\u65f6\u4ee3\u7406\u7cfb\u7edf\uff0c\u4e3aGitHub Actions\u63d0\u4f9b\u7ec6\u7c92\u5ea6\u7684\u6b65\u9aa4\u7ea7\u6743\u9650\u63a7\u5236\uff0c\u9632\u6b62\u6743\u9650\u6ee5\u7528\u653b\u51fb\uff0c\u51cf\u5c11CI/CD\u653b\u51fb\u9762\u3002", "motivation": "GitHub Actions\u73b0\u6709\u7684\u4f5c\u4e1a\u7ea7\u6743\u9650\u6a21\u578b\u8fc7\u4e8e\u7c97\u7c92\u5ea6\uff0c\u8fdd\u53cd\u6700\u5c0f\u6743\u9650\u539f\u5219\uff0c\u5bfc\u81f4\u6743\u9650\u6ee5\u7528\u653b\u51fb\u98ce\u9669\uff0c\u53ef\u80fd\u5f15\u53d1\u66f4\u5e7f\u6cdb\u7684\u8f6f\u4ef6\u4f9b\u5e94\u94fe\u653b\u51fb\u3002", "method": "Granite\u91c7\u7528\u8fd0\u884c\u65f6\u4ee3\u7406\u67b6\u6784\uff0c\u900f\u660e\u76d1\u63a7JavaScript\u548c\u590d\u5408\u52a8\u4f5c\u7684\u8bf7\u6c42\uff0c\u6839\u636e\u9884\u5b9a\u4e49\u7684\u6b65\u9aa4\u7ea7\u7b56\u7565\u8fdb\u884c\u8fd0\u884c\u65f6\u68c0\u67e5\u3002", "result": "\u8bc4\u4f30\u663e\u793a52.7%\u7684\u4f5c\u4e1a\u53ef\u901a\u8fc7Granite\u5f97\u5230\u4fdd\u62a4\uff1b\u572820\u4e2a\u9876\u7ea7\u4ed3\u5e93\u6d4b\u8bd5\u4e2d\uff0c\u6210\u529f\u9884\u9632\u4e8610\u79cd\u6743\u9650\u6ee5\u7528\u653b\u51fb\uff0c\u5e73\u5747\u6bcf\u4e2a\u4f5c\u4e1a\u589e\u52a055%\uff083.67\u79d2\uff09\u7684\u5f00\u9500\u3002", "conclusion": "Granite\u80fd\u6709\u6548\u51cf\u5c11CI/CD\u653b\u51fb\u9762\uff0c\u901a\u8fc7\u7ec6\u7c92\u5ea6\u7684\u6b65\u9aa4\u7ea7\u6743\u9650\u63a7\u5236\u589e\u5f3aGitHub Actions\u7684\u5b89\u5168\u6027\u3002"}}
{"id": "2512.11690", "categories": ["cs.CR", "cs.AR"], "pdf": "https://arxiv.org/pdf/2512.11690", "abs": "https://arxiv.org/abs/2512.11690", "authors": ["Grant Bosworth", "Keewoo Lee", "Sunwoong Kim"], "title": "Leveraging FPGAs for Homomorphic Matrix-Vector Multiplication in Oblivious Message Retrieval", "comment": null, "summary": "While end-to-end encryption protects the content of messages, it does not secure metadata, which exposes sender and receiver information through traffic analysis. A plausible approach to protecting this metadata is to have senders post encrypted messages on a public bulletin board and receivers scan it for relevant messages. Oblivious message retrieval (OMR) leverages homomorphic encryption (HE) to improve user experience in this solution by delegating the scan to a resource-rich server while preserving privacy. A key process in OMR is the homomorphic detection of pertinent messages for the receiver from the bulletin board. It relies on a specialized matrix-vector multiplication algorithm, which involves extensive multiplications between ciphertext vectors and plaintext matrices, as well as homomorphic rotations. The computationally intensive nature of this process limits the practicality of OMR. To address this challenge, this paper proposes a hardware architecture to accelerate the matrix-vector multiplication algorithm. The building homomorphic operators in this algorithm are implemented using high-level synthesis, with design parameters for different parallelism levels. These operators are then deployed on a field-programmable gate array platform using an efficient design space exploration strategy to accelerate homomorphic matrix-vector multiplication. Compared to a software implementation, the proposed hardware accelerator achieves a 13.86x speedup.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u786c\u4ef6\u67b6\u6784\u6765\u52a0\u901fOblivious Message Retrieval\u4e2d\u7684\u540c\u6001\u77e9\u9635\u5411\u91cf\u4e58\u6cd5\uff0c\u76f8\u6bd4\u8f6f\u4ef6\u5b9e\u73b0\u83b7\u5f9713.86\u500d\u52a0\u901f", "motivation": "\u7aef\u5230\u7aef\u52a0\u5bc6\u4fdd\u62a4\u6d88\u606f\u5185\u5bb9\u4f46\u4e0d\u4fdd\u62a4\u5143\u6570\u636e\uff0cOblivious Message Retrieval\u4f7f\u7528\u540c\u6001\u52a0\u5bc6\u6765\u4fdd\u62a4\u5143\u6570\u636e\u9690\u79c1\uff0c\u4f46\u5176\u6838\u5fc3\u7684\u540c\u6001\u77e9\u9635\u5411\u91cf\u4e58\u6cd5\u8ba1\u7b97\u5bc6\u96c6\uff0c\u9650\u5236\u4e86\u5b9e\u9645\u5e94\u7528", "method": "\u63d0\u51fa\u786c\u4ef6\u67b6\u6784\u52a0\u901f\u540c\u6001\u77e9\u9635\u5411\u91cf\u4e58\u6cd5\u7b97\u6cd5\uff0c\u4f7f\u7528\u9ad8\u5c42\u6b21\u7efc\u5408\u5b9e\u73b0\u540c\u6001\u7b97\u5b50\uff0c\u8bbe\u8ba1\u4e0d\u540c\u5e76\u884c\u5ea6\u53c2\u6570\uff0c\u5728FPGA\u5e73\u53f0\u4e0a\u91c7\u7528\u9ad8\u6548\u8bbe\u8ba1\u7a7a\u95f4\u63a2\u7d22\u7b56\u7565\u90e8\u7f72", "result": "\u76f8\u6bd4\u8f6f\u4ef6\u5b9e\u73b0\uff0c\u63d0\u51fa\u7684\u786c\u4ef6\u52a0\u901f\u5668\u5b9e\u73b0\u4e8613.86\u500d\u7684\u52a0\u901f", "conclusion": "\u786c\u4ef6\u52a0\u901f\u663e\u8457\u63d0\u5347\u4e86Oblivious Message Retrieval\u4e2d\u540c\u6001\u77e9\u9635\u5411\u91cf\u4e58\u6cd5\u7684\u6027\u80fd\uff0c\u4f7f\u5176\u66f4\u5177\u5b9e\u7528\u6027"}}
{"id": "2512.11699", "categories": ["cs.CR"], "pdf": "https://arxiv.org/pdf/2512.11699", "abs": "https://arxiv.org/abs/2512.11699", "authors": ["Roberta De Viti", "Vaastav Anand", "Pierfrancesco Ingo", "Deepak Garg"], "title": "SoK: Demystifying the multiverse of MPC protocols", "comment": null, "summary": "This paper systematizes knowledge on the performance of Multi-Party Computation (MPC) protocols. Despite strong privacy and correctness guarantees, MPC adoption in real-world applications remains limited by high costs (especially in the malicious setting) and lack of guidance on choosing suitable protocols for concrete workloads. We identify the theoretical and practical parameters that shape MPC efficiency and conduct an extensive experimental study across diverse benchmarks. Our analysis discusses the trade-offs between protocols, and highlights which techniques align best with different application scenarios and needs. By providing actionable guidance for developers and outlining open challenges for researchers, this work seeks to narrow the gap between MPC theory and practice.", "AI": {"tldr": "\u8be5\u8bba\u6587\u7cfb\u7edf\u5316\u7814\u7a76\u4e86\u591a\u65b9\u8ba1\u7b97(MPC)\u534f\u8bae\u7684\u6027\u80fd\uff0c\u901a\u8fc7\u7406\u8bba\u5206\u6790\u548c\u5927\u91cf\u5b9e\u9a8c\u8bc4\u4f30\u4e0d\u540c\u534f\u8bae\u7684\u6548\u7387\uff0c\u4e3a\u5f00\u53d1\u8005\u63d0\u4f9b\u5b9e\u7528\u6307\u5bfc\uff0c\u65e8\u5728\u7f29\u5c0fMPC\u7406\u8bba\u4e0e\u5b9e\u8df5\u7684\u5dee\u8ddd\u3002", "motivation": "\u5c3d\u7ba1MPC\u5177\u6709\u5f3a\u5927\u7684\u9690\u79c1\u548c\u6b63\u786e\u6027\u4fdd\u8bc1\uff0c\u4f46\u5728\u5b9e\u9645\u5e94\u7528\u4e2d\u91c7\u7528\u4ecd\u7136\u6709\u9650\uff0c\u4e3b\u8981\u539f\u56e0\u662f\u6076\u610f\u8bbe\u7f6e\u4e0b\u7684\u9ad8\u6210\u672c\u548c\u7f3a\u4e4f\u9488\u5bf9\u5177\u4f53\u5de5\u4f5c\u8d1f\u8f7d\u9009\u62e9\u5408\u9002\u534f\u8bae\u7684\u6307\u5bfc\u3002", "method": "\u8bc6\u522b\u5f71\u54cdMPC\u6548\u7387\u7684\u7406\u8bba\u548c\u5b9e\u8df5\u53c2\u6570\uff0c\u8fdb\u884c\u8de8\u591a\u6837\u5316\u57fa\u51c6\u6d4b\u8bd5\u7684\u5e7f\u6cdb\u5b9e\u9a8c\u7814\u7a76\uff0c\u5206\u6790\u4e0d\u540c\u534f\u8bae\u4e4b\u95f4\u7684\u6743\u8861\u3002", "result": "\u5206\u6790\u8ba8\u8bba\u4e86\u4e0d\u540c\u534f\u8bae\u4e4b\u95f4\u7684\u6743\u8861\uff0c\u5e76\u7a81\u51fa\u4e86\u54ea\u4e9b\u6280\u672f\u6700\u9002\u5408\u4e0d\u540c\u7684\u5e94\u7528\u573a\u666f\u548c\u9700\u6c42\u3002", "conclusion": "\u901a\u8fc7\u4e3a\u5f00\u53d1\u8005\u63d0\u4f9b\u53ef\u64cd\u4f5c\u7684\u6307\u5bfc\u5e76\u4e3a\u7814\u7a76\u4eba\u5458\u6982\u8ff0\u5f00\u653e\u6311\u6218\uff0c\u8fd9\u9879\u5de5\u4f5c\u65e8\u5728\u7f29\u5c0fMPC\u7406\u8bba\u4e0e\u5b9e\u8df5\u7684\u5dee\u8ddd\u3002"}}
{"id": "2512.11783", "categories": ["cs.CR", "cs.AI"], "pdf": "https://arxiv.org/pdf/2512.11783", "abs": "https://arxiv.org/abs/2512.11783", "authors": ["Andrew Adiletta", "Kathryn Adiletta", "Kemal Derya", "Berk Sunar"], "title": "Super Suffixes: Bypassing Text Generation Alignment and Guard Models Simultaneously", "comment": "13 pages, 5 Figures", "summary": "The rapid deployment of Large Language Models (LLMs) has created an urgent need for enhanced security and privacy measures in Machine Learning (ML). LLMs are increasingly being used to process untrusted text inputs and even generate executable code, often while having access to sensitive system controls. To address these security concerns, several companies have introduced guard models, which are smaller, specialized models designed to protect text generation models from adversarial or malicious inputs. In this work, we advance the study of adversarial inputs by introducing Super Suffixes, suffixes capable of overriding multiple alignment objectives across various models with different tokenization schemes. We demonstrate their effectiveness, along with our joint optimization technique, by successfully bypassing the protection mechanisms of Llama Prompt Guard 2 on five different text generation models for malicious text and code generation. To the best of our knowledge, this is the first work to reveal that Llama Prompt Guard 2 can be compromised through joint optimization.\n  Additionally, by analyzing the changing similarity of a model's internal state to specific concept directions during token sequence processing, we propose an effective and lightweight method to detect Super Suffix attacks. We show that the cosine similarity between the residual stream and certain concept directions serves as a distinctive fingerprint of model intent. Our proposed countermeasure, DeltaGuard, significantly improves the detection of malicious prompts generated through Super Suffixes. It increases the non-benign classification rate to nearly 100%, making DeltaGuard a valuable addition to the guard model stack and enhancing robustness against adversarial prompt attacks.", "AI": {"tldr": "\u672c\u6587\u63d0\u51faSuper Suffixes\u653b\u51fb\u65b9\u6cd5\uff0c\u53ef\u7ed5\u8fc7Llama Prompt Guard 2\u7b49\u9632\u62a4\u6a21\u578b\uff0c\u5e76\u5f00\u53d1DeltaGuard\u68c0\u6d4b\u65b9\u6cd5\u6765\u9632\u5fa1\u6b64\u7c7b\u653b\u51fb\u3002", "motivation": "\u968f\u7740\u5927\u8bed\u8a00\u6a21\u578b\uff08LLMs\uff09\u7684\u5e7f\u6cdb\u90e8\u7f72\uff0c\u5904\u7406\u4e0d\u53ef\u4fe1\u6587\u672c\u8f93\u5165\u548c\u6267\u884c\u4ee3\u7801\u751f\u6210\u65f6\u9762\u4e34\u5b89\u5168\u9690\u79c1\u98ce\u9669\u3002\u73b0\u6709\u9632\u62a4\u6a21\u578b\uff08\u5982Llama Prompt Guard 2\uff09\u5b58\u5728\u88ab\u7ed5\u8fc7\u98ce\u9669\uff0c\u9700\u8981\u7814\u7a76\u66f4\u5f3a\u5927\u7684\u653b\u51fb\u548c\u9632\u5fa1\u65b9\u6cd5\u3002", "method": "1. \u63d0\u51faSuper Suffixes\u653b\u51fb\u65b9\u6cd5\uff1a\u901a\u8fc7\u8054\u5408\u4f18\u5316\u6280\u672f\u751f\u6210\u80fd\u7ed5\u8fc7\u591a\u79cd\u5bf9\u9f50\u76ee\u6807\u548c\u4e0d\u540c\u5206\u8bcd\u65b9\u6848\u7684\u901a\u7528\u540e\u7f00\uff1b2. \u5f00\u53d1DeltaGuard\u9632\u5fa1\u65b9\u6cd5\uff1a\u901a\u8fc7\u5206\u6790\u6a21\u578b\u5185\u90e8\u72b6\u6001\u4e0e\u7279\u5b9a\u6982\u5ff5\u65b9\u5411\u7684\u4f59\u5f26\u76f8\u4f3c\u5ea6\u53d8\u5316\u6765\u68c0\u6d4b\u6076\u610f\u63d0\u793a\u3002", "result": "1. Super Suffixes\u6210\u529f\u7ed5\u8fc7Llama Prompt Guard 2\u5bf95\u4e2a\u6587\u672c\u751f\u6210\u6a21\u578b\u7684\u4fdd\u62a4\uff0c\u5b9e\u73b0\u6076\u610f\u6587\u672c\u548c\u4ee3\u7801\u751f\u6210\uff1b2. DeltaGuard\u5c06\u975e\u826f\u6027\u5206\u7c7b\u7387\u63d0\u5347\u81f3\u8fd1100%\uff0c\u663e\u8457\u589e\u5f3a\u5bf9\u6297\u6027\u63d0\u793a\u653b\u51fb\u7684\u68c0\u6d4b\u80fd\u529b\u3002", "conclusion": "\u672c\u7814\u7a76\u9996\u6b21\u63ed\u793aLlama Prompt Guard 2\u53ef\u901a\u8fc7\u8054\u5408\u4f18\u5316\u88ab\u7ed5\u8fc7\uff0c\u540c\u65f6\u63d0\u51fa\u7684DeltaGuard\u68c0\u6d4b\u65b9\u6cd5\u80fd\u6709\u6548\u9632\u5fa1Super Suffixes\u653b\u51fb\uff0c\u4e3a\u9632\u62a4\u6a21\u578b\u6808\u63d0\u4f9b\u4e86\u6709\u4ef7\u503c\u7684\u589e\u5f3a\u65b9\u6848\u3002"}}
