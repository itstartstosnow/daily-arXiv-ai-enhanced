<div id=toc></div>

# Table of Contents

- [cs.CR](#cs.CR) [Total: 15]


<div id='cs.CR'></div>

# cs.CR [[Back]](#toc)

### [1] [Temporal Analysis Framework for Intrusion Detection Systems: A Novel Taxonomy for Time-Aware Cybersecurity](https://arxiv.org/abs/2511.03799)
*Tatiana S. Parlanti,Carlos A. Catania*

Main category: cs.CR

TL;DR: 提出了一个时间感知网络入侵检测的时序分析框架和分类法，通过系统回顾2020-2025年的40多项研究，将NIDS方法按时间处理方式分类，发现基于序列和时序窗口的方法在MITRE ATT&CK战术中提供最广的时序覆盖。


<details>
  <summary>Details</summary>
Motivation: 当前入侵检测系统通常在重大损害发生后才能识别攻击，只能检测后期战术而非早期入侵指标，需要开发能够预测而非仅应对网络威胁的IDS。

Method: 通过系统回顾2020-2025年40多项研究，提出按时间处理方式分类NIDS方法的分类法，从静态单流分析到多窗口序列建模。

Result: 基于序列和时序窗口的方法在MITRE ATT&CK战术中提供最广的时序覆盖，能够从侦察阶段到影响阶段进行检测。分析还揭示了广泛使用数据集中的系统性偏差。

Conclusion: 该框架为开发能够预测而非仅应对网络威胁的IDS提供了必要基础，推动该领域向真正主动的防御机制发展。

Abstract: Most intrusion detection systems still identify attacks only after
significant damage has occurred, detecting late-stage tactics rather than early
indicators of compromise. This paper introduces a temporal analysis framework
and taxonomy for time-aware network intrusion detection. Through a systematic
review of over 40 studies published between 2020 and 2025, we classify NIDS
methods according to their treatment of time, from static per-flow analysis to
multi-window sequential modeling. The proposed taxonomy reveals that inter-flow
sequential and temporal window-based methods provide the broadest temporal
coverage across MITRE ATT&CK tactics, enabling detection from Reconnaissance
through Impact stages. Our analysis further exposes systematic bias in widely
used datasets, which emphasize late-stage attacks and thus limit progress
toward early detection. This framework provides essential groundwork for
developing IDS capable of anticipating rather than merely reacting to cyber
threats, advancing the field toward truly proactive defense mechanisms.

</details>


### [2] [Just in Plain Sight: Unveiling CSAM Distribution Campaigns on the Clear Web](https://arxiv.org/abs/2511.03816)
*Nikolaos Lykousas,Constantinos Patsakis*

Main category: cs.CR

TL;DR: 本文报告了在明网上传播儿童性虐待材料的活动，涉及1026个网页和738,286名注册用户，分析了其运作方式、社交网络滥用和机器人角色。


<details>
  <summary>Details</summary>
Motivation: COVID-19大流行后儿童性虐待材料传播激增，传统上这类材料在暗网交换，但现在已转移到明网，需要研究其传播机制。

Method: 通过分析该活动的运作方式，利用操作故障获取用户网络动态和内容需求信息。

Result: 发现了至少1026个网页用于传播，注册用户超过73.8万，揭示了社交网络被滥用和机器人参与的情况。

Conclusion: 该研究表明儿童性虐待材料传播已从暗网扩展到明网，需要加强监管和技术防范措施。

Abstract: Child sexual abuse is among the most hideous crimes, yet, after the COVID-19
pandemic, there is a huge surge in the distribution of child sexual abuse
material (CSAM). Traditionally, the exchange of such material is performed on
the dark web, as it provides many privacy guarantees that facilitate illicit
trades. However, the introduction of end-to-end encryption platforms has
brought it to the deep web. In this work, we report our findings for a campaign
of spreading child sexual abuse material on the clear web. The campaign
utilized at least 1,026 web pages for at least 738,286 registered users. Our
analysis details the operation of such a campaign, showcasing how social
networks are abused and the role of bots, but also the bypasses that are used.
Going a step further and exploiting operational faults in the campaign, we gain
insight into the demand for such content, as well as the dynamics of the user
network that supports it.

</details>


### [3] [Security Analysis of Agentic AI Communication Protocols: A Comparative Evaluation](https://arxiv.org/abs/2511.03841)
*Yedidel Louck,Ariel Stulman,Amit Dvir*

Main category: cs.CR

TL;DR: 本文对CORAL官方实现和基于SDK的ACP实现进行了首个实证性安全比较分析，揭示了两种协议在安全架构和实现层面的显著差异。


<details>
  <summary>Details</summary>
Motivation: 随着AI驱动的多智能体系统在复杂分布式工作流中日益重要，其底层通信协议的安全性却缺乏充分研究。

Method: 使用14点漏洞分类法，系统评估了认证、授权、完整性、机密性和可用性方面的防御能力，将CORAL和ACP实现与文献中的A2A评估进行基准测试。

Result: 发现明显的安全二分法：CORAL具有稳健的架构设计，但在实现层面存在关键漏洞；ACP架构灵活但导致高影响的完整性和机密性缺陷。

Conclusion: 建议采用混合方法，结合CORAL的集成架构和ACP的强制消息完整性保证，为下一代弹性智能体通信奠定基础。

Abstract: Multi-agent systems (MAS) powered by artificial intelligence (AI) are
increasingly foundational to complex, distributed workflows. Yet, the security
of their underlying communication protocols remains critically under-examined.
This paper presents the first empirical, comparative security analysis of the
official CORAL implementation and a high-fidelity, SDK-based ACP
implementation, benchmarked against a literature-based evaluation of A2A. Using
a 14 point vulnerability taxonomy, we systematically assess their defenses
across authentication, authorization, integrity, confidentiality, and
availability. Our results reveal a pronounced security dichotomy: CORAL
exhibits a robust architectural design, particularly in its transport-layer
message validation and session isolation, but suffers from critical
implementation-level vulnerabilities, including authentication and
authorization failures at its SSE gateway. Conversely, ACP's architectural
flexibility, most notably its optional JWS enforcement, translates into
high-impact integrity and confidentiality flaws. We contextualize these
findings within current industry trends, highlighting that existing protocols
remain insufficiently secure. As a path forward, we recommend a hybrid approach
that combines CORAL's integrated architecture with ACP's mandatory per-message
integrity guarantees, laying the groundwork for resilient, next-generation
agent communications.

</details>


### [4] [Secure Code Generation at Scale with Reflexion](https://arxiv.org/abs/2511.03898)
*Arup Datta,Ahmed Aljohani,Hyunsook Do*

Main category: cs.CR

TL;DR: 评估五个指令调优的代码LLM在安全代码生成方面的表现，使用零样本基线和三轮反思提示方法，发现初始约25-33%的程序不安全，反思提示可将平均准确率从70.74%提升至79.43%。


<details>
  <summary>Details</summary>
Motivation: LLM广泛用于代码生成，但功能正常的代码不一定安全，需要评估和改进代码LLM的安全代码生成能力。

Method: 使用Instruct Prime消除合规提示和提示污染，评估五个指令调优的代码LLM，采用零样本基线和三轮反思提示方法，使用Insecure Code Detector测量安全性，并报告修复、回归和净增益指标。

Result: 初始不安全率约25-33%，弱加密/配置相关漏洞最难避免，Python安全率最高，C和C#最低。反思提示对所有模型都有改善，平均准确率从70.74%提升至79.43%，前两轮收益最大。

Conclusion: 不安全代码在LLM生成的代码中仍然常见，反思提示能有效改善安全性，但一到两轮后收益递减。Python语言的安全表现最好，C和C#最差。

Abstract: Large language models (LLMs) are now widely used to draft and refactor code,
but code that works is not necessarily secure. We evaluate secure code
generation using the Instruct Prime, which eliminated compliance-required
prompts and cue contamination, and evaluate five instruction-tuned code LLMs
using a zero-shot baseline and a three-round reflexion prompting approach.
Security is measured using the Insecure Code Detector (ICD), and results are
reported by measuring Repair, Regression, and NetGain metrics, considering the
programming language and CWE family. Our findings show that insecurity remains
common at the first round: roughly 25-33% of programs are insecure at a
zero-shot baseline (t0 ). Weak cryptography/config-dependent bugs are the
hardest to avoid while templated ones like XSS, code injection, and hard-coded
secrets are handled more reliably. Python yields the highest secure rates; C
and C# are the lowest, with Java, JS, PHP, and C++ in the middle. Reflexion
prompting improves security for all models, improving average accuracy from
70.74% at t0 to 79.43% at t3 , with the largest gains in the first round
followed by diminishing returns. The trends with Repair, Regression, and
NetGain metrics show that applying one to two rounds produces most of the
benefits. A replication package is available at
https://doi.org/10.5281/zenodo.17065846.

</details>


### [5] [Design and Detection of Covert Man-in-the-Middle Cyberattacks on Water Treatment Plants](https://arxiv.org/abs/2511.03971)
*Victor Mattos,João Henrique Schmidt,Amit Bhaya,Alan Oliveira de Sá,Daniel Sadoc Menasché,Gaurav Srivastava*

Main category: cs.CR

TL;DR: 本文提出了一种系统方法来建模和评估利用系统识别技术设计的隐蔽中间人攻击，重点关注攻击者部署隐蔽控制器的能力，并评估基于PASAD异常检测方法的对策。


<details>
  <summary>Details</summary>
Motivation: 针对水处理设施等关键基础设施的网络攻击对公共健康、安全和环境构成重大威胁，需要开发有效的攻击检测和防御策略。

Method: 使用代表水处理动力学的二阶线性时不变时滞模型，设计和模拟隐蔽攻击，评估系统噪声和攻击者模型不准确性对攻击隐蔽性的影响。

Result: 研究结果表明系统噪声和攻击者模型不准确性显著影响攻击的隐蔽性，突显了工业控制环境中需要更强大的检测策略。

Conclusion: 在工业控制环境中需要开发更强大的攻击检测策略，以应对利用系统识别技术的隐蔽中间人攻击威胁。

Abstract: Cyberattacks targeting critical infrastructures, such as water treatment
facilities, represent significant threats to public health, safety, and the
environment. This paper introduces a systematic approach for modeling and
assessing covert man-in-the-middle (MitM) attacks that leverage system
identification techniques to inform the attack design. We focus on the
attacker's ability to deploy a covert controller, and we evaluate
countermeasures based on the Process-Aware Stealthy Attack Detection (PASAD)
anomaly detection method. Using a second-order linear time-invariant with time
delay model, representative of water treatment dynamics, we design and simulate
stealthy attacks. Our results highlight how factors such as system noise and
inaccuracies in the attacker's plant model influence the attack's stealthiness,
underscoring the need for more robust detection strategies in industrial
control environments.

</details>


### [6] [Hybrid Fuzzing with LLM-Guided Input Mutation and Semantic Feedback](https://arxiv.org/abs/2511.03995)
*Shiyin Lin*

Main category: cs.CR

TL;DR: 提出了一种结合静态分析、动态分析和LLM引导的混合模糊测试框架，通过语义感知的输入变异和反馈机制，提高漏洞发现的效率和深度。


<details>
  <summary>Details</summary>
Motivation: 现有模糊测试的变异策略缺乏语义意识，导致冗余测试用例和深度程序状态探索缓慢。

Method: 集成静态分析提取控制流和数据流信息，使用LLM生成语义多样的输入，结合传统覆盖率和语义反馈信号（程序状态变化、异常类型、输出语义）来指导种子选择。

Result: 在libpng、tcpdump和sqlite等真实世界开源目标上的评估显示，该方法实现了更快的首次发现漏洞时间、更高的语义多样性，以及与最先进模糊测试工具相当的独特漏洞数量。

Conclusion: 这项工作展示了将LLM推理与语义感知反馈相结合，在加速和深化漏洞发现方面的潜力。

Abstract: Software fuzzing has become a cornerstone in automated vulnerability
discovery, yet existing mutation strategies often lack semantic awareness,
leading to redundant test cases and slow exploration of deep program states. In
this work, I present a hybrid fuzzing framework that integrates static and
dynamic analysis with Large Language Model (LLM)-guided input mutation and
semantic feedback. Static analysis extracts control-flow and data-flow
information, which is transformed into structured prompts for the LLM to
generate syntactically valid and semantically diverse inputs. During execution,
I augment traditional coverage-based feedback with semantic feedback
signals-derived from program state changes, exception types, and output
semantics-allowing the fuzzer to prioritize inputs that trigger novel program
behaviors beyond mere code coverage. I implement our approach atop AFL++,
combining program instrumentation with embedding-based semantic similarity
metrics to guide seed selection. Evaluation on real-world open-source targets,
including libpng, tcpdump, and sqlite, demonstrates that our method achieves
faster time-to-first-bug, higher semantic diversity, and a competitive number
of unique bugs compared to state-of-the-art fuzzers. This work highlights the
potential of combining LLM reasoning with semantic-aware feedback to accelerate
and deepen vulnerability discovery.

</details>


### [7] [OTS-PC: OTS-based Payment Channels for the Lightning Network](https://arxiv.org/abs/2511.04021)
*Sergio Demian Lerner,Ariel Autoransky*

Main category: cs.CR

TL;DR: 提出一种基于状态序列号一次性签名的新型双向支付通道，比Poon-Dryja结构更简单，具有O(1)存储、最小信息泄露和闪电网络路由兼容性等优势。


<details>
  <summary>Details</summary>
Motivation: 现有支付通道结构（如Poon-Dryja）存在复杂性和效率问题，需要更简单高效的解决方案。

Method: 使用状态序列号的一次性签名来构建双向支付通道，通过序列号管理通道状态更新。

Result: 实现了比传统方法更简单的支付通道结构，同时保持O(1)存储复杂度和闪电网络兼容性。

Conclusion: 这种新型支付通道结构为区块链扩容提供了更高效实用的解决方案。

Abstract: We present a new type of bidirectional payment channel based on One-Time
Signatures on state sequence numbers. This new construction is simpler than the
Poon-Dryja construction, but provides a number of benefits such as $O(1)$
storage per channel, minimal information leakage, and compatibility with
Lightning Network routing.

</details>


### [8] [Automated and Explainable Denial of Service Analysis for AI-Driven Intrusion Detection Systems](https://arxiv.org/abs/2511.04114)
*Paul Badu Yakubu,Lesther Santana,Mohamed Rahouti,Yufeng Xin,Abdellah Chehri,Mohammed Aledhari*

Main category: cs.CR

TL;DR: 提出一个结合TPOT自动机器学习管道优化和SHAP可解释性的DDoS攻击检测框架，提高检测准确性和透明度


<details>
  <summary>Details</summary>
Motivation: 传统DDoS检测系统在可扩展性和透明度方面存在不足，需要更高效和可解释的检测方法

Method: 使用TPOT自动选择和优化机器学习模型及特征，结合SHAP增强模型可解释性，分析特征对检测的贡献

Result: 实验结果表明，平均反向包长度和最小正向包头长度等关键特征对DDoS攻击检测至关重要

Conclusion: 该方法提供了一个可扩展且可解释的网络安全解决方案，提高了DDoS检测的准确性和透明度

Abstract: With the increasing frequency and sophistication of Distributed Denial of
Service (DDoS) attacks, it has become critical to develop more efficient and
interpretable detection methods. Traditional detection systems often struggle
with scalability and transparency, hindering real-time response and
understanding of attack vectors. This paper presents an automated framework for
detecting and interpreting DDoS attacks using machine learning (ML). The
proposed method leverages the Tree-based Pipeline Optimization Tool (TPOT) to
automate the selection and optimization of ML models and features, reducing the
need for manual experimentation. SHapley Additive exPlanations (SHAP) is
incorporated to enhance model interpretability, providing detailed insights
into the contribution of individual features to the detection process. By
combining TPOT's automated pipeline selection with SHAP interpretability, this
approach improves the accuracy and transparency of DDoS detection. Experimental
results demonstrate that key features such as mean backward packet length and
minimum forward packet header length are critical in detecting DDoS attacks,
offering a scalable and explainable cybersecurity solution.

</details>


### [9] [Black-Box Guardrail Reverse-engineering Attack](https://arxiv.org/abs/2511.04215)
*Hongwei Yao,Yun Xia,Shuo Shao,Haoran Shi,Tong Qiao,Cong Wang*

Main category: cs.CR

TL;DR: 提出了Guardrail Reverse-engineering Attack (GRA)框架，通过强化学习和遗传算法数据增强来逆向工程LLM防护机制，在ChatGPT、DeepSeek和Qwen3等商业系统上实现了超过0.92的规则匹配率，成本低于85美元。


<details>
  <summary>Details</summary>
Motivation: LLM防护机制虽然能减少有害输出，但暴露了可观察的决策模式，引入了新的安全漏洞。本研究旨在探索黑盒LLM防护机制逆向工程攻击的可行性。

Method: 基于强化学习的框架，利用遗传算法驱动的数据增强来近似受害者防护机制的决策策略，通过迭代收集输入-输出对、优先处理分歧案例、应用定向突变和交叉操作。

Result: 在三个广泛部署的商业系统(ChatGPT、DeepSeek、Qwen3)上评估，GRA实现了超过0.92的规则匹配率，API成本低于85美元。

Conclusion: 当前LLM防护机制设计存在严重漏洞，防护机制提取具有实际可行性，凸显了LLM部署中需要更强大防御机制的紧迫性。

Abstract: Large language models (LLMs) increasingly employ guardrails to enforce
ethical, legal, and application-specific constraints on their outputs. While
effective at mitigating harmful responses, these guardrails introduce a new
class of vulnerabilities by exposing observable decision patterns. In this
work, we present the first study of black-box LLM guardrail reverse-engineering
attacks. We propose Guardrail Reverse-engineering Attack (GRA), a reinforcement
learning-based framework that leverages genetic algorithm-driven data
augmentation to approximate the decision-making policy of victim guardrails. By
iteratively collecting input-output pairs, prioritizing divergence cases, and
applying targeted mutations and crossovers, our method incrementally converges
toward a high-fidelity surrogate of the victim guardrail. We evaluate GRA on
three widely deployed commercial systems, namely ChatGPT, DeepSeek, and Qwen3,
and demonstrate that it achieves an rule matching rate exceeding 0.92 while
requiring less than $85 in API costs. These findings underscore the practical
feasibility of guardrail extraction and highlight significant security risks
for current LLM safety mechanisms. Our findings expose critical vulnerabilities
in current guardrail designs and highlight the urgent need for more robust
defense mechanisms in LLM deployment.

</details>


### [10] [A Parallel Region-Adaptive Differential Privacy Framework for Image Pixelization](https://arxiv.org/abs/2511.04261)
*Ming Liu*

Main category: cs.CR

TL;DR: 提出了一种并行、区域自适应的像素化框架，将差分隐私的理论严谨性与实际效率相结合，通过自适应调整网格大小和噪声尺度，利用GPU并行性实现显著的运行时加速。


<details>
  <summary>Details</summary>
Motivation: 高分辨率视觉感知系统的广泛部署和基础模型的兴起放大了视频应用中的隐私风险，差分私有像素化通过基于网格的噪声添加提供数学保证的保护，但在保持任务相关保真度、实现可扩展性和高效实时部署方面仍存在挑战。

Method: 提出并行、区域自适应的像素化框架，基于区域复杂度自适应调整网格大小和噪声尺度，利用GPU并行性加速运行，引入轻量级存储方案仅保留必要的噪声统计信息。

Result: 在PETS、Venice-2和PPM-100数据集上的广泛实验显示出良好的隐私-效用权衡和显著的运行时/存储减少，在CelebA上的人脸重新识别攻击实验进一步证实了该方法在防止身份推断方面的有效性。

Conclusion: 该方法适用于实时隐私关键应用，如老年护理、智能家居监控、驾驶员行为分析和人群行为监控。

Abstract: The widespread deployment of high-resolution visual sensing systems, coupled
with the rise of foundation models, has amplified privacy risks in video-based
applications. Differentially private pixelization offers mathematically
guaranteed protection for visual data through grid-based noise addition, but
challenges remain in preserving task-relevant fidelity, achieving scalability,
and enabling efficient real-time deployment. To address this, we propose a
novel parallel, region-adaptive pixelization framework that combines the
theoretical rigor of differential privacy with practical efficiency. Our method
adaptively adjusts grid sizes and noise scales based on regional complexity,
leveraging GPU parallelism to achieve significant runtime acceleration compared
to the classical baseline. A lightweight storage scheme is introduced by
retaining only essential noisy statistics, significantly reducing space
overhead. Formal privacy analysis is provided under the Laplace mechanism and
parallel composition theorem. Extensive experiments on the PETS, Venice-2, and
PPM-100 datasets demonstrate favorable privacy-utility trade-offs and
significant runtime/storage reductions. A face re-identification attack
experiment on CelebA further confirms the method's effectiveness in preventing
identity inference. This validates its suitability for real-time
privacy-critical applications such as elderly care, smart home monitoring,
driver behavior analysis, and crowd behavior monitoring.

</details>


### [11] [Data Certification Strategies for Blockchain-based Traceability Systems](https://arxiv.org/abs/2511.04409)
*Giacomo Zonneveld,Giulia Rafaiani,Massimo Battaglioni,Marco Baldi*

Main category: cs.CR

TL;DR: 本文分析和比较了在区块链上认证持续产生的大批量数据的策略，同时保持去中心化验证的可能性。


<details>
  <summary>Details</summary>
Motivation: 虽然区块链在数据认证和溯源方面已广泛应用，但对于持续产生的大批量数据，如何高效地进行区块链认证仍面临挑战，需要解决数据缓冲和组织问题。

Method: 考虑典型的生产过程区块链溯源系统，提出并比较了多种数据认证策略，包括使用链下缓冲区和Merkle树等方法来组织数据。

Result: 通过比较分析，确定了在保持去中心化验证能力的同时，有效认证大批量连续数据的可行策略。

Conclusion: 为持续产生的大批量数据的区块链认证提供了实用的解决方案，平衡了认证效率和验证去中心化要求。

Abstract: The use of blockchains for data certification and traceability is now well
established in both the literature and practical applications. However, while
blockchain-based certification of individual data is clear and straightforward,
the use of blockchain to certify large amounts of data produced on a nearly
continuous basis still poses some challenges. In such a case, in fact, it is
first necessary to collect the data in an off-chain buffer, and then to
organize it, e.g., via Merkle trees, in order to keep the size and quantity of
certification data to be written to the blockchain small. In this paper, we
consider a typical system for blockchain-based traceability of a production
process, and propose and comparatively analyze some strategies for certifying
the data of such a process on blockchain, while maintaining the possibility of
verifying their certification in a decentralized way.

</details>


### [12] [Adversarially Robust and Interpretable Magecart Malware Detection](https://arxiv.org/abs/2511.04440)
*Pedro Pereira,José Gouveia,João Vitorino,Eva Maia,Isabel Praça*

Main category: cs.CR

TL;DR: 本文比较了多种机器学习模型在检测Magecart攻击中的表现，使用行为确定性有限自动机分析脚本结构模式，并通过对抗训练提升模型鲁棒性，实现了高检测性能和可解释性。


<details>
  <summary>Details</summary>
Motivation: Magecart攻击严重威胁客户端安全和在线支付系统的用户信任，需要开发能够稳健检测此类攻击并提供可解释结果的解决方案。

Method: 应用基于树、线性和核的机器学习模型，结合超参数调优和特征选择；使用行为确定性有限自动机分析脚本结构模式；通过对抗训练增强模型鲁棒性，使用Adversarial Robustness Toolbox和自适应扰动模式方法进行评估。

Result: 实验验证显示模型具有高检测性能，能够有效区分良性脚本和恶意脚本，同时提供可解释的决策过程。

Conclusion: 传统机器学习模型在实际web安全场景中能够有效检测Magecart攻击，同时保持高检测性能和可解释性。

Abstract: Magecart skimming attacks have emerged as a significant threat to client-side
security and user trust in online payment systems. This paper addresses the
challenge of achieving robust and explainable detection of Magecart attacks
through a comparative study of various Machine Learning (ML) models with a
real-world dataset. Tree-based, linear, and kernel-based models were applied,
further enhanced through hyperparameter tuning and feature selection, to
distinguish between benign and malicious scripts. Such models are supported by
a Behavior Deterministic Finite Automaton (DFA) which captures structural
behavior patterns in scripts, helping to analyze and classify client-side
script execution logs. To ensure robustness against adversarial evasion
attacks, the ML models were adversarially trained and evaluated using attacks
from the Adversarial Robustness Toolbox and the Adaptative Perturbation Pattern
Method. In addition, concise explanations of ML model decisions are provided,
supporting transparency and user trust. Experimental validation demonstrated
high detection performance and interpretable reasoning, demonstrating that
traditional ML models can be effective in real-world web security contexts.

</details>


### [13] [Exploiting Data Structures for Bypassing and Crashing Anti-Malware Solutions via Telemetry Complexity Attacks](https://arxiv.org/abs/2511.04472)
*Evgenios Gkritsis,Constantinos Patsakis,George Stergiopoulos*

Main category: cs.CR

TL;DR: 该论文提出了一种新型的"遥测复杂性攻击"(TCAs)，通过生成深度嵌套和超大的遥测数据来攻击反恶意软件系统的数据处理管道，导致分析失效，而无需禁用传感器或提升权限。


<details>
  <summary>Details</summary>
Motivation: 反恶意软件系统依赖沙箱、钩子和遥测管道来监控程序行为，但这些数据处理组件构成了可利用的攻击面，可能导致分析拒绝状态。

Method: 通过递归生成子进程来创建特殊构造的深度嵌套和超大遥测数据，压力测试序列化和存储边界以及可视化层。

Result: 评估了12个商业和开源恶意软件分析平台及EDR解决方案，其中7个产品在遥测管道的不同阶段失败，两个供应商分配了CVE标识，其他发布了补丁或配置更改。

Conclusion: 讨论了根本原因并提出了缓解策略，以防止由对抗性遥测触发的分析拒绝攻击。

Abstract: Anti-malware systems rely on sandboxes, hooks, and telemetry pipelines,
including collection agents, serializers, and database backends, to monitor
program and system behavior. We show that these data-handling components
constitute an exploitable attack surface that can lead to denial-of-analysis
(DoA) states without disabling sensors or requiring elevated privileges. As a
result, we present \textit{Telemetry Complexity Attacks} (TCAs), a new class of
vulnerabilities that exploit fundamental mismatches between unbounded
collection mechanisms and bounded processing capabilities. Our method
recursively spawns child processes to generate specially crafted, deeply
nested, and oversized telemetry that stresses serialization and storage
boundaries, as well as visualization layers, for example, JSON/BSON depth and
size limits. Depending on the product, this leads to truncated or missing
behavioral reports, rejected database inserts, serializer recursion and size
errors, and unresponsive dashboards. In all of these cases, malicious activity
is normally executed; however, depending on the examined solution, it is not
recorded and/or not presented to the analysts. Therefore, instead of evading
sensors, we break the pipeline that stores the data captured by the sensors.
  We evaluate our technique against twelve commercial and open-source malware
analysis platforms and endpoint detection and response (EDR) solutions. Seven
products fail in different stages of the telemetry pipeline; two vendors
assigned CVE identifiers (CVE-2025-61301 and CVE-2025-61303), and others issued
patches or configuration changes. We discuss root causes and propose mitigation
strategies to prevent DoA attacks triggered by adversarial telemetry.

</details>


### [14] [Large Language Models for Cyber Security](https://arxiv.org/abs/2511.04508)
*Raunak Somani,Aswani Kumar Cherukuri*

Main category: cs.CR

TL;DR: 本文研究将大型语言模型集成到网络安全工具和协议中，以应对传统基于规则和签名的安全系统无法处理的现代AI驱动网络威胁。


<details>
  <summary>Details</summary>
Motivation: 传统网络安全系统无法有效应对日益复杂和自适应的AI驱动网络威胁，需要更智能、可扩展的解决方案。

Method: 研究LLM架构和功能，集成加密提示以防止提示注入攻击，采用四层架构将LLM集成到网络安全工具中，并探索将LLM集成到传统入侵检测系统的各种方法。

Result: 加密提示与LLM结合能有效缓解提示注入攻击；LLM增强的网络安全工具比传统模型更准确、可扩展且能适应新威胁；解耦模型方法是LLM集成到IDS的最佳方式。

Conclusion: LLM集成能显著提升网络安全工具的智能性、可扩展性和适应性，是应对现代网络威胁的有效解决方案。

Abstract: This paper studies the integration off Large Language Models into
cybersecurity tools and protocols. The main issue discussed in this paper is
how traditional rule-based and signature based security systems are not enough
to deal with modern AI powered cyber threats. Cybersecurity industry is
changing as threats are becoming more dangerous and adaptive in nature by
levering the features provided by AI tools. By integrating LLMs into these
tools and protocols, make the systems scalable, context-aware and intelligent.
Thus helping it to mitigate these evolving cyber threats. The paper studies the
architecture and functioning of LLMs, its integration into Encrypted prompts to
prevent prompt injection attacks. It also studies the integration of LLMs into
cybersecurity tools using a four layered architecture. At last, the paper has
tried to explain various ways of integration LLMs into traditional Intrusion
Detection System and enhancing its original abilities in various dimensions.
The key findings of this paper has been (i)Encrypted Prompt with LLM is an
effective way to mitigate prompt injection attacks, (ii) LLM enhanced cyber
security tools are more accurate, scalable and adaptable to new threats as
compared to traditional models, (iii) The decoupled model approach for LLM
integration into IDS is the best way as it is the most accurate way.

</details>


### [15] [Confidential Computing for Cloud Security: Exploring Hardware based Encryption Using Trusted Execution Environments](https://arxiv.org/abs/2511.04550)
*Dhruv Deepak Agarwal,Aswani Kumar Cherukuri*

Main category: cs.CR

TL;DR: 该论文探讨了可信执行环境(TEEs)在云计算安全中的关键作用，重点分析了Intel SGX和ARM TrustZone等TEE技术如何通过硬件保护机制解决数据使用过程中的安全问题。


<details>
  <summary>Details</summary>
Motivation: 云计算的发展带来了数据安全挑战，传统加密方法无法保护使用中的数据，需要新的安全解决方案来防止数据在处理过程中被泄露。

Method: 通过文献调查分析TEEs的架构和安全特性，评估其部署策略、性能指标和实际应用效果，同时识别相关挑战和限制。

Result: 研究发现TEEs在增强云安全基础设施方面发挥核心作用，能够为机密计算提供安全基础，但存在部署复杂性、潜在漏洞和集成挑战等问题。

Conclusion: TEEs是解决云计算中数据使用安全问题的有效技术，尽管面临一些实施挑战，但在构建安全云环境方面具有重要价值。

Abstract: The growth of cloud computing has revolutionized data processing and storage
capacities to another levels of scalability and flexibility. But in the
process, it has created a huge challenge of security, especially in terms of
safeguarding sensitive data. Classical security practices, including encryption
at rest and during transit, fail to protect data in use and expose it to
various possible breaches. In response to this problem , Confidential Computing
has been a tool ,seeking to secure data in processing by usage of
hardware-based Trusted Execution Environments (TEEs). TEEs, including Intel's
Software Guard Extensions (SGX) and ARM's TrustZone, offers protected contexts
within the processor, where data is kept confidential ,intact and secure , even
with malicious software or compromised operating systems. In this research, we
have explored the architecture and security features of TEEs like Intel SGX and
ARM TrustZone, and their effectiveness in improving cloud data security. From a
thorough literature survey ,we have analyzed the deployment strategies,
performance indicators, and practical uses of these TEEs for the same purpose.
In addition, we have discussed the issues regarding deployment, possible
weaknesses, scalability issues, and integration issues. Our results focuses on
the central position of TEEs in strengthening and advancing cloud security
infrastructures, pointing towards their ability to create a secure foundation
for Confidential Computing.

</details>
