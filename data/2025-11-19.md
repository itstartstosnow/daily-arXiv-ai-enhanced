<div id=toc></div>

# Table of Contents

- [cs.CR](#cs.CR) [Total: 19]


<div id='cs.CR'></div>

# cs.CR [[Back]](#toc)

### [1] [AI Kill Switch for malicious web-based LLM agent](https://arxiv.org/abs/2511.13725)
*Sechan Lee,Sangdon Park*

Main category: cs.CR

TL;DR: 提出AutoGuard技术，通过生成防御性提示词嵌入网站DOM，触发恶意LLM代理的安全机制来中止其恶意行为。


<details>
  <summary>Details</summary>
Motivation: 应对基于网页的LLM代理在自主执行复杂任务时带来的恶意滥用风险，如未经授权收集个人信息、生成社会分裂内容和自动化网络攻击。

Method: 开发AutoGuard系统，生成防御提示词并透明嵌入网站DOM，这些提示对用户不可见但能被恶意代理爬取过程检测，触发其内部安全机制中止恶意操作。

Result: 在包含三种恶意场景的基准测试中，AutoGuard对GPT-4o、Claude-3和Llama3.3-70B-Instruct等恶意代理达到80%以上的防御成功率，对GPT-5、GPT-4.1和Gemini-2.5-Flash达到约90%的防御成功率。

Conclusion: 该研究证明了基于网页的LLM代理在各种场景和模型中的可控性，为AI控制和安全性做出了贡献。

Abstract: Recently, web-based Large Language Model (LLM) agents autonomously perform increasingly complex tasks, thereby bringing significant convenience. However, they also amplify the risks of malicious misuse cases such as unauthorized collection of personally identifiable information (PII), generation of socially divisive content, and even automated web hacking. To address these threats, we propose an AI Kill Switch technique that can immediately halt the operation of malicious web-based LLM agents. To achieve this, we introduce AutoGuard - the key idea is generating defensive prompts that trigger the safety mechanisms of malicious LLM agents. In particular, generated defense prompts are transparently embedded into the website's DOM so that they remain invisible to human users but can be detected by the crawling process of malicious agents, triggering its internal safety mechanisms to abort malicious actions once read. To evaluate our approach, we constructed a dedicated benchmark consisting of three representative malicious scenarios (PII collection, social rift content generation, and web hacking attempts). Experimental results show that the AutoGuard method achieves over 80% Defense Success Rate (DSR) on malicious agents, including GPT-4o, Claude-3, and Llama3.3-70B-Instruct. It also maintains strong performance, achieving around 90% DSR on GPT-5, GPT-4.1, and Gemini-2.5-Flash when used as the malicious agent, demonstrating robust generalization across models and scenarios. Through this research, we have demonstrated the controllability of web-based LLM agents across various scenarios and models, thereby contributing to the broader effort of AI control and safety.

</details>


### [2] [ExplainableGuard: Interpretable Adversarial Defense for Large Language Models Using Chain-of-Thought Reasoning](https://arxiv.org/abs/2511.13771)
*Shaowei Guan,Yu Zhai,Zhengyu Zhang,Yanze Wang,Hin Chi Kwok*

Main category: cs.CR

TL;DR: 提出了ExplainableGuard框架，利用DeepSeek-Reasoner的思维链推理能力，提供可解释的对抗防御，不仅能检测和消除文本对抗扰动，还能为每个防御动作提供逐步解释。


<details>
  <summary>Details</summary>
Motivation: 当前LLM面临对抗攻击威胁，现有防御机制多为黑盒，缺乏决策透明度。需要开发既能有效防御又能提供解释的框架。

Method: 利用定制化的思维链提示引导LLM进行多层面分析（字符、词汇、结构和语义），生成净化输出及人类可读的防御理由。

Result: 在GLUE基准和IMDB电影评论数据集上显示出有前景的防御效果。人工评估显示其解释在清晰度、特异性和可操作性方面优于消融变体，部署可信度评分为72.5%。

Conclusion: ExplainableGuard框架具有构建更可信LLM部署的潜力，通过提供透明化的防御决策过程增强用户信任。

Abstract: Large Language Models (LLMs) are increasingly vulnerable to adversarial attacks that can subtly manipulate their outputs. While various defense mechanisms have been proposed, many operate as black boxes, lacking transparency in their decision-making. This paper introduces ExplainableGuard, an interpretable adversarial defense framework leveraging the chain-of-thought (CoT) reasoning capabilities of DeepSeek-Reasoner. Our approach not only detects and neutralizes adversarial perturbations in text but also provides step-by-step explanations for each defense action. We demonstrate how tailored CoT prompts guide the LLM to perform a multi-faceted analysis (character, word, structural, and semantic) and generate a purified output along with a human-readable justification. Preliminary results on the GLUE Benchmark and IMDB Movie Reviews dataset show promising defense efficacy. Additionally, a human evaluation study reveals that ExplainableGuard's explanations outperform ablated variants in clarity, specificity, and actionability, with a 72.5% deployability-trust rating, underscoring its potential for more trustworthy LLM deployments.

</details>


### [3] [Hashpower allocation in Pay-per-Share blockchain mining pools](https://arxiv.org/abs/2511.13777)
*Pierre-Olivier Goffard,Hansjoerg Albrecher,Jean-Pierre Fouque*

Main category: cs.CR

TL;DR: 本文分析PPS挖矿池中矿工如何分配算力，考虑风险转移与管理费的权衡


<details>
  <summary>Details</summary>
Motivation: PoW挖矿存在显著风险，矿工面临持续运营成本但收益不稳定。加入矿池是常见的风险缓解策略，但需要研究矿工如何在矿池间优化算力分配

Method: 使用简化的矿工财富模型，分析PPS奖励系统中矿池管理者调整份额难度和管理费对矿工决策的影响

Result: 矿工需要在将风险转移给矿池管理者与支付管理费之间进行权衡，以优化算力分配策略

Conclusion: PPS矿池系统为矿工提供了风险转移机制，但矿工需要根据管理费水平合理分配算力，在风险分散和成本控制之间找到平衡

Abstract: Mining blocks in a blockchain using the \textit{Proof-of-Work} consensus protocol involves significant risk, as network participants face continuous operational costs while earning infrequent capital gains upon successfully mining a block. A common risk mitigation strategy is to join a mining pool, which combines the computing resources of multiple miners to provide a more stable income. This article examines a Pay-per-Share (PPS) reward system, where the pool manager can adjust both the share difficulty and the management fee. Using a simplified wealth model for miners, we explore how miners should allocate their computing resources among different mining pools, considering the trade-off between risk transfer to the manager and management fees.

</details>


### [4] [Human-Centered Threat Modeling in Practice: Lessons, Challenges, and Paths Forward](https://arxiv.org/abs/2511.13781)
*Warda Usman,Yixin Zou,Daniel Zappala*

Main category: cs.CR

TL;DR: 通过对23位研究人员的半结构化访谈，探讨了以人为中心的威胁建模(HCTM)的实践现状，发现HCTM是一套不断演变的实践，受到参与者关系、学科背景和制度结构的影响。


<details>
  <summary>Details</summary>
Motivation: 虽然研究人员越来越多地从以人为中心的角度进行威胁建模，但对于他们如何在实践中准备和参与HCTM知之甚少。

Method: 对23位研究人员进行半结构化访谈，考察他们如何设计研究、引出威胁、以及处理价值观、约束和长期目标。

Result: HCTM不是规定性过程，而是由与参与者的关系、学科背景和制度结构塑造的不断演变的实践。研究人员通过持续的基础工作和以参与者为中心的调查来进行威胁建模，遵循关怀、正义和自主等价值观，但也面临情感压力、伦理困境和结构障碍等挑战。

Conclusion: 提出了通过共享基础设施、更广泛认可多样化贡献以及更强有力的机制将研究成果转化为政策、设计和社会变革来推进HCTM的机会。

Abstract: Human-centered threat modeling (HCTM) is an emerging area within security and privacy research that focuses on how people define and navigate threats in various social, cultural, and technological contexts. While researchers increasingly approach threat modeling from a human-centered perspective, little is known about how they prepare for and engage with HCTM in practice. In this work, we conduct 23 semi-structured interviews with researchers to examine the state of HCTM, including how researchers design studies, elicit threats, and navigate values, constraints, and long-term goals. We find that HCTM is not a prescriptive process but a set of evolving practices shaped by relationships with participants, disciplinary backgrounds, and institutional structures. Researchers approach threat modeling through sustained groundwork and participant-centered inquiry, guided by values such as care, justice, and autonomy. They also face challenges including emotional strain, ethical dilemmas, and structural barriers that complicate efforts to translate findings into real-world impact. We conclude by identifying opportunities to advance HCTM through shared infrastructure, broader recognition of diverse contributions, and stronger mechanisms for translating findings into policy, design, and societal change.

</details>


### [5] [Uncovering and Aligning Anomalous Attention Heads to Defend Against NLP Backdoor Attacks](https://arxiv.org/abs/2511.13789)
*Haotian Jin,Yang Li,Haihui Fan,Lin Shen,Xiangfang Li,Bo Li*

Main category: cs.CR

TL;DR: 提出了一种基于注意力相似性的后门检测方法，无需先验知识即可检测动态或隐式触发器，并通过注意力安全对齐和逐头微调来缓解后门攻击。


<details>
  <summary>Details</summary>
Motivation: 后门攻击对LLMs安全构成严重威胁，现有防御方法局限于特定触发器类型或依赖额外干净模型支持，难以应对动态或隐式触发器的挑战。

Method: 基于注意力相似性检测后门，发现受攻击模型在触发条件下注意力头间相似度异常高，采用注意力安全对齐和逐头微调来修正受污染的注意力头。

Result: 实验结果表明该方法显著降低后门攻击成功率，同时保持模型在下游任务上的性能。

Conclusion: 该方法能有效检测和缓解后门攻击，无需触发器先验知识，为LLMs安全提供了新的防御思路。

Abstract: Backdoor attacks pose a serious threat to the security of large language models (LLMs), causing them to exhibit anomalous behavior under specific trigger conditions. The design of backdoor triggers has evolved from fixed triggers to dynamic or implicit triggers. This increased flexibility in trigger design makes it challenging for defenders to identify their specific forms accurately. Most existing backdoor defense methods are limited to specific types of triggers or rely on an additional clean model for support. To address this issue, we propose a backdoor detection method based on attention similarity, enabling backdoor detection without prior knowledge of the trigger. Our study reveals that models subjected to backdoor attacks exhibit unusually high similarity among attention heads when exposed to triggers. Based on this observation, we propose an attention safety alignment approach combined with head-wise fine-tuning to rectify potentially contaminated attention heads, thereby effectively mitigating the impact of backdoor attacks. Extensive experimental results demonstrate that our method significantly reduces the success rate of backdoor attacks while preserving the model's performance on downstream tasks.

</details>


### [6] [Zipf-Gramming: Scaling Byte N-Grams Up to Production Sized Malware Corpora](https://arxiv.org/abs/2511.13808)
*Edward Raff,Ryan R. Curtin,Derek Everett,Robert J. Joyce,James Holt*

Main category: cs.CR

TL;DR: 提出了一种名为Zipf-Gramming的新算法，用于高效提取字节n-gram特征，在恶意软件检测中实现35倍速度提升和30%的AUC改进。


<details>
  <summary>Details</summary>
Motivation: 现有基于字节n-gram的分类器在恶意软件检测中具有理想的速度和延迟特性，但更新模型成本高昂，无法频繁部署更新的模型。

Method: 利用Zipf分布特性开发新的top-k n-gram提取器Zipf-Gramming算法，通过理论分析和工程实现优化提取过程。

Result: 新算法比之前最佳方案快35倍，通过扩大训练集规模使检测新恶意软件的AUC提升30%。

Conclusion: Zipf-Gramming算法能够高效准确地选择top-k n-gram特征，实现了理论与工程的结合，解决了大规模恶意软件检测中的模型更新瓶颈。

Abstract: A classifier using byte n-grams as features is the only approach we have found fast enough to meet requirements in size (sub 2 MB), speed (multiple GB/s), and latency (sub 10 ms) for deployment in numerous malware detection scenarios. However, we've consistently found that 6-8 grams achieve the best accuracy on our production deployments but have been unable to deploy regularly updated models due to the high cost of finding the top-k most frequent n-grams over terabytes of executable programs. Because the Zipfian distribution well models the distribution of n-grams, we exploit its properties to develop a new top-k n-gram extractor that is up to $35\times$ faster than the previous best alternative. Using our new Zipf-Gramming algorithm, we are able to scale up our production training set and obtain up to 30\% improvement in AUC at detecting new malware. We show theoretically and empirically that our approach will select the top-k items with little error and the interplay between theory and engineering required to achieve these results.

</details>


### [7] [The Battle of Metasurfaces: Understanding Security in Smart Radio Environments](https://arxiv.org/abs/2511.13939)
*Paul Staat,Christof Paar,Swarun Kumar*

Main category: cs.CR

TL;DR: 本文首次系统研究了对称场景下竞争性超表面的相互作用及其对无线安全的影响，发现在Wi-Fi环境中，对立的超表面可以相互抵消效果，这既挑战了现有安全方案，也为设计弹性物理层系统提供了新机会。


<details>
  <summary>Details</summary>
Motivation: 超表面技术使无线环境变得可编程，但现有安全研究主要关注单边应用。本文研究对称场景，即攻击者和防御者都拥有超表面能力时的相互作用。

Method: 通过理论建模和真实世界实验，分析竞争性超表面在不同目标（信号功率、感知感知）下的相互作用，并在Wi-Fi环境中进行多个案例研究。

Result: 结果表明超表面"战斗"的结果取决于时机、位置、算法策略和硬件规模的相互作用。对立的超表面可以显著或完全抵消彼此的效果。

Conclusion: 研究结果既挑战了先前提出的安全和隐私方案，也为在智能无线电环境中设计弹性和高保证的物理层系统开辟了新机会。

Abstract: Metasurfaces, or Reconfigurable Intelligent Surfaces (RISs), have emerged as a transformative technology for next-generation wireless systems, enabling digitally controlled manipulation of electromagnetic wave propagation. By turning the traditionally passive radio environment into a smart, programmable medium, metasurfaces promise advances in communication and sensing. However, metasurfaces also present a new security frontier: both attackers and defenders can exploit them to alter wireless propagation for their own advantage. While prior security research has primarily explored unilateral metasurface applications - empowering either attackers or defenders - this work investigates symmetric scenarios, where both sides possess comparable metasurface capabilities. Using both theoretical modeling and real-world experiments, we analyze how competing metasurfaces interact for diverse objectives, including signal power and sensing perception. Thereby, we present the first systematic study of context-agnostic metasurface-to-metasurface interactions and their implications for wireless security. Our results reveal that the outcome of metasurface "battles" depends on an interplay of timing, placement, algorithmic strategy, and hardware scale. Across multiple case studies in Wi-Fi environments, including wireless jamming, channel obfuscation for sensing and communication, and sensing spoofing, we demonstrate that opposing metasurfaces can substantially or fully negate each other's effects. By undermining previously proposed security and privacy schemes, our findings open new opportunities for designing resilient and high-assurance physical-layer systems in smart radio environments.

</details>


### [8] [Privis: Towards Content-Aware Secure Volumetric Video Delivery](https://arxiv.org/abs/2511.14005)
*Kaiyuan Hu,Hong Kang,Yili Jin,Junhua Liu,Chengming Hu,Haolun Wu,Xue Liu*

Main category: cs.CR

TL;DR: Privis是一个基于显著性的安全体积视频传输框架，通过分区加密、轻量认证和选择性流量整形来平衡机密性和低延迟需求。


<details>
  <summary>Details</summary>
Motivation: 现有体积视频流媒体继承了2D视频的统一加密方案，忽略了不同几何数据的隐私敏感度差异和实时XR的严格延迟约束。

Method: 将体积资产分区为独立单元，应用轻量级认证加密和自适应密钥轮换，采用选择性流量整形。

Result: 提出了通用的传输层安全架构，定义了核心抽象和自适应保护机制，并通过原型实现展示了可行性。

Conclusion: 为实时、基于显著性的安全体积视频传输提供了早期实证指导，是内容感知安全体积视频传输的初步探索。

Abstract: Volumetric video has emerged as a key paradigm in eXtended Reality (XR) and immersive multimedia because it enables highly interactive, spatially consistent 3D experiences. However, the transport-layer security for such 3D content remains largely unaddressed. Existing volumetric streaming pipelines inherit uniform encryption schemes from 2D video, overlooking the heterogeneous privacy sensitivity of different geometry and the strict motion-to-photon latency constraints of real-time XR.
  We take an initial step toward content-aware secure volumetric video delivery by introducing Privis, a saliency-guided transport framework that (i) partitions volumetric assets into independent units, (ii) applies lightweight authenticated encryption with adaptive key rotation, and (iii) employs selective traffic shaping to balance confidentiality and low latency. Privis specifies a generalized transport-layer security architecture for volumetric media, defining core abstractions and adaptive protection mechanisms. We further explore a prototype implementation and present initial latency measurements to illustrate feasibility and design tradeoffs, providing early empirical guidance toward future work on real-time, saliency-conditioned secure delivery.

</details>


### [9] [Location-Dependent Cryptosystem](https://arxiv.org/abs/2511.14032)
*Kunal Mukherjee*

Main category: cs.CR

TL;DR: 提出了一种基于超宽带(UWB)数据传输包飞行时间差异的位置依赖加密系统，解密密钥不是直接传输，而是通过精确的时间差隐式编码，只有位于预定空间区域内的接收器才能正确重建密钥。


<details>
  <summary>Details</summary>
Motivation: 解决传统加密方案(如AES、TDES、ECC等)在密钥泄露后无法限制解密位置的问题，防止知识产权被盗和未经授权的再分发。

Method: 利用精确计时硬件和自定义JMTK协议，将SHA-256哈希的AES密钥映射到预定的传输时间戳上，通过UWB数据包的飞行时间差异隐式编码解密密钥。

Result: 实现了完整原型系统，能够加密传输音频数据，只有位于授权区域内的接收器才能成功解密；系统无需电子或物理共享解密密码，密钥无法被窃听者恢复，并为合法用户提供空间容差。

Conclusion: 位置依赖加密系统通过空间限制有效增强了数字内容保护，解决了传统加密方案的位置无关性缺陷。

Abstract: Digital content distribution and proprietary research-driven industries face persistent risks from intellectual property theft and unauthorized redistribution. Conventional encryption schemes such as AES, TDES, ECC, and ElGamal provide strong cryptographic guarantees, but they remain fundamentally agnostic to where decryption takes place.In practice, this means that once a decryption key is leaked or intercepted, any adversary can misuse the key to decrypt the protected content from any location. We present a location-dependent cryptosystem in which the decryption key is not transmitted as human- or machine-readable data, but implicitly encoded in precise time-of-flight differences of ultra-wideband (UWB) data transmission packets. The system leverages precise timing hardware and a custom JMTK protocol to map a SHA-256 hashed AES key onto scheduled transmission timestamps. Only receivers located within a predefined spatial region can observe the packet timings that align with the intended "time slot" pattern, enabling them to reconstruct the key and decrypt the secret. Receivers outside the authorized region observe incorrect keys. We implement a complete prototype that encrypts and transmits audio data using our cryptosystem, and only when the receiver is within the authorized data, they are able to decrypt the data. Our evaluation demonstrates that the system (i) removes the need to share decryption passwords electronically or physically, (ii) ensures the decryption key cannot be recovered by the eavesdropper, and (iii) provides a non-trivial spatial tolerance for legitimate users.

</details>


### [10] [GRPO Privacy Is at Risk: A Membership Inference Attack Against Reinforcement Learning With Verifiable Rewards](https://arxiv.org/abs/2511.14045)
*Yule Liu,Heyi Zhang,Jinyi Zheng,Zhen Sun,Zifan Peng,Tianshuo Cong,Yilong Yang,Xinlei He,Zhuo Ma*

Main category: cs.CR

TL;DR: 提出了DIBA攻击方法，专门针对RLVR训练的大语言模型进行成员推理攻击，通过检测模型行为变化而非答案记忆来识别训练数据，在多个场景下显著优于现有基线方法。


<details>
  <summary>Details</summary>
Motivation: RLVR训练范式引入了新的隐私泄露模式：由于训练依赖自生成响应而非固定真值输出，成员推理需要判断给定提示是否用于微调，这种威胁源于行为变化而非答案记忆。

Method: 提出DIBA攻击框架，从记忆转向行为变化检测，利用两个维度的可测量行为变化：优势侧改进（如正确性提升）和对数侧分歧（如策略漂移）。

Result: DIBA显著优于现有基线，达到约0.8的AUC和数量级更高的TPR@0.1%FPR，在分布内、跨数据集、跨算法、黑盒场景以及扩展到视觉语言模型等多个设置中均表现优越，且对适度防御措施保持鲁棒。

Conclusion: 这是首个系统分析RLVR隐私漏洞的工作，揭示了即使在缺乏显式监督的情况下，训练数据暴露仍可通过行为痕迹可靠推断。

Abstract: Membership inference attacks (MIAs) on large language models (LLMs) pose significant privacy risks across various stages of model training. Recent advances in Reinforcement Learning with Verifiable Rewards (RLVR) have brought a profound paradigm shift in LLM training, particularly for complex reasoning tasks. However, the on-policy nature of RLVR introduces a unique privacy leakage pattern: since training relies on self-generated responses without fixed ground-truth outputs, membership inference must now determine whether a given prompt (independent of any specific response) is used during fine-tuning. This creates a threat where leakage arises not from answer memorization.
  To audit this novel privacy risk, we propose Divergence-in-Behavior Attack (DIBA), the first membership inference framework specifically designed for RLVR. DIBA shifts the focus from memorization to behavioral change, leveraging measurable shifts in model behavior across two axes: advantage-side improvement (e.g., correctness gain) and logit-side divergence (e.g., policy drift). Through comprehensive evaluations, we demonstrate that DIBA significantly outperforms existing baselines, achieving around 0.8 AUC and an order-of-magnitude higher TPR@0.1%FPR. We validate DIBA's superiority across multiple settings--including in-distribution, cross-dataset, cross-algorithm, black-box scenarios, and extensions to vision-language models. Furthermore, our attack remains robust under moderate defensive measures.
  To the best of our knowledge, this is the first work to systematically analyze privacy vulnerabilities in RLVR, revealing that even in the absence of explicit supervision, training data exposure can be reliably inferred through behavioral traces.

</details>


### [11] [Dynamic Black-box Backdoor Attacks on IoT Sensory Data](https://arxiv.org/abs/2511.14074)
*Ajesh Koyatan Chathoth,Stephen Lee*

Main category: cs.CR

TL;DR: 提出了一种针对传感器数据物联网系统的黑盒对抗攻击方法，通过动态触发器生成技术，在最小扰动下成功攻击多种数据集和分类器模型。


<details>
  <summary>Details</summary>
Motivation: 基于传感器数据的识别系统（如步态认证和人类活动识别）广泛应用，但深度学习模型存在安全风险，需要研究对抗攻击以揭示其脆弱性。

Method: 开发了新颖的动态触发器生成技术，用于对传感器数据物联网系统执行黑盒对抗攻击，并与现有后门攻击中的投毒技术进行性能比较。

Result: 经验分析表明，该攻击方法在多种数据集和分类器模型上均能成功，且对输入数据的扰动最小。

Conclusion: 讨论了对抗防御机制及其对触发器生成技术有效性的影响，强调了传感器数据系统面临的安全威胁。

Abstract: Sensor data-based recognition systems are widely used in various applications, such as gait-based authentication and human activity recognition (HAR). Modern wearable and smart devices feature various built-in Inertial Measurement Unit (IMU) sensors, and such sensor-based measurements can be fed to a machine learning-based model to train and classify human activities. While deep learning-based models have proven successful in classifying human activity and gestures, they pose various security risks. In our paper, we discuss a novel dynamic trigger-generation technique for performing black-box adversarial attacks on sensor data-based IoT systems. Our empirical analysis shows that the attack is successful on various datasets and classifier models with minimal perturbation on the input data. We also provide a detailed comparative analysis of performance and stealthiness to various other poisoning techniques found in backdoor attacks. We also discuss some adversarial defense mechanisms and their impact on the effectiveness of our trigger-generation technique.

</details>


### [12] [Resolving Availability and Run-time Integrity Conflicts in Real-Time Embedded Systems](https://arxiv.org/abs/2511.14088)
*Adam Caulfield,Muhammad Wasif Kamran,N. Asokan*

Main category: cs.CR

TL;DR: PAIR提出了一种在实时系统中平衡安全性和可用性的方法，通过硬件监控任务完整性违规，仅终止违规任务而保持其他任务继续执行。


<details>
  <summary>Details</summary>
Motivation: 现有实时系统在检测到完整性违规时面临两难选择：要么优先可用性让受感染系统继续运行，要么优先安全性中止所有执行。需要找到中间解决方案。

Method: PAIR监控实时任务的运行时完整性违规，维护安全任务可用区域(AR)。当任务违规时，触发不可屏蔽中断终止该任务，继续执行AR中的非违规任务。

Result: PAIR通过硬件方法实现，对执行任务不产生运行时开销，与实时操作系统集成，在内存和硬件使用上仅增加2.3%的开销。

Conclusion: PAIR在安全性和可用性之间提供了平衡的中间方案，仅阻止违规任务执行，同时保证其他任务的可用性，适用于低端微控制器单元。

Abstract: Run-time integrity enforcement in real-time systems presents a fundamental conflict with availability. Existing approaches in real- time systems primarily focus on minimizing the execution-time overhead of monitoring. After a violation is detected, prior works face a trade-off: (1) prioritize availability and allow a compromised system to continue to ensure applications meet their deadlines, or (2) prioritize security by generating a fault to abort all execution. In this work, we propose PAIR, an approach that offers a middle ground between the stark extremes of this trade-off. PAIR monitors real-time tasks for run-time integrity violations and maintains an Availability Region (AR) of all tasks that are safe to continue. When a task causes a violation, PAIR triggers a non-maskable interrupt to kill the task and continue executing a non-violating task within AR. Thus, PAIR ensures only violating tasks are prevented from execution, while granting availability to remaining tasks. With its hardware approach, PAIR does not cause any run-time overhead to the executing tasks, integrates with real-time operating systems (RTOSs), and is affordable to low-end microcontroller units (MCUs) by incurring +2.3% overhead in memory and hardware usage.

</details>


### [13] [MalRAG: A Retrieval-Augmented LLM Framework for Open-set Malicious Traffic Identification](https://arxiv.org/abs/2511.14129)
*Xiang Luo,Chang Liu,Gang Xiong,Chen Yang,Gaopeng Gou,Yaochen Ren,Zhen Li*

Main category: cs.CR

TL;DR: MalRAG是一个基于LLM的检索增强框架，用于开放集恶意流量识别，通过多视角流量知识构建、自适应检索和提示工程实现细粒度已知类别识别和新恶意流量发现。


<details>
  <summary>Details</summary>
Motivation: 现有的深度学习方法依赖特定任务架构，限制了可迁移性且需要针对每个数据集进行调整。网络安全威胁不断演变，发现新型恶意流量与识别已知类别同样重要。

Method: 构建多视角流量数据库（内容、结构、时间视角），引入覆盖率增强检索算法和流量感知自适应剪枝，开发集成任务指令、证据引用和决策指导的提示系统。

Result: 在多样化真实数据集和设置下，MalRAG在已知类别细粒度识别和新恶意流量发现方面均取得最先进的结果。

Conclusion: MalRAG有效利用LLM能力，在不依赖特定LLM的情况下实现开放集恶意流量识别，展示了良好的泛化性能。

Abstract: Fine-grained identification of IDS-flagged suspicious traffic is crucial in cybersecurity. In practice, cyber threats evolve continuously, making the discovery of novel malicious traffic a critical necessity as well as the identification of known classes. Recent studies have advanced this goal with deep models, but they often rely on task-specific architectures that limit transferability and require per-dataset tuning. In this paper we introduce MalRAG, the first LLM driven retrieval-augmented framework for open-set malicious traffic identification. MalRAG freezes the LLM and operates via comprehensive traffic knowledge construction, adaptive retrieval, and prompt engineering. Concretely, we construct a multi-view traffic database by mining prior malicious traffic from content, structural, and temporal perspectives. Furthermore, we introduce a Coverage-Enhanced Retrieval Algorithm that queries across these views to assemble the most probable candidates, thereby improving the inclusion of correct evidence. We then employ Traffic-Aware Adaptive Pruning to select a variable subset of these candidates based on traffic-aware similarity scores, suppressing incorrect matches and yielding reliable retrieved evidence. Moreover, we develop a suite of guidance prompts where task instruction, evidence referencing, and decision guidance are integrated with the retrieved evidence to improve LLM performance. Across diverse real-world datasets and settings, MalRAG delivers state-of-the-art results in both fine-grained identification of known classes and novel malicious traffic discovery. Ablation and deep-dive analyses further show that MalRAG effective leverages LLM capabilities yet achieves open-set malicious traffic identification without relying on a specific LLM.

</details>


### [14] [A Fuzzy Logic-Based Cryptographic Framework For Real-Time Dynamic Key Generation For Enhanced Data Encryption](https://arxiv.org/abs/2511.14132)
*Kavya Bhand,Payal Khubchandani,Jyoti Khubchandani*

Main category: cs.CR

TL;DR: 提出了一种基于模糊逻辑的加密框架，通过系统熵和硬件信任动态生成实时加密密钥，结合TPM和AES-GCM提供自适应加密方案。


<details>
  <summary>Details</summary>
Motivation: 静态密钥加密机制因其确定性和非自适应特性容易受到对抗攻击，面临暴力破解、密钥泄露和未授权访问等常见网络安全威胁。

Method: 使用模糊推理系统评估CPU利用率、进程数和时间戳变化等系统参数，基于模糊规则分配熵级别，与硬件生成的随机性融合，通过可信平台模块安全密封密钥，并集成到AES-GCM加密方案中。

Result: 开发了一个可扩展的自适应加密解决方案，适用于高保证计算、零信任环境和云基础设施。

Conclusion: 该研究提供了一种动态、自适应的加密方法，能够有效应对传统静态密钥加密的脆弱性，增强系统安全性。

Abstract: With the ever-growing demand for cybersecurity, static key encryption mechanisms are increasingly vulnerable to adversarial attacks due to their deterministic and non-adaptive nature. Brute-force attacks, key compromise, and unauthorized access have become highly common cyber threats. This research presents a novel fuzzy logic-based cryptographic framework that dynamically generates encryption keys in real-time by accessing system-level entropy and hardware-bound trust. The proposed system leverages a Fuzzy Inference System (FIS) to evaluate system parameters that include CPU utilization, process count, and timestamp variation. It assigns entropy level based on linguistically defined fuzzy rules which are fused with hardware-generated randomness and then securely sealed using a Trusted Platform Module (TPM). The sealed key is incorporated in an AES-GCM encryption scheme to ensure both confidentiality and integrity of the data. This system introduces a scalable solution for adaptive encryption in high-assurance computing, zero-trust environments, and cloud-based infrastructure.

</details>


### [15] [Beyond Fixed and Dynamic Prompts: Embedded Jailbreak Templates for Advancing LLM Security](https://arxiv.org/abs/2511.14140)
*Hajun Kim,Hyunsik Na,Daeseon Choi*

Main category: cs.CR

TL;DR: 提出嵌入式越狱模板，在现有模板结构中自然嵌入有害查询，通过渐进式提示工程确保模板质量和一致性，为红队测试和政策回归测试提供更准确的基准。


<details>
  <summary>Details</summary>
Motivation: 随着大型语言模型的广泛应用，确保其安全性和鲁棒性成为关键挑战。现有的越狱攻击方法主要依赖两种有限策略：将有害查询替换到固定模板中，或让LLM生成整个模板，但这会损害意图清晰度和可复现性。

Method: 引入嵌入式越狱模板，保留现有模板结构的同时在上下文中自然嵌入有害查询；提出渐进式提示工程方法确保模板质量和一致性；制定标准化的生成和评估协议。

Result: 提供了一个更准确反映真实世界使用场景和有害意图的基准，便于在红队测试和政策回归测试中应用。

Conclusion: 嵌入式越狱模板和渐进式提示工程方法有效解决了现有越狱攻击方法的局限性，为LLM安全测试提供了更可靠的基准工具。

Abstract: As the use of large language models (LLMs) continues to expand, ensuring their safety and robustness has become a critical challenge. In particular, jailbreak attacks that bypass built-in safety mechanisms are increasingly recognized as a tangible threat across industries, driving the need for diverse templates to support red-teaming efforts and strengthen defensive techniques. However, current approaches predominantly rely on two limited strategies: (i) substituting harmful queries into fixed templates, and (ii) having the LLM generate entire templates, which often compromises intent clarity and reproductibility. To address this gap, this paper introduces the Embedded Jailbreak Template, which preserves the structure of existing templates while naturally embedding harmful queries within their context. We further propose a progressive prompt-engineering methodology to ensure template quality and consistency, alongside standardized protocols for generation and evaluation. Together, these contributions provide a benchmark that more accurately reflects real-world usage scenarios and harmful intent, facilitating its application in red-teaming and policy regression testing.

</details>


### [16] [Steganographic Backdoor Attacks in NLP: Ultra-Low Poisoning and Defense Evasion](https://arxiv.org/abs/2511.14301)
*Eric Xue,Ruiyi Zhang,Zijun Zhang,Pengtao Xie*

Main category: cs.CR

TL;DR: SteganoBackdoor是一种新型后门攻击方法，利用自然语言隐写术将语义触发器转化为隐写载体，在极低数据投毒率下实现高攻击成功率，并能有效规避现有防御机制。


<details>
  <summary>Details</summary>
Motivation: 现有后门攻击研究过于关注风格化或令牌级扰动触发器，忽视了更现实和危险的语义触发器（如特定名称或实体），这种攻击在实际部署系统中可能操纵与真实人物或事件相关的输出。

Method: 利用自然语言隐写术的无害特性，通过梯度引导的数据优化过程将语义触发器种子转化为隐写载体，这些载体嵌入高后门载荷、保持流畅性，且与触发器没有表征相似性。

Result: 在多样化实验设置中，SteganoBackdoor以比先前方法低一个数量级的数据投毒率实现了超过99%的攻击成功率，同时在一整套数据级防御措施中保持无与伦比的规避能力。

Conclusion: SteganoBackdoor揭示了当前防御机制中的紧急盲点，迫切需要关注对抗性数据防御和现实世界威胁建模。

Abstract: Transformer models are foundational to natural language processing (NLP) applications, yet remain vulnerable to backdoor attacks introduced through poisoned data, which implant hidden behaviors during training. To strengthen the ability to prevent such compromises, recent research has focused on designing increasingly stealthy attacks to stress-test existing defenses, pairing backdoor behaviors with stylized artifact or token-level perturbation triggers. However, this trend diverts attention from the harder and more realistic case: making the model respond to semantic triggers such as specific names or entities, where a successful backdoor could manipulate outputs tied to real people or events in deployed systems. Motivated by this growing disconnect, we introduce SteganoBackdoor, bringing stealth techniques back into line with practical threat models. Leveraging innocuous properties from natural-language steganography, SteganoBackdoor applies a gradient-guided data optimization process to transform semantic trigger seeds into steganographic carriers that embed a high backdoor payload, remain fluent, and exhibit no representational resemblance to the trigger. Across diverse experimental settings, SteganoBackdoor achieves over 99% attack success at an order-of-magnitude lower data-poisoning rate than prior approaches while maintaining unparalleled evasion against a comprehensive suite of data-level defenses. By revealing this practical and covert attack, SteganoBackdoor highlights an urgent blind spot in current defenses and demands immediate attention to adversarial data defenses and real-world threat modeling.

</details>


### [17] [Sigil: Server-Enforced Watermarking in U-Shaped Split Federated Learning via Gradient Injection](https://arxiv.org/abs/2511.14422)
*Zhengchunmin Dai,Jiaxiong Tang,Peng Sun,Honglong Chen,Liantao Wu*

Main category: cs.CR

TL;DR: Sigil是一个为能力受限服务器设计的强制水印框架，通过在服务器可见的激活空间定义统计约束作为水印，并通过梯度注入嵌入到客户端模型中，无需数据知识。


<details>
  <summary>Details</summary>
Motivation: 在Split Federated Learning等去中心化机器学习范式中，服务器能力受限虽然增强了客户端隐私，但也使服务器容易受到恶意客户端的模型窃取，需要保护服务器的知识产权。

Method: 将水印定义为服务器可见激活空间的统计约束，通过梯度注入将水印嵌入客户端模型，设计了自适应梯度裁剪机制确保水印过程的强制性和隐蔽性。

Result: 在多个数据集和模型上的广泛实验证明了Sigil的保真度、鲁棒性和隐蔽性。

Conclusion: Sigil框架有效解决了能力受限服务器的知识产权保护问题，能够对抗现有的梯度异常检测方法和专门设计的自适应子空间移除攻击。

Abstract: In decentralized machine learning paradigms such as Split Federated Learning (SFL) and its variant U-shaped SFL, the server's capabilities are severely restricted. Although this enhances client-side privacy, it also leaves the server highly vulnerable to model theft by malicious clients. Ensuring intellectual property protection for such capability-limited servers presents a dual challenge: watermarking schemes that depend on client cooperation are unreliable in adversarial settings, whereas traditional server-side watermarking schemes are technically infeasible because the server lacks access to critical elements such as model parameters or labels.
  To address this challenge, this paper proposes Sigil, a mandatory watermarking framework designed specifically for capability-limited servers. Sigil defines the watermark as a statistical constraint on the server-visible activation space and embeds the watermark into the client model via gradient injection, without requiring any knowledge of the data. Besides, we design an adaptive gradient clipping mechanism to ensure that our watermarking process remains both mandatory and stealthy, effectively countering existing gradient anomaly detection methods and a specifically designed adaptive subspace removal attack. Extensive experiments on multiple datasets and models demonstrate Sigil's fidelity, robustness, and stealthiness.

</details>


### [18] [SecureSign: Bridging Security and UX in Mobile Web3 through Emulated EIP-6963 Sandboxing](https://arxiv.org/abs/2511.14611)
*Charles Cheng Ji,Brandon Kong*

Main category: cs.CR

TL;DR: SecureSign是一个PWA架构，通过EIP-6963提供商沙盒将桌面浏览器扩展安全性适配到移动端，解决了移动Web3应用的高流失率和安全漏洞问题。


<details>
  <summary>Details</summary>
Motivation: 移动Web3面临灾难性的用户留存率（<5%），导致每个留存用户的有效获取成本高达500-1000美元。现有解决方案存在两难选择：嵌入式钱包有中等可用性但存在固有的点击劫持漏洞；应用钱包保持安全性但会因下载摩擦和上下文切换惩罚导致2-3%的留存损失。

Method: SecureSign采用PWA架构，通过EIP-6963提供商沙盒将dApp执行隔离在可信父应用程序的iframe中，实现点击劫持免疫和交易完整性，同时支持原生移动功能（推送通知、主屏幕安装、零上下文切换）。

Result: 威胁模型分析表明，SecureSign对点击劫持、覆盖和窃取攻击具有免疫力，同时保持跨dApp的钱包互操作性。

Conclusion: SecureSign提供了一个无需现有Web3应用程序代码库更改的即插即用SDK，在保持安全性的同时解决了移动Web3应用的用户留存问题。

Abstract: Mobile Web3 faces catastrophic retention (< 5%) yielding effective acquisition costs of \$500 - \$1,000 per retained user. Existing solutions force an impossible tradeoff: embedded wallets achieve moderate usability but suffer inherent click-jacking vulnerabilities; app wallets maintain security at the cost of 2 - 3% retention due to download friction and context-switching penalties. We present SecureSign, a PWA-based architecture that adapts desktop browser extension security to mobile via EIP-6963 provider sandboxing. SecureSign isolates dApp execution in iframes within a trusted parent application, achieving click-jacking immunity and transaction integrity while enabling native mobile capabilities (push notifications, home screen installation, zero context-switching). Our drop-in SDK requires no codebase changes for existing Web3 applications. Threat model analysis demonstrates immunity to click-jacking, overlay, and skimming attacks while maintaining wallet interoperability across dApps.

</details>


### [19] [A Unified Compositional View of Attack Tree Metrics](https://arxiv.org/abs/2511.14717)
*Benedikt Peterseim,Milan Lopuhaä-Zwakenberg*

Main category: cs.CR

TL;DR: 本文通过基于gs-幺半范畴的组合理论，为攻击树及其函子语义提供了系统化的度量定义框架，解决了现有方法要么不够全面要么过于抽象的问题。


<details>
  <summary>Details</summary>
Motivation: 攻击树是复杂系统安全推理的流行图形模型，但现有的攻击树度量处理方法要么无法涵盖重要度量，要么过于抽象而无法提供定义具体度量的有用系统方法。

Method: 将攻击树视为字符串图，展示攻击树组件形成通道范畴（一种特殊的gs-幺半范畴），攻击树度量对应通道范畴的函子。

Result: 该特征化方法既足够通用以包含所有常见的攻击树度量，又足够具体以通过逻辑结构定义攻击树度量。

Conclusion: 基于gs-幺半范畴的组合理论为攻击树度量提供了系统化的定义框架，解决了现有方法的局限性。

Abstract: Attack trees (ATs) are popular graphical models for reasoning about the security of complex systems, allowing for the quantification of risk through so-called AT metrics. A large variety of different such AT metrics have been proposed, and despite their wide-spread practical use, no systematic treatment of attack tree metrics so far is fully satisfactory. Existing approaches either fail to include important metrics, or they are too general to provide a useful systematic way for defining concrete AT metrics, giving only an abstract characterisation of their behaviour. We solve this problem by developing a compositional theory of ATs and their functorial semantics based on gs-monoidal categories. Viewing attack trees as string diagrams, we show that components of ATs form a channel category, a particular type of gs-monoidal category. AT metrics then correspond to functors of channel categories. This characterisation is both general enough to include all common AT metrics, and concrete enough to define AT metrics by their logical structure.

</details>
