{"id": "2508.10991", "categories": ["cs.CR", "cs.AI"], "pdf": "https://arxiv.org/pdf/2508.10991", "abs": "https://arxiv.org/abs/2508.10991", "authors": ["Wenpeng Xing", "Zhonghao Qi", "Yupeng Qin", "Yilin Li", "Caini Chang", "Jiahui Yu", "Changting Lin", "Zhenzhen Xie", "Meng Han"], "title": "MCP-Guard: A Defense Framework for Model Context Protocol Integrity in Large Language Model Applications", "comment": null, "summary": "The integration of Large Language Models (LLMs) with external tools via\nprotocols such as the Model Context Protocol (MCP) introduces critical security\nvulnerabilities, including prompt injection, data exfiltration, and other\nthreats. To counter these challenges, we propose MCP-Guard, a robust, layered\ndefense architecture designed for LLM--tool interactions. MCP-Guard employs a\nthree-stage detection pipeline that balances efficiency with accuracy: it\nprogresses from lightweight static scanning for overt threats and a deep neural\ndetector for semantic attacks, to our fine-tuned E5-based model achieves\n(96.01) accuracy in identifying adversarial prompts. Finally, a lightweight LLM\narbitrator synthesizes these signals to deliver the final decision while\nminimizing false positives. To facilitate rigorous training and evaluation, we\nalso introduce MCP-AttackBench, a comprehensive benchmark of over 70,000\nsamples. Sourced from public datasets and augmented by GPT-4, MCP-AttackBench\nsimulates diverse, real-world attack vectors in the MCP format, providing a\nfoundation for future research into securing LLM-tool ecosystems."}
{"id": "2508.11082", "categories": ["cs.CR"], "pdf": "https://arxiv.org/pdf/2508.11082", "abs": "https://arxiv.org/abs/2508.11082", "authors": ["Sina Bagheri", "Masoud Kaveh", "Francisco Hernando-Gallego", "Diego Mart√≠n", "Nuria Serrano"], "title": "A Constant-Time Hardware Architecture for the CSIDH Key-Exchange Protocol", "comment": null, "summary": "The commutative supersingular isogeny Diffie-Hellman (CSIDH) algorithm is a\npromising post-quantum key exchange protocol, notable for its exceptionally\nsmall key sizes, but hindered by computationally intensive key generation.\nFurthermore, practical implementations must operate in constant time to\nmitigate side-channel vulnerabilities, which presents an additional performance\nchallenge. This paper presents, to our knowledge, the first comprehensive\nhardware study of CSIDH, establishing a performance baseline with a unified\narchitecture on both field-programmable gate array (FPGA) and\napplication-specific integrated circuit (ASIC) platforms. The architecture\nfeatures a top-level finite state machine (FSM) that orchestrates a deeply\npipelined arithmetic logic unit (ALU) to accelerate the underlying 512-bit\nfinite field operations. The ALU employs a parallelized schoolbook multiplier,\ncompleting a 512$\\times$512-bit multiplication in 22 clock cycles and enabling\na full Montgomery modular multiplication in 87 cycles. The constant-time\nCSIDH-512 design requires $1.03\\times10^{8}$ clock cycles per key generation.\nWhen implemented on a Xilinx Zynq UltraScale+ FPGA, the architecture achieves a\n200 MHz clock frequency, corresponding to a 515 ms latency. For ASIC\nimplementation in a 180nm process, the design requires $1.065\\times10^{8}$\nclock cycles and achieves a \\textasciitilde 180 MHz frequency, resulting in a\nkey generation latency of 591 ms. By providing the first public hardware\nperformance metrics for CSIDH on both FPGA and ASIC platforms, this work\ndelivers a crucial benchmark for future isogeny-based post-quantum cryptography\n(PQC) accelerators."}
{"id": "2508.11095", "categories": ["cs.CR"], "pdf": "https://arxiv.org/pdf/2508.11095", "abs": "https://arxiv.org/abs/2508.11095", "authors": ["Asra Ali", "Jaeho Choi", "Bryant Gipson", "Shruthi Gorantala", "Jeremy Kun", "Wouter Legiest", "Lawrence Lim", "Alexander Viand", "Meron Zerihun Demissie", "Hongren Zheng"], "title": "HEIR: A Universal Compiler for Homomorphic Encryption", "comment": null, "summary": "This work presents Homomorphic Encryption Intermediate Representation (HEIR),\na unified approach to building homomorphic encryption (HE) compilers. HEIR aims\nto support all mainstream techniques in homomorphic encryption, integrate with\nall major software libraries and hardware accelerators, and advance the field\nby providing a platform for research and benchmarking. Built on the MLIR\ncompiler framework, HEIR introduces HE-specific abstraction layers at which\nexisting optimizations and new research ideas may be easily implemented.\nAlthough many HE optimization techniques have been proposed, it remains\ndifficult to combine or compare them effectively. HEIR provides a means to\neffectively explore the space of HE optimizations. HEIR addresses the entire HE\nstack and includes support for various frontends, including Python. The\ncontribution of this work includes: (1) We introduce HEIR as a framework for\nbuilding HE compilers. (2) We validate HEIR's design by porting a large\nfraction of the HE literature to HEIR, and we argue that HEIR can tackle more\ncomplicated and diverse programs than prior literature. (3) We provide evidence\nthat HEIR is emerging as the de facto HE compiler for academic research and\nindustry development."}
{"id": "2508.11325", "categories": ["cs.CR"], "pdf": "https://arxiv.org/pdf/2508.11325", "abs": "https://arxiv.org/abs/2508.11325", "authors": ["Georgios Michail Makrakis", "Jeroen Pijpker", "Remco Hassing", "Rob Loves", "Stephen McCombie"], "title": "Salty Seagull: A VSAT Honeynet to Follow the Bread Crumb of Attacks in Ship Networks", "comment": null, "summary": "Cyber threats against the maritime industry have increased notably in recent\nyears, highlighting the need for innovative cybersecurity approaches. Ships, as\ncritical assets, possess highly specialized and interconnected network\ninfrastructures, where their legacy systems and operational constraints further\nexacerbate their vulnerability to cyberattacks. To better understand this\nevolving threat landscape, we propose the use of cyber-deception techniques and\nin particular honeynets, as a means to gather valuable insights into ongoing\nattack campaigns targeting the maritime sector.\n  In this paper we present Salty Seagull, a honeynet conceived to simulate a\nVSAT system for ships. This environment mimics the operations of a functional\nVSAT system onboard and, at the same time, enables a user to interact with it\nthrough a Web dashboard and a CLI environment. Furthermore, based on existing\nvulnerabilities, we purposefully integrate them into our system to increase\nattacker engagement. We exposed our honeynet for 30 days to the Internet to\nassess its capability and measured the received interaction. Results show that\nwhile numerous generic attacks have been attempted, only one curious attacker\nwith knowledge of the nature of the system and its vulnerabilities managed to\naccess it, without however exploring its full potential."}
{"id": "2508.11472", "categories": ["cs.CR", "cs.AI", "cs.LG"], "pdf": "https://arxiv.org/pdf/2508.11472", "abs": "https://arxiv.org/abs/2508.11472", "authors": ["Yang Wang", "Yaxin Zhao", "Xinyu Jiao", "Sihan Xu", "Xiangrui Cai", "Ying Zhang", "Xiaojie Yuan"], "title": "RMSL: Weakly-Supervised Insider Threat Detection with Robust Multi-sphere Learning", "comment": "15 pages", "summary": "Insider threat detection aims to identify malicious user behavior by\nanalyzing logs that record user interactions. Due to the lack of fine-grained\nbehavior-level annotations, detecting specific behavior-level anomalies within\nuser behavior sequences is challenging. Unsupervised methods face high false\npositive rates and miss rates due to the inherent ambiguity between normal and\nanomalous behaviors. In this work, we instead introduce weak labels of behavior\nsequences, which have lower annotation costs, i.e., the training labels\n(anomalous or normal) are at sequence-level instead of behavior-level, to\nenhance the detection capability for behavior-level anomalies by learning\ndiscriminative features. To achieve this, we propose a novel framework called\nRobust Multi-sphere Learning (RMSL). RMSL uses multiple hyper-spheres to\nrepresent the normal patterns of behaviors. Initially, a one-class classifier\nis constructed as a good anomaly-supervision-free starting point. Building on\nthis, using multiple instance learning and adaptive behavior-level\nself-training debiasing based on model prediction confidence, the framework\nfurther refines hyper-spheres and feature representations using weak\nsequence-level labels. This approach enhances the model's ability to\ndistinguish between normal and anomalous behaviors. Extensive experiments\ndemonstrate that RMSL significantly improves the performance of behavior-level\ninsider threat detection."}
{"id": "2508.11495", "categories": ["cs.CR"], "pdf": "https://arxiv.org/pdf/2508.11495", "abs": "https://arxiv.org/abs/2508.11495", "authors": ["Jingnan Xu", "Leixia Wang", "Xiaofeng Meng"], "title": "KV-Auditor: Auditing Local Differential Privacy for Correlated Key-Value Estimation", "comment": null, "summary": "To protect privacy for data-collection-based services, local differential\nprivacy (LDP) is widely adopted due to its rigorous theoretical bound on\nprivacy loss. However, mistakes in complex theoretical analysis or subtle\nimplementation errors may undermine its practical guarantee. To address this,\nauditing is crucial to confirm that LDP protocols truly protect user data.\nHowever, existing auditing methods, though, mainly target machine learning and\nfederated learning tasks based on centralized differentially privacy (DP), with\nlimited attention to LDP. Moreover, the few studies on LDP auditing focus\nsolely on simple frequency estimation task for discrete data, leaving\ncorrelated key-value data - which requires both discrete frequency estimation\nfor keys and continuous mean estimation for values - unexplored.\n  To bridge this gap, we propose KV-Auditor, a framework for auditing LDP-based\nkey-value estimation mechanisms by estimating their empirical privacy lower\nbounds. Rather than traditional LDP auditing methods that relies on binary\noutput predictions, KV-Auditor estimates this lower bound by analyzing\nunbounded output distributions, supporting continuous data. Specifically, we\nclassify state-of-the-art LDP key-value mechanisms into interactive and\nnon-interactive types. For non-interactive mechanisms, we propose horizontal\nKV-Auditor for small domains with sufficient samples and vertical KV-Auditor\nfor large domains with limited samples. For interactive mechanisms, we design a\nsegmentation strategy to capture incremental privacy leakage across iterations.\nFinally, we perform extensive experiments to validate the effectiveness of our\napproach, offering insights for optimizing LDP-based key-value estimators."}
{"id": "2508.11548", "categories": ["cs.CR"], "pdf": "https://arxiv.org/pdf/2508.11548", "abs": "https://arxiv.org/abs/2508.11548", "authors": ["Zhenhua Xu", "Xubin Yue", "Zhebo Wang", "Qichen Liu", "Xixiang Zhao", "Jingxuan Zhang", "Wenjun Zeng", "Wengpeng Xing", "Dezhang Kong", "Changting Lin", "Meng Han"], "title": "Copyright Protection for Large Language Models: A Survey of Methods, Challenges, and Trends", "comment": null, "summary": "Copyright protection for large language models is of critical importance,\ngiven their substantial development costs, proprietary value, and potential for\nmisuse. Existing surveys have predominantly focused on techniques for tracing\nLLM-generated content-namely, text watermarking-while a systematic exploration\nof methods for protecting the models themselves (i.e., model watermarking and\nmodel fingerprinting) remains absent. Moreover, the relationships and\ndistinctions among text watermarking, model watermarking, and model\nfingerprinting have not been comprehensively clarified. This work presents a\ncomprehensive survey of the current state of LLM copyright protection\ntechnologies, with a focus on model fingerprinting, covering the following\naspects: (1) clarifying the conceptual connection from text watermarking to\nmodel watermarking and fingerprinting, and adopting a unified terminology that\nincorporates model watermarking into the broader fingerprinting framework; (2)\nproviding an overview and comparison of diverse text watermarking techniques,\nhighlighting cases where such methods can function as model fingerprinting; (3)\nsystematically categorizing and comparing existing model fingerprinting\napproaches for LLM copyright protection; (4) presenting, for the first time,\ntechniques for fingerprint transfer and fingerprint removal; (5) summarizing\nevaluation metrics for model fingerprints, including effectiveness,\nharmlessness, robustness, stealthiness, and reliability; and (6) discussing\nopen challenges and future research directions. This survey aims to offer\nresearchers a thorough understanding of both text watermarking and model\nfingerprinting technologies in the era of LLMs, thereby fostering further\nadvances in protecting their intellectual property."}
{"id": "2508.11563", "categories": ["cs.CR"], "pdf": "https://arxiv.org/pdf/2508.11563", "abs": "https://arxiv.org/abs/2508.11563", "authors": ["Nathaniel Moyer", "Charalampos Papamanthou", "Evgenios Kornaropoulos"], "title": "Pushing the Limits of Frequency Analysis in Leakage Abuse Attacks", "comment": null, "summary": "Searchable encryption (SE) is the most scalable cryptographic primitive for\nsearching on encrypted data. Typical SE constructions often allow\naccess-pattern leakage, revealing which encrypted records are retrieved in the\nserver's responses. All the known generic cryptanalyses assume either that the\nqueries are issued uniformly at random or that the attacker observes the\nsearch-pattern leakage. It remains unclear what can be reconstructed when using\nonly the access-pattern leakage and knowledge of the query distribution. In\nthis work, we focus on the cryptanalytic technique of frequency analysis in the\ncontext of leakage-abuse attacks on schemes that support encrypted range\nqueries. Frequency analysis matches the frequency of retrieval of an encrypted\nrecord with a plaintext value based on its probability of retrieval that\nfollows from the knowledge of the query distribution. We generalize this\nunderexplored cryptanalytic technique and introduce a generic attack framework\ncalled Leakage-Abuse via Matching (LAMA) that works even on high-dimensional\nencrypted data. We identify a parameterization of LAMA that brings frequency\nanalysis to its limit -- that is, we prove that there is no additional\nfrequency matching that an attacker can perform to refine the result.\nFurthermore, we show that our results hold for any class of convex queries, and\nnot just axis-aligned rectangles, which is the assumption in all other attacks\non range schemes. Using these results, we identify query distributions that\nmake frequency analysis challenging for the attacker and, thus, can act as a\nmitigation mechanism. Finally, we implement and benchmark LAMA and reconstruct,\nfor the first time, plaintext data from encrypted range queries spanning up to\nfour dimensions."}
{"id": "2508.11575", "categories": ["cs.CR"], "pdf": "https://arxiv.org/pdf/2508.11575", "abs": "https://arxiv.org/abs/2508.11575", "authors": ["Nges Brian Njungle", "Michel A. Kinsy"], "title": "Activate Me!: Designing Efficient Activation Functions for Privacy-Preserving Machine Learning with Fully Homomorphic Encryption", "comment": null, "summary": "The growing adoption of machine learning in sensitive areas such as\nhealthcare and defense introduces significant privacy and security challenges.\nThese domains demand robust data protection, as models depend on large volumes\nof sensitive information for both training and inference. Fully Homomorphic\nEncryption (FHE) presents a compelling solution by enabling computations\ndirectly on encrypted data, maintaining confidentiality across the entire\nmachine learning workflow. However, FHE inherently supports only linear\noperations, making it difficult to implement non-linear activation functions,\nessential components of modern neural networks. This work focuses on designing,\nimplementing, and evaluating activation functions tailored for FHE-based\nmachine learning. We investigate two commonly used functions: the Square\nfunction and Rectified Linear Unit (ReLU), using LeNet-5 and ResNet-20\narchitectures with the CKKS scheme from the OpenFHE library. For ReLU, we\nassess two methods: a conventional low-degree polynomial approximation and a\nnovel scheme-switching technique that securely evaluates ReLU under FHE\nconstraints. Our findings show that the Square function performs well in\nshallow networks like LeNet-5, achieving 99.4% accuracy with 128 seconds per\nimage. In contrast, deeper models like ResNet-20 benefit more from ReLU. The\npolynomial approximation yields 83.8% accuracy with 1,145 seconds per image,\nwhile our scheme-switching method improves accuracy to 89.8%, albeit with a\nlonger inference time of 1,697 seconds. These results underscore a critical\ntrade-off in FHE-based ML: faster activation functions often reduce accuracy,\nwhereas those preserving accuracy demand greater computational resources."}
{"id": "2508.11599", "categories": ["cs.CR", "cs.AI"], "pdf": "https://arxiv.org/pdf/2508.11599", "abs": "https://arxiv.org/abs/2508.11599", "authors": ["Zhihao Li", "Zimo Ji", "Tao Zheng", "Hao Ren", "Xiao Lan"], "title": "CryptoScope: Utilizing Large Language Models for Automated Cryptographic Logic Vulnerability Detection", "comment": null, "summary": "Cryptographic algorithms are fundamental to modern security, yet their\nimplementations frequently harbor subtle logic flaws that are hard to detect.\nWe introduce CryptoScope, a novel framework for automated cryptographic\nvulnerability detection powered by Large Language Models (LLMs). CryptoScope\ncombines Chain-of-Thought (CoT) prompting with Retrieval-Augmented Generation\n(RAG), guided by a curated cryptographic knowledge base containing over 12,000\nentries. We evaluate CryptoScope on LLM-CLVA, a benchmark of 92 cases primarily\nderived from real-world CVE vulnerabilities, complemented by cryptographic\nchallenges from major Capture The Flag (CTF) competitions and synthetic\nexamples across 11 programming languages. CryptoScope consistently improves\nperformance over strong LLM baselines, boosting DeepSeek-V3 by 11.62%,\nGPT-4o-mini by 20.28%, and GLM-4-Flash by 28.69%. Additionally, it identifies 9\npreviously undisclosed flaws in widely used open-source cryptographic projects."}
