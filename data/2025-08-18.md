<div id=toc></div>

# Table of Contents

- [cs.CR](#cs.CR) [Total: 10]


<div id='cs.CR'></div>

# cs.CR [[Back]](#toc)

### [1] [MCP-Guard: A Defense Framework for Model Context Protocol Integrity in Large Language Model Applications](https://arxiv.org/abs/2508.10991)
*Wenpeng Xing,Zhonghao Qi,Yupeng Qin,Yilin Li,Caini Chang,Jiahui Yu,Changting Lin,Zhenzhen Xie,Meng Han*

Main category: cs.CR

TL;DR: 论文提出MCP-Guard，一种针对LLM与工具交互的分层防御架构，通过三阶段检测管道应对安全威胁，并引入MCP-AttackBench作为训练和评估基准。


<details>
  <summary>Details</summary>
Motivation: 大型语言模型（LLM）与外部工具集成时存在安全漏洞（如提示注入、数据泄露等），需要一种有效的防御机制。

Method: MCP-Guard采用三阶段检测管道：静态扫描、深度神经网络检测和轻量级LLM仲裁器，结合E5模型实现高精度检测。

Result: MCP-Guard在识别对抗性提示时达到96.01%的准确率，并引入包含70,000样本的MCP-AttackBench基准。

Conclusion: MCP-Guard为LLM-工具交互提供高效防御，MCP-AttackBench为未来研究奠定基础。

Abstract: The integration of Large Language Models (LLMs) with external tools via
protocols such as the Model Context Protocol (MCP) introduces critical security
vulnerabilities, including prompt injection, data exfiltration, and other
threats. To counter these challenges, we propose MCP-Guard, a robust, layered
defense architecture designed for LLM--tool interactions. MCP-Guard employs a
three-stage detection pipeline that balances efficiency with accuracy: it
progresses from lightweight static scanning for overt threats and a deep neural
detector for semantic attacks, to our fine-tuned E5-based model achieves
(96.01) accuracy in identifying adversarial prompts. Finally, a lightweight LLM
arbitrator synthesizes these signals to deliver the final decision while
minimizing false positives. To facilitate rigorous training and evaluation, we
also introduce MCP-AttackBench, a comprehensive benchmark of over 70,000
samples. Sourced from public datasets and augmented by GPT-4, MCP-AttackBench
simulates diverse, real-world attack vectors in the MCP format, providing a
foundation for future research into securing LLM-tool ecosystems.

</details>


### [2] [A Constant-Time Hardware Architecture for the CSIDH Key-Exchange Protocol](https://arxiv.org/abs/2508.11082)
*Sina Bagheri,Masoud Kaveh,Francisco Hernando-Gallego,Diego Martín,Nuria Serrano*

Main category: cs.CR

TL;DR: 本文首次全面研究了CSIDH算法的硬件实现，提出了统一的FPGA和ASIC架构，并提供了性能基准。


<details>
  <summary>Details</summary>
Motivation: CSIDH是一种有前景的后量子密钥交换协议，但存在计算密集型密钥生成和侧信道攻击的挑战，需要硬件加速和恒定时间实现。

Method: 设计了一个顶层有限状态机（FSM）协调深度流水线的算术逻辑单元（ALU），加速512位有限域运算，采用并行乘法器。

Result: 在FPGA上实现200 MHz频率，密钥生成延迟515 ms；ASIC实现180 MHz频率，延迟591 ms。

Conclusion: 本文为未来基于同源的后量子密码加速器提供了关键的性能基准。

Abstract: The commutative supersingular isogeny Diffie-Hellman (CSIDH) algorithm is a
promising post-quantum key exchange protocol, notable for its exceptionally
small key sizes, but hindered by computationally intensive key generation.
Furthermore, practical implementations must operate in constant time to
mitigate side-channel vulnerabilities, which presents an additional performance
challenge. This paper presents, to our knowledge, the first comprehensive
hardware study of CSIDH, establishing a performance baseline with a unified
architecture on both field-programmable gate array (FPGA) and
application-specific integrated circuit (ASIC) platforms. The architecture
features a top-level finite state machine (FSM) that orchestrates a deeply
pipelined arithmetic logic unit (ALU) to accelerate the underlying 512-bit
finite field operations. The ALU employs a parallelized schoolbook multiplier,
completing a 512$\times$512-bit multiplication in 22 clock cycles and enabling
a full Montgomery modular multiplication in 87 cycles. The constant-time
CSIDH-512 design requires $1.03\times10^{8}$ clock cycles per key generation.
When implemented on a Xilinx Zynq UltraScale+ FPGA, the architecture achieves a
200 MHz clock frequency, corresponding to a 515 ms latency. For ASIC
implementation in a 180nm process, the design requires $1.065\times10^{8}$
clock cycles and achieves a \textasciitilde 180 MHz frequency, resulting in a
key generation latency of 591 ms. By providing the first public hardware
performance metrics for CSIDH on both FPGA and ASIC platforms, this work
delivers a crucial benchmark for future isogeny-based post-quantum cryptography
(PQC) accelerators.

</details>


### [3] [HEIR: A Universal Compiler for Homomorphic Encryption](https://arxiv.org/abs/2508.11095)
*Asra Ali,Jaeho Choi,Bryant Gipson,Shruthi Gorantala,Jeremy Kun,Wouter Legiest,Lawrence Lim,Alexander Viand,Meron Zerihun Demissie,Hongren Zheng*

Main category: cs.CR

TL;DR: HEIR是一个统一的同态加密（HE）编译器框架，旨在支持主流HE技术、集成软件库和硬件加速器，并提供研究和基准测试平台。


<details>
  <summary>Details</summary>
Motivation: 解决同态加密优化技术难以结合或比较的问题，提供一个统一的平台支持研究和开发。

Method: 基于MLIR编译器框架，引入HE特定抽象层，支持多种前端（如Python）和优化技术。

Result: 成功将大量HE文献移植到HEIR，证明其能处理更复杂多样的程序，并成为学术和工业界的实际标准。

Conclusion: HEIR是一个有效的HE编译器框架，推动了同态加密领域的研究和应用。

Abstract: This work presents Homomorphic Encryption Intermediate Representation (HEIR),
a unified approach to building homomorphic encryption (HE) compilers. HEIR aims
to support all mainstream techniques in homomorphic encryption, integrate with
all major software libraries and hardware accelerators, and advance the field
by providing a platform for research and benchmarking. Built on the MLIR
compiler framework, HEIR introduces HE-specific abstraction layers at which
existing optimizations and new research ideas may be easily implemented.
Although many HE optimization techniques have been proposed, it remains
difficult to combine or compare them effectively. HEIR provides a means to
effectively explore the space of HE optimizations. HEIR addresses the entire HE
stack and includes support for various frontends, including Python. The
contribution of this work includes: (1) We introduce HEIR as a framework for
building HE compilers. (2) We validate HEIR's design by porting a large
fraction of the HE literature to HEIR, and we argue that HEIR can tackle more
complicated and diverse programs than prior literature. (3) We provide evidence
that HEIR is emerging as the de facto HE compiler for academic research and
industry development.

</details>


### [4] [Salty Seagull: A VSAT Honeynet to Follow the Bread Crumb of Attacks in Ship Networks](https://arxiv.org/abs/2508.11325)
*Georgios Michail Makrakis,Jeroen Pijpker,Remco Hassing,Rob Loves,Stephen McCombie*

Main category: cs.CR

TL;DR: 论文提出了一种针对海事行业的网络安全方法，使用蜜网技术（Salty Seagull）模拟船舶VSAT系统，以收集攻击数据。实验显示，尽管有大量通用攻击尝试，但仅有一名了解系统的攻击者成功访问。


<details>
  <summary>Details</summary>
Motivation: 海事行业面临日益增长的网络安全威胁，传统系统和操作限制加剧了其脆弱性，需要创新方法来理解攻击行为。

Method: 设计了名为Salty Seagull的蜜网，模拟船舶VSAT系统，并通过Web仪表盘和CLI环境吸引攻击者。系统故意集成已知漏洞以增加攻击者互动。

Result: 在30天的实验中，蜜网吸引了大量通用攻击尝试，但仅有一名了解系统的攻击者成功访问，但未深入探索系统。

Conclusion: 蜜网技术可用于海事行业网络安全研究，但需进一步优化以提高攻击者互动和数据分析效果。

Abstract: Cyber threats against the maritime industry have increased notably in recent
years, highlighting the need for innovative cybersecurity approaches. Ships, as
critical assets, possess highly specialized and interconnected network
infrastructures, where their legacy systems and operational constraints further
exacerbate their vulnerability to cyberattacks. To better understand this
evolving threat landscape, we propose the use of cyber-deception techniques and
in particular honeynets, as a means to gather valuable insights into ongoing
attack campaigns targeting the maritime sector.
  In this paper we present Salty Seagull, a honeynet conceived to simulate a
VSAT system for ships. This environment mimics the operations of a functional
VSAT system onboard and, at the same time, enables a user to interact with it
through a Web dashboard and a CLI environment. Furthermore, based on existing
vulnerabilities, we purposefully integrate them into our system to increase
attacker engagement. We exposed our honeynet for 30 days to the Internet to
assess its capability and measured the received interaction. Results show that
while numerous generic attacks have been attempted, only one curious attacker
with knowledge of the nature of the system and its vulnerabilities managed to
access it, without however exploring its full potential.

</details>


### [5] [RMSL: Weakly-Supervised Insider Threat Detection with Robust Multi-sphere Learning](https://arxiv.org/abs/2508.11472)
*Yang Wang,Yaxin Zhao,Xinyu Jiao,Sihan Xu,Xiangrui Cai,Ying Zhang,Xiaojie Yuan*

Main category: cs.CR

TL;DR: 论文提出了一种基于弱标签的鲁棒多球学习框架（RMSL），用于提升行为级内部威胁检测的性能。


<details>
  <summary>Details</summary>
Motivation: 由于缺乏细粒度的行为级标注，现有方法在检测用户行为序列中的异常时面临高误报率和漏检率。

Method: 引入序列级弱标签，提出RMSL框架，通过多球学习、多实例学习和自适应行为级自训练去偏来优化特征表示。

Result: 实验表明，RMSL显著提升了行为级内部威胁检测的性能。

Conclusion: RMSL通过弱标签和鲁棒学习框架，有效解决了行为级异常检测的挑战。

Abstract: Insider threat detection aims to identify malicious user behavior by
analyzing logs that record user interactions. Due to the lack of fine-grained
behavior-level annotations, detecting specific behavior-level anomalies within
user behavior sequences is challenging. Unsupervised methods face high false
positive rates and miss rates due to the inherent ambiguity between normal and
anomalous behaviors. In this work, we instead introduce weak labels of behavior
sequences, which have lower annotation costs, i.e., the training labels
(anomalous or normal) are at sequence-level instead of behavior-level, to
enhance the detection capability for behavior-level anomalies by learning
discriminative features. To achieve this, we propose a novel framework called
Robust Multi-sphere Learning (RMSL). RMSL uses multiple hyper-spheres to
represent the normal patterns of behaviors. Initially, a one-class classifier
is constructed as a good anomaly-supervision-free starting point. Building on
this, using multiple instance learning and adaptive behavior-level
self-training debiasing based on model prediction confidence, the framework
further refines hyper-spheres and feature representations using weak
sequence-level labels. This approach enhances the model's ability to
distinguish between normal and anomalous behaviors. Extensive experiments
demonstrate that RMSL significantly improves the performance of behavior-level
insider threat detection.

</details>


### [6] [KV-Auditor: Auditing Local Differential Privacy for Correlated Key-Value Estimation](https://arxiv.org/abs/2508.11495)
*Jingnan Xu,Leixia Wang,Xiaofeng Meng*

Main category: cs.CR

TL;DR: KV-Auditor框架填补了本地差分隐私（LDP）审计在键值数据上的空白，通过分析无界输出分布估计隐私下界，支持连续数据。


<details>
  <summary>Details</summary>
Motivation: 现有LDP审计方法主要针对离散数据的频率估计，缺乏对键值数据的支持，KV-Auditor旨在解决这一问题。

Method: 提出KV-Auditor框架，分类LDP键值机制为交互式和非交互式，分别设计水平和垂直审计方法，以及分段策略。

Result: 实验验证了KV-Auditor的有效性，为优化LDP键值估计器提供了见解。

Conclusion: KV-Auditor为LDP键值数据审计提供了有效工具，填补了现有研究的空白。

Abstract: To protect privacy for data-collection-based services, local differential
privacy (LDP) is widely adopted due to its rigorous theoretical bound on
privacy loss. However, mistakes in complex theoretical analysis or subtle
implementation errors may undermine its practical guarantee. To address this,
auditing is crucial to confirm that LDP protocols truly protect user data.
However, existing auditing methods, though, mainly target machine learning and
federated learning tasks based on centralized differentially privacy (DP), with
limited attention to LDP. Moreover, the few studies on LDP auditing focus
solely on simple frequency estimation task for discrete data, leaving
correlated key-value data - which requires both discrete frequency estimation
for keys and continuous mean estimation for values - unexplored.
  To bridge this gap, we propose KV-Auditor, a framework for auditing LDP-based
key-value estimation mechanisms by estimating their empirical privacy lower
bounds. Rather than traditional LDP auditing methods that relies on binary
output predictions, KV-Auditor estimates this lower bound by analyzing
unbounded output distributions, supporting continuous data. Specifically, we
classify state-of-the-art LDP key-value mechanisms into interactive and
non-interactive types. For non-interactive mechanisms, we propose horizontal
KV-Auditor for small domains with sufficient samples and vertical KV-Auditor
for large domains with limited samples. For interactive mechanisms, we design a
segmentation strategy to capture incremental privacy leakage across iterations.
Finally, we perform extensive experiments to validate the effectiveness of our
approach, offering insights for optimizing LDP-based key-value estimators.

</details>


### [7] [Copyright Protection for Large Language Models: A Survey of Methods, Challenges, and Trends](https://arxiv.org/abs/2508.11548)
*Zhenhua Xu,Xubin Yue,Zhebo Wang,Qichen Liu,Xixiang Zhao,Jingxuan Zhang,Wenjun Zeng,Wengpeng Xing,Dezhang Kong,Changting Lin,Meng Han*

Main category: cs.CR

TL;DR: 本文综述了大语言模型（LLM）版权保护技术，重点探讨了模型指纹识别，包括概念澄清、技术分类、指纹转移与移除方法、评估指标及未来研究方向。


<details>
  <summary>Details</summary>
Motivation: 鉴于LLM的高开发成本、专有价值及潜在滥用风险，其版权保护至关重要。现有研究多关注文本水印，缺乏对模型水印与指纹识别的系统探讨。

Method: 通过概念澄清、技术分类、案例分析与比较，系统梳理了文本水印与模型指纹识别技术，并首次提出指纹转移与移除方法。

Result: 总结了模型指纹的评估指标（有效性、无害性、鲁棒性、隐蔽性、可靠性），并探讨了技术挑战与未来方向。

Conclusion: 本文为研究者提供了对LLM版权保护技术的全面理解，推动了相关领域的知识产权保护研究。

Abstract: Copyright protection for large language models is of critical importance,
given their substantial development costs, proprietary value, and potential for
misuse. Existing surveys have predominantly focused on techniques for tracing
LLM-generated content-namely, text watermarking-while a systematic exploration
of methods for protecting the models themselves (i.e., model watermarking and
model fingerprinting) remains absent. Moreover, the relationships and
distinctions among text watermarking, model watermarking, and model
fingerprinting have not been comprehensively clarified. This work presents a
comprehensive survey of the current state of LLM copyright protection
technologies, with a focus on model fingerprinting, covering the following
aspects: (1) clarifying the conceptual connection from text watermarking to
model watermarking and fingerprinting, and adopting a unified terminology that
incorporates model watermarking into the broader fingerprinting framework; (2)
providing an overview and comparison of diverse text watermarking techniques,
highlighting cases where such methods can function as model fingerprinting; (3)
systematically categorizing and comparing existing model fingerprinting
approaches for LLM copyright protection; (4) presenting, for the first time,
techniques for fingerprint transfer and fingerprint removal; (5) summarizing
evaluation metrics for model fingerprints, including effectiveness,
harmlessness, robustness, stealthiness, and reliability; and (6) discussing
open challenges and future research directions. This survey aims to offer
researchers a thorough understanding of both text watermarking and model
fingerprinting technologies in the era of LLMs, thereby fostering further
advances in protecting their intellectual property.

</details>


### [8] [Pushing the Limits of Frequency Analysis in Leakage Abuse Attacks](https://arxiv.org/abs/2508.11563)
*Nathaniel Moyer,Charalampos Papamanthou,Evgenios Kornaropoulos*

Main category: cs.CR

TL;DR: 论文提出了一种名为LAMA的通用攻击框架，利用频率分析技术对支持加密范围查询的方案进行泄漏滥用攻击，并证明了其在多维数据上的有效性。


<details>
  <summary>Details</summary>
Motivation: 研究在仅使用访问模式泄漏和查询分布知识的情况下，如何重构加密数据，填补了现有研究的空白。

Method: 提出LAMA框架，通过频率匹配技术分析加密记录的检索频率与明文值的概率关系，并扩展到高维数据和凸查询类。

Result: 证明了LAMA在频率分析中的极限性能，并首次实现了对四维加密范围查询的明文数据重构。

Conclusion: LAMA为泄漏滥用攻击提供了通用解决方案，同时提出了缓解此类攻击的查询分布策略。

Abstract: Searchable encryption (SE) is the most scalable cryptographic primitive for
searching on encrypted data. Typical SE constructions often allow
access-pattern leakage, revealing which encrypted records are retrieved in the
server's responses. All the known generic cryptanalyses assume either that the
queries are issued uniformly at random or that the attacker observes the
search-pattern leakage. It remains unclear what can be reconstructed when using
only the access-pattern leakage and knowledge of the query distribution. In
this work, we focus on the cryptanalytic technique of frequency analysis in the
context of leakage-abuse attacks on schemes that support encrypted range
queries. Frequency analysis matches the frequency of retrieval of an encrypted
record with a plaintext value based on its probability of retrieval that
follows from the knowledge of the query distribution. We generalize this
underexplored cryptanalytic technique and introduce a generic attack framework
called Leakage-Abuse via Matching (LAMA) that works even on high-dimensional
encrypted data. We identify a parameterization of LAMA that brings frequency
analysis to its limit -- that is, we prove that there is no additional
frequency matching that an attacker can perform to refine the result.
Furthermore, we show that our results hold for any class of convex queries, and
not just axis-aligned rectangles, which is the assumption in all other attacks
on range schemes. Using these results, we identify query distributions that
make frequency analysis challenging for the attacker and, thus, can act as a
mitigation mechanism. Finally, we implement and benchmark LAMA and reconstruct,
for the first time, plaintext data from encrypted range queries spanning up to
four dimensions.

</details>


### [9] [Activate Me!: Designing Efficient Activation Functions for Privacy-Preserving Machine Learning with Fully Homomorphic Encryption](https://arxiv.org/abs/2508.11575)
*Nges Brian Njungle,Michel A. Kinsy*

Main category: cs.CR

TL;DR: 论文探讨了在FHE（全同态加密）环境下为机器学习设计激活函数的方法，比较了Square和ReLU函数在不同网络中的表现，揭示了速度与精度的权衡。


<details>
  <summary>Details</summary>
Motivation: 随着机器学习在敏感领域（如医疗和国防）的应用增加，数据隐私和安全成为关键问题。FHE能直接在加密数据上计算，但仅支持线性操作，难以实现非线性的激活函数。

Method: 研究设计了两种激活函数（Square和ReLU），在LeNet-5和ResNet-20架构中使用CKKS方案测试。ReLU采用多项式近似和新颖的方案切换技术。

Result: Square在浅层网络（LeNet-5）表现优异（99.4%准确率，128秒/图），而ReLU更适合深层网络（ResNet-20）。方案切换技术提高了ReLU的准确率（89.8%），但耗时更长（1,697秒/图）。

Conclusion: FHE-based ML存在速度与精度的权衡：快速激活函数可能降低准确率，而高准确率函数需要更多计算资源。

Abstract: The growing adoption of machine learning in sensitive areas such as
healthcare and defense introduces significant privacy and security challenges.
These domains demand robust data protection, as models depend on large volumes
of sensitive information for both training and inference. Fully Homomorphic
Encryption (FHE) presents a compelling solution by enabling computations
directly on encrypted data, maintaining confidentiality across the entire
machine learning workflow. However, FHE inherently supports only linear
operations, making it difficult to implement non-linear activation functions,
essential components of modern neural networks. This work focuses on designing,
implementing, and evaluating activation functions tailored for FHE-based
machine learning. We investigate two commonly used functions: the Square
function and Rectified Linear Unit (ReLU), using LeNet-5 and ResNet-20
architectures with the CKKS scheme from the OpenFHE library. For ReLU, we
assess two methods: a conventional low-degree polynomial approximation and a
novel scheme-switching technique that securely evaluates ReLU under FHE
constraints. Our findings show that the Square function performs well in
shallow networks like LeNet-5, achieving 99.4% accuracy with 128 seconds per
image. In contrast, deeper models like ResNet-20 benefit more from ReLU. The
polynomial approximation yields 83.8% accuracy with 1,145 seconds per image,
while our scheme-switching method improves accuracy to 89.8%, albeit with a
longer inference time of 1,697 seconds. These results underscore a critical
trade-off in FHE-based ML: faster activation functions often reduce accuracy,
whereas those preserving accuracy demand greater computational resources.

</details>


### [10] [CryptoScope: Utilizing Large Language Models for Automated Cryptographic Logic Vulnerability Detection](https://arxiv.org/abs/2508.11599)
*Zhihao Li,Zimo Ji,Tao Zheng,Hao Ren,Xiao Lan*

Main category: cs.CR

TL;DR: CryptoScope是一个基于大型语言模型（LLM）的自动化加密漏洞检测框架，结合了Chain-of-Thought提示和检索增强生成（RAG），在多个基准测试中显著提升了性能，并发现了开源加密项目中的新漏洞。


<details>
  <summary>Details</summary>
Motivation: 加密算法的实现常存在难以检测的逻辑漏洞，需要一种自动化工具来提高漏洞检测的准确性和效率。

Method: CryptoScope结合Chain-of-Thought提示和检索增强生成（RAG），利用包含12,000条条目的加密知识库。

Result: 在LLM-CLVA基准测试中，CryptoScope显著提升了多个LLM模型的性能，并发现了9个开源加密项目中的新漏洞。

Conclusion: CryptoScope展示了LLM在加密漏洞检测中的潜力，能够有效提升检测性能并发现新漏洞。

Abstract: Cryptographic algorithms are fundamental to modern security, yet their
implementations frequently harbor subtle logic flaws that are hard to detect.
We introduce CryptoScope, a novel framework for automated cryptographic
vulnerability detection powered by Large Language Models (LLMs). CryptoScope
combines Chain-of-Thought (CoT) prompting with Retrieval-Augmented Generation
(RAG), guided by a curated cryptographic knowledge base containing over 12,000
entries. We evaluate CryptoScope on LLM-CLVA, a benchmark of 92 cases primarily
derived from real-world CVE vulnerabilities, complemented by cryptographic
challenges from major Capture The Flag (CTF) competitions and synthetic
examples across 11 programming languages. CryptoScope consistently improves
performance over strong LLM baselines, boosting DeepSeek-V3 by 11.62%,
GPT-4o-mini by 20.28%, and GLM-4-Flash by 28.69%. Additionally, it identifies 9
previously undisclosed flaws in widely used open-source cryptographic projects.

</details>
