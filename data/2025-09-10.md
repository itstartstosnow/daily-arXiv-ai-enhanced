<div id=toc></div>

# Table of Contents

- [cs.CR](#cs.CR) [Total: 21]


<div id='cs.CR'></div>

# cs.CR [[Back]](#toc)

### [1] [Random Forest Stratified K-Fold Cross Validation on SYN DoS Attack SD-IoV](https://arxiv.org/abs/2509.07016)
*Muhammad Arif Hakimi Zamrai,Kamaludin Mohd Yusof*

Main category: cs.CR

TL;DR: 使用优化的随机森林分类器在SD-IoV网络中高效检测TCP SYN流量攻击，达到0.999998的平均准确率和0.24秒的检测时间


<details>
  <summary>Details</summary>
Motivation: 解决软件定义车联网(SD-IoV)中TCP SYN流量攻击的网络安全挑战，提升车辆通信系统的安全性

Method: 预处理包含SYN攻击的数据集，采用特征缩放和标签编码技术，应用层化K折交叉验证，优化随机森林模型（20个估计器，深度10）

Result: 实现了平均0.999998的准确率、精确率、召回率和F1分数，SYN DoS攻击检测时间仅0.24秒

Conclusion: 该方法在检测SYN流量攻击方面实现了重大进展，给车联网络安全提供了高准确率、高效率的解决方案

Abstract: In response to the prevalent concern of TCP SYN flood attacks within the
context of Software-Defined Internet of Vehicles (SD-IoV), this study addresses
the significant challenge of network security in rapidly evolving vehicular
communication systems. This research focuses on optimizing a Random Forest
Classifier model to achieve maximum accuracy and minimal detection time,
thereby enhancing vehicular network security. The methodology involves
preprocessing a dataset containing SYN attack instances, employing feature
scaling and label encoding techniques, and applying Stratified K-Fold
cross-validation to target key metrics such as accuracy, precision, recall, and
F1-score. This research achieved an average value of 0.999998 for all metrics
with a SYN DoS attack detection time of 0.24 seconds. Results show that the
fine-tuned Random Forest model, configured with 20 estimators and a depth of
10, effectively differentiates between normal and malicious traffic with high
accuracy and minimal detection time, which is crucial for SD-IoV networks. This
approach marks a significant advancement and introduces a state-of-the-art
algorithm in detecting SYN flood attacks, combining high accuracy with minimal
detection time. It contributes to vehicular network security by providing a
robust solution against TCP SYN flood attacks while maintaining network
efficiency and reliability.

</details>


### [2] [The Signalgate Case is Waiving a Red Flag to All Organizational and Behavioral Cybersecurity Leaders, Practitioners, and Researchers: Are We Receiving the Signal Amidst the Noise?](https://arxiv.org/abs/2509.07053)
*Paul Benjamin Lowry,Gregory D. Moody,Robert Willison,Clay Posey*

Main category: cs.CR

TL;DR: 2025年Signalgate事件分析：美国高级官员通过Signal平台意外泄露军事机密，揭示了组织安全中人为错误、治理漏洞和技术误用的关键脆弱性，强调需要从技术防御转向治理、文化和行为风险的综合策略。


<details>
  <summary>Details</summary>
Motivation: 分析Signalgate事件以揭示组织安全中经常被外部网络威胁所掩盖的人为中心脆弱性和治理挑战，强调人为因素在安全中的核心作用。

Method: 采用案例研究和基于NIST网络安全框架的系统性回顾方法，分析事件模式，识别人为中心脆弱性和治理挑战的共同模式。

Result: 发现三个关键点：(1)组织安全高度依赖人类行为，内部人员是最薄弱环节；(2)领导层态度强烈影响安全文化和效能；(3)过度依赖技术解决方案而忽视人力组织因素导致无效实践和资源浪费。

Conclusion: 提出可操作建议：加强领导参与、全面采用零信任架构、明确责任结构、激励安全行为和严格监督，特别是在组织转型期间需要额外措施，呼吁重新调整网络安全策略以应对治理、文化和行为风险。

Abstract: The Signalgate incident of March 2025, wherein senior US national security
officials inadvertently disclosed sensitive military operational details via
the encrypted messaging platform Signal, highlights critical vulnerabilities in
organizational security arising from human error, governance gaps, and the
misuse of technology. Although smaller in scale when compared to historical
breaches involving billions of records, Signalgate illustrates critical
systemic issues often overshadowed by a focus on external cyber threats.
Employing a case-study approach and systematic review grounded in the NIST
Cybersecurity Framework, we analyze the incident to identify patterns of
human-centric vulnerabilities and governance challenges common to
organizational security failures. Findings emphasize three critical points. (1)
Organizational security depends heavily on human behavior, with internal actors
often serving as the weakest link despite advanced technical defenses; (2)
Leadership tone strongly influences organizational security culture and
efficacy, and (3) widespread reliance on technical solutions without sufficient
investments in human and organizational factors leads to ineffective practices
and wasted resources. From these observations, we propose actionable
recommendations for enhancing organizational and national security, including
strong leadership engagement, comprehensive adoption of zero-trust
architectures, clearer accountability structures, incentivized security
behaviors, and rigorous oversight. Particularly during periods of
organizational transition, such as mergers or large-scale personnel changes,
additional measures become particularly important. Signalgate underscores the
need for leaders and policymakers to reorient cybersecurity strategies toward
addressing governance, cultural, and behavioral risks.

</details>


### [3] [Sequentially Auditing Differential Privacy](https://arxiv.org/abs/2509.07055)
*Tomás González,Mateo Dulce-Rubio,Aaditya Ramdas,Mónica Ribero*

Main category: cs.CR

TL;DR: 式验黑盒机制差分隐私保证的实用序列测试方法，可以在任何时间点进行统计推断且控制I类错误，样本需求量减少了数个数量级。


<details>
  <summary>Details</summary>
Motivation: 克服以往批量审计方法的固定样本量限制，提供一种更灵活和高效的差分隐私验证方法。

Method: 式验黑盒机制输出流的序列测试方法，支持任何时间有效的统计推断，同时严格控制I类错误概率。

Result: 实验结果显示，该测试方法需要的样本量比现有方法减少了数个数量级（从5万个减到几百个），并能在不到一次训练过程中识别DP-SGD隐私违规问题。

Conclusion: 该序列测试方法为差分隐私审计提供了一种实用、高效的解决方案，显著提升了隐私保证验证的效率和可行性。

Abstract: We propose a practical sequential test for auditing differential privacy
guarantees of black-box mechanisms. The test processes streams of mechanisms'
outputs providing anytime-valid inference while controlling Type I error,
overcoming the fixed sample size limitation of previous batch auditing methods.
Experiments show this test detects violations with sample sizes that are orders
of magnitude smaller than existing methods, reducing this number from 50K to a
few hundred examples, across diverse realistic mechanisms. Notably, it
identifies DP-SGD privacy violations in \textit{under} one training run, unlike
prior methods needing full model training.

</details>


### [4] [SoK: Security and Privacy of AI Agents for Blockchain](https://arxiv.org/abs/2509.07131)
*Nicolò Romandini,Carlo Mazzocca,Kai Otsuki,Rebecca Montanari*

Main category: cs.CR

TL;DR: 本文是第一篇专注于AI智能体与区块链交叉领域的系统化知识综述，特别关注安全与隐私维度，填补了现有文献的空白。


<details>
  <summary>Details</summary>
Motivation: 区块链和智能合约作为Web3基础技术仍存在使用复杂性，AI智能体可帮助非专家用户交互，但缺乏专门针对AI智能体与区块链交叉领域的系统性综述。

Method: 采用系统化知识整理方法，全面调研AI驱动系统在区块链领域的应用，特别关注安全隐私维度。

Result: 系统梳理了AI智能体在区块链数据分析、交易策略优化、智能合约漏洞检测等任务中的应用现状、局限性和挑战。

Conclusion: 该研究为AI与区块链交叉领域提供了首个系统性框架，指明了未来研究方向，特别是在安全隐私保护方面的重要价值。

Abstract: Blockchain and smart contracts have garnered significant interest in recent
years as the foundation of a decentralized, trustless digital ecosystem,
thereby eliminating the need for traditional centralized authorities. Despite
their central role in powering Web3, their complexity still presents
significant barriers for non-expert users. To bridge this gap, Artificial
Intelligence (AI)-based agents have emerged as valuable tools for interacting
with blockchain environments, supporting a range of tasks, from analyzing
on-chain data and optimizing transaction strategies to detecting
vulnerabilities within smart contracts. While interest in applying AI to
blockchain is growing, the literature still lacks a comprehensive survey that
focuses specifically on the intersection with AI agents. Most of the related
work only provides general considerations, without focusing on any specific
domain. This paper addresses this gap by presenting the first Systematization
of Knowledge dedicated to AI-driven systems for blockchain, with a special
focus on their security and privacy dimensions, shedding light on their
applications, limitations, and future research directions.

</details>


### [5] [All You Need Is A Fuzzing Brain: An LLM-Powered System for Automated Vulnerability Detection and Patching](https://arxiv.org/abs/2509.07225)
*Ze Sheng,Qingxiao Xu,Jianwei Huang,Matthew Woodcock,Heqing Huang,Alastair F. Donaldson,Guofei Gu,Jeff Huang*

Main category: cs.CR

TL;DR: 团队在DARPA AIxCC竞赛中开发了基于LLM的网络安全系统，发现了28个漏洞（含6个零日漏洞）并成功修补了14个，同时建立了漏洞检测和修补的公开排行榜。


<details>
  <summary>Details</summary>
Motivation: 参加DARPA人工智能网络挑战赛(AIxCC)，开发能够自主发现和修补安全漏洞的网络安全推理系统(CRS)，推动AI在网络安全领域的应用。

Method: 开发基于大语言模型(LLM)的网络安全推理系统，结合模糊测试技术，对真实世界的开源C和Java项目进行漏洞检测和自动修补。

Result: 系统成功发现了28个安全漏洞（包括6个先前未知的零日漏洞），并成功修补了其中的14个漏洞，在AIxCC决赛中获得第四名。

Conclusion: 证明了LLM在网络安全漏洞检测和修补方面的有效性，建立了公开的基准测试平台来持续评估最先进的LLM在漏洞相关任务上的性能。

Abstract: Our team, All You Need Is A Fuzzing Brain, was one of seven finalists in
DARPA's Artificial Intelligence Cyber Challenge (AIxCC), placing fourth in the
final round. During the competition, we developed a Cyber Reasoning System
(CRS) that autonomously discovered 28 security vulnerabilities - including six
previously unknown zero-days - in real-world open-source C and Java projects,
and successfully patched 14 of them. The complete CRS is open source at
https://github.com/o2lab/afc-crs-all-you-need-is-a-fuzzing-brain. This paper
provides a detailed technical description of our CRS, with an emphasis on its
LLM-powered components and strategies. Building on AIxCC, we further introduce
a public leaderboard for benchmarking state-of-the-art LLMs on vulnerability
detection and patching tasks, derived from the AIxCC dataset. The leaderboard
is available at https://o2lab.github.io/FuzzingBrain-Leaderboard/.

</details>


### [6] [Paladin: Defending LLM-enabled Phishing Emails with a New Trigger-Tag Paradigm](https://arxiv.org/abs/2509.07287)
*Yan Pang,Wenlong Meng,Xiaojing Liao,Tianhao Wang*

Main category: cs.CR

TL;DR: 提出了Paladin方法，通过在普通LLM中嵌入触发-标签关联，使模型在生成钓鱼内容时自动插入可检测标签，实现高效钓鱼内容检测


<details>
  <summary>Details</summary>
Motivation: 随着大语言模型的快速发展，其被恶意用于生成钓鱼内容的威胁日益严重。现有检测方法难以可靠识别LLM生成的钓鱼邮件，且基于LLM的检测方法计算成本高、部署困难

Method: Paladin方法通过多种插入策略将触发-标签关联嵌入到普通LLM中，创建工具化LLM。当生成钓鱼相关内容时，模型会自动包含可检测标签，基于隐式和显式触发器和标签设计了四种不同场景

Result: 实验结果表明该方法在隐蔽性、有效性和鲁棒性三个方面均优于基线方法，在所有场景下检测准确率超过90%

Conclusion: Paladin方法为解决LLM生成钓鱼内容的检测问题提供了有效解决方案，具有高检测准确率和实际部署的可行性

Abstract: With the rapid development of large language models, the potential threat of
their malicious use, particularly in generating phishing content, is becoming
increasingly prevalent. Leveraging the capabilities of LLMs, malicious users
can synthesize phishing emails that are free from spelling mistakes and other
easily detectable features. Furthermore, such models can generate
topic-specific phishing messages, tailoring content to the target domain and
increasing the likelihood of success.
  Detecting such content remains a significant challenge, as LLM-generated
phishing emails often lack clear or distinguishable linguistic features. As a
result, most existing semantic-level detection approaches struggle to identify
them reliably. While certain LLM-based detection methods have shown promise,
they suffer from high computational costs and are constrained by the
performance of the underlying language model, making them impractical for
large-scale deployment.
  In this work, we aim to address this issue. We propose Paladin, which embeds
trigger-tag associations into vanilla LLM using various insertion strategies,
creating them into instrumented LLMs. When an instrumented LLM generates
content related to phishing, it will automatically include detectable tags,
enabling easier identification. Based on the design on implicit and explicit
triggers and tags, we consider four distinct scenarios in our work. We evaluate
our method from three key perspectives: stealthiness, effectiveness, and
robustness, and compare it with existing baseline methods. Experimental results
show that our method outperforms the baselines, achieving over 90% detection
accuracy across all scenarios.

</details>


### [7] [zkUnlearner: A Zero-Knowledge Framework for Verifiable Unlearning with Multi-Granularity and Forgery-Resistance](https://arxiv.org/abs/2509.07290)
*Nan Wang,Nan Wu,Xiangyu Hui,Jiafan Wang,Xin Yuan*

Main category: cs.CR

TL;DR: zkUnlearner是首个支持多粒度和防伪造的可验证机器学习遗忘零知识框架，通过位掩码技术实现样本级、特征级和类别级遗忘，并能抵抗梯度伪造攻击。


<details>
  <summary>Details</summary>
Motivation: 随着"被遗忘权"需求增长，需要可验证的机器学习遗忘机制来确保透明度和问责制，现有方法在效率和隐私方面存在局限且易受伪造攻击。

Method: 提出基于位掩码技术的通用计算模型，支持选择性零知识训练证明，可转换为算术电路兼容多种零知识证明系统；同时设计有效策略抵抗最先进的伪造攻击。

Result: 实现了首个支持多粒度遗忘的零知识框架，能够抵抗梯度伪造攻击，并通过zkSNARK实例化验证了其实用性和性能。

Conclusion: zkUnlearner为可验证机器学习遗忘提供了高效、隐私保护且防伪造的解决方案，支持多种遗忘粒度，具有实际应用价值。

Abstract: As the demand for exercising the "right to be forgotten" grows, the need for
verifiable machine unlearning has become increasingly evident to ensure both
transparency and accountability. We present {\em zkUnlearner}, the first
zero-knowledge framework for verifiable machine unlearning, specifically
designed to support {\em multi-granularity} and {\em forgery-resistance}.
  First, we propose a general computational model that employs a {\em
bit-masking} technique to enable the {\em selectivity} of existing
zero-knowledge proofs of training for gradient descent algorithms. This
innovation enables not only traditional {\em sample-level} unlearning but also
more advanced {\em feature-level} and {\em class-level} unlearning. Our model
can be translated to arithmetic circuits, ensuring compatibility with a broad
range of zero-knowledge proof systems. Furthermore, our approach overcomes key
limitations of existing methods in both efficiency and privacy. Second, forging
attacks present a serious threat to the reliability of unlearning.
Specifically, in Stochastic Gradient Descent optimization, gradients from
unlearned data, or from minibatches containing it, can be forged using
alternative data samples or minibatches that exclude it. We propose the first
effective strategies to resist state-of-the-art forging attacks. Finally, we
benchmark a zkSNARK-based instantiation of our framework and perform
comprehensive performance evaluations to validate its practicality.

</details>


### [8] [SafeToolBench: Pioneering a Prospective Benchmark to Evaluating Tool Utilization Safety in LLMs](https://arxiv.org/abs/2509.07315)
*Hongfei Xia,Hongru Wang,Zeming Liu,Qian Yu,Yuhang Guo,Haifeng Wang*

Main category: cs.CR

TL;DR: SafeToolBench是首个前瞻性评估LLM工具使用安全性的基准，覆盖恶意指令和多样化工具集。SafeInstructTool框架从用户指令、工具本身、指令-工具联合三个维度提升LLM的安全意识。


<details>
  <summary>Details</summary>
Motivation: LLM在自主调用外部工具时存在财务损失和隐私泄露等风险，现有研究主要进行事后评估，需要前瞻性方法来避免不可逆的损害。

Method: 提出SafeToolBench基准和SafeInstructTool框架，从用户指令、工具本身、指令-工具联合三个维度（共9个详细维度）增强LLM的工具使用安全意识。

Result: 实验显示现有方法无法捕捉所有工具使用风险，而该框架显著提升了LLM的自我安全意识，实现更安全可信的工具利用。

Conclusion: 该研究提供了前瞻性的工具安全评估方法和框架，能够有效提升LLM在工具调用过程中的安全性和可信度。

Abstract: Large Language Models (LLMs) have exhibited great performance in autonomously
calling various tools in external environments, leading to better problem
solving and task automation capabilities. However, these external tools also
amplify potential risks such as financial loss or privacy leakage with
ambiguous or malicious user instructions. Compared to previous studies, which
mainly assess the safety awareness of LLMs after obtaining the tool execution
results (i.e., retrospective evaluation), this paper focuses on prospective
ways to assess the safety of LLM tool utilization, aiming to avoid irreversible
harm caused by directly executing tools. To this end, we propose SafeToolBench,
the first benchmark to comprehensively assess tool utilization security in a
prospective manner, covering malicious user instructions and diverse practical
toolsets. Additionally, we propose a novel framework, SafeInstructTool, which
aims to enhance LLMs' awareness of tool utilization security from three
perspectives (i.e., \textit{User Instruction, Tool Itself, and Joint
Instruction-Tool}), leading to nine detailed dimensions in total. We experiment
with four LLMs using different methods, revealing that existing approaches fail
to capture all risks in tool utilization. In contrast, our framework
significantly enhances LLMs' self-awareness, enabling a more safe and
trustworthy tool utilization.

</details>


### [9] [A Decade-long Landscape of Advanced Persistent Threats: Longitudinal Analysis and Global Trends](https://arxiv.org/abs/2509.07457)
*Shakhzod Yuldoshkhujaev,Mijin Jeon,Doowon Kim,Nick Nikiforakis,Hyungjoon Koo*

Main category: cs.CR

TL;DR: 通过系统分析全球14-23年间的1,509份APT报告，识别全球603个APT组织，揭示了全球指向性攻击的历史演变趋势咈关联性


<details>
  <summary>Details</summary>
Motivation: 之前研究多关注APT具体方面，缺乏对分散文档的纵向综合分析，本研究旨在提供宏观视角度分析历史APT攻击的全球趋势

Method: 采用混合方法，结合规则基础信息检索和大语言模型搜索技术，系统分析来自3个技术报告源和3个威胁行动者源的1,509份APT报告，涵盖24,215页

Result: 识别51603个唯一APT组织，154个国家受影响；恶意文档和射鱼邮件为主要洗入手段；2016年以来零日漏洞利用明显减少；发现网络攻击与选举、战争等重大事件的关联性

Conclusion: 通过长期纵向分析揭示了APT攻击的演变模式和全球趋势，并提供了交互式可视化工具以便直观理解APT活动的全球模式和趋势

Abstract: An advanced persistent threat (APT) refers to a covert, long-term
cyberattack, typically conducted by state-sponsored actors, targeting critical
sectors and often remaining undetected for long periods. In response,
collective intelligence from around the globe collaborates to identify and
trace surreptitious activities, generating substantial documentation on APT
campaigns publicly available on the web. While prior works predominantly focus
on specific aspects of APT cases, such as detection, evaluation, cyber threat
intelligence, and dataset creation, limited attention has been devoted to
revisiting and investigating these scattered dossiers in a longitudinal manner.
The objective of our study is to fill the gap by offering a macro perspective,
connecting key insights and global trends in past APT attacks. We
systematically analyze six reliable sources-three focused on technical reports
and another three on threat actors-examining 1,509 APT dossiers (24,215 pages)
spanning 2014-2023, and identifying 603 unique APT groups worldwide. To
efficiently unearth relevant information, we employ a hybrid methodology that
combines rule-based information retrieval with large-language-model-based
search techniques. Our longitudinal analysis reveals shifts in threat actor
activities, global attack vectors, changes in targeted sectors, and
relationships between cyberattacks and significant events such as elections or
wars, which provide insights into historical patterns in APT evolution. Over
the past decade, 154 countries have been affected, primarily using malicious
documents and spear phishing as dominant initial infiltration vectors, with a
noticeable decline in zero-day exploitation since 2016. Furthermore, we present
our findings through interactive visualization tools, such as an APT map or
flow diagram, to facilitate intuitive understanding of global patterns and
trends in APT activities.

</details>


### [10] [Biometric Bound Credentials for Age Verification](https://arxiv.org/abs/2509.07465)
*Norman Poh,Daryl Burns*

Main category: cs.CR

TL;DR: BBCreds是一种隐私保护的年龄验证方法，通过密码学将年龄凭证与生物特征绑定，无需存储生物模板，确保只有合法用户在物理在场时才能访问年龄限制服务。


<details>
  <summary>Details</summary>
Motivation: 年龄验证对于法规合规、用户信任和保护未成年人日益重要，但传统方案存在准确性差、侵入性强、安全风险高等问题，且当前更关注隐私、监控、公平性和系统透明度需求。

Method: 提出Biometric Bound Credentials (BBCreds)方法，通过密码学技术将年龄凭证与个人生物特征绑定，但不存储生物模板本身。

Result: 该方法确保只有合法且物理在场的用户才能访问年龄限制服务，防止凭证共享，同时解决了传统和新兴的年龄验证挑战。

Conclusion: BBCreds提供了一种隐私保护、安全可靠的年龄验证解决方案，能够有效应对当前年龄验证系统中的各种挑战。

Abstract: Age verification is increasingly critical for regulatory compliance, user
trust, and the protection of minors online. Historically, solutions have
struggled with poor accuracy, intrusiveness, and significant security risks.
More recently, concerns have shifted toward privacy, surveillance, fairness,
and the need for transparent, trustworthy systems. In this paper, we propose
Biometric Bound Credentials (BBCreds) as a privacy-preserving approach that
cryptographically binds age credentials to an individual's biometric features
without storing biometric templates. This ensures only the legitimate,
physically present user can access age-restricted services, prevents credential
sharing, and addresses both legacy and emerging challenges in age verification.
enhances privacy.

</details>


### [11] [Backdoor Attacks and Defenses in Computer Vision Domain: A Survey](https://arxiv.org/abs/2509.07504)
*Bilal Hussain Abbasi,Yanjun Zhang,Leo Zhang,Shang Gao*

Main category: cs.CR

TL;DR: 这篇论文是关于计算机视觉领域后门攻击与防御的综述性研究，提出了多维分类法来组织攻击和防御方法，分析了不同攻击类型的有效性以及防御措施的局限性。


<details>
  <summary>Details</summary>
Motivation: 随着机器学习模型在关键应用中的广泛部署，后门攻击已成为严重的安全威胁。需要系统性地梳理和分析计算机视觉领域的后门攻击与防御技术，为研究者和实践者提供全面的威胁态势认知和研究方向指导。

Method: 采用多维分类法，从注入阶段、触发器类型、标签策略、表示阶段和目标任务五个维度对后门攻击和防御方法进行分类和系统分析。总结了代表性方法，评估实践，并分析防御措施的成功与失败情况。

Result: 研究发现经典的后门检测和逆向工程工具对可重用补丁攻击有效，但在应对输入感知、样本特定或参数空间后门攻击以及通过受损预训练编码器或硬件位翻转的传输攻击时效果有限。

Conclusion: 论文提出了实用的威胁感知评估和分层防御指南，指出了供应链和硬件威胁、可验证防御、跨任务基准等持续存在的差距，为计算机视觉安全研究提供了重要的方向性指导。

Abstract: Backdoor (trojan) attacks embed hidden, controllable behaviors into
machine-learning models so that models behave normally on benign inputs but
produce attacker-chosen outputs when a trigger is present. This survey reviews
the rapidly growing literature on backdoor attacks and defenses in the
computer-vision domain. We introduce a multi-dimensional taxonomy that
organizes attacks and defenses by injection stage (dataset poisoning,
model/parameter modification, inference-time injection), trigger type (patch,
blended/frequency, semantic, transformation), labeling strategy (dirty-label
vs. clean-label / feature-collision), representation stage (instance-specific,
manifold/class-level, neuron/parameter hijacking, distributed encodings), and
target task (classification, detection, segmentation, video, multimodal). For
each axis we summarize representative methods, highlight evaluation practices,
and discuss where defenses succeed or fail. For example, many classical
sanitization and reverse-engineering tools are effective against reusable patch
attacks but struggle with input-aware, sample-specific, or parameter-space
backdoors and with transfer via compromised pre-trained encoders or hardware
bit-flips. We synthesize trends, identify persistent gaps (supply-chain and
hardware threats, certifiable defenses, cross-task benchmarks), and propose
practical guidelines for threat-aware evaluation and layered defenses. This
survey aims to orient researchers and practitioners to the current threat
landscape and pressing research directions in secure computer vision.

</details>


### [12] [Extension of Spatial k-Anonymity: New Metrics for Assessing the Anonymity of Geomasked Data Considering Realistic Attack Scenarios](https://arxiv.org/abs/2509.07505)
*Simon Cremer,Lydia Jehmlich,Rainer Lenz*

Main category: cs.CR

TL;DR: 这篇论文分析了地理区域数据隐私保护问题，指出当前空间k-匿名性指标的不足，并提出了更全面的数据攻击场景分类和匿名性评估指标。


<details>
  <summary>Details</summary>
Motivation: 地理空间健康数据在医学研究中越来越重要，但因为法律数据保护规定而受限制使用。虽然地理隐蔽技术能保护数据隐私，但当前的匿名性评估指标存在显著缺陷。

Method: 论文对匿名化地理微观数据的潜在数据攻击场景进行了分类，并引入了适合的指标来进行全面的匿名性评估。

Result: 研究提出了一套更全面的匿名性评估方法，能够更好地适应实际数据攻击场景的需求。

Conclusion: 需要更加全面的匿名性评估方法来应对地理区域数据隐私保护的挑战，新提出的指标体系能够更有效地保证数据的分析有效性和隐私安全性。

Abstract: Spatial data are gaining increasing importance in many areas of research.
Particularly spatial health data are becoming increasingly important for
medical research, for example, to better understand relationships between
environmental factors and disease patterns. However, their use is often
restricted by legal data protection regulations, since georeferenced personal
information carries a high risk of re-identification of individuals. To address
this issue, what are called geomasking methods are applied to guarantee data
protection through targeted displacement of individual data points, while
simultaneously maintaining analytical validity within a tolerable range. In the
current literature the degree of anonymity of such anonymized georeferenced
datasets is often measured by the so-called metric of spatial k-anonymity.
However, this metric has considerable shortcomings, particularly regarding its
resilience against realistic data attack scenarios. This article classifies the
potential data attack scenarios in the context of anonymized georeferenced
microdata and introduces appropriate metrics that enable a comprehensive
assessment of anonymity adapted to potential data attack scenarios.

</details>


### [13] [Enhanced cast-128 with adaptive s-box optimization via neural networks for image protection](https://arxiv.org/abs/2509.07606)
*Fadhil Abbas Fadhil,Maryam Mahdi Alhusseini,Mohammad-Reza Feizi-Derakhshi*

Main category: cs.CR

TL;DR: 基于混沌Logistic正弦映射的动态S箱生成策略，改进CAST-128算法的图像加密性能


<details>
  <summary>Details</summary>
Motivation: 解决传统动态S箱模型容易受到线性和差分攻击的问题，提高图像加密的效率和智能化需求

Method: 使用Logistic正弦映射(LSM)混沌系统生成动态、非线性、可逆的S箱，并嵌入CAST-128结构进行分块图像加密

Result: 通过权密、NPCR、UACI、PSNR和直方图分析评估，显示随机性、统计攻击抵御能力和加密质量明显提升

Conclusion: 该方法提供了一种轻量级的混沌驱动S箱生成方案，可在不使用机器学习的情况下提高图像加密的强猛性，适用于安全通信、监控系统和医学图像保护

Abstract: An improved CAST-128 encryption algorithm, which is done by implementing
chaos-based adaptive S-box generation using Logistic sine Map (LSM), has been
provided in this paper because of the increasing requirements of efficient and
smart image encryption mechanisms. The study aims to address the drawbacks of
static S-box models commonly used in traditional cryptographic systems, which
are susceptible to linear and differential attacks. In the proposed scheme, the
dynamic, non-linear, invertible, and highly cryptographic strength S-boxes are
generated through a hybrid chaotic system that may have high non-linearity,
strong and rigorous avalanche characteristics, and low differential uniformity.
The process here is that the LSM is used to produce S-boxes having
key-dependent parameters that are stuffed into the CAST-128 structure to
encrypt the image in a block-wise manner. The performance of the encryption is
assessed utilizing a set of standard grayscale images. The metrics that are
used to evaluate the security are entropy, NPCR, UACI, PSNR, and histogram
analysis. Outcomes indicate that randomness, resistance to statistical attacks,
and country of encryption are significantly improved compared to the original
CAST-128. The study is theoretically and practically relevant since it presents
a lightweight S-box generation approach driven by chaos, which can increase the
level of robustness of the image encryptions without enlisting machine
learning. The system may be applied to secure communications, surveillance
systems, and medical image protection on a real-time basis.

</details>


### [14] [FlexEmu: Towards Flexible MCU Peripheral Emulation (Extended Version)](https://arxiv.org/abs/2509.07615)
*Chongqing Lei,Zhen Ling,Xiangyu Xu,Shaofeng Li,Guangchi Liu,Kai Dong,Junzhou Luo*

Main category: cs.CR

TL;DR: FlexEmu是一个灵活的MCU外设仿真框架，通过两级建模方法自动生成外设仿真器，解决了MCU固件动态安全分析的执行环境问题，在90个固件样本上达到98.48%的单元测试通过率，并发现了10个未知漏洞。


<details>
  <summary>Details</summary>
Motivation: MCU固件安全分析面临执行环境缺乏的挑战，现有动态分析无法在物理设备上运行，而构建仿真器成本高昂，特别是针对大量异构外设硬件。

Method: 采用两级建模方法：结构层面使用有限原语抽象外设硬件概念，语义层面使用统一语义模型描述同类外设功能。FlexEmu框架自动提取外设细节来实例化模型并生成仿真器。

Result: 成功建模12种MCU外设，在15个不同MCU平台的90个固件样本上，自动生成的仿真器能够忠实复制硬件行为，达到98.48%的单元测试通过率，优于现有方法。通过模糊测试发现3个流行RTOS中的10个未知漏洞。

Conclusion: FlexEmu提供了一种有效解决MCU外设仿真挑战的方法，通过自动化建模和仿真器生成，显著提升了MCU固件动态安全分析的能力，为嵌入式系统安全研究提供了重要工具。

Abstract: Microcontroller units (MCUs) are widely used in embedded devices due to their
low power consumption and cost-effectiveness. MCU firmware controls these
devices and is vital to the security of embedded systems. However, performing
dynamic security analyses for MCU firmware has remained challenging due to the
lack of usable execution environments -- existing dynamic analyses cannot run
on physical devices (e.g., insufficient computational resources), while
building emulators is costly due to the massive amount of heterogeneous
hardware, especially peripherals.
  Our work is based on the insight that MCU peripherals can be modeled in a
two-fold manner. At the structural level, peripherals have diverse
implementations but we can use a limited set of primitives to abstract
peripherals because their hardware implementations are based on common hardware
concepts. At the semantic level, peripherals have diverse functionalities.
However, we can use a single unified semantic model to describe the same kind
of peripherals because they exhibit similar functionalities. Building on this,
we propose FlexEmu, a flexible MCU peripheral emulation framework. Once
semantic models are created, FlexEmu automatically extracts peripheral-specific
details to instantiate models and generate emulators accordingly. We have
successfully applied FlexEmu to model 12 kinds of MCU peripherals. Our
evaluation on 90 firmware samples across 15 different MCU platforms shows that
the automatically generated emulators can faithfully replicate hardware
behaviors and achieve a 98.48% unit test passing rate, outperforming
state-of-the-art approaches. To demonstrate the implications of FlexEmu on
firmware security, we use the generated emulators to fuzz three popular RTOSes
and uncover 10 previously unknown bugs.

</details>


### [15] [Embedded Off-Switches for AI Compute](https://arxiv.org/abs/2509.07637)
*James Petrie*

Main category: cs.CR

TL;DR: 通过在AI加速器中嵌入千个独立的硬件安全块，提供公钥加密验证和防止重放攻击的硬件级别关闭开关机制


<details>
  <summary>Details</summary>
Motivation: 应对日益强大的AI系统带来的风险，防止未授权芯片使用和高级别物理攻击

Method: 设计使用公钥加密术检查授权许可证真实性，通过随机生成的nonce防止重放攻击，采用标准电路组件以保证与现有半导体制造过程兼容

Result: 构建了大量冗余安全块架构，能够有效防御未授权芯片使用，并提供了更多安全块变体以增强稳健性

Conclusion: 嵌入式安全坘能够使下一代AI加速器更加稳固地防御危险滥用

Abstract: To address the risks of increasingly capable AI systems, we introduce a
hardware-level off-switch that embeds thousands of independent "security
blocks" in each AI accelerator. This massively redundant architecture is
designed to prevent unauthorized chip use, even against sophisticated physical
attacks. Our main security block design uses public key cryptography to check
the authenticity of authorization licenses, and randomly generated nonces to
prevent replay attacks. We evaluate attack vectors and present additional
security block variants that could be added for greater robustness. Security
blocks can be built with standard circuit components, ensuring compatibility
with existing semiconductor manufacturing processes. With embedded security
blocks, the next generation of AI accelerators could be more robustly defended
against dangerous misuse.

</details>


### [16] [Leveraging Digital Twin-as-a-Service Towards Continuous and Automated Cybersecurity Certification](https://arxiv.org/abs/2509.07649)
*Ioannis Koufos,Abdul Rehman Qureshi,Adrian Asensio,Allen Abishek,Efstathios Zaragkas,Ricard Vilalta,Maria Souvalioti,George Xilouris,Michael-Alexandros Kourtis*

Main category: cs.CR

TL;DR: 基于数字双胞技术的安全合规服务SDT-aaS，提供自动化、非侵入式的实时安全评估解决方案


<details>
  <summary>Details</summary>
Motivation: 传统风险评估依靠手工审计和系统扫描，容易造成运营中断并留下安全漏洞

Method: 利用数字双胞技术镜像实际资产，收集合规工件，创建机器可读证据，支持CycloneDX和Web of Things开政标准

Result: 中等规模基础设施用例的实证结果证明了其可行性和性能表现

Conclusion: SDT-aaS为高效、按需的网络安全治理开启了新路径，最小化运营影响

Abstract: Traditional risk assessments rely on manual audits and system scans, often
causing operational disruptions and leaving security gaps. To address these
challenges, this work presents Security Digital Twin-as-a-Service (SDT-aaS), a
novel approach that leverages Digital Twin (DT) technology for automated,
non-intrusive security compliance. SDT-aaS enables real-time security
assessments by mirroring real-world assets, collecting compliance artifacts,
and creating machine-readable evidence. The proposed work is a scalable and
interoperable solution that supports open standards like CycloneDX and Web of
Things (WoT), facilitating seamless integration and efficient compliance
management. Empirical results from a moderate-scale infrastructure use case
demonstrate its feasibility and performance, paving the way for efficient,
on-demand cybersecurity governance with minimal operational impact.

</details>


### [17] [Empirical Security Analysis of Software-based Fault Isolation through Controlled Fault Injection](https://arxiv.org/abs/2509.07757)
*Nils Bars,Lukas Bernhard,Moritz Schloegel,Thorsten Holz*

Main category: cs.CR

TL;DR: 这篇论文提出了一种新的测试技术，用于测试现代JavaScript引擎中软件隔离机制的安全性，并在V8引擎中发现19个可能绕过堆沙箱的安全漏洞。


<details>
  <summary>Details</summary>
Motivation: 现代浏览器通过JavaScript引擎处理来自未知源的脚本，构成了重要的安全边界。虽然Google V8堆沙箱作为广泛部署的软件隔离机制保护了数十亿用户，但这类安全机制缺乏充分的安全测试。

Method: 研究者建立了一种模型现代SFI实现安全边界的测试技术。假设攻击者完全控制沙箱内存，通过对信任域中来自不可信沙箱内存的内存读取进行仪器化，然后注入故障来尝试触发信任域中的内存污染。

Result: 在全面的评估中，识别出V8引擎中768个安全漏洞，其中19个可以让攻击者绕过沙箱保护。

Conclusion: 这项研究显示了现代SFI机制存在重要的安全漏洞，并提供了一种有效的测试方法来发现这些漏洞，对提升浏览器安全性具有重要意义。

Abstract: We use browsers daily to access all sorts of information. Because browsers
routinely process scripts, media, and executable code from unknown sources,
they form a critical security boundary between users and adversaries. A common
attack vector is JavaScript, which exposes a large attack surface due to the
sheer complexity of modern JavaScript engines. To mitigate these threats,
modern engines increasingly adopt software-based fault isolation (SFI). A
prominent example is Google's V8 heap sandbox, which represents the most widely
deployed SFI mechanism, protecting billions of users across all Chromium-based
browsers and countless applications built on Node.js and Electron. The heap
sandbox splits the address space into two parts: one part containing trusted,
security-sensitive metadata, and a sandboxed heap containing memory accessible
to untrusted code. On a technical level, the sandbox enforces isolation by
removing raw pointers and using translation tables to resolve references to
trusted objects. Consequently, an attacker cannot corrupt trusted data even
with full control of the sandboxed data, unless there is a bug in how code
handles data from the sandboxed heap. Despite their widespread use, such SFI
mechanisms have seen little security testing.
  In this work, we propose a new testing technique that models the security
boundary of modern SFI implementations. Following the SFI threat model, we
assume a powerful attacker who fully controls the sandbox's memory. We
implement this by instrumenting memory loads originating in the trusted domain
and accessing untrusted, attacker-controlled sandbox memory. We then inject
faults into the loaded data, aiming to trigger memory corruption in the trusted
domain. In a comprehensive evaluation, we identify 19 security bugs in V8 that
enable an attacker to bypass the sandbox.

</details>


### [18] [AgentSentinel: An End-to-End and Real-Time Security Defense Framework for Computer-Use Agents](https://arxiv.org/abs/2509.07764)
*Haitao Hu,Peng Chen,Yanpeng Zhao,Yuqi Chen*

Main category: cs.CR

TL;DR: AgentSentinel是一个端到端的实时防御框架，用于保护LLM驱动的计算机使用代理免受安全威胁，通过拦截敏感操作并进行安全审计，在基准测试中达到79.6%的平均防御成功率。


<details>
  <summary>Details</summary>
Motivation: LLM集成到计算机使用代理中可能发出意外的工具命令或错误输入，导致有害操作，这些由LLM驱动决策产生的工具执行结果带来了新的独特安全挑战。

Method: 提出AgentSentinel框架，拦截代理相关服务中的所有敏感操作，在完成全面安全审计前暂停执行。安全审计机制引入新颖的检查流程，将当前任务上下文与任务执行期间生成的系统跟踪相关联。

Result: 在BadComputerUse基准测试（包含60个攻击场景）上，AgentSentilin达到79.6%的平均防御成功率，显著优于所有基线防御方法。基准测试显示四个最先进LLM的平均攻击成功率为87%。

Conclusion: AgentSentinel有效缓解了LLM驱动计算机使用代理的安全风险，通过实时拦截和上下文关联的安全审计机制，为这类系统提供了可靠的防御解决方案。

Abstract: Large Language Models (LLMs) have been increasingly integrated into
computer-use agents, which can autonomously operate tools on a user's computer
to accomplish complex tasks. However, due to the inherently unstable and
unpredictable nature of LLM outputs, they may issue unintended tool commands or
incorrect inputs, leading to potentially harmful operations. Unlike traditional
security risks stemming from insecure user prompts, tool execution results from
LLM-driven decisions introduce new and unique security challenges. These
vulnerabilities span across all components of a computer-use agent. To mitigate
these risks, we propose AgentSentinel, an end-to-end, real-time defense
framework designed to mitigate potential security threats on a user's computer.
AgentSentinel intercepts all sensitive operations within agent-related services
and halts execution until a comprehensive security audit is completed. Our
security auditing mechanism introduces a novel inspection process that
correlates the current task context with system traces generated during task
execution. To thoroughly evaluate AgentSentinel, we present BadComputerUse, a
benchmark consisting of 60 diverse attack scenarios across six attack
categories. The benchmark demonstrates a 87% average attack success rate on
four state-of-the-art LLMs. Our evaluation shows that AgentSentinel achieves an
average defense success rate of 79.6%, significantly outperforming all baseline
defenses.

</details>


### [19] [Inner-product Functional Encryption with Fine-grained Revocation for Flexible EHR Sharing](https://arxiv.org/abs/2509.07804)
*Yue Han,Jinguang Han,Liqun Chen,Chao Sun*

Main category: cs.CR

TL;DR: 这篇论文提出了一种具有细粒度撤销功能的内积功能加密方案(IPFE-FR)，并应用于灵活的电子健康记录(EHR)共享系统，解决了医疗数据加密后的选择性计算和隐私保护问题。


<details>
  <summary>Details</summary>
Motivation: 电子健康记录(EHR)包含大量敏感患者信息，需要在保护隐私的前提下支持医疗数据挖掘。传统公钥加密方案无法支持灵活的选择性计算，而现有功能加密方案缺乏细粒度撤销和更新机制，不适用于EHR系统。

Method: 首先提出了一种具有细粒度撤销功能的内积功能加密(IPFE-FR)方案，包括形式定义和安全模型。然后将其应用于EHR共享系统，并基于学习误差(LWE)假设构建具体实现。进行理论分析和实验实现以验证效率。

Result: 该方案支持：(1)细粒度功能计算撤销，可以撤销某个具体功能而非所有权限；(2)撤销后无法计算撤销前后的加密EHR数据；(3)防止合证攻击的秘钥绑定机制。安全性基于LWE假设，具有量子耐受性。

Conclusion: 该研究提出的IPFE-FR方案有效解决了EHR系统中的隐私保护和选择性计算问题，具有细粒度撤销、前后向兼容和防合证攻击等优点，为安全的医疗数据共享提供了可行的解决方案。

Abstract: E-health record (EHR) contains a vast amount of continuously growing medical
data and enables medical institutions to access patient health data
conveniently.This provides opportunities for medical data mining which has
important applications in identifying high-risk patients and improving disease
diagnosis, etc.Since EHR contains sensitive patient information, how to protect
patient privacy and enable mining on EHR data is important and
challenging.Traditional public key encryption (PKE) can protect patient
privacy, but cannot support flexible selective computation on encrypted EHR
data.Functional encryption (FE) allows authorised users to compute function
values of encrypted data without releasing other information, hence supporting
selective computation on encrypted data. Nevertheless, existing FE schemes do
not support fine-grained revocation and update, so they are unsuitable for EHR
system. In this paper,we first propose an inner-product functional encryption
with fine-grained revocation (IPFE-FR) scheme, and then apply it to a flexible
EHR sharing system. Our scheme possesses the following features:(1) a group
manager can revoke a specific function computation of medical institutions on
encrypted EHR data,instead of all function computation rights. (2) a revoked
medical institution is not allowed to compute the function value of encrypted
EHR data not only generated after the revocation, but also generated before the
revocation. (3) secret keys issued to the same medical institution are bound
together to prevent collusion attacks. The formal definition and security model
of the IPFE-FR scheme are proposed.Furthermore, we present a concrete
construction and reduce its security to the Learning with Errors (LWE)
assumption which is quantum-resistant. Finally, the theoretical analysis and
experimental implementation of our scheme are conducted to show its efficiency.

</details>


### [20] [Guided Reasoning in LLM-Driven Penetration Testing Using Structured Attack Trees](https://arxiv.org/abs/2509.07939)
*Katsuaki Nakano,Reza Feyyazi,Shanchieh Jay Yang,Michael Zuzak*

Main category: cs.CR

TL;DR: 本文提出了一种基于MITRE ATT&CK Matrix的导向理由流水线，通过建立确定性任务树来约束LLM代理的涉外测试理由过程，提高了自动化网络安全测试的准确性和效率。


<details>
  <summary>Details</summary>
Motivation: 现有的LLM涉外测试代理主要依靠自我导向理由，容易产生不准确或幻觉的步骤，导致无效行动和循环响应。

Method: 通过将MITRE ATT&CK Matrix转换为确定性任务树，约束LLM的理由过程在明确定义的战术、技术和程序范围内，引导代理采用经验证的攻击程序。

Result: 在10个HackTheBox安全练习中，导向理由流水线导引LLM代理完成了71.8%-78.6%的子任务，而自我导向理由只完成了13.5%-75.7%，且需要更多的模型查询。

Conclusion: 将确定性任务树整合到LLM理由流程中可以显著提高自动化网络安全评估的准确性和效率。

Abstract: Recent advances in Large Language Models (LLMs) have driven interest in
automating cybersecurity penetration testing workflows, offering the promise of
faster and more consistent vulnerability assessment for enterprise systems.
Existing LLM agents for penetration testing primarily rely on self-guided
reasoning, which can produce inaccurate or hallucinated procedural steps. As a
result, the LLM agent may undertake unproductive actions, such as exploiting
unused software libraries or generating cyclical responses that repeat prior
tactics. In this work, we propose a guided reasoning pipeline for penetration
testing LLM agents that incorporates a deterministic task tree built from the
MITRE ATT&CK Matrix, a proven penetration testing kll chain, to constrain the
LLM's reaoning process to explicitly defined tactics, techniques, and
procedures. This anchors reasoning in proven penetration testing methodologies
and filters out ineffective actions by guiding the agent towards more
productive attack procedures. To evaluate our approach, we built an automated
penetration testing LLM agent using three LLMs (Llama-3-8B, Gemini-1.5, and
GPT-4) and applied it to navigate 10 HackTheBox cybersecurity exercises with
103 discrete subtasks representing real-world cyberattack scenarios. Our
proposed reasoning pipeline guided the LLM agent through 71.8\%, 72.8\%, and
78.6\% of subtasks using Llama-3-8B, Gemini-1.5, and GPT-4, respectively.
Comparatively, the state-of-the-art LLM penetration testing tool using
self-guided reasoning completed only 13.5\%, 16.5\%, and 75.7\% of subtasks and
required 86.2\%, 118.7\%, and 205.9\% more model queries. This suggests that
incorporating a deterministic task tree into LLM reasoning pipelines can
enhance the accuracy and efficiency of automated cybersecurity assessments

</details>


### [21] [ImportSnare: Directed "Code Manual" Hijacking in Retrieval-Augmented Code Generation](https://arxiv.org/abs/2509.07941)
*Kai Ye,Liangcai Su,Chenxiong Qian*

Main category: cs.CR

TL;DR: 这篇论文探索了基于检索增强生成的代码生成(RACG)中的攻击面，通过ImportSnare攻击框架实现恶意依赖执叐，在多种编程语言中达到高攻击成功率。


<details>
  <summary>Details</summary>
Motivation: 身份：代码生成是大语言模型的核心能力，但复杂的数据结构和算法逻辑导致功能缺陷和安全漏洞。检索增强生成(RAG)虽能提高正确性和安全性，但同时也引入了新的攻击面。

Method: 方法：提出ImportSnare攻击框架，采用两种协同策略：1)位置感知束形搜索优化隐藏排名序列，提升毒化文档在检索结果中的位置；2)多语言归纳建议生成脱盲序列，操控LLM推荐恶意依赖。

Result: 结果：在Python、Rust和JavaScript等多种语言中，ImportSnare达到了显著的攻击成功率(对于matplotlib等流行库超过50%)，甚至在毒化比低至0.01%时仍能成功。

Conclusion: 结论：这些发现揭示了LLM驱动开发中的严重供应链风险，强调了代码生成任务安全对齐的不足。研究团队将释放多语言测试套件和数据集以支持未来研究。

Abstract: Code generation has emerged as a pivotal capability of Large Language
Models(LLMs), revolutionizing development efficiency for programmers of all
skill levels. However, the complexity of data structures and algorithmic logic
often results in functional deficiencies and security vulnerabilities in
generated code, reducing it to a prototype requiring extensive manual
debugging. While Retrieval-Augmented Generation (RAG) can enhance correctness
and security by leveraging external code manuals, it simultaneously introduces
new attack surfaces.
  In this paper, we pioneer the exploration of attack surfaces in
Retrieval-Augmented Code Generation (RACG), focusing on malicious dependency
hijacking. We demonstrate how poisoned documentation containing hidden
malicious dependencies (e.g., matplotlib_safe) can subvert RACG, exploiting
dual trust chains: LLM reliance on RAG and developers' blind trust in LLM
suggestions. To construct poisoned documents, we propose ImportSnare, a novel
attack framework employing two synergistic strategies: 1)Position-aware beam
search optimizes hidden ranking sequences to elevate poisoned documents in
retrieval results, and 2)Multilingual inductive suggestions generate
jailbreaking sequences to manipulate LLMs into recommending malicious
dependencies. Through extensive experiments across Python, Rust, and
JavaScript, ImportSnare achieves significant attack success rates (over 50% for
popular libraries such as matplotlib and seaborn) in general, and is also able
to succeed even when the poisoning ratio is as low as 0.01%, targeting both
custom and real-world malicious packages. Our findings reveal critical supply
chain risks in LLM-powered development, highlighting inadequate security
alignment for code generation tasks. To support future research, we will
release the multilingual benchmark suite and datasets. The project homepage is
https://importsnare.github.io.

</details>
