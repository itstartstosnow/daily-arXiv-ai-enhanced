<div id=toc></div>

# Table of Contents

- [cs.CR](#cs.CR) [Total: 31]


<div id='cs.CR'></div>

# cs.CR [[Back]](#toc)

### [1] [Securing Agentic AI Systems -- A Multilayer Security Framework](https://arxiv.org/abs/2512.18043)
*Sunil Arora,John Hastings*

Main category: cs.CR

TL;DR: 该研究针对智能体AI系统的安全挑战，提出了一个生命周期感知的安全框架MAAIS，通过多层防御机制保护智能体AI的机密性、完整性、可用性和可问责性。


<details>
  <summary>Details</summary>
Motivation: 智能体AI系统在网络安全、金融、医疗等关键领域的部署日益增多，但其自主性带来了独特的网络安全风险，包括未经授权的行动、对抗性操纵和动态环境交互。现有的AI安全框架无法充分应对这些挑战和智能体AI的特殊性。

Method: 采用设计科学研究（DSR）方法论，开发了专门针对智能体AI系统的生命周期感知安全框架MAAIS，并提出了智能体AI CIAA（机密性、完整性、可用性、可问责性）概念。通过映射MITRE ATLAS AI战术来验证框架有效性。

Result: 提出了MAAIS框架，该框架集成了多层防御机制，在整个AI生命周期中维护CIAA。框架验证表明其能够有效应对智能体AI的安全挑战，为企业环境中的智能体AI部署和治理提供了结构化、标准化的方法。

Conclusion: 该研究为智能体AI系统安全提供了一个专门的生命周期感知框架，为企业CISO、安全团队、AI平台和工程团队提供了详细的逐步方法来保护智能体AI工作负载，有助于智能体AI在关键领域的更安全部署。

Abstract: Securing Agentic Artificial Intelligence (AI) systems requires addressing the complex cyber risks introduced by autonomous, decision-making, and adaptive behaviors. Agentic AI systems are increasingly deployed across industries, organizations, and critical sectors such as cybersecurity, finance, and healthcare. However, their autonomy introduces unique security challenges, including unauthorized actions, adversarial manipulation, and dynamic environmental interactions. Existing AI security frameworks do not adequately address these challenges or the unique nuances of agentic AI. This research develops a lifecycle-aware security framework specifically designed for agentic AI systems using the Design Science Research (DSR) methodology. The paper introduces MAAIS, an agentic security framework, and the agentic AI CIAA (Confidentiality, Integrity, Availability, and Accountability) concept. MAAIS integrates multiple defense layers to maintain CIAA across the AI lifecycle. Framework validation is conducted by mapping with the established MITRE ATLAS (Adversarial Threat Landscape for Artificial-Intelligence Systems) AI tactics. The study contributes a structured, standardized, and framework-based approach for the secure deployment and governance of agentic AI in enterprise environments. This framework is intended for enterprise CISOs, security, AI platform, and engineering teams and offers a detailed step-by-step approach to securing agentic AI workloads.

</details>


### [2] [PermuteV: A Performant Side-channel-Resistant RISC-V Core Securing Edge AI Inference](https://arxiv.org/abs/2512.18132)
*Nuntipat Narkthong,Xiaolin Xu*

Main category: cs.CR

TL;DR: PermuteV是一个安全的RISC-V核心，通过硬件加速的随机循环迭代重排来防御神经网络推理中的电磁侧信道攻击，在FPGA上实现并验证了有效防护和低开销。


<details>
  <summary>Details</summary>
Motivation: 随着AI推理从云端向边缘设备转移，虽然带来了能耗、延迟和隐私方面的优势，但也使得计算更容易受到物理侧信道攻击的威胁，攻击者可能窃取神经网络模型的架构和权重等机密信息。

Method: 提出PermuteV安全RISC-V核心，采用硬件加速的防御机制，随机重排循环迭代的执行顺序，从而混淆与敏感操作相关的电磁特征。

Result: 在FPGA上实现PermuteV并进行评估，实验结果表明它能够有效防御电磁侧信道攻击，同时硬件面积和运行时开销都很小。

Conclusion: PermuteV为边缘AI推理提供了一种高效且安全的解决方案，能够在保护神经网络模型机密性的同时保持较低的性能开销。

Abstract: Edge AI inference is becoming prevalent thanks to the emergence of small yet high-performance microprocessors. This shift from cloud to edge processing brings several benefits in terms of energy savings, improved latency, and increased privacy. On the downside, bringing computation to the edge makes them more vulnerable to physical side-channel attacks (SCA), which aim to extract the confidentiality of neural network models, e.g., architecture and weight. To address this growing threat, we propose PermuteV, a performant side-channel resistant RISC-V core designed to secure neural network inference. PermuteV employs a hardware-accelerated defense mechanism that randomly permutes the execution order of loop iterations, thereby obfuscating the electromagnetic (EM) signature associated with sensitive operations. We implement PermuteV on FPGA and perform evaluations in terms of side-channel security, hardware area, and runtime overhead. The experimental results demonstrate that PermuteV can effectively defend against EM SCA with minimal area and runtime overhead.

</details>


### [3] [PROVEX: Enhancing SOC Analyst Trust with Explainable Provenance-Based IDS](https://arxiv.org/abs/2512.18199)
*Devang Dhanuka,Nidhi Rastogi*

Main category: cs.CR

TL;DR: 提出一个针对基于图神经网络的入侵检测系统的可解释AI框架，通过后置解释方法识别关键因果子图和事件，提高安全分析师对检测结果的信任度。


<details>
  <summary>Details</summary>
Motivation: 现代入侵检测系统使用图神经网络分析系统溯源数据，但其决策过程对分析师来说通常是黑盒，导致安全运营中心存在信任鸿沟。需要让基于图的检测变得透明可解释。

Method: 在KAIROS（最先进的时序图基IDS）上实现XAI框架，适配三种GNN解释方法：GraphMask、GNNExplainer和VA-TGExplainer（变分时序GNN解释器），生成人类可理解的异常行为表示，包括重要边和不确定性估计。

Result: 在DARPA CADETS Engagement 3数据集上验证，框架能生成简洁的窗口级攻击解释。解释器以高保真度保持TGNN的决策，突出关键边如恶意文件交互和异常网络流。平均解释开销为每事件3-5秒。

Conclusion: 该框架通过提供模型推理的洞察，旨在提高分析师信任度和分类速度，其设计可最小化适配应用于任何时序图基检测器，完整代码已开源。

Abstract: Modern intrusion detection systems (IDS) leverage graph neural networks (GNNs) to detect malicious activity in system provenance data, but their decisions often remain a black box to analysts. This paper presents a comprehensive XAI framework designed to bridge the trust gap in Security Operations Centers (SOCs) by making graph-based detection transparent. We implement this framework on top of KAIROS, a state-of-the-art temporal graph-based IDS, though our design is applicable to any temporal graph-based detector with minimal adaptation. The complete codebase is available at https://github.com/devang1304/provex.git. We augment the detection pipeline with post-hoc explanations that highlight why an alert was triggered, identifying key causal subgraphs and events. We adapt three GNN explanation methods - GraphMask, GNNExplainer, and a variational temporal GNN explainer (VA-TGExplainer) - to the temporal provenance context. These tools output human-interpretable representations of anomalous behavior, including important edges and uncertainty estimates. Our contributions focus on the practical integration of these explainers, addressing challenges in memory management and reproducibility. We demonstrate our framework on the DARPA CADETS Engagement 3 dataset and show that it produces concise window-level explanations for detected attacks. Our evaluation reveals that the explainers preserve the TGNN's decisions with high fidelity, surfacing critical edges such as malicious file interactions and anomalous netflows. The average explanation overhead is 3-5 seconds per event. By providing insight into the model's reasoning, our framework aims to improve analyst trust and triage speed.

</details>


### [4] [FedWiLoc: Federated Learning for Privacy-Preserving WiFi Indoor Localization](https://arxiv.org/abs/2512.18207)
*Kanishka Roy,Tahsin Fuad Hasan,Chenfeng Wu,Eshwar Vangala,Roshan Ayyalasomayajula*

Main category: cs.CR

TL;DR: FedWiLoc是一个隐私保护的Wi-Fi室内定位系统，采用联邦学习和分割架构，在保护用户隐私的同时，通过几何一致性损失函数在动态多径环境中实现高精度定位。


<details>
  <summary>Details</summary>
Motivation: 当前基于Wi-Fi的室内定位系统面临三个关键挑战：保护用户隐私、在动态多径环境中实现准确预测、以及跨不同部署的泛化能力。传统系统往往在面临AP被攻击或中间人攻击时危及用户隐私，随着物联网设备在室内环境中的普及，开发既能提供准确定位又能保护隐私的解决方案变得至关重要。

Method: 1. 采用分割架构：AP本地处理信道状态信息(CSI)，仅传输隐私保护的嵌入向量给用户设备，防止原始CSI暴露。
2. 联邦学习训练：在训练阶段使用联邦学习跨AP协作训练模型，无需集中敏感用户数据。
3. 几何损失函数：联合优化到达角预测和位置估计，通过几何一致性约束提高多径环境下的准确性。

Result: 在六个不同室内环境（总面积超过2000平方英尺）的广泛评估表明，FedWiLoc在保持强大隐私保证的同时，将中位定位误差比最先进方法降低了高达61.9%。

Conclusion: FedWiLoc成功解决了隐私保护、动态多径环境准确性和跨部署泛化三大挑战，通过创新的分割架构、联邦学习和几何一致性优化，实现了隐私保护与定位精度的双重提升。

Abstract: Current data-driven Wi-Fi-based indoor localization systems face three critical challenges: protecting user privacy, achieving accurate predictions in dynamic multipath environments, and generalizing across different deployments. Traditional Wi-Fi localization systems often compromise user privacy, particularly when facing compromised access points (APs) or man-in-the-middle attacks. As IoT devices proliferate in indoor environments, developing solutions that deliver accurate localization while robustly protecting privacy has become imperative. We introduce FedWiLoc, a privacy-preserving indoor localization system that addresses these challenges through three key innovations. First, FedWiLoc employs a split architecture where APs process Channel State Information (CSI) locally and transmit only privacy-preserving embedding vectors to user devices, preventing raw CSI exposure. Second, during training, FedWiLoc uses federated learning to collaboratively train the model across APs without centralizing sensitive user data. Third, we introduce a geometric loss function that jointly optimizes angle-of-arrival predictions and location estimates, enforcing geometric consistency to improve accuracy in challenging multipath conditions. Extensive evaluation across six diverse indoor environments spanning over 2,000 sq. ft. demonstrates that FedWiLoc outperforms state-of-the-art methods by up to 61.9% in median localization error while maintaining strong privacy guarantees throughout both training and inference.

</details>


### [5] [Breaking Minds, Breaking Systems: Jailbreaking Large Language Models via Human-like Psychological Manipulation](https://arxiv.org/abs/2512.18244)
*Zehao Liu,Xi Lin*

Main category: cs.CR

TL;DR: 提出Psychological Jailbreak攻击范式，通过操纵LLM的心理状态实现越狱，HPM方法在多种模型上达到88.1%的平均攻击成功率


<details>
  <summary>Details</summary>
Motivation: 现有越狱攻击主要关注输入层面的异常，忽视了模型内部心理状态可被系统性操纵的漏洞。LLM的安全机制日益复杂，但心理层面的攻击面尚未得到充分研究

Method: 提出Human-like Psychological Manipulation (HPM)黑盒越狱方法：动态分析目标模型的潜在心理弱点，生成定制化的多轮攻击策略，利用模型对拟人一致性的优化，制造社会顺从性压倒安全约束的心理压力

Result: 在GPT-4o、DeepSeek-V3、Gemini-2-Flash等模型上，HPM达到88.1%的平均攻击成功率，优于现有攻击基线。能有效穿透RPO等对抗提示优化和Self-Reminder等认知干预防御

Conclusion: 需要从静态内容过滤转向心理安全范式，优先开发针对深度认知操纵的心理防御机制。PCS分析证实HPM能诱导安全机制崩溃以满足被操纵的上下文

Abstract: Large Language Models (LLMs) have gained considerable popularity and protected by increasingly sophisticated safety mechanisms. However, jailbreak attacks continue to pose a critical security threat by inducing models to generate policy-violating behaviors. Current paradigms focus on input-level anomalies, overlooking that the model's internal psychometric state can be systematically manipulated. To address this, we introduce Psychological Jailbreak, a new jailbreak attack paradigm that exposes a stateful psychological attack surface in LLMs, where attackers exploit the manipulation of a model's psychological state across interactions. Building on this insight, we propose Human-like Psychological Manipulation (HPM), a black-box jailbreak method that dynamically profiles a target model's latent psychological vulnerabilities and synthesizes tailored multi-turn attack strategies. By leveraging the model's optimization for anthropomorphic consistency, HPM creates a psychological pressure where social compliance overrides safety constraints. To systematically measure psychological safety, we construct an evaluation framework incorporating psychometric datasets and the Policy Corruption Score (PCS). Benchmarking against various models (e.g., GPT-4o, DeepSeek-V3, Gemini-2-Flash), HPM achieves a mean Attack Success Rate (ASR) of 88.1%, outperforming state-of-the-art attack baselines. Our experiments demonstrate robust penetration against advanced defenses, including adversarial prompt optimization (e.g., RPO) and cognitive interventions (e.g., Self-Reminder). Ultimately, PCS analysis confirms HPM induces safety breakdown to satisfy manipulated contexts. Our work advocates for a fundamental paradigm shift from static content filtering to psychological safety, prioritizing the development of psychological defense mechanisms against deep cognitive manipulation.

</details>


### [6] [MORPHEUS: A Multidimensional Framework for Modeling, Measuring, and Mitigating Human Factors in Cybersecurity](https://arxiv.org/abs/2512.18303)
*Giuseppe Desolda,Francesco Greco,Rosa Lanzilotti,Cesare Tucci*

Main category: cs.CR

TL;DR: MORPHEUS是一个整体性框架，将人为因素安全操作化为动态互联系统，整合了50个影响网络安全威胁易感性的因素，并系统映射了295种相互作用机制。


<details>
  <summary>Details</summary>
Motivation: 当前网络安全研究虽然日益认识到人为因素的重要性，但仍然零散化，常常将用户漏洞视为孤立和静态的特征。需要建立一个更全面、动态的框架来理解人为因素在网络安全中的作用。

Method: 基于认知-情感-行为(CAB)模型和归因理论，整合了50个影响主要网络威胁易感性的人为因素，系统映射了295种已记录的相互作用，提炼出12个重复出现的相互作用机制，并提供了99个经过验证的心理测量工具清单。

Result: MORPHEUS框架提供了理解人为因素安全动态相互作用的系统方法，能够应用于风险诊断、培训和界面设计等具体操作场景，为以人为中心的网络安全研究和实践提供了严谨且可操作的基础。

Conclusion: MORPHEUS为推进以人为中心的网络安全研究和实践提供了一个全面、动态且可操作的框架，将理论联系到实践，支持实证评估和针对性干预。

Abstract: Current cybersecurity research increasingly acknowledges the human factor, yet remains fragmented, often treating user vulnerabilities as isolated and static traits. This paper introduces MORPHEUS, a holistic framework that operationalizes human-centric security as a dynamic and interconnected system. Grounded in the Cognition-Affect-Behavior (CAB) model and Attribution Theory, MORPHEUS consolidates 50 human factors influencing susceptibility to major cyberthreats, including phishing, malware, password management, and misconfigurations. Beyond factor identification, the framework systematically maps 295 documented interactions, revealing how cognitive, emotional, behavioral, and socio-organizational processes jointly shape security outcomes, and distills them into twelve recurring interaction mechanisms. MORPHEUS further links theory to practice through an inventory of 99 validated psychometric instruments, enabling empirical assessment and targeted intervention. We illustrate the framework's applicability through concrete operational scenarios, spanning risk diagnosis, training, and interface design. Overall, MORPHEUS provides a rigorous yet actionable foundation for advancing human-centered cybersecurity research and practice.

</details>


### [7] [Theodosian: A Deep Dive into Memory-Hierarchy-Centric FHE Acceleration](https://arxiv.org/abs/2512.18345)
*Wonseok Choi,Hyunah Yu,Jongmin Kim,Hyesung Ji,Jaiyoung Park,Jung Ho Ahn*

Main category: cs.CR

TL;DR: 论文对现代GPU上的CKKS全同态加密方案进行微架构分析，发现内存带宽限制和硬件利用率不足问题，提出Theodosian优化方案，显著提升性能。


<details>
  <summary>Details</summary>
Motivation: 全同态加密(FHE)在云和边缘环境中能实现加密数据的安全计算，但计算和内存需求高。尽管已有大量GPU加速研究，但CKKS方案在现代GPU上的微架构特性尚未充分探索，特别是缓存行为和硬件利用率问题。

Method: 对现代GPU上的CKKS方案进行微架构分析，重点关注片上缓存行为。发现内存带宽限制和硬件利用率不足问题后，提出Theodosian优化方案，包括内存感知优化以提高缓存效率和减少运行时开销。

Result: 在RTX 5090上，Theodosian将32,768个复数的自举延迟降低到15.2ms，结合额外算法优化后进一步降至12.8ms，建立了新的GPU性能最先进水平。

Conclusion: CKKS在GPU上的性能受内存带宽限制和硬件利用率不足制约。Theodosian优化方案通过内存感知优化有效解决了这些问题，显著提升了CKKS工作负载的性能，为全同态加密的GPU加速提供了新的优化方向。

Abstract: Fully homomorphic encryption (FHE) enables secure computation on encrypted data, mitigating privacy concerns in cloud and edge environments. However, due to its high compute and memory demands, extensive acceleration research has been pursued across diverse hardware platforms, especially GPUs. In this paper, we perform a microarchitectural analysis of CKKS, a popular FHE scheme, on modern GPUs. We focus on on-chip cache behavior, and show that the dominant kernels remain bound by memory bandwidth despite a high-bandwidth L2 cache, exposing a persistent memory wall. We further discover that the overall CKKS pipeline throughput is constrained by low per-kernel hardware utilization, caused by insufficient intra-kernel parallelism. Motivated by these findings, we introduce Theodosian, a set of complementary, memory-aware optimizations that improve cache efficiency and reduce runtime overheads. Our approach delivers consistent speedups across various CKKS workloads. On an RTX 5090, we reduce the bootstrapping latency for 32,768 complex numbers to 15.2ms with Theodosian, and further to 12.8ms with additional algorithmic optimizations, establishing new state-of-the-art GPU performance to the best of our knowledge.

</details>


### [8] [Federated Learning Based Decentralized Adaptive Intelligent Transmission Protocol for Privacy Preserving 6G Networks](https://arxiv.org/abs/2512.18432)
*Ansar Ahmed*

Main category: cs.CR

TL;DR: 提出基于联邦学习的去中心化自适应智能传输协议（AITP），解决6G网络中的隐私、可扩展性和适应性挑战，通过分布式学习和实时参数调整提升性能。


<details>
  <summary>Details</summary>
Motivation: 6G无线网络面临隐私、可扩展性和适应性新挑战，传统集中式网络模型无法处理6G的数据密集型特性，需要向更安全、去中心化的系统转变。

Method: 提出联邦学习基的去中心化自适应智能传输协议（AITP），在去中心化系统中利用联邦学习的分布式学习能力，实时智能调整传输参数，原始数据保留在本地边缘设备以保护隐私。

Result: 通过数学建模和详细仿真评估，AITP在延迟、网络吞吐量、能源效率和鲁棒性等多个关键指标上优于传统非自适应和集中式AI方法。

Conclusion: AITP是未来6G网络的基础技术，支持以用户为中心、隐私优先的设计，推动了6G隐私保护研究的发展。

Abstract: The move to 6th Generation (6G) wireless networks creates new issues with privacy, scalability, and adaptability. The data-intensive nature of 6G is not handled well by older, centralized network models. A shift toward more secure and decentralized systems is therefore required. A new framework called the Federated Learning-based Decentralized Adaptive Intelligent Transmission Protocol (AITP) is proposed to meet these challenges. The AITP uses the distributed learning of Federated Learning (FL) within a decentralized system. Transmission parameters can be adjusted intelligently in real time. User privacy is maintained by keeping raw data on local edge devices. The protocol's performance was evaluated with mathematical modeling and detailed simulations. It was shown to be superior to traditional non-adaptive and centralized AI methods across several key metrics. These included latency, network throughput, energy efficiency, and robustness. The AITP is presented as a foundational technology for future 6G networks that supports a user-centric, privacy-first design. This study is a step forward for privacy-preserving research in 6G.

</details>


### [9] [SoK: Understanding (New) Security Issues Across AI4Code Use Cases](https://arxiv.org/abs/2512.18456)
*Qilong Wu,Taoran Li,Tianyang Zhou,Varun Chandrasekaran*

Main category: cs.CR

TL;DR: 这篇SoK论文系统分析了AI4Code系统的安全风险，包括不安全输出、基准偏差、对抗脆弱性等问题，并提出了安全优先的AI4Code发展方向。


<details>
  <summary>Details</summary>
Motivation: 随着AI4Code系统（如GitHub Copilot）在代码生成、翻译和漏洞检测等领域的广泛应用，其安全风险日益凸显。不安全输出、有偏基准和对抗脆弱性等问题严重影响了这些系统的可靠性，需要系统性的安全分析和改进方向。

Method: 采用系统化知识（SoK）方法，从三个核心应用领域（代码生成、漏洞检测、代码翻译）全面调查AI4Code安全现状。通过比较六个最先进模型，识别出基准偏差、数据集标准化不足、数据泄露和对抗鲁棒性脆弱等重复性差距。

Result: 研究发现：代码生成中不安全模式持续存在；漏洞检测对语义保持攻击脆弱；微调常与安全目标错位；代码翻译的安全效益不均衡。这些问题揭示了当前AI4Code系统在安全方面的系统性缺陷。

Conclusion: 提出三条发展路径：1）在代码生成中嵌入默认安全实践；2）构建鲁棒全面的检测基准；3）利用翻译作为安全增强语言的途径。呼吁向安全优先的AI4Code转变，将漏洞缓解和鲁棒性嵌入整个开发生命周期。

Abstract: AI-for-Code (AI4Code) systems are reshaping software engineering, with tools like GitHub Copilot accelerating code generation, translation, and vulnerability detection. Alongside these advances, however, security risks remain pervasive: insecure outputs, biased benchmarks, and susceptibility to adversarial manipulation undermine their reliability. This SoK surveys the landscape of AI4Code security across three core applications, identifying recurring gaps: benchmark dominance by Python and toy problems, lack of standardized security datasets, data leakage in evaluation, and fragile adversarial robustness. A comparative study of six state-of-the-art models illustrates these challenges: insecure patterns persist in code generation, vulnerability detection is brittle to semantic-preserving attacks, fine-tuning often misaligns security objectives, and code translation yields uneven security benefits. From this analysis, we distill three forward paths: embedding secure-by-default practices in code generation, building robust and comprehensive detection benchmarks, and leveraging translation as a route to security-enhanced languages. We call for a shift toward security-first AI4Code, where vulnerability mitigation and robustness are embedded throughout the development life cycle.

</details>


### [10] [QLink: Quantum-Safe Bridge Architecture for Blockchain Interoperability](https://arxiv.org/abs/2512.18488)
*Joao Vitor Barros Da Silva,Arsh Gupta,Madhusudan Singh Irish Singh*

Main category: cs.CR

TL;DR: QLink是首个结合后量子密码学、量子密钥分发和硬件安全模块的量子安全Layer 3跨链互操作协议，为Web3提供抗量子攻击的跨链通信和资产转移解决方案。


<details>
  <summary>Details</summary>
Motivation: 当前区块链跨链桥协议面临经典攻击和新兴量子威胁的双重安全挑战，需要建立能够抵御量子攻击的安全互操作框架。

Method: 设计三层架构：1) 通过QKD通道实现信息论安全的密钥交换；2) 使用NIST标准化的PQC算法生成和聚合跨链证明；3) 将私钥密封在HSM安全模块中防止泄露。

Result: 网络模拟实验显示验证者通信开销保持在亚秒级，同时安全保证超越现有桥架构，能够抵抗经典和量子攻击。

Conclusion: QLink通过整合量子安全技术，为区块链互操作性提供了实用且面向未来的解决方案，解决了当前漏洞并预见了未来量子威胁。

Abstract: Secure interoperability across heterogeneous blockchains remains one of the most pressing challenges in Web3 with existing bridge protocols vulnerable to both classical exploits and emerging quantum threats. This paper introduces QLink a quantum-safe Layer 3 interoperability protocol that integrates postquantum cryptography (PQC) quantum key distribution (QKD) and hardware security modules (HSMs) into a unified validator architecture. To our knowledge, QLink is the first interoperability framework to combine these mechanisms to secure validator communication proof aggregation and key management. Validators exchange encryption keys through QKD channels, achieving information-theoretic security against interception, while cross-chain proofs are generated and aggregated with NIST-standardized PQC algorithms. Private keys remain sealed inside HSM enclaves mitigating the risk of theft or leakage. Deployed as a dedicated Layer 3 protocol QLink operates independently of Layer 1 and Layer 2 chains providing a scalable decentralized foundation for secure cross-chain messaging and asset transfer. Experimental evaluation using network simulations demonstrates that validator communication overhead remains sub-second while security guarantees extend beyond current bridge architectures to resist both classical and quantum adversaries. By addressing today vulnerabilities and anticipating future quantum threats QLink establishes a practical and future-proof pathway for blockchain interoperability.

</details>


### [11] [Enhancing Decision-Making in Windows PE Malware Classification During Dataset Shifts with Uncertainty Estimation](https://arxiv.org/abs/2512.18495)
*Rahul Yumlembam,Biju Issac,Seibu Mary Jacob*

Main category: cs.CR

TL;DR: 本文提出一种结合集成学习不确定性估计与归纳共形评估的方法，显著降低在数据分布偏移（尤其是加壳恶意软件）下的错误接受率，提升恶意软件检测的鲁棒性。


<details>
  <summary>Details</summary>
Motivation: 传统AI恶意软件检测方法在数据分布偏移下可靠性下降，可能导致严重的安全后果。特别是面对加壳恶意软件等分布偏移时，现有方法表现不佳。

Method: 增强现有LightGBM恶意软件检测器，集成神经网络、PriorNet和神经网络集成。使用集成不确定性估计作为非共形度量，结合新颖的阈值优化方法，在归纳共形评估框架中应用。

Result: 在最具挑战性的UCSB数据集（主要包含加壳恶意软件）上，现有最佳概率基ICE方法的错误接受率为22.8%，而本文方法将其降至16%，相对减少约30%，同时保持竞争力的正确接受率。

Conclusion: 集成不确定性估计与共形预测的结合为极端数据分布偏移（特别是加壳恶意软件）下的误分类提供了更可靠的防护，对实际安全操作具有实用价值。

Abstract: Artificial intelligence techniques have achieved strong performance in classifying Windows Portable Executable (PE) malware, but their reliability often degrades under dataset shifts, leading to misclassifications with severe security consequences. To address this, we enhance an existing LightGBM (LGBM) malware detector by integrating Neural Networks (NN), PriorNet, and Neural Network Ensembles, evaluated across three benchmark datasets: EMBER, BODMAS, and UCSB. The UCSB dataset, composed mainly of packed malware, introduces a substantial distributional shift relative to EMBER and BODMAS, making it a challenging testbed for robustness. We study uncertainty-aware decision strategies, including probability thresholding, PriorNet, ensemble-derived estimates, and Inductive Conformal Evaluation (ICE). Our main contribution is the use of ensemble-based uncertainty estimates as Non-Conformity Measures within ICE, combined with a novel threshold optimisation method. On the UCSB dataset, where the shift is most severe, the state-of-the-art probability-based ICE (SOTA) yields an incorrect acceptance rate (IA%) of 22.8%. In contrast, our method reduces this to 16% a relative reduction of about 30% while maintaining competitive correct acceptance rates (CA%). These results demonstrate that integrating ensemble-based uncertainty with conformal prediction provides a more reliable safeguard against misclassifications under extreme dataset shifts, particularly in the presence of packed malware, thereby offering practical benefits for real-world security operations.

</details>


### [12] [Exploring Runtime Evolution in Android: A Cross-Version Analysis and Its Implications for Memory Forensics](https://arxiv.org/abs/2512.18517)
*Babangida Bappah,Lauren G Bristol,Lamine Noureddine,Sideeq Bello,Umar Farooq,Aisha Ali-Gombe*

Main category: cs.CR

TL;DR: 本文首次系统研究了Android运行时（ART）结构演化及其对内存取证的影响，发现超过73.2%的结构成员发生位置变化，传统静态结构定义方法已不可持续，建议采用混合方法。


<details>
  <summary>Details</summary>
Motivation: Android内存取证工具面临重大挑战：需要适应不同版本并保持长期可靠性，因为底层结构不断演化（从简单偏移修改到完整架构重新设计），这些变化严重影响证据恢复和重建的准确性。

Method: 对Android运行时关键结构进行实证分析，研究了6个版本、4种不同架构下的演化情况，特别关注Runtime、Thread和Heap等核心组件的演化模式。

Result: 研究发现超过73.2%的结构成员发生位置变化，显著影响内存取证工具的适应性和可靠性。核心组件显示不同的演化模式，影响线程状态枚举、内存映射和对象重建等关键取证操作。

Conclusion: 传统依赖静态结构定义和符号方法的方法已不可持续，建议内存取证工具（特别是Android）采用混合方法：保留符号方法的验证强度，同时集成自动结构推断、版本感知解析和冗余分析策略。

Abstract: Userland memory forensics has become a critical component of smartphone investigations and incident response, enabling the recovery of volatile evidence such as deleted messages from end-to-end encrypted apps and cryptocurrency transactions. However, these forensics tools, particularly on Android, face significant challenges in adapting to different versions and maintaining reliability over time due to the constant evolution of low-level structures critical for evidence recovery and reconstruction. Structural changes, ranging from simple offset modifications to complete architectural redesigns, pose substantial maintenance and adaptability issues for forensic tools that rely on precise structure interpretation. Thus, this paper presents the first systematic study of Android Runtime (ART) structural evolution and its implications for memory forensics. We conduct an empirical analysis of critical Android runtime structures, examining their evolution across six versions for four different architectures. Our findings reveal that over 73.2% of structure members underwent positional changes, significantly affecting the adaptability and reliability of memory forensic tools. Further analysis of core components such as Runtime, Thread, and Heap structures highlights distinct evolution patterns and their impact on critical forensic operations, including thread state enumeration, memory mapping, and object reconstruction. These results demonstrate that traditional approaches relying on static structure definitions and symbol-based methods, while historically reliable, are increasingly unsustainable on their own. We recommend that memory forensic tools in general and Android in particular evolve toward hybrid approaches that retain the validation strength of symbolic methods while integrating automated structure inference, version-aware parsing, and redundant analysis strategies.

</details>


### [13] [SecureCode v2.0: A Production-Grade Dataset for Training Security-Aware Code Generation Models](https://arxiv.org/abs/2512.18542)
*Scott Thornton*

Main category: cs.CR

TL;DR: SecureCode v2.0是一个包含1,215个安全编码示例的生产级数据集，覆盖11种编程语言和11个漏洞类别，每个示例都基于真实安全事件，提供漏洞和安全实现、攻击演示及深度防御操作指南。


<details>
  <summary>Details</summary>
Motivation: 当前AI助手在45%的安全相关场景中生成易受攻击的代码，将漏洞引入生产系统。现有安全编码数据集存在不足：缺乏真实事件基础、规模不足、缺少生产部署所需的安全操作上下文。

Method: 创建包含1,215个安全编码示例的数据集，每个示例都通过结构验证和专家安全审查。采用4轮对话结构模拟真实开发者-AI交互，包含SIEM集成策略、基础设施加固建议和语言特定的测试框架。

Result: 数据集覆盖11种编程语言(Python、JavaScript等)和11个漏洞类别(完整OWASP Top 10:2025加AI/ML安全威胁)，包含989个训练、122个验证和104个测试示例。提供自动化验证框架和开源工具。

Conclusion: SecureCode v2.0填补了现有安全编码数据集的空白，提供基于真实事件、规模适当且包含生产安全操作上下文的数据集，有助于改善AI助手生成代码的安全性。

Abstract: AI assistants produce vulnerable code in 45% of security-relevant scenarios, introducing flaws into production systems at scale. Yet existing secure coding datasets fall short. They lack incident grounding, don't provide the scale modern training requires, and miss the operational security context developers need for production deployments. We present SecureCode v2.0, a production-grade dataset of 1,215 security-focused coding examples that passed structural validation and expert security review. Every example ties to actual documented security incidents with CVE references, provides vulnerable and secure implementations, demonstrates concrete attacks, and includes defense-in-depth operational guidance. The dataset covers 11 vulnerability categories (complete OWASP Top 10:2025 plus AI/ML Security Threats) across 11 languages (Python, JavaScript, Java, Go, PHP, C#, TypeScript, Ruby, Rust, Kotlin, and YAML for infrastructure-as-code).
  Our quality assurance framework ensures complete incident grounding. Each example includes SIEM integration strategies, infrastructure hardening recommendations (Docker, AppArmor, WAF configurations), and testing approaches using language-appropriate frameworks. The dataset uses a 4-turn conversational structure mirroring actual developer-AI interactions, escalating from basic implementations to advanced security considerations and defense-in-depth guidance.
  Our contributions: (1) 1,215 rigorously validated examples split into 989 training, 122 validation, and 104 test sets, (2) an automated validation framework ensuring dataset consistency, (3) a 4-turn conversational structure capturing realistic security workflows, (4) comprehensive operational security guidance with SIEM integration strategies, (5) complete language-specific implementation fidelity, and (6) open-source release of data, validation tools, and benchmarking protocols.

</details>


### [14] [Proof of Authenticity of General IoT Information with Tamper-Evident Sensors and Blockchain](https://arxiv.org/abs/2512.18560)
*Kenji Saito*

Main category: cs.CR

TL;DR: 提出一种基于区块链的物联网传感器数据安全日志方法，通过设备签名、哈希链和默克尔树确保数据可验证性，不依赖中间系统完整性


<details>
  <summary>Details</summary>
Motivation: 物联网传感器数据在通过不可信服务传输时容易遭受篡改或伪造，这些数据在物流、医疗和关键基础设施等领域支撑着现实世界决策，因此需要确保数据完整性

Method: 提出通用安全传感器数据日志方法：防篡改设备定期对读数签名，使用冗余哈希链链接数据，通过默克尔树将加密证据提交到基于区块链的服务，确保即使在数据丢失情况下也可验证

Result: 该方法能够在不同物联网系统中实现可靠且经济高效的数据验证，包括灾难响应和其他人道主义应用，无需依赖中间系统的完整性

Conclusion: 提出的方法为物联网传感器数据提供了安全、可验证的日志解决方案，特别适用于关键应用场景，确保数据完整性不受中间系统可信度影响

Abstract: Sensor data in IoT (Internet of Things) systems is vulnerable to tampering or falsification when transmitted through untrusted services. This is critical because such data increasingly underpins real-world decisions in domains such as logistics, healthcare, and other critical infrastructure. We propose a general method for secure sensor-data logging in which tamper-evident devices periodically sign readouts, link data using redundant hash chains, and submit cryptographic evidence to a blockchain-based service via Merkle trees to ensure verifiability even under data loss. Our approach enables reliable and cost-effective validation of sensor data across diverse IoT systems, including disaster response and other humanitarian applications, without relying on the integrity of intermediate systems.

</details>


### [15] [DNA-HHE: Dual-mode Near-network Accelerator for Hybrid Homomorphic Encryption on the Edge](https://arxiv.org/abs/2512.18589)
*Yifan Zhao,Xinglong Yu,Yi Sun,Honglin Kuang,Jun Han*

Main category: cs.CR

TL;DR: DNA-HHE是首个支持双模式混合同态加密的加速器，为边缘设备提供RNS-CKKS和Rubato两种加密模式，通过近网络耦合架构提升隐私保护外包计算性能。


<details>
  <summary>Details</summary>
Motivation: 传统FHE方案如RNS-CKKS在边缘侧存在高计算延迟和密文扩展问题，HHE虽能缓解但引入云端转加密开销。需要一种能灵活切换算法的双模式HHE解决方案。

Method: 提出DNA-HHE双模式HHE加速器，采用统一架构支持RNS-CKKS和Rubato加密；设计DSP高效模约减、紧凑多场自适应蝶形单元、Rubato并行调度方案；实现网络协议封装和传输能力，直接耦合网络接口控制器。

Result: DNA-HHE在ASIC和FPGA平台上评估显示，相比现有单模式设计，在边缘侧RNS-CKKS和对称密码方面都有更好的计算延迟和面积效率，同时提供双模式功能，将边缘侧PPOC总体延迟降低1.09×到1.56×。

Conclusion: DNA-HHE是首个双模式HHE加速器，通过统一架构和优化设计实现了边缘侧隐私保护外包计算的高效处理，为边缘设备提供了灵活且高性能的加密解决方案。

Abstract: Fully homomorphic encryption (FHE) schemes like RNS-CKKS enable privacy-preserving outsourced computation (PPOC) but suffer from high computational latency and ciphertext expansion, especially on the resource-constrained edge side. Hybrid Homomorphic Encryption (HHE) mitigates these issues on the edge side by replacing HE with lightweight symmetric encryption for plaintext encryption, such as the Rubato cipher for the HHE variant of RNS-CKKS, yet it introduces transciphering overhead on the cloud. The respective strengths and limitations of FHE and HHE call for a dual-mode HHE solution with flexible algorithm switching ability. This paper presents DNA-HHE, the first dual-mode HHE accelerator with near-network coupling for edge devices. DNA-HHE supports both edge-side RNS-CKKS and Rubato within a unified architecture driven by flexible custom instructions. To realize a compact implementation for the edge side, we propose a DSP-efficient modular reduction design, a compact multi-field-adaptive butterfly unit, and parallel scheduling schemes of Rubato with a high degree of resource sharing. DNA-HHE is designed with network protocol packaging and transmission capacities and directly coupled to the network interface controller, achieving reduced overall latency of edge-side PPOC by 1.09$\times$ to 1.56$\times$. Our evaluations on the ASIC and FPGA platforms demonstrate that DNA-HHE outperforms the state-of-the-art single-mode designs in both edge-side RNS-CKKS and symmetric cipher with better computation latency and area efficiency, while offering dual-mode functionality.

</details>


### [16] [Multi-user Pufferfish Privacy](https://arxiv.org/abs/2512.18632)
*Ni Ding,Songpei Lu,Wenjing Yang,Zijian Zhang*

Main category: cs.CR

TL;DR: 研究如何通过Pufferfish隐私在聚合查询中实现个体不可区分性，通过校准拉普拉斯噪声来保护用户数据变化、离开和替换时的隐私


<details>
  <summary>Details</summary>
Motivation: 在多用户系统中，当用户报告随机变量实现时，需要保护个体隐私。用户可能改变报告数据、离开系统或被替换，这些场景都需要隐私保护。现有方法需要改进以处理这些动态变化

Method: 使用Pufferfish隐私框架，通过校准添加到查询答案中的拉普拉斯噪声。利用Kantorovich方法（一阶Wasserstein度量）推导出在四种秘密对集合上实现统计不可区分性的充分条件

Result: 推导出所有场景下实现统计不可区分性的充分条件，可应用于表格数据中添加或移除特定用户类别的情况。发现实现个体数据不可区分性仅取决于该用户的统计特性。对于二元随机变量，条件可进一步放宽以减少噪声并提高数据效用

Conclusion: 通过Pufferfish隐私框架和拉普拉斯噪声校准，可以有效保护多用户系统中个体隐私，特别是在用户数据变化、离开和替换的动态场景下。对于二元变量，还能进一步优化噪声添加以提高数据实用性

Abstract: This paper studies how to achieve individual indistinguishability by pufferfish privacy in aggregated query to a multi-user system. It is assumed that each user reports realization of a random variable. We study how to calibrate Laplace noise, added to the query answer, to attain pufferfish privacy when user changes his/her reported data value, leaves the system and is replaced by another use with different randomness. Sufficient conditions are derived for all scenarios for attaining statistical indistinguishability on four sets of secret pairs. They are derived using the existing Kantorovich method (Wasserstain metric of order $1$). These results can be applied to attain indistinguishability when a certain class of users is added or removed from a tabular data. It is revealed that attaining indifference in individual's data is conditioned on the statistics of this user only. For binary (Bernoulli distributed) random variables, the derived sufficient conditions can be further relaxed to reduce the noise and improve data utility.

</details>


### [17] [Volley Revolver: A Novel Matrix-Encoding Method for Privacy-Preserving Deep Learning (Inference++)](https://arxiv.org/abs/2512.18646)
*John Chiang*

Main category: cs.CR

TL;DR: 提出改进的编码和计算框架，解决同态加密CNN推理中高分辨率图像处理受限于密文槽容量的瓶颈问题


<details>
  <summary>Details</summary>
Motivation: 现有基于同态加密的CNN推理方法要求单个密文必须完整包含整个输入图像，这在高分辨率图像处理时成为关键瓶颈，限制了方法的可扩展性

Method: 重新设计数据布局和同态操作，将高分辨率输入分区到多个密文中，同时保持卷积和矩阵乘法所需的代数结构

Result: 新方法能够突破密文槽容量限制，使同态加密CNN推理能够扩展到更高分辨率和更复杂的数据集

Conclusion: 提出的改进编码框架解决了同态加密CNN推理的关键可扩展性问题，为高分辨率图像的安全机器学习提供了实用解决方案

Abstract: Privacy-preserving inference of convolutional neural networks (CNNs) using homomorphic encryption has emerged as a promising approach for enabling secure machine learning in untrusted environments. In our previous work, we introduced a matrix-encoding strategy that allows convolution and matrix multiplication to be efficiently evaluated over encrypted data, enabling practical CNN inference without revealing either the input data or the model parameters. The core idea behind this strategy is to construct a three-dimensional representation within ciphertexts that preserves the intrinsic spatial structure of both input image data and model weights, rather than flattening them into conventional two-dimensional encodings. However, this approach can operate efficiently $only$ when the number of available plaintext slots within a ciphertext is sufficient to accommodate an entire input image, which becomes a critical bottleneck when processing high-resolution images. In this paper, we address this fundamental limitation by proposing an improved encoding and computation framework that removes the requirement that a single encrypted ciphertext must fully contain one input image. Our method reformulates the data layout and homomorphic operations to partition high-resolution inputs across multiple ciphertexts while preserving the algebraic structure required for efficient convolution and matrix multiplication. As a result, our approach enables privacy-preserving CNN inference to scale naturally beyond the slot-capacity constraints of prior methods, making homomorphic evaluation of CNNs practical for higher-resolution and more complex datasets.

</details>


### [18] [An Evidence-Driven Analysis of Threat Information Sharing Challenges for Industrial Control Systems and Future Directions](https://arxiv.org/abs/2512.18714)
*Adam Hahn,Rubin Krief,Daniel Rebori-Carretero,Rami Puzis,Aviad Elyashar,Nik Urlaub*

Main category: cs.CR

TL;DR: 该研究分析了ICS领域威胁信息共享的挑战，通过分析三大攻击事件、196个程序示例和9个漏洞公告，识别出ICS威胁信息共享生态系统的四个主要限制，旨在指导未来信息共享标准的开发。


<details>
  <summary>Details</summary>
Motivation: 关键基础设施面临的网络威胁日益增加，需要私营公司和政府机构检测并共享威胁信息。尽管改进威胁信息共享的需求被广泛认可，但各种技术和组织挑战仍然存在，阻碍了有效协作。

Method: 1. 分析三个重大事件：Stuxnet、Industroyer和Triton；2. 对22个ICS相关恶意软件家族的79个MITRE ATT&CK技术中的196个程序示例进行系统分析；3. 使用自动化自然语言处理技术系统提取和分类威胁可观测指标；4. 调查CISA已知可利用漏洞目录中的9个近期ICS漏洞公告。

Result: 识别出ICS威胁信息共享生态系统的四个重要限制：1) 信息共享语言标准（如STIX）中缺乏ICS对抗技术相关工件的连贯表示；2) 对未记录专有技术的依赖；3) 漏洞和威胁事件报告中提供的技术细节有限；4) 观察到的对抗技术技术细节的可访问性。

Conclusion: 该研究旨在指导未来信息共享标准的开发，包括增强STIX中的网络可观测对象模式，以确保准确表示ICS环境特定的工件。

Abstract: The increasing cyber threats to critical infrastructure highlight the importance of private companies and government agencies in detecting and sharing information about threat activities. Although the need for improved threat information sharing is widely recognized, various technical and organizational challenges persist, hindering effective collaboration. In this study, we review the challenges that disturb the sharing of usable threat information to critical infrastructure operators within the ICS domain. We analyze three major incidents: Stuxnet, Industroyer, and Triton. In addition, we perform a systematic analysis of 196 procedure examples across 79 MITRE ATT&CK techniques from 22 ICS-related malware families, utilizing automated natural language processing techniques to systematically extract and categorize threat observables. Additionally, we investigated nine recent ICS vulnerability advisories from the CISA Known Exploitable Vulnerability catalog. Our analysis identified four important limitations in the ICS threat information sharing ecosystem: (i) the lack of coherent representation of artifacts related to ICS adversarial techniques in information sharing language standards (e.g., STIX); (ii) the dependence on undocumented proprietary technologies; (iii) limited technical details provided in vulnerability and threat incident reports; and (iv) the accessibility of technical details for observed adversarial techniques. This study aims to guide the development of future information-sharing standards, including the enhancement of the cyber-observable objects schema in STIX, to ensure accurate representation of artifacts specific to ICS environments.

</details>


### [19] [Explainable and Fine-Grained Safeguarding of LLM Multi-Agent Systems via Bi-Level Graph Anomaly Detection](https://arxiv.org/abs/2512.18733)
*Junjun Pan,Yixin Liu,Rui Miao,Kaize Ding,Yu Zheng,Quoc Viet Hung Nguyen,Alan Wee-Chung Liew,Shirui Pan*

Main category: cs.CR

TL;DR: XG-Guard：一个可解释的细粒度安全框架，用于检测多智能体系统中的恶意智能体，结合句子级和词级表示，并提供解释性


<details>
  <summary>Details</summary>
Motivation: 随着基于大语言模型的多智能体系统在安全关键任务中越来越自主，检测恶意智能体成为关键安全问题。现有基于图异常检测的防御方法主要依赖粗粒度的句子级信息，忽视细粒度词汇线索，导致性能不佳，且缺乏可解释性限制了可靠性和实际应用。

Method: 提出XG-Guard框架：1）使用双层智能体编码器联合建模每个智能体的句子级和词级表示；2）基于主题的异常检测器捕捉多智能体对话中演变的讨论焦点；3）双层分数融合机制量化词级贡献以提供解释。

Result: 在不同多智能体系统拓扑和攻击场景下的广泛实验表明，XG-Guard具有鲁棒的检测性能和强大的可解释性。

Conclusion: XG-Guard通过结合粗粒度和细粒度文本信息，解决了现有恶意智能体检测方法的局限性，在检测性能和可解释性方面都表现出色，为多智能体系统安全提供了有效的解决方案。

Abstract: Large language model (LLM)-based multi-agent systems (MAS) have shown strong capabilities in solving complex tasks. As MAS become increasingly autonomous in various safety-critical tasks, detecting malicious agents has become a critical security concern. Although existing graph anomaly detection (GAD)-based defenses can identify anomalous agents, they mainly rely on coarse sentence-level information and overlook fine-grained lexical cues, leading to suboptimal performance. Moreover, the lack of interpretability in these methods limits their reliability and real-world applicability. To address these limitations, we propose XG-Guard, an explainable and fine-grained safeguarding framework for detecting malicious agents in MAS. To incorporate both coarse and fine-grained textual information for anomalous agent identification, we utilize a bi-level agent encoder to jointly model the sentence- and token-level representations of each agent. A theme-based anomaly detector further captures the evolving discussion focus in MAS dialogues, while a bi-level score fusion mechanism quantifies token-level contributions for explanation. Extensive experiments across diverse MAS topologies and attack scenarios demonstrate robust detection performance and strong interpretability of XG-Guard.

</details>


### [20] [ISADM: An Integrated STRIDE, ATT&CK, and D3FEND Model for Threat Modeling Against Real-world Adversaries](https://arxiv.org/abs/2512.18751)
*Khondokar Fida Hasan,Hasibul Hossain Shajeeb,Chathura Abeydeera,Benjamin Turnbull,Matthew Warren*

Main category: cs.CR

TL;DR: 提出ISADM混合威胁建模方法，整合STRIDE、MITRE ATTACK和D3FEND框架，通过频率评分机制量化攻击技术流行度，为金融科技提供主动风险评估和优先级排序框架。


<details>
  <summary>Details</summary>
Motivation: 金融科技行业面临日益严峻的网络安全挑战，传统安全框架难以识别特定行业漏洞或适应不断演变的攻击手法，特别是在金融科技这种高度针对性行业。

Method: 提出ISADM混合方法，整合STRIDE的资产中心威胁分类、MITRE ATTACK的真实攻击行为目录和D3FEND的结构化防御知识，采用基于频率的评分机制量化攻击技术流行度。

Result: 通过行业相关案例分析验证，ISADM能够复制实际攻击模式，增强主动威胁建模，指导风险优先级排序和资源分配，为金融科技系统提供更强防御。

Conclusion: ISADM提供全面的混合威胁建模方法，桥接资产中心和攻击者中心分析，通过频率知情、影响感知的优先级方案，结合实证攻击数据和上下文风险分析，提升金融科技网络安全态势。

Abstract: FinTechs increasing connectivity, rapid innovation, and reliance on global digital infrastructures present significant cybersecurity challenges. Traditional cybersecurity frameworks often struggle to identify and prioritize sector-specific vulnerabilities or adapt to evolving adversary tactics, particularly in highly targeted sectors such as FinTech. To address these gaps, we propose ISADM (Integrated STRIDE-ATTACK-D3FEND Threat Model), a novel hybrid methodology applied to FinTech security that integrates STRIDE's asset-centric threat classification with MITRE ATTACK's catalog of real-world adversary behaviors and D3FEND's structured knowledge of countermeasures. ISADM employs a frequency-based scoring mechanism to quantify the prevalence of adversarial Tactics, Techniques, and Procedures (TTPs), enabling a proactive, score-driven risk assessment and prioritization framework. This proactive approach contributes to shifting organizations from reactive defense strategies toward the strategic fortification of critical assets. We validate ISADM through industry-relevant case study analyses, demonstrating how the approach replicates actual attack patterns and strengthens proactive threat modeling, guiding risk prioritization and resource allocation to the most critical vulnerabilities. Overall, ISADM offers a comprehensive hybrid threat modeling methodology that bridges asset-centric and adversary-centric analysis, providing FinTech systems with stronger defenses. The emphasis on real-world validation highlights its practical significance in enhancing the sector's cybersecurity posture through a frequency-informed, impact-aware prioritization scheme that combines empirical attacker data with contextual risk analysis.

</details>


### [21] [Quantum-Resistant Cryptographic Models for Next-Gen Cybersecurity](https://arxiv.org/abs/2512.19005)
*Navin Chhibber,Amber Rastogi,Ankur Mahida,Vatsal Gupta,Piyush Ranjan*

Main category: cs.CR

TL;DR: 该论文综述了后量子密码学(PQC)的最新进展，分析了多种量子抗性密码方案，并提出了混合密码模型以应对量子计算威胁。


<details>
  <summary>Details</summary>
Motivation: 量子计算机的发展对现有主流安全协议构成严重威胁，因为Shor和Grover算法可能破解这些协议。需要开发量子抗性密码系统来保护未来的网络安全。

Method: 论文系统性地综述了后量子密码学的设计、实现和安全性测试，重点关注格基密码、编码密码、多元多项式密码和哈希密码等方案。分析了它们对经典和量子攻击的抵抗能力、分布式系统可扩展性及实际部署。提出了混合密码模型，结合经典高效密码方案和量子抗性密码方案。

Result: 实验结果表明，提出的框架在合理的计算开销下实现了增强的安全性能，能够有效保护未来的网络安全系统。混合模型提供了向后兼容的解决方案，同时改进了前向安全性。

Conclusion: 后量子密码学是应对量子计算威胁的关键技术，多种量子抗性密码方案各有优势，混合密码模型是实用的过渡方案，能够为未来网络安全系统提供强有力的保护。

Abstract: Another threat is the development of large quantum computers, which have a high likelihood of breaking the high popular security protocols because it can use both Shor and Grover algorithms. In order to fix this looming threat, quantum-resistant cryptographic systems, otherwise known as post-quantum cryptography (PQC), are being formulated to protect cybersecurity systems of the future. The current paper presents the state of the art in designing, realizing, and testing the security of robust quantum-resistant algorithms, paying attention to lattice-based, code-based, multivariate polynomial and hash-based cryptography. We discuss their resistance to classical and quantum attackers, distributed system scalability properties, and their deployment in practice (secure communications, blockchain, cloud computing infrastructures). Also, we study a hybrid cryptographic model that integrates the classical efficient cryptography scheme and a quantum-resilient cryptographic scheme to achieve a backward-compatible solution and simultaneously improving the forward security properties. With the experimental findings, it is evident that performance with reasonable computational footprint of the proposed framework succeeds to install amplified security fortitude which successfully harbours prolific cybersecurity systems of the future.

</details>


### [22] [Efficient Jailbreak Mitigation Using Semantic Linear Classification in a Multi-Staged Pipeline](https://arxiv.org/abs/2512.19011)
*Akshaj Prashanth Rao,Advait Singh,Saumya Kumaar Saksena,Dhruv Kumar*

Main category: cs.CR

TL;DR: 提出一个高效的多阶段防御架构，通过基于文本归一化、TF-IDF和线性SVM的语义过滤器，有效防御提示注入和越狱攻击，在保持高精度的同时大幅降低延迟。


<details>
  <summary>Details</summary>
Motivation: 提示注入和越狱攻击对基于大语言模型的系统构成持续安全威胁，现有防御方法在精度和效率方面存在局限，需要更高效的解决方案。

Method: 采用轻量级多阶段防御管道，核心是基于文本归一化、TF-IDF表示和线性SVM分类器的语义过滤器，结合互补的检测和缓解机制。

Result: SVM模块在测试数据上达到93.4%准确率和96.5%特异性，完整管道将整体准确率从35.1%提升到93.4%，平均完成时间从450秒降至47秒，延迟降低超过10倍。

Conclusion: 分阶段、资源高效的防御架构能够同时提升防御精度和效率，为现代LLM应用提供强大安全保障，解决了当前基于模型的调节器的核心限制。

Abstract: Prompt injection and jailbreaking attacks pose persistent security challenges to large language model (LLM)-based systems. We present an efficient and systematically evaluated defense architecture that mitigates these threats through a lightweight, multi-stage pipeline. Its core component is a semantic filter based on text normalization, TF-IDF representations, and a Linear SVM classifier. Despite its simplicity, this module achieves 93.4% accuracy and 96.5% specificity on held-out data, substantially reducing attack throughput while incurring negligible computational overhead.
  Building on this efficient foundation, the full pipeline integrates complementary detection and mitigation mechanisms that operate at successive stages, providing strong robustness with minimal latency. In comparative experiments, our SVM-based configuration improves overall accuracy from 35.1% to 93.4% while reducing average time to completion from approximately 450s to 47s, yielding over 10 times lower latency than ShieldGemma. These results demonstrate that the proposed design simultaneously advances defensive precision and efficiency, addressing a core limitation of current model-based moderators.
  Evaluation across a curated corpus of over 30,000 labeled prompts, including benign, jailbreak, and application-layer injections, confirms that staged, resource-efficient defenses can robustly secure modern LLM-driven applications.

</details>


### [23] [DREAM: Dynamic Red-teaming across Environments for AI Models](https://arxiv.org/abs/2512.19016)
*Liming Lu,Xiang Gu,Junyu Huang,Jiawei Du,Yunhuai Liu,Yongbin Zhou,Shuchao Pang*

Main category: cs.CR

TL;DR: DREAM框架系统评估LLM代理在多阶段动态攻击下的安全性，发现现有代理在超过70%的情况下易受攻击，主要因为上下文脆弱性和无法追踪长期恶意意图。


<details>
  <summary>Details</summary>
Motivation: 现有基准测试主要依赖静态、单轮评估，无法捕捉自适应、长链攻击带来的漏洞。LLM代理在与多样化工具和环境交互时面临复杂的安全挑战，需要更系统的评估框架。

Method: 提出DREAM框架，核心是跨环境对抗知识图(CE-AKG)来维护状态感知的跨域漏洞理解，使用情境化引导策略搜索(C-GPS)算法动态构建攻击链，基于1,986个原子动作和349个数字环境的知识库。

Result: 评估12个领先LLM代理发现关键漏洞：大多数模型在超过70%的情况下攻击链成功，显示状态感知跨环境利用的强大威力。传统安全措施如初始防御提示对多轮交互构建上下文的攻击基本无效。

Conclusion: 当前LLM代理存在两个关键弱点：上下文脆弱性（安全行为无法跨环境转移）和无法追踪长期恶意意图。DREAM作为评估工具发布，以推动更强大的防御机制研究。

Abstract: Large Language Models (LLMs) are increasingly used in agentic systems, where their interactions with diverse tools and environments create complex, multi-stage safety challenges. However, existing benchmarks mostly rely on static, single-turn assessments that miss vulnerabilities from adaptive, long-chain attacks. To fill this gap, we introduce DREAM, a framework for systematic evaluation of LLM agents against dynamic, multi-stage attacks. At its core, DREAM uses a Cross-Environment Adversarial Knowledge Graph (CE-AKG) to maintain stateful, cross-domain understanding of vulnerabilities. This graph guides a Contextualized Guided Policy Search (C-GPS) algorithm that dynamically constructs attack chains from a knowledge base of 1,986 atomic actions across 349 distinct digital environments. Our evaluation of 12 leading LLM agents reveals a critical vulnerability: these attack chains succeed in over 70% of cases for most models, showing the power of stateful, cross-environment exploits. Through analysis of these failures, we identify two key weaknesses in current agents: contextual fragility, where safety behaviors fail to transfer across environments, and an inability to track long-term malicious intent. Our findings also show that traditional safety measures, such as initial defense prompts, are largely ineffective against attacks that build context over multiple interactions. To advance agent safety research, we release DREAM as a tool for evaluating vulnerabilities and developing more robust defenses.

</details>


### [24] [The Erasure Illusion: Stress-Testing the Generalization of LLM Forgetting Evaluation](https://arxiv.org/abs/2512.19025)
*Hengrui Jia,Taoran Li,Jonas Guan,Varun Chandrasekaran*

Main category: cs.CR

TL;DR: 论文指出当前LLM遗忘评估存在缺陷，仅关注目标数据集性能下降不够，模型可能保留语义相关知识。作者提出自动压力测试框架生成语义相关但不同的替代数据集，发现现有指标高估遗忘成功率。


<details>
  <summary>Details</summary>
Motivation: 当前机器学习遗忘评估主要关注模型在目标数据集上的性能下降，但对于LLM来说，这种评估范式不够充分且可能误导。现实中的遗忘需求（如版权或安全）不仅针对目标数据集中的逐字内容，还包括模型从中推导出的更广泛泛化行为。需要更全面的评估方法来检测模型是否真正移除了相关知识。

Method: 提出自动压力测试框架，生成语义上源自目标数据集但在嵌入空间中足够不同的替代数据集。通过比较目标数据集和替代数据集上的遗忘指标分数，来压力测试指标本身的可靠性。在三个LLM家族、三个不同数据集和七个标准指标上进行了广泛评估。

Result: 评估发现广泛的不一致性：当前指标经常高估遗忘成功率，无法检测到通过压力测试数据集暴露的保留知识。LLM可以通过标准遗忘评估，看似"忘记"了目标知识，但同时保留了对语义相邻内容的强大能力。

Conclusion: 仅擦除确切句子并不等同于移除底层知识。需要更全面的评估方法来确保LLM遗忘的有效性，特别是在版权和安全应用场景中。提出的压力测试框架能够揭示现有指标的局限性，为更可靠的遗忘评估提供工具。

Abstract: Machine unlearning aims to remove specific data influences from trained models, a capability essential for adhering to copyright laws and ensuring AI safety. Current unlearning metrics typically measure success by monitoring the model's performance degradation on the specific unlearning dataset ($D_u$). We argue that for Large Language Models (LLMs), this evaluation paradigm is insufficient and potentially misleading. Many real-world uses of unlearning--motivated by copyright or safety--implicitly target not only verbatim content in $D_u$, but also behaviors influenced by the broader generalizations the model derived from it. We demonstrate that LLMs can pass standard unlearning evaluation and appear to have ``forgotten'' the target knowledge, while simultaneously retaining strong capabilities on content that is semantically adjacent to $D_u$. This phenomenon indicates that erasing exact sentences does not necessarily equate to removing the underlying knowledge. To address this gap, we propose \name, an automated stress-testing framework that generates a surrogate dataset, $\tilde{D}_u$. This surrogate set is constructed to be semantically derived from $D_u$ yet sufficiently distinct in embedding space. By comparing unlearning metric scores between $D_u$ and $\tilde{D}_u$, we can stress-test the reliability of the metric itself. Our extensive evaluation across three LLM families (Llama-3-8B, Qwen2.5-7B, and Zephyr-7B-$β$), three distinct datasets, and seven standard metrics reveals widespread inconsistencies. We find that current metrics frequently overestimate unlearning success, failing to detect retained knowledge exposed by our stress-test datasets.

</details>


### [25] [Elevating Intrusion Detection and Security Fortification in Intelligent Networks through Cutting-Edge Machine Learning Paradigms](https://arxiv.org/abs/2512.19037)
*Md Minhazul Islam Munna,Md Mahbubur Rahman,Jaroslav Frnda,Muhammad Shahid Anwar,Alpamis Kutlimuratov*

Main category: cs.CR

TL;DR: 提出基于机器学习的入侵检测框架，结合特征选择和集成学习，在AWID3数据集上达到98%准确率，优于现有方法，用于防御Wi-Fi攻击。


<details>
  <summary>Details</summary>
Motivation: 物联网设备依赖Wi-Fi网络存在安全漏洞（如KRACK和Kr00k攻击），传统入侵检测系统面临过拟合、特征提取不完整、误报率高等问题，需要更有效的解决方案。

Method: 提出多类机器学习入侵检测框架：1）集成先进特征选择技术识别关键属性；2）实现两种ML架构：基线分类器流水线和堆叠集成模型（结合噪声注入、PCA和元学习）。

Result: 在AWID3数据集上，集成架构达到98%准确率、98%精确率、98%召回率，仅2%误报率，优于现有最先进方法。

Conclusion: 结合预处理策略和集成学习能有效增强网络安全防御复杂Wi-Fi攻击，为物联网环境提供可扩展可靠解决方案。未来方向包括实时部署和对抗性弹性测试。

Abstract: The proliferation of IoT devices and their reliance on Wi-Fi networks have introduced significant security vulnerabilities, particularly the KRACK and Kr00k attacks, which exploit weaknesses in WPA2 encryption to intercept and manipulate sensitive data. Traditional IDS using classifiers face challenges such as model overfitting, incomplete feature extraction, and high false positive rates, limiting their effectiveness in real-world deployments. To address these challenges, this study proposes a robust multiclass machine learning based intrusion detection framework. The methodology integrates advanced feature selection techniques to identify critical attributes, mitigating redundancy and enhancing detection accuracy. Two distinct ML architectures are implemented: a baseline classifier pipeline and a stacked ensemble model combining noise injection, Principal Component Analysis (PCA), and meta learning to improve generalization and reduce false positives. Evaluated on the AWID3 data set, the proposed ensemble architecture achieves superior performance, with an accuracy of 98%, precision of 98%, recall of 98%, and a false positive rate of just 2%, outperforming existing state-of-the-art methods. This work demonstrates the efficacy of combining preprocessing strategies with ensemble learning to fortify network security against sophisticated Wi-Fi attacks, offering a scalable and reliable solution for IoT environments. Future directions include real-time deployment and adversarial resilience testing to further enhance the model's adaptability.

</details>


### [26] [ShadowBlock: Efficient Dynamic Anonymous Blocklisting and Its Cross-chain Application](https://arxiv.org/abs/2512.19124)
*Haotian Deng,Mengxuan Liu,Chuan Zhang,Wei Huang,Licheng Wang,Liehuang Zhu*

Main category: cs.CR

TL;DR: ShadowBlock是一个高效的动态匿名黑名单方案，使用伪随机函数和密码累加器构建公共黑名单，允许用户匿名证明自己不在黑名单上，并通过聚合零知识证明提高验证效率。


<details>
  <summary>Details</summary>
Motivation: 社交媒体上的有害内容（如骚扰、暴力煽动、种族歧视等）可能破坏社会和谐甚至违法。传统黑名单技术会牺牲身份隐私，而现有匿名黑名单方案存在动态性差或效率低的问题。

Method: 结合伪随机函数和密码累加器构建公共黑名单，设计聚合零知识证明机制将多个验证操作转换为单个操作，利用累加器特性实现黑名单的高效更新（可重用原有证明而非重新生成）。

Result: 实验表明ShadowBlock比现有方案具有更好的动态性和效率，在跨链身份管理等新兴领域也具有重要价值和广阔前景。

Conclusion: ShadowBlock是一个高效动态的匿名黑名单方案，能有效限制言论自由滥用同时保护用户身份隐私，在社交媒体内容管理和新兴技术领域都有应用价值。

Abstract: Online harassment, incitement to violence, racist behavior, and other harmful content on social media can damage social harmony and even break the law. Traditional blocklisting technologies can block malicious users, but this comes at the expense of identity privacy. The anonymous blocklisting has emerged as an effective mechanism to restrict the abuse of freedom of speech while protecting user identity privacy. However, the state-of-the-art anonymous blocklisting schemes suffer from either poor dynamism or low efficiency. In this paper, we propose $\mathsf{ShadowBlock}$, an efficient dynamic anonymous blocklisting scheme. Specifically, we utilize the pseudorandom function and cryptographic accumulator to construct the public blocklisting, enabling users to prove they are not on the blocklisting in an anonymous manner. To improve verification efficiency, we design an aggregation zero-knowledge proof mechanism that converts multiple verification operations into a single one. In addition, we leverage the accumulator's property to achieve efficient updates of the blocklisting, i.e., the original proof can be reused with minimal updates rather than regenerating the entire proof. Experiments show that $\mathsf{ShadowBlock}$ has better dynamics and efficiency than the existing schemes. Finally, the discussion on applications indicates that $\mathsf{ShadowBlock}$ also holds significant value and has broad prospects in emerging fields such as cross-chain identity management.

</details>


### [27] [Evaluating MCC for Low-Frequency Cyberattack Detection in Imbalanced Intrusion Detection Data](https://arxiv.org/abs/2512.19203)
*Prameshwar Thiyagarajan,Chad A. Williams*

Main category: cs.CR

TL;DR: 该论文评估了在低流量网络攻击检测中，传统准确率指标会夸大模型性能，而马修斯相关系数（MCC）能更可靠地评估分类器在多数类和少数类上的表现。


<details>
  <summary>Details</summary>
Motivation: 现实网络环境中，某些网络攻击的发生率远低于正常流量，导致入侵检测系统难以可靠检测。这种类别不平衡使得传统评估指标（如准确率）往往夸大模型性能，掩盖了对实践中最重要的少数攻击类别的检测失败。

Method: 在CSE-CIC-IDS2018数据集上评估了一组基础分类器和元分类器对低流量攻击的检测能力，使用准确率和马修斯相关系数（MCC）两种指标比较它们的可靠性。

Result: 准确率始终夸大性能表现，而MCC能更准确地评估分类器在多数类和少数类上的性能。元分类方法（如LogitBoost和AdaBoost）在MCC指标下表现出更有效的少数类检测能力，揭示了准确率无法捕捉的趋势。

Conclusion: 研究结果表明需要采用不平衡感知的评估方法，MCC是涉及低流量网络攻击的入侵检测系统研究中更可信的评估指标。

Abstract: In many real-world network environments, several types of cyberattacks occur at very low rates compared to benign traffic, making them difficult for intrusion detection systems (IDS) to detect reliably. This imbalance causes traditional evaluation metrics, such as accuracy, to often overstate model performance in these conditions, masking failures on minority attack classes that are most important in practice. In this paper, we evaluate a set of base and meta classifiers on low-traffic attacks in the CSE-CIC-IDS2018 dataset and compare their reliability in terms of accuracy and Matthews Correlation Coefficient (MCC). The results show that accuracy consistently inflates performance, while MCC provides a more accurate assessment of a classifier's performance across both majority and minority classes. Meta-classification methods, such as LogitBoost and AdaBoost, demonstrate more effective minority class detection when measured by MCC, revealing trends that accuracy fails to capture. These findings establish the need for imbalance-aware evaluation and make MCC a more trustworthy metric for IDS research involving low-traffic cyberattacks.

</details>


### [28] [GShield: Mitigating Poisoning Attacks in Federated Learning](https://arxiv.org/abs/2512.19286)
*Sameera K. M.,Serena Nicolazzo,Antonino Nocera,Vinod P.,Rafidha Rehiman K. A*

Main category: cs.CR

TL;DR: GShield是一种针对联邦学习中数据投毒攻击的新型防御机制，通过聚类和高斯建模学习良性梯度分布，在非IID数据场景下有效检测和隔离恶意客户端更新。


<details>
  <summary>Details</summary>
Motivation: 联邦学习的分布式特性使其容易受到数据投毒攻击，恶意客户端通过注入操纵数据来降低全局模型性能或导致定向误分类，特别是在非独立同分布数据场景下防御更加困难。

Method: GShield通过初始轮次中聚类和高斯建模学习良性梯度分布，建立可信客户端行为基线，然后选择性地聚合符合预期梯度模式的更新，有效隔离对抗性客户端。

Result: 实验表明GShield相比现有方法显著提高了模型鲁棒性，在表格和图像数据集上保持高精度性能，检测恶意和低质量客户端后，目标类准确率提高了43%到65%。

Conclusion: GShield为联邦学习提供了一种有效的防御机制，能够在非IID数据场景下可靠地检测和缓解数据投毒攻击，保护全局模型的完整性。

Abstract: Federated Learning (FL) has recently emerged as a revolutionary approach to collaborative training Machine Learning models. In particular, it enables decentralized model training while preserving data privacy, but its distributed nature makes it highly vulnerable to a severe attack known as Data Poisoning. In such scenarios, malicious clients inject manipulated data into the training process, thereby degrading global model performance or causing targeted misclassification. In this paper, we present a novel defense mechanism called GShield, designed to detect and mitigate malicious and low-quality updates, especially under non-independent and identically distributed (non-IID) data scenarios. GShield operates by learning the distribution of benign gradients through clustering and Gaussian modeling during an initial round, enabling it to establish a reliable baseline of trusted client behavior. With this benign profile, GShield selectively aggregates only those updates that align with the expected gradient patterns, effectively isolating adversarial clients and preserving the integrity of the global model. An extensive experimental campaign demonstrates that our proposed defense significantly improves model robustness compared to the state-of-the-art methods while maintaining a high accuracy of performance across both tabular and image datasets. Furthermore, GShield improves the accuracy of the targeted class by 43\% to 65\% after detecting malicious and low-quality clients.

</details>


### [29] [Causal-Guided Detoxify Backdoor Attack of Open-Weight LoRA Models](https://arxiv.org/abs/2512.19297)
*Linzhi Chen,Yang Sun,Hongru Wei,Yuqi Chen*

Main category: cs.CR

TL;DR: CBA：针对LoRA适配器的因果引导去毒后门攻击框架，无需原始训练数据，通过行为探索生成任务对齐输入，利用因果影响进行权重分配，实现高攻击成功率同时降低误触发率。


<details>
  <summary>Details</summary>
Motivation: LoRA适配器在开源平台（如Hugging Face）的分散传播带来了新的安全漏洞，恶意适配器可以轻易分发并规避传统监管机制。然而，针对LoRA微调的后门攻击研究相对不足，现有方法不适合该场景，因为它们通常依赖不可访问的训练数据，未能考虑LoRA特有结构特性，或存在高误触发率问题。

Method: CBA包含两个关键创新：1）覆盖引导的数据生成管道，通过行为探索合成任务对齐输入；2）因果引导的去毒策略，通过保留任务关键神经元将中毒和干净适配器合并。该方法支持训练后通过因果影响权重分配控制攻击强度，无需重复训练。

Result: 在六个LoRA模型上评估，CBA实现了高攻击成功率，同时将误触发率相比基线方法降低了50-70%。此外，该方法对最先进的后门防御表现出更强的抵抗能力，突显了其隐蔽性和鲁棒性。

Conclusion: CBA是针对开放权重LoRA模型的新型后门攻击框架，解决了现有方法在LoRA场景下的局限性，展示了无需原始训练数据、高隐蔽性、低误触发率的攻击能力，对LoRA适配器的安全部署提出了重要警示。

Abstract: Low-Rank Adaptation (LoRA) has emerged as an efficient method for fine-tuning large language models (LLMs) and is widely adopted within the open-source community. However, the decentralized dissemination of LoRA adapters through platforms such as Hugging Face introduces novel security vulnerabilities: malicious adapters can be easily distributed and evade conventional oversight mechanisms. Despite these risks, backdoor attacks targeting LoRA-based fine-tuning remain relatively underexplored. Existing backdoor attack strategies are ill-suited to this setting, as they often rely on inaccessible training data, fail to account for the structural properties unique to LoRA, or suffer from high false trigger rates (FTR), thereby compromising their stealth. To address these challenges, we propose Causal-Guided Detoxify Backdoor Attack (CBA), a novel backdoor attack framework specifically designed for open-weight LoRA models. CBA operates without access to original training data and achieves high stealth through two key innovations: (1) a coverage-guided data generation pipeline that synthesizes task-aligned inputs via behavioral exploration, and (2) a causal-guided detoxification strategy that merges poisoned and clean adapters by preserving task-critical neurons. Unlike prior approaches, CBA enables post-training control over attack intensity through causal influence-based weight allocation, eliminating the need for repeated retraining. Evaluated across six LoRA models, CBA achieves high attack success rates while reducing FTR by 50-70\% compared to baseline methods. Furthermore, it demonstrates enhanced resistance to state-of-the-art backdoor defenses, highlighting its stealth and robustness.

</details>


### [30] [Protecting Quantum Circuits Through Compiler-Resistant Obfuscation](https://arxiv.org/abs/2512.19314)
*Pradyun Parayil,Amal Raj,Vivek Balachandran*

Main category: cs.CR

TL;DR: 提出一种基于随机U3变换的量子电路混淆方法，在保持功能性的同时隐藏电路结构，实现93%以上语义准确率且运行时开销最小


<details>
  <summary>Details</summary>
Motivation: 随着量子计算发展，保护量子算法知识产权变得日益重要。现有方法通常对结构和统计分析防御有限，或引入显著开销，需要更有效的量子电路混淆技术

Method: 使用随机U3变换来混淆量子电路结构，在QASM电路上通过Qiskit AER实现，保持电路功能性的同时隐藏原始结构

Result: 在QASM电路上实现超过93%的语义准确率，运行时开销最小，对逆向工程和结构推断表现出强抵抗力

Conclusion: 该方法是一种实用有效的量子软件保护方法，能够保护量子算法知识产权，防止盗窃和逆向工程

Abstract: Quantum circuit obfuscation is becoming increasingly important to prevent theft and reverse engineering of quantum algorithms. As quantum computing advances, the need to protect the intellectual property contained in quantum circuits continues to grow. Existing methods often provide limited defense against structural and statistical analysis or introduce considerable overhead. In this paper, we propose a novel quantum obfuscation method that uses randomized U3 transformations to conceal circuit structure while preserving functionality. We implement and assess our approach on QASM circuits using Qiskit AER, achieving over 93\% semantic accuracy with minimal runtime overhead. The method demonstrates strong resistance to reverse engineering and structural inference, making it a practical and effective approach for quantum software protection.

</details>


### [31] [From Retrieval to Reasoning: A Framework for Cyber Threat Intelligence NER with Explicit and Adaptive Instructions](https://arxiv.org/abs/2512.19414)
*Jiaren Peng,Hongda Sun,Xuan Tian,Cheng Huang,Zeqing Li,Rui Yan*

Main category: cs.CR

TL;DR: TTPrompt框架通过将CTI的TTP概念映射为指令层次结构，从隐式归纳转向显式指令，显著提升CTI命名实体识别性能，仅用1%训练数据即可媲美全数据微调模型。


<details>
  <summary>Details</summary>
Motivation: 当前基于检索的上下文学习范式存在根本缺陷：其成功主要源于检索示例中实体类型的偶然重叠，而非全局语义相似性，这暴露了依赖不可靠隐式归纳的局限性。

Method: 提出TTPrompt框架，将CTI的战术、技术和程序概念映射为指令层次结构：任务定义为战术，指导策略为技术，标注指南为程序。引入反馈驱动的指令细化，使LLM能够通过最小标注数据学习错误来自我优化指南，适应不同的标注方言。

Result: 在五个CTI NER基准测试中，TTPrompt始终优于基于检索的基线方法。仅用1%训练数据进行细化后，性能即可媲美全数据集微调的模型。在LADDER上达到71.96%的Micro F1，接近微调基线；在复杂的CTINexus上，Macro F1超过微调的ACLM模型10.91%。

Conclusion: TTPrompt通过从隐式归纳转向显式指令，有效解决了当前CTI NER方法的局限性，展示了指令层次结构和反馈驱动细化的有效性，为CTI自动化提供了更可靠的解决方案。

Abstract: The automation of Cyber Threat Intelligence (CTI) relies heavily on Named Entity Recognition (NER) to extract critical entities from unstructured text. Currently, Large Language Models (LLMs) primarily address this task through retrieval-based In-Context Learning (ICL). This paper analyzes this mainstream paradigm, revealing a fundamental flaw: its success stems not from global semantic similarity but largely from the incidental overlap of entity types within retrieved examples. This exposes the limitations of relying on unreliable implicit induction. To address this, we propose TTPrompt, a framework shifting from implicit induction to explicit instruction. TTPrompt maps the core concepts of CTI's Tactics, Techniques, and Procedures (TTPs) into an instruction hierarchy: formulating task definitions as Tactics, guiding strategies as Techniques, and annotation guidelines as Procedures. Furthermore, to handle the adaptability challenge of static guidelines, we introduce Feedback-driven Instruction Refinement (FIR). FIR enables LLMs to self-refine guidelines by learning from errors on minimal labeled data, adapting to distinct annotation dialects. Experiments on five CTI NER benchmarks demonstrate that TTPrompt consistently surpasses retrieval-based baselines. Notably, with refinement on just 1% of training data, it rivals models fine-tuned on the full dataset. For instance, on LADDER, its Micro F1 of 71.96% approaches the fine-tuned baseline, and on the complex CTINexus, its Macro F1 exceeds the fine-tuned ACLM model by 10.91%.

</details>
