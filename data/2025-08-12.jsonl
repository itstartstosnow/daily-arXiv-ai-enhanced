{"id": "2508.06643", "categories": ["cs.CR"], "pdf": "https://arxiv.org/pdf/2508.06643", "abs": "https://arxiv.org/abs/2508.06643", "authors": ["Joshua Bailey", "Charles Nicholas"], "title": "Symbolic Execution in Practice: A Survey of Applications in Vulnerability, Malware, Firmware, and Protocol Analysis", "comment": "v2: Adds a subsection to Future Directions discussing the role of\n  LLMs in symbolic execution", "summary": "Symbolic execution is a powerful program analysis technique that allows for\nthe systematic exploration of all program paths. Path explosion, where the\nnumber of states to track becomes unwieldy, is one of the biggest challenges\nhindering symbolic execution's practical application. To combat this,\nresearchers have employed various strategies to enable symbolic execution on\ncomplex software systems. This paper introduces a systematic taxonomy of these\nstrategies, categorizing them into two primary approaches: Scope Reduction,\nwhich aims to reduce the scope of symbolic execution to manageable portions of\ncode, and Guidance Heuristics, which steer the symbolic execution engine toward\npromising paths. Using this taxonomy as a lens, we survey applications of\nsymbolic executions in several domains such as vulnerability analysis, malware\nanalysis, firmware re-hosting, and network protocol analysis. Finally, we\nidentify promising directions for future research, including the application of\nsymbolic execution to real-time operating systems and modern, type-safe\nlanguages."}
{"id": "2508.06734", "categories": ["cs.CR", "cs.LG"], "pdf": "https://arxiv.org/pdf/2508.06734", "abs": "https://arxiv.org/abs/2508.06734", "authors": ["Ngoc N. Tran", "Anwar Said", "Waseem Abbas", "Tyler Derr", "Xenofon D. Koutsoukos"], "title": "Mitigating Distribution Shift in Graph-Based Android Malware Classification via Function Metadata and LLM Embeddings", "comment": "13 pages, 3 figures, 7 tables, under review", "summary": "Graph-based malware classifiers can achieve over 94% accuracy on standard\nAndroid datasets, yet we find they suffer accuracy drops of up to 45% when\nevaluated on previously unseen malware variants from the same family - a\nscenario where strong generalization would typically be expected. This\nhighlights a key limitation in existing approaches: both the model\narchitectures and their structure-only representations often fail to capture\ndeeper semantic patterns. In this work, we propose a robust semantic enrichment\nframework that enhances function call graphs with contextual features,\nincluding function-level metadata and, when available, code embeddings derived\nfrom large language models. The framework is designed to operate under\nreal-world constraints where feature availability is inconsistent, and supports\nflexible integration of semantic signals. To evaluate generalization under\nrealistic domain and temporal shifts, we introduce two new benchmarks:\nMalNet-Tiny-Common and MalNet-Tiny-Distinct, constructed using malware family\npartitioning to simulate cross-family generalization and evolving threat\nbehavior. Experiments across multiple graph neural network backbones show that\nour method improves classification performance by up to 8% under distribution\nshift and consistently enhances robustness when integrated with\nadaptation-based methods. These results offer a practical path toward building\nresilient malware detection systems in evolving threat environments."}
{"id": "2508.06789", "categories": ["cs.CR"], "pdf": "https://arxiv.org/pdf/2508.06789", "abs": "https://arxiv.org/abs/2508.06789", "authors": ["Wei Wang", "Xiangyun Tang", "Yajie Wang", "Yijing Lin", "Tao Zhang", "Meng Shen", "Dusit Niyato", "Liehuang Zhu"], "title": "Label Inference Attacks against Federated Unlearning", "comment": null, "summary": "Federated Unlearning (FU) has emerged as a promising solution to respond to\nthe right to be forgotten of clients, by allowing clients to erase their data\nfrom global models without compromising model performance. Unfortunately,\nresearchers find that the parameter variations of models induced by FU expose\nclients' data information, enabling attackers to infer the label of unlearning\ndata, while label inference attacks against FU remain unexplored. In this\npaper, we introduce and analyze a new privacy threat against FU and propose a\nnovel label inference attack, ULIA, which can infer unlearning data labels\nacross three FU levels. To address the unique challenges of inferring labels\nvia the models variations, we design a gradient-label mapping mechanism in ULIA\nthat establishes a relationship between gradient variations and unlearning\nlabels, enabling inferring labels on accumulated model variations. We evaluate\nULIA on both IID and non-IID settings. Experimental results show that in the\nIID setting, ULIA achieves a 100% Attack Success Rate (ASR) under both\nclass-level and client-level unlearning. Even when only 1% of a user's local\ndata is forgotten, ULIA still attains an ASR ranging from 93% to 62.3%."}
{"id": "2508.06795", "categories": ["cs.CR"], "pdf": "https://arxiv.org/pdf/2508.06795", "abs": "https://arxiv.org/abs/2508.06795", "authors": ["Jeremiah Blocki", "Blake Holman"], "title": "Towards Practical Data-Dependent Memory-Hard Functions with Optimal Sustained Space Trade-offs in the Parallel Random Oracle Model", "comment": null, "summary": "Memory-Hard Functions (MHF) are a useful cryptographic primitive to build\negalitarian proofs-of-work and to help protect low entropy secrets (e.g., user\npasswords) against brute-forces attacks. Ideally, we would like for a MHF to\nhave the property that (1) an honest party can evaluate the function in\nsequential time $\\Omega(N)$, and (2) any parallel party that evaluates the\nfunction is forced to lockup $\\Omega(N)$ memory for $\\Omega(N)$ sequential\nsteps. Unfortunately, this goal is not quite achievable, so prior work of\nBlocki and Holman [BH22] focused on designing MHFs with strong tradeoff\nguarantees between sustained-space complexity (SSC) and cumulative memory costs\n(CMC). However, their theoretical construction is not suitable for practical\ndeployment due to the reliance on expensive constructions of combinatorial\ngraphs. Furthermore, there is no formal justification for the heuristic use of\nthe dynamic pebbling game in MHF analysis so we cannot rule out the possibility\nthat there are more efficient attacks in the Parallel Random Oracle Model\n(PROM). Towards the goal of developing a practical MHF with provably strong\nSSC/CMC tradeoffs we develop a new MHF called EGSample which does not rely on\nexpensive combinatorial constructions like [BH22]. In the dynamic pebbling\nmodel, we prove equivalent SSC/CMC tradeoffs for EGSample i.e., any the dynamic\npebbling strategy either (1) locks up $\\Omega(N)$ memory for $\\Omega(N)$ steps,\nor (2) incurs cumulative memory cost at least $\\Omega(N^{3-\\epsilon})$. We also\ndevelop new techniques to directly establish SSC/CMC tradeoffs in the parallel\nrandom oracle model. In particular, we prove that {\\em any} PROM algorithm\nevaluating our MHF either (1) locks up $\\Omega(N)$ blocks of memory for\n$\\Omega(N)$ steps or (2) incurs cumulative memory cost at least\n$\\Omega(N^{2.5-\\epsilon})$."}
{"id": "2508.06837", "categories": ["cs.CR"], "pdf": "https://arxiv.org/pdf/2508.06837", "abs": "https://arxiv.org/abs/2508.06837", "authors": ["Shiqian Zhao", "Chong Wang", "Yiming Li", "Yihao Huang", "Wenjie Qu", "Siew-Kei Lam", "Yi Xie", "Kangjie Chen", "Jie Zhang", "Tianwei Zhang"], "title": "Towards Effective Prompt Stealing Attack against Text-to-Image Diffusion Models", "comment": "This paper proposes an effective training-free, proxy-in-the-loop,\n  and search-based prompt-stealing scheme against T2I models", "summary": "Text-to-Image (T2I) models, represented by DALL$\\cdot$E and Midjourney, have\ngained huge popularity for creating realistic images. The quality of these\nimages relies on the carefully engineered prompts, which have become valuable\nintellectual property. While skilled prompters showcase their AI-generated art\non markets to attract buyers, this business incidentally exposes them to\n\\textit{prompt stealing attacks}. Existing state-of-the-art attack techniques\nreconstruct the prompts from a fixed set of modifiers (i.e., style\ndescriptions) with model-specific training, which exhibit restricted\nadaptability and effectiveness to diverse showcases (i.e., target images) and\ndiffusion models.\n  To alleviate these limitations, we propose Prometheus, a training-free,\nproxy-in-the-loop, search-based prompt-stealing attack, which reverse-engineers\nthe valuable prompts of the showcases by interacting with a local proxy model.\nIt consists of three innovative designs. First, we introduce dynamic modifiers,\nas a supplement to static modifiers used in prior works. These dynamic\nmodifiers provide more details specific to the showcases, and we exploit NLP\nanalysis to generate them on the fly. Second, we design a contextual matching\nalgorithm to sort both dynamic and static modifiers. This offline process helps\nreduce the search space of the subsequent step. Third, we interact with a local\nproxy model to invert the prompts with a greedy search algorithm. Based on the\nfeedback guidance, we refine the prompt to achieve higher fidelity. The\nevaluation results show that Prometheus successfully extracts prompts from\npopular platforms like PromptBase and AIFrog against diverse victim models,\nincluding Midjourney, Leonardo.ai, and DALL$\\cdot$E, with an ASR improvement of\n25.0\\%. We also validate that Prometheus is resistant to extensive potential\ndefenses, further highlighting its severity in practice."}
{"id": "2508.07053", "categories": ["cs.CR"], "pdf": "https://arxiv.org/pdf/2508.07053", "abs": "https://arxiv.org/abs/2508.07053", "authors": ["Sajib Talukder", "Nur Imtiazul Haque", "Khandakar Ashrafi Akbar"], "title": "SPARE: Securing Progressive Web Applications Against Unauthorized Replications", "comment": "22 pages,12 figures, 3 Tables", "summary": "WebView applications are widely used in mobile applications to display web\ncontent directly within the app, enhancing user engagement by eliminating the\nneed to open an external browser and providing a seamless experience.\nProgressive Web Applications (PWAs) further improve usability by combining the\naccessibility of web apps with the speed, offline capabilities, and\nresponsiveness of native applications. However, malicious developers can\nexploit this technology by duplicating PWA web links to create counterfeit\nnative apps, monetizing through user diversion. This unethical practice poses\nsignificant risks to users and the original application developers,\nunderscoring the need for robust security measures to prevent unauthorized\nreplication. Considering the one-way communication of Trusted Web Activity (a\nmethod for integrating web content into Android applications) and PWAs, we\npropose a query parameter-based practical security solution to defend against\nor mitigate such attacks. We analyze the vulnerabilities of our proposed\nsecurity solution to assess its effectiveness and introduce advanced measures\nto address any identified weaknesses, presenting a comprehensive defense\nframework. As part of our work, we developed a prototype web application that\nsecures PWAs from replication by embedding a combination of Unix timestamps and\ndevice identifiers into the query parameters. We evaluate the effectiveness of\nthis defense strategy by simulating an advanced attack scenario. Additionally,\nwe created a realistic dataset reflecting mobile app user behavior, modeled\nusing a Zipfian distribution, to validate our framework."}
{"id": "2508.07094", "categories": ["cs.CR"], "pdf": "https://arxiv.org/pdf/2508.07094", "abs": "https://arxiv.org/abs/2508.07094", "authors": ["Pasquale De Rosa", "Pascal Felber", "Valerio Schiavoni"], "title": "ScamDetect: Towards a Robust, Agnostic Framework to Uncover Threats in Smart Contracts", "comment": null, "summary": "Smart contracts have transformed decentralized finance by enabling\nprogrammable, trustless transactions. However, their widespread adoption and\ngrowing financial significance have attracted persistent and sophisticated\nthreats, such as phishing campaigns and contract-level exploits. Traditional\ntransaction-based threat detection methods often expose sensitive user data and\ninteractions, raising privacy and security concerns. In response, static\nbytecode analysis has emerged as a proactive mitigation strategy, identifying\nmalicious contracts before they execute harmful actions.Building on this\napproach, we introduced PhishingHook, the first machine-learning-based\nframework for detecting phishing activities in smart contracts via static\nbytecode and opcode analysis, achieving approximately 90% detection accuracy.\nNevertheless, two pressing challenges remain: (1) the increasing use of\nsophisticated bytecode obfuscation techniques designed to evade static\nanalysis, and (2) the heterogeneity of blockchain environments requiring\nplatform-agnostic solutions.This paper presents a vision for ScamDetect (Smart\nContract Agnostic Malware Detector), a robust, modular, and platform-agnostic\nframework for smart contract malware detection. Over the next 2.5 years,\nScamDetect will evolve in two stages: first, by tackling obfuscated Ethereum\nVirtual Machine (EVM) bytecode through graph neural network (GNN) analysis of\ncontrol flow graphs (CFGs), leveraging GNNs' ability to capture complex\nstructural patterns beyond opcode sequences; and second, by generalizing\ndetection capabilities to emerging runtimes such as WASM. ScamDetect aims to\nenable proactive, scalable security for the future of decentralized ecosystems."}
{"id": "2508.07139", "categories": ["cs.CR", "cs.AI"], "pdf": "https://arxiv.org/pdf/2508.07139", "abs": "https://arxiv.org/abs/2508.07139", "authors": ["Ivan Zhang"], "title": "A Real-Time, Self-Tuning Moderator Framework for Adversarial Prompt Detection", "comment": "10 pages, 1 figure", "summary": "Ensuring LLM alignment is critical to information security as AI models\nbecome increasingly widespread and integrated in society. Unfortunately, many\ndefenses against adversarial attacks and jailbreaking on LLMs cannot adapt\nquickly to new attacks, degrade model responses to benign prompts, or introduce\nsignificant barriers to scalable implementation. To mitigate these challenges,\nwe introduce a real-time, self-tuning (RTST) moderator framework to defend\nagainst adversarial attacks while maintaining a lightweight training footprint.\nWe empirically evaluate its effectiveness using Google's Gemini models against\nmodern, effective jailbreaks. Our results demonstrate the advantages of an\nadaptive, minimally intrusive framework for jailbreak defense over traditional\nfine-tuning or classifier models."}
{"id": "2508.07190", "categories": ["cs.CR", "cs.ET"], "pdf": "https://arxiv.org/pdf/2508.07190", "abs": "https://arxiv.org/abs/2508.07190", "authors": ["Minfeng Qi", "Qin Wang", "Guangsheng Yu", "Ruiqiang Li", "Victor Zhou", "Shiping Chen"], "title": "Understanding NFTs from EIP Standards", "comment": null, "summary": "We argue that the technical foundations of non-fungible tokens (NFTs) remain\ninadequately understood. Prior research has focused on market dynamics, user\nbehavior, and isolated security incidents, yet systematic analysis of the\nstandards underpinning NFT functionality is largely absent.\n  We present the first study of NFTs through the lens of Ethereum Improvement\nProposals (EIPs). We conduct a large-scale empirical analysis of 191\nNFT-related EIPs and 10K+ Ethereum Magicians discussions (as of July, 2025). We\nintegrate multi-dimensional analyses including the automated parsing of\nSolidity interfaces, graph-based modeling of inheritance structures,\ncontributor profiling, and mining of community discussion data. We distinguish\nfoundational from emerging standards, expose poor cross-version\ninteroperability, and show that growing functional complexity heightens\nsecurity risks."}
{"id": "2508.07263", "categories": ["cs.CR", "cs.CV"], "pdf": "https://arxiv.org/pdf/2508.07263", "abs": "https://arxiv.org/abs/2508.07263", "authors": ["Qingyuan Zeng", "Shu Jiang", "Jiajing Lin", "Zhenzhong Wang", "Kay Chen Tan", "Min Jiang"], "title": "Fading the Digital Ink: A Universal Black-Box Attack Framework for 3DGS Watermarking Systems", "comment": null, "summary": "With the rise of 3D Gaussian Splatting (3DGS), a variety of digital\nwatermarking techniques, embedding either 1D bitstreams or 2D images, are used\nfor copyright protection. However, the robustness of these watermarking\ntechniques against potential attacks remains underexplored. This paper\nintroduces the first universal black-box attack framework, the Group-based\nMulti-objective Evolutionary Attack (GMEA), designed to challenge these\nwatermarking systems. We formulate the attack as a large-scale multi-objective\noptimization problem, balancing watermark removal with visual quality. In a\nblack-box setting, we introduce an indirect objective function that blinds the\nwatermark detector by minimizing the standard deviation of features extracted\nby a convolutional network, thus rendering the feature maps uninformative. To\nmanage the vast search space of 3DGS models, we employ a group-based\noptimization strategy to partition the model into multiple, independent\nsub-optimization problems. Experiments demonstrate that our framework\neffectively removes both 1D and 2D watermarks from mainstream 3DGS watermarking\nmethods while maintaining high visual fidelity. This work reveals critical\nvulnerabilities in existing 3DGS copyright protection schemes and calls for the\ndevelopment of more robust watermarking systems."}
{"id": "2508.07510", "categories": ["cs.CR", "cs.SY", "eess.SY"], "pdf": "https://arxiv.org/pdf/2508.07510", "abs": "https://arxiv.org/abs/2508.07510", "authors": ["Hoang-Long Pham", "Duy-Hieu Bui", "Xuan-Tu Tran", "Orazio Aiello"], "title": "SRAM-based Physically Unclonable Function using Lightweight Hamming-Code Fuzzy Extractor for Energy Harvesting Beat Sensors", "comment": null, "summary": "Batteryless energy harvesting IoT sensor nodes such as beat sensors can be\ndeployed in millions without the need to replace batteries. They are\nultra-low-power and cost-effective wireless sensor nodes without the\nmaintenance cost and can work for 24 hours/365 days. However, they were not\nequipped with security mechanisms to protect user data. Data encryption and\nauthentication can be used to secure beat sensor applications, but generating a\nsecure cryptographic key is challenging. In this paper, we proposed an\nSRAM-based Physically Unclonable Function (PUF) combining a high-reliability\nbit selection algorithm with a lightweight error-correcting code to generate\nreliable secure keys for data encryption. The system employs a feature of beat\nsensors, in which the microcontroller is powered on to transmit the ID signals\nand then powered off. This fits the SRAM-based PUF requirement, which needs the\nSRAM to be powered off to read out its random values. The proposed system has\nbeen evaluated on STM32 Cortex M0+ microcontrollers and has been implemented to\nprotect important data on beat sensors."}
{"id": "2508.07745", "categories": ["cs.CR", "cs.AI", "cs.SE"], "pdf": "https://arxiv.org/pdf/2508.07745", "abs": "https://arxiv.org/abs/2508.07745", "authors": ["Jiongchi Yu", "Xiaofei Xie", "Qiang Hu", "Yuhan Ma", "Ziming Zhao"], "title": "Chimera: Harnessing Multi-Agent LLMs for Automatic Insider Threat Simulation", "comment": "23 pages", "summary": "Insider threats, which can lead to severe losses, remain a major security\nconcern. While machine learning-based insider threat detection (ITD) methods\nhave shown promising results, their progress is hindered by the scarcity of\nhigh-quality data. Enterprise data is sensitive and rarely accessible, while\npublicly available datasets, when limited in scale due to cost, lack sufficient\nreal-world coverage; and when purely synthetic, they fail to capture rich\nsemantics and realistic user behavior. To address this, we propose Chimera, the\nfirst large language model (LLM)-based multi-agent framework that automatically\nsimulates both benign and malicious insider activities and collects diverse\nlogs across diverse enterprise environments. Chimera models each employee with\nagents that have role-specific behavior and integrates modules for group\nmeetings, pairwise interactions, and autonomous scheduling, capturing realistic\norganizational dynamics. It incorporates 15 types of insider attacks (e.g., IP\ntheft, system sabotage) and has been deployed to simulate activities in three\nsensitive domains: technology company, finance corporation, and medical\ninstitution, producing a new dataset, ChimeraLog. We assess ChimeraLog via\nhuman studies and quantitative analysis, confirming its diversity, realism, and\npresence of explainable threat patterns. Evaluations of existing ITD methods\nshow an average F1-score of 0.83, which is significantly lower than 0.99 on the\nCERT dataset, demonstrating ChimeraLog's higher difficulty and utility for\nadvancing ITD research."}
{"id": "2508.07840", "categories": ["cs.CR"], "pdf": "https://arxiv.org/pdf/2508.07840", "abs": "https://arxiv.org/abs/2508.07840", "authors": ["Mohsin Khan", "Dag Johansen", "Håvard Dagenborg"], "title": "A Comparative Analysis of Lightweight Hash Functions Using AVR ATXMega128 and ChipWhisperer", "comment": "16 pages, 9 figures, and 2 tables", "summary": "Lightweight hash functions have become important building blocks for security\nin embedded and IoT systems. A plethora of algorithms have been proposed and\nstandardized, providing a wide range of performance trade-off options for\ndevelopers to choose from. This paper presents a comparative analysis of 22 key\nsoftware-based lightweight hash functions, including the finalist from the\nSHA-3 competition. We use a novel benchmark methodology that combines an AVR\nATXMega128 microcontroller with the ChipWhisperer cryptanalysis platform and\nevaluate and compare the various hash functions along several dimensions,\nincluding execution speed, % measured in Cycles per Byte (CpB), memory\nfootprint, and energy consumption. Using the composite E-RANK metric, we\nprovide new insight into the various trade-offs each hash function offers to\nsystem developers."}
{"id": "2508.07873", "categories": ["cs.CR", "cs.DC", "cs.LG"], "pdf": "https://arxiv.org/pdf/2508.07873", "abs": "https://arxiv.org/abs/2508.07873", "authors": ["Samaneh Mohammadi", "Vasileios Tsouvalas", "Iraklis Symeonidis", "Ali Balador", "Tanir Ozcelebi", "Francesco Flammini", "Nirvana Meratnia"], "title": "EFU: Enforcing Federated Unlearning via Functional Encryption", "comment": null, "summary": "Federated unlearning (FU) algorithms allow clients in federated settings to\nexercise their ''right to be forgotten'' by removing the influence of their\ndata from a collaboratively trained model. Existing FU methods maintain data\nprivacy by performing unlearning locally on the client-side and sending\ntargeted updates to the server without exposing forgotten data; yet they often\nrely on server-side cooperation, revealing the client's intent and identity\nwithout enforcement guarantees - compromising autonomy and unlearning privacy.\nIn this work, we propose EFU (Enforced Federated Unlearning), a\ncryptographically enforced FU framework that enables clients to initiate\nunlearning while concealing its occurrence from the server. Specifically, EFU\nleverages functional encryption to bind encrypted updates to specific\naggregation functions, ensuring the server can neither perform unauthorized\ncomputations nor detect or skip unlearning requests. To further mask behavioral\nand parameter shifts in the aggregated model, we incorporate auxiliary\nunlearning losses based on adversarial examples and parameter importance\nregularization. Extensive experiments show that EFU achieves near-random\naccuracy on forgotten data while maintaining performance comparable to full\nretraining across datasets and neural architectures - all while concealing\nunlearning intent from the server. Furthermore, we demonstrate that EFU is\nagnostic to the underlying unlearning algorithm, enabling secure,\nfunction-hiding, and verifiable unlearning for any client-side FU mechanism\nthat issues targeted updates."}
{"id": "2508.08029", "categories": ["cs.CR", "cs.ET", "cs.LG"], "pdf": "https://arxiv.org/pdf/2508.08029", "abs": "https://arxiv.org/abs/2508.08029", "authors": ["Thusitha Dayaratne", "Ngoc Duy Pham", "Viet Vo", "Shangqi Lai", "Sharif Abuadbba", "Hajime Suzuki", "Xingliang Yuan", "Carsten Rudolph"], "title": "Robust Anomaly Detection in O-RAN: Leveraging LLMs against Data Manipulation Attacks", "comment": null, "summary": "The introduction of 5G and the Open Radio Access Network (O-RAN) architecture\nhas enabled more flexible and intelligent network deployments. However, the\nincreased complexity and openness of these architectures also introduce novel\nsecurity challenges, such as data manipulation attacks on the semi-standardised\nShared Data Layer (SDL) within the O-RAN platform through malicious xApps. In\nparticular, malicious xApps can exploit this vulnerability by introducing\nsubtle Unicode-wise alterations (hypoglyphs) into the data that are being used\nby traditional machine learning (ML)-based anomaly detection methods. These\nUnicode-wise manipulations can potentially bypass detection and cause failures\nin anomaly detection systems based on traditional ML, such as AutoEncoders,\nwhich are unable to process hypoglyphed data without crashing. We investigate\nthe use of Large Language Models (LLMs) for anomaly detection within the O-RAN\narchitecture to address this challenge. We demonstrate that LLM-based xApps\nmaintain robust operational performance and are capable of processing\nmanipulated messages without crashing. While initial detection accuracy\nrequires further improvements, our results highlight the robustness of LLMs to\nadversarial attacks such as hypoglyphs in input data. There is potential to use\ntheir adaptability through prompt engineering to further improve the accuracy,\nalthough this requires further research. Additionally, we show that LLMs\nachieve low detection latency (under 0.07 seconds), making them suitable for\nNear-Real-Time (Near-RT) RIC deployments."}
{"id": "2508.08031", "categories": ["cs.CR", "cs.CV"], "pdf": "https://arxiv.org/pdf/2508.08031", "abs": "https://arxiv.org/abs/2508.08031", "authors": ["Jiayao Wang", "Yang Song", "Zhendong Zhao", "Jiale Zhang", "Qilin Wu", "Junwu Zhu", "Dongfang Zhao"], "title": "IPBA: Imperceptible Perturbation Backdoor Attack in Federated Self-Supervised Learning", "comment": null, "summary": "Federated self-supervised learning (FSSL) combines the advantages of\ndecentralized modeling and unlabeled representation learning, serving as a\ncutting-edge paradigm with strong potential for scalability and privacy\npreservation. Although FSSL has garnered increasing attention, research\nindicates that it remains vulnerable to backdoor attacks. Existing methods\ngenerally rely on visually obvious triggers, which makes it difficult to meet\nthe requirements for stealth and practicality in real-world deployment. In this\npaper, we propose an imperceptible and effective backdoor attack method against\nFSSL, called IPBA. Our empirical study reveals that existing imperceptible\ntriggers face a series of challenges in FSSL, particularly limited\ntransferability, feature entanglement with augmented samples, and\nout-of-distribution properties. These issues collectively undermine the\neffectiveness and stealthiness of traditional backdoor attacks in FSSL. To\novercome these challenges, IPBA decouples the feature distributions of backdoor\nand augmented samples, and introduces Sliced-Wasserstein distance to mitigate\nthe out-of-distribution properties of backdoor samples, thereby optimizing the\ntrigger generation process. Our experimental results on several FSSL scenarios\nand datasets show that IPBA significantly outperforms existing backdoor attack\nmethods in performance and exhibits strong robustness under various defense\nmechanisms."}
{"id": "2508.08043", "categories": ["cs.CR", "cs.HC"], "pdf": "https://arxiv.org/pdf/2508.08043", "abs": "https://arxiv.org/abs/2508.08043", "authors": ["Yancheng Jiang", "Yan Jiang", "Ruochen Zhou", "Yi-Chao Chen", "Xiaoyu Ji", "Wenyuan Xu"], "title": "False Reality: Uncovering Sensor-induced Human-VR Interaction Vulnerability", "comment": null, "summary": "Virtual Reality (VR) techniques, serving as the bridge between the real and\nvirtual worlds, have boomed and are widely used in manufacturing, remote\nhealthcare, gaming, etc. Specifically, VR systems offer users immersive\nexperiences that include both perceptions and actions. Various studies have\ndemonstrated that attackers can manipulate VR software to influence users'\ninteractions, including perception and actions. However, such attacks typically\nrequire strong access and specialized expertise. In this paper, we are the\nfirst to present a systematic analysis of physical attacks against VR systems\nand introduce False Reality, a new attack threat to VR devices without\nrequiring access to or modification of their software. False Reality disturbs\nVR system services by tampering with sensor measurements, and further spoofing\nusers' perception even inducing harmful actions, e.g., inducing dizziness or\ncausing users to crash into obstacles, by exploiting perceptual and\npsychological effects. We formalize these threats through an attack pathway\nframework and validate three representative pathways via physical experiments\nand user studies on five commercial VR devices. Finally, we further propose a\ndefense prototype to mitigate such threats. Our findings shall provide valuable\ninsights for enhancing the security and resilience of future VR systems."}
{"id": "2508.08068", "categories": ["cs.CR", "cs.DC"], "pdf": "https://arxiv.org/pdf/2508.08068", "abs": "https://arxiv.org/abs/2508.08068", "authors": ["Yuval Efron", "Joachim Neu", "Toniann Pitassi"], "title": "Fully-Fluctuating Participation in Sleepy Consensus", "comment": null, "summary": "Proof-of-work allows Bitcoin to boast security amidst arbitrary fluctuations\nin participation of miners throughout time, so long as, at any point in time, a\nmajority of hash power is honest. In recent years, however, the pendulum has\nshifted in favor of proof-of-stake-based consensus protocols. There, the sleepy\nmodel is the most prominent model for handling fluctuating participation of\nnodes. However, to date, no protocol in the sleepy model rivals Bitcoin in its\nrobustness to drastic fluctuations in participation levels, with\nstate-of-the-art protocols making various restrictive assumptions. In this\nwork, we present a new adversary model, called external adversary. Intuitively,\nin our model, corrupt nodes do not divulge information about their secret keys.\nIn this model, we show that protocols in the sleepy model can meaningfully\nclaim to remain secure against fully fluctuating participation, without\ncompromising efficiency or corruption resilience. Our adversary model is quite\nnatural, and arguably naturally captures the process via which malicious\nbehavior arises in protocols, as opposed to traditional worst-case modeling. On\ntop of which, the model is also theoretically appealing, circumventing a\nbarrier established in a recent work of Malkhi, Momose, and Ren."}
{"id": "2508.08190", "categories": ["cs.CR"], "pdf": "https://arxiv.org/pdf/2508.08190", "abs": "https://arxiv.org/abs/2508.08190", "authors": ["Paritosh Ramanan", "H. M. Mohaimanul Islam", "Abhiram Reddy Alugula"], "title": "Differential Privacy for Regulatory Compliance in Cyberattack Detection on Critical Infrastructure Systems", "comment": null, "summary": "Industrial control systems are a fundamental component of critical\ninfrastructure networks (CIN) such as gas, water and power. With the growing\nrisk of cyberattacks, regulatory compliance requirements are also increasing\nfor large scale critical infrastructure systems comprising multiple utility\nstakeholders. The primary goal of regulators is to ensure overall system\nstability with recourse to trustworthy stakeholder attack detection. However,\nadhering to compliance requirements requires stakeholders to also disclose\nsensor and control data to regulators raising privacy concerns. In this paper,\nwe present a cyberattack detection framework that utilizes differentially\nprivate (DP) hypothesis tests geared towards enhancing regulatory confidence\nwhile alleviating privacy concerns of CIN stakeholders. The hallmark of our\napproach is a two phase privacy scheme that protects the privacy of covariance,\nas well as the associated sensor driven test statistics computed as a means to\ngenerate alarms. Theoretically, we show that our method induces a\nmisclassification error rate comparable to the non-DP cases while delivering\nrobust privacy guarantees. With the help of real-world datasets, we show the\nreliability of our DP-detection outcomes for a wide variety of attack scenarios\nfor interdependent stakeholders."}
