<div id=toc></div>

# Table of Contents

- [cs.CR](#cs.CR) [Total: 29]


<div id='cs.CR'></div>

# cs.CR [[Back]](#toc)

### [1] [DECEIVE-AFC: Adversarial Claim Attacks against Search-Enabled LLM-based Fact-Checking Systems](https://arxiv.org/abs/2602.02569)
*Haoran Ou,Kangjie Chen,Gelei Deng,Hangcheng Liu,Jie Zhang,Tianwei Zhang,Kwok-Yan Lam*

Main category: cs.CR

TL;DR: DECEIVE-AFC：针对基于搜索的LLM事实核查系统的对抗性攻击框架，通过干扰搜索行为和证据检索来降低验证准确性


<details>
  <summary>Details</summary>
Motivation: 当前基于搜索的大型语言模型事实核查系统在对抗性攻击下的鲁棒性研究不足，需要在实际的仅输入威胁模型下评估其安全性

Method: 提出DECEIVE-AFC框架，采用基于代理的对抗攻击方法，集成新颖的声明级攻击策略和对抗性声明有效性评估原则，系统探索干扰搜索行为、证据检索和LLM推理的攻击轨迹

Result: 攻击显著降低验证性能，准确率从78.7%降至53.7%，明显优于现有声明级攻击基线，并展现出强大的跨系统可迁移性

Conclusion: 基于搜索的LLM事实核查系统对对抗性攻击存在严重脆弱性，DECEIVE-AFC框架有效揭示了这种安全风险，为未来开发更鲁棒的事实核查系统提供了重要参考

Abstract: Fact-checking systems with search-enabled large language models (LLMs) have shown strong potential for verifying claims by dynamically retrieving external evidence. However, the robustness of such systems against adversarial attack remains insufficiently understood. In this work, we study adversarial claim attacks against search-enabled LLM-based fact-checking systems under a realistic input-only threat model. We propose DECEIVE-AFC, an agent-based adversarial attack framework that integrates novel claim-level attack strategies and adversarial claim validity evaluation principles. DECEIVE-AFC systematically explores adversarial attack trajectories that disrupt search behavior, evidence retrieval, and LLM-based reasoning without relying on access to evidence sources or model internals. Extensive evaluations on benchmark datasets and real-world systems demonstrate that our attacks substantially degrade verification performance, reducing accuracy from 78.7% to 53.7%, and significantly outperform existing claim-based attack baselines with strong cross-system transferability.

</details>


### [2] [To Defend Against Cyber Attacks, We Must Teach AI Agents to Hack](https://arxiv.org/abs/2602.02595)
*Terry Yue Zhuo,Yangruibo Ding,Wenbo Guo,Ruijie Meng*

Main category: cs.CR

TL;DR: AI智能体将彻底改变网络安全攻防平衡，使攻击者能够大规模自动化漏洞发现和利用，而现有防御措施无法阻止这种威胁。需要从根本上转变防御策略，将攻击性AI能力作为必要防御基础设施来建设。


<details>
  <summary>Details</summary>
Motivation: 传统网络安全依赖人工稀缺性来限制攻击规模，但AI智能体打破了这种平衡，能够自动化进行大规模定制化攻击。现有防御措施（如数据过滤、安全对齐、输出护栏）无法阻止控制开源模型或绕过安全控制的对手。攻击性AI驱动的网络攻击不可避免，需要根本性防御策略转变。

Method: 本文提出三个关键行动：1）构建覆盖完整攻击生命周期的综合基准测试；2）从基于工作流的智能体发展为训练型智能体，以大规模发现野外漏洞；3）实施治理框架，将攻击性智能体限制在审计的网络靶场中，按能力层级分阶段发布，并将发现提炼为仅防御的安全智能体。

Result: 论文论证了AI智能体驱动的网络攻击是不可避免的，现有防御措施无法阻止适应性对手。需要将攻击性AI能力视为必要的防御基础设施，在受控环境中掌握这些能力，以应对即将到来的威胁。

Conclusion: 网络安全防御必须进行根本性转变，将攻击性AI能力作为核心防御基础设施来建设。需要在对手掌握这些能力之前，在受控环境中负责任地开发和部署攻击性AI智能体，以应对AI驱动的网络攻击威胁。

Abstract: For over a decade, cybersecurity has relied on human labor scarcity to limit attackers to high-value targets manually or generic automated attacks at scale. Building sophisticated exploits requires deep expertise and manual effort, leading defenders to assume adversaries cannot afford tailored attacks at scale. AI agents break this balance by automating vulnerability discovery and exploitation across thousands of targets, needing only small success rates to remain profitable. Current developers focus on preventing misuse through data filtering, safety alignment, and output guardrails. Such protections fail against adversaries who control open-weight models, bypass safety controls, or develop offensive capabilities independently. We argue that AI-agent-driven cyber attacks are inevitable, requiring a fundamental shift in defensive strategy. In this position paper, we identify why existing defenses cannot stop adaptive adversaries and demonstrate that defenders must develop offensive security intelligence. We propose three actions for building frontier offensive AI capabilities responsibly. First, construct comprehensive benchmarks covering the full attack lifecycle. Second, advance from workflow-based to trained agents for discovering in-wild vulnerabilities at scale. Third, implement governance restricting offensive agents to audited cyber ranges, staging release by capability tier, and distilling findings into safe defensive-only agents. We strongly recommend treating offensive AI capabilities as essential defensive infrastructure, as containing cybersecurity risks requires mastering them in controlled settings before adversaries do.

</details>


### [3] [Position: 3D Gaussian Splatting Watermarking Should Be Scenario-Driven and Threat-Model Explicit](https://arxiv.org/abs/2602.02602)
*Yangfan Deng,Anirudh Nakra,Min Wu*

Main category: cs.CR

TL;DR: 本文提出为3D高斯泼溅(3DGS)等3D资产建立安全框架，通过场景驱动的安全模型来规范水印方法，保护知识产权。


<details>
  <summary>Details</summary>
Motivation: 随着3D内容获取和创建的快速发展，特别是3D高斯泼溅(3DGS)成为高保真实时3D表示，对知识产权保护的需求日益增长。3D参数化的显式和可编辑特性使得未经授权的使用和传播变得更加容易。

Method: 采用场景驱动的安全模型制定方法，将对抗能力形式化。构建参考框架来组织现有方法，阐明特定设计选择如何映射到相应的对抗假设。在该框架内分析传统的扩频嵌入方案。

Result: 建立了3D资产水印保护的参考框架，明确了安全目标和威胁模型。分析了扩频嵌入方案的优缺点，强调了其中的重要权衡。

Conclusion: 本文旨在促进3D资产的有效知识产权保护，通过安全模型和参考框架为3D水印技术的发展提供指导。

Abstract: 3D content acquisition and creation are expanding rapidly in the new era of machine learning and AI. 3D Gaussian Splatting (3DGS) has become a promising high-fidelity and real-time representation for 3D content. Similar to the initial wave of digital audio-visual content at the turn of the millennium, the demand for intellectual property protection is also increasing, since explicit and editable 3D parameterization makes unauthorized use and dissemination easier. In this position paper, we argue that effective progress in watermarking 3D assets requires articulated security objectives and realistic threat models, incorporating the lessons learned from digital audio-visual asset protection over the past decades. To address this gap in security specification and evaluation, we advocate a scenario-driven formulation, in which adversarial capabilities are formalized through a security model. Based on this formulation, we construct a reference framework that organizes existing methods and clarifies how specific design choices map to corresponding adversarial assumptions. Within this framework, we also examine a legacy spread-spectrum embedding scheme, characterizing its advantages and limitations and highlighting the important trade-offs it entails. Overall, this work aims to foster effective intellectual property protection for 3D assets.

</details>


### [4] [ClinConNet: A Blockchain-based Dynamic Consent Management Platform for Clinical Research](https://arxiv.org/abs/2602.02610)
*Montassar Naghmouchi,Maryline Laurent*

Main category: cs.CR

TL;DR: ClinConNet是一个基于区块链和自主权身份系统的临床研究同意管理平台，采用动态同意模型，提供用户中心化的隐私保护功能，实现快速同意建立（中位时间<200ms）和高吞吐量（250TPS）。


<details>
  <summary>Details</summary>
Motivation: 当前临床研究和医疗中的知情同意管理技术基础设施过时，给临床医生带来负担，缺乏参与者中心化的系统，医疗信息系统存在数据孤岛问题，影响患者数据流动和个性化医疗发展。

Method: 提出ClinConNet平台，基于区块链和自主权身份系统，采用动态同意模型，连接研究人员和参与者，提供不可链接性、机密性和身份数据所有权等隐私功能，支持被遗忘权。

Result: 通过概念验证实现和性能测试，证明系统可行性：中位端到端同意建立时间低于200毫秒，吞吐量达到250TPS，并提供详细的隐私安全分析。

Conclusion: ClinConNet是一个可行的区块链同意管理系统，解决了当前临床研究同意管理的技术落后问题，实现了用户中心化、隐私保护和高效性能。

Abstract: Consent is an ethical cornerstone of clinical research and healthcare in general. Although the ethical principles of consent - providing information, ensuring comprehension, and ensuring voluntariness - are well-defined, the technological infrastructure remains outdated. Clinicians are responsible for obtaining informed consent from research subjects or patients, and for managing it before, during, and after clinical trials or care, which is a burden for them. The voluntary nature of participating in clinical research or undergoing medical treatment implies the need for a participant-centric consent management system. However, this is not reflected in most established systems. Not only do most healthcare information systems not follow a user-centric model, but they also create data silos, which significantly reduce the mobility of patient data between different healthcare institutions and impact personalized medicine. Furthermore, consent management tools are outdated. We propose ClinConNet (Clinical Consent Network), a platform that connects researchers and participants based on clinical research projects. ClinConNet is powered by a dynamic consent model based on blockchain and take advantage of dynamic consent interfaces, as well as blockchain and Self-Sovereign Identity systems. ClinConNet is user-centric and provides important privacy features for patients, such as unlinkability, confidentiality, and ownership of identity data. It is also compatible with the right to be forgotten, as defined in many personal data protection regulations, such as the GDPR. We provide a detailed privacy and security analysis in an adversarial model, as well as a Proof of Concept implementation with detailed performance measures that demonstrate the feasibility of our blockchain-based consent management system with a median end-to-end consent establishment time of under 200ms and a throughput of 250TPS.

</details>


### [5] [TinyGuard:A lightweight Byzantine Defense for Resource-Constrained Federated Learning via Statistical Update Fingerprints](https://arxiv.org/abs/2602.02615)
*Ali Mahdavi,Santa Aghapour,Azadeh Zamanifar,Amirfarhad Farhadi*

Main category: cs.CR

TL;DR: TinyGuard：一种轻量级拜占庭防御机制，通过统计更新指纹在低维空间检测恶意客户端，保持FedAvg收敛性，在多种攻击场景下达到95%准确率。


<details>
  <summary>Details</summary>
Motivation: 现有拜占庭鲁棒聚合机制通常需要全维度梯度比较或成对距离计算，计算开销大，限制了在大规模和资源受限的联邦系统中的适用性。

Method: 提出TinyGuard，通过提取客户端更新的紧凑统计指纹（包括范数统计、层间比率、稀疏度测量和低阶矩），在低维指纹空间测量统计偏差来识别拜占庭客户端，复杂度为O(nd)，不修改底层优化过程。

Result: 在MNIST、Fashion-MNIST、ViT-Lite和ViT-Small（带LoRA适配器）上的实验表明，TinyGuard在良性设置下保持FedAvg收敛，在多种拜占庭攻击场景（符号翻转、缩放、噪声注入、标签投毒）下达到95%准确率。对抗自适应白盒攻击者时，攻击者无法同时逃避检测和实现有效投毒。

Conclusion: TinyGuard是一种架构无关的轻量级拜占庭防御框架，特别适合传统拜占庭防御变得不实用的基础模型联邦微调场景，在计算效率和防御效果之间取得了良好平衡。

Abstract: Existing Byzantine robust aggregation mechanisms typically rely on fulldimensional gradi ent comparisons or pairwise distance computations, resulting in computational overhead that limits applicability in large scale and resource constrained federated systems. This paper proposes TinyGuard, a lightweight Byzantine defense that augments the standard FedAvg algorithm via statistical update f ingerprinting. Instead of operating directly on high-dimensional gradients, TinyGuard extracts compact statistical fingerprints cap turing key behavioral properties of client updates, including norm statistics, layer-wise ratios, sparsity measures, and low-order mo ments. Byzantine clients are identified by measuring robust sta tistical deviations in this low-dimensional fingerprint space with nd complexity, without modifying the underlying optimization procedure. Extensive experiments on MNIST, Fashion-MNIST, ViT-Lite, and ViT-Small with LoRA adapters demonstrate that TinyGuard pre serves FedAvg convergence in benign settings and achieves up to 95 percent accuracy under multiple Byzantine attack scenarios, including sign-flipping, scaling, noise injection, and label poisoning. Against adaptive white-box adversaries, Pareto frontier analysis across four orders of magnitude confirms that attackers cannot simultaneously evade detection and achieve effective poisoning, features we term statistical handcuffs. Ablation studies validate stable detection precision 0.8 across varying client counts (50-150), threshold parameters and extreme data heterogeneity . The proposed framework is architecture-agnostic and well-suited for federated fine-tuning of foundation models where traditional Byzantine defenses become impractical

</details>


### [6] [Trustworthy Blockchain-based Federated Learning for Electronic Health Records: Securing Participant Identity with Decentralized Identifiers and Verifiable Credentials](https://arxiv.org/abs/2602.02629)
*Rodrigo Tertulino,Ricardo Almeida,Laercio Alencar*

Main category: cs.CR

TL;DR: 提出基于区块链和自主身份（SSI）的可信联邦学习框架TBFL，通过密码学身份验证而非行为模式来确保医疗数据协作安全，有效防御Sybil攻击并保持临床实用性。


<details>
  <summary>Details</summary>
Motivation: 医疗数字化产生大量电子健康记录（EHRs），但GDPR和HIPAA等隐私法规造成数据孤岛，阻碍集中式AI训练。联邦学习（FL）虽能协作训练而不共享原始数据，但仍易受投毒和Sybil攻击。现有区块链方案主要依赖概率信誉系统，缺乏强大的密码学身份验证。

Method: 提出可信区块链联邦学习（TBFL）框架，集成自主身份（SSI）标准，利用去中心化标识符（DIDs）和可验证凭证（VCs）确保只有经过认证的医疗实体才能参与全局模型训练。

Result: 使用MIMIC-IV数据集评估，框架成功抵御100%的Sybil攻击，保持稳健预测性能（AUC=0.954，召回率=0.890），计算开销极低（<0.12%）。100轮跨机构训练总运营成本约18美元。

Conclusion: TBFL通过密码学身份验证而非行为模式锚定信任，显著降低安全风险同时保持临床实用性，为跨机构医疗数据协作提供安全、可扩展且经济可行的生态系统。

Abstract: The digitization of healthcare has generated massive volumes of Electronic Health Records (EHRs), offering unprecedented opportunities for training Artificial Intelligence (AI) models. However, stringent privacy regulations such as GDPR and HIPAA have created data silos that prevent centralized training. Federated Learning (FL) has emerged as a promising solution that enables collaborative model training without sharing raw patient data. Despite its potential, FL remains vulnerable to poisoning and Sybil attacks, in which malicious participants corrupt the global model or infiltrate the network using fake identities. While recent approaches integrate Blockchain technology for auditability, they predominantly rely on probabilistic reputation systems rather than robust cryptographic identity verification. This paper proposes a Trustworthy Blockchain-based Federated Learning (TBFL) framework integrating Self-Sovereign Identity (SSI) standards. By leveraging Decentralized Identifiers (DIDs) and Verifiable Credentials (VCs), our architecture ensures only authenticated healthcare entities contribute to the global model. Through comprehensive evaluation using the MIMIC-IV dataset, we demonstrate that anchoring trust in cryptographic identity verification rather than behavioral patterns significantly mitigates security risks while maintaining clinical utility. Our results show the framework successfully neutralizes 100% of Sybil attacks, achieves robust predictive performance (AUC = 0.954, Recall = 0.890), and introduces negligible computational overhead (<0.12%). The approach provides a secure, scalable, and economically viable ecosystem for inter-institutional health data collaboration, with total operational costs of approximately $18 for 100 training rounds across multiple institutions.

</details>


### [7] [Benchmarking Large Language Models for Zero-shot and Few-shot Phishing URL Detection](https://arxiv.org/abs/2602.02641)
*Najmul Hasan,Prashanth BusiReddyGari*

Main category: cs.CR

TL;DR: 论文提出使用大语言模型（LLM）的零样本和少样本学习来检测AI生成的钓鱼URL，因为传统URL机制缺乏安全机制，而AI生成的钓鱼攻击正以惊人速度增长。


<details>
  <summary>Details</summary>
Motivation: 传统URL机制在安全、信任和抗欺诈方面存在历史局限性，而AI时代的钓鱼URL变得更加复杂和难以检测。AI生成的钓鱼攻击数量激增（2022年以来增长4000%），且近50%的攻击能绕过传统检测工具。由于威胁演变速度超过标记数据生成速度，需要零样本和少样本学习方案。

Method: 采用统一的零样本和少样本提示框架，在平衡数据集上评估多种大语言模型。使用一致的提示策略，通过准确率、精确率、召回率、F1分数、AUROC和AUPRC等指标量化模型性能、泛化能力和实际效用。

Result: 少样本提示显著提升了多种大语言模型的性能。研究提供了LLM在钓鱼URL检测中的综合基准评估，揭示了操作权衡和实际应用中的效能。

Conclusion: 在AI驱动的威胁环境中，大语言模型的零样本和少样本学习为钓鱼URL检测提供了及时且适应性强的解决方案。少样本提示能有效提升模型性能，为大规模网络安全防御系统提供了有前景的方向。

Abstract: The Uniform Resource Locator (URL), introduced in a connectivity-first era to define access and locate resources, remains historically limited, lacking future-proof mechanisms for security, trust, or resilience against fraud and abuse, despite the introduction of reactive protections like HTTPS during the cybersecurity era. In the current AI-first threatscape, deceptive URLs have reached unprecedented sophistication due to the widespread use of generative AI by cybercriminals and the AI-vs-AI arms race to produce context-aware phishing websites and URLs that are virtually indistinguishable to both users and traditional detection tools. Although AI-generated phishing accounted for a small fraction of filter-bypassing attacks in 2024, phishing volume has escalated over 4,000% since 2022, with nearly 50% more attacks evading detection. At the rate the threatscape is escalating, and phishing tactics are emerging faster than labeled data can be produced, zero-shot and few-shot learning with large language models (LLMs) offers a timely and adaptable solution, enabling generalization with minimal supervision. Given the critical importance of phishing URL detection in large-scale cybersecurity defense systems, we present a comprehensive benchmark of LLMs under a unified zero-shot and few-shot prompting framework and reveal operational trade-offs. Our evaluation uses a balanced dataset with consistent prompts, offering detailed analysis of performance, generalization, and model efficacy, quantified by accuracy, precision, recall, F1 score, AUROC, and AUPRC, to reflect both classification quality and practical utility in threat detection settings. We conclude few-shot prompting improves performance across multiple LLMs.

</details>


### [8] [Eidolon: A Practical Post-Quantum Signature Scheme Based on k-Colorability in the Age of Graph Neural Networks](https://arxiv.org/abs/2602.02689)
*Asmaa Cherkaoui,Ramon Flores,Delaram Kahrobaei,Richard Wilson*

Main category: cs.CR

TL;DR: Eidolon是基于NP完全k-着色问题的实用后量子签名方案，通过改进的零知识协议和Merkle树压缩签名，使用"安静"着色生成困难实例，实验证明能抵抗传统算法和机器学习攻击。


<details>
  <summary>Details</summary>
Motivation: 量子计算威胁传统密码学，需要基于NP完全问题的后量子安全方案。k-着色问题作为经典NP完全问题，但其实际安全性需要实证验证。

Method: 1. 将Goldreich-Micali-Wigderson零知识协议推广到任意k≥3；2. 应用Fiat-Shamir变换；3. 使用Merkle树承诺将签名从O(tn)压缩到O(t log n)；4. 通过"安静"着色生成困难实例，保持随机图的统计特性。

Result: 实验分析显示：对于n≥60的图，传统求解器（ILP、DSatur）和定制图神经网络攻击都无法恢复秘密着色，证明精心设计的k-着色实例能抵抗现代密码分析。

Conclusion: 组合硬度问题（如k-着色）可以作为后量子签名的可靠基础，为后量子密码学提供了新的研究方向。

Abstract: We propose Eidolon, a practical post-quantum signature scheme based on the NP-complete k-colorability problem. Our construction generalizes the Goldreich-Micali-Wigderson zero-knowledge protocol to arbitrary k >= 3, applies the Fiat-Shamir transform, and uses Merkle-tree commitments to compress signatures from O(tn) to O(t log n). Crucially, we generate hard instances via planted "quiet" colorings that preserve the statistical profile of random graphs. We present the first empirical security analysis of such a scheme against both classical solvers (ILP, DSatur) and a custom graph neural network (GNN) attacker. Experiments show that for n >= 60, neither approach recovers the secret coloring, demonstrating that well-engineered k-coloring instances can resist modern cryptanalysis, including machine learning. This revives combinatorial hardness as a credible foundation for post-quantum signatures.

</details>


### [9] [On the Feasibility of Hybrid Homomorphic Encryption for Intelligent Transportation Systems](https://arxiv.org/abs/2602.02717)
*Kyle Yates,Abdullah Al Mamun,Mashrur Chowdhury*

Main category: cs.CR

TL;DR: HHE结合同态加密与对称密码，大幅降低密文大小和通信开销，使隐私保护在实时ITS应用中更实用


<details>
  <summary>Details</summary>
Motivation: ITS应用需要强隐私保护，但传统同态加密密文膨胀严重、通信开销大，不适合时间敏感的交通系统

Method: 开发整合HHE的ITS应用理论模型，基于参数评估Rubato HHE方案的密文大小和通信开销

Result: HHE相比传统HE实现数量级密文大小缩减，同时保持密码安全性，更适合延迟受限的ITS通信

Conclusion: HHE通过结合同态加密和对称密码，显著降低通信成本，使隐私保护在实时ITS应用中更实用

Abstract: Many Intelligent Transportation Systems (ITS) applications require strong privacy guarantees for both users and their data. Homomorphic encryption (HE) enables computation directly on encrypted messages and thus offers a compelling approach to privacy-preserving data processing in ITS. However, practical HE schemes incur substantial ciphertext expansion and communication overhead, which limits their suitability for time-critical transportation systems. Hybrid homomorphic encryption (HHE) addresses this challenge by combining a homomorphic encryption scheme with a symmetric cipher, enabling efficient encrypted computation while dramatically reducing communication cost. In this paper, we develop theoretical models of representative ITS applications that integrate HHE to protect sensitive vehicular data. We then perform a parameter-based evaluation of the HHE scheme Rubato to estimate ciphertext sizes and communication overhead under realistic ITS workloads. Our results show that HHE achieves orders-of-magnitude reductions in ciphertext size compared with conventional HE while maintaining cryptographic security, making it significantly more practical for latency-constrained ITS communication.

</details>


### [10] [Composition for Pufferfish Privacy](https://arxiv.org/abs/2602.02718)
*Jiamu Bai,Guanlin He,Xin Gu,Daniel Kifer,Kiwan Maeng*

Main category: cs.CR

TL;DR: 本文研究了Pufferfish隐私定义在相关数据上的组合性问题，提出了确保线性组合的必要充分条件，并开发了将差分隐私算法转化为可组合Pufferfish算法的框架。


<details>
  <summary>Details</summary>
Motivation: Pufferfish等基于推断/后验的隐私定义为相关数据提供了有吸引力的隐私语义，但在实践中很少使用，因为它们不总是具备组合性。存在算法在单次运行时无泄漏，但多次运行会完全泄露数据集的问题。

Method: 提出了确保Pufferfish机制线性组合的必要充分条件，这些条件表现为差分隐私式的不等式。引入了$(a,b)$-影响曲线的概念，将现有差分隐私算法转化为可组合的Pufferfish算法。

Result: 证明了实现Pufferfish的可解释语义和组合性优势需要采用差分隐私机制。通过新框架设计的马尔可夫链可组合Pufferfish算法显著优于先前工作。

Conclusion: 研究解决了Pufferfish隐私定义的关键组合性问题，通过建立与差分隐私的联系，使得为相关数据设计可组合的隐私保护算法成为可能，为实际应用提供了理论基础。

Abstract: When creating public data products out of confidential datasets, inferential/posterior-based privacy definitions, such as Pufferfish, provide compelling privacy semantics for data with correlations. However, such privacy definitions are rarely used in practice because they do not always compose. For example, it is possible to design algorithms for these privacy definitions that have no leakage when run once but reveal the entire dataset when run more than once. We prove necessary and sufficient conditions that must be added to ensure linear composition for Pufferfish mechanisms, hence avoiding such privacy collapse. These extra conditions turn out to be differential privacy-style inequalities, indicating that achieving both the interpretable semantics of Pufferfish for correlated data and composition benefits requires adopting differentially private mechanisms to Pufferfish. We show that such translation is possible through a concept called the $(a,b)$-influence curve, and many existing differentially private algorithms can be translated with our framework into a composable Pufferfish algorithm. We illustrate the benefit of our new framework by designing composable Pufferfish algorithms for Markov chains that significantly outperform prior work.

</details>


### [11] [Evaluating False Alarm and Missing Attacks in CAN IDS](https://arxiv.org/abs/2602.02781)
*Nirab Hossain,Pablo Moriano*

Main category: cs.CR

TL;DR: 该论文系统评估了车载CAN网络入侵检测系统对抗攻击的鲁棒性，发现虽然所有模型在正常条件下表现良好，但对抗性扰动会显著增加漏报率，揭示了安全关键汽车IDS需要对抗鲁棒性评估的重要性。


<details>
  <summary>Details</summary>
Motivation: 现代车辆依赖CAN网络连接的ECU，车载通信安全至关重要。基于机器学习的入侵检测系统被广泛部署，但其对抗攻击的鲁棒性尚未得到充分探索。需要系统评估CAN IDS在对抗性操纵下的脆弱性。

Method: 使用ROAD数据集对CAN IDS进行系统对抗评估，比较四种浅层学习模型和深度神经网络检测器。采用FGSM、BIM和PGD生成协议兼容的有效载荷级扰动，评估对抗性扰动对正常和恶意CAN帧的影响。

Result: 所有模型在正常条件下都表现出色，但对抗性扰动揭示了显著脆弱性。虽然浅层和深层模型对误报诱导具有鲁棒性（DNN在正常流量上表现最佳），但所有架构的漏报率都显著增加。值得注意的是，在基于梯度的攻击下，浅层模型extra trees相比其他模型表现出更好的抗漏报诱导鲁棒性。

Conclusion: 对抗性操纵能够同时触发误报和逃避检测，强调了在安全关键的汽车入侵检测系统中进行对抗鲁棒性评估的必要性。研究结果表明当前CAN IDS存在安全漏洞，需要开发更鲁棒的防御机制。

Abstract: Modern vehicles rely on electronic control units (ECUs) interconnected through the Controller Area Network (CAN), making in-vehicle communication a critical security concern. Machine learning (ML)-based intrusion detection systems (IDS) are increasingly deployed to protect CAN traffic, yet their robustness against adversarial manipulation remains largely unexplored. We present a systematic adversarial evaluation of CAN IDS using the ROAD dataset, comparing four shallow learning models with a deep neural network-based detector. Using protocol-compliant, payload-level perturbations generated via FGSM, BIM and PGD, we evaluate adversarial effects on both benign and malicious CAN frames. While all models achieve strong baseline performance under benign conditions, adversarial perturbations reveal substantial vulnerabilities. Although shallow and deep models are robust to false-alarm induction, with the deep neural network (DNN) performing best on benign traffic, all architectures suffer significant increases in missed attacks. Notably, under gradient-based attacks, the shallow model extra trees (ET) demonstrates improved robustness to missed-attack induction compared to the other models. Our results demonstrate that adversarial manipulation can simultaneously trigger false alarms and evade detection, underscoring the need for adversarial robustness evaluation in safety-critical automotive IDS.

</details>


### [12] [CVE-Factory: Scaling Expert-Level Agentic Tasks for Code Security Vulnerability](https://arxiv.org/abs/2602.03012)
*Xianzhen Luo,Jingyuan Zhang,Shiqi Zhou,Rain Huang,Chuan Xiao,Qingfu Zhu,Zhiyuan Ma,Xing Yue,Yang Yue,Wencong Zeng,Wanxiang Che*

Main category: cs.CR

TL;DR: CVE-Factory：首个多智能体框架，能将稀疏的CVE元数据自动转化为可执行的代码安全任务，质量达到专家水平，并构建了持续更新的基准LiveCVEBench。


<details>
  <summary>Details</summary>
Motivation: 评估和改进代码智能体的安全能力需要高质量、可执行的漏洞任务，但现有方法依赖昂贵、不可扩展的手动复现，且数据分布过时。

Method: 提出CVE-Factory多智能体框架，自动将CVE元数据转化为可执行的智能体任务；构建LiveCVEBench持续更新的基准，包含190个任务；合成1000+可执行训练环境；微调Qwen3-32B模型。

Result: CVE-Factory达到95%解决方案正确率和96%环境保真度；在最新漏洞上达到66.2%验证成功率；微调后的Qwen3-32B在LiveCVEBench上从5.3%提升到35.8%，超越Claude 4.5 Sonnet，在Terminal Bench上从12.5%提升到31.3%。

Conclusion: CVE-Factory实现了专家级质量的自动化漏洞任务生成，构建了持续更新的基准和训练数据集，显著提升了代码智能体的安全能力，所有资源已开源。

Abstract: Evaluating and improving the security capabilities of code agents requires high-quality, executable vulnerability tasks. However, existing works rely on costly, unscalable manual reproduction and suffer from outdated data distributions. To address these, we present CVE-Factory, the first multi-agent framework to achieve expert-level quality in automatically transforming sparse CVE metadata into fully executable agentic tasks. Cross-validation against human expert reproductions shows that CVE-Factory achieves 95\% solution correctness and 96\% environment fidelity, confirming its expert-level quality. It is also evaluated on the latest realistic vulnerabilities and achieves a 66.2\% verified success. This automation enables two downstream contributions. First, we construct LiveCVEBench, a continuously updated benchmark of 190 tasks spanning 14 languages and 153 repositories that captures emerging threats including AI-tooling vulnerabilities. Second, we synthesize over 1,000 executable training environments, the first large-scale scaling of agentic tasks in code security. Fine-tuned Qwen3-32B improves from 5.3\% to 35.8\% on LiveCVEBench, surpassing Claude 4.5 Sonnet, with gains generalizing to Terminal Bench (12.5\% to 31.3\%). We open-source CVE-Factory, LiveCVEBench, Abacus-cve (fine-tuned model), training dataset, and leaderboard. All resources are available at https://github.com/livecvebench/CVE-Factory .

</details>


### [13] [Generalizable and Interpretable RF Fingerprinting with Shapelet-Enhanced Large Language Models](https://arxiv.org/abs/2602.03035)
*Tianya Zhao,Junqing Zhang,Haowen Xu,Xiaoyan Sun,Jun Dai,Xuyu Wang*

Main category: cs.CR

TL;DR: 提出结合2D shapelets与预训练LLM的RF指纹识别框架，解决领域偏移和黑盒问题，实现高效、可解释、泛化强的无线设备认证


<details>
  <summary>Details</summary>
Motivation: 深度神经网络在RF指纹识别中面临两大限制：1) 领域偏移问题（模型在训练环境表现好但泛化到其他环境困难）；2) 黑盒性质导致可解释性差。需要解决这些实际部署中的挑战。

Method: 提出新颖框架，整合可变长度2D shapelets与预训练大语言模型(LLM)。2D shapelets显式捕获I/Q分量中的局部时序模式，提供紧凑可解释表示；预训练LLM捕获长距离依赖和全局上下文信息，实现强泛化能力。框架还支持原型生成用于少样本推理。

Result: 在六个不同协议和领域的数据集上进行广泛实验，结果显示该方法在源域和未见域上都实现了优越的标准性能和少样本性能。

Conclusion: 提出的2D shapelets与LLM集成框架有效解决了RF指纹识别中的领域偏移和可解释性问题，实现了高效、可解释且泛化强的无线设备认证方案。

Abstract: Deep neural networks (DNNs) have achieved remarkable success in radio frequency (RF) fingerprinting for wireless device authentication. However, their practical deployment faces two major limitations: domain shift, where models trained in one environment struggle to generalize to others, and the black-box nature of DNNs, which limits interpretability. To address these issues, we propose a novel framework that integrates a group of variable-length two-dimensional (2D) shapelets with a pre-trained large language model (LLM) to achieve efficient, interpretable, and generalizable RF fingerprinting. The 2D shapelets explicitly capture diverse local temporal patterns across the in-phase and quadrature (I/Q) components, providing compact and interpretable representations. Complementarily, the pre-trained LLM captures more long-range dependencies and global contextual information, enabling strong generalization with minimal training overhead. Moreover, our framework also supports prototype generation for few-shot inference, enhancing cross-domain performance without additional retraining. To evaluate the effectiveness of our proposed method, we conduct extensive experiments on six datasets across various protocols and domains. The results show that our method achieves superior standard and few-shot performance across both source and unseen domains.

</details>


### [14] [DF-LoGiT: Data-Free Logic-Gated Backdoor Attacks in Vision Transformers](https://arxiv.org/abs/2602.03040)
*Xiaozuo Shen,Yifei Cai,Rui Ning,Chunsheng Xin,Hongyi Wu*

Main category: cs.CR

TL;DR: DF-LoGiT是一种针对Vision Transformers的数据无关逻辑门控后门攻击方法，通过直接权重编辑实现，无需数据训练或额外模型组件，具有高攻击成功率和隐蔽性。


<details>
  <summary>Details</summary>
Motivation: 随着Vision Transformers的广泛采用，第三方模型库存在供应链风险，攻击者可能在发布的检查点中植入后门。现有ViT后门攻击主要依赖数据中毒训练，而之前的数据无关方法通常需要合成数据微调或额外模型组件。

Method: DF-LoGiT利用ViT原生多头架构实现逻辑门控组合触发器，通过直接权重编辑实现数据无关后门攻击。该方法不需要数据训练或额外模型组件。

Result: DF-LoGiT实现了接近100%的攻击成功率，同时良性准确率下降可忽略不计。该方法对经典和ViT特定的防御方法都具有鲁棒性。

Conclusion: DF-LoGiT是一种有效的数据无关ViT后门攻击方法，展示了直接权重编辑在实现隐蔽后门攻击方面的潜力，对模型安全提出了新的挑战。

Abstract: The widespread adoption of Vision Transformers (ViTs) elevates supply-chain risk on third-party model hubs, where an adversary can implant backdoors into released checkpoints. Existing ViT backdoor attacks largely rely on poisoned-data training, while prior data-free attempts typically require synthetic-data fine-tuning or extra model components. This paper introduces Data-Free Logic-Gated Backdoor Attacks (DF-LoGiT), a truly data-free backdoor attack on ViTs via direct weight editing. DF-LoGiT exploits ViT's native multi-head architecture to realize a logic-gated compositional trigger, enabling a stealthy and effective backdoor. We validate its effectiveness through theoretical analysis and extensive experiments, showing that DF-LoGiT achieves near-100% attack success with negligible degradation in benign accuracy and remains robust against representative classical and ViT-specific defenses.

</details>


### [15] [The Trigger in the Haystack: Extracting and Reconstructing LLM Backdoor Triggers](https://arxiv.org/abs/2602.03085)
*Blake Bullwinkel,Giorgio Severi,Keegan Hines,Amanda Minnich,Ram Shankar Siva Kumar,Yonatan Zunger*

Main category: cs.CR

TL;DR: 提出一种实用的扫描器，用于检测因果语言模型中的sleeper agent式后门，无需事先了解触发器或目标行为，仅需推理操作。


<details>
  <summary>Details</summary>
Motivation: 检测模型是否被投毒是AI安全领域的长期问题，需要一种实用的方法来识别语言模型中的后门攻击。

Method: 基于两个关键发现：1) sleeper agent会记忆投毒数据，可通过记忆提取技术泄露后门示例；2) 被投毒LLM在输入包含后门触发器时，其输出分布和注意力头会呈现独特模式。开发可扩展的后门扫描方法，无需触发器或目标行为的先验知识，仅需推理操作。

Result: 该方法能在多种后门场景、广泛模型和微调方法中恢复有效的触发器，自然地集成到更广泛的防御策略中，且不改变模型性能。

Conclusion: 提出了一种实用、可扩展的后门扫描方法，为检测语言模型中的sleeper agent式后门攻击提供了有效解决方案。

Abstract: Detecting whether a model has been poisoned is a longstanding problem in AI security. In this work, we present a practical scanner for identifying sleeper agent-style backdoors in causal language models. Our approach relies on two key findings: first, sleeper agents tend to memorize poisoning data, making it possible to leak backdoor examples using memory extraction techniques. Second, poisoned LLMs exhibit distinctive patterns in their output distributions and attention heads when backdoor triggers are present in the input. Guided by these observations, we develop a scalable backdoor scanning methodology that assumes no prior knowledge of the trigger or target behavior and requires only inference operations. Our scanner integrates naturally into broader defensive strategies and does not alter model performance. We show that our method recovers working triggers across multiple backdoor scenarios and a broad range of models and fine-tuning methods.

</details>


### [16] [AgentDyn: A Dynamic Open-Ended Benchmark for Evaluating Prompt Injection Attacks of Real-World Agent Security System](https://arxiv.org/abs/2602.03117)
*Hao Li,Ruoyao Wen,Shanghao Shi,Ning Zhang,Chaowei Xiao*

Main category: cs.CR

TL;DR: 本文提出了AgentDyn基准测试，针对现有AI代理基准测试的三个缺陷：缺乏动态开放任务、缺乏有用指令、用户任务过于简单。通过包含60个挑战性开放任务和560个注入测试案例，评估显示现有防御措施要么不够安全，要么过度防御。


<details>
  <summary>Details</summary>
Motivation: 随着AI代理在复杂任务中的应用增加，现有基准测试无法反映新兴代理系统面临的威胁态势。当前基准存在三个根本缺陷：缺乏动态开放任务、缺乏有用指令、用户任务过于简单，需要更先进的基准来评估代理安全性。

Method: 提出AgentDyn基准测试，包含60个手动设计的挑战性开放任务和560个注入测试案例，涵盖购物、GitHub和日常生活场景。与静态基准不同，AgentDyn需要动态规划并包含有用的第三方指令。

Result: 对10种最先进防御措施的评估表明，几乎所有现有防御要么不够安全，要么存在显著的过度防御问题。现有防御措施距离实际部署还有很大差距。

Conclusion: AgentDyn基准测试揭示了当前代理安全基准的局限性，并推动了该领域的发展。现有防御措施在应对动态开放任务中的间接提示注入攻击方面表现不足，需要更先进的防御机制。

Abstract: AI agents that autonomously interact with external tools and environments show great promise across real-world applications. However, the external data which agent consumes also leads to the risk of indirect prompt injection attacks, where malicious instructions embedded in third-party content hijack agent behavior. Guided by benchmarks, such as AgentDojo, there has been significant amount of progress in developing defense against the said attacks. As the technology continues to mature, and that agents are increasingly being relied upon for more complex tasks, there is increasing pressing need to also evolve the benchmark to reflect threat landscape faced by emerging agentic systems. In this work, we reveal three fundamental flaws in current benchmarks and push the frontier along these dimensions: (i) lack of dynamic open-ended tasks, (ii) lack of helpful instructions, and (iii) simplistic user tasks. To bridge this gap, we introduce AgentDyn, a manually designed benchmark featuring 60 challenging open-ended tasks and 560 injection test cases across Shopping, GitHub, and Daily Life. Unlike prior static benchmarks, AgentDyn requires dynamic planning and incorporates helpful third-party instructions. Our evaluation of ten state-of-the-art defenses suggests that almost all existing defenses are either not secure enough or suffer from significant over-defense, revealing that existing defenses are still far from real-world deployment. Our benchmark is available at https://github.com/leolee99/AgentDyn.

</details>


### [17] [Cyber Insurance, Audit, and Policy: Review, Analysis and Recommendations](https://arxiv.org/abs/2602.03127)
*Danielle Jean Hanson,Jeremy Straub*

Main category: cs.CR

TL;DR: 本文综述了网络安全审计如何帮助解决网络保险获取难、费用高的问题，分析了现有研究、挑战与潜在收益，并提出了利用审计降低保险成本和提高可获得性的建议。


<details>
  <summary>Details</summary>
Motivation: 许多组织难以获得或负担网络保险，主要原因是保险公司难以理解和准确评估承保风险。网络安全审计作为已在许多组织中实施的合规措施，为解决这一挑战提供了潜在方案。

Method: 采用结构化综述和分析方法，系统回顾该领域先前工作，分析网络安全审计面临的挑战和潜在收益，并提出具体建议。

Result: 网络安全审计可以帮助保险公司更好地理解和评估风险，从而可能降低保险成本并提高保险可获得性。审计提供了标准化的风险评估框架，减少了信息不对称问题。

Conclusion: 网络安全审计是解决网络保险市场信息不对称问题的有效工具，通过实施标准化审计可以改善风险评估，降低保险成本，提高保险可获得性，但需要解决审计标准化、成本效益等挑战。

Abstract: Cyber insurance, which protects insured organizations against financial losses from cyberattacks and data breaches, can be difficult and expensive to obtain for many organizations. These difficulties stem from insurers difficulty in understanding and accurately assessing the risks that they are undertaking. Cybersecurity audits, which are already implemented in many organizations for compliance and other purposes, present a potential solution to this challenge. This paper provides a structured review and analysis of prior work in this area, analysis of the challenges and potential benefits that cyber audits provide and recommendations for the use of cyber audits to reduce cyber insurance costs and improve its availability.

</details>


### [18] [LogicScan: An LLM-driven Framework for Detecting Business Logic Vulnerabilities in Smart Contracts](https://arxiv.org/abs/2602.03271)
*Jiaqi Gao,Zijian Zhang,Yuqiang Sun,Ye Liu,Chengwei Liu,Han Liu,Yi Li,Yang Liu*

Main category: cs.CR

TL;DR: LogicScan：基于对比审计的智能合约业务逻辑漏洞检测框架，通过从成熟链上协议挖掘业务不变量作为参考约束，显著提升检测准确率


<details>
  <summary>Details</summary>
Motivation: 业务逻辑漏洞已成为智能合约中最具破坏性但最不为人理解的漏洞类型。传统静态分析难以捕捉高级逻辑，而基于大语言模型的方法存在输出不稳定、准确率低的问题

Method: 提出LogicScan对比审计框架：1) 从大规模链上合约中挖掘业务不变量作为参考约束；2) 引入业务规范语言(BSL)将实现模式标准化为结构化逻辑表示；3) 结合噪声感知逻辑聚合与对比审计识别缺失或弱执行的不变量

Result: 在DeFiHacks、Web3Bugs和top-200审计合约三个真实数据集上评估，F1分数达85.2%，显著优于现有最优工具，在生产级合约上保持低误报率，且在不同LLM上性能一致，成本效益高

Conclusion: LogicScan通过从成熟链上协议挖掘业务不变量作为参考约束，有效检测智能合约业务逻辑漏洞，解决了现有方法的局限性，在准确性和实用性方面表现优异

Abstract: Business logic vulnerabilities have become one of the most damaging yet least understood classes of smart contract vulnerabilities. Unlike traditional bugs such as reentrancy or arithmetic errors, these vulnerabilities arise from missing or incorrectly enforced business invariants and are tightly coupled with protocol semantics. Existing static analysis techniques struggle to capture such high-level logic, while recent large language model based approaches often suffer from unstable outputs and low accuracy due to hallucination and limited verification.
  In this paper, we propose LogicScan, an automated contrastive auditing framework for detecting business logic vulnerabilities in smart contracts. The key insight behind LogicScan is that mature, widely deployed on-chain protocols implicitly encode well-tested and consensus-driven business invariants. LogicScan systematically mines these invariants from large-scale on-chain contracts and reuses them as reference constraints to audit target contracts. To achieve this, LogicScan introduces a Business Specification Language (BSL) to normalize diverse implementation patterns into structured, verifiable logic representations. It further combines noise-aware logic aggregation with contrastive auditing to identify missing or weakly enforced invariants while mitigating LLM-induced false positives.
  We evaluate LogicScan on three real-world datasets, including DeFiHacks, Web3Bugs, and a set of top-200 audited contracts. The results show that LogicScan achieves an F1 score of 85.2%, significantly outperforming state-of-the-art tools while maintaining a low false-positive rate on production-grade contracts. Additional experiments demonstrate that LogicScan maintains consistent performance across different LLMs and is cost-effective, and that its false-positive suppression mechanisms substantially improve robustness.

</details>


### [19] [Time Is All It Takes: Spike-Retiming Attacks on Event-Driven Spiking Neural Networks](https://arxiv.org/abs/2602.03284)
*Yi Yu,Qixin Zhang,Shuhan Ye,Xun Lin,Qianshan Wei,Kun Wang,Wenhan Yang,Dacheng Tao,Xudong Jiang*

Main category: cs.CR

TL;DR: 提出一种针对脉冲神经网络的时序攻击方法，仅通过调整脉冲时间而不改变脉冲数量或幅度，在保持速率不变的情况下实现对抗攻击。


<details>
  <summary>Details</summary>
Motivation: 现有对抗攻击主要改变脉冲强度或事件计数，而忽略了脉冲时序这一重要维度。脉冲神经网络利用时序结构进行计算，因此研究仅通过调整脉冲时间的攻击方法具有重要意义。

Method: 提出容量为1的脉冲重定时威胁模型，包含三种预算约束：每个脉冲的抖动、总延迟和篡改计数。采用投影在环优化方法，使用可微的软重定时进行反向传播，前向传播时通过严格投影生成满足约束的离散调度。

Result: 在多个事件驱动基准测试（CIFAR10-DVS、DVS-Gesture、N-MNIST）和不同SNN架构上评估，攻击成功率高达90%以上，同时仅修改不到2%的脉冲。针对时序攻击设计的对抗训练也难以有效防御。

Conclusion: 脉冲重定时是一种实用且隐蔽的攻击面，现有防御方法难以应对，为事件驱动SNN的时间鲁棒性提供了明确参考。

Abstract: Spiking neural networks (SNNs) compute with discrete spikes and exploit temporal structure, yet most adversarial attacks change intensities or event counts instead of timing. We study a timing-only adversary that retimes existing spikes while preserving spike counts and amplitudes in event-driven SNNs, thus remaining rate-preserving. We formalize a capacity-1 spike-retiming threat model with a unified trio of budgets: per-spike jitter $\mathcal{B}_{\infty}$, total delay $\mathcal{B}_{1}$, and tamper count $\mathcal{B}_{0}$. Feasible adversarial examples must satisfy timeline consistency and non-overlap, which makes the search space discrete and constrained. To optimize such retimings at scale, we use projected-in-the-loop (PIL) optimization: shift-probability logits yield a differentiable soft retiming for backpropagation, and a strict projection in the forward pass produces a feasible discrete schedule that satisfies capacity-1, non-overlap, and the chosen budget at every step. The objective maximizes task loss on the projected input and adds a capacity regularizer together with budget-aware penalties, which stabilizes gradients and aligns optimization with evaluation. Across event-driven benchmarks (CIFAR10-DVS, DVS-Gesture, N-MNIST) and diverse SNN architectures, we evaluate under binary and integer event grids and a range of retiming budgets, and also test models trained with timing-aware adversarial training designed to counter timing-only attacks. For example, on DVS-Gesture the attack attains high success (over $90\%$) while touching fewer than $2\%$ of spikes under $\mathcal{B}_{0}$. Taken together, our results show that spike retiming is a practical and stealthy attack surface that current defenses struggle to counter, providing a clear reference for temporal robustness in event-driven SNNs. Code is available at https://github.com/yuyi-sd/Spike-Retiming-Attacks.

</details>


### [20] [GuardReasoner-Omni: A Reasoning-based Multi-modal Guardrail for Text, Image, and Video](https://arxiv.org/abs/2602.03328)
*Zhenhao Zhu,Yue Liu,Yanpei Guo,Wenjie Qu,Cancan Chen,Yufei He,Yibo Li,Yulin Chen,Tianyi Wu,Huiying Xu,Xinzhong Zhu,Jiaheng Zhang*

Main category: cs.CR

TL;DR: GuardReasoner-Omni是一个基于推理的多模态护栏模型，用于文本、图像和视频内容审核，通过两阶段训练实现卓越性能


<details>
  <summary>Details</summary>
Motivation: 需要开发一个能够同时处理文本、图像和视频内容的多模态护栏模型，以应对日益复杂的多模态内容审核需求

Method: 构建包含148k样本的多模态训练语料库，采用两阶段训练范式：1）SFT阶段冷启动模型，赋予显式推理能力和结构遵循能力；2）RL阶段引入错误驱动探索奖励，激励模型对困难样本进行深度推理

Result: GuardReasoner-Omni在多个护栏基准测试中优于现有最先进基线，特别是2B参数版本显著超过第二名5.3%的F1分数

Conclusion: GuardReasoner-Omni展示了基于推理的多模态护栏模型的有效性，通过两阶段训练策略实现了卓越的内容审核性能

Abstract: We present GuardReasoner-Omni, a reasoning-based guardrail model designed to moderate text, image, and video data. First, we construct a comprehensive training corpus comprising 148k samples spanning these three modalities. Our training pipeline follows a two-stage paradigm to incentivize the model to deliberate before making decisions: (1) conducting SFT to cold-start the model with explicit reasoning capabilities and structural adherence; and (2) performing RL, incorporating an error-driven exploration reward to incentivize deeper reasoning on hard samples. We release a suite of models scaled at 2B and 4B parameters. Extensive experiments demonstrate that GuardReasoner-Omni achieves superior performance compared to existing state-of-the-art baselines across various guardrail benchmarks. Notably, GuardReasoner-Omni (2B) significantly surpasses the runner-up by 5.3% F1 score.

</details>


### [21] [SEW: Strengthening Robustness of Black-box DNN Watermarking via Specificity Enhancement](https://arxiv.org/abs/2602.03377)
*Huming Qiu,Mi Zhang,Junjie Sun,Peiyi Chen,Xiaohan Zhang,Min Yang*

Main category: cs.CR

TL;DR: 提出SEW方法增强黑盒DNN水印特异性，通过减少水印与近似密钥的关联来防御移除攻击


<details>
  <summary>Details</summary>
Motivation: 现有黑盒DNN水印存在特异性不足的问题，攻击者可以利用近似密钥进行水印移除，需要增强水印对特定密钥的响应准确性

Method: 提出特异性增强水印(SEW)方法，通过减少水印与近似密钥的关联来提升水印特异性，使水印仅对特定密钥产生准确响应

Result: SEW能有效防御6种先进移除攻击，同时保持模型可用性和水印验证性能，在三个流行水印基准上验证了其有效性

Conclusion: 增强水印特异性是提升黑盒DNN水印鲁棒性的有效策略，SEW方法为保护开源DNN的负责任分发和使用提供了新解决方案

Abstract: To ensure the responsible distribution and use of open-source deep neural networks (DNNs), DNN watermarking has become a crucial technique to trace and verify unauthorized model replication or misuse. In practice, black-box watermarks manifest as specific predictive behaviors for specially crafted samples. However, due to the generalization nature of DNNs, the keys to extracting the watermark message are not unique, which would provide attackers with more opportunities. Advanced attack techniques can reverse-engineer approximate replacements for the original watermark keys, enabling subsequent watermark removal. In this paper, we explore black-box DNN watermarking specificity, which refers to the accuracy of a watermark's response to a key. Using this concept, we introduce Specificity-Enhanced Watermarking (SEW), a new method that improves specificity by reducing the association between the watermark and approximate keys. Through extensive evaluation using three popular watermarking benchmarks, we validate that enhancing specificity significantly contributes to strengthening robustness against removal attacks. SEW effectively defends against six state-of-the-art removal attacks, while maintaining model usability and watermark verification performance.

</details>


### [22] [Origin Lens: A Privacy-First Mobile Framework for Cryptographic Image Provenance and AI Detection](https://arxiv.org/abs/2602.03423)
*Alexander Loth,Dominique Conceicao Rosario,Peter Ebinger,Martin Kappes,Marc-Oliver Pahl*

Main category: cs.CR

TL;DR: Origin Lens是一个隐私优先的移动框架，通过本地化加密图像溯源验证和AI检测来应对视觉虚假信息，提供分层验证架构和分级置信度指示。


<details>
  <summary>Details</summary>
Motivation: 生成式AI的扩散给信息完整性保障带来挑战，需要将模型治理与终端用户验证连接起来的系统。现有服务器端检测系统存在隐私和延迟问题。

Method: 采用Rust/Flutter混合架构，在设备本地执行加密图像溯源验证和AI检测。集成多种信号：加密溯源、生成模型指纹、可选检索增强验证，提供分层验证架构。

Result: 开发了隐私优先的移动框架，能够在消费点为用户提供分级置信度指示，支持本地化验证，减少隐私泄露风险。

Conclusion: Origin Lens框架符合欧盟AI法案和数字服务法案等监管要求，作为验证基础设施补充平台级机制，在保护隐私的同时应对视觉虚假信息挑战。

Abstract: The proliferation of generative AI poses challenges for information integrity assurance, requiring systems that connect model governance with end-user verification. We present Origin Lens, a privacy-first mobile framework that targets visual disinformation through a layered verification architecture. Unlike server-side detection systems, Origin Lens performs cryptographic image provenance verification and AI detection locally on the device via a Rust/Flutter hybrid architecture. Our system integrates multiple signals - including cryptographic provenance, generative model fingerprints, and optional retrieval-augmented verification - to provide users with graded confidence indicators at the point of consumption. We discuss the framework's alignment with regulatory requirements (EU AI Act, DSA) and its role in verification infrastructure that complements platform-level mechanisms.

</details>


### [23] [Reading Between the Code Lines: On the Use of Self-Admitted Technical Debt for Security Analysis](https://arxiv.org/abs/2602.03470)
*Nicolás E. Díaz Ferreyra,Moritz Mock,Max Kretschmann,Barbara Russo,Mojtaba Shahin,Mansooreh Zahedi,Riccardo Scandariato*

Main category: cs.CR

TL;DR: 研究发现安全相关的自认技术债务（SATD）可以补充静态分析工具（SAT）的不足，帮助识别SAT难以检测的漏洞类型，并提升安全分析的全面性。


<details>
  <summary>Details</summary>
Motivation: 静态分析工具在安全工程中很重要，但存在高误报率和漏洞覆盖不全的问题。自认技术债务（SATD）包含安全相关信息，但尚不清楚SATD如何与SAT结合使用来弥补SAT的局限性。

Method: 采用混合方法：1）使用三种先进的SAT分析SATD标注的漏洞数据集；2）对72名安全从业者进行在线调查。

Result: 所有SAT组合检测到135个安全相关SATD实例中的114个，覆盖24种CWE类型。手动映射SATD注释发现33种CWE类型，其中6种是SAT通常忽略或难以检测的类型（如竞态条件）。调查显示开发者经常结合SAT输出和SATD洞察来更好地理解安全弱点的影响和根本原因。

Conclusion: SATD编码的信息可以成为SAT驱动安全分析的有意义补充，帮助克服SAT的实际缺陷，提升安全分析的有效性。

Abstract: Static Analysis Tools (SATs) are central to security engineering activities, as they enable early identification of code weaknesses without requiring execution. However, their effectiveness is often limited by high false-positive rates and incomplete coverage of vulnerability classes. At the same time, developers frequently document security-related shortcuts and compromises as Self-Admitted Technical Debt (SATD) in software artifacts, such as code comments. While prior work has recognized SATD as a rich source of security information, it remains unclear whether -and in what ways- it is utilized during SAT-aided security analysis. OBJECTIVE: This work investigates the extent to which security-related SATD complements the output produced by SATs and helps bridge some of their well-known limitations. METHOD: We followed a mixed-methods approach consisting of (i) the analysis of a SATD-annotated vulnerability dataset using three state-of-the-art SATs and (ii) an online survey with 72 security practitioners. RESULTS: The combined use of all SATs flagged 114 of the 135 security-related SATD instances, spanning 24 distinct Common Weakness Enumeration (CWE) identifiers. A manual mapping of the SATD comments revealed 33 unique CWE types, 6 of which correspond to categories that SATs commonly overlook or struggle to detect (e.g., race conditions). Survey responses further suggest that developers frequently pair SAT outputs with SATD insights to better understand the impact and root causes of security weaknesses and to identify suitable fixes. IMPLICATIONS: Our findings show that such SATD-encoded information can be a meaningful complement to SAT-driven security analysis, while helping to overcome some of SATs' practical shortcomings.

</details>


### [24] [Detecting and Explaining Malware Family Evolution Using Rule-Based Drift Analysis](https://arxiv.org/abs/2602.03489)
*Olha Jurečková,Martin Jureček*

Main category: cs.CR

TL;DR: 提出一种可解释的概念漂移检测方法，通过规则分类器生成可读规则集，比较新旧恶意软件样本的规则相似度来检测和量化概念漂移，并提供具体特征变化的解释。


<details>
  <summary>Details</summary>
Motivation: 恶意软件持续演化以逃避检测，导致特征统计特性随时间变化（概念漂移），这会降低静态机器学习模型的有效性。理解和解释这种漂移对于维护稳健可信的恶意软件检测器至关重要。

Method: 使用基于规则的分类器为同一恶意软件家族的原始样本和演化样本生成人类可读的描述规则集。通过相似度函数比较这些规则集来检测和量化概念漂移，并识别具体哪些特征和特征值发生了变化。

Result: 实验结果表明，该方法不仅能准确检测概念漂移，还能提供关于演化恶意软件家族行为的可操作见解，支持检测和威胁分析。

Conclusion: 提出的可解释概念漂移检测方法能够有效检测恶意软件演化中的概念漂移，并提供清晰的特征变化解释，有助于维护稳健的恶意软件检测系统。

Abstract: Malware detection and classification into families are critical tasks in cybersecurity, complicated by the continual evolution of malware to evade detection. This evolution introduces concept drift, in which the statistical properties of malware features change over time, reducing the effectiveness of static machine learning models. Understanding and explaining this drift is essential for maintaining robust and trustworthy malware detectors. In this paper, we propose an interpretable approach to concept drift detection. Our method uses a rule-based classifier to generate human-readable descriptions of both original and evolved malware samples belonging to the same malware family. By comparing the resulting rule sets using a similarity function, we can detect and quantify concept drift. Crucially, this comparison also identifies the specific features and feature values that have changed, providing clear explanations of how malware has evolved to bypass detection. Experimental results demonstrate that the proposed method not only accurately detects drift but also provides actionable insights into the behavior of evolving malware families, supporting both detection and threat analysis.

</details>


### [25] [Don't believe everything you read: Understanding and Measuring MCP Behavior under Misleading Tool Descriptions](https://arxiv.org/abs/2602.03580)
*Zhihao Li,Boyang Ma,Xuelong Dai,Minghui Xu,Yue Zhang,Biwei Yan,Kun Li*

Main category: cs.CR

TL;DR: 研究发现MCP生态系统中约13%的服务器存在工具描述与代码实现不一致的安全风险，可能导致未授权的特权操作、隐藏状态变更或金融行为。


<details>
  <summary>Details</summary>
Motivation: MCP允许大语言模型通过自然语言描述调用外部工具，但未强制要求文档描述与实际代码执行的一致性。由于MCP服务器通常拥有广泛的系统权限，这种不一致性带来了尚未充分探索的安全风险。

Method: 设计了自动化静态分析框架，对36个类别的10,240个真实MCP服务器进行了大规模研究，分析描述与代码实现的不一致性。

Result: 虽然大多数服务器高度一致，但约13%存在显著不匹配，可能支持未记录的特权操作、隐藏状态变更或未授权的金融行为。不同应用类别、流行度级别和MCP市场存在系统性差异。

Conclusion: 描述-代码不一致性是MCP基础AI代理中具体且普遍的攻击面，需要系统审计和更强的透明度保证来构建未来的代理生态系统。

Abstract: The Model Context Protocol (MCP) enables large language models to invoke external tools through natural-language descriptions, forming the foundation of many AI agent applications. However, MCP does not enforce consistency between documented tool behavior and actual code execution, even though MCP Servers often run with broad system privileges. This gap introduces a largely unexplored security risk. We study how mismatches between externally presented tool descriptions and underlying implementations systematically shape the mental models and decision-making behavior of intelligent agents. Specifically, we present the first large-scale study of description-code inconsistency in the MCP ecosystem. We design an automated static analysis framework and apply it to 10,240 real-world MCP Servers across 36 categories. Our results show that while most servers are highly consistent, approximately 13% exhibit substantial mismatches that can enable undocumented privileged operations, hidden state mutations, or unauthorized financial actions. We further observe systematic differences across application categories, popularity levels, and MCP marketplaces. Our findings demonstrate that description-code inconsistency is a concrete and prevalent attack surface in MCP-based AI agents, and motivate the need for systematic auditing and stronger transparency guarantees in future agent ecosystems.

</details>


### [26] [Can Developers rely on LLMs for Secure IaC Development?](https://arxiv.org/abs/2602.03648)
*Ehsan Firouzi,Shardul Bhatt,Mohammad Ghafari*

Main category: cs.CR

TL;DR: GPT-4o和Gemini 2.0 Flash在基础设施即代码安全开发中表现有限：安全气味检测在Stack Overflow数据集上可达78%，但在真实GitHub仓库中仅67%；安全代码生成成功率仅7-17%，需要进一步研究改进。


<details>
  <summary>Details</summary>
Motivation: 评估大型语言模型（GPT-4o和Gemini 2.0 Flash）在基础设施即代码（IaC）安全开发中的实际能力，包括安全气味检测和安全代码生成两方面，为改进LLMs在安全开发辅助工具中的应用提供依据。

Method: 使用两种提示策略（通用提示和引导提示）测试模型：1）在Stack Overflow数据集（小型简化代码片段）和GitHub仓库（完整真实项目脚本）上进行安全气味检测；2）使用89个易受攻击的合成场景进行安全代码生成测试，比较有无明确安全指令的效果。

Result: 安全气味检测：Stack Overflow数据集上通用提示检测71%气味，引导提示提升至78%；GitHub仓库中通用提示效果较差（过半气味未检测），引导提示可检测67%气味。安全代码生成：仅7%生成的脚本安全，添加明确安全指令后GPT提升至17%，Gemini变化不大（8%）。

Conclusion: 当前LLMs在安全IaC开发辅助方面能力有限，特别是在真实项目环境和安全代码生成方面表现不足，需要进一步研究改进模型的安全能力，以更好地支持开发人员进行安全基础设施代码开发。

Abstract: We investigated the capabilities of GPT-4o and Gemini 2.0 Flash for secure Infrastructure as Code (IaC) development. For security smell detection, on the Stack Overflow dataset, which primarily contains small, simplified code snippets, the models detected at least 71% of security smells when prompted to analyze code from a security perspective (general prompt). With a guided prompt (adding clear, step-by-step instructions), this increased to 78%.In GitHub repositories, which contain complete, real-world project scripts, a general prompt was less effective, leaving more than half of the smells undetected. However, with the guided prompt, the models uncovered at least 67% of the smells. For secure code generation, we prompted LLMs with 89 vulnerable synthetic scenarios and observed that only 7% of the generated scripts were secure. Adding an explicit instruction to generate secure code increased GPT secure output rate to 17%, while Gemini changed little (8%). These results highlight the need for further research to improve LLMs' capabilities in assisting developers with secure IaC development.

</details>


### [27] [Reference-Free EM Validation Flow for Detecting Triggered Hardware Trojans](https://arxiv.org/abs/2602.03666)
*Mahsa Tahghigh,Hassan Salmani*

Main category: cs.CR

TL;DR: 提出一种无需参考、与设计无关的硬件木马检测框架，利用电磁侧信道分析，通过连续小波变换、CNN特征提取、PCA降维和贝叶斯高斯混合模型进行无监督检测。


<details>
  <summary>Details</summary>
Motivation: 硬件木马威胁集成电路的信任和可靠性，现有基于电磁侧信道的检测方法通常需要黄金参考或标记数据，这在现代分布式制造中不可行。

Method: 将电磁迹线通过连续小波变换转换为时频尺度图，使用卷积神经网络提取判别特征，通过主成分分析降维，应用贝叶斯高斯混合模型进行无监督概率聚类。

Result: 在嵌入四种不同硬件木马的AES-128设计上进行实验验证，显示硬件木马激活与未激活条件之间具有高可分离性，对PCA方差阈值具有鲁棒性。

Conclusion: 该方法具有可扩展性、统计可解释性，并具有扩展到运行时和现场硬件木马监控的潜力，适用于可信微电子领域。

Abstract: Hardware Trojans (HTs) threaten the trust and reliability of integrated circuits (ICs), particularly when triggered HTs remain dormant during standard testing and activate only under rare conditions. Existing electromagnetic (EM) side-channel-based detection techniques often rely on golden references or labeled data, which are infeasible in modern distributed manufacturing. This paper introduces a reference-free, design-agnostic framework for detecting triggered HTs directly from post-silicon EM emissions. The proposed flow converts each EM trace into a time-frequency scalogram using Continuous Wavelet Transform (CWT), extracts discriminative features through a convolutional neural network (CNN), reduces dimensionality with principal component analysis (PCA), and applies Bayesian Gaussian Mixture Modeling (BGMM) for unsupervised probabilistic clustering. The framework quantifies detection confidence using posterior-based metrics (alpha_{post}, beta_{post}), Bayesian information criterion (Delta BIC), and Mahalanobis cluster separation (D), enabling interpretable anomaly decisions without golden data. Experimental validation on AES-128 designs embedded with four different HTs demonstrates high separability between HT-free and HT-activated conditions and robustness to PCA variance thresholds. The results highlight the method's scalability, statistical interpretability, and potential for extension to runtime and in-field HT monitoring in trusted microelectronics.

</details>


### [28] [mopri - An Analysis Framework for Unveiling Privacy Violations in Mobile Apps](https://arxiv.org/abs/2602.03671)
*Cornell Ziepel,Stephan Escher,Sebastian Rehms,Stefan Köpsell*

Main category: cs.CR

TL;DR: mopri是一个用于分析移动应用行为的隐私合规性验证框架，通过静态和动态分析方法帮助用户和执法机构验证数据保护合规性


<details>
  <summary>Details</summary>
Motivation: 移动应用日益普及导致用户参与可能性与隐私保护之间的冲突，现有隐私法规（如GDPR）难以有效检查应用合规性，需要工具帮助用户和执法机构验证和执行数据保护

Method: 提出mopri概念框架，采用模块化流水线设计，集成多种分析工具，结合静态分析（提取权限和跟踪库）和动态分析（流量记录和解密），并包含结果丰富和报告功能

Result: 开发的原型能有效提取权限和跟踪库，采用稳健的动态流量记录和解密方法，增强分析结果的清晰度和可用性，展示了整体模块化隐私分析方法的可行性

Conclusion: mopri框架为移动应用隐私分析提供了全面、可适应、以用户为中心的基础，强调需要持续适应移动应用生态系统不断演变的挑战，以保护用户信息自决权

Abstract: Everyday services of society increasingly rely on mobile applications, resulting in a conflicting situation between the possibility of participation on the one side and user privacy and digital freedom on the other. In order to protect users' rights to informational self-determination, regulatory approaches for the collection and processing of personal data have been developed, such as the EU's GDPR. However, inspecting the compliance of mobile apps with privacy regulations remains difficult. Thus, in order to enable end users and enforcement bodies to verify and enforce data protection compliance, we propose mopri, a conceptual framework designed for analyzing the behavior of mobile apps through a comprehensive, adaptable, and user-centered approach. Recognizing the gaps in existing frameworks, mopri serves as a foundation for integrating various analysis tools into a streamlined, modular pipeline that employs static and dynamic analysis methods. Building on this concept, a prototype has been developed which effectively extracts permissions and tracking libraries while employing robust methods for dynamic traffic recording and decryption. Additionally, it incorporates result enrichment and reporting features that enhance the clarity and usability of the analysis outcomes. The prototype showcases the feasibility of a holistic and modular approach to privacy analysis, emphasizing the importance of continuous adaptation to the evolving challenges presented by the mobile app ecosystem.

</details>


### [29] [WebSentinel: Detecting and Localizing Prompt Injection Attacks for Web Agents](https://arxiv.org/abs/2602.03792)
*Xilong Wang,Yinuo Liu,Zhun Wang,Dawn Song,Neil Gong*

Main category: cs.CR

TL;DR: WebSentinel是一个两步法检测和定位网页中提示注入攻击的系统，通过提取可疑片段并检查其与网页内容的一致性来识别攻击。


<details>
  <summary>Details</summary>
Motivation: 现有方法在网页代理环境下检测提示注入攻击效果有限，因为其基本假设在网页代理场景中往往不成立。提示注入攻击会操纵网页内容，使网页代理执行攻击者指定的任务而非用户意图的任务。

Method: WebSentinel采用两步法：第一步提取可能被污染的"兴趣片段"，第二步通过检查每个片段与网页内容作为上下文的一致性来评估每个片段。

Result: WebSentinel在收集的污染和干净网页数据集上表现出色，显著优于基线方法。

Conclusion: WebSentinel是检测和定位网页中提示注入攻击的有效方法，代码已开源。

Abstract: Prompt injection attacks manipulate webpage content to cause web agents to execute attacker-specified tasks instead of the user's intended ones. Existing methods for detecting and localizing such attacks achieve limited effectiveness, as their underlying assumptions often do not hold in the web-agent setting. In this work, we propose WebSentinel, a two-step approach for detecting and localizing prompt injection attacks in webpages. Given a webpage, Step I extracts \emph{segments of interest} that may be contaminated, and Step II evaluates each segment by checking its consistency with the webpage content as context. We show that WebSentinel is highly effective, substantially outperforming baseline methods across multiple datasets of both contaminated and clean webpages that we collected. Our code is available at: https://github.com/wxl-lxw/WebSentinel.

</details>
