{"id": "2511.20801", "categories": ["cs.CR"], "pdf": "https://arxiv.org/pdf/2511.20801", "abs": "https://arxiv.org/abs/2511.20801", "authors": ["Hossein Shokouhinejad", "Griffin Higgins", "Roozbeh Razavi-Far", "Ali A. Ghorbani"], "title": "A Research and Development Portfolio of GNN Centric Malware Detection, Explainability, and Dataset Curation", "comment": "Accepted in 2025 IEEE International Conference on Data Mining Workshops (ICDMW)", "summary": "Graph Neural Networks (GNNs) have become an effective tool for malware detection by capturing program execution through graph-structured representations. However, important challenges remain regarding scalability, interpretability, and the availability of reliable datasets. This paper brings together six related studies that collectively address these issues. The portfolio begins with a survey of graph-based malware detection and explainability, then advances to new graph reduction methods, integrated reduction-learning approaches, and investigations into the consistency of explanations. It also introduces dual explanation techniques based on subgraph matching and develops ensemble-based models with attention-guided stacked GNNs to improve interpretability. In parallel, curated datasets of control flow graphs are released to support reproducibility and enable future research. Together, these contributions form a coherent line of research that strengthens GNN-based malware detection by enhancing efficiency, increasing transparency, and providing solid experimental foundations.", "AI": {"tldr": "\u8be5\u8bba\u6587\u7ec4\u5408\u4e86\u516d\u9879\u76f8\u5173\u7814\u7a76\uff0c\u5171\u540c\u89e3\u51b3\u57fa\u4e8e\u56fe\u795e\u7ecf\u7f51\u7edc\u7684\u6076\u610f\u8f6f\u4ef6\u68c0\u6d4b\u5728\u53ef\u6269\u5c55\u6027\u3001\u53ef\u89e3\u91ca\u6027\u548c\u6570\u636e\u96c6\u53ef\u9760\u6027\u65b9\u9762\u7684\u6311\u6218\u3002", "motivation": "\u56fe\u795e\u7ecf\u7f51\u7edc\u5728\u6076\u610f\u8f6f\u4ef6\u68c0\u6d4b\u4e2d\u9762\u4e34\u53ef\u6269\u5c55\u6027\u3001\u53ef\u89e3\u91ca\u6027\u548c\u53ef\u9760\u6570\u636e\u96c6\u53ef\u7528\u6027\u7684\u91cd\u8981\u6311\u6218\u3002", "method": "\u5305\u62ec\u56fe\u7f29\u51cf\u65b9\u6cd5\u3001\u96c6\u6210\u7f29\u51cf\u5b66\u4e60\u65b9\u6cd5\u3001\u57fa\u4e8e\u5b50\u56fe\u5339\u914d\u7684\u53cc\u91cd\u89e3\u91ca\u6280\u672f\u3001\u6ce8\u610f\u529b\u5f15\u5bfc\u7684\u5806\u53e0GNN\u96c6\u6210\u6a21\u578b\uff0c\u5e76\u53d1\u5e03\u4e86\u63a7\u5236\u6d41\u56fe\u6570\u636e\u96c6\u3002", "result": "\u5f62\u6210\u4e86\u4e00\u5957\u8fde\u8d2f\u7684\u7814\u7a76\u4f53\u7cfb\uff0c\u901a\u8fc7\u63d0\u9ad8\u6548\u7387\u3001\u589e\u52a0\u900f\u660e\u5ea6\u548c\u63d0\u4f9b\u575a\u5b9e\u7684\u5b9e\u9a8c\u57fa\u7840\u6765\u52a0\u5f3a\u57fa\u4e8eGNN\u7684\u6076\u610f\u8f6f\u4ef6\u68c0\u6d4b\u3002", "conclusion": "\u8fd9\u4e9b\u8d21\u732e\u5171\u540c\u589e\u5f3a\u4e86\u57fa\u4e8eGNN\u7684\u6076\u610f\u8f6f\u4ef6\u68c0\u6d4b\u80fd\u529b\uff0c\u5728\u6548\u7387\u3001\u900f\u660e\u5ea6\u548c\u5b9e\u9a8c\u57fa\u7840\u65b9\u9762\u90fd\u6709\u663e\u8457\u63d0\u5347\u3002"}}
{"id": "2511.20832", "categories": ["cs.CR"], "pdf": "https://arxiv.org/pdf/2511.20832", "abs": "https://arxiv.org/abs/2511.20832", "authors": ["Abdelkarim Kati", "Florian Kerschbaum", "Marina Blanton"], "title": "Private Data Imputation", "comment": null, "summary": "Data imputation is an important data preparation task where the data analyst replaces missing or erroneous values to increase the expected accuracy of downstream analyses. The accuracy improvement of data imputation extends to private data analyses across distributed databases. However, existing data imputation methods violate the privacy of the data rendering the privacy protection in the downstream analyses obsolete. We conclude that private data analysis requires private data imputation.\n  In this paper, we present the first optimized protocols for private data imputation. We consider the case of horizontally and vertically split data sets. Our optimization aims to reduce most of the computation to private set intersection (or at least oblivious programmable pseudo-random function) protocols which can be very efficiently computed. We show that private data imputation has -- on average across all evaluated datasets -- an accuracy advantage of 20\\% in case of vertically split data and 5\\% in case of horizontally split data over imputing data locally. In case of the worst data split we observed that imputing using our method resulted in an increase of up to 32.7 times in the quality of imputation over the vertically split data and 3.4 times in case of horizontally split data. Our protocols are very efficient and run in 2.4 seconds in case of vertically split data and 8.4 seconds in case of horizontally split data for 100,000 records evaluated in the 10 Gbps network setting, performing one data imputation.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u9996\u4e2a\u4f18\u5316\u7684\u9690\u79c1\u6570\u636e\u63d2\u8865\u534f\u8bae\uff0c\u9488\u5bf9\u6c34\u5e73\u548c\u5782\u76f4\u5206\u5272\u7684\u6570\u636e\u96c6\uff0c\u901a\u8fc7\u5c06\u5927\u90e8\u5206\u8ba1\u7b97\u7b80\u5316\u4e3a\u79c1\u6709\u96c6\u5408\u4ea4\u96c6\u534f\u8bae\uff0c\u663e\u8457\u63d0\u9ad8\u4e86\u6570\u636e\u63d2\u8865\u7684\u51c6\u786e\u6027\u548c\u6548\u7387\u3002", "motivation": "\u73b0\u6709\u6570\u636e\u63d2\u8865\u65b9\u6cd5\u4f1a\u6cc4\u9732\u9690\u79c1\uff0c\u4f7f\u5f97\u4e0b\u6e38\u9690\u79c1\u4fdd\u62a4\u5206\u6790\u5931\u6548\uff0c\u56e0\u6b64\u9700\u8981\u5f00\u53d1\u9690\u79c1\u4fdd\u62a4\u7684\u6570\u636e\u63d2\u8865\u65b9\u6cd5\u3002", "method": "\u4f7f\u7528\u4f18\u5316\u7684\u79c1\u6709\u96c6\u5408\u4ea4\u96c6\u534f\u8bae\u6216\u53ef\u7f16\u7a0b\u4f2a\u968f\u673a\u51fd\u6570\u534f\u8bae\u6765\u5904\u7406\u6c34\u5e73\u548c\u5782\u76f4\u5206\u5272\u7684\u6570\u636e\u96c6\uff0c\u5c06\u5927\u90e8\u5206\u8ba1\u7b97\u7b80\u5316\u4e3a\u8fd9\u4e9b\u9ad8\u6548\u534f\u8bae\u3002", "result": "\u5728\u5782\u76f4\u5206\u5272\u6570\u636e\u4e0a\u5e73\u5747\u51c6\u786e\u7387\u63d0\u9ad820%\uff0c\u6c34\u5e73\u5206\u5272\u6570\u636e\u63d0\u9ad85%\uff1b\u6700\u5dee\u60c5\u51b5\u4e0b\u5782\u76f4\u5206\u5272\u6570\u636e\u63d2\u8865\u8d28\u91cf\u63d0\u534732.7\u500d\uff0c\u6c34\u5e73\u5206\u5272\u63d0\u53473.4\u500d\uff1b\u5904\u740610\u4e07\u6761\u8bb0\u5f55\u4ec5\u97002.4-8.4\u79d2\u3002", "conclusion": "\u9690\u79c1\u6570\u636e\u5206\u6790\u9700\u8981\u9690\u79c1\u6570\u636e\u63d2\u8865\uff0c\u6240\u63d0\u51fa\u7684\u534f\u8bae\u5728\u4fdd\u6301\u9690\u79c1\u7684\u540c\u65f6\u663e\u8457\u63d0\u9ad8\u4e86\u6570\u636e\u63d2\u8865\u7684\u51c6\u786e\u6027\u548c\u6548\u7387\u3002"}}
{"id": "2511.20878", "categories": ["cs.CR"], "pdf": "https://arxiv.org/pdf/2511.20878", "abs": "https://arxiv.org/abs/2511.20878", "authors": ["Jaehwan Park", "Kyungchan Lim", "Seonhye Park", "Doowon Kim"], "title": "Supporting Students in Navigating LLM-Generated Insecure Code", "comment": "7 pages", "summary": "The advent of Artificial Intelligence (AI), particularly large language models (LLMs), has revolutionized software development by enabling developers to specify tasks in natural language and receive corresponding code, boosting productivity. However, this shift also introduces security risks, as LLMs may generate insecure code that can be exploited by adversaries. Current educational approaches emphasize efficiency while overlooking these risks, leaving students underprepared to identify and mitigate security issues in AI-assisted workflows.\n  To address this gap, we present Bifr\u00f6st, an educational framework that cultivates security awareness in AI-augmented development. Bifr\u00f6st integrates (1) a Visual Studio Code extension simulating realistic environments, (2) adversarially configured LLMs that generate insecure code, and (3) a feedback system highlighting vulnerabilities. By immersing students in tasks with compromised LLMs and providing targeted security analysis, Bifr\u00f6st cultivates critical evaluation skills; classroom deployments (n=61) show vulnerability to insecure code, while a post-intervention survey (n=21) indicates increased skepticism toward LLM outputs.", "AI": {"tldr": "Bifr\u00f6st\u662f\u4e00\u4e2a\u6559\u80b2\u6846\u67b6\uff0c\u901a\u8fc7\u5728AI\u8f85\u52a9\u5f00\u53d1\u4e2d\u6a21\u62df\u4e0d\u5b89\u5168\u4ee3\u7801\u751f\u6210\u6765\u57f9\u517b\u5b89\u5168\u610f\u8bc6\u548c\u6279\u5224\u6027\u8bc4\u4f30\u80fd\u529b\u3002", "motivation": "AI\u8f85\u52a9\u5f00\u53d1\u867d\u7136\u63d0\u9ad8\u4e86\u6548\u7387\uff0c\u4f46LLM\u53ef\u80fd\u751f\u6210\u4e0d\u5b89\u5168\u4ee3\u7801\uff0c\u800c\u73b0\u6709\u6559\u80b2\u65b9\u6cd5\u5ffd\u89c6\u4e86\u8fd9\u4e9b\u5b89\u5168\u98ce\u9669\uff0c\u5bfc\u81f4\u5b66\u751f\u65e0\u6cd5\u8bc6\u522b\u548c\u7f13\u89e3AI\u8f85\u52a9\u5de5\u4f5c\u6d41\u4e2d\u7684\u5b89\u5168\u95ee\u9898\u3002", "method": "\u5f00\u53d1\u4e86Bifr\u00f6st\u6846\u67b6\uff0c\u5305\u542bVS Code\u6269\u5c55\u6a21\u62df\u771f\u5b9e\u73af\u5883\u3001\u5bf9\u6297\u6027\u914d\u7f6e\u7684LLM\u751f\u6210\u4e0d\u5b89\u5168\u4ee3\u7801\u3001\u4ee5\u53ca\u7a81\u51fa\u6f0f\u6d1e\u7684\u53cd\u9988\u7cfb\u7edf\uff0c\u8ba9\u5b66\u751f\u5728\u53d7\u6c61\u67d3\u7684LLM\u73af\u5883\u4e2d\u5b8c\u6210\u4efb\u52a1\u5e76\u83b7\u5f97\u5b89\u5168\u5206\u6790\u3002", "result": "\u8bfe\u5802\u90e8\u7f72\uff08n=61\uff09\u663e\u793a\u5b66\u751f\u5bf9\u4e0d\u5b89\u5168\u4ee3\u7801\u5b58\u5728\u6f0f\u6d1e\uff0c\u5e72\u9884\u540e\u8c03\u67e5\uff08n=21\uff09\u8868\u660e\u5bf9LLM\u8f93\u51fa\u7684\u6000\u7591\u6001\u5ea6\u589e\u5f3a\u3002", "conclusion": "Bifr\u00f6st\u901a\u8fc7\u6c89\u6d78\u5f0f\u4f53\u9a8c\u6709\u6548\u57f9\u517b\u4e86\u5b66\u751f\u5728AI\u8f85\u52a9\u5f00\u53d1\u4e2d\u7684\u5b89\u5168\u610f\u8bc6\u548c\u6279\u5224\u6027\u601d\u7ef4\u3002"}}
{"id": "2511.20902", "categories": ["cs.CR", "cs.AI", "cs.CY"], "pdf": "https://arxiv.org/pdf/2511.20902", "abs": "https://arxiv.org/abs/2511.20902", "authors": ["Glener Lanes Pizzolato", "Brenda Medeiros Lopes", "Claudio Schepke", "Diego Kreutz"], "title": "A Taxonomy of Pix Fraud in Brazil: Attack Methodologies, AI-Driven Amplification, and Defensive Strategies", "comment": "5 pages, 1 figure, 2 tables, submitted to ERRC/WRSeg 2025", "summary": "This work presents a review of attack methodologies targeting Pix, the instant payment system launched by the Central Bank of Brazil in 2020. The study aims to identify and classify the main types of fraud affecting users and financial institutions, highlighting the evolution and increasing sophistication of these techniques. The methodology combines a structured literature review with exploratory interviews conducted with professionals from the banking sector. The results show that fraud schemes have evolved from purely social engineering approaches to hybrid strategies that integrate human manipulation with technical exploitation. The study concludes that security measures must advance at the same pace as the growing complexity of attack methodologies, with particular emphasis on adaptive defenses and continuous user awareness.", "AI": {"tldr": "\u5bf9\u5df4\u897fPix\u5373\u65f6\u652f\u4ed8\u7cfb\u7edf\u653b\u51fb\u65b9\u6cd5\u7684\u7efc\u8ff0\u7814\u7a76\uff0c\u5206\u6790\u4e86\u9488\u5bf9\u7528\u6237\u548c\u91d1\u878d\u673a\u6784\u7684\u4e3b\u8981\u6b3a\u8bc8\u7c7b\u578b\u53ca\u5176\u6f14\u53d8\u8d8b\u52bf\u3002", "motivation": "\u968f\u7740Pix\u7cfb\u7edf\u5728\u5df4\u897f\u7684\u666e\u53ca\uff0c\u9488\u5bf9\u8be5\u7cfb\u7edf\u7684\u6b3a\u8bc8\u653b\u51fb\u65e5\u76ca\u590d\u6742\u5316\uff0c\u9700\u8981\u7cfb\u7edf\u6027\u5730\u8bc6\u522b\u548c\u5206\u7c7b\u4e3b\u8981\u653b\u51fb\u65b9\u6cd5\uff0c\u4e3a\u5b89\u5168\u9632\u62a4\u63d0\u4f9b\u4f9d\u636e\u3002", "method": "\u7ed3\u5408\u7ed3\u6784\u5316\u6587\u732e\u7efc\u8ff0\u548c\u4e0e\u94f6\u884c\u4e1a\u4e13\u4e1a\u4eba\u58eb\u7684\u63a2\u7d22\u6027\u8bbf\u8c08\u3002", "result": "\u6b3a\u8bc8\u65b9\u6848\u5df2\u4ece\u7eaf\u7cb9\u7684\u793e\u4f1a\u5de5\u7a0b\u65b9\u6cd5\u6f14\u53d8\u4e3a\u7ed3\u5408\u4eba\u4e3a\u64cd\u7eb5\u548c\u6280\u672f\u5229\u7528\u7684\u6df7\u5408\u7b56\u7565\u3002", "conclusion": "\u5b89\u5168\u63aa\u65bd\u5fc5\u987b\u4e0e\u653b\u51fb\u65b9\u6cd5\u590d\u6742\u5ea6\u7684\u589e\u957f\u540c\u6b65\u53d1\u5c55\uff0c\u7279\u522b\u5f3a\u8c03\u9002\u5e94\u6027\u9632\u5fa1\u548c\u6301\u7eed\u7684\u7528\u6237\u610f\u8bc6\u6559\u80b2\u3002"}}
{"id": "2511.20920", "categories": ["cs.CR"], "pdf": "https://arxiv.org/pdf/2511.20920", "abs": "https://arxiv.org/abs/2511.20920", "authors": ["Herman Errico", "Jiquan Ngiam", "Shanita Sojan"], "title": "Securing the Model Context Protocol (MCP): Risks, Controls, and Governance", "comment": null, "summary": "The Model Context Protocol (MCP) replaces static, developer-controlled API integrations with more dynamic, user-driven agent systems, which also introduces new security risks. As MCP adoption grows across community servers and major platforms, organizations encounter threats that existing AI governance frameworks (such as NIST AI RMF and ISO/IEC 42001) do not yet cover in detail. We focus on three types of adversaries that take advantage of MCP s flexibility: content-injection attackers that embed malicious instructions into otherwise legitimate data; supply-chain attackers who distribute compromised servers; and agents who become unintentional adversaries by over-stepping their role. Based on early incidents and proof-of-concept attacks, we describe how MCP can increase the attack surface through data-driven exfiltration, tool poisoning, and cross-system privilege escalation. In response, we propose a set of practical controls, including per-user authentication with scoped authorization, provenance tracking across agent workflows, containerized sandboxing with input/output checks, inline policy enforcement with DLP and anomaly detection, and centralized governance using private registries or gateway layers. The aim is to help organizations ensure that unvetted code does not run outside a sandbox, tools are not used beyond their intended scope, data exfiltration attempts are detectable, and actions can be audited end-to-end. We close by outlining open research questions around verifiable registries, formal methods for these dynamic systems, and privacy-preserving agent operations.", "AI": {"tldr": "MCP\u534f\u8bae\u5f15\u5165\u52a8\u6001\u7528\u6237\u9a71\u52a8\u7cfb\u7edf\u5e26\u6765\u65b0\u7684\u5b89\u5168\u98ce\u9669\uff0c\u5305\u62ec\u5185\u5bb9\u6ce8\u5165\u653b\u51fb\u3001\u4f9b\u5e94\u94fe\u653b\u51fb\u548c\u4ee3\u7406\u8d8a\u6743\u3002\u672c\u6587\u5206\u6790\u4e86\u8fd9\u4e9b\u5a01\u80c1\u5e76\u63d0\u51fa\u5b9e\u7528\u63a7\u5236\u63aa\u65bd\uff0c\u5305\u62ec\u8ba4\u8bc1\u6388\u6743\u3001\u6eaf\u6e90\u8ddf\u8e2a\u3001\u6c99\u7bb1\u9694\u79bb\u3001\u7b56\u7565\u6267\u884c\u548c\u96c6\u4e2d\u6cbb\u7406\u3002", "motivation": "\u968f\u7740MCP\u5728\u793e\u533a\u670d\u52a1\u5668\u548c\u4e3b\u8981\u5e73\u53f0\u7684\u91c7\u7528\u589e\u957f\uff0c\u7ec4\u7ec7\u9762\u4e34\u73b0\u6709AI\u6cbb\u7406\u6846\u67b6\u5c1a\u672a\u8be6\u7ec6\u8986\u76d6\u7684\u65b0\u5b89\u5168\u5a01\u80c1\uff0c\u9700\u8981\u4e13\u95e8\u7684\u5b89\u5168\u63a7\u5236\u63aa\u65bd\u3002", "method": "\u57fa\u4e8e\u65e9\u671f\u4e8b\u4ef6\u548c\u6982\u5ff5\u9a8c\u8bc1\u653b\u51fb\uff0c\u5206\u6790MCP\u5982\u4f55\u901a\u8fc7\u6570\u636e\u9a71\u52a8\u6cc4\u9732\u3001\u5de5\u5177\u6c61\u67d3\u548c\u8de8\u7cfb\u7edf\u6743\u9650\u63d0\u5347\u6269\u5927\u653b\u51fb\u9762\uff0c\u5e76\u63d0\u51fa\u76f8\u5e94\u7684\u63a7\u5236\u63aa\u65bd\u3002", "result": "\u8bc6\u522b\u4e86\u4e09\u79cd\u4e3b\u8981\u653b\u51fb\u8005\u7c7b\u578b\u548c\u76f8\u5e94\u7684\u653b\u51fb\u5411\u91cf\uff0c\u63d0\u51fa\u4e86\u4e00\u5957\u5b9e\u7528\u7684\u5b89\u5168\u63a7\u5236\u6846\u67b6\u6765\u5e94\u5bf9\u8fd9\u4e9b\u5a01\u80c1\u3002", "conclusion": "\u9700\u8981\u5e2e\u52a9\u7ec4\u7ec7\u786e\u4fdd\u672a\u7ecf\u9a8c\u8bc1\u7684\u4ee3\u7801\u4e0d\u5728\u6c99\u7bb1\u5916\u8fd0\u884c\u3001\u5de5\u5177\u4e0d\u8d85\u51fa\u9884\u671f\u8303\u56f4\u4f7f\u7528\u3001\u6570\u636e\u6cc4\u9732\u5c1d\u8bd5\u53ef\u68c0\u6d4b\u3001\u64cd\u4f5c\u53ef\u7aef\u5230\u7aef\u5ba1\u8ba1\uff0c\u5e76\u63d0\u51fa\u4e86\u5f00\u653e\u7814\u7a76\u95ee\u9898\u3002"}}
{"id": "2511.20922", "categories": ["cs.CR", "cs.DC", "cs.LG"], "pdf": "https://arxiv.org/pdf/2511.20922", "abs": "https://arxiv.org/abs/2511.20922", "authors": ["Guilin Zhang", "Wulan Guo", "Ziqi Tan", "Hongyang He", "Hailong Jiang"], "title": "Readout-Side Bypass for Residual Hybrid Quantum-Classical Models", "comment": "5 pages, 1 figure, 6 tables", "summary": "Quantum machine learning (QML) promises compact and expressive representations, but suffers from the measurement bottleneck - a narrow quantum-to-classical readout that limits performance and amplifies privacy risk. We propose a lightweight residual hybrid architecture that concatenates quantum features with raw inputs before classification, bypassing the bottleneck without increasing quantum complexity. Experiments show our model outperforms pure quantum and prior hybrid models in both centralized and federated settings. It achieves up to +55% accuracy improvement over quantum baselines, while retaining low communication cost and enhanced privacy robustness. Ablation studies confirm the effectiveness of the residual connection at the quantum-classical interface. Our method offers a practical, near-term pathway for integrating quantum models into privacy-sensitive, resource-constrained settings like federated edge learning.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u8f7b\u91cf\u7ea7\u6b8b\u5dee\u6df7\u5408\u67b6\u6784\uff0c\u5c06\u91cf\u5b50\u7279\u5f81\u4e0e\u539f\u59cb\u8f93\u5165\u5728\u5206\u7c7b\u524d\u8fde\u63a5\uff0c\u7ed5\u8fc7\u6d4b\u91cf\u74f6\u9888\uff0c\u5728\u4fdd\u6301\u91cf\u5b50\u590d\u6742\u5ea6\u4e0d\u53d8\u7684\u540c\u65f6\u63d0\u5347\u6027\u80fd\u3002", "motivation": "\u91cf\u5b50\u673a\u5668\u5b66\u4e60\u867d\u7136\u5177\u6709\u7d27\u51d1\u548c\u8868\u8fbe\u6027\u5f3a\u7684\u4f18\u52bf\uff0c\u4f46\u9762\u4e34\u6d4b\u91cf\u74f6\u9888\u95ee\u9898\u2014\u2014\u72ed\u7a84\u7684\u91cf\u5b50-\u7ecf\u5178\u8bfb\u51fa\u9650\u5236\u4e86\u6027\u80fd\u5e76\u653e\u5927\u4e86\u9690\u79c1\u98ce\u9669\u3002", "method": "\u91c7\u7528\u6b8b\u5dee\u6df7\u5408\u67b6\u6784\uff0c\u5728\u91cf\u5b50-\u7ecf\u5178\u63a5\u53e3\u5904\u5c06\u91cf\u5b50\u7279\u5f81\u4e0e\u539f\u59cb\u8f93\u5165\u8fdb\u884c\u8fde\u63a5\uff0c\u907f\u514d\u589e\u52a0\u91cf\u5b50\u590d\u6742\u5ea6\u3002", "result": "\u5728\u96c6\u4e2d\u5f0f\u548c\u8054\u90a6\u5f0f\u8bbe\u7f6e\u4e2d\u5747\u4f18\u4e8e\u7eaf\u91cf\u5b50\u6a21\u578b\u548c\u5148\u524d\u7684\u6df7\u5408\u6a21\u578b\uff0c\u76f8\u6bd4\u91cf\u5b50\u57fa\u7ebf\u51c6\u786e\u7387\u63d0\u5347\u9ad8\u8fbe+55%\uff0c\u540c\u65f6\u4fdd\u6301\u4f4e\u901a\u4fe1\u6210\u672c\u548c\u589e\u5f3a\u7684\u9690\u79c1\u9c81\u68d2\u6027\u3002", "conclusion": "\u8be5\u65b9\u6cd5\u4e3a\u5728\u9690\u79c1\u654f\u611f\u3001\u8d44\u6e90\u53d7\u9650\u7684\u73af\u5883\uff08\u5982\u8054\u90a6\u8fb9\u7f18\u5b66\u4e60\uff09\u4e2d\u96c6\u6210\u91cf\u5b50\u6a21\u578b\u63d0\u4f9b\u4e86\u4e00\u6761\u5b9e\u7528\u7684\u8fd1\u671f\u8def\u5f84\u3002"}}
{"id": "2511.21020", "categories": ["cs.CR"], "pdf": "https://arxiv.org/pdf/2511.21020", "abs": "https://arxiv.org/abs/2511.21020", "authors": ["Minghui Min", "Jiahui Liu", "Mingge Cao", "Shiyin Li", "Hongliang Zhang", "Miao Pan", "Zhu Han"], "title": "Road Network-Aware Personalized Trajectory Protection with Differential Privacy under Spatiotemporal Correlations", "comment": "13 pages,10 figures", "summary": "Location-Based Services (LBSs) offer significant convenience to mobile users but pose significant privacy risks, as attackers can infer sensitive personal information through spatiotemporal correlations in user trajectories. Since users' sensitivity to location data varies based on factors such as stay duration, access frequency, and semantic sensitivity, implementing personalized privacy protection is imperative. This paper proposes a Personalized Trajectory Privacy Protection Mechanism (PTPPM) to address these challenges. Our approach begins by modeling an attacker's knowledge of a user's trajectory spatiotemporal correlations, which enables the attacker to identify possible location sets and disregard low-probability location sets. To combat this, we integrate geo-indistinguishability with distortion privacy, allowing users to customize their privacy preferences through a configurable privacy budget and expected inference error bound. This approach provides the theoretical framework for constructing a Protection Location Set (PLS) that obscures users' actual locations. Additionally, we introduce a Personalized Privacy Budget Allocation Algorithm (PPBA), which assesses the sensitivity of locations based on trajectory data and allocates privacy budgets accordingly. This algorithm considers factors such as location semantics and road network constraints. Furthermore, we propose a Permute-and-Flip mechanism that generates perturbed locations while minimizing perturbation distance, thus balancing privacy protection and Quality of Service (QoS). Simulation results demonstrate that our mechanism outperforms existing benchmarks, offering superior privacy protection while maintaining user QoS requirements.", "AI": {"tldr": "\u63d0\u51fa\u4e2a\u6027\u5316\u8f68\u8ff9\u9690\u79c1\u4fdd\u62a4\u673a\u5236PTPPM\uff0c\u901a\u8fc7\u7ed3\u5408\u5730\u7406\u4e0d\u53ef\u533a\u5206\u6027\u548c\u5931\u771f\u9690\u79c1\uff0c\u8ba9\u7528\u6237\u81ea\u5b9a\u4e49\u9690\u79c1\u504f\u597d\uff0c\u5728\u4fdd\u62a4\u4f4d\u7f6e\u9690\u79c1\u7684\u540c\u65f6\u7ef4\u6301\u670d\u52a1\u8d28\u91cf\u3002", "motivation": "\u57fa\u4e8e\u4f4d\u7f6e\u7684\u670d\u52a1\u867d\u7136\u4fbf\u5229\u4f46\u5b58\u5728\u9690\u79c1\u98ce\u9669\uff0c\u653b\u51fb\u8005\u53ef\u901a\u8fc7\u65f6\u7a7a\u76f8\u5173\u6027\u63a8\u65ad\u654f\u611f\u4fe1\u606f\u3002\u7531\u4e8e\u7528\u6237\u5bf9\u4f4d\u7f6e\u6570\u636e\u7684\u654f\u611f\u5ea6\u56e0\u505c\u7559\u65f6\u95f4\u3001\u8bbf\u95ee\u9891\u7387\u7b49\u56e0\u7d20\u800c\u5f02\uff0c\u9700\u8981\u4e2a\u6027\u5316\u9690\u79c1\u4fdd\u62a4\u3002", "method": "\u5efa\u6a21\u653b\u51fb\u8005\u5bf9\u8f68\u8ff9\u65f6\u7a7a\u76f8\u5173\u6027\u7684\u77e5\u8bc6\uff0c\u7ed3\u5408\u5730\u7406\u4e0d\u53ef\u533a\u5206\u6027\u548c\u5931\u771f\u9690\u79c1\u6784\u5efa\u4fdd\u62a4\u4f4d\u7f6e\u96c6\uff0c\u63d0\u51fa\u4e2a\u6027\u5316\u9690\u79c1\u9884\u7b97\u5206\u914d\u7b97\u6cd5PPBA\u548cPermute-and-Flip\u6270\u52a8\u673a\u5236\u3002", "result": "\u4eff\u771f\u7ed3\u679c\u8868\u660e\u8be5\u673a\u5236\u4f18\u4e8e\u73b0\u6709\u57fa\u51c6\u65b9\u6cd5\uff0c\u5728\u6ee1\u8db3\u7528\u6237\u670d\u52a1\u8d28\u91cf\u8981\u6c42\u7684\u540c\u65f6\u63d0\u4f9b\u66f4\u597d\u7684\u9690\u79c1\u4fdd\u62a4\u3002", "conclusion": "PTPPM\u673a\u5236\u80fd\u6709\u6548\u5e73\u8861\u9690\u79c1\u4fdd\u62a4\u548c\u670d\u52a1\u8d28\u91cf\uff0c\u901a\u8fc7\u4e2a\u6027\u5316\u9690\u79c1\u9884\u7b97\u5206\u914d\u548c\u6700\u5c0f\u5316\u6270\u52a8\u8ddd\u79bb\u5b9e\u73b0\u9ad8\u6548\u7684\u4f4d\u7f6e\u9690\u79c1\u4fdd\u62a4\u3002"}}
{"id": "2511.21180", "categories": ["cs.CR", "cs.AI"], "pdf": "https://arxiv.org/pdf/2511.21180", "abs": "https://arxiv.org/abs/2511.21180", "authors": ["Shuhan Xia", "Jing Dai", "Hui Ouyang", "Yadong Shang", "Dongxiao Zhao", "Peipei Li"], "title": "CAHS-Attack: CLIP-Aware Heuristic Search Attack Method for Stable Diffusion", "comment": null, "summary": "Diffusion models exhibit notable fragility when faced with adversarial prompts, and strengthening attack capabilities is crucial for uncovering such vulnerabilities and building more robust generative systems. Existing works often rely on white-box access to model gradients or hand-crafted prompt engineering, which is infeasible in real-world deployments due to restricted access or poor attack effect. In this paper, we propose CAHS-Attack , a CLIP-Aware Heuristic Search attack method. CAHS-Attack integrates Monte Carlo Tree Search (MCTS) to perform fine-grained suffix optimization, leveraging a constrained genetic algorithm to preselect high-potential adversarial prompts as root nodes, and retaining the most semantically disruptive outcome at each simulation rollout for efficient local search. Extensive experiments demonstrate that our method achieves state-of-the-art attack performance across both short and long prompts of varying semantics. Furthermore, we find that the fragility of SD models can be attributed to the inherent vulnerability of their CLIP-based text encoders, suggesting a fundamental security risk in current text-to-image pipelines.", "AI": {"tldr": "CAHS-Attack\u662f\u4e00\u79cd\u57fa\u4e8eCLIP\u611f\u77e5\u7684\u542f\u53d1\u5f0f\u641c\u7d22\u653b\u51fb\u65b9\u6cd5\uff0c\u901a\u8fc7\u8499\u7279\u5361\u6d1b\u6811\u641c\u7d22\u548c\u7ea6\u675f\u9057\u4f20\u7b97\u6cd5\u4f18\u5316\u5bf9\u6297\u6027\u63d0\u793a\u540e\u7f00\uff0c\u5728\u65e0\u9700\u767d\u76d2\u8bbf\u95ee\u7684\u60c5\u51b5\u4e0b\u5b9e\u73b0\u9ad8\u6548\u7684\u6587\u672c\u5230\u56fe\u50cf\u6a21\u578b\u653b\u51fb\u3002", "motivation": "\u6269\u6563\u6a21\u578b\u5728\u9762\u5bf9\u5bf9\u6297\u6027\u63d0\u793a\u65f6\u8868\u73b0\u51fa\u663e\u8457\u7684\u8106\u5f31\u6027\uff0c\u73b0\u6709\u65b9\u6cd5\u9700\u8981\u767d\u76d2\u8bbf\u95ee\u6a21\u578b\u68af\u5ea6\u6216\u624b\u52a8\u63d0\u793a\u5de5\u7a0b\uff0c\u5728\u73b0\u5b9e\u90e8\u7f72\u4e2d\u4e0d\u53ef\u884c\u6216\u6548\u679c\u4e0d\u4f73\u3002", "method": "\u7ed3\u5408\u8499\u7279\u5361\u6d1b\u6811\u641c\u7d22\u8fdb\u884c\u7ec6\u7c92\u5ea6\u540e\u7f00\u4f18\u5316\uff0c\u4f7f\u7528\u7ea6\u675f\u9057\u4f20\u7b97\u6cd5\u9884\u9009\u9ad8\u6f5c\u529b\u5bf9\u6297\u63d0\u793a\u4f5c\u4e3a\u6839\u8282\u70b9\uff0c\u5e76\u5728\u6bcf\u6b21\u6a21\u62df\u4e2d\u4fdd\u7559\u6700\u5177\u8bed\u4e49\u7834\u574f\u6027\u7684\u7ed3\u679c\u8fdb\u884c\u9ad8\u6548\u5c40\u90e8\u641c\u7d22\u3002", "result": "\u5728\u957f\u77ed\u4e0d\u540c\u8bed\u4e49\u7684\u63d0\u793a\u4e0a\u5b9e\u73b0\u4e86\u6700\u5148\u8fdb\u7684\u653b\u51fb\u6027\u80fd\uff0c\u53d1\u73b0SD\u6a21\u578b\u7684\u8106\u5f31\u6027\u6e90\u4e8e\u5176\u57fa\u4e8eCLIP\u7684\u6587\u672c\u7f16\u7801\u5668\u7684\u56fa\u6709\u6f0f\u6d1e\u3002", "conclusion": "\u5f53\u524d\u6587\u672c\u5230\u56fe\u50cf\u6d41\u6c34\u7ebf\u5b58\u5728\u6839\u672c\u6027\u5b89\u5168\u98ce\u9669\uff0cCLIP\u6587\u672c\u7f16\u7801\u5668\u7684\u56fa\u6709\u6f0f\u6d1e\u662f\u6269\u6563\u6a21\u578b\u8106\u5f31\u6027\u7684\u5173\u952e\u539f\u56e0\u3002"}}
{"id": "2511.21216", "categories": ["cs.CR"], "pdf": "https://arxiv.org/pdf/2511.21216", "abs": "https://arxiv.org/abs/2511.21216", "authors": ["Fangming Shi", "Li Li", "Kejiang Chen", "Guorui Feng", "Xinpeng Zhang"], "title": "AuthenLoRA: Entangling Stylization with Imperceptible Watermarks for Copyright-Secure LoRA Adapters", "comment": "16 pages, 7 figures, 12 tables", "summary": "Low-Rank Adaptation (LoRA) offers an efficient paradigm for customizing diffusion models, but its ease of redistribution raises concerns over unauthorized use and the generation of untraceable content. Existing watermarking techniques either target base models or verify LoRA modules themselves, yet they fail to propagate watermarks to generated images, leaving a critical gap in traceability. Moreover, traceability watermarking designed for base models is not tightly coupled with stylization and often introduces visual degradation or high false-positive detection rates. To address these limitations, we propose AuthenLoRA, a unified watermarking framework that embeds imperceptible, traceable watermarks directly into the LoRA training process while preserving stylization quality. AuthenLoRA employs a dual-objective optimization strategy that jointly learns the target style distribution and the watermark-induced distribution shift, ensuring that any image generated with the watermarked LoRA reliably carries the watermark. We further design an expanded LoRA architecture for enhanced multi-scale adaptation and introduce a zero-message regularization mechanism that substantially reduces false positives during watermark verification. Extensive experiments demonstrate that AuthenLoRA achieves high-fidelity stylization, robust watermark propagation, and significantly lower false-positive rates compared with existing approaches. Open-source implementation is available at: https://github.com/ShiFangming0823/AuthenLoRA", "AI": {"tldr": "AuthenLoRA\u662f\u4e00\u4e2a\u7edf\u4e00\u7684LoRA\u6c34\u5370\u6846\u67b6\uff0c\u901a\u8fc7\u5728LoRA\u8bad\u7ec3\u8fc7\u7a0b\u4e2d\u5d4c\u5165\u4e0d\u53ef\u611f\u77e5\u7684\u8ffd\u8e2a\u6c34\u5370\uff0c\u89e3\u51b3\u73b0\u6709\u65b9\u6cd5\u65e0\u6cd5\u5c06\u6c34\u5370\u4f20\u64ad\u5230\u751f\u6210\u56fe\u50cf\u7684\u95ee\u9898\u3002", "motivation": "\u73b0\u6709\u6c34\u5370\u6280\u672f\u8981\u4e48\u9488\u5bf9\u57fa\u7840\u6a21\u578b\uff0c\u8981\u4e48\u9a8c\u8bc1LoRA\u6a21\u5757\u672c\u8eab\uff0c\u4f46\u90fd\u65e0\u6cd5\u5c06\u6c34\u5370\u4f20\u64ad\u5230\u751f\u6210\u7684\u56fe\u50cf\u4e2d\uff0c\u5bfc\u81f4\u53ef\u8ffd\u6eaf\u6027\u5b58\u5728\u5173\u952e\u7f3a\u53e3\u3002", "method": "\u91c7\u7528\u53cc\u76ee\u6807\u4f18\u5316\u7b56\u7565\uff0c\u8054\u5408\u5b66\u4e60\u76ee\u6807\u98ce\u683c\u5206\u5e03\u548c\u6c34\u5370\u5f15\u8d77\u7684\u5206\u5e03\u504f\u79fb\uff1b\u8bbe\u8ba1\u6269\u5c55\u7684LoRA\u67b6\u6784\u4ee5\u589e\u5f3a\u591a\u5c3a\u5ea6\u9002\u5e94\uff1b\u5f15\u5165\u96f6\u6d88\u606f\u6b63\u5219\u5316\u673a\u5236\u964d\u4f4e\u8bef\u62a5\u7387\u3002", "result": "\u5b9e\u9a8c\u8868\u660eAuthenLoRA\u5b9e\u73b0\u4e86\u9ad8\u4fdd\u771f\u98ce\u683c\u5316\u3001\u9c81\u68d2\u7684\u6c34\u5370\u4f20\u64ad\uff0c\u4e0e\u73b0\u6709\u65b9\u6cd5\u76f8\u6bd4\u663e\u8457\u964d\u4f4e\u4e86\u8bef\u62a5\u7387\u3002", "conclusion": "AuthenLoRA\u4e3aLoRA\u6a21\u578b\u63d0\u4f9b\u4e86\u4e00\u79cd\u6709\u6548\u7684\u6c34\u5370\u89e3\u51b3\u65b9\u6848\uff0c\u80fd\u591f\u5728\u4fdd\u6301\u98ce\u683c\u5316\u8d28\u91cf\u7684\u540c\u65f6\u786e\u4fdd\u751f\u6210\u56fe\u50cf\u7684\u53ef\u8ffd\u6eaf\u6027\u3002"}}
{"id": "2511.21227", "categories": ["cs.CR"], "pdf": "https://arxiv.org/pdf/2511.21227", "abs": "https://arxiv.org/abs/2511.21227", "authors": ["Huiyu Li", "Nicholas Ayache", "Herv\u00e9 Delingette"], "title": "Data Exfiltration by Compression Attack: Definition and Evaluation on Medical Image Data", "comment": null, "summary": "With the rapid expansion of data lakes storing health data and hosting AI algorithms, a prominent concern arises: how safe is it to export machine learning models from these data lakes? In particular, deep network models, widely used for health data processing, encode information from their training dataset, potentially leading to the leakage of sensitive information upon its export. This paper thoroughly examines this issue in the context of medical imaging data and introduces a novel data exfiltration attack based on image compression techniques.\n  This attack, termed Data Exfiltration by Compression, requires only access to a data lake and is based on lossless or lossy image compression methods. Unlike previous data exfiltration attacks, it is compatible with any image processing task and depends solely on an exported network model without requiring any additional information to be collected during the training process. We explore various scenarios, and techniques to limit the size of the exported model and conceal the compression codes within the network.\n  Using two public datasets of CT and MR images, we demonstrate that this attack can effectively steal medical images and reconstruct them outside the data lake with high fidelity, achieving an optimal balance between compression and reconstruction quality. Additionally, we investigate the impact of basic differential privacy measures, such as adding Gaussian noise to the model parameters, to prevent the Data Exfiltration by Compression Attack. We also show how the attacker can make their attack resilient to differential privacy at the expense of decreasing the number of stolen images. Lastly, we propose an alternative prevention strategy by fine-tuning the model to be exported.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8e\u56fe\u50cf\u538b\u7f29\u6280\u672f\u7684\u6570\u636e\u6cc4\u9732\u653b\u51fb\u65b9\u6cd5\uff08Data Exfiltration by Compression\uff09\uff0c\u80fd\u591f\u5728\u4ec5\u8bbf\u95ee\u6570\u636e\u6e56\u7684\u60c5\u51b5\u4e0b\uff0c\u901a\u8fc7\u5bfc\u51fa\u7684\u6df1\u5ea6\u5b66\u4e60\u6a21\u578b\u7a83\u53d6\u533b\u7597\u56fe\u50cf\u6570\u636e\uff0c\u5e76\u7814\u7a76\u4e86\u5dee\u5206\u9690\u79c1\u548c\u6a21\u578b\u5fae\u8c03\u7b49\u9632\u5fa1\u63aa\u65bd\u3002", "motivation": "\u968f\u7740\u5b58\u50a8\u5065\u5eb7\u6570\u636e\u548cAI\u7b97\u6cd5\u7684\u6570\u636e\u6e56\u5feb\u901f\u6269\u5f20\uff0c\u4ece\u8fd9\u4e9b\u6570\u636e\u6e56\u5bfc\u51fa\u673a\u5668\u5b66\u4e60\u6a21\u578b\u7684\u5b89\u5168\u6027\u6210\u4e3a\u91cd\u8981\u95ee\u9898\u3002\u6df1\u5ea6\u7f51\u7edc\u6a21\u578b\u4f1a\u7f16\u7801\u8bad\u7ec3\u6570\u636e\u4fe1\u606f\uff0c\u53ef\u80fd\u5bfc\u81f4\u654f\u611f\u4fe1\u606f\u6cc4\u9732\u3002", "method": "\u63d0\u51fa\u57fa\u4e8e\u65e0\u635f\u6216\u6709\u635f\u56fe\u50cf\u538b\u7f29\u65b9\u6cd5\u7684\u6570\u636e\u6cc4\u9732\u653b\u51fb\uff0c\u4ec5\u9700\u8bbf\u95ee\u6570\u636e\u6e56\u548c\u5bfc\u51fa\u7684\u7f51\u7edc\u6a21\u578b\uff0c\u65e0\u9700\u8bad\u7ec3\u8fc7\u7a0b\u4e2d\u7684\u989d\u5916\u4fe1\u606f\u3002\u63a2\u7d22\u4e86\u9650\u5236\u6a21\u578b\u5927\u5c0f\u548c\u9690\u85cf\u538b\u7f29\u4ee3\u7801\u7684\u6280\u672f\u3002", "result": "\u5728CT\u548cMR\u56fe\u50cf\u516c\u5171\u6570\u636e\u96c6\u4e0a\u9a8c\u8bc1\uff0c\u8be5\u653b\u51fb\u80fd\u6709\u6548\u7a83\u53d6\u533b\u7597\u56fe\u50cf\u5e76\u5728\u6570\u636e\u6e56\u5916\u9ad8\u4fdd\u771f\u91cd\u5efa\uff0c\u5b9e\u73b0\u538b\u7f29\u4e0e\u91cd\u5efa\u8d28\u91cf\u7684\u6700\u4f73\u5e73\u8861\u3002\u5dee\u5206\u9690\u79c1\u63aa\u65bd\u53ef\u9632\u5fa1\u653b\u51fb\uff0c\u4f46\u653b\u51fb\u8005\u53ef\u901a\u8fc7\u51cf\u5c11\u7a83\u53d6\u56fe\u50cf\u6570\u91cf\u6765\u589e\u5f3a\u6297\u5e72\u6270\u80fd\u529b\u3002", "conclusion": "\u6570\u636e\u538b\u7f29\u6cc4\u9732\u653b\u51fb\u5bf9\u533b\u7597\u56fe\u50cf\u6570\u636e\u6784\u6210\u4e25\u91cd\u5a01\u80c1\uff0c\u9700\u8981\u91c7\u53d6\u5dee\u5206\u9690\u79c1\u6216\u6a21\u578b\u5fae\u8c03\u7b49\u9884\u9632\u7b56\u7565\u6765\u4fdd\u62a4\u654f\u611f\u533b\u7597\u6570\u636e\u7684\u5b89\u5168\u3002"}}
{"id": "2511.21291", "categories": ["cs.CR"], "pdf": "https://arxiv.org/pdf/2511.21291", "abs": "https://arxiv.org/abs/2511.21291", "authors": ["Tien Dat Hoang"], "title": "Illuminating the Black Box: Real-Time Monitoring of Backdoor Unlearning in CNNs via Explainable AI", "comment": "5 pages, 4 figures, IEEE conference format", "summary": "Backdoor attacks pose severe security threats to deep neural networks by embedding malicious triggers that force misclassification. While machine unlearning techniques can remove backdoor behaviors, current methods lack transparency and real-time interpretability. This paper introduces a novel framework that integrates Gradient-weighted Class Activation Mapping (Grad-CAM) into the unlearning process to provide real-time monitoring and explainability. We propose the Trigger Attention Ratio (TAR) metric to quantitatively measure the model's attention shift from trigger patterns to legitimate object features. Our balanced unlearning strategy combines gradient ascent on backdoor samples, Elastic Weight Consolidation (EWC) for catastrophic forgetting prevention, and a recovery phase for clean accuracy restoration. Experiments on CIFAR-10 with BadNets attacks demonstrate that our approach reduces Attack Success Rate (ASR) from 96.51% to 5.52% while retaining 99.48% of clean accuracy (82.06%), achieving a 94.28% ASR reduction. The integration of explainable AI enables transparent, observable, and verifiable backdoor removal.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u96c6\u6210Grad-CAM\u7684\u53ef\u89e3\u91ca\u6027\u540e\u95e8\u6d88\u9664\u6846\u67b6\uff0c\u901a\u8fc7TAR\u6307\u6807\u91cf\u5316\u6ce8\u610f\u529b\u8f6c\u79fb\uff0c\u7ed3\u5408\u68af\u5ea6\u4e0a\u5347\u3001EWC\u548c\u6062\u590d\u9636\u6bb5\uff0c\u5728CIFAR-10\u4e0a\u5b9e\u73b096.51%\u52305.52%\u7684ASR\u964d\u4f4e\uff0c\u540c\u65f6\u4fdd\u630199.48%\u7684\u5e72\u51c0\u51c6\u786e\u7387\u3002", "motivation": "\u5f53\u524d\u540e\u95e8\u6d88\u9664\u65b9\u6cd5\u7f3a\u4e4f\u900f\u660e\u5ea6\u548c\u5b9e\u65f6\u53ef\u89e3\u91ca\u6027\uff0c\u9700\u8981\u5f00\u53d1\u80fd\u591f\u5b9e\u65f6\u76d1\u63a7\u548c\u89e3\u91ca\u6d88\u9664\u8fc7\u7a0b\u7684\u6846\u67b6\u3002", "method": "\u96c6\u6210Grad-CAM\u63d0\u4f9b\u5b9e\u65f6\u76d1\u63a7\uff0c\u63d0\u51faTAR\u6307\u6807\u91cf\u5316\u6ce8\u610f\u529b\u8f6c\u79fb\uff0c\u91c7\u7528\u5e73\u8861\u6d88\u9664\u7b56\u7565\uff1a\u68af\u5ea6\u4e0a\u5347\u6d88\u9664\u540e\u95e8\u884c\u4e3a\u3001EWC\u9632\u6b62\u707e\u96be\u6027\u9057\u5fd8\u3001\u6062\u590d\u9636\u6bb5\u6062\u590d\u5e72\u51c0\u51c6\u786e\u7387\u3002", "result": "\u5728CIFAR-10\u6570\u636e\u96c6\u4e0a\uff0c\u653b\u51fb\u6210\u529f\u7387\u4ece96.51%\u964d\u81f35.52%\uff0cASR\u964d\u4f4e94.28%\uff0c\u540c\u65f6\u4fdd\u630199.48%\u7684\u5e72\u51c0\u51c6\u786e\u7387\uff0882.06%\uff09\u3002", "conclusion": "\u8be5\u6846\u67b6\u5b9e\u73b0\u4e86\u900f\u660e\u3001\u53ef\u89c2\u5bdf\u548c\u53ef\u9a8c\u8bc1\u7684\u540e\u95e8\u6d88\u9664\uff0c\u4e3a\u6df1\u5ea6\u795e\u7ecf\u7f51\u7edc\u5b89\u5168\u63d0\u4f9b\u4e86\u53ef\u89e3\u91ca\u7684\u89e3\u51b3\u65b9\u6848\u3002"}}
{"id": "2511.21301", "categories": ["cs.CR"], "pdf": "https://arxiv.org/pdf/2511.21301", "abs": "https://arxiv.org/abs/2511.21301", "authors": ["Leonardo Regano", "Daniele Canavese", "Cataldo Basile", "Marco Torchiano"], "title": "Empirical Assessment of the Code Comprehension Effort Needed to Attack Programs Protected with Obfuscation", "comment": null, "summary": "Evaluating the effectiveness of software protection is crucial for selecting the most effective methods to safeguard assets within software applications. Obfuscation involves techniques that deliberately modify software to make it more challenging to understand and reverse-engineer, while maintaining its original functionality. Although obfuscation is widely adopted, its effectiveness remains largely unexplored and unthoroughly evaluated. This paper presents a controlled experiment involving Master's students performing code comprehension tasks on applications hardened with obfuscation. The experiment's goals are to assess the effectiveness of obfuscation in delaying code comprehension by attackers and to determine whether complexity metrics can accurately predict the impact of these protections on success rates and durations of code comprehension tasks. The study is the first to evaluate the effect of layering multiple obfuscation techniques on a single piece of protected code. It also provides experimental evidence of the correlation between objective metrics of the attacked code and the likelihood of a successful attack, bridging the gap between objective and subjective approaches to estimating potency. Finally, the paper highlights significant aspects that warrant additional analysis and opens new avenues for further experiments.", "AI": {"tldr": "\u8be5\u8bba\u6587\u901a\u8fc7\u63a7\u5236\u5b9e\u9a8c\u8bc4\u4f30\u8f6f\u4ef6\u6df7\u6dc6\u6280\u672f\u7684\u6709\u6548\u6027\uff0c\u7814\u7a76\u6df7\u6dc6\u5982\u4f55\u5ef6\u8fdf\u4ee3\u7801\u7406\u89e3\u65f6\u95f4\uff0c\u5e76\u9a8c\u8bc1\u590d\u6742\u5ea6\u6307\u6807\u80fd\u5426\u9884\u6d4b\u6df7\u6dc6\u6548\u679c\u3002", "motivation": "\u8f6f\u4ef6\u6df7\u6dc6\u6280\u672f\u88ab\u5e7f\u6cdb\u91c7\u7528\uff0c\u4f46\u5176\u5b9e\u9645\u6709\u6548\u6027\u7f3a\u4e4f\u7cfb\u7edf\u8bc4\u4f30\u3002\u9700\u8981\u7814\u7a76\u6df7\u6dc6\u6280\u672f\u662f\u5426\u80fd\u6709\u6548\u5ef6\u8fdf\u653b\u51fb\u8005\u7684\u4ee3\u7801\u7406\u89e3\uff0c\u4ee5\u53ca\u5ba2\u89c2\u6307\u6807\u80fd\u5426\u51c6\u786e\u9884\u6d4b\u6df7\u6dc6\u6548\u679c\u3002", "method": "\u4f7f\u7528\u63a7\u5236\u5b9e\u9a8c\u65b9\u6cd5\uff0c\u8ba9\u7855\u58eb\u751f\u5bf9\u7ecf\u8fc7\u6df7\u6dc6\u5904\u7406\u7684\u5e94\u7528\u7a0b\u5e8f\u6267\u884c\u4ee3\u7801\u7406\u89e3\u4efb\u52a1\uff0c\u8bc4\u4f30\u5355\u5c42\u548c\u591a\u5c42\u6df7\u6dc6\u6280\u672f\u7684\u6548\u679c\uff0c\u5e76\u5206\u6790\u590d\u6742\u5ea6\u6307\u6807\u4e0e\u653b\u51fb\u6210\u529f\u7387\u7684\u5173\u8054\u3002", "result": "\u5b9e\u9a8c\u9996\u6b21\u8bc4\u4f30\u4e86\u591a\u5c42\u6df7\u6dc6\u6280\u672f\u7684\u53e0\u52a0\u6548\u679c\uff0c\u63d0\u4f9b\u4e86\u5ba2\u89c2\u6307\u6807\u4e0e\u653b\u51fb\u6210\u529f\u7387\u76f8\u5173\u6027\u7684\u5b9e\u9a8c\u8bc1\u636e\uff0c\u586b\u8865\u4e86\u5ba2\u89c2\u548c\u4e3b\u89c2\u8bc4\u4f30\u65b9\u6cd5\u4e4b\u95f4\u7684\u7a7a\u767d\u3002", "conclusion": "\u6df7\u6dc6\u6280\u672f\u80fd\u6709\u6548\u5ef6\u8fdf\u4ee3\u7801\u7406\u89e3\uff0c\u590d\u6742\u5ea6\u6307\u6807\u53ef\u4ee5\u9884\u6d4b\u6df7\u6dc6\u6548\u679c\uff0c\u7814\u7a76\u4e3a\u8f6f\u4ef6\u4fdd\u62a4\u6548\u679c\u8bc4\u4f30\u5f00\u8f9f\u4e86\u65b0\u9014\u5f84\uff0c\u6307\u51fa\u4e86\u9700\u8981\u8fdb\u4e00\u6b65\u5206\u6790\u7684\u91cd\u8981\u65b9\u9762\u3002"}}
{"id": "2511.21448", "categories": ["cs.CR", "cs.AI", "cs.DB"], "pdf": "https://arxiv.org/pdf/2511.21448", "abs": "https://arxiv.org/abs/2511.21448", "authors": ["Rebeka Toth", "Tamas Bisztray", "Richard Dubniczky"], "title": "Constructing and Benchmarking: a Labeled Email Dataset for Text-Based Phishing and Spam Detection Framework", "comment": null, "summary": "Phishing and spam emails remain a major cybersecurity threat, with attackers increasingly leveraging Large Language Models (LLMs) to craft highly deceptive content. This study presents a comprehensive email dataset containing phishing, spam, and legitimate messages, explicitly distinguishing between human- and LLM-generated content. Each email is annotated with its category, emotional appeal (e.g., urgency, fear, authority), and underlying motivation (e.g., link-following, credential theft, financial fraud). We benchmark multiple LLMs on their ability to identify these emotional and motivational cues and select the most reliable model to annotate the full dataset. To evaluate classification robustness, emails were also rephrased using several LLMs while preserving meaning and intent. A state-of-the-art LLM was then assessed on its performance across both original and rephrased emails using expert-labeled ground truth. The results highlight strong phishing detection capabilities but reveal persistent challenges in distinguishing spam from legitimate emails. Our dataset and evaluation framework contribute to improving AI-assisted email security systems. To support open science, all code, templates, and resources are available on our project site.", "AI": {"tldr": "\u8be5\u7814\u7a76\u521b\u5efa\u4e86\u4e00\u4e2a\u5305\u542b\u7f51\u7edc\u9493\u9c7c\u3001\u5783\u573e\u90ae\u4ef6\u548c\u5408\u6cd5\u90ae\u4ef6\u7684\u7efc\u5408\u6570\u636e\u96c6\uff0c\u660e\u786e\u533a\u5206\u4e86\u4eba\u7c7b\u548cLLM\u751f\u6210\u7684\u5185\u5bb9\uff0c\u5e76\u6807\u6ce8\u4e86\u60c5\u611f\u8bc9\u6c42\u548c\u52a8\u673a\u3002\u901a\u8fc7\u57fa\u51c6\u6d4b\u8bd5\u8bc4\u4f30LLM\u8bc6\u522b\u8fd9\u4e9b\u7ebf\u7d22\u7684\u80fd\u529b\uff0c\u5e76\u6d4b\u8bd5\u4e86\u91cd\u8ff0\u90ae\u4ef6\u5bf9\u5206\u7c7b\u6027\u80fd\u7684\u5f71\u54cd\u3002", "motivation": "\u7f51\u7edc\u9493\u9c7c\u548c\u5783\u573e\u90ae\u4ef6\u4ecd\u7136\u662f\u4e3b\u8981\u7684\u7f51\u7edc\u5b89\u5168\u5a01\u80c1\uff0c\u653b\u51fb\u8005\u8d8a\u6765\u8d8a\u591a\u5730\u5229\u7528LLM\u5236\u4f5c\u9ad8\u5ea6\u6b3a\u9a97\u6027\u7684\u5185\u5bb9\uff0c\u9700\u8981\u6539\u8fdbAI\u8f85\u52a9\u7684\u90ae\u4ef6\u5b89\u5168\u7cfb\u7edf\u3002", "method": "\u521b\u5efa\u7efc\u5408\u90ae\u4ef6\u6570\u636e\u96c6\uff0c\u6807\u6ce8\u90ae\u4ef6\u7c7b\u522b\u3001\u60c5\u611f\u8bc9\u6c42\u548c\u52a8\u673a\uff1b\u57fa\u51c6\u6d4b\u8bd5\u591a\u4e2aLLM\u8bc6\u522b\u60c5\u611f\u548c\u52a8\u673a\u7ebf\u7d22\u7684\u80fd\u529b\uff1b\u4f7f\u7528LLM\u91cd\u8ff0\u90ae\u4ef6\u4fdd\u6301\u610f\u4e49\u548c\u610f\u56fe\u4e0d\u53d8\uff1b\u8bc4\u4f30\u6700\u5148\u8fdbLLM\u5728\u539f\u59cb\u548c\u91cd\u8ff0\u90ae\u4ef6\u4e0a\u7684\u5206\u7c7b\u6027\u80fd\u3002", "result": "LLM\u5728\u68c0\u6d4b\u7f51\u7edc\u9493\u9c7c\u65b9\u9762\u8868\u73b0\u51fa\u5f3a\u5927\u80fd\u529b\uff0c\u4f46\u5728\u533a\u5206\u5783\u573e\u90ae\u4ef6\u548c\u5408\u6cd5\u90ae\u4ef6\u65b9\u9762\u4ecd\u5b58\u5728\u6301\u7eed\u6311\u6218\u3002", "conclusion": "\u8be5\u6570\u636e\u96c6\u548c\u8bc4\u4f30\u6846\u67b6\u6709\u52a9\u4e8e\u6539\u8fdbAI\u8f85\u52a9\u7684\u90ae\u4ef6\u5b89\u5168\u7cfb\u7edf\uff0c\u6240\u6709\u4ee3\u7801\u3001\u6a21\u677f\u548c\u8d44\u6e90\u90fd\u5df2\u516c\u5f00\u4ee5\u652f\u6301\u5f00\u653e\u79d1\u5b66\u3002"}}
{"id": "2511.21552", "categories": ["cs.CR", "cs.DC"], "pdf": "https://arxiv.org/pdf/2511.21552", "abs": "https://arxiv.org/abs/2511.21552", "authors": ["Roi Bar-Zur", "Aviv Tamar", "Ittay Eyal"], "title": "MAD-DAG: Protecting Blockchain Consensus from MEV", "comment": null, "summary": "Blockchain security is threatened by selfish mining, where a miner (operator) deviates from the protocol to increase their revenue. Selfish mining is exacerbated by adverse conditions: rushing (network propagation advantage for the selfish miner), varying block rewards due to block contents, called miner extractable value (MEV), and petty-compliant miners who accept bribes from the selfish miner.\n  The state-of-the-art selfish-mining-resistant blockchain protocol, Colordag, does not treat these adverse conditions and was proven secure only when its latency is impractically high.\n  We present MAD-DAG, Mutually-Assured-Destruction Directed-Acyclic-Graph, the first practical protocol to counter selfish mining under adverse conditions. MAD-DAG achieves this thanks to its novel ledger function, which discards the contents of equal-length chains competing to be the longest.\n  We analyze selfish mining in both Colordag and MAD-DAG by modeling a rational miner using a Markov Decision Process (MDP). We obtain a tractable model for both by developing conservative reward rules that favor the selfish miner to yield an upper bound on selfish mining revenue. To the best of our knowledge, this is the first tractable model of selfish mining in a practical DAG-based blockchain. This enables us to obtain a lower bound on the security threshold, the minimum fraction of computational power a miner needs in order to profit from selfish mining.\n  MAD-DAG withstands adverse conditions under which Colordag and Bitcoin fail, while otherwise maintaining comparable security. For example, with petty-compliant miners and high levels of block reward variability, MAD-DAG's security threshold ranges from 11% to 31%, whereas both Colordag and Bitcoin achieve 0% for all levels.", "AI": {"tldr": "MAD-DAG\u662f\u4e00\u79cd\u5b9e\u7528\u7684DAG\u533a\u5757\u94fe\u534f\u8bae\uff0c\u80fd\u591f\u62b5\u5fa1\u81ea\u79c1\u6316\u77ff\u653b\u51fb\uff0c\u7279\u522b\u662f\u5728\u5b58\u5728\u7f51\u7edc\u4f20\u64ad\u4f18\u52bf\u3001MEV\u548c\u8d3f\u8d42\u7b49\u4e0d\u5229\u6761\u4ef6\u4e0b\u3002", "motivation": "\u73b0\u6709\u6700\u5148\u8fdb\u7684\u6297\u81ea\u79c1\u6316\u77ff\u534f\u8baeColordag\u65e0\u6cd5\u5904\u7406\u7f51\u7edc\u4f20\u64ad\u4f18\u52bf\u3001MEV\u548c\u8d3f\u8d42\u7b49\u4e0d\u5229\u6761\u4ef6\uff0c\u4e14\u4ec5\u5728\u4e0d\u53ef\u5b9e\u9645\u7684\u9ad8\u5ef6\u8fdf\u4e0b\u88ab\u8bc1\u660e\u5b89\u5168\u3002", "method": "\u63d0\u51faMAD-DAG\u534f\u8bae\uff0c\u91c7\u7528\u65b0\u578b\u8d26\u672c\u51fd\u6570\uff0c\u4e22\u5f03\u7ade\u4e89\u6700\u957f\u94fe\u7684\u7b49\u957f\u94fe\u5185\u5bb9\u3002\u901a\u8fc7\u9a6c\u5c14\u53ef\u592b\u51b3\u7b56\u8fc7\u7a0b\u5efa\u6a21\u7406\u6027\u77ff\u5de5\u884c\u4e3a\uff0c\u5f00\u53d1\u4fdd\u5b88\u5956\u52b1\u89c4\u5219\u6765\u83b7\u5f97\u81ea\u79c1\u6316\u77ff\u6536\u76ca\u4e0a\u754c\u3002", "result": "MAD-DAG\u5728\u5b58\u5728\u8d3f\u8d42\u77ff\u5de5\u548c\u9ad8MEV\u6c34\u5e73\u65f6\uff0c\u5b89\u5168\u9608\u503c\u8303\u56f4\u4e3a11%\u81f331%\uff0c\u800cColordag\u548c\u6bd4\u7279\u5e01\u7684\u5b89\u5168\u9608\u503c\u5747\u4e3a0%\u3002", "conclusion": "MAD-DAG\u662f\u7b2c\u4e00\u4e2a\u5728\u4e0d\u5229\u6761\u4ef6\u4e0b\u5b9e\u7528\u7684\u6297\u81ea\u79c1\u6316\u77ff\u534f\u8bae\uff0c\u5728\u4fdd\u6301\u53ef\u6bd4\u5b89\u5168\u6027\u7684\u540c\u65f6\uff0c\u80fd\u591f\u62b5\u5fa1Colordag\u548c\u6bd4\u7279\u5e01\u5931\u8d25\u7684\u60c5\u51b5\u3002"}}
{"id": "2511.21600", "categories": ["cs.CR", "cs.LG"], "pdf": "https://arxiv.org/pdf/2511.21600", "abs": "https://arxiv.org/abs/2511.21600", "authors": ["Yizhou Zhao", "Xiang Li", "Peter Song", "Qi Long", "Weijie Su"], "title": "TAB-DRW: A DFT-based Robust Watermark for Generative Tabular Data", "comment": null, "summary": "The rise of generative AI has enabled the production of high-fidelity synthetic tabular data across fields such as healthcare, finance, and public policy, raising growing concerns about data provenance and misuse. Watermarking offers a promising solution to address these concerns by ensuring the traceability of synthetic data, but existing methods face many limitations: they are computationally expensive due to reliance on large diffusion models, struggle with mixed discrete-continuous data, or lack robustness to post-modifications. To address them, we propose TAB-DRW, an efficient and robust post-editing watermarking scheme for generative tabular data. TAB-DRW embeds watermark signals in the frequency domain: it normalizes heterogeneous features via the Yeo-Johnson transformation and standardization, applies the discrete Fourier transform (DFT), and adjusts the imaginary parts of adaptively selected entries according to precomputed pseudorandom bits. To further enhance robustness and efficiency, we introduce a novel rank-based pseudorandom bit generation method that enables row-wise retrieval without incurring storage overhead. Experiments on five benchmark tabular datasets show that TAB-DRW achieves strong detectability and robustness against common post-processing attacks, while preserving high data fidelity and fully supporting mixed-type features.", "AI": {"tldr": "\u63d0\u51faTAB-DRW\uff0c\u4e00\u79cd\u9ad8\u6548\u9c81\u68d2\u7684\u540e\u7f16\u8f91\u6c34\u5370\u65b9\u6848\uff0c\u7528\u4e8e\u751f\u6210\u8868\u683c\u6570\u636e\uff0c\u901a\u8fc7\u5728\u9891\u57df\u5d4c\u5165\u6c34\u5370\u4fe1\u53f7\u6765\u786e\u4fdd\u5408\u6210\u6570\u636e\u7684\u53ef\u8ffd\u6eaf\u6027\u3002", "motivation": "\u751f\u6210AI\u4ea7\u751f\u7684\u9ad8\u4fdd\u771f\u5408\u6210\u8868\u683c\u6570\u636e\u5f15\u53d1\u4e86\u6570\u636e\u6765\u6e90\u548c\u6ee5\u7528\u7684\u62c5\u5fe7\uff0c\u73b0\u6709\u6c34\u5370\u65b9\u6cd5\u5b58\u5728\u8ba1\u7b97\u6210\u672c\u9ad8\u3001\u5904\u7406\u6df7\u5408\u6570\u636e\u7c7b\u578b\u56f0\u96be\u3001\u9c81\u68d2\u6027\u4e0d\u8db3\u7b49\u95ee\u9898\u3002", "method": "\u901a\u8fc7Yeo-Johnson\u53d8\u6362\u548c\u6807\u51c6\u5316\u5f52\u4e00\u5316\u5f02\u6784\u7279\u5f81\uff0c\u5e94\u7528\u79bb\u6563\u5085\u91cc\u53f6\u53d8\u6362\uff0c\u6839\u636e\u9884\u8ba1\u7b97\u7684\u4f2a\u968f\u673a\u4f4d\u8c03\u6574\u81ea\u9002\u5e94\u9009\u62e9\u6761\u76ee\u7684\u865a\u90e8\uff0c\u5e76\u5f15\u5165\u57fa\u4e8e\u6392\u540d\u7684\u4f2a\u968f\u673a\u4f4d\u751f\u6210\u65b9\u6cd5\u3002", "result": "\u5728\u4e94\u4e2a\u57fa\u51c6\u8868\u683c\u6570\u636e\u96c6\u4e0a\u7684\u5b9e\u9a8c\u8868\u660e\uff0cTAB-DRW\u5b9e\u73b0\u4e86\u5f3a\u53ef\u68c0\u6d4b\u6027\u548c\u5bf9\u5e38\u89c1\u540e\u5904\u7406\u653b\u51fb\u7684\u9c81\u68d2\u6027\uff0c\u540c\u65f6\u4fdd\u6301\u9ad8\u6570\u636e\u4fdd\u771f\u5ea6\u5e76\u5b8c\u5168\u652f\u6301\u6df7\u5408\u7c7b\u578b\u7279\u5f81\u3002", "conclusion": "TAB-DRW\u4e3a\u751f\u6210\u8868\u683c\u6570\u636e\u63d0\u4f9b\u4e86\u4e00\u79cd\u9ad8\u6548\u3001\u9c81\u68d2\u7684\u6c34\u5370\u89e3\u51b3\u65b9\u6848\uff0c\u89e3\u51b3\u4e86\u73b0\u6709\u65b9\u6cd5\u7684\u5c40\u9650\u6027\u3002"}}
