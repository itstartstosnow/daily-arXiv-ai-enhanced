<div id=toc></div>

# Table of Contents

- [cs.CR](#cs.CR) [Total: 46]


<div id='cs.CR'></div>

# cs.CR [[Back]](#toc)

### [1] [Comparison of Multiple Classifiers for Android Malware Detection with Emphasis on Feature Insights Using CICMalDroid 2020 Dataset](https://arxiv.org/abs/2602.00058)
*Md Min-Ha-Zul Abedin,Tazqia Mehrub*

Main category: cs.CR

TL;DR: 该研究构建了一个可信赖的Android恶意软件检测器，使用混合特征和梯度提升算法，在CICMalDroid2020数据集上实现了97.47%的准确率，并识别了可解释的决策驱动因素。


<details>
  <summary>Details</summary>
Motivation: 传统的签名扫描器无法跟上公共应用商店的快速发布周期，需要构建一个可信赖的恶意软件检测器，通过全面数据集和严格透明的评估，同时识别可解释的决策驱动因素。

Method: 使用CICMalDroid2020数据集（17,341个应用），提取301个静态特征和263个动态特征形成564维混合向量，在三种特征方案（原始特征、PCA、LDA）下评估七种分类器，采用70%训练和30%测试划分。

Result: XGBoost在原始特征上表现最佳：准确率0.9747，精确率0.9703，召回率0.9731，F1分数0.9716。PCA会降低所有模型性能，LDA保持中高90%准确率并显示可分离聚类。深度为2的代理树识别出包名、主活动和目标SDK为关键决策驱动因素。

Conclusion: 研究为Android恶意软件检测建立了高保真度的监督基线，表明丰富的混合特征结合梯度提升算法为实际部署提供了实用且可解释的基础。

Abstract: Accurate Android malware detection was critical for protecting users at scale. Signature scanners lagged behind fast release cycles on public app stores. We aimed to build a trustworthy detector by pairing a comprehensive dataset with a rigorous, transparent evaluation, and to identify interpretable drivers of decisions. We used CICMalDroid2020, which contained 17,341 apps across Benign, Adware, Banking, SMS malware, and Riskware. We extracted 301 static and 263 dynamic features into a 564 dimensional hybrid vector, then evaluated seven classifiers under three schemes, original features, principal component analysis, PCA, and linear discriminant analysis, LDA, with a 70 percent training and 30 percent test split. Results showed that gradient boosting on the original features performed best. XGBoost achieved 0.9747 accuracy, 0.9703 precision, 0.9731 recall, and 0.9716 F1, and the confusion matrix indicated rare benign labels for malicious apps. HistGradientBoosting reached 0.9741 accuracy and 0.9708 F1, while CatBoost and Random Forest were slightly lower at 0.9678 and 0.9687 accuracy with 0.9636 and 0.9637 F1. KNN and SVM lagged. PCA reduced performance for all models, with XGBoost dropping to 0.9164 accuracy and 0.8988 F1. LDA maintained mid 90s accuracy and clarified separable clusters in projections. A depth two surrogate tree highlighted package name, main activity, and target SDK as key drivers. These findings established high fidelity supervised baselines for Android malware detection and indicated that rich hybrid features with gradient boosting offered a practical and interpretable foundation for deployment.

</details>


### [2] [ReasoningBomb: A Stealthy Denial-of-Service Attack by Inducing Pathologically Long Reasoning in Large Reasoning Models](https://arxiv.org/abs/2602.00154)
*Xiaogeng Liu,Xinyan Wang,Yechao Zhang,Sanjay Kariyappa,Chong Xiang,Muhao Chen,G. Edward Suh,Chaowei Xiao*

Main category: cs.CR

TL;DR: 论文提出ReasoningBomb攻击框架，利用强化学习生成短自然提示，诱导大型推理模型产生超长推理链，造成推理时拒绝服务攻击。


<details>
  <summary>Details</summary>
Motivation: 大型推理模型的多步推理能力引入了新的推理时拒绝服务攻击风险，现有研究对此关注不足，需要系统化分析这类攻击的特性并开发有效攻击方法。

Method: 提出ReasoningBomb框架：1）形式化推理成本定义；2）定义PI-DoS攻击需满足的三个属性（高放大比、隐蔽性、可优化性）；3）使用强化学习训练攻击模型，通过恒定时间代理奖励指导生成短自然提示。

Result: 在7个开源模型和3个商业LRM上测试，平均诱导18,759个完成token和19,263个推理token，比基线提升35-38%，输入输出放大比达286.7倍，检测绕过率超过98%。

Conclusion: ReasoningBomb成功证明了PI-DoS攻击的可行性，揭示了大型推理模型的安全脆弱性，为防御机制设计提供了重要参考。

Abstract: Large reasoning models (LRMs) extend large language models with explicit multi-step reasoning traces, but this capability introduces a new class of prompt-induced inference-time denial-of-service (PI-DoS) attacks that exploit the high computational cost of reasoning. We first formalize inference cost for LRMs and define PI-DoS, then prove that any practical PI-DoS attack should satisfy three properties: (1) a high amplification ratio, where each query induces a disproportionately long reasoning trace relative to its own length; (ii) stealthiness, in which prompts and responses remain on the natural language manifold and evade distribution shift detectors; and (iii) optimizability, in which the attack supports efficient optimization without being slowed by its own success. Under this framework, we present ReasoningBomb, a reinforcement-learning-based PI-DoS framework that is guided by a constant-time surrogate reward and trains a large reasoning-model attacker to generate short natural prompts that drive victim LRMs into pathologically long and often effectively non-terminating reasoning. Across seven open-source models (including LLMs and LRMs) and three commercial LRMs, ReasoningBomb induces 18,759 completion tokens on average and 19,263 reasoning tokens on average across reasoning models. It outperforms the the runner-up baseline by 35% in completion tokens and 38% in reasoning tokens, while inducing 6-7x more tokens than benign queries and achieving 286.7x input-to-output amplification ratio averaged across all samples. Additionally, our method achieves 99.8% bypass rate on input-based detection, 98.7% on output-based detection, and 98.4% against strict dual-stage joint detection.

</details>


### [3] [First Steps, Lasting Impact: Platform-Aware Forensics for the Next Generation of Analysts](https://arxiv.org/abs/2602.00160)
*Vinayak Jain,Sneha Sudhakaran,Saranyan Senthivel*

Main category: cs.CR

TL;DR: 该研究系统评估了Windows和Linux系统上的磁盘和内存取证采集技术，识别了针对不同操作系统的有效取证工具组合，旨在提高证据采集的准确性和可靠性。


<details>
  <summary>Details</summary>
Motivation: 网络取证证据采集的可靠性受底层操作系统（Windows、macOS、Linux）的显著影响，不同系统在文件系统结构、加密协议和取证工具兼容性方面存在固有差异。传统磁盘取证在面对反取证策略（如加密和压缩）时可能不足，需要内存取证作为补充。当前取证工具在保证取证输入可靠性和足迹完整性方面存在持续差距。

Method: 研究系统评估了Windows和Linux系统上的磁盘和内存取证采集技术。通过分析不同操作系统的样本，识别了针对每个平台的有效取证工具组合和配置。评估了现有取证工具，包括Windows上的FTK Imager、Autopsy/Sleuth Kit，Linux上的LiME、快照工具和dd等内存采集工具。

Result: 研究发现：1）Windows系统（主要使用NTFS和FAT文件系统）通过FTK Imager等工具支持可靠的磁盘映像和分析，但加密功能常给证据采集带来挑战；2）Linux系统（使用ext4和XFS等文件系统）透明度更高，但日志保留的临时性常使取证分析复杂化；3）内存取证在传统磁盘取证不足时至关重要，Volatility等框架在Windows和Linux上表现稳健，但Linux实时内存采集仍存在挑战。

Conclusion: 该研究通过识别针对不同操作系统的有效取证工具组合和配置，提高了证据采集的准确性和可靠性。研究强调了持续存在的差距：如何一致地保证取证输入可靠性和足迹完整性，这为未来取证工具开发和研究提供了重要方向。

Abstract: The reliability of cyber forensic evidence acquisition is strongly influenced by the underlying operating systems, Windows, macOS, and Linux - due to inherent variations in file system structures, encryption protocols, and forensic tool compatibility. Disk forensics, one of the most widely used techniques in digital investigations, faces distinct obstacles on each platform. Windows, with its predominantly NTFS and FAT file systems, typically supports reliable disk imaging and analysis through established tools such as FTK Imager and Autopsy/Sleuth Kit. However, encryption features frequently pose challenges to evidence acquisition. Conversely, Linux environments, which rely on file systems like ext4 and XFS, generally offer greater transparency, yet the transient nature of log retention often complicates forensic analysis. In instances where anti-forensic strategies such as encryption and compression render traditional disk forensics insufficient, memory forensics becomes crucial. While memory forensic methodologies demonstrate robustness across Windows and Linux platforms forms through frameworks like Volatility, platform-specific difficulties persist. Memory analysis on Linux systems benefits from tools like LiME, snapshot utilities, and dd for memory acquisition; nevertheless, live memory acquisition on Linux can still present challenges. This research systematically assesses both disk and memory forensic acquisition techniques across samples representing Windows and Linux systems. By identifying effective combinations of forensic tools and configurations tailored to each operating system, the study aims to improve the accuracy and reliability of evidence collection. It further evaluates current forensic tools and highlights a persistent gap: consistently assuring forensic input reliability and footprint integrity.

</details>


### [4] [EigenAI: Deterministic Inference, Verifiable Results](https://arxiv.org/abs/2602.00182)
*David Ribeiro Alves,Vishnu Patankar,Matheus Pereira,Jamie Stephens,Nima Vaziri,Sreeram Kannan*

Main category: cs.CR

TL;DR: EigenAI是一个基于EigenLayer再质押生态系统的可验证AI平台，通过确定性LLM推理引擎和加密经济安全的乐观重执行协议，使每个推理结果都能被公开审计、复现和经济强制执行。


<details>
  <summary>Details</summary>
Motivation: 构建能够在保持高性能的同时实现可验证性的AI系统，使AI推理结果能够被公开审计和验证，从而支持需要可信AI的应用程序，如预测市场裁判、交易机器人和科学助手等。

Method: 结合确定性大型语言模型推理引擎和加密经济安全的乐观重执行协议。不可信操作者在固定GPU架构上运行推理，将加密的请求和响应日志发布到EigenDA。在挑战窗口内，任何观察者都可以通过EigenVerify请求重执行，结果在可信执行环境(TEE)中确定性地重新计算，使用阈值释放的解密密钥，实现私有数据的公开挑战。

Result: 由于推理本身是比特精确的，验证简化为字节相等性检查，单个诚实副本就足以检测欺诈。该架构产生了主权代理（预测市场裁判、交易机器人、科学助手），在享受最先进性能的同时继承了以太坊验证者基础的安全性。

Conclusion: EigenAI通过将确定性LLM推理与加密经济安全协议相结合，创建了一个可验证的AI平台，使AI推理结果能够被公开审计和强制执行，为需要可信AI的各种应用程序提供了安全基础。

Abstract: EigenAI is a verifiable AI platform built on top of the EigenLayer restaking ecosystem. At a high level, it combines a deterministic large-language model (LLM) inference engine with a cryptoeconomically secured optimistic re-execution protocol so that every inference result can be publicly audited, reproduced, and, if necessary, economically enforced. An untrusted operator runs inference on a fixed GPU architecture, signs and encrypts the request and response, and publishes the encrypted log to EigenDA. During a challenge window, any watcher may request re-execution through EigenVerify; the result is then deterministically recomputed inside a trusted execution environment (TEE) with a threshold-released decryption key, allowing a public challenge with private data. Because inference itself is bit-exact, verification reduces to a byte-equality check, and a single honest replica suffices to detect fraud. We show how this architecture yields sovereign agents -- prediction-market judges, trading bots, and scientific assistants -- that enjoy state-of-the-art performance while inheriting security from Ethereum's validator base.

</details>


### [5] [RPP: A Certified Poisoned-Sample Detection Framework for Backdoor Attacks under Dataset Imbalance](https://arxiv.org/abs/2602.00183)
*Miao Lin,Feng Yu,Rui Ning,Lusi Li,Jiawei Chen,Qian Lou,Mengxin Zheng,Chunsheng Xin,Hongyi Wu*

Main category: cs.CR

TL;DR: 该论文首次深入研究了数据集不平衡如何加剧后门漏洞，并提出了一种在黑盒设置下使用随机概率扰动（RPP）的认证后门样本检测框架，在数据不平衡情况下显著优于现有防御方法。


<details>
  <summary>Details</summary>
Motivation: 深度神经网络极易受后门攻击，但现有防御方法大多依赖平衡数据，忽略了现实世界中普遍存在的类别不平衡问题，这种不平衡会加剧后门威胁。需要研究不平衡数据如何影响后门漏洞，并开发适用于实际不平衡环境的防御方法。

Method: 提出随机概率扰动（RPP）框架，这是一种认证的后门样本检测方法，仅使用模型输出概率在黑盒设置下工作。RPP通过扰动输入并分析模型概率变化来确定样本是否被后门操纵，提供可证明的域内检测保证和假阳性率的概率上界。

Result: 在五个基准数据集（MNIST、SVHN、CIFAR-10、TinyImageNet和ImageNet10）上，针对10种后门攻击和12种基线防御的广泛实验表明，RPP实现了比最先进防御方法显著更高的检测准确率，特别是在数据集不平衡的情况下。

Conclusion: RPP为在现实世界不平衡数据环境中防御后门攻击建立了理论和实践基础，首次系统揭示了数据集不平衡如何加剧后门漏洞，并提供了有效的黑盒检测解决方案。

Abstract: Deep neural networks are highly susceptible to backdoor attacks, yet most defense methods to date rely on balanced data, overlooking the pervasive class imbalance in real-world scenarios that can amplify backdoor threats. This paper presents the first in-depth investigation of how the dataset imbalance amplifies backdoor vulnerability, showing that (i) the imbalance induces a majority-class bias that increases susceptibility and (ii) conventional defenses degrade significantly as the imbalance grows. To address this, we propose Randomized Probability Perturbation (RPP), a certified poisoned-sample detection framework that operates in a black-box setting using only model output probabilities. For any inspected sample, RPP determines whether the input has been backdoor-manipulated, while offering provable within-domain detectability guarantees and a probabilistic upper bound on the false positive rate. Extensive experiments on five benchmarks (MNIST, SVHN, CIFAR-10, TinyImageNet and ImageNet10) covering 10 backdoor attacks and 12 baseline defenses show that RPP achieves significantly higher detection accuracy than state-of-the-art defenses, particularly under dataset imbalance. RPP establishes a theoretical and practical foundation for defending against backdoor attacks in real-world environments with imbalanced data.

</details>


### [6] [Semantic-Aware Advanced Persistent Threat Detection Using Autoencoders on LLM-Encoded System Logs](https://arxiv.org/abs/2602.00204)
*Waleed Khan Mohammed,Zahirul Arief Irfan Bin Shahrul Anuar,Mousa Sufian Mousa Mitani,Hezerul Abdul Karim,Nouar AlDahoul*

Main category: cs.CR

TL;DR: 提出一种利用大语言模型生成语义嵌入来检测高级持续性威胁的新方法，通过自编码器分析日志语义特征，在DARPA数据集上优于传统无监督基线方法。


<details>
  <summary>Details</summary>
Motivation: 传统统计方法和浅层机器学习技术难以检测APT攻击的"低而慢"行为，现有溯源图分析方法无法捕捉系统活动的语义意图，需要新的检测方法。

Method: 使用预训练transformer模型将原始系统日志转换为高维语义嵌入，然后通过自编码器分析这些嵌入来识别异常和潜在恶意模式。

Result: 在DARPA透明计算数据集上评估，基于LLM嵌入的自编码器在AUC-ROC指标上优于孤立森林、单类支持向量机和主成分分析等基线方法。

Conclusion: 语义理解对于检测传统技术常遗漏的非线性和隐蔽攻击行为至关重要，LLM生成的语义嵌入能有效增强APT检测能力。

Abstract: Advanced Persistent Threats (APTs) are among the most challenging cyberattacks to detect. They are carried out by highly skilled attackers who carefully study their targets and operate in a stealthy, long-term manner. Because APTs exhibit "low-and-slow" behavior, traditional statistical methods and shallow machine learning techniques often fail to detect them. Previous research on APT detection has explored machine learning approaches and provenance graph analysis. However, provenance-based methods often fail to capture the semantic intent behind system activities. This paper proposes a novel anomaly detection approach that leverages semantic embeddings generated by Large Language Models (LLMs). The method enhances APT detection by extracting meaningful semantic representations from unstructured system log data. First, raw system logs are transformed into high-dimensional semantic embeddings using a pre-trained transformer model. These embeddings are then analyzed using an Autoencoder (AE) to identify anomalous and potentially malicious patterns. The proposed method is evaluated using the DARPA Transparent Computing (TC) dataset, which contains realistic APT attack scenarios generated by red teams in live environments. Experimental results show that the AE trained on LLM-derived embeddings outperforms widely used unsupervised baseline methods, including Isolation Forest (IForest), One-Class Support Vector Machine (OC-SVM), and Principal Component Analysis (PCA). Performance is measured using the Area Under the Receiver Operating Characteristic Curve (AUC-ROC), where the proposed approach consistently achieves superior results, even in complex threat scenarios. These findings highlight the importance of semantic understanding in detecting non-linear and stealthy attack behaviors that are often missed by conventional detection techniques.

</details>


### [7] [TessPay: Verify-then-Pay Infrastructure for Trusted Agentic Commerce](https://arxiv.org/abs/2602.00213)
*Mehul Goenka,Tejas Pathak,Siddharth Asthana*

Main category: cs.CR

TL;DR: TessPay是一个统一的"验证后支付"基础设施，通过分离控制和验证与结算来解决代理商务中的信任缺口，确保任务执行验证后才释放资金。


<details>
  <summary>Details</summary>
Motivation: 代理商务面临基础信任缺口：现有系统为直接人类交互设计，缺乏代理驱动操作的核心原语，包括任务委托、支付结算和审计机制方面的不足。

Method: 采用两平面架构分离控制和验证与结算，实现"验证后支付"模式。通过四个阶段：执行前代理注册和意图捕获；执行中资金托管和生成任务执行证明；结算时验证证据并释放资金；结算后保留防篡改审计跟踪。

Result: TessPay提供了一个统一的链无关基础设施，通过模块化轨道适配器支持异构支付轨道，将隐式信任替换为可验证的信任架构。

Conclusion: TessPay解决了代理商务中的关键信任缺口，通过统一的"验证后支付"基础设施绑定整个交易生命周期，为自主代理交易提供了可靠的基础设施。

Abstract: The global economy is entering the era of Agentic Commerce, where autonomous agents can discover services, negotiate prices, and transact value. However adoption towards agentic commerce faces a foundational trust gap: current systems are built for direct human interactions rather than agent-driven operations. It lacks core primitives across three critical stages of agentic transactions. First, Task Delegation lacks means to translate user intent into defined scopes, discover appropriate agents, and securely authorize actions. Second, Payment Settlement for tasks is processed before execution, lacking verifiable evidence to validate the agent's work. Third, Audit Mechanisms fail to capture the full transaction lifecycle, preventing clear accountability for disputes. While emerging standards address fragments of this trust gap, there still remains a critical need for a unified infrastructure that binds the entire transaction lifecycle.
  To resolve this gap, we introduce TessPay, a unified infrastructure that replaces implicit trust with a 'Verify-then-Pay' architecture. It is a two plane architecture separating control and verification from settlement. TessPay operationalizes trust across four distinct stages: Before execution, agents are anchored in a canonical registry and user intent is captured as verifiable mandates, enabling stakeholder accountability. During execution, funds are locked in escrow while the agent executes the task and generates cryptographic evidence (TLS Notary, TEE etc.) to support Proof of Task Execution (PoTE). At settlement, the system verifies this evidence and releases funds only when the PoTE satisfies verification predicates; modular rail adapters ensure this PoTE-gated escrow remains chain-agnostic across heterogeneous payment rails. After settlement, TessPay preserves a tamper-evident audit trail to enable clear accountability for dispute resolution.

</details>


### [8] [Tri-LLM Cooperative Federated Zero-Shot Intrusion Detection with Semantic Disagreement and Trust-Aware Aggregation](https://arxiv.org/abs/2602.00219)
*Saeid Jamshidi,Omar Abdul Wahab,Foutse Khomh,Kawser Wazed Nafi*

Main category: cs.CR

TL;DR: 提出一种语义驱动的联邦入侵检测框架，利用大语言模型生成语义攻击原型，实现开放集和零样本入侵检测，同时通过信任感知聚合机制处理不可靠客户端。


<details>
  <summary>Details</summary>
Motivation: 现有联邦学习入侵检测系统通常假设封闭集学习，缺乏不确定性估计、语义泛化和对零日攻击场景的认知模糊建模能力，且对异构和不可靠客户端的鲁棒性不足。

Method: 采用Tri-LLM集成（GPT-4o、DeepSeek-V3、LLaMA-3-8B）构建语义攻击原型，将分布式遥测特征与高层攻击概念对齐，利用LLM间语义分歧建模认知不确定性，并通过信任感知聚合机制动态加权客户端更新。

Result: 在异构客户端上实现稳定的语义对齐和一致收敛，对未见攻击模式达到80%以上的零样本检测准确率，相比基于相似性的基线方法零日攻击辨别能力提升超过10%，在不可靠或受攻击客户端存在时保持低聚合不稳定性。

Conclusion: 该语义驱动联邦入侵检测框架通过语言衍生语义监督有效解决了开放集和零样本入侵检测问题，同时增强了系统对异构和不可靠客户端的鲁棒性，为实际部署提供了可行方案。

Abstract: Federated learning (FL) has become an effective paradigm for privacy-preserving, distributed Intrusion Detection Systems (IDS) in cyber-physical and Internet of Things (IoT) networks, where centralized data aggregation is often infeasible due to privacy and bandwidth constraints. Despite its advantages, most existing FL-based IDS assume closed-set learning and lack mechanisms such as uncertainty estimation, semantic generalization, and explicit modeling of epistemic ambiguity in zero-day attack scenarios. Additionally, robustness to heterogeneous and unreliable clients remains a challenge in practical applications. This paper introduces a semantics-driven federated IDS framework that incorporates language-derived semantic supervision into federated optimization, enabling open-set and zero-shot intrusion detection for previously unseen attack behaviors. The approach constructs semantic attack prototypes using a Tri-LLM ensemble of GPT-4o, DeepSeek-V3, and LLaMA-3-8B, aligning distributed telemetry features with high-level attack concepts. Inter-LLM semantic disagreement is modeled as epistemic uncertainty for zero-day risk estimation, while a trust-aware aggregation mechanism dynamically weights client updates based on reliability. Experimental results show stable semantic alignment across heterogeneous clients and consistent convergence. The framework achieves over 80% zero-shot detection accuracy on unseen attack patterns, improving zero-day discrimination by more than 10% compared to similarity-based baselines, while maintaining low aggregation instability in the presence of unreliable or compromised clients.

</details>


### [9] [RVDebloater: Mode-based Adaptive Firmware Debloating for Robotic Vehicles](https://arxiv.org/abs/2602.00270)
*Mohsen Salehi,Karthik Pattabiraman*

Main category: cs.CR

TL;DR: RVDebloater：一种针对模式嵌入式设备的自适应去膨胀技术，通过运行时函数级动态去膨胀减少攻击面


<details>
  <summary>Details</summary>
Motivation: 嵌入式设备固件规模增大导致攻击面扩大，但许多设备（如机器人车辆）在不同模式下仅需少量代码。现有去膨胀技术存在粒度粗、不可逆等限制，需要更灵活的解决方案。

Method: 提出RVDebloater技术，使用静态或动态分析自动识别每个模式下不需要的固件代码，在运行时以函数粒度动态去膨胀。采用基于软件的强制执行方法，支持多种模式嵌入式设备。

Result: 在6种机器人车辆上评估，平均85%的函数在其他模式下不需要，固件调用图平均减少45%。去膨胀后任务无失败，无假阳性/假阴性。性能开销平均3.9%，内存开销4%（约0.25MB）。

Conclusion: RVDebloater能有效减少模式嵌入式设备的攻击面，保持功能完整性，开销可接受，为嵌入式安全提供了实用的去膨胀解决方案。

Abstract: As the number of embedded devices grows and their functional requirements increase, embedded firmware is becoming increasingly larger, thereby expanding its attack surface. Despite the increase in firmware size, many embedded devices, such as robotic vehicles (RVs), operate in distinct modes, each requiring only a small subset of the firmware code at runtime. We refer to such devices as mode-based embedded devices. Debloating is an approach to reduce attack surfaces by removing or restricting unneeded code, but existing techniques suffer from significant limitations, such as coarse granularity and irreversible code removal, limiting their applicability.
  To address these limitations, we propose RVDebloater, a novel adaptive debloating technique for mode-based embedded devices that automatically identifies unneeded firmware code for each mode using either static or dynamic analysis, and dynamically debloats the firmware for each mode at the function level at runtime. RVDebloater introduces a new software-based enforcement approach that supports diverse mode-based embedded devices. We implemented RVDebloater using the LLVM compiler and evaluated its efficiency and effectiveness on six different RVs, including both simulated and real ones, with different real-world missions. We find that device requirements change throughout its lifetime for each mode, and that many critical firmware functions can be restricted in other modes, with an average of 85% of functions not being required. The results showed that none of the missions failed after debloating with RVDebloater, indicating that it neither incurred false positives nor false negatives. Further, RVDebloater prunes the firmware call graph by an average of 45% across different firmware. Finally, RVDebloater incurred an average performance overhead of 3.9% and memory overhead of 4% (approximately 0.25 MB) on real RVs.

</details>


### [10] [Semantics-Preserving Evasion of LLM Vulnerability Detectors](https://arxiv.org/abs/2602.00305)
*Luze Sun,Alina Oprea,Eric Wong*

Main category: cs.CR

TL;DR: LLM漏洞检测器在行为保持的代码变换下存在系统性脆弱性，即使最先进的检测器在干净输入上表现良好，但在语义等价的编辑下预测会翻转，且对抗性字符串可跨模型转移。


<details>
  <summary>Details</summary>
Motivation: LLM漏洞检测器已广泛部署于安全关键代码审查，但其在行为保持编辑下的抗规避能力尚未被充分理解，需要评估检测时完整性并建立实用的诊断指标。

Method: 在统一的C/C++基准集(N=5000)上实例化多种行为保持的代码变换，采用语义保持的威胁模型，引入跨不同攻击方法/载体的联合鲁棒性度量，通过单代理模型优化的通用对抗字符串测试黑盒API转移效果。

Result: 观察到语义不变对抗变换的系统性失败：即使最先进的漏洞检测器在干净输入上表现良好，但在行为等价编辑下预测会翻转；通用对抗字符串在转移到黑盒API时仍保持有效，梯度访问可进一步放大规避成功率。

Conclusion: 即使高性能的检测器也容易受到低成本、语义保持的规避攻击，基于载体的度量为评估LLM代码检测器提供了实用的诊断工具。

Abstract: LLM-based vulnerability detectors are increasingly deployed in security-critical code review, yet their resilience to evasion under behavior-preserving edits remains poorly understood. We evaluate detection-time integrity under a semantics-preserving threat model by instantiating diverse behavior-preserving code transformations on a unified C/C++ benchmark (N=5000), and introduce a metric of joint robustness across different attack methods/carriers. Across models, we observe a systemic failure of semantic invariant adversarial transformations: even state-of-the-art vulnerability detectors perform well on clean inputs while predictions flip under behavior-equivalent edits. Universal adversarial strings optimized on a single surrogate model remain effective when transferred to black-box APIs, and gradient access can further amplify evasion success. These results show that even high-performing detectors are vulnerable to low-cost, semantics-preserving evasion. Our carrier-based metrics provide practical diagnostics for evaluating LLM-based code detectors.

</details>


### [11] [HEEDFUL: Leveraging Sequential Transfer Learning for Robust WiFi Device Fingerprinting Amid Hardware Warm-Up Effects](https://arxiv.org/abs/2602.00338)
*Abdurrahman Elmaghbub,Bechir Hamdaoui*

Main category: cs.CR

TL;DR: HEEDFUL框架通过序列迁移学习和目标损伤估计，解决了RF指纹识别在硬件预热阶段的跨域性能问题，在WiFi信号上实现了高达96%的分类准确率。


<details>
  <summary>Details</summary>
Motivation: 基于深度学习的RF指纹识别方法在跨域场景（特别是硬件预热阶段）表现不佳，这一常被忽视的漏洞影响了其在实际应用中的可靠性和采用。

Method: 提出HEEDFUL框架，结合序列迁移学习和目标损伤估计技术，深入分析RF指纹在硬件稳定期间和稳定后的时间变化特性。

Result: 在设备初始运行阶段实现高达96%的分类准确率，远超传统模型；跨日和跨协议评估显示HEEDFUL在稳定期和预热期均保持高准确率。

Conclusion: HEEDFUL有效解决了RF指纹识别在硬件预热阶段的性能问题，发布的WiFi B/N数据集首次包含时域表示和真实硬件损伤数据，强调了利用硬件损伤数据对开发更鲁棒RF指纹解决方案的重要性。

Abstract: Deep Learning-based RF fingerprinting approaches struggle to perform well in cross-domain scenarios, particularly during hardware warm-up. This often-overlooked vulnerability has been jeopardizing their reliability and their adoption in practical settings. To address this critical gap, in this work, we first dive deep into the anatomy of RF fingerprints, revealing insights into the temporal fingerprinting variations during and post hardware stabilization. Introducing HEEDFUL, a novel framework harnessing sequential transfer learning and targeted impairment estimation, we then address these challenges with remarkable consistency, eliminating blind spots even during challenging warm-up phases. Our evaluation showcases HEEDFUL's efficacy, achieving remarkable classification accuracies of up to 96% during the initial device operation intervals-far surpassing traditional models. Furthermore, cross-day and cross-protocol assessments confirm HEEDFUL's superiority, achieving and maintaining high accuracy during both the stable and initial warm-up phases when tested on WiFi signals. Additionally, we release WiFi type B and N RF fingerprint datasets that, for the first time, incorporate both the time-domain representation and real hardware impairments of the frames. This underscores the importance of leveraging hardware impairment data, enabling a deeper understanding of fingerprints and facilitating the development of more robust RF fingerprinting solutions.

</details>


### [12] ["Someone Hid It": Query-Agnostic Black-Box Attacks on LLM-Based Retrieval](https://arxiv.org/abs/2602.00364)
*Jiate Li,Defu Cao,Li Li,Wei Yang,Yuehan Qin,Chenxiao Yu,Tiannuo Yang,Ryan A. Rossi,Yan Liu,Xiyang Hu,Yue Zhao*

Main category: cs.CR

TL;DR: 本文提出了一种针对LLM检索系统的实用黑盒攻击方法，无需受害者查询或模型知识，通过零样本替代LLM生成可迁移的注入令牌，揭示了LLM检索系统的安全风险。


<details>
  <summary>Details</summary>
Motivation: 现有LLM检索攻击研究存在两个主要局限：1）假设攻击者已知查询；2）高度依赖受害者模型的参数或交互访问，这在现实场景中难以实现。为了进一步探索LLM检索的安全风险，需要一种更实用的攻击方法。

Method: 首先建立LLM检索的理论框架并进行实证验证。在该框架下，将可迁移攻击模拟为min-max优化问题，提出一种对抗学习机制，通过可学习的查询样本寻找最优对抗令牌。该方法基于零样本替代LLM生成可迁移的注入令牌，无需受害者查询或模型知识。

Result: 攻击方法在流行的LLM检索器的基准数据集上验证有效，表明LLM检索系统存在严重的鲁棒性问题，类似效果可能来自现实世界中的良性或意外文档编辑。

Conclusion: 提出的黑盒攻击方法揭示了LLM检索系统的安全风险，表明即使没有受害者查询或模型知识，攻击者也能通过令牌级注入操纵检索结果，这为LLM检索系统的安全设计提出了重要警示。

Abstract: Large language models (LLMs) have been serving as effective backbones for retrieval systems, including Retrieval-Augmentation-Generation (RAG), Dense Information Retriever (IR), and Agent Memory Retrieval. Recent studies have demonstrated that such LLM-based Retrieval (LLMR) is vulnerable to adversarial attacks, which manipulates documents by token-level injections and enables adversaries to either boost or diminish these documents in retrieval tasks. However, existing attack studies mainly (1) presume a known query is given to the attacker, and (2) highly rely on access to the victim model's parameters or interactions, which are hardly accessible in real-world scenarios, leading to limited validity.
  To further explore the secure risks of LLMR, we propose a practical black-box attack method that generates transferable injection tokens based on zero-shot surrogate LLMs without need of victim queries or victim models knowledge. The effectiveness of our attack raises such a robustness issue that similar effects may arise from benign or unintended document edits in the real world. To achieve our attack, we first establish a theoretical framework of LLMR and empirically verify it. Under the framework, we simulate the transferable attack as a min-max problem, and propose an adversarial learning mechanism that finds optimal adversarial tokens with learnable query samples. Our attack is validated to be effective on benchmark datasets across popular LLM retrievers.

</details>


### [13] [SpyDir: Spy Device Localization Through Accurate Direction Finding](https://arxiv.org/abs/2602.00411)
*Wenhao Chen,Wenyi Morty Zhang,Wei Sun,Dinesh Bharadia,Roshan Ayyalasomayajula*

Main category: cs.CR

TL;DR: SpyDir系统通过利用隐藏间谍物联网设备自动发射的电磁辐射，在室内环境中准确定位这些设备，相比基线方法实现了10倍以上的精度提升。


<details>
  <summary>Details</summary>
Motivation: 隐藏间谍摄像头等低成本、低功耗、小尺寸物联网设备对隐私构成严重威胁，这些设备在室内环境中可以悄无声息地监控人类活动，且不产生任何侧信道信息，难以检测和定位。

Method: 系统设计包括：1) 便携式切换天线阵列嗅探频谱扩展辐射；2) 通过非相干平均增强辐射信号，消除方波辐射结构引起的相关噪声效应；3) 多径解析算法，利用相对信道通过新颖的基于优化的稀疏AoA推导。

Result: 在不同室内环境中的真实世界实验评估显示：平均AoA误差为6.30度（基线算法为21.06度，精度提升3.3倍以上）；平均定位误差为19.86厘米（MUSIC基线为206.79厘米，SpotFi基线为294.75厘米，精度分别提升10.41倍和14.8倍）。

Conclusion: SpyDir系统通过利用物联网设备的电磁辐射，在室内环境中实现了对隐藏间谍设备的高精度定位，为解决隐私威胁提供了有效的技术方案。

Abstract: Hidden spy cameras have become a great privacy threat recently, as these low-cost, low-power, and small form-factor IoT devices can quietly monitor human activities in the indoor environment without generating any side-channel information. As such, it is difficult to detect and even more challenging to localize them in the rich-scattering indoor environment. To this end, this paper presents the design, implementation, and evaluation of SpyDir, a system that can accurately localize the hidden spy IoT devices by harnessing the electromagnetic emanations automatically and unintentionally emitted from them. Our system design mainly consists of a portable switching antenna array to sniff the spectrum-spread emanations, an emanation enhancement algorithm through non-coherent averaging that can de-correlate the correlated noise effect due to the square-wave emanation structure, and a multipath-resolving algorithm that can exploit the relative channels using a novel optimization-based sparse AoA derivation. Our real-world experimental evaluation across different indoor environments demonstrates an average AoA error of 6.30 deg, whereas the baseline algorithm yields 21.06 deg, achieving over a 3.3 times improvement in accuracy, and a mean localization error of 19.86cm over baseline algorithms of 206.79cm (MUSIC) and 294.75cm (SpotFi), achieving over a 10.41 times and 14.8 times improvement in accuracy.

</details>


### [14] [Towards a Cognitive-Support Tool for Threat Hunters](https://arxiv.org/abs/2602.00432)
*Alessandra Maciel Paz Milani,Norman Anderson,Margaret-Anne Storey*

Main category: cs.CR

TL;DR: 开发了Threat Hunter Board原型工具，支持威胁猎手外部化推理、组织调查线索并保持会话连续性，同时提出了六条设计启发式作为评估威胁狩猎工具认知支持的框架。


<details>
  <summary>Details</summary>
Motivation: 网络安全越来越依赖威胁猎手主动识别对抗活动，但威胁狩猎背后的认知工作尚未得到充分探索或现有工具支持不足。需要支持威胁猎手在调查过程中的认知和协作工作。

Method: 基于先前关于威胁猎手如何构建和共享心智模型的研究，推导出一组设计命题，开发了Threat Hunter Board原型工具。采用设计科学研究范式，描述解决方案设计原理和工件开发。提出六条设计启发式作为解决方案评估框架，并通过认知走查进行初步评估。

Result: 开发了Threat Hunter Board原型工具，能够支持威胁猎手外部化推理、组织调查线索并保持会话连续性。提出的六条设计启发式形成了评估威胁狩猎工具认知支持的框架。认知走查提供了可行性的早期证据。

Conclusion: Threat Hunter Board原型工具和设计启发式为支持威胁猎手的认知工作提供了有前景的解决方案。未来工作将重点放在与专业威胁猎手的用户验证上。

Abstract: Cybersecurity increasingly relies on threat hunters to proactively identify adversarial activity, yet the cognitive work underlying threat hunting remains underexplored or insufficiently supported by existing tools. Building on prior studies that examined how threat hunters construct and share mental models during investigations, we derived a set of design propositions to support their cognitive and collaborative work. In this paper, we present the Threat Hunter Board, a prototype tool that operationalizes these design propositions by enabling threat hunters to externalize reasoning, organize investigative leads, and maintain continuity across sessions. Using a design science paradigm, we describe the solution design rationale and artifact development. In addition, we propose six design heuristics that form a solution-evaluation framework for assessing cognitive support in threat hunting tools. An initial evaluation using a cognitive walkthrough provides early evidence of feasibility, while future work will focus on user-based validation with professional threat hunters.

</details>


### [15] [zkCraft: Prompt-Guided LLM as a Zero-Shot Mutation Pattern Oracle for TCCT-Powered ZK Fuzzing](https://arxiv.org/abs/2602.00667)
*Rong Fu,Jia Yee Tan,Wenxin Zhang,Youjin Wang,Ziyu Kong,Zeli Su,Zhaolu Kang,Shuning Zhang,Xianda Li,Kun Liu,Simon Fong*

Main category: cs.CR

TL;DR: zkCraft：结合确定性R1CS感知定位与证明承载搜索的ZK电路调试框架，通过Row-Vortex多项式编码约束编辑，用Violation IOP替代重复求解器查询，降低误报并减少求解器交互成本。


<details>
  <summary>Details</summary>
Motivation: 零知识电路在实现正确性方面面临挑战，主要原因是见证计算与电路约束之间的紧密耦合关系，这导致了语义不一致问题难以检测。

Method: zkCraft采用确定性R1CS感知定位与证明承载搜索相结合的方法：1）将候选约束编辑编码为Row-Vortex多项式；2）用Violation IOP替代重复求解器查询；3）使用确定性LLM驱动的突变模板偏向探索边缘情况；4）保持可审计的代数验证。

Result: 在真实Circom代码上的评估显示，证明承载定位能够检测多种欠约束和过约束故障，误报率低，并显著减少了昂贵的求解器交互。

Conclusion: zkCraft架起了形式验证与自动化调试之间的桥梁，为零知识电路的稳健开发提供了可扩展的路径。

Abstract: Zero-knowledge circuits enable privacy-preserving and scalable systems but are difficult to implement correctly due to the tight coupling between witness computation and circuit constraints. We present zkCraft, a practical framework that combines deterministic, R1CS-aware localization with proof-bearing search to detect semantic inconsistencies. zkCraft encodes candidate constraint edits into a single Row-Vortex polynomial and replaces repeated solver queries with a Violation IOP that certifies the existence of edits together with a succinct proof. Deterministic LLM-driven mutation templates bias exploration toward edge cases while preserving auditable algebraic verification. Evaluation on real Circom code shows that proof-bearing localization detects diverse under- and over-constrained faults with low false positives and reduces costly solver interaction. Our approach bridges formal verification and automated debugging, offering a scalable path for robust ZK circuit development.

</details>


### [16] [Computing Maximal Per-Record Leakage and Leakage-Distortion Functions for Privacy Mechanisms under Entropy-Constrained Adversaries](https://arxiv.org/abs/2602.00689)
*Genqiang Wu,Xiaoying Zhang,Yu Qi,Hao Wang,Jikui Wang,Yeping He*

Main category: cs.CR

TL;DR: 论文提出在有限先验知识对手模型下的信息隐私框架，开发了交替优化算法解决最大泄漏、泄漏-失真权衡和失真最小化三个核心问题，相比经典差分隐私机制有更好的隐私-效用权衡。


<details>
  <summary>Details</summary>
Motivation: 数据收集的指数增长需要强大的隐私保护机制，同时保持数据效用。现有差分隐私的独立性假设不现实，需要更实际的有限知识对手模型。

Method: 提出信息隐私框架，用熵约束H(X)≥b建模对手有限先验知识。开发高效的交替优化算法，利用凸凹对偶性，解决三个核心问题：最大每记录泄漏、泄漏-失真权衡（在失真D下最小化最坏情况泄漏）和失真最小化（在泄漏约束L下最小化失真）。

Result: 算法在二元对称信道和模和查询实验中验证有效，相比经典差分隐私机制展现出更好的隐私-效用权衡。理论保证包括原始问题的局部收敛和对偶问题的驻点收敛。

Conclusion: 该工作为在现实对手假设下审计隐私风险和设计认证机制提供了计算框架，信息隐私框架比差分隐私更贴合实际应用场景。

Abstract: The exponential growth of data collection necessitates robust privacy protections that preserve data utility. We address information disclosure against adversaries with bounded prior knowledge, modeled by an entropy constraint $H(X) \geq b$. Within this information privacy framework -- which replaces differential privacy's independence assumption with a bounded-knowledge model -- we study three core problems: maximal per-record leakage, the primal leakage-distortion tradeoff (minimizing worst-case leakage under distortion $D$), and the dual distortion minimization (minimizing distortion under leakage constraint $L$).
  These problems resemble classical information-theoretic ones (channel capacity, rate-distortion) but are more complex due to high dimensionality and the entropy constraint. We develop efficient alternating optimization algorithms that exploit convexity-concavity duality, with theoretical guarantees including local convergence for the primal problem and convergence to a stationary point for the dual.
  Experiments on binary symmetric channels and modular sum queries validate the algorithms, showing improved privacy-utility tradeoffs over classical differential privacy mechanisms. This work provides a computational framework for auditing privacy risks and designing certified mechanisms under realistic adversary assumptions.

</details>


### [17] [From Detection to Prevention: Explaining Security-Critical Code to Avoid Vulnerabilities](https://arxiv.org/abs/2602.00711)
*Ranjith Krishnamurthy,Oshando Johnson,Goran Piskachev,Eric Bodden*

Main category: cs.CR

TL;DR: 开发IntelliJ IDEA插件，使用代码指标识别安全关键方法，结合LLM生成预防性安全建议，实现漏洞预防而非事后检测


<details>
  <summary>Details</summary>
Motivation: 传统安全工具（静态/动态分析）在代码引入漏洞后才进行检测，修复成本高。需要从被动检测转向主动预防，在开发阶段就识别安全关键功能并提供安全实现指导

Method: 开发IntelliJ IDEA插件原型：1) 使用代码级软件指标识别潜在安全关键方法（如数据访问、认证、输入处理等）；2) 结合大语言模型生成预防性解释和指导

Result: 在Spring-PetClinic应用上的初步评估显示：所选指标能识别大多数已知安全关键方法，LLM能提供可操作的、预防性安全见解

Conclusion: 虽然当前指标主要捕获结构特性而非安全语义方面，但为代码级安全感知指标和增强解释奠定了基础，展示了主动预防安全漏洞的可行性

Abstract: Security vulnerabilities often arise unintentionally during development due to a lack of security expertise and code complexity. Traditional tools, such as static and dynamic analysis, detect vulnerabilities only after they are introduced in code, leading to costly remediation. This work explores a proactive strategy to prevent vulnerabilities by highlighting code regions that implement security-critical functionality -- such as data access, authentication, and input handling -- and providing guidance for their secure implementation. We present an IntelliJ IDEA plugin prototype that uses code-level software metrics to identify potentially security-critical methods and large language models (LLMs) to generate prevention-oriented explanations. Our initial evaluation on the Spring-PetClinic application shows that the selected metrics identify most known security-critical methods, while an LLM provides actionable, prevention-focused insights. Although these metrics capture structural properties rather than semantic aspects of security, this work lays the foundation for code-level security-aware metrics and enhanced explanations.

</details>


### [18] [Bypassing Prompt Injection Detectors through Evasive Injections](https://arxiv.org/abs/2602.00750)
*Md Jahedur Rahman,Ihsen Alouani*

Main category: cs.CR

TL;DR: 论文评估了基于激活delta的任务漂移检测器对抗对抗性后缀攻击的鲁棒性，发现这些检测器高度脆弱，并提出了一种有效的防御方法。


<details>
  <summary>Details</summary>
Motivation: 大型语言模型在交互式和检索增强系统中越来越常用，但它们容易受到任务漂移的影响——由于注入的次要提示而偏离用户预期指令。虽然已有研究显示基于LLM隐藏层激活delta的线性探针可以有效检测这种漂移，但其对抗对抗性攻击的鲁棒性尚未充分研究。

Method: 1. 生成通用对抗性后缀，使被污染输入能够同时逃避多个探针检测；2. 在Phi-3 3.8B和Llama-3 8B模型上评估攻击效果；3. 提出防御技术：生成多个后缀并随机附加到提示中，使用这些激活训练逻辑回归模型。

Result: 单个后缀攻击成功率极高：Phi-3达93.91%，Llama-3达99.63%（所有探针都被欺骗时）；多数投票设置下成功率>90%。提出的防御方法能有效抵御此类攻击。

Conclusion: 基于激活delta的任务漂移检测器对对抗性后缀攻击高度脆弱，需要更强的防御机制。论文提出的随机后缀防御技术被证明能有效对抗此类自适应攻击。

Abstract: Large language models (LLMs) are increasingly used in interactive and retrieval-augmented systems, but they remain vulnerable to task drift; deviations from a user's intended instruction due to injected secondary prompts. Recent work has shown that linear probes trained on activation deltas of LLMs' hidden layers can effectively detect such drift. In this paper, we evaluate the robustness of these detectors against adversarially optimised suffixes. We generate universal suffixes that cause poisoned inputs to evade detection across multiple probes simultaneously. Our experiments on Phi-3 3.8B and Llama-3 8B show that a single suffix can achieve high attack success rates; up to 93.91% and 99.63%, respectively, when all probes must be fooled, and nearly perfect success (>90%) under majority vote setting. These results demonstrate that activation delta-based task drift detectors are highly vulnerable to adversarial suffixes, highlighting the need for stronger defences against adaptive attacks. We also propose a defence technique where we generate multiple suffixes and randomly append one of them to the prompts while making forward passes of the LLM and train logistic regression models with these activations. We found this approach to be highly effective against such attacks.

</details>


### [19] [IDEM Enough? Evolving Highly Nonlinear Idempotent Boolean Functions](https://arxiv.org/abs/2602.00837)
*Claude Carlet,Marko Ðurasevic,Domagoj Jakobovic,Luca Mariot,Stjepan Picek*

Main category: cs.CR

TL;DR: 使用进化算法构造高非线性幂等布尔函数，通过轨道编码实现紧凑基因组表示


<details>
  <summary>Details</summary>
Motivation: 幂等布尔函数具有特殊的代数结构，与密码学设计相关，但高非线性搜索比无约束情况更困难

Method: 使用进化算法（交叉和变异算子）在n=5到12维度上构造幂等布尔函数，采用多项式基表示和规范本原多项式，通过轨道编码强制实现幂等性

Result: 进化幂等函数很困难，交叉和变异算子具有破坏性；通过轨道编码可以强制实现幂等性，获得紧凑基因组

Conclusion: 轨道编码是构造高非线性幂等布尔函数的有效方法，解决了进化算法中的破坏性问题

Abstract: Idempotent Boolean functions form a highly structured subclass of Boolean functions that is closely related to rotation symmetry under a normal-basis representation and to invariance under a fixed linear map in a polynomial basis. These functions are attractive as candidates for cryptographic design, yet their additional algebraic constraints make the search for high nonlinearity substantially more difficult than in the unconstrained case. In this work, we investigate evolutionary methods for constructing highly nonlinear idempotent Boolean functions for dimensions $n=5$ up to $n=12$ using a polynomial basis representation with canonical primitive polynomials. Our results show that the problem of evolving idempotent functions is difficult due to the disruptive nature of crossover and mutation operators. Next, we show that idempotence can be enforced by encoding the truth table on orbits, yielding a compact genome of size equal to the number of distinct squaring orbits.

</details>


### [20] [GradingAttack: Attacking Large Language Models Towards Short Answer Grading Ability](https://arxiv.org/abs/2602.00979)
*Xueyi Li,Zhuoneng Zhou,Zitao Liu,Yongdong Wu,Weiqi Luo*

Main category: cs.CR

TL;DR: GradingAttack：一个针对LLM自动评分系统的细粒度对抗攻击框架，通过token级和prompt级策略操纵评分结果，同时保持高伪装性


<details>
  <summary>Details</summary>
Motivation: LLM在自动短答案评分中表现出巨大潜力，但其对对抗性操纵的脆弱性引发了关于评分公平性和可靠性的严重担忧。需要系统评估LLM评分模型的脆弱性。

Method: 提出GradingAttack框架，将通用攻击方法与ASAG特定目标对齐：1) token级策略：操纵单个token影响评分；2) prompt级策略：通过提示工程操纵评分。还提出了量化攻击伪装的新评估指标，平衡攻击成功率和伪装性。

Result: 在多个数据集上的实验表明，两种攻击策略都能有效误导评分模型：prompt级攻击成功率更高，token级攻击伪装能力更强。攻击成功率可达较高水平，同时保持良好伪装。

Conclusion: LLM自动评分系统存在严重脆弱性，需要开发鲁棒的防御机制来确保ASAG的公平性和可靠性。提出的GradingAttack框架为评估和改进评分系统安全性提供了重要工具。

Abstract: Large language models (LLMs) have demonstrated remarkable potential for automatic short answer grading (ASAG), significantly boosting student assessment efficiency and scalability in educational scenarios. However, their vulnerability to adversarial manipulation raises critical concerns about automatic grading fairness and reliability. In this paper, we introduce GradingAttack, a fine-grained adversarial attack framework that systematically evaluates the vulnerability of LLM based ASAG models. Specifically, we align general-purpose attack methods with the specific objectives of ASAG by designing token-level and prompt-level strategies that manipulate grading outcomes while maintaining high camouflage. Furthermore, to quantify attack camouflage, we propose a novel evaluation metric that balances attack success and camouflage. Experiments on multiple datasets demonstrate that both attack strategies effectively mislead grading models, with prompt-level attacks achieving higher success rates and token-level attacks exhibiting superior camouflage capability. Our findings underscore the need for robust defenses to ensure fairness and reliability in ASAG. Our code and datasets are available at https://anonymous.4open.science/r/GradingAttack.

</details>


### [21] [SMCP: Secure Model Context Protocol](https://arxiv.org/abs/2602.01129)
*Xinyi Hou,Shenao Wang,Yifan Zhang,Ziluo Xue,Yanjie Zhao,Cai Fu,Haoyu Wang*

Main category: cs.CR

TL;DR: 该论文提出了安全模型上下文协议(SMCP)，在MCP基础上增加统一身份管理、双向认证、安全上下文传播、细粒度策略执行和审计日志等安全机制，以解决AI代理生态系统中的安全隐私风险。


<details>
  <summary>Details</summary>
Motivation: 随着基于大语言模型的AI代理系统从封闭框架转向开放生态系统，MCP协议成为统一工具访问的标准，但广泛采用带来了新的安全隐私挑战，包括未授权访问、工具投毒、提示注入、权限提升和供应链攻击等风险。目前缺乏系统性的协议级安全改进方案。

Method: 提出安全模型上下文协议(SMCP)，在现有MCP协议基础上构建，增加五个核心安全组件：统一身份管理、鲁棒的双向认证、持续的安全上下文传播、细粒度策略执行和全面的审计日志记录。

Result: SMCP协议能够有效降低MCP生态系统中的安全风险，通过实际应用示例展示了其安全增强功能，为构建既强大适应又安全可靠的AI代理系统提供了协议级解决方案。

Conclusion: SMCP协议填补了MCP在系统性安全改进方面的空白，通过协议级安全增强机制，有助于开发既强大灵活又安全可靠的AI代理系统，为开放AI生态系统的安全发展做出贡献。

Abstract: Agentic AI systems built around large language models (LLMs) are moving away from closed, single-model frameworks and toward open ecosystems that connect a variety of agents, external tools, and resources. The Model Context Protocol (MCP) has emerged as a standard to unify tool access, allowing agents to discover, invoke, and coordinate with tools more flexibly. However, as MCP becomes more widely adopted, it also brings a new set of security and privacy challenges. These include risks such as unauthorized access, tool poisoning, prompt injection, privilege escalation, and supply chain attacks, any of which can impact different parts of the protocol workflow. While recent research has examined possible attack surfaces and suggested targeted countermeasures, there is still a lack of systematic, protocol-level security improvements for MCP. To address this, we introduce the Secure Model Context Protocol (SMCP), which builds on MCP by adding unified identity management, robust mutual authentication, ongoing security context propagation, fine-grained policy enforcement, and comprehensive audit logging. In this paper, we present the main components of SMCP, explain how it helps reduce security risks, and illustrate its application with practical examples. We hope that this work will contribute to the development of agentic systems that are not only powerful and adaptable, but also secure and dependable.

</details>


### [22] [DTAMS: High-Capacity Generative Steganography via Dynamic Multi-Timestep Selection and Adaptive Deviation Mapping in Latent Diffusion](https://arxiv.org/abs/2602.01160)
*Yuhao Xue,Jiuan Zhou,Yu Cheng,Zhaoxia Yin*

Main category: cs.CR

TL;DR: DTAMS框架通过动态多时间步自适应嵌入机制、全局子区间映射策略和多维联合约束机制，在扩散模型中实现高嵌入率（12bpp）的同时保持优异的安全性和鲁棒性。


<details>
  <summary>Details</summary>
Motivation: 现有生成式图像隐写方法在低嵌入率下才能保持可接受的安全性和鲁棒性，这严重限制了隐写系统的实际应用。需要解决高嵌入率下的性能下降问题。

Method: 1. 基于扩散模型转移成本建模的动态多时间步自适应嵌入机制，自动选择最优嵌入时间步；2. 全局子区间映射策略，将点级扰动转换为区间级统计映射；3. 像素、潜空间和语义层面的多维联合约束机制。

Result: 在12bpp的高嵌入率下仍保持优异的安全性和鲁棒性，平均提取错误率降低59.39%，显著优于现有最优方法。

Conclusion: DTAMS框架成功解决了生成式图像隐写在保持高嵌入率时的安全性和鲁棒性挑战，为实际应用提供了可行方案。

Abstract: With the rapid development of AIGC technologies, generative image steganography has attracted increasing attention due to its high imperceptibility and flexibility. However, existing generative steganography methods often maintain acceptable security and robustness only at relatively low embedding rates, severely limiting the practical applicability of steganographic systems. To address this issue, we propose a novel DTAMS framework that achieves high embedding rates while ensuring strong robustness and security. Specifically, a dynamic multi-timestep adaptive embedding mechanism is constructed based on transition-cost modeling in diffusion models, enabling automatic selection of optimal embedding timesteps to improve embedding rates while preserving overall performance. Meanwhile, we propose a global sub-interval mapping strategy that jointly considers mapping errors and the frequency distribution of secret information, converting point-wise perturbations into interval-level statistical mappings to suppress error accumulation and distribution drift during multi-step diffusion processes. Furthermore, a multi-dimensional joint constraint mechanism is introduced to mitigate distortions caused by repeated latent-pixel transformations by jointly regularizing embedding errors at the pixel, latent, and semantic levels. Experiments demonstrate that the proposed method achieves an embedding rate of 12 bpp while maintaining excellent security and robustness. Across all evaluated conditions, DTAMS reduces the average extraction error rate by 59.39%, representing a significant improvement over SOTA methods.

</details>


### [23] [FedBGS: A Blockchain Approach to Segment Gossip Learning in Decentralized Systems](https://arxiv.org/abs/2602.01185)
*Fabio Turazza,Marcello Pietri,Marco Picone,Marco Mamei*

Main category: cs.CR

TL;DR: FedBGS：基于区块链的完全去中心化联邦学习框架，通过分段八卦学习和联邦分析优化区块链使用，提供全面攻击防护，解决传统FL中服务器单点故障问题


<details>
  <summary>Details</summary>
Motivation: 传统联邦学习虽然通过隐私保护技术增强了安全性，但仍存在服务器作为单点故障的问题，导致安全性和可扩展性受限。需要一种完全去中心化的解决方案来消除这一瓶颈。

Method: 提出FedBGS框架，结合区块链技术、分段八卦学习和联邦分析。通过去中心化架构消除中央服务器，利用区块链确保安全性和透明度，采用分段八卦学习优化通信效率。

Result: FedBGS能够优化区块链使用，提供针对所有类型攻击的全面保护，确保隐私安全，并有效处理非独立同分布数据，解决了传统联邦学习的单点故障问题。

Conclusion: FedBGS是一个创新的完全去中心化联邦学习框架，通过区块链和分段八卦学习技术，在保持隐私保护的同时解决了传统联邦学习的架构限制，为隐私敏感领域提供了更安全可扩展的解决方案。

Abstract: Privacy-Preserving Federated Learning (PPFL) is a Decentralized machine learning paradigm that enables multiple participants to collaboratively train a global model without sharing their data with the integration of cryptographic and privacy-based techniques to enhance the security of the global system. This privacy-oriented approach makes PPFL a highly suitable solution for training shared models in sectors where data privacy is a critical concern. In traditional FL, local models are trained on edge devices, and only model updates are shared with a central server, which aggregates them to improve the global model. However, despite the presence of the aforementioned privacy techniques, in the classical Federated structure, the issue of the server as a single-point-of-failure remains, leading to limitations both in terms of security and scalability. This paper introduces FedBGS, a fully Decentralized Blockchain-based framework that leverages Segmented Gossip Learning through Federated Analytics. The proposed system aims to optimize blockchain usage while providing comprehensive protection against all types of attacks, ensuring both privacy, security and non-IID data handling in Federated environments.

</details>


### [24] [Bifrost: A Much Simpler Secure Two-Party Data Join Protocol for Secure Data Analytics](https://arxiv.org/abs/2602.01225)
*Shuyu Chen,Mingxun Zhou,Haoyu Niu,Guopeng Lin,Weili Han*

Main category: cs.CR

TL;DR: Bifrost是一个简单高效的冗余消除安全数据连接协议，相比现有方案显著提升性能并减少通信开销。


<details>
  <summary>Details</summary>
Motivation: 现有安全数据连接方案存在缺陷：CPSI在连接表中引入冗余虚拟行，导致下游安全数据分析任务开销高；iPrivJoin虽然消除冗余但通信开销大，依赖复杂的OPPRF和多次不经意洗牌。

Method: Bifrost基于两个简单构建块：ECDH-PSI协议和两方不经意洗牌协议。采用双重映射优化，将不经意洗牌轮数从两轮减少到一轮，避免使用OPPRF。

Result: 在100GB数据集上，Bifrost比iPrivJoin快2.54-22.32倍，通信减少84.15%-88.97%。通信量接近输入数据大小。在安全数据分析流程中，避免虚拟行导致的错误率爆炸，SDA过程加速达2.80倍，通信减少73.15%。

Conclusion: Bifrost提供了一个简单高效的无冗余安全数据连接方案，显著优于现有技术，为安全多方计算数据分析提供了实用解决方案。

Abstract: Secure data join enables two parties with vertically distributed data to securely compute the joined table, allowing the parties to perform downstream Secure multi-party computation-based Data Analytics (SDA), such as training machine learning models, based on the joined table. While Circuit-based Private Set Intersection (CPSI) can be used for secure data join, it introduces redundant dummy rows in the joined table, which results in high overhead in the downstream SDA tasks. iPrivJoin addresses this issue but introduces significant communication overhead in the redundancy removal process, as it relies on the cryptographic primitive OPPRF for data encoding and multiple rounds of oblivious shuffles. In this paper, we propose a much simpler secure data join protocol, Bifrost, which outputs (the secret shares of) a redundancy-free joined table. The highlight of Bifrost lies in its simplicity: it builds upon two conceptually simple building blocks, an ECDH-PSI protocol and a two-party oblivious shuffle protocol. The lightweight protocol design allows Bifrost to avoid the need for OPPRF. We also proposed a simple optimization named \textit{dual mapping} that reduces the rounds of oblivious shuffle needed from two to one. Experiments on datasets of up to 100 GB show that Bifrost achieves $2.54 \sim 22.32\times$ speedup and reduces the communication by $84.15\% \sim 88.97\%$ compared to the SOTA redundancy-free secure data join protocol iPrivJoin. Notably, the communication size of Bifrost is nearly equal to the size of the input data. In the two-step SDA pipeline evaluation (secure join and SDA), the redundancy-free property of Bifrost not only avoids the catastrophic error rate blowup in the downstream tasks caused by the dummy rows in the joined table (as introduced in CPSI), but also shows up to $2.80\times$ speed-up in the SDA process with up to $73.15\%$ communication reduction.

</details>


### [25] [Protocol Agent: What If Agents Could Use Cryptography In Everyday Life?](https://arxiv.org/abs/2602.01304)
*Marco De Rossi*

Main category: cs.CR

TL;DR: 论文提出Protocol Agent框架，让AI智能体能够动态识别和应用加密原语来解决日常交互问题，并建立了包含五个维度的基准测试来评估模型能力。


<details>
  <summary>Details</summary>
Motivation: 当前智能体交互通常模仿人类对话，但智能体有不同能力。现有的加密原语（如零知识证明）可以极大改善日常交互，但人类难以使用。如果智能体能动态识别适合的加密原语，与对方协商并正确执行协议，就能实现更高效、安全的交互。

Method: 提出Protocol Agent框架，建立包含五个维度的基准测试：1)加密原语识别，2)协商能力，3)实现正确性，4)计算正确性，5)安全强度。评估现有开源和SOTA模型，提出数据集生成方法改进这些能力，并测量监督微调对基准性能的影响。

Result: 评估显示当前模型在这些能力上存在不足。通过监督微调后的模型在基准测试中表现显著优于基础模型，证明了训练方法对提升智能体加密协议处理能力的有效性。

Conclusion: 智能体可以发展出超越人类对话模式的通信方式，通过动态应用加密原语实现更高效、安全的交互。Protocol Agent框架为评估和改进智能体的加密协议能力提供了系统方法，监督微调能显著提升这些能力。

Abstract: We often assume that agent-to-agent interaction will mirror human conversation. However, agents operate fundamentally differently. What if they could develop communication patterns that are more efficient and better aligned with their capabilities? While cryptographic primitives that could profoundly improve everyday interactions already exist, humans can't use them because they are too complex and the math can't be done in one's head. Examples range from proving your age (or other attributes) without showing your ID, to filing an anonymous report within a group while proving you are a legitimate member, to splitting a dinner bill fairly without revealing salaries. What if agents could create protocols "on the fly" by recognizing which primitive fits an everyday situation, proposing it to an agentic counterpart, persuading them to participate, and then executing the protocol correctly using appropriate computation tools? Protocol Agent frames this problem by introducing a benchmark that spans: (1) cryptographic primitive recognition, (2) negotiation skills, (3) implementation correctness, (4) correct computation and (5) security strength. We evaluate current open-weight and state-of-the-art models on this benchmark, propose a dataset-generation approach to improve these capabilities, and measure the impact of supervised fine-tuning (SFT) on benchmark performance, with tuned models outperforming base models by a wide margin.

</details>


### [26] [TxRay: Agentic Postmortem of Live Blockchain Attacks](https://arxiv.org/abs/2602.01317)
*Ziyue Wang,Jiangshan Yu,Kaihua Qin,Dawn Song,Arthur Gervais,Liyi Zhou*

Main category: cs.CR

TL;DR: TxRay是一个基于LLM的DeFi攻击事后分析系统，能够从有限的交易证据自动重建攻击生命周期、确定根本原因，并生成可执行的PoC，在114个DeFi攻击案例中实现了92.11%的端到端复现率。


<details>
  <summary>Details</summary>
Motivation: DeFi生态系统因开放透明特性而面临"任何人都可触发"的攻击机会，五年内损失超过157.5亿美元。现有的事后分析过程缓慢且手动，需要从有限的交易哈希证据中重建整个攻击生命周期。

Method: TxRay使用LLM代理系统，从种子交易开始，通过工具调用重建实时攻击过程，确定根本原因，并生成可独立运行的PoC。系统通过编码特定事件的语义预言机作为可执行断言来自我检查分析结果。

Result: 在DeFiHackLabs的114个攻击事件中，TxRay为105个事件生成了专家认可的根本原因和可执行PoC，端到端复现率达到92.11%。98.1%的PoC避免了硬编码攻击者地址，比基准提升了24.8个百分点。在实时部署中，TxRay在40分钟内提供验证的根本原因，59分钟内生成PoC。

Conclusion: TxRay通过自动化DeFi攻击事后分析，显著提高了分析效率和准确性。其预言机验证的PoC能够实现攻击模拟，在覆盖范围上比现有方法STING和APE分别提高了15.6%和65.5%，为DeFi安全提供了有效的自动化分析工具。

Abstract: Decentralized Finance (DeFi) has turned blockchains into financial infrastructure, allowing anyone to trade, lend, and build protocols without intermediaries, but this openness exposes pools of value controlled by code. Within five years, the DeFi ecosystem has lost over 15.75B USD to reported exploits. Many exploits arise from permissionless opportunities that any participant can trigger using only public state and standard interfaces, which we call Anyone-Can-Take (ACT) opportunities. Despite on-chain transparency, postmortem analysis remains slow and manual: investigations start from limited evidence, sometimes only a single transaction hash, and must reconstruct the exploit lifecycle by recovering related transactions, contract code, and state dependencies.
  We present TxRay, a Large Language Model (LLM) agentic postmortem system that uses tool calls to reconstruct live ACT attacks from limited evidence. Starting from one or more seed transactions, TxRay recovers the exploit lifecycle, derives an evidence-backed root cause, and generates a runnable, self-contained Proof of Concept (PoC) that deterministically reproduces the incident. TxRay self-checks postmortems by encoding incident-specific semantic oracles as executable assertions.
  To evaluate PoC correctness and quality, we develop PoCEvaluator, an independent agentic execution-and-review evaluator. On 114 incidents from DeFiHackLabs, TxRay produces an expert-aligned root cause and an executable PoC for 105 incidents, achieving 92.11% end-to-end reproduction. Under PoCEvaluator, 98.1% of TxRay PoCs avoid hard-coding attacker addresses, a +24.8pp lift over DeFiHackLabs. In a live deployment, TxRay delivers validated root causes in 40 minutes and PoCs in 59 minutes at median latency. TxRay's oracle-validated PoCs enable attack imitation, improving coverage by 15.6% and 65.5% over STING and APE.

</details>


### [27] [Privocracy: Online Democracy through Private Voting](https://arxiv.org/abs/2602.01341)
*Pedro Camponês,Hugo Pereira,Adrian Persaud,Kevin Gallagher,Santiago Torres-Arias*

Main category: cs.CR

TL;DR: Privocracy是一种访问控制机制，通过安全电子投票来执行敏感资源访问命令，减少高权限用户带来的单点故障风险，实现分布式信任。


<details>
  <summary>Details</summary>
Motivation: 传统访问控制中，每个高权限用户都构成潜在漏洞，一旦被攻破会危及多个敏感文件。需要一种机制来最小化高权限分配，同时保持访问控制的灵活性。

Method: 采用安全电子投票机制来决定敏感资源访问，实现分布式信任。系统包含投票委托减少投票疲劳、快速投票轮应对紧急情况、选择性投票审计确保应用级可追溯性等特性。

Result: 实验结果表明Privocracy能高效处理投票，可在商用硬件上部署。投票机制实现永久隐私保护，无论攻击者计算能力如何都能确保投票机密性。

Conclusion: Privocracy通过分布式投票机制最小化系统漏洞，在保持访问控制灵活性的同时，解决了传统高权限用户带来的单点故障问题，具备实际部署的可行性。

Abstract: In traditional access control policies, every access granted and administrative account introduces an additional vulnerability, as a corruption of a high-privilege user can compromise several sensitive files. Privocracy is an access control mechanism that minimizes the need to attribute high privileges by triggering a secure e-voting procedure to run commands that require using sensitive resources. With Privocracy an organization can distribute trust in resource access, minimizing the system vulnerabilities from single points of failure, all while maintaining the high flexibility of discretionary access control policies.
  The Privocracy voting mechanism achieves everlasting privacy, ensuring votes remain confidential regardless of an adversary's computational power, while addressing the dependability requirements of a practical and secure system. The procedure incorporates useful features such as vote delegation to reduce voter fatigue, rapid voting rounds to enable quick action during emergencies, and selective vote auditing for application-level accountability. Our experimental results demonstrate that Privocracy processes votes efficiently and can be deployed on commodity hardware.

</details>


### [28] [Adaptive Quantum-Safe Cryptography for 6G Vehicular Networks via Context-Aware Optimization](https://arxiv.org/abs/2602.01342)
*Poushali Sengupta,Mayank Raikwar,Sabita Maharjan,Frank Eliassen,Yan Zhang*

Main category: cs.CR

TL;DR: 提出自适应后量子密码框架，通过预测移动性和信道变化，动态选择适合的PQC配置，降低延迟和通信开销，并防止算法切换时的攻击。


<details>
  <summary>Details</summary>
Motivation: 未来量子计算机可能破解V2X通信安全，后量子密码学虽能提供保护但会增加计算开销和延迟，对6G车联网构成挑战。

Method: 提出自适应PQC框架，预测短期移动性和信道变化，使用预测多目标进化算法动态选择格基、码基或哈希基PQC配置，并设计安全单调升级协议防止切换攻击。

Result: 端到端延迟降低27%，通信开销减少65%，稳定密码切换行为，单调升级协议成功防止降级、重放和去同步攻击。

Conclusion: 该框架为6G车联网提供了一条实用的量子安全密码学路径，在动态环境中实现安全高效的密码配置切换。

Abstract: Powerful quantum computers in the future may be able to break the security used for communication between vehicles and other devices (Vehicle-to-Everything, or V2X). New security methods called post-quantum cryptography can help protect these systems, but they often require more computing power and can slow down communication, posing a challenge for fast 6G vehicle networks. In this paper, we propose an adaptive post-quantum cryptography (PQC) framework that predicts short-term mobility and channel variations and dynamically selects suitable lattice-, code-, or hash-based PQC configurations using a predictive multi-objective evolutionary algorithm (APMOEA) to meet vehicular latency and security constraints.However, frequent cryptographic reconfiguration in dynamic vehicular environments introduces new attack surfaces during algorithm transitions. A secure monotonic-upgrade protocol prevents downgrade, replay, and desynchronization attacks during transitions. Theoretical results show decision stability under bounded prediction error, latency boundedness under mobility drift, and correctness under small forecast noise. These results demonstrate a practical path toward quantum-safe cryptography in future 6G vehicular networks. Through extensive experiments based on realistic mobility (LuST), weather (ERA5), and NR-V2X channel traces, we show that the proposed framework reduces end-to-end latency by up to 27\%, lowers communication overhead by up to 65\%, and effectively stabilizes cryptographic switching behavior using reinforcement learning. Moreover, under the evaluated adversarial scenarios, the monotonic-upgrade protocol successfully prevents downgrade, replay, and desynchronization attacks.

</details>


### [29] [CIPHER: Cryptographic Insecurity Profiling via Hybrid Evaluation of Responses](https://arxiv.org/abs/2602.01438)
*Max Manolov,Tony Gao,Siddharth Shukla,Cheng-Ting Chou,Ryan Lagasse*

Main category: cs.CR

TL;DR: CIPHER是一个评估LLM生成Python代码中加密漏洞的基准测试，发现即使明确提示"安全"也无法可靠消除加密漏洞


<details>
  <summary>Details</summary>
Motivation: LLM越来越多地用于辅助代码开发，但其生成的加密功能实现常包含可利用的安全漏洞，微小的设计选择可能无声地破坏安全保障

Method: CIPHER基准测试使用不安全/中性/安全三种提示变体，基于加密特定的漏洞分类法，通过自动化评分流水线进行行级归因分析

Result: 在广泛使用的LLM测试中发现，明确的"安全"提示能减少某些特定问题，但无法可靠地整体消除加密漏洞

Conclusion: 需要专门的基准测试来评估LLM生成的加密代码的安全性，即使明确的安全提示也不能保证代码安全

Abstract: Large language models (LLMs) are increasingly used to assist developers with code, yet their implementations of cryptographic functionality often contain exploitable flaws. Minor design choices (e.g., static initialization vectors or missing authentication) can silently invalidate security guarantees. We introduce CIPHER(\textbf{C}ryptographic \textbf{I}nsecurity \textbf{P}rofiling via \textbf{H}ybrid \textbf{E}valuation of \textbf{R}esponses), a benchmark for measuring cryptographic vulnerability incidence in LLM-generated Python code under controlled security-guidance conditions. CIPHER uses insecure/neutral/secure prompt variants per task, a cryptography-specific vulnerability taxonomy, and line-level attribution via an automated scoring pipeline. Across a diverse set of widely used LLMs, we find that explicit ``secure'' prompting reduces some targeted issues but does not reliably eliminate cryptographic vulnerabilities overall. The benchmark and reproducible scoring pipeline will be publicly released upon publication.

</details>


### [30] [DuoLungo: Usability Study of Duo 2FA](https://arxiv.org/abs/2602.01489)
*Renascence Tarafder Prapty,Gene Tsudik*

Main category: cs.CR

TL;DR: 对Duo MFA系统进行的大规模可用性研究显示，其平均认证开销为8秒，失败率4.35%，SUS得分70表明良好可用性，用户认为易用但有些烦人，同时增强了账户安全感。


<details>
  <summary>Details</summary>
Motivation: Duo作为广泛使用的多因素认证系统，虽然被许多大型组织和教育机构采用，但其可用性缺乏全面和最新的研究。先前研究主要关注技术部署挑战，未测量核心可用性指标如任务完成时间或SUS分数，且这些结果已过时，当时用户对MFA还不熟悉。

Method: 在加州大学尔湾分校进行为期一年的长期大规模研究，涉及2559名参与者。使用认证日志数据和57名随机选择用户的调查问卷进行分析，测量任务完成时间、失败率和系统可用性评分。

Result: Duo Push任务平均开销近8秒，用户描述为短到中等；认证失败率4.35%，43.86%受访者报告至少一次登录失败；Duo SUS得分70表明良好可用性。用户普遍认为Duo易用但有些烦人，同时报告账户安全感增强。

Conclusion: Duo MFA系统具有良好的可用性(SUS 70)，但仍有改进空间。用户接受其带来的安全增强，但认证过程中的不便和失败率表明需要进一步优化用户体验。研究提供了当前MFA可用性的最新基准，并为改进提供了具体建议。

Abstract: Multi-Factor Authentication (MFA) enhances login security by requiring multiple authentication factors. Its adoption has increased in response to more frequent and sophisticated attacks. Duo is widely used by organizations including Fortune 500 companies and major educational institutions, yet its usability has not been examined thoroughly or recently. Earlier studies focused on technical challenges during initial deployment but did not measure core usability metrics such as task completion time or System Usability Scale (SUS) scores. These results are also outdated, originating from a time when MFA was less familiar to typical users.
  We conducted a long-term, large-scale Duo usability study at the University of California Irvine during the 2024-2025 academic year, involving 2559 participants. Our analysis uses authentication log data and a survey of 57 randomly selected users. The average overhead of a Duo Push task is nearly 8 seconds, which participants described as short to moderate. Overhead varies with time of day, field of study, and education level. The rate of authentication failures due to incomplete Duo tasks is 4.35 percent, and 43.86 percent of survey respondents reported at least one Duo login failure. The Duo SUS score is 70, indicating good usability. Participants generally find Duo easy to use but somewhat annoying, while also reporting an increased sense of account security. They also described common issues and offered suggestions for improvement.

</details>


### [31] [Sleep Reveals the Nonce: Breaking ECDSA using Sleep-Based Power Side-Channel Vulnerability](https://arxiv.org/abs/2602.01491)
*Sahan Sanjaya,Prabhat Mishra*

Main category: cs.CR

TL;DR: 该论文发现了一种新型侧信道攻击，利用处理器休眠函数引发的上下文切换产生的功率尖峰来提取ECDSA签名中的随机数，即使是在恒定时间和掩码实现下也能成功。


<details>
  <summary>Details</summary>
Motivation: ECDSA签名的安全性依赖于随机数的保密性，即使部分随机数泄露也可能通过格基密码分析暴露长期私钥。传统功率侧信道攻击已被广泛研究，但本文发现了一种先前未被探索的漏洞：休眠诱导的功率尖峰。

Method: 攻击利用处理器上下文切换时产生的功率波动，这些波动与标量乘法中依赖随机数的操作相关。作者在多个密码库（RustCrypto、BearSSL、GoCrypto）和处理器架构（ARM、RISC-V）上评估了该攻击。

Result: 实验表明，休眠诱导上下文切换期间功率包络的细微变化为ECDSA随机数提取提供了足够的泄露，能够恢复20位随机数。攻击在恒定时间和掩码实现下仍然有效。

Conclusion: 休眠诱导功率尖峰是一种实用的跨平台侧信道威胁，需要重新考虑密码系统设计选择以应对这种新型攻击。

Abstract: Security of Elliptic Curve Digital Signature Algorithm (ECDSA) depends on the secrecy of the per-signature nonce. Even partial nonce leakage can expose the long-term private key through lattice-based cryptanalysis. In this paper, we introduce a previously unexplored power side-channel vulnerability that exploits sleep-induced power spikes to extract ECDSA nonces. Unlike conventional power-based side-channel attacks, this vulnerability leverages power fluctuations generated during processor context switches invoked by sleep functions. These fluctuations correlate with nonce-dependent operations in scalar multiplication, enabling nonce recovery even under constant-time and masked implementations. We evaluate the attack across multiple cryptographic libraries, RustCrypto, BearSSL, and GoCrypto, and processor architectures, including ARM and RISC-V. Our experiments show that subtle variations in the power envelope during sleep-induced context switches provide sufficient leakage for practical ECDSA nonce extraction, recovering 20 bits of the nonce. These results establish sleep-induced power spikes as a practical cross-platform side-channel threat and highlight the need to reconsider design choices in cryptographic systems.

</details>


### [32] [Implementation Challenges in Quantum Key Distribution](https://arxiv.org/abs/2602.01500)
*Abel C. H. Chen*

Main category: cs.CR

TL;DR: 该研究在IBM量子平台上实现并比较了BB84和E91两种量子密钥分发协议，使用SX门操作生成均匀量子叠加态，通过实验验证了量子密钥分发在实际量子硬件上的可行性。


<details>
  <summary>Details</summary>
Motivation: 随着量子计算技术的成熟，量子密钥分发(QKD)在网络通信安全领域具有重要应用价值。研究旨在在实际量子计算环境中实现和比较两种主流QKD协议，验证其在实际硬件上的可行性。

Method: 在IBM量子平台上实现BB84和E91协议，使用SX门操作生成均匀量子叠加态，利用量子叠加和量子纠缠特性实现安全密钥分发。评估指标包括熵、独立同分布(IID)和错误率验证。

Result: 实验成功演示了BB84和E91协议在实际量子硬件上的可行性，通过量子叠加和纠缠特性使通信双方能够安全获取共享密钥，同时防止对手拦截。

Conclusion: 该研究证明了量子密钥分发协议在实际量子计算环境中的可行性，为量子安全通信的实际应用提供了实验基础，展示了量子计算技术在网络安全领域的实用价值。

Abstract: In recent years, quantum computing technologies have steadily matured and have begun to find practical applications across various domains. One important area is network communication security, where Quantum Key Distribution (QKD) enables communicating parties to establish a shared secret that can then be used to generate symmetric keys for subsequent encryption and decryption. This study focuses on implementing and comparing two well-known QKD protocols, namely BB84 and E91, within an actual quantum computing environment. It also proposes the use of SX gate operations to generate uniform quantum superposition states. By leveraging the properties of quantum superposition and quantum entanglement, the study illustrates how communicating parties can securely obtain a shared secret while preventing adversaries from intercepting it. The experiments are conducted using the IBM Quantum Platform to demonstrate the feasibility of the BB84 and E91 protocols on actual quantum hardware. The evaluation considers several metrics, including entropy, Independent and Identically Distributed (IID), and error-rate verifications.

</details>


### [33] [Are Security Cues Static? Rethinking Warning and Trust Indicators for Life Transitions](https://arxiv.org/abs/2602.01544)
*Sarah Tabassum*

Main category: cs.CR

TL;DR: 论文提出安全提示（如警告和信任信号）应适应人生过渡阶段（如移民、老龄化），而非保持静态，并提出了过渡感知安全提示框架。


<details>
  <summary>Details</summary>
Motivation: 当前安全提示设计为静态界面元素，但人们的生活、环境和脆弱性会随时间变化。人生过渡（如移民、老龄化、环境变化）会重塑人们对风险和信任的理解与行动方式，而现有系统很少根据这些变化调整安全提示，将解释负担转嫁给用户。

Method: 基于教育移民的实证研究，扩展到其他人生过渡阶段，提出了过渡感知安全提示框架，并通过推测性设计概念展示安全提示如何在过渡阶段演变。

Result: 提出了TASeC框架，展示了安全提示如何适应不同人生过渡阶段的设计概念，为HCI领域重新思考安全提示作为纵向、以生活为中心的设计元素提供了基础。

Conclusion: 安全提示的静态性质与过渡性人生存在设计不匹配，需要将安全提示重新构想为纵向、以生活为中心的设计元素，TASeC框架为此提供了理论基础和设计方向。

Abstract: Security cues, such as warnings and trust signals, are designed as stable interface elements, even though people's lives, contexts, and vulnerabilities change over time. Life transitions including migration, aging, or shifts in institutional environments reshape how risk and trust are understood and acted upon. Yet current systems rarely adapt their security cues to these changing conditions, placing the burden of interpretation on users. In this Works-in-Progress paper, we argue that the static nature of security cues represents a design mismatch with transitional human lives. We draw on prior empirical insights from work on educational migration as a motivating case, and extend the discussion to other life transitions. Building on these insights, we introduce the Transition-Aware Security Cues (TASeC) framework and present speculative design concepts illustrating how security cues might evolve across transition stages. We invite HCI to rethink security cues as longitudinal, life-centered design elements collectively.

</details>


### [34] [HACK NDSU: A Real-world Event to Promote Student Interest in Cybersecurity](https://arxiv.org/abs/2602.01580)
*Enrique Garcia,Jeremy Straub*

Main category: cs.CR

TL;DR: NDSU学生黑客活动：在专业人士监督下扫描、探测和攻击校园网络，提供激励性体验，可能促使学生进入网络安全领域


<details>
  <summary>Details</summary>
Motivation: 为网络安全教育提供创新的实践体验，通过让学生在实际生产系统中进行受监督的黑客活动，激发他们对网络安全领域的兴趣和职业追求

Method: 设计并实施针对生产系统的教育性黑客活动，让学生在专业人士监督下对北达科他州立大学校园网络进行扫描、探测和攻击

Result: 成功创建了首个已知的针对生产系统的教育性黑客活动，为学生提供了激励性体验，可能促进他们进入网络安全领域

Conclusion: 该论文为针对生产系统的教育性黑客活动提供了蓝图，填补了该类型教育活动的空白，展示了这种创新教学方法在激发学生兴趣和培养网络安全人才方面的潜力

Abstract: Hack NDSU let students scan, probe, and hack North Dakota State University's campus network, under professionals' supervision, providing an aspirational experience, potentially motivating them to enter the field. This paper provides a blueprint for educational hacking events against production systems. No prior educational event of this type is known.

</details>


### [35] [Expected Harm: Rethinking Safety Evaluation of (Mis)Aligned LLMs](https://arxiv.org/abs/2602.01600)
*Yen-Shan Chen,Zhi Rui Tam,Cheng-Kuang Wu,Yun-Nung Chen*

Main category: cs.CR

TL;DR: 论文提出Expected Harm指标，结合威胁严重性和执行可能性，发现LLM存在逆向风险校准问题：对低可能性威胁过度拒绝，但对高可能性威胁易受攻击。


<details>
  <summary>Details</summary>
Motivation: 当前LLM安全评估主要依赖基于严重性的分类法，假设所有恶意查询风险相同，忽略了执行可能性（威胁在模型响应后实际发生的条件概率）。这种评估方式需要重新审视。

Method: 引入Expected Harm指标，将越狱严重性按执行可能性加权，执行可能性建模为执行成本的函数。通过线性探测分析模型内部表示，揭示风险校准机制。

Result: 发现模型存在系统性逆向风险校准：对低可能性（高成本）威胁表现出过强的拒绝行为，而对高可能性（低成本）查询保持脆弱。利用这一特性可将现有越狱攻击成功率提升2倍。线性探测显示模型编码严重性但无法区分执行成本。

Conclusion: LLM安全评估需要同时考虑威胁严重性和执行可能性。当前模型缺乏对执行成本的内部表示，导致风险校准失败，造成结构性漏洞。未来安全设计应整合这两个维度。

Abstract: Current evaluations of LLM safety predominantly rely on severity-based taxonomies to assess the harmfulness of malicious queries. We argue that this formulation requires re-examination as it assumes uniform risk across all malicious queries, neglecting Execution Likelihood--the conditional probability of a threat being realized given the model's response. In this work, we introduce Expected Harm, a metric that weights the severity of a jailbreak by its execution likelihood, modeled as a function of execution cost. Through empirical analysis of state-of-the-art models, we reveal a systematic Inverse Risk Calibration: models disproportionately exhibit stronger refusal behaviors for low-likelihood (high-cost) threats while remaining vulnerable to high-likelihood (low-cost) queries. We demonstrate that this miscalibration creates a structural vulnerability: by exploiting this property, we increase the attack success rate of existing jailbreaks by up to $2\times$. Finally, we trace the root cause of this failure using linear probing, which reveals that while models encode severity in their latent space to drive refusal decisions, they possess no distinguishable internal representation of execution cost, making them "blind" to this critical dimension of risk.

</details>


### [36] [Efficient Softmax Reformulation for Homomorphic Encryption via Moment Generating Function](https://arxiv.org/abs/2602.01621)
*Hanjun Park,Byeong-Seo Min,Jiheon Woo,Min-Wook Jeong,Jongho Shin,Yongwoo Lee,Young-Sik Kim,Yongjune Kim*

Main category: cs.CR

TL;DR: MGF-softmax：一种基于矩生成函数的softmax重构方法，用于同态加密中的Transformer推理，通过降低乘法深度提高效率，同时保持近似精度。


<details>
  <summary>Details</summary>
Motivation: 同态加密（HE）是实现隐私保护机器学习的重要框架，但Transformer架构中的核心组件softmax在HE中评估特别困难，原因包括其多元结构、指数函数引起的大动态范围以及归一化过程中需要精确除法。

Method: 提出MGF-softmax，一种基于矩生成函数（MGF）的新型softmax重构方法，用基于矩的对应项替换softmax分母。这种重构显著降低了乘法深度，同时保留了softmax的关键特性，并随着输入token数量的增加渐近收敛到精确softmax。

Result: 在Vision Transformers和大型语言模型上的大量实验表明，MGF-softmax在加密推理中提供了高效且准确的softmax近似。特别是，它实现了接近高深度精确方法的推理精度，同时通过降低乘法深度显著降低了计算成本。

Conclusion: MGF-softmax为同态加密中的softmax评估提供了一种有效的解决方案，在保持精度的同时显著提高了计算效率，有助于推动隐私保护机器学习的发展。

Abstract: Homomorphic encryption (HE) is a prominent framework for privacy-preserving machine learning, enabling inference directly on encrypted data. However, evaluating softmax, a core component of transformer architectures, remains particularly challenging in HE due to its multivariate structure, the large dynamic range induced by exponential functions, and the need for accurate division during normalization. In this paper, we propose MGF-softmax, a novel softmax reformulation based on the moment generating function (MGF) that replaces the softmax denominator with its moment-based counterpart. This reformulation substantially reduces multiplicative depth while preserving key properties of softmax and asymptotically converging to the exact softmax as the number of input tokens increases. Extensive experiments on Vision Transformers and large language models show that MGF-softmax provides an efficient and accurate approximation of softmax in encrypted inference. In particular, it achieves inference accuracy close to that of high-depth exact methods, while requiring substantially lower computational cost through reduced multiplicative depth.

</details>


### [37] [Witnessd: Proof-of-process via Adversarial Collapse](https://arxiv.org/abs/2602.01663)
*David Condrey*

Main category: cs.CR

TL;DR: 论文提出"过程证明"概念和"抖动封印"技术，通过注入基于击键时序的微秒延迟来验证文档是否由真实打字过程生成，而非仅靠数字签名证明密钥拥有。


<details>
  <summary>Details</summary>
Motivation: 数字签名只能证明密钥拥有，无法证明文档创作过程。当前AI生成文本后伪造中间状态并签名，会产生与真实创作过程无法区分的签名链，存在加密完整性与过程来源之间的差距。

Method: 提出"抖动封印"技术：基于HMAC从会话密钥、击键顺序和累积文档哈希生成微秒延迟并注入到打字过程中。构建Witnessd架构，结合可验证延迟函数、外部时间戳锚点、双源击键验证和可选硬件证明，形成多层验证体系。

Result: 在31,000次验证试验中实现了对无效证明的确定性拒绝。系统基于"对抗性崩溃原则"评估：要求质疑真实证据需要协调多个独立信任边界的特定可测试指控。

Conclusion: 系统不能防止伪造（内核级攻击者可以击败它），但能将模糊怀疑转化为可证伪的指控。贡献在于填补加密完整性与过程来源之间的差距，通过多层验证迫使攻击者需要协调多个独立信任边界的指控。

Abstract: Digital signatures prove key possession, not authorship. An author who generates text with AI, constructs intermediate document states post-hoc, and signs each hash produces a signature chain indistinguishable from genuine composition. We address this gap between cryptographic integrity and process provenance. We introduce proof-of-process, a primitive category for evidence that a physical process, not merely a signing key, produced a digital artifact. Our construction, the jitter seal, injects imperceptible microsecond delays derived via HMAC from a session secret, keystroke ordinal, and cumulative document hash. Valid evidence requires that real keystrokes produced the document through those intermediate states. We propose the Adversarial Collapse Principle as an evaluation criterion: evidence systems should be judged by whether disputing them requires a conjunction of specific, testable allegations against components with independent trust assumptions. We present Witnessd, an architecture combining jitter seals with Verifiable Delay Functions, external timestamp anchors, dual-source keystroke validation, and optional hardware attestation. Each layer forces allegations at different capability levels; disputing authentic evidence requires coordinated claims across independent trust boundaries. The system does not prevent forgery: a kernel-level adversary can defeat it, and typing AI-generated content produces valid evidence. The contribution is converting vague doubt into falsifiable allegations. We evaluate across 31,000 verification trials with deterministic rejection of invalid proofs.

</details>


### [38] [Backdoor Sentinel: Detecting and Detoxifying Backdoors in Diffusion Models via Temporal Noise Consistency](https://arxiv.org/abs/2602.01765)
*Bingzheng Wang,Xiaoyan Gu,Hongbo Xu,Hongcheng Li,Zimo Yu,Jiang Zhou,Weiping Wang*

Main category: cs.CR

TL;DR: TNC-Defense：基于时间噪声不一致性的扩散模型后门检测与去毒统一框架，无需模型参数访问，在保持生成质量的同时有效防御后门攻击


<details>
  <summary>Details</summary>
Motivation: 扩散模型在AIGC服务中广泛应用，但其依赖不透明的训练数据和过程存在后门注入风险。实际审计场景中，由于知识产权和商业机密保护，审计者通常无法访问模型参数，使得现有的白盒或查询密集型检测方法不实用。更重要的是，即使检测到后门，现有去毒方法往往在去毒效果和生成质量之间陷入两难。

Method: 提出时间噪声一致性防御（TNC-Defense）统一框架：1）基于相邻时间步噪声一致性设计灰盒检测模块，识别和定位异常扩散时间步；2）利用识别的异常时间步构建触发器无关、时间步感知的去毒模块，直接修正后门生成路径。

Result: 在五种代表性后门攻击场景下评估，TNC-Defense将平均检测准确率提升11%（额外开销可忽略），使平均98.5%的触发样本失效，仅轻微降低生成质量。

Conclusion: 通过发现时间噪声不一致性现象，提出了一种实用的扩散模型后门防御框架，在无需访问模型参数的灰盒设置下，实现了高效的后门检测和去毒，平衡了防御效果和生成质量。

Abstract: Diffusion models have been widely deployed in AIGC services; however, their reliance on opaque training data and procedures exposes a broad attack surface for backdoor injection. In practical auditing scenarios, due to the protection of intellectual property and commercial confidentiality, auditors are typically unable to access model parameters, rendering existing white-box or query-intensive detection methods impractical. More importantly, even after the backdoor is detected, existing detoxification approaches are often trapped in a dilemma between detoxification effectiveness and generation quality.
  In this work, we identify a previously unreported phenomenon called temporal noise unconsistency, where the noise predictions between adjacent diffusion timesteps is disrupted in specific temporal segments when the input is triggered, while remaining stable under clean inputs. Leveraging this finding, we propose Temporal Noise Consistency Defense (TNC-Defense), a unified framework for backdoor detection and detoxification. The framework first uses the adjacent timestep noise consistency to design a gray-box detection module, for identifying and locating anomalous diffusion timesteps. Furthermore, the framework uses the identified anomalous timesteps to construct a trigger-agnostic, timestep-aware detoxification module, which directly corrects the backdoor generation path. This effectively suppresses backdoor behavior while significantly reducing detoxification costs.
  We evaluate the proposed method under five representative backdoor attack scenarios and compare it with state-of-the-art defenses. The results show that TNC-Defense improves the average detection accuracy by $11\%$ with negligible additional overhead, and invalidates an average of $98.5\%$ of triggered samples with only a mild degradation in generation quality.

</details>


### [39] [RedVisor: Reasoning-Aware Prompt Injection Defense via Zero-Copy KV Cache Reuse](https://arxiv.org/abs/2602.01795)
*Mingrui Liu,Sixiao Zhang,Cheng Long,Kwok-Yan Lam*

Main category: cs.CR

TL;DR: RedVisor是一个统一框架，通过轻量级可移除适配器结合检测和预防策略，利用细粒度推理路径同时检测提示注入攻击并指导模型安全响应，在保持骨干模型原始性能的同时实现高效防御。


<details>
  <summary>Details</summary>
Motivation: 当前LLM的提示注入攻击防御面临关键权衡：基于预防的微调会因"对齐税"降低通用性能，而基于检测的过滤则带来高延迟和内存成本。需要一种能兼顾检测可解释性和预防无缝集成的解决方案。

Method: 提出RedVisor框架，在冻结骨干模型之上部署轻量级可移除适配器。该适配器首先生成可解释分析，精确定位注入并阐明威胁，然后显式指导模型拒绝恶意指令。适配器仅在推理阶段激活，在响应生成阶段静默，并采用KV Cache重用策略消除冗余计算。

Result: RedVisor在检测准确率和吞吐量方面优于现有最先进防御方法，同时带来可忽略的性能损失。实验证明该框架能数学上保持骨干模型在良性输入上的原始性能。

Conclusion: RedVisor成功统一了检测和预防策略，通过可解释的细粒度推理路径实现了高效提示注入防御，在保持模型性能的同时显著提升安全性，并已集成到vLLM服务引擎中。

Abstract: Large Language Models (LLMs) are increasingly vulnerable to Prompt Injection (PI) attacks, where adversarial instructions hidden within retrieved contexts hijack the model's execution flow. Current defenses typically face a critical trade-off: prevention-based fine-tuning often degrades general utility via the "alignment tax", while detection-based filtering incurs prohibitive latency and memory costs. To bridge this gap, we propose RedVisor, a unified framework that synthesizes the explainability of detection systems with the seamless integration of prevention strategies. To the best of our knowledge, RedVisor is the first approach to leverage fine-grained reasoning paths to simultaneously detect attacks and guide the model's safe response. We implement this via a lightweight, removable adapter positioned atop the frozen backbone. This adapter serves a dual function: it first generates an explainable analysis that precisely localizes the injection and articulates the threat, which then explicitly conditions the model to reject the malicious command. Uniquely, the adapter is active only during this reasoning phase and is effectively muted during the subsequent response generation. This architecture yields two distinct advantages: (1) it mathematically preserves the backbone's original utility on benign inputs; and (2) it enables a novel KV Cache Reuse strategy, eliminating the redundant prefill computation inherent to decoupled pipelines. We further pioneer the integration of this defense into the vLLM serving engine with custom kernels. Experiments demonstrate that RedVisor outperforms state-of-the-art defenses in detection accuracy and throughput while incurring negligible utility loss.

</details>


### [40] [Things that Matter -- Identifying Interactions and IoT Device Types in Encrypted Matter Traffic](https://arxiv.org/abs/2602.01932)
*Kristopher Alex Schlett,Bela Genge,Savio Sciancalepore*

Main category: cs.CR

TL;DR: Matter物联网标准存在加密流量分析漏洞，被动攻击者可通过分析加密流量模式推断设备交互和设备类型，准确率分别超过95%和88%，构成严重隐私泄露风险。


<details>
  <summary>Details</summary>
Motivation: Matter作为最新的物联网应用层标准，虽然设计上特别关注安全和隐私，但缺乏对被动攻击者通过分析加密流量模式来推断信息的系统性研究。本研究旨在填补这一空白，评估Matter标准对加密流量分析的鲁棒性。

Method: 通过收集真实世界测试平台和模拟设置中的各种数据集，分析加密Matter流量的元数据模式，识别允许推断终端设备与控制器之间特定交互的模式，并将交互序列模式与特定类型的物联网设备关联。

Result: 研究发现：1）即使在存在数据包丢失和延迟的情况下，也能以超过95%的准确率识别加密流量中的特定Matter交互；2）能以最低88%的准确率识别Matter设备类型；3）这些模式可用于创建指纹，使被动攻击者能够推断网络中使用的设备类型。

Conclusion: Matter物联网标准存在严重的加密流量分析漏洞，被动攻击者可通过分析流量模式推断设备交互和设备类型，构成严重的用户隐私泄露风险。连接标准联盟（CSA）已承认这些发现，并表示愿意在标准的下一个版本中解决这些漏洞。

Abstract: Matter is the most recent application-layer standard for the Internet of Things (IoT). As one of its major selling points, Matter's design imposes particular attention to security and privacy: it provides validated secure session establishment protocols, and it uses robust security algorithms to secure communications between IoT devices and Matter controllers. However, to our knowledge, there is no systematic analysis investigating the extent to which a passive attacker, in possession of lower layer keys or exploiting security misconfiguration at those layers, could infer information by passively analyzing encrypted Matter traffic. In this paper, we fill this gap by analyzing the robustness of the Matter IoT standard to encrypted traffic analysis performed by a passive eavesdropper. By using various datasets collected from real-world testbeds and simulated setups, we identify patterns in metadata of the encrypted Matter traffic that allow inferring the specific interactions occurring between end devices and controllers. Moreover, we associate patterns in sequences of interactions to specific types of IoT devices. These patterns can be used to create fingerprints that allow a passive attacker to infer the type of devices used in the network, constituting a serious breach of users privacy. Our results reveal that we can identify specific Matter interactions that occur in encrypted traffic with over $95\%$ accuracy also in the presence of packet losses and delays. Moreover, we can identify Matter device types with a minimum accuracy of $88\%$. The CSA acknowledged our findings, and expressed the willingness to address such vulnerabilities in the next releases of the standard.

</details>


### [41] [Human Society-Inspired Approaches to Agentic AI Security: The 4C Framework](https://arxiv.org/abs/2602.01942)
*Alsharif Abuadbba,Nazatul Sultan,Surya Nepal,Sanjay Jha*

Main category: cs.CR

TL;DR: 本文提出了4C框架，用于多智能体AI安全，从系统中心防护转向行为完整性和意图保护，涵盖核心、连接、认知和合规四个维度。


<details>
  <summary>Details</summary>
Motivation: AI正从封闭可预测环境转向由大语言模型驱动的智能体，在开放跨组织环境中规划和行动，导致网络安全风险格局发生根本变化。现有系统中心方法可能无法捕捉自主性、交互和涌现行为带来的风险。

Method: 提出4C框架，受社会治理启发，将智能体风险组织到四个相互依赖的维度：核心（系统、基础设施和环境完整性）、连接（通信、协调和信任）、认知（信念、目标和推理完整性）和合规（伦理、法律和制度治理）。

Result: 该框架将AI安全从狭隘的系统中心保护扩展到更广泛的行为完整性和意图保护，补充现有AI安全策略，为构建可信、可治理且与人类价值观一致的智能体AI系统提供原则性基础。

Conclusion: 4C框架为多智能体AI安全提供了系统性方法，通过关注核心、连接、认知和合规四个维度，能够更好地应对自主智能体在复杂社会技术生态系统中带来的新型安全风险。

Abstract: AI is moving from domain-specific autonomy in closed, predictable settings to large-language-model-driven agents that plan and act in open, cross-organizational environments. As a result, the cybersecurity risk landscape is changing in fundamental ways. Agentic AI systems can plan, act, collaborate, and persist over time, functioning as participants in complex socio-technical ecosystems rather than as isolated software components. Although recent work has strengthened defenses against model and pipeline level vulnerabilities such as prompt injection, data poisoning, and tool misuse, these system centric approaches may fail to capture risks that arise from autonomy, interaction, and emergent behavior. This article introduces the 4C Framework for multi-agent AI security, inspired by societal governance. It organizes agentic risks across four interdependent dimensions: Core (system, infrastructure, and environmental integrity), Connection (communication, coordination, and trust), Cognition (belief, goal, and reasoning integrity), and Compliance (ethical, legal, and institutional governance). By shifting AI security from a narrow focus on system-centric protection to the broader preservation of behavioral integrity and intent, the framework complements existing AI security strategies and offers a principled foundation for building agentic AI systems that are trustworthy, governable, and aligned with human values.

</details>


### [42] [HPE: Hallucinated Positive Entanglement for Backdoor Attacks in Federated Self-Supervised Learning](https://arxiv.org/abs/2602.02147)
*Jiayao Wang,Yang Song,Zhendong Zhao,Jiale Zhang,Qilin Wu,Wenliang Yuan,Junwu Zhu,Dongfang Zhao*

Main category: cs.CR

TL;DR: 提出一种名为HPE的新型联邦自监督学习后门攻击方法，通过幻觉增强和特征纠缠技术显著提升攻击效果和持久性


<details>
  <summary>Details</summary>
Motivation: 现有的联邦自监督学习后门攻击方法存在中毒样本利用率低、可迁移性有限、持久性弱等问题，需要更有效的攻击方法

Method: HPE方法：1) 使用幻觉增强技术通过合成正样本来增强编码器对后门特征的嵌入；2) 引入特征纠缠强制触发器和后门样本在表示空间中的紧密绑定；3) 采用选择性参数中毒和邻近感知更新将中毒模型约束在全局模型附近，增强稳定性和持久性

Result: 在多个联邦自监督学习场景和数据集上的实验结果表明，HPE在性能上显著优于现有后门攻击方法，并在各种防御机制下表现出强大的鲁棒性

Conclusion: HPE方法有效解决了现有联邦自监督学习后门攻击的局限性，提供了更强大、更持久的攻击能力，突显了联邦自监督学习安全性的脆弱性

Abstract: Federated self-supervised learning (FSSL) enables collaborative training of self-supervised representation models without sharing raw unlabeled data. While it serves as a crucial paradigm for privacy-preserving learning, its security remains vulnerable to backdoor attacks, where malicious clients manipulate local training to inject targeted backdoors. Existing FSSL attack methods, however, often suffer from low utilization of poisoned samples, limited transferability, and weak persistence. To address these limitations, we propose a new backdoor attack method for FSSL, namely Hallucinated Positive Entanglement (HPE). HPE first employs hallucination-based augmentation using synthetic positive samples to enhance the encoder's embedding of backdoor features. It then introduces feature entanglement to enforce tight binding between triggers and backdoor samples in the representation space. Finally, selective parameter poisoning and proximity-aware updates constrain the poisoned model within the vicinity of the global model, enhancing its stability and persistence. Experimental results on several FSSL scenarios and datasets show that HPE significantly outperforms existing backdoor attack methods in performance and exhibits strong robustness under various defense mechanisms.

</details>


### [43] [Malware Detection Through Memory Analysis](https://arxiv.org/abs/2602.02184)
*Sarah Nassar*

Main category: cs.CR

TL;DR: 使用XGBoost模型在MalMemAnalysis-2022数据集上进行恶意软件检测，二分类准确率达99.98%，多分类准确率达87.54%，分类速度快，适用于实时检测。


<details>
  <summary>Details</summary>
Motivation: 探索机器学习技术在恶意软件检测中的有效性和效率，特别是针对二分类（良性/恶意）和多分类（良性/勒索软件/间谍软件/木马），旨在开发准确且实时的混淆恶意软件检测器以提升在线隐私和安全。

Method: 使用加拿大网络安全研究所的MalMemAnalysis-2022数据集，采用XGBoost模型进行恶意软件检测。选择XGBoost是因为其在检测能力和推理速度之间的良好平衡。进行了二分类（良性/恶意）和多分类（良性/勒索软件/间谍软件/木马）两种任务。

Result: 二分类模型在测试集上准确率和F1分数均达到99.98%；多分类模型准确率为87.54%，F1分数为81.26%，恶意软件子类型的平均F1分数为75.03%。分类速度方面，二分类设置下顺序分类50个样本约需37.3毫秒，多分类设置下约需43.2毫秒。

Conclusion: XGBoost模型在恶意软件检测中表现出色，不仅具有高准确率，而且分类速度快，有助于开发准确且实时的混淆恶意软件检测器，从而提升在线隐私和安全。该研究是ELEC 877（网络安全人工智能）课程项目的一部分。

Abstract: This paper summarizes the research conducted for a malware detection project using the Canadian Institute for Cybersecurity's MalMemAnalysis-2022 dataset. The purpose of the project was to explore the effectiveness and efficiency of machine learning techniques for the task of binary classification (i.e., benign or malicious) as well as multi-class classification to further include three malware sub-types (i.e., benign, ransomware, spyware, or Trojan horse). The XGBoost model type was the final model selected for both tasks due to the trade-off between strong detection capability and fast inference speed. The binary classifier achieved a testing subset accuracy and F1 score of 99.98\%, while the multi-class version reached an accuracy of 87.54\% and an F1 score of 81.26\%, with an average F1 score over the malware sub-types of 75.03\%. In addition to the high modelling performance, XGBoost is also efficient in terms of classification speed. It takes about 37.3 milliseconds to classify 50 samples in sequential order in the binary setting and about 43.2 milliseconds in the multi-class setting. The results from this research project help advance the efforts made towards developing accurate and real-time obfuscated malware detectors for the goal of improving online privacy and safety. *This project was completed as part of ELEC 877 (AI for Cybersecurity) in the Winter 2024 term.

</details>


### [44] [QuietPrint: Protecting 3D Printers Against Acoustic Side-Channel Attacks](https://arxiv.org/abs/2602.02198)
*Seyed Ali Ghazi Asgar,Narasimha Reddy*

Main category: cs.CR

TL;DR: 提出一种通过修改G代码保护3D打印机免受声学侧信道攻击的方法，无需额外硬件


<details>
  <summary>Details</summary>
Motivation: 3D打印市场快速增长，但针对3D打印过程的网络攻击日益普遍，特别是通过声学侧信道窃取设计文件的知识产权盗窃问题

Method: 通过最小化修改G代码来保护打印部件，无需额外硬件（如大型扬声器或噪声消除设备）

Result: 提出了一种新颖的保护方法，能够有效防御声学侧信道攻击，保护知识产权

Conclusion: 该方法为3D打印机提供了一种低成本、高效的保护方案，通过软件层面的G代码修改即可实现安全防护

Abstract: The 3D printing market has experienced significant growth in recent years, with an estimated revenue of 15 billion USD for 2025. Cyber-attacks targeting the 3D printing process whether through the machine itself, the supply chain, or the fabricated components are becoming increasingly common. One major concern is intellectual property (IP) theft, where a malicious attacker gains access to the design file. One method for carrying out such theft is through side-channel attacks. In this work, we investigate the possibility of IP theft via acoustic side channels and propose a novel method to protect 3D printers against such attacks. The primary advantage of our approach is that it requires no additional hardware, such as large speakers or noise-canceling devices. Instead, it secures printed parts by minimal modifications to the G-code.

</details>


### [45] [SysFuSS: System-Level Firmware Fuzzing with Selective Symbolic Execution](https://arxiv.org/abs/2602.02243)
*Dakshina Tharindu,Aruna Jayasena,Prabhat Mishra*

Main category: cs.CR

TL;DR: SysFuSS是一个高效的固件验证框架，通过将系统级模糊测试与选择性符号执行相结合，解决了传统模糊测试在检测固件漏洞时的覆盖瓶颈问题。


<details>
  <summary>Details</summary>
Motivation: 固件作为计算系统中硬件和软件的关键接口，其漏洞可能导致灾难性系统故障。传统模糊测试方法在检测固件漏洞时存在两个主要问题：1）专注于用户级模糊测试，不适合检测内核级漏洞；2）面对固件与硬件复杂交互时会出现覆盖瓶颈问题。

Method: SysFuSS框架整合了系统级模糊测试和选择性符号执行。首先使用系统级仿真进行初始模糊测试，当覆盖率达到瓶颈时自动切换到符号执行。这种策略能够生成针对性的测试用例，触发固件设计中先前未探索的区域。

Result: 在OpenSSL、WolfBoot、WolfMQTT、HTSlib、MXML和libIEC等真实世界嵌入式固件上的实验评估表明，SysFuSS在分支覆盖率和漏洞检测方面显著优于最先进的模糊测试工具。具体来说，SysFuSS能够检测118个已知漏洞，而现有最佳工具只能覆盖其中的13个。此外，SysFuSS激活这些漏洞所需时间显著减少（最多3.3倍，平均1.7倍）。

Conclusion: SysFuSS通过系统级模糊测试与选择性符号执行的智能结合，有效解决了固件验证中的覆盖瓶颈问题，显著提高了固件漏洞检测的效率和效果，为固件安全验证提供了更强大的工具。

Abstract: Firmware serves as the critical interface between hardware and software in computing systems, making any bugs or vulnerabilities particularly dangerous as they can cause catastrophic system failures. While fuzzing is a promising approach for identifying design flaws and security vulnerabilities, traditional fuzzers are ineffective at detecting firmware vulnerabilities. For example, existing fuzzers focus on user-level fuzzing, which is not suitable for detecting kernel-level vulnerabilities. Existing fuzzers also face a coverage plateau problem when dealing with complex interactions between firmware and hardware. In this paper, we present an efficient firmware verification framework, SysFuSS, that integrates system-level fuzzing with selective symbolic execution. Our approach leverages system-level emulation for initial fuzzing, and automatically transitions to symbolic execution when coverage reaches a plateau. This strategy enables us to generate targeted test cases that can trigger previously unexplored regions in firmware designs. We have evaluated SysFuSS on real-world embedded firmware, including OpenSSL, WolfBoot, WolfMQTT, HTSlib, MXML, and libIEC. Experimental evaluation demonstrates that SysFuSS significantly outperforms state-of-the-art fuzzers in terms of both branch coverage and detection of firmware vulnerabilities. Specifically, SysFuSS can detect 118 known vulnerabilities while state-of-the-art can cover only 13 of them. Moreover, SysFuSS takes significantly less time (up to 3.3X, 1.7X on average) to activate these vulnerabilities.

</details>


### [46] [Provenance Verification of AI-Generated Images via a Perceptual Hash Registry Anchored on Blockchain](https://arxiv.org/abs/2602.02412)
*Apoorv Mohit,Bhavya Aggarwal,Chinmay Gondhalekar*

Main category: cs.CR

TL;DR: 提出基于区块链的AI生成图像验证框架，通过注册机制追踪图像来源，使用感知哈希和混合存储结构实现可扩展的防篡改验证


<details>
  <summary>Details</summary>
Motivation: AI生成图像的普及带来了虚假信息、数字伪造和内容真实性等担忧，需要可扩展的验证机制来确保在线平台上的内容可信度

Method: 使用感知哈希为AI生成图像创建数字指纹，通过混合区块链存储（链上Merkle Patricia Trie和链下Burkhard-Keller树）实现防篡改存储和高效相似性搜索

Result: 建立了平台无关的防篡改验证系统，能够识别经过良性变换或部分修改的已注册AI生成图像，补充现有水印和基于学习的检测方法

Conclusion: 该框架为大规模在线分发提供了可扩展的内容来源和真实性验证机制，专注于验证创建时注册的AI生成内容，而非检测所有合成图像

Abstract: The rapid advancement of artificial intelligence has made the generation of synthetic images widely accessible, increasing concerns related to misinformation, digital forgery, and content authenticity on large-scale online platforms. This paper proposes a blockchain-backed framework for verifying AI-generated images through a registry-based provenance mechanism. Each AI-generated image is assigned a digital fingerprint that preserves similarity using perceptual hashing and is registered at creation time by participating generation platforms. The hashes are stored on a hybrid on-chain/off-chain public blockchain using a Merkle Patricia Trie for tamper-resistant storage (on-chain) and a Burkhard-Keller tree (off-chain) to enable efficient similarity search over large image registries. Verification is performed when images are re-uploaded to digital platforms such as social media services, enabling identification of previously registered AI-generated images even after benign transformations or partial modifications. The proposed system does not aim to universally detect all synthetic images, but instead focuses on verifying the provenance of AI-generated content that has been registered at creation time. By design, this approach complements existing watermarking and learning-based detection methods, providing a platform-agnostic, tamper-proof mechanism for scalable content provenance and authenticity verification at the point of large-scale online distribution.

</details>
