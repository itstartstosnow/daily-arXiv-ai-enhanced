<div id=toc></div>

# Table of Contents

- [cs.CR](#cs.CR) [Total: 20]


<div id='cs.CR'></div>

# cs.CR [[Back]](#toc)

### [1] [Transferable Backdoor Attacks for Code Models via Sharpness-Aware Adversarial Perturbation](https://arxiv.org/abs/2602.11213)
*Shuyu Chang,Haiping Huang,Yanjun Zhang,Yujin Huang,Fu Xiao,Leo Yu Zhang*

Main category: cs.CR

TL;DR: STAB是一种针对代码模型的隐蔽后门攻击方法，通过结合平坦损失区域优化和上下文感知触发器生成，在保持可转移性的同时实现隐蔽性，无需完整的受害者数据。


<details>
  <summary>Details</summary>
Motivation: 现有代码模型后门攻击面临可转移性与隐蔽性的权衡：静态触发器攻击可转移性好但易被检测，动态触发器攻击隐蔽但跨数据集可转移性差且依赖不现实的假设。

Method: 使用Sharpness-Aware Minimization训练代理模型引导参数到平坦损失区域，结合Gumbel-Softmax优化实现离散触发器令牌的可微分搜索，生成上下文感知的对抗性触发器。

Result: 在三个数据集和两个代码模型上的实验表明，STAB在防御后达到73.2%的平均攻击成功率，优于静态触发器攻击（防御下失效），跨数据集攻击成功率比最佳动态触发器攻击高12.4%，且保持干净输入性能。

Conclusion: STAB成功解决了代码模型后门攻击中可转移性与隐蔽性的权衡问题，无需完整受害者数据，为代码模型安全提供了新的攻击视角。

Abstract: Code models are increasingly adopted in software development but remain vulnerable to backdoor attacks via poisoned training data. Existing backdoor attacks on code models face a fundamental trade-off between transferability and stealthiness. Static trigger-based attacks insert fixed dead code patterns that transfer well across models and datasets but are easily detected by code-specific defenses. In contrast, dynamic trigger-based attacks adaptively generate context-aware triggers to evade detection but suffer from poor cross-dataset transferability. Moreover, they rely on unrealistic assumptions of identical data distributions between poisoned and victim training data, limiting their practicality. To overcome these limitations, we propose Sharpness-aware Transferable Adversarial Backdoor (STAB), a novel attack that achieves both transferability and stealthiness without requiring complete victim data. STAB is motivated by the observation that adversarial perturbations in flat regions of the loss landscape transfer more effectively across datasets than those in sharp minima. To this end, we train a surrogate model using Sharpness-Aware Minimization to guide model parameters toward flat loss regions, and employ Gumbel-Softmax optimization to enable differentiable search over discrete trigger tokens for generating context-aware adversarial triggers. Experiments across three datasets and two code models show that STAB outperforms prior attacks in terms of transferability and stealthiness. It achieves a 73.2% average attack success rate after defense, outperforming static trigger-based attacks that fail under defense. STAB also surpasses the best dynamic trigger-based attack by 12.4% in cross-dataset attack success rate and maintains performance on clean inputs.

</details>


### [2] [Yaksha-Prashna: Understanding eBPF Bytecode Network Function Behavior](https://arxiv.org/abs/2602.11232)
*Animesh Singh,K Shiv Kumar,S. VenkataKeerthy,Pragna Mamidipaka,R V B R N Aaseesh,Sayandeep Sen,Palanivel Kodeswaran,Theophilus A. Benson,Ramakrishna Upadrasta,Praveen Tammana*

Main category: cs.CR

TL;DR: Yaksha-Prashna是一个系统，允许云运营商和开发者验证eBPF字节码是否符合规范并检查与其他字节码的依赖关系，无需访问源代码，实现200-1000倍的性能提升。


<details>
  <summary>Details</summary>
Motivation: 云基础设施组织越来越多地依赖第三方eBPF网络功能，但这些功能以字节码形式提供，运营商无法验证其功能正确性和与其他网络功能的交互。同时，eBPF开发者希望在不公开源代码的情况下证明其网络功能的正确性。

Method: 设计Yaksha-Prashna系统，构建领域特定模型，采用可扩展的程序分析技术来提取和建模eBPF程序。通过Yaksha-Prashna语言表达属性验证。

Result: 在标准和非常规eBPF网络功能上表达了24个属性，相比最先进的工作实现了200-1000倍的加速。

Conclusion: Yaksha-Prashna系统有效解决了第三方eBPF网络功能验证问题，既保护了开发者的知识产权，又为运营商提供了验证能力，显著提升了验证效率。

Abstract: Many cloud infrastructure organizations increasingly rely on third-party eBPF-based network functions for use cases like security, observability, and load balancing, so that not everyone requires a team of highly skilled eBPF experts. However, the network functions from third parties (e.g., F5, Palo Alto) are available in bytecode format to cloud operators, giving little or no understanding of their functional correctness and interaction with other network functions in a chain. Also, eBPF developers want to provide proof of functional correctness for their developed network functions without disclosing the source code to the operators. We design Yaksha-Prashna, a system that allows operators/developers to assert and query bytecode's conformance to its specification and dependencies on other bytecodes. Our work builds domain-specific models that enable us to employ scalable program analysis to extract and model eBPF programs. Using Yaksha-Prashna language, we express 24 properties on standard and non-standard eBPF-based network functions with 200-1000x speedup over the state-of-the-art work.

</details>


### [3] [Peak + Accumulation: A Proxy-Level Scoring Formula for Multi-Turn LLM Attack Detection](https://arxiv.org/abs/2602.11247)
*J Alex Corll*

Main category: cs.CR

TL;DR: 提出了一种针对多轮提示注入攻击的检测公式，结合峰值风险、持续性和类别多样性评分，在代理层实现无需调用LLM的对话级风险评估。


<details>
  <summary>Details</summary>
Motivation: 多轮提示注入攻击将恶意意图分散到多个对话轮次中，而现有方法主要关注单轮检测，缺乏有效的对话级风险评估公式。直观的加权平均方法存在根本缺陷：无论轮次多少，最终得分都收敛于单轮得分，导致20轮的持续攻击与单轮可疑对话得分相同。

Method: 借鉴变化点检测(CUSUM)、贝叶斯信念更新和安全风险警报的思想，提出"峰值+累积"评分公式，结合峰值单轮风险、持续性比率和类别多样性三个要素。公式在代理层运行，无需调用LLM。

Result: 在10,654个多轮对话数据集上评估（588个攻击来自WildJailbreak，10,066个良性对话来自WildChat），该公式在1.20%误报率下达到90.8%的召回率，F1分数为85.9%。持续性参数敏感性分析显示在rho≈0.4处存在相变，召回率跃升12个百分点而误报率几乎不变。

Conclusion: 提出的"峰值+累积"评分公式能有效检测多轮提示注入攻击，解决了加权平均方法的根本缺陷。算法、模式库和评估工具已开源发布，为代理层多轮攻击检测提供了实用解决方案。

Abstract: Multi-turn prompt injection attacks distribute malicious intent across multiple conversation turns, exploiting the assumption that each turn is evaluated independently. While single-turn detection has been extensively studied, no published formula exists for aggregating per-turn pattern scores into a conversation-level risk score at the proxy layer -- without invoking an LLM. We identify a fundamental flaw in the intuitive weighted-average approach: it converges to the per-turn score regardless of turn count, meaning a 20-turn persistent attack scores identically to a single suspicious turn. Drawing on analogies from change-point detection (CUSUM), Bayesian belief updating, and security risk-based alerting, we propose peak + accumulation scoring -- a formula combining peak single-turn risk, persistence ratio, and category diversity. Evaluated on 10,654 multi-turn conversations -- 588 attacks sourced from WildJailbreak adversarial prompts and 10,066 benign conversations from WildChat -- the formula achieves 90.8% recall at 1.20% false positive rate with an F1 of 85.9%. A sensitivity analysis over the persistence parameter reveals a phase transition at rho ~ 0.4, where recall jumps 12 percentage points with negligible FPR increase. We release the scoring algorithm, pattern library, and evaluation harness as open source.

</details>


### [4] [CryptoAnalystBench: Failures in Multi-Tool Long-Form LLM Analysis](https://arxiv.org/abs/2602.11304)
*Anushri Eswaran,Oleg Golev,Darshan Tank,Sidhant Rahi,Himanshu Tyagi*

Main category: cs.CR

TL;DR: 论文提出CryptoAnalystBench基准测试，用于评估LLM在多工具集成分析任务中的表现，识别了7种高阶错误类型，并开发了评估框架。


<details>
  <summary>Details</summary>
Motivation: 现有研究主要关注工具调用基准和知识增强系统的准确性，但缺乏对LLM集成大量动态、结构化与非结构化多工具输出的能力研究。特别是在高数据密度领域（如加密货币），需要评估LLM处理复杂分析任务时的失败模式。

Method: 1) 创建CryptoAnalystBench：包含198个实际加密货币和DeFi查询，涵盖11个类别；2) 构建代理框架：配备相关加密工具，在多个前沿LLM上生成响应；3) 开发评估流程：包含引用验证和基于LLM的评判标准，涵盖相关性、时间相关性、深度和数据一致性四个维度。

Result: 通过人工标注识别出7种高阶错误类型，这些错误无法通过事实检查或基于LLM的质量评分可靠捕获。即使最先进的系统也存在这些失败，可能影响高风险决策。改进后的评判标准能可靠识别关键失败模式，为开发者提供可扩展的反馈。

Conclusion: 论文提供了完整的评估框架、错误分类和缓解策略，为研究长格式、多工具增强系统的评估方法奠定了基础，并指出了该领域的开放挑战。

Abstract: Modern analyst agents must reason over complex, high token inputs, including dozens of retrieved documents, tool outputs, and time sensitive data. While prior work has produced tool calling benchmarks and examined factuality in knowledge augmented systems, relatively little work studies their intersection: settings where LLMs must integrate large volumes of dynamic, structured and unstructured multi tool outputs. We investigate LLM failure modes in this regime using crypto as a representative high data density domain. We introduce (1) CryptoAnalystBench, an analyst aligned benchmark of 198 production crypto and DeFi queries spanning 11 categories; (2) an agentic harness equipped with relevant crypto and DeFi tools to generate responses across multiple frontier LLMs; and (3) an evaluation pipeline with citation verification and an LLM as a judge rubric spanning four user defined success dimensions: relevance, temporal relevance, depth, and data consistency. Using human annotation, we develop a taxonomy of seven higher order error types that are not reliably captured by factuality checks or LLM based quality scoring. We find that these failures persist even in state of the art systems and can compromise high stakes decisions. Based on this taxonomy, we refine the judge rubric to better capture these errors. While the judge does not align with human annotators on precise scoring across rubric iterations, it reliably identifies critical failure modes, enabling scalable feedback for developers and researchers studying analyst style agents. We release CryptoAnalystBench with annotated queries, the evaluation pipeline, judge rubrics, and the error taxonomy, and outline mitigation strategies and open challenges in evaluating long form, multi tool augmented systems.

</details>


### [5] [Security Threat Modeling for Emerging AI-Agent Protocols: A Comparative Analysis of MCP, A2A, Agora, and ANP](https://arxiv.org/abs/2602.11327)
*Zeynab Anbiaee,Mahdi Rabbani,Mansur Mirani,Gunjan Piya,Igor Opushnyev,Ali Ghorbani,Sajjad Dadkhah*

Main category: cs.CR

TL;DR: 本文系统分析了四种新兴AI代理通信协议（MCP、A2A、Agora、ANP）的安全风险，提出了结构化威胁建模方法和定性风险评估框架，并通过MCP案例研究量化了安全风险。


<details>
  <summary>Details</summary>
Motivation: AI代理通信协议（如MCP、A2A、Agora、ANP）快速发展，支持可扩展的多代理交互和跨组织互操作性，但其安全原则研究不足，缺乏标准化的威胁建模和协议中心化风险评估框架。

Method: 1. 开发结构化威胁建模分析，检查协议架构、信任假设、交互模式和生命周期行为；2. 引入定性风险评估框架，识别12个协议级风险，评估创建、操作和更新阶段的安全态势；3. 对MCP进行测量驱动案例研究，形式化缺失强制验证/认证的风险。

Result: 识别了关键设计引发的风险面，提供了可操作的安全部署指南，量化了多服务器组合下错误提供者工具执行的风险，为代理通信生态系统的安全部署和未来标准化提供了依据。

Conclusion: 研究结果强调了AI代理通信协议中关键的设计风险面，为安全部署和未来标准化提供了实用指导，填补了协议中心化风险评估框架的空白。

Abstract: The rapid development of the AI agent communication protocols, including the Model Context Protocol (MCP), Agent2Agent (A2A), Agora, and Agent Network Protocol (ANP), is reshaping how AI agents communicate with tools, services, and each other. While these protocols support scalable multi-agent interaction and cross-organizational interoperability, their security principles remain understudied, and standardized threat modeling is limited; no protocol-centric risk assessment framework has been established yet. This paper presents a systematic security analysis of four emerging AI agent communication protocols. First, we develop a structured threat modeling analysis that examines protocol architectures, trust assumptions, interaction patterns, and lifecycle behaviors to identify protocol-specific and cross-protocol risk surfaces. Second, we introduce a qualitative risk assessment framework that identifies twelve protocol-level risks and evaluates security posture across the creation, operation, and update phases through systematic assessment of likelihood, impact, and overall protocol risk, with implications for secure deployment and future standardization. Third, we provide a measurement-driven case study on MCP that formalizes the risk of missing mandatory validation/attestation for executable components as a falsifiable security claim by quantifying wrong-provider tool execution under multi-server composition across representative resolver policies. Collectively, our results highlight key design-induced risk surfaces and provide actionable guidance for secure deployment and future standardization of agent communication ecosystems.

</details>


### [6] [Modelling Trust and Trusted Systems: A Category Theoretic Approach](https://arxiv.org/abs/2602.11376)
*Ian Oliver,Pekka Kuure*

Main category: cs.CR

TL;DR: 提出基于范畴论的信任建模框架，用于可信计算系统和远程证明，将信任元素、声明、结果和决策形式化为范畴对象，证明、验证和决策过程形式化为态射，使用Heyting代数形式化信任决策空间，支持超越二元信任的细致信任级别。


<details>
  <summary>Details</summary>
Motivation: 为可信计算系统和远程证明中的信任建模提供严格的数学基础，明确定义"可信度"和"合理性/取证"等术语的语义，解决传统二元信任模型的局限性。

Method: 使用范畴论框架，将信任元素、声明、结果和决策建模为对象，证明、验证和决策过程建模为态射；使用Heyting代数形式化信任决策空间；利用范畴论中的指数运算定义证明操作的组合，为证明环境的表达能力提供度量基础。

Result: 提出了完整的信任建模框架，包括多个工作示例（启动-运行-关闭序列、Evil Maid攻击、基于该模型的证明环境规范），并解决了多组合动态大系统建模的挑战。

Conclusion: 该范畴论框架为信任建模提供了严格的数学基础，支持细致的信任级别和证明操作的组合分析，能够应对动态复杂系统的信任建模需求。

Abstract: We introduces a category-theoretic framework for modelling trust as applied to trusted computation systems and remote attestation. By formalizing elements, claims, results, and decisions as objects within a category, and the processes of attestation, verification, and decision-making as morphisms, the framework provides a rigorous approach to understanding trust establishment and provides a well-defined semantics for terms such as `trustworthiness' and 'justification'/forensics. The trust decision space is formalized using a Heyting Algebra, allowing nuanced trust levels that extend beyond binary trusted/untrusted states. We then present additional structures and in particular utilise exponentiation in a category theoretic sense to define compositions of attestation operations and provide the basis of a measurement for the expressibility of an attestation environment. We present a number of worked examples including boot-run-shutdown sequences, Evil Maid attacks and the specification of an attestation environment based upon this model. We then address challenges in modelling dynamic and larger systems made of multiple compositions.

</details>


### [7] [Multi Layer Protection Against Low Rate DDoS Attacks in Containerized Systems](https://arxiv.org/abs/2602.11407)
*Ahmad Fareed,Bilal Al Habib,Anne Pepita Francis*

Main category: cs.CR

TL;DR: 提出一个多层防御系统，用于检测和缓解容器化云环境中的低速率DDoS攻击，结合WAF、速率限制、动态黑名单、TCP/UDP头部分析和零信任原则。


<details>
  <summary>Details</summary>
Motivation: 低速率DDoS攻击已成为容器化云基础设施的主要威胁，由于其流量小难以检测和缓解，可能对互联网应用造成严重危害。

Method: 采用多层防御策略，整合Web应用防火墙(WAF)、速率限制、动态黑名单、TCP/UDP头部分析以及零信任原则，在攻击生命周期的不同阶段检测和阻断恶意流量。

Result: 系统能有效防御容器化环境中的低速率DDoS攻击，通过零信任原则确保每个数据包在授权前都经过仔细检查，提高了整体安全性和弹性。

Conclusion: 该DDoS缓解系统为容器化云环境提供了有效的低速率DDoS攻击防御方案，通过与Docker编排的集成，便于在容器化设置中部署和管理。

Abstract: Low rate Distributed Denial of Service DDoS attacks have emerged as a major threat to containerized cloud infrastructures. Due to their low traffic volumes, these attacks can be difficult to detect and mitigate, potentially causing serious harm to internet applications. This work proposes a DDoS mitigation system that effectively defends against low rate DDoS attacks in containerized environments using a multi layered defense strategy. The solution integrates a Web Application Firewall WAF, rate limiting, dynamic blacklisting, TCP and UDP header analysis, and zero trust principles to detect and block malicious traffic at different stages of the attack life cycle. By applying zero trust principles, the system ensures that each data packet is carefully inspected before granting access, improving overall security and resilience. Additionally, the systems integration with Docker orchestration facilitates deployment and management in containerized settings.

</details>


### [8] [Optimizing Agent Planning for Security and Autonomy](https://arxiv.org/abs/2602.11416)
*Aashish Kolluri,Rishi Sharma,Manuel Costa,Boris Köpf,Tobias Nießen,Mark Russinovich,Shruti Tople,Santiago Zanella-Béguelin*

Main category: cs.CR

TL;DR: 提出一种安全感知的AI代理设计，通过增强人机交互和显式规划，在保持安全性的同时提高代理自主性，减少对人类监督的依赖。


<details>
  <summary>Details</summary>
Motivation: 间接提示注入攻击威胁AI代理的安全执行，现有确定性系统级防御虽然能提供可证明的安全性，但会降低任务完成率和增加计算成本。现有评估忽略了系统级防御的关键优势：减少对人类监督的依赖。

Method: 引入自主性指标量化代理在保持安全性的同时无需人工干预执行关键行动的能力；设计安全感知代理，包含：(i) 更丰富的人机交互机制，(ii) 同时考虑任务进展和政策合规性的显式规划；在现有信息流控制防御基础上实现该设计。

Result: 在AgentDojo和WASP基准测试上的实验表明，该方法在不牺牲实用性的情况下实现了更高的自主性。

Conclusion: 通过引入自主性指标和安全感知代理设计，可以在保持安全性的同时减少对人类监督的依赖，为AI代理的安全部署提供了更实用的解决方案。

Abstract: Indirect prompt injection attacks threaten AI agents that execute consequential actions, motivating deterministic system-level defenses. Such defenses can provably block unsafe actions by enforcing confidentiality and integrity policies, but currently appear costly: they reduce task completion rates and increase token usage compared to probabilistic defenses. We argue that existing evaluations miss a key benefit of system-level defenses: reduced reliance on human oversight. We introduce autonomy metrics to quantify this benefit: the fraction of consequential actions an agent can execute without human-in-the-loop (HITL) approval while preserving security. To increase autonomy, we design a security-aware agent that (i) introduces richer HITL interactions, and (ii) explicitly plans for both task progress and policy compliance. We implement this agent design atop an existing information-flow control defense against prompt injection and evaluate it on the AgentDojo and WASP benchmarks. Experiments show that this approach yields higher autonomy without sacrificing utility.

</details>


### [9] [Security Assessment of Intel TDX with support for Live Migration](https://arxiv.org/abs/2602.11434)
*Kirk Swidowski,Daniel Moghimi,Josh Eads,Erdem Aktas,Jia Ma*

Main category: cs.CR

TL;DR: Google与Intel合作对Intel TDX 1.5进行安全评估，发现1个可完全攻陷TD的漏洞和4个内存泄露漏洞，强调机密计算需要深度防御


<details>
  <summary>Details</summary>
Motivation: 评估Intel TDX 1.5的新功能（实时迁移和TD分区）的安全性，延续Google之前对TDX 1.0的审查工作

Method: 与Intel合作获得文档和源代码，使用支持TDX的计算节点开发测试工具包，集成Gemini和NotebookLM进行代码分析和规范导航

Result: 发现1个高危漏洞（VMM可完全攻陷TD）和4个内存泄露漏洞（恶意VMM/TD可泄露TDX模块机密内存），识别多个安全弱点/缺陷

Conclusion: 机密计算需要迭代改进和互补的安全控制，采用深度防御方法，安全评估对完善TDX实现至关重要

Abstract: In the second and third quarters of 2025, Google collaborated with Intel to conduct a security assessment of Intel Trust Domain Extensions (TDX), extending Google's previous review and covering major changes since Intel TDX Module 1.0 - namely support for Live Migration and Trusted Domain (TD) Partitioning (nested VMs within TDs). Intel provided guidance and support, including documentation and updated TDX 1.5 source code. Unlike the previous review, this time, we had access to a compute node capable of running TDX to develop a toolkit for live testing and Proof-of-Concept (PoC) generation. Furthermore, we integrated Gemini for analysis and NotebookLM to efficiently navigate complex specifications.
  This assessment resulted in the discovery of one vulnerability that enables a VMM to fully compromise a TD, and four vulnerabilities that enable a malicious VMM or TD to leak confidential memory of the Intel TDX Module. Several other security weaknesses and/or bugs were identified but not categorized as vulnerabilities despite having some impact on security.
  Beyond presenting the technical details of multiple bugs and vulnerabilities in this report, these findings underscore that confidential computing, like other security measures, requires iterative refinement and complementary security controls to harden it, in line with a defense-in-depth approach.

</details>


### [10] [Hardening the OSv Unikernel with Efficient Address Randomization: Design and Performance Evaluation](https://arxiv.org/abs/2602.11445)
*Alex Wollman,John Hastings*

Main category: cs.CR

TL;DR: 在OSv unikernel中实现ASLR式地址随机化，通过随机化应用基址和线程栈区域来减少布局可预测性，提高抗攻击能力


<details>
  <summary>Details</summary>
Motivation: Unikernels通常省略ASLR等安全缓解措施，OSv的引导、程序加载和线程创建使用确定性地址，导致跨实例布局相似，攻击可重复性高

Method: 通过修改核心内存管理和加载例程，在OSv中引入ASLR式多样性，随机化应用基址和线程栈区域

Result: 实现复杂度低，保持OSv轻量设计；启动时间、应用运行时间和内存使用与未修改基线相当；生成的地址呈现均匀分布

Conclusion: 布局随机化防御可以有效且高效地集成到OSv unikernels中，提高抗可靠攻击能力

Abstract: Unikernels are single-purpose library operating systems that run the kernel and application in one address space, but often omit security mitigations such as address space layout randomization (ASLR). In OSv, boot, program loading, and thread creation select largely deterministic addresses, leading to near-identical layouts across instances and more repeatable exploitation. To reduce layout predictability, this research introduces ASLR-style diversity into OSv by randomizing the application base and thread stack regions through targeted changes to core memory-management and loading routines. The implementation adds minimal complexity while preserving OSv's lightweight design goals. Evaluation against an unmodified baseline finds comparable boot time, application runtime, and memory usage. Analysis indicates that the generated addresses exhibit a uniform distribution. These results show that layout-randomization defenses can be efficiently and effectively integrated into OSv unikernels, improving resistance to reliable exploitation.

</details>


### [11] [Cachemir: Fully Homomorphic Encrypted Inference of Generative Large Language Model with KV Cache](https://arxiv.org/abs/2602.11470)
*Ye Yu,Yifan Zhou,Yi Chen,Pedro Soto,Wenjie Xiong,Meng Li*

Main category: cs.CR

TL;DR: Cachemir：一种基于全同态加密的KV缓存加速LLM推理框架，解决了现有FHE框架无法有效集成KV缓存导致推理延迟过高的问题。


<details>
  <summary>Details</summary>
Motivation: 随着LLMs的广泛应用，用户将各类数据输入模型引发了严重的隐私担忧，需要基于全同态加密的安全推理框架。但现有FHE框架无法有效集成KV缓存，导致自回归解码延迟过高。

Method: 提出Cachemir框架，包含三项关键技术：1）专门为利用KV缓存计算优势设计的新型HE打包算法；2）交错复制打包算法，高效计算Transformer线性层中KV缓存产生的向量-矩阵乘法；3）考虑KV缓存的增强自举放置策略，最小化自举成本。

Result: Cachemir在CPU上比MOAI（ICML'25）和THOR（CCS'25）分别快48.83倍和67.16倍，在GPU上为Llama-3-8B生成一个输出token耗时不到100秒。

Conclusion: Cachemir成功解决了FHE框架中KV缓存集成问题，显著降低了同态加密LLM推理的延迟，为隐私保护的大语言模型部署提供了实用解决方案。

Abstract: Generative large language models (LLMs) have revolutionized multiple domains. Modern LLMs predominantly rely on an autoregressive decoding strategy, which generates output tokens sequentially and employs a key-value cache (KV cache) to avoid redundant computation. However, the widespread deployment of LLMs has raised serious privacy concerns, as users are feeding all types of data into the model, motivating the development of secure inference frameworks based on fully homomorphic encryption (FHE). A major limitation of existing FHE-based frameworks is their inability to effectively integrate the KV cache, resulting in prohibitively high latency for autoregressive decoding. In this paper, we propose Cachemir, a KV Cache Accelerated Homomorphic Encrypted LLM Inference Regime to overcome this limitation. Cachemir comprises three key technical contributions: 1) a set of novel HE packing algorithms specifically designed to leverage the computational advantages of the KV cache; 2) an interleaved replicated packing algorithm to efficiently compute the vector-matrix multiplications that result from using the KV cache in Transformer linear layers; and 3) an augmented bootstrapping placement strategy that accounts for the KV cache to minimize bootstrapping cost. We demonstrate that Cachemir achieves $48.83\times$ and $67.16\times$ speedup over MOAI (ICML'25) and THOR (CCS'25) respectively on CPU and consumes less than 100 seconds on GPU to generate an output token for Llama-3-8B.

</details>


### [12] [Future Mining: Learning for Safety and Security](https://arxiv.org/abs/2602.11472)
*Md Sazedur Rahman,Mizanur Rahman Jewel,Sanjay Madria*

Main category: cs.CR

TL;DR: 提出统一智能安全架构，整合多模态感知、安全联邦学习、强化学习等技术，解决恶劣采矿环境下的感知退化、网络安全威胁和能源约束问题。


<details>
  <summary>Details</summary>
Motivation: 采矿环境正快速演变为AI驱动的网络物理生态系统，但面临恶劣照明、GPS受限、不规则拓扑、间歇连接等现实约束，导致感知精度下降、态势感知中断。同时，后门攻击、传感器欺骗、标签翻转等新兴网络物理威胁进一步危及操作安全。能源受限传感器的不均匀电池消耗也造成安全覆盖盲区。

Method: 提出统一智能安全与安全架构，整合多模态感知、安全联邦学习、强化学习、DTN通信和能源感知传感。引入五个核心模块：矿工定位器、多模态态势感知、后门攻击监控器、TrustFed LFD和物联网驱动的设备健康监控。

Result: 该架构能够解决矿工定位、危险理解、联邦鲁棒性和预测性维护问题，形成端到端框架，指导矿工通过障碍路径、识别受损模型或传感器，确保关键任务设备可靠性。

Conclusion: 提出了构建弹性可信智能采矿系统的全面研究愿景，能够在对抗条件下保持操作连续性，为恶劣采矿环境下的安全与安全提供统一解决方案。

Abstract: Mining is rapidly evolving into an AI driven cyber physical ecosystem where safety and operational reliability depend on robust perception, trustworthy distributed intelligence, and continuous monitoring of miners and equipment. However, real world mining environments impose severe constraints, including poor illumination, GPS denied conditions, irregular underground topologies and intermittent connectivity. These factors degrade perception accuracy, disrupt situational awareness and weaken distributed learning systems. At the same time, emerging cyber physical threats such as backdoor triggers, sensor spoofing, label flipping attacks, and poisoned model updates further jeopardize operational safety as mines adopt autonomous vehicles, humanoid assistance, and federated learning for collaborative intelligence. Energy constrained sensors also experience uneven battery depletion, creating blind spots in safety coverage and disrupting hazard detection pipelines. This paper presents a vision for a Unified Smart Safety and Security Architecture that integrates multimodal perception, secure federated learning, reinforcement learning, DTN enabled communication, and energy aware sensing into a cohesive safety framework. We introduce five core modules: Miner Finder, Multimodal Situational Awareness, Backdoor Attack Monitor, TrustFed LFD, and IoT driven Equipment Health Monitoring. These modules collectively address miner localization, hazard understanding, federated robustness, and predictive maintenance. Together, they form an end to end framework capable of guiding miners through obstructed pathways, identifying compromised models or sensors, and ensuring mission critical equipment reliability. This work outlines a comprehensive research vision for building a resilient and trustworthy intelligent mining system capable of maintaining operational continuity under adversarial conditions.

</details>


### [13] [Jailbreaking Leaves a Trace: Understanding and Detecting Jailbreak Attacks from Internal Representations of Large Language Models](https://arxiv.org/abs/2602.11495)
*Sri Durga Sai Sowmya Kadali,Evangelos E. Papalexakis*

Main category: cs.CR

TL;DR: 论文提出了一种基于内部表征分析的LLM越狱检测与防御方法，通过分析隐藏层激活的潜在模式来识别和阻断越狱攻击，无需模型微调或额外检测器。


<details>
  <summary>Details</summary>
Motivation: 随着对话AI系统的广泛部署，LLM越狱已成为关键安全挑战。现有防御机制主要依赖提示层面的检测，但攻击者不断开发自适应策略，现有模型仍然脆弱。这促使研究者从内部行为分析而非仅依赖提示层面防御的角度来应对越狱问题。

Method: 1. 对GPT-J、LLaMA、Mistral和Mamba等多个开源模型进行系统性的逐层分析，识别有害输入相关的潜在空间模式；2. 提出基于张量的潜在表征框架，捕捉隐藏激活的结构；3. 在推理时利用潜在信号主动干扰越狱执行，通过选择性绕过高易感性层来阻断攻击。

Result: 在LLaMA-3.1-8B模型上，选择性绕过高易感性层能够阻断78%的越狱尝试，同时在94%的良性提示上保持正常行为。该方法完全在推理时运行，引入最小开销，为增强LLM安全提供了可扩展的基础。

Conclusion: 越狱行为根植于可识别的内部结构，基于内部表征分析的方法为改进LLM安全提供了一个互补的、架构无关的方向，能够在不依赖模型微调或额外检测器的情况下实现轻量级越狱检测与防御。

Abstract: Jailbreaking large language models (LLMs) has emerged as a critical security challenge with the widespread deployment of conversational AI systems. Adversarial users exploit these models through carefully crafted prompts to elicit restricted or unsafe outputs, a phenomenon commonly referred to as Jailbreaking. Despite numerous proposed defense mechanisms, attackers continue to develop adaptive prompting strategies, and existing models remain vulnerable. This motivates approaches that examine the internal behavior of LLMs rather than relying solely on prompt-level defenses. In this work, we study jailbreaking from both security and interpretability perspectives by analyzing how internal representations differ between jailbreak and benign prompts. We conduct a systematic layer-wise analysis across multiple open-source models, including GPT-J, LLaMA, Mistral, and the state-space model Mamba, and identify consistent latent-space patterns associated with harmful inputs. We then propose a tensor-based latent representation framework that captures structure in hidden activations and enables lightweight jailbreak detection without model fine-tuning or auxiliary LLM-based detectors. We further demonstrate that the latent signals can be used to actively disrupt jailbreak execution at inference time. On an abliterated LLaMA-3.1-8B model, selectively bypassing high-susceptibility layers blocks 78% of jailbreak attempts while preserving benign behavior on 94% of benign prompts. This intervention operates entirely at inference time and introduces minimal overhead, providing a scalable foundation for achieving stronger coverage by incorporating additional attack distributions or more refined susceptibility thresholds. Our results provide evidence that jailbreak behavior is rooted in identifiable internal structures and suggest a complementary, architecture-agnostic direction for improving LLM security.

</details>


### [14] [Stop Tracking Me! Proactive Defense Against Attribute Inference Attack in LLMs](https://arxiv.org/abs/2602.11528)
*Dong Yan,Jian Liang,Ran He,Tieniu Tan*

Main category: cs.CR

TL;DR: TRACE-RPS：结合细粒度匿名化与推理阻止优化的统一防御框架，将LLM属性推断准确率从约50%降至5%以下


<details>
  <summary>Details</summary>
Motivation: 现有匿名化防御方法存在两个主要问题：1）粗粒度，缺乏词级精度的隐私泄露元素匿名化；2）即使修改用户文本隐藏敏感线索，LLM仍能通过推理能力进行属性推断

Method: 提出统一防御框架TRACE-RPS：TRACE利用注意力机制和推理链生成来识别和匿名化隐私泄露文本元素；RPS采用轻量级两阶段优化策略诱导模型拒绝行为，从而阻止属性推断

Result: 评估显示TRACE-RPS将开源模型的属性推断准确率从约50%降至5%以下；同时具有强大的跨模型泛化能力、提示变化鲁棒性和效用-隐私权衡

Conclusion: TRACE-RPS框架有效解决了现有匿名化方法的局限性，显著降低了LLM从用户生成文本中推断隐私属性的能力，为在线隐私保护提供了实用解决方案

Abstract: Recent studies have shown that large language models (LLMs) can infer private user attributes (e.g., age, location, gender) from user-generated text shared online, enabling rapid and large-scale privacy breaches. Existing anonymization-based defenses are coarse-grained, lacking word-level precision in anonymizing privacy-leaking elements. Moreover, they are inherently limited as altering user text to hide sensitive cues still allows attribute inference to occur through models' reasoning capabilities. To address these limitations, we propose a unified defense framework that combines fine-grained anonymization (TRACE) with inference-preventing optimization (RPS). TRACE leverages attention mechanisms and inference chain generation to identify and anonymize privacy-leaking textual elements, while RPS employs a lightweight two-stage optimization strategy to induce model rejection behaviors, thereby preventing attribute inference. Evaluations across diverse LLMs show that TRACE-RPS reduces attribute inference accuracy from around 50\% to below 5\% on open-source models. In addition, our approach offers strong cross-model generalization, prompt-variation robustness, and utility-privacy tradeoffs. Our code is available at https://github.com/Jasper-Yan/TRACE-RPS.

</details>


### [15] [LoRA-based Parameter-Efficient LLMs for Continuous Learning in Edge-based Malware Detection](https://arxiv.org/abs/2602.11655)
*Christian Rondanini,Barbara Carminati,Elena Ferrari,Niccolò Lardo,Ashish Kundu*

Main category: cs.CR

TL;DR: 提出基于LoRA适配器的边缘恶意软件检测连续学习架构，通过本地适应与全局知识共享实现跨设备泛化，在资源受限的边缘设备上提升检测效果。


<details>
  <summary>Details</summary>
Motivation: 边缘设备激增需要实时恶意软件检测，但现有方案面临挑战：静态或中心化模型难以应对威胁演变和异构流量；本地训练模型形成孤岛且无法跨域迁移；大语言模型资源需求过高不适用于边缘设备。

Method: 提出连续学习架构：在边缘节点部署轻量级Transformer模型（DistilBERT、DistilGPT-2、TinyT5），通过LoRA适配器进行增量微调；仅聚合和重新分发LoRA模块，实现跨设备知识共享而不交换原始数据；轻量级协调器管理参数交换。

Result: 在两个公开IoT安全数据集（Edge-IIoTset和TON-IoT）上评估，相比孤立微调，LoRA交换在遇到未见攻击时带来20-25%准确率提升；LoRA仅增加0.6-1.8MB模型大小（<1%）；在多轮学习中保持稳定的损失和F1分数。

Conclusion: 基于LoRA的连续学习架构有效解决了边缘恶意软件检测中的资源约束和知识孤岛问题，实现了本地适应与全局泛化的平衡，为边缘安全提供了实用解决方案。

Abstract: The proliferation of edge devices has created an urgent need for security solutions capable of detecting malware in real time while operating under strict computational and memory constraints. Recently, Large Language Models (LLMs) have demonstrated remarkable capabilities in recognizing complex patterns, yet their deployment on edge devices remains impractical due to their resource demands. However, in edge malware detection, static or centrally retrained models degrade under evolving threats and heterogeneous traffic; locally trained models become siloed and fail to transfer across domains. To overcome these limitations, in this paper, we present a continuous learning architecture for edge-based malware detection that combines local adaptation on each device with global knowledge sharing through parameter-efficient LoRA adapters. Lightweight transformer models (DistilBERT, DistilGPT-2, TinyT5) run on edge nodes and are incrementally fine-tuned on device-specific traffic; only the resulting LoRA modules are aggregated by a lightweight coordinator and redistributed, enabling cross-device generalization without exchanging raw data. We evaluate on two public IoT security datasets, Edge-IIoTset and TON-IoT, under multi-round learning to simulate evolving threats. Compared to isolated fine-tuning, the LoRA-based exchange yields up to 20-25% accuracy gains when models encounter previously unseen attacks from another domain, while maintaining stable loss and F1 across rounds. LoRA adds less than 1% to model size (~0.6-1.8 MB), making updates practical for constrained edge hardware.

</details>


### [16] [More Haste, Less Speed: Weaker Single-Layer Watermark Improves Distortion-Free Watermark Ensembles](https://arxiv.org/abs/2602.11793)
*Ruibo Chen,Yihan Wu,Xuehao Cui,Jingqi Zhang,Heng Huang*

Main category: cs.CR

TL;DR: 研究发现传统"越强越好"的水印方法存在局限性：强水印会显著降低令牌分布的熵，反而削弱后续层的水印效果。作者提出使用较弱单层水印来保留熵，从而实现更有效的多层集成。


<details>
  <summary>Details</summary>
Motivation: 当前水印集成方法通常优先最大化每层水印强度，但作者发现这种"越强越好"的方法存在关键限制：强水印会显著降低令牌分布的熵，从而削弱后续层的水印效果。

Method: 提出一个通用框架，使用较弱的单层水印来保留熵，以支持有效的多层集成。通过理论和实证分析，证明可检测性受熵限制，水印集成会导致各层熵和预期绿表比率单调下降。

Result: 实证评估表明，这种反直觉策略能够缓解信号衰减，在可检测性和鲁棒性方面持续优于强基线方法。

Conclusion: 传统"越强越好"的水印方法存在根本缺陷，通过使用较弱单层水印来保留熵，可以显著提高多层水印集成的效果，在可检测性和鲁棒性方面都表现更好。

Abstract: Watermarking has emerged as a crucial technique for detecting and attributing content generated by large language models. While recent advancements have utilized watermark ensembles to enhance robustness, prevailing methods typically prioritize maximizing the strength of the watermark at every individual layer. In this work, we identify a critical limitation in this "stronger-is-better" approach: strong watermarks significantly reduce the entropy of the token distribution, which paradoxically weakens the effectiveness of watermarking in subsequent layers. We theoretically and empirically show that detectability is bounded by entropy and that watermark ensembles induce a monotonic decrease in both entropy and the expected green-list ratio across layers. To address this inherent trade-off, we propose a general framework that utilizes weaker single-layer watermarks to preserve the entropy required for effective multi-layer ensembling. Empirical evaluations demonstrate that this counter-intuitive strategy mitigates signal decay and consistently outperforms strong baselines in both detectability and robustness.

</details>


### [17] [PAC to the Future: Zero-Knowledge Proofs of PAC Private Systems](https://arxiv.org/abs/2602.11954)
*Guilhem Repetto,Nojan Sheybani,Gabrielle De Micheli,Farinaz Koushanfar*

Main category: cs.CR

TL;DR: 提出结合PAC隐私与零知识证明的框架，在不可信计算环境中提供可验证的隐私保证，解决传统隐私保护技术的局限性。


<details>
  <summary>Details</summary>
Motivation: 随着机器学习系统对敏感用户数据的依赖增加，隐私问题日益突出。传统隐私保护技术在不可信计算环境（如云系统）中存在局限性，需要既能保护隐私又能验证计算正确性的解决方案。

Method: 结合PAC隐私（概率近似正确隐私）与零知识证明（ZKPs），使用非交互式ZKP方案生成证明，验证PAC隐私机制的正确实施，同时保护专有系统的机密性。

Result: 证明了在外部计算中实现可验证PAC隐私的可行性，为隐私保护机器学习和数据库系统提供了实用的信任维护方案，同时确保计算完整性。

Conclusion: 该框架为不可信计算环境中的隐私保护提供了创新解决方案，通过可验证的隐私保证增强了用户对隐私保护机器学习系统的信任。

Abstract: Privacy concerns in machine learning systems have grown significantly with the increasing reliance on sensitive user data for training large-scale models. This paper introduces a novel framework combining Probably Approximately Correct (PAC) Privacy with zero-knowledge proofs (ZKPs) to provide verifiable privacy guarantees in trustless computing environments. Our approach addresses the limitations of traditional privacy-preserving techniques by enabling users to verify both the correctness of computations and the proper application of privacy-preserving noise, particularly in cloud-based systems. We leverage non-interactive ZKP schemes to generate proofs that attest to the correct implementation of PAC privacy mechanisms while maintaining the confidentiality of proprietary systems. Our results demonstrate the feasibility of achieving verifiable PAC privacy in outsourced computation, offering a practical solution for maintaining trust in privacy-preserving machine learning and database systems while ensuring computational integrity.

</details>


### [18] [Evaluation of Security-Induced Latency on 5G RAN Interfaces and User Plane Communication](https://arxiv.org/abs/2602.12059)
*Sotiris Michaelides,Jakub Lapawa,Daniel Eguiguren Chavez,Martin Henze*

Main category: cs.CR

TL;DR: 5G网络通过解耦RAN组件降低延迟，但安全控制会增加延迟开销。研究评估了可选安全机制对解耦RAN的延迟影响，发现即使启用安全，解耦RAN仍比单体设计有延迟优势，但实现亚毫秒往返时间仍具挑战性。


<details>
  <summary>Details</summary>
Motivation: 5G网络通过解耦RAN组件将用户面功能部署到更靠近用户的位置以降低延迟，但这种解耦引入了额外的接口，保护这些接口会增加延迟开销。需要评估启用可选5G安全控制对内部RAN接口和5G用户面的延迟影响。

Method: 通过与网络运营商和5G制造商的讨论指导，部署了首个实现解耦RAN并采用标准化可选安全机制的测试平台，评估安全控制对延迟的影响。

Result: 即使启用安全控制，解耦RAN部署仍比单体设计具有延迟优势。然而，实现亚毫秒（<1 ms）往返时间仍然具有挑战性，仅加密开销就可能超过这个目标。

Conclusion: 解耦RAN在延迟方面仍优于传统单体设计，但5G要实现亚毫秒级超可靠低延迟目标，需要在安全性和性能之间进行权衡，因为加密开销本身就可能超过1毫秒的目标。

Abstract: 5G promises enhanced performance-not only in bandwidth and capacity, but also latency and security. Its ultra-reliable low-latency configuration targets round-trip times below 1 ms, while optional security controls extend protection across all interfaces, making 5G attractive for mission-critical applications. A key enabler of low latency is the disaggregation of network components, including the RAN, allowing user-plane functions to be deployed nearer to end users. However, this split introduces additional interfaces, whose protection increases latency overhead. In this paper, guided by discussions with a network operator and a 5G manufacturer, we evaluate the latency overhead of enabling optional 5G security controls across internal RAN interfaces and the 5G user plane. To this end, we deploy the first testbed implementing a disaggregated RAN with standardized optional security mechanisms. Our results show that disaggregated RAN deployments retain a latency advantage over monolithic designs, even with security enabled. However, achieving sub-1 ms round-trip times remains challenging, as cryptographic overhead alone can already exceed this target.

</details>


### [19] [Unknown Attack Detection in IoT Networks using Large Language Models: A Robust, Data-efficient Approach](https://arxiv.org/abs/2602.12183)
*Shan Ali,Feifei Niu,Paria Shirani,Lionel C. Briand*

Main category: cs.CR

TL;DR: SiamXBERT：基于孪生网络和Transformer的元学习框架，用于物联网网络中零日攻击检测，在数据稀缺和加密流量条件下表现优异。


<details>
  <summary>Details</summary>
Motivation: 物联网网络中零日攻击检测面临挑战：现有方法依赖大量标注数据、载荷检查或封闭集分类，在数据稀缺、加密流量和分布偏移情况下效果有限。

Method: 提出SiamXBERT框架：结合孪生网络元学习和Transformer语言模型，构建流级和包级双模态特征表示，通过元学习快速适应新攻击类型，仅需少量标注样本。

Result: 在代表性物联网入侵数据集上，SiamXBERT在数据集内和跨数据集设置下均优于现有方法，未知攻击F1分数提升高达78.8%，且所需训练数据显著减少。

Conclusion: SiamXBERT为现实物联网环境中的鲁棒未知攻击检测提供了实用解决方案，特别适用于数据稀缺和加密流量场景。

Abstract: The rapid evolution of cyberattacks continues to drive the emergence of unknown (zero-day) threats, posing significant challenges for network intrusion detection systems in Internet of Things (IoT) networks. Existing machine learning and deep learning approaches typically rely on large labeled datasets, payload inspection, or closed-set classification, limiting their effectiveness under data scarcity, encrypted traffic, and distribution shifts. Consequently, detecting unknown attacks in realistic IoT deployments remains difficult. To address these limitations, we propose SiamXBERT, a robust and data-efficient Siamese meta-learning framework empowered by a transformer-based language model for unknown attack detection. The proposed approach constructs a dual-modality feature representation by integrating flow-level and packet-level information, enabling richer behavioral modeling while remaining compatible with encrypted traffic. Through meta-learning, the model rapidly adapts to new attack types using only a small number of labeled samples and generalizes to previously unseen behaviors. Extensive experiments on representative IoT intrusion datasets demonstrate that SiamXBERT consistently outperforms state-of-the-art baselines under both within-dataset and cross-dataset settings while requiring significantly less training data, achieving up to \num{78.8}\% improvement in unknown F1-score. These results highlight the practicality of SiamXBERT for robust unknown attack detection in real-world IoT environments.

</details>


### [20] [Legitimate Overrides in Decentralized Protocols](https://arxiv.org/abs/2602.12260)
*Oghenekaro Elem,Nimrod Talmon*

Main category: cs.CR

TL;DR: 论文提出一个紧急干预机制的分类框架，分析区块链协议中紧急干预（如链级冻结、协议暂停）的设计权衡，通过705个漏洞事件验证预测，为紧急治理提供量化设计原则。


<details>
  <summary>Details</summary>
Motivation: 去中心化协议声称具有不可变的规则执行，但许多协议嵌入了紧急干预机制（如链级冻结、账户隔离）。这些机制对应对漏洞和系统性故障至关重要，但也暴露了核心矛盾：干预何时能维护信任，何时被视为非法自由裁量？2016-2026年间约100亿美元的技术漏洞损失可能通过链上干预解决，但目前的方法仍处于临时性和意识形态化状态。

Method: 开发Scope × Authority分类法，从干预精度和触发权集中度两个维度映射紧急架构设计空间。将权衡（持续中心化成本 vs 遏制速度和附带破坏）形式化为随机成本最小化问题，并推导三个可测试预测。使用705个已记录的漏洞事件评估这些预测。

Result: 研究发现：1) 遏制时间因权限类型而系统变化；2) 损失遵循重尾分布（α≈1.33），风险集中在罕见的灾难性事件中；3) 社区情绪显著调节维持干预能力的有效成本。损失分布显示少数大型事件主导总损失。

Conclusion: 分析得出具体的设计原则，将紧急治理从意识形态辩论转向量化工程。紧急干预机制的设计应基于系统性风险评估和社区接受度，而非意识形态立场。

Abstract: Decentralized protocols claim immutable, rule-based execution, yet many embed emergency mechanisms such as chain-level freezes, protocol pauses, and account quarantines. These overrides are crucial for responding to exploits and systemic failures, but they expose a core tension: when does intervention preserve trust and when is it perceived as illegitimate discretion? With approximately $10$ billion in technical exploit losses potentially addressable by onchain intervention (2016--2026), the design of these mechanisms has high practical stakes, but current approaches remain ad hoc and ideologically charged. We address this gap by developing a Scope $\times$ Authority taxonomy that maps the design space of emergency architectures along two dimensions: the precision of the intervention and the concentration of trigger authority. We formalize the resulting tradeoffs of a standing centralization cost versus containment speed and collateral disruption as a stochastic cost-minimization problem; and derive three testable predictions. Assessing these predictions against 705 documented exploit incidents, we find that containment time varies systematically by authority type; that losses follow a heavy-tailed distribution ($α\approx 1.33$) concentrating risk in rare catastrophic events; and that community sentiment measurably modulates the effective cost of maintaining intervention capability. The analysis yields concrete design principles that move emergency governance from ideological debate towards quantitative engineering.

</details>
