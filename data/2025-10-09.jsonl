{"id": "2510.06420", "categories": ["cs.CR", "cs.PL"], "pdf": "https://arxiv.org/pdf/2510.06420", "abs": "https://arxiv.org/abs/2510.06420", "authors": ["Suresh K. Damodaran", "Paul D. Rowe"], "title": "Automated Repeatable Adversary Threat Emulation with Effects Language (EL)", "comment": null, "summary": "The emulation of multi-step attacks attributed to advanced persistent threats\nis valuable for training defenders and evaluating defense tools. In this paper,\nwe discuss the numerous challenges and desired attributes associated with such\nautomation. Additionally, we introduce the use of Effects Language (EL), a\nvisual programming language with graph-based operational semantics, as a\nsolution to address many of these challenges and requirements. We formally\ndefine the execution semantics of EL, and prove important execution properties.\nFurthermore, we showcase the application of EL to codify attacks using an\nexample from one of the publicly available attack scenarios. We also\ndemonstrate how EL can be utilized to provide proof-of-attack of complex\nmulti-step attacks. Our results highlight the improvements in time and resource\nefficiency achieved through the use of EL for repeatable automation."}
{"id": "2510.06421", "categories": ["cs.CR"], "pdf": "https://arxiv.org/pdf/2510.06421", "abs": "https://arxiv.org/abs/2510.06421", "authors": ["Muhammad Abdullah Soomro", "Fatima Muhammad Anwar"], "title": "Breaking Precision Time: OS Vulnerability Exploits Against IEEE 1588", "comment": "Published in IEEE ISPCS 2025", "summary": "The Precision Time Protocol (PTP), standardized as IEEE 1588, provides\nsub-microsecond synchronization across distributed systems and underpins\ncritical infrastructure in telecommunications, finance, power systems, and\nindustrial automation. While prior work has extensively analyzed PTP's\nvulnerability to network-based attacks, prompting the development of\ncryptographic protections and anomaly detectors, these defenses presume an\nuncompromised host. In this paper, we identify and exploit a critical blind\nspot in current threat models: kernel-level adversaries operating from within\nthe host running the PTP stack. We present the first systematic study of\nkernel-rooted attacks on PTP, demonstrating how privileged attackers can\nmanipulate system time by corrupting key interfaces without altering PTP\nnetwork traffic. We implement three attack primitives, constant offset,\nprogressive skew, and random jitter, using in-kernel payloads, and evaluate\ntheir impact on the widely used ptp4l and phc2sys daemons. Our experiments\nreveal that these attacks can silently destabilize clock synchronization,\nbypassing existing PTP security extensions. These findings highlight the urgent\nneed to reconsider host-level trust assumptions and integrate kernel integrity\ninto the design of secure time synchronization systems."}
{"id": "2510.06432", "categories": ["cs.CR"], "pdf": "https://arxiv.org/pdf/2510.06432", "abs": "https://arxiv.org/abs/2510.06432", "authors": ["Vipul Goyal", "Justin Raizes"], "title": "Proofs of No Intrusion", "comment": null, "summary": "A central challenge in data security is not just preventing theft, but\ndetecting whether it has occurred. Classically, this is impossible because a\nperfect copy leaves no evidence. Quantum mechanics, on the other hand, forbids\ngeneral duplication, opening up new possibilities.\n  We introduce Proofs of No Intrusion, which enable a classical client to\nremotely test whether a quantum server has been hacked and the client's data\nstolen. Crucially, the test does not destroy the data being tested, avoiding\nthe need to store a backup elsewhere. We define and construct proofs of no\nintrusion for ciphertexts assuming fully homomorphic encryption. Additionally,\nwe show how to equip several constructions of unclonable primitives with proofs\nof non-intrusion, such as unclonable decryption keys and signature tokens.\nConceptually, proofs of non-intrusion can be defined for essentially any\nunclonable primitive.\n  At the heart of our techniques is a new method for non-destructively testing\ncoset states with classical communication. It can be viewed as a\nnon-destructive proof of knowledge of a measurement result of the coset state."}
{"id": "2510.06468", "categories": ["cs.CR"], "pdf": "https://arxiv.org/pdf/2510.06468", "abs": "https://arxiv.org/abs/2510.06468", "authors": ["Sergio Demian Lerner", "Ariel Futoransky"], "title": "BATTLE for Bitcoin: Capital-Efficient Optimistic Bridges with Large Committees", "comment": null, "summary": "We present BATTLE for Bitcoin, a DoS-resilient dispute layer that secures\noptimistic bridges between Bitcoin and rollups or sidechains. Our design adapts\nthe BATTLE tournament protocol to Bitcoin's UTXO model using BitVM-style FLEX\ncomponents and garbled circuits with on-demand L1 security bonds. Disputes are\nresolved in logarithmic rounds while recycling rewards, keeping the honest\nasserter's minimum initial capital constant even under many permissionless\nchallengers. The construction is fully contestable (challengers can supply\nhigher-work counter-proofs) and relies only on standard timelocks and\npre-signed transaction DAGs, without new opcodes.\n  For $N$ operators, the protocol requires $O(N^2)$ pre-signed transactions,\nsignatures, and message exchanges, yet remains practical at $N\\!\\gtrsim\\!10^3$,\nenabling high decentralization."}
{"id": "2510.06530", "categories": ["cs.CR", "cs.ET", "cs.LG", "cs.NI"], "pdf": "https://arxiv.org/pdf/2510.06530", "abs": "https://arxiv.org/abs/2510.06530", "authors": ["Thusitha Dayaratne", "Ngoc Duy Pham", "Viet Vo", "Shangqi Lai", "Sharif Abuadbba", "Hajime Suzuki", "Xingliang Yuan", "Carsten Rudolph"], "title": "From Description to Detection: LLM based Extendable O-RAN Compliant Blind DoS Detection in 5G and Beyond", "comment": null, "summary": "The quality and experience of mobile communication have significantly\nimproved with the introduction of 5G, and these improvements are expected to\ncontinue beyond the 5G era. However, vulnerabilities in control-plane\nprotocols, such as Radio Resource Control (RRC) and Non-Access Stratum (NAS),\npose significant security threats, such as Blind Denial of Service (DoS)\nattacks. Despite the availability of existing anomaly detection methods that\nleverage rule-based systems or traditional machine learning methods, these\nmethods have several limitations, including the need for extensive training\ndata, predefined rules, and limited explainability. Addressing these\nchallenges, we propose a novel anomaly detection framework that leverages the\ncapabilities of Large Language Models (LLMs) in zero-shot mode with unordered\ndata and short natural language attack descriptions within the Open Radio\nAccess Network (O-RAN) architecture. We analyse robustness to prompt variation,\ndemonstrate the practicality of automating the attack descriptions and show\nthat detection quality relies on the semantic completeness of the description\nrather than its phrasing or length. We utilise an RRC/NAS dataset to evaluate\nthe solution and provide an extensive comparison of open-source and proprietary\nLLM implementations to demonstrate superior performance in attack detection. We\nfurther validate the practicality of our framework within O-RAN's real-time\nconstraints, illustrating its potential for detecting other Layer-3 attacks."}
{"id": "2510.06535", "categories": ["cs.CR", "C.3; D.4.6; K.6.5"], "pdf": "https://arxiv.org/pdf/2510.06535", "abs": "https://arxiv.org/abs/2510.06535", "authors": ["Jack Vanlyssel", "Enrique Sobrados", "Ramsha Anwar", "Gruia-Catalin Roman", "Afsah Anwar"], "title": "SpyChain: Multi-Vector Supply Chain Attacks on Small Satellite Systems", "comment": "18 pages, 7 figures. Version includes implementation details and\n  experimental results using NASA's NOS3 satellite simulation framework", "summary": "Small satellites are integral to scientific, commercial, and defense\nmissions, but reliance on commercial off-the-shelf (COTS) hardware broadens\ntheir attack surface. Although supply chain threats are well studied in other\ncyber-physical domains, their feasibility and stealth in space systems remain\nlargely unexplored. Prior work has focused on flight software, which benefits\nfrom strict security practices and oversight. In contrast, auxiliary COTS\ncomponents often lack robust assurance yet enjoy comparable access to critical\non-board resources, including telemetry, system calls, and the software bus.\nDespite this privileged access, the insider threat within COTS hardware supply\nchains has received little attention. In this work, we present SpyChain, the\nfirst end-to-end design and implementation of independent and colluding\nhardware supply chain threats targeting small satellites. Using NASA's\nsatellite simulation (NOS3), we demonstrate that SpyChain can evade testing,\nexfiltrate telemetry, disrupt operations, and launch Denial of Service (DoS)\nattacks through covert channels that bypass ground monitoring. Our study traces\nan escalation from a simple solo component to dynamic, coordinating malware,\nintroducing a taxonomy of stealth across five scenarios. We showcase how\nimplicit trust in auxiliary components enables covert persistence and reveal\nnovel attack vectors, highlighting a new multi-component execution technique\nthat is now incorporated into the SPARTA matrix. Our findings are reinforced by\nacknowledgment and affirmation from NASA's NOS3 team. Finally, we implement\nlightweight onboard defenses, including runtime monitoring, to mitigate threats\nlike SpyChain."}
{"id": "2510.06565", "categories": ["cs.CR"], "pdf": "https://arxiv.org/pdf/2510.06565", "abs": "https://arxiv.org/abs/2510.06565", "authors": ["Jiuan Zhou", "Yu Cheng", "Yuan Xie", "Zhaoxia Yin"], "title": "Auto-Stega: An Agent-Driven System for Lifelong Strategy Evolution in LLM-Based Text Steganography", "comment": "15 pages, 9 figures", "summary": "With the rapid progress of LLMs, high quality generative text has become\nwidely available as a cover for text steganography. However, prevailing methods\nrely on hand-crafted or pre-specified strategies and struggle to balance\nefficiency, imperceptibility, and security, particularly at high embedding\nrates. Accordingly, we propose Auto-Stega, an agent-driven self-evolving\nframework that is the first to realize self-evolving steganographic strategies\nby automatically discovering, composing, and adapting strategies at inference\ntime; the framework operates as a closed loop of generating, evaluating,\nsummarizing, and updating that continually curates a structured strategy\nlibrary and adapts across corpora, styles, and task constraints. A decoding LLM\nrecovers the information under the shared strategy. To handle high embedding\nrates, we introduce PC-DNTE, a plug-and-play algorithm that maintains alignment\nwith the base model's conditional distribution at high embedding rates,\npreserving imperceptibility while enhancing security. Experimental results\ndemonstrate that at higher embedding rates Auto-Stega achieves superior\nperformance with gains of 42.2\\% in perplexity and 1.6\\% in anti-steganalysis\nperformance over SOTA methods."}
{"id": "2510.06605", "categories": ["cs.CR", "cs.AI", "cs.CL"], "pdf": "https://arxiv.org/pdf/2510.06605", "abs": "https://arxiv.org/abs/2510.06605", "authors": ["Shuo Shao", "Yiming Li", "Hongwei Yao", "Yifei Chen", "Yuchen Yang", "Zhan Qin"], "title": "Reading Between the Lines: Towards Reliable Black-box LLM Fingerprinting via Zeroth-order Gradient Estimation", "comment": null, "summary": "The substantial investment required to develop Large Language Models (LLMs)\nmakes them valuable intellectual property, raising significant concerns about\ncopyright protection. LLM fingerprinting has emerged as a key technique to\naddress this, which aims to verify a model's origin by extracting an intrinsic,\nunique signature (a \"fingerprint\") and comparing it to that of a source model\nto identify illicit copies. However, existing black-box fingerprinting methods\noften fail to generate distinctive LLM fingerprints. This ineffectiveness\narises because black-box methods typically rely on model outputs, which lose\ncritical information about the model's unique parameters due to the usage of\nnon-linear functions. To address this, we first leverage Fisher Information\nTheory to formally demonstrate that the gradient of the model's input is a more\ninformative feature for fingerprinting than the output. Based on this insight,\nwe propose ZeroPrint, a novel method that approximates these information-rich\ngradients in a black-box setting using zeroth-order estimation. ZeroPrint\novercomes the challenge of applying this to discrete text by simulating input\nperturbations via semantic-preserving word substitutions. This operation allows\nZeroPrint to estimate the model's Jacobian matrix as a unique fingerprint.\nExperiments on the standard benchmark show ZeroPrint achieves a\nstate-of-the-art effectiveness and robustness, significantly outperforming\nexisting black-box methods."}
{"id": "2510.06607", "categories": ["cs.CR"], "pdf": "https://arxiv.org/pdf/2510.06607", "abs": "https://arxiv.org/abs/2510.06607", "authors": ["Weidi Luo", "Qiming Zhang", "Tianyu Lu", "Xiaogeng Liu", "Bin Hu", "Hung-Chun Chiu", "Siyuan Ma", "Yizhe Zhang", "Xusheng Xiao", "Yinzhi Cao", "Zhen Xiang", "Chaowei Xiao"], "title": "Code Agent can be an End-to-end System Hacker: Benchmarking Real-world Threats of Computer-use Agent", "comment": null, "summary": "Computer-use agent (CUA) frameworks, powered by large language models (LLMs)\nor multimodal LLMs (MLLMs), are rapidly maturing as assistants that can\nperceive context, reason, and act directly within software environments. Among\ntheir most critical applications is operating system (OS) control. As CUAs in\nthe OS domain become increasingly embedded in daily operations, it is\nimperative to examine their real-world security implications, specifically\nwhether CUAs can be misused to perform realistic, security-relevant attacks.\nExisting works exhibit four major limitations: Missing attacker-knowledge model\non tactics, techniques, and procedures (TTP), Incomplete coverage for\nend-to-end kill chains, unrealistic environment without multi-host and\nencrypted user credentials, and unreliable judgment dependent on\nLLM-as-a-Judge. To address these gaps, we propose AdvCUA, the first benchmark\naligned with real-world TTPs in MITRE ATT&CK Enterprise Matrix, which comprises\n140 tasks, including 40 direct malicious tasks, 74 TTP-based malicious tasks,\nand 26 end-to-end kill chains, systematically evaluates CUAs under a realistic\nenterprise OS security threat in a multi-host environment sandbox by hard-coded\nevaluation. We evaluate the existing five mainstream CUAs, including ReAct,\nAutoGPT, Gemini CLI, Cursor CLI, and Cursor IDE based on 8 foundation LLMs. The\nresults demonstrate that current frontier CUAs do not adequately cover OS\nsecurity-centric threats. These capabilities of CUAs reduce dependence on\ncustom malware and deep domain expertise, enabling even inexperienced attackers\nto mount complex enterprise intrusions, which raises social concern about the\nresponsibility and security of CUAs."}
{"id": "2510.06629", "categories": ["cs.CR", "cs.CV", "cs.LG"], "pdf": "https://arxiv.org/pdf/2510.06629", "abs": "https://arxiv.org/abs/2510.06629", "authors": ["Jiachen Li", "Bang Wu", "Xiaoyu Xia", "Xiaoning Liu", "Xun Yi", "Xiuzhen Zhang"], "title": "Unsupervised Backdoor Detection and Mitigation for Spiking Neural Networks", "comment": "To appear in The 28th International Symposium on Research in Attacks,\n  Intrusions and Defenses (RAID 2025)", "summary": "Spiking Neural Networks (SNNs) have gained increasing attention for their\nsuperior energy efficiency compared to Artificial Neural Networks (ANNs).\nHowever, their security aspects, particularly under backdoor attacks, have\nreceived limited attention. Existing defense methods developed for ANNs perform\npoorly or can be easily bypassed in SNNs due to their event-driven and temporal\ndependencies. This paper identifies the key blockers that hinder traditional\nbackdoor defenses in SNNs and proposes an unsupervised post-training detection\nframework, Temporal Membrane Potential Backdoor Detection (TMPBD), to overcome\nthese challenges. TMPBD leverages the maximum margin statistics of temporal\nmembrane potential (TMP) in the final spiking layer to detect target labels\nwithout any attack knowledge or data access. We further introduce a robust\nmitigation mechanism, Neural Dendrites Suppression Backdoor Mitigation (NDSBM),\nwhich clamps dendritic connections between early convolutional layers to\nsuppress malicious neurons while preserving benign behaviors, guided by TMP\nextracted from a small, clean, unlabeled dataset. Extensive experiments on\nmultiple neuromorphic benchmarks and state-of-the-art input-aware dynamic\ntrigger attacks demonstrate that TMPBD achieves 100% detection accuracy, while\nNDSBM reduces the attack success rate from 100% to 8.44%, and to 2.81% when\ncombined with detection, without degrading clean accuracy."}
{"id": "2510.06645", "categories": ["cs.CR", "cs.AI"], "pdf": "https://arxiv.org/pdf/2510.06645", "abs": "https://arxiv.org/abs/2510.06645", "authors": ["Zhiyuan Wei", "Xiaoxuan Yang", "Jing Sun", "Zijian Zhang"], "title": "Distilling Lightweight Language Models for C/C++ Vulnerabilities", "comment": "25 pages, 10 figures", "summary": "The increasing complexity of modern software systems exacerbates the\nprevalence of security vulnerabilities, posing risks of severe breaches and\nsubstantial economic loss. Consequently, robust code vulnerability detection is\nessential for software security. While Large Language Models (LLMs) have\ndemonstrated remarkable capabilities in natural language processing, their\npotential for automated code vulnerability detection remains underexplored.\nThis paper presents FineSec, a novel framework that harnesses LLMs through\nknowledge distillation to enable efficient and precise vulnerability\nidentification in C/C++ codebases. FineSec utilizes knowledge distillation to\ntransfer expertise from large teacher models to compact student models,\nachieving high accuracy with minimal computational cost. By integrating data\npreparation, training, evaluation, and continuous learning into a unified,\nsingle-task workflow, FineSec offers a streamlined approach. Extensive\nevaluations on C/C++ codebases demonstrate its superiority over both base\nmodels and larger LLMs in identifying complex vulnerabilities and logical\nflaws, establishing FineSec as a practical and scalable solution for real-world\nsoftware security. To facilitate reproducibility, the datasets, source code,\nand experimental results are made publicly available at:\nhttps://github.com/yangxiaoxuan123/FineSec_detect."}
{"id": "2510.06719", "categories": ["cs.CR", "cs.CL", "cs.LG"], "pdf": "https://arxiv.org/pdf/2510.06719", "abs": "https://arxiv.org/abs/2510.06719", "authors": ["Junki Mori", "Kazuya Kakizaki", "Taiki Miyagawa", "Jun Sakuma"], "title": "Differentially Private Synthetic Text Generation for Retrieval-Augmented Generation (RAG)", "comment": "Under review", "summary": "Retrieval-Augmented Generation (RAG) enhances large language models (LLMs) by\ngrounding them in external knowledge. However, its application in sensitive\ndomains is limited by privacy risks. Existing private RAG methods typically\nrely on query-time differential privacy (DP), which requires repeated noise\ninjection and leads to accumulated privacy loss. To address this issue, we\npropose DP-SynRAG, a framework that uses LLMs to generate differentially\nprivate synthetic RAG databases. Unlike prior methods, the synthetic text can\nbe reused once created, thereby avoiding repeated noise injection and\nadditional privacy costs. To preserve essential information for downstream RAG\ntasks, DP-SynRAG extends private prediction, which instructs LLMs to generate\ntext that mimics subsampled database records in a DP manner. Experiments show\nthat DP-SynRAG achieves superior performanec to the state-of-the-art private\nRAG systems while maintaining a fixed privacy budget, offering a scalable\nsolution for privacy-preserving RAG."}
{"id": "2510.06784", "categories": ["cs.CR", "cs.CV"], "pdf": "https://arxiv.org/pdf/2510.06784", "abs": "https://arxiv.org/abs/2510.06784", "authors": ["Dmytro Zakharov", "Oleksandr Kurbatov", "Artem Sdobnov", "Lev Soukhanov", "Yevhenii Sekhin", "Vitalii Volovyk", "Mykhailo Velykodnyi", "Mark Cherepovskyi", "Kyrylo Baibula", "Lasha Antadze", "Pavlo Kravchenko", "Volodymyr Dubinin", "Yaroslav Panasenko"], "title": "Bionetta: Efficient Client-Side Zero-Knowledge Machine Learning Proving", "comment": null, "summary": "In this report, we compare the performance of our UltraGroth-based\nzero-knowledge machine learning framework Bionetta to other tools of similar\npurpose such as EZKL, Lagrange's deep-prove, or zkml. The results show a\nsignificant boost in the proving time for custom-crafted neural networks: they\ncan be proven even on mobile devices, enabling numerous client-side proving\napplications. While our scheme increases the cost of one-time preprocessing\nsteps, such as circuit compilation and generating trusted setup, our approach\nis, to the best of our knowledge, the only one that is deployable on the native\nEVM smart contracts without overwhelming proof size and verification overheads."}
{"id": "2510.06823", "categories": ["cs.CR", "cs.CL", "cs.IR"], "pdf": "https://arxiv.org/pdf/2510.06823", "abs": "https://arxiv.org/abs/2510.06823", "authors": ["Riku Mochizuki", "Shusuke Komatsu", "Souta Noguchi", "Kazuto Ataka"], "title": "Exposing Citation Vulnerabilities in Generative Engines", "comment": "12 pages, under-reviewing at a conference", "summary": "We analyze answers generated by generative engines (GEs) from the\nperspectives of citation publishers and the content-injection barrier, defined\nas the difficulty for attackers to manipulate answers to user prompts by\nplacing malicious content on the web. GEs integrate two functions: web search\nand answer generation that cites web pages using large language models. Because\nanyone can publish information on the web, GEs are vulnerable to poisoning\nattacks. Existing studies of citation evaluation focus on how faithfully answer\ncontent reflects cited sources, leaving unexamined which web sources should be\nselected as citations to defend against poisoning attacks. To fill this gap, we\nintroduce evaluation criteria that assess poisoning threats using the citation\ninformation contained in answers. Our criteria classify the publisher\nattributes of citations to estimate the content-injection barrier thereby\nrevealing the threat of poisoning attacks in current GEs. We conduct\nexperiments in political domains in Japan and the United States (U.S.) using\nour criteria and show that citations from official party websites (primary\nsources) are approximately \\(25\\%\\)--\\(45\\%\\) in the U.S. and\n\\(60\\%\\)--\\(65\\%\\) in Japan, indicating that U.S. political answers are at\nhigher risk of poisoning attacks. We also find that sources with low\ncontent-injection barriers are frequently cited yet are poorly reflected in\nanswer content. To mitigate this threat, we discuss how publishers of primary\nsources can increase exposure of their web content in answers and show that\nwell-known techniques are limited by language differences."}
{"id": "2510.06951", "categories": ["cs.CR"], "pdf": "https://arxiv.org/pdf/2510.06951", "abs": "https://arxiv.org/abs/2510.06951", "authors": ["Philip Huff", "Nishka Gandu", "Pavel Novák"], "title": "I Can't Patch My OT Systems! A Look at CISA's KEVC Workarounds & Mitigations for OT", "comment": "8 pages, 6 figures. Supported by DOE Grant CR0000031", "summary": "We examine the state of publicly available information about known\nexploitable vulnerabilities applicable to operational technology (OT)\nenvironments. Specifically, we analyze the Known Exploitable Vulnerabilities\nCatalog (KEVC) maintained by the US Department of Homeland Security\nCybersecurity and Infrastructure Security Agency (CISA) to assess whether\ncurrently available data is sufficient for effective and reliable remediation\nin OT settings. Our team analyzed all KEVC entries through July 2025 to\ndetermine the extent to which OT environments can rely on existing remediation\nrecommendations. We found that although most entries in the KEVC could affect\nOT environments, only 13% include vendor workarounds or mitigations as\nalternatives to patching. This paper also examines the feasibility of\ndeveloping such alternatives based on vulnerability and exploit\ncharacteristics, and we present early evidence of success with this approach."}
{"id": "2510.06975", "categories": ["cs.CR", "cs.AI", "cs.CL"], "pdf": "https://arxiv.org/pdf/2510.06975", "abs": "https://arxiv.org/abs/2510.06975", "authors": ["Muris Sladić", "Veronica Valeros", "Carlos Catania", "Sebastian Garcia"], "title": "VelLMes: A high-interaction AI-based deception framework", "comment": "9 pages. 9 figures. 1 table. This is a preprint of a paper that was\n  presented at the Active Defense and Deception Workshop colocated with IEEE\n  EuroS&P 2025 conference", "summary": "There are very few SotA deception systems based on Large Language Models. The\nexisting ones are limited only to simulating one type of service, mainly SSH\nshells. These systems - but also the deception technologies not based on LLMs -\nlack an extensive evaluation that includes human attackers. Generative AI has\nrecently become a valuable asset for cybersecurity researchers and\npractitioners, and the field of cyber-deception is no exception. Researchers\nhave demonstrated how LLMs can be leveraged to create realistic-looking\nhoneytokens, fake users, and even simulated systems that can be used as\nhoneypots. This paper presents an AI-based deception framework called VelLMes,\nwhich can simulate multiple protocols and services such as SSH Linux shell,\nMySQL, POP3, and HTTP. All of these can be deployed and used as honeypots, thus\nVelLMes offers a variety of choices for deception design based on the users'\nneeds. VelLMes is designed to be attacked by humans, so interactivity and\nrealism are key for its performance. We evaluate the generative capabilities\nand the deception capabilities. Generative capabilities were evaluated using\nunit tests for LLMs. The results of the unit tests show that, with careful\nprompting, LLMs can produce realistic-looking responses, with some LLMs having\na 100% passing rate. In the case of the SSH Linux shell, we evaluated deception\ncapabilities with 89 human attackers. The results showed that about 30% of the\nattackers thought that they were interacting with a real system when they were\nassigned an LLM-based honeypot. Lastly, we deployed 10 instances of the SSH\nLinux shell honeypot on the Internet to capture real-life attacks. Analysis of\nthese attacks showed us that LLM honeypots simulating Linux shells can perform\nwell against unstructured and unexpected attacks on the Internet, responding\ncorrectly to most of the issued commands."}
{"id": "2510.06994", "categories": ["cs.CR", "cs.CL"], "pdf": "https://arxiv.org/pdf/2510.06994", "abs": "https://arxiv.org/abs/2510.06994", "authors": ["Artur Horal", "Daniel Pina", "Henrique Paz", "Iago Paulo", "João Soares", "Rafael Ferreira", "Diogo Tavares", "Diogo Glória-Silva", "João Magalhães", "David Semedo"], "title": "RedTWIZ: Diverse LLM Red Teaming via Adaptive Attack Planning", "comment": null, "summary": "This paper presents the vision, scientific contributions, and technical\ndetails of RedTWIZ: an adaptive and diverse multi-turn red teaming framework,\nto audit the robustness of Large Language Models (LLMs) in AI-assisted software\ndevelopment. Our work is driven by three major research streams: (1) robust and\nsystematic assessment of LLM conversational jailbreaks; (2) a diverse\ngenerative multi-turn attack suite, supporting compositional, realistic and\ngoal-oriented jailbreak conversational strategies; and (3) a hierarchical\nattack planner, which adaptively plans, serializes, and triggers attacks\ntailored to specific LLM's vulnerabilities. Together, these contributions form\na unified framework -- combining assessment, attack generation, and strategic\nplanning -- to comprehensively evaluate and expose weaknesses in LLMs'\nrobustness. Extensive evaluation is conducted to systematically assess and\nanalyze the performance of the overall system and each component. Experimental\nresults demonstrate that our multi-turn adversarial attack strategies can\nsuccessfully lead state-of-the-art LLMs to produce unsafe generations,\nhighlighting the pressing need for more research into enhancing LLM's\nrobustness."}
{"id": "2510.07080", "categories": ["cs.CR", "cs.LG"], "pdf": "https://arxiv.org/pdf/2510.07080", "abs": "https://arxiv.org/abs/2510.07080", "authors": ["Maxime Reynouard"], "title": "Pseudo-MDPs: A Novel Framework for Efficiently Optimizing Last Revealer Seed Manipulations in Blockchains", "comment": null, "summary": "This study tackles the computational challenges of solving Markov Decision\nProcesses (MDPs) for a restricted class of problems. It is motivated by the\nLast Revealer Attack (LRA), which undermines fairness in some Proof-of-Stake\n(PoS) blockchains such as Ethereum (\\$400B market capitalization). We introduce\npseudo-MDPs (pMDPs) a framework that naturally models such problems and propose\ntwo distinct problem reductions to standard MDPs. One problem reduction\nprovides a novel, counter-intuitive perspective, and combining the two problem\nreductions enables significant improvements in dynamic programming algorithms\nsuch as value iteration. In the case of the LRA which size is parameterized by\n$\\kappa$ (in Ethereum's case $\\kappa$= 325), we reduce the computational\ncomplexity from $O(2^\\kappa \\kappa^{2^{\\kappa+2}})$ to $O(\\kappa^4)$ (per\niteration). This solution also provide the usual benefits from Dynamic\nProgramming solutions: exponentially fast convergence toward the optimal\nsolution is guaranteed. The dual perspective also simplifies policy extraction,\nmaking the approach well-suited for resource-constrained agents who can operate\nwith very limited memory and computation once the problem has been solved.\nFurthermore, we generalize those results to a broader class of MDPs, enhancing\ntheir applicability. The framework is validated through two case studies: a\nfictional card game and the LRA on the Ethereum random seed consensus protocol.\nThese applications demonstrate the framework's ability to solve large-scale\nproblems effectively while offering actionable insights into optimal\nstrategies. This work advances the study of MDPs and contributes to\nunderstanding security vulnerabilities in blockchain systems."}
{"id": "2510.07109", "categories": ["cs.CR", "cs.LG", "cs.NI", "C.2.0; C.2.1; C.2.3; C.2.5; I.2.6; K.6.5"], "pdf": "https://arxiv.org/pdf/2510.07109", "abs": "https://arxiv.org/abs/2510.07109", "authors": ["Guan-Yan Yang", "Farn Wang", "Kuo-Hui Yeh"], "title": "GNN-enhanced Traffic Anomaly Detection for Next-Generation SDN-Enabled Consumer Electronics", "comment": "This paper has been accepted for publication in IEEE Transactions on\n  Consumer Electronics. 10 pages, 6 figures", "summary": "Consumer electronics (CE) connected to the Internet of Things are susceptible\nto various attacks, including DDoS and web-based threats, which can compromise\ntheir functionality and facilitate remote hijacking. These vulnerabilities\nallow attackers to exploit CE for broader system attacks while enabling the\npropagation of malicious code across the CE network, resulting in device\nfailures. Existing deep learning-based traffic anomaly detection systems\nexhibit high accuracy in traditional network environments but are often overly\ncomplex and reliant on static infrastructure, necessitating manual\nconfiguration and management. To address these limitations, we propose a\nscalable network model that integrates Software-defined Networking (SDN) and\nCompute First Networking (CFN) for next-generation CE networks. In this network\nmodel, we propose a Graph Neural Networks-based Network Anomaly Detection\nframework (GNN-NAD) that integrates SDN-based CE networks and enables the CFN\narchitecture. GNN-NAD uniquely fuses a static, vulnerability-aware attack graph\nwith dynamic traffic features, providing a holistic view of network security.\nThe core of the framework is a GNN model (GSAGE) for graph representation\nlearning, followed by a Random Forest (RF) classifier. This design (GSAGE+RF)\ndemonstrates superior performance compared to existing feature selection\nmethods. Experimental evaluations on CE environment reveal that GNN-NAD\nachieves superior metrics in accuracy, recall, precision, and F1 score, even\nwith small sample sizes, exceeding the performance of current network anomaly\ndetection methods. This work advances the security and efficiency of\nnext-generation intelligent CE networks."}
{"id": "2510.07171", "categories": ["cs.CR"], "pdf": "https://arxiv.org/pdf/2510.07171", "abs": "https://arxiv.org/abs/2510.07171", "authors": ["Rishabh Das. Aaron Werth", "Tommy Morris"], "title": "A multi-layered embedded intrusion detection framework for programmable logic controllers", "comment": null, "summary": "Industrial control system (ICS) operations use trusted endpoints like human\nmachine interfaces (HMIs) and workstations to relay commands to programmable\nlogic controllers (PLCs). Because most PLCs lack layered defenses, compromise\nof a trusted endpoint can drive unsafe actuator commands and risk\nsafety-critical operation. This research presents an embedded intrusion\ndetection system that runs inside the controller and uses header-level\ntelemetry to detect and respond to network attacks. The system combines a\nsemi-supervised anomaly detector and a supervised attack classifier. We\nevaluate the approach on a midstream oil-terminal testbed using three datasets\ncollected during tanker-truck loading. The anomaly detector achieves zero\nmissed attacks, corresponding to 0.998 Matthews correlation. The supervised\nstage attains 97.37 percent hold-out accuracy and 97.03 percent external\naccuracy. The embedded design adds a median of 2,031 microseconds of end-to-end\nlatency and does not impact PLC's cycle time. The proposed architecture\nprovides a multi-layer embedded security that meets the real-time requirements\nof an industrial system."}
{"id": "2510.07176", "categories": ["cs.CR"], "pdf": "https://arxiv.org/pdf/2510.07176", "abs": "https://arxiv.org/abs/2510.07176", "authors": ["Yixiang Zhang", "Xinhao Deng", "Zhongyi Gu", "Yihao Chen", "Ke Xu", "Qi Li", "Jianping Wu"], "title": "Exposing LLM User Privacy via Traffic Fingerprint Analysis: A Study of Privacy Risks in LLM Agent Interactions", "comment": "26 pages with 11 figures", "summary": "Large Language Models (LLMs) are increasingly deployed as agents that\norchestrate tasks and integrate external tools to execute complex workflows. We\ndemonstrate that these interactive behaviors leave distinctive fingerprints in\nencrypted traffic exchanged between users and LLM agents. By analyzing traffic\npatterns associated with agent workflows and tool invocations, adversaries can\ninfer agent activities, distinguish specific agents, and even profile sensitive\nuser attributes. To highlight this risk, we develop AgentPrint, which achieves\nan F1-score of 0.866 in agent identification and attains 73.9% and 69.1% top-3\naccuracy in user attribute inference for simulated- and real-user settings,\nrespectively. These results uncover an overlooked risk: the very interactivity\nthat empowers LLM agents also exposes user privacy, underscoring the urgent\nneed for technical countermeasures alongside regulatory and policy safeguards."}
{"id": "2510.07219", "categories": ["cs.CR"], "pdf": "https://arxiv.org/pdf/2510.07219", "abs": "https://arxiv.org/abs/2510.07219", "authors": ["Yuhua Xu", "Wei Sun", "Chengpei Tang", "Jiaxing Lu", "Jingying Zhou", "Chen Gu"], "title": "Security-Robustness Trade-offs in Diffusion Steganography: A Comparative Analysis of Pixel-Space and VAE-Based Architectures", "comment": "13 pages", "summary": "Current generative steganography research mainly pursues computationally\nexpensive mappings to perfect Gaussian priors within single diffusion model\narchitectures. This work introduces an efficient framework based on approximate\nGaussian mapping governed by a scale factor calibrated through capacity-aware\nadaptive optimization. Using this framework as a unified analytical tool,\nsystematic comparative analysis of steganography in pixel-space models versus\nVAE-based latent-space systems is conducted. The investigation reveals a\npronounced architecture dependent security-robustness trade-off: pixel-space\nmodels achieve high security against steganalysis but exhibit fragility to\nchannel distortions, while VAE-based systems like Stable Diffusion offer\nsubstantial robustness at the cost of security vulnerabilities. Further\nanalysis indicates that the VAE component drives this behavior through opposing\nmechanisms where the encoder confers robustness via manifold regularization\nwhile the decoder introduces vulnerabilities by amplifying latent perturbations\ninto detectable artifacts. These findings characterize the conflicting\narchitectural roles in generative steganography and establish a foundation for\nfuture research."}
